{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BVXP5ggLoca",
        "outputId": "0e13e3a1-44bf-4282-8a2b-594b0d037ac6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colab-xterm\n",
            "  Downloading colab_xterm-0.2.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: ptyprocess~=0.7.0 in /usr/local/lib/python3.11/dist-packages (from colab-xterm) (0.7.0)\n",
            "Requirement already satisfied: tornado>5.1 in /usr/local/lib/python3.11/dist-packages (from colab-xterm) (6.4.2)\n",
            "Downloading colab_xterm-0.2.0-py3-none-any.whl (115 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/115.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m112.6/115.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.6/115.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: colab-xterm\n",
            "Successfully installed colab-xterm-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install colab-xterm\n",
        "%load_ext colabxterm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# curl -fsSL https://ollama.com/install.sh | sh\n",
        "# ollama serve & ollama pull llama3 & ollama pull nomic-embed-text"
      ],
      "metadata": {
        "id": "8nwHS8Q4S3Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "3H6Y0_9lcyjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "https://localhost:10000/": {
              "data": "PCFkb2N0eXBlIGh0bWw+PGh0bWw+PGhlYWQ+PG1ldGEgY2hhcnNldD0idXRmLTgiLz48c2NyaXB0IGRlZmVyPSJkZWZlciIgc3JjPSJtYWluLmpzIj48L3NjcmlwdD48L2hlYWQ+PGJvZHk+PGRpdiBpZD0idGVybWluYWwiPjwvZGl2PjwvYm9keT48L2h0bWw+",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/main.js": {
              "data": "/*! For license information please see main.js.LICENSE.txt */
(()=>{var e={102:(e,t,r)=>{"use strict";r.d(t,{Z:()=>a});var i=r(81),n=r.n(i),o=r(645),s=r.n(o)()(n());s.push([e.id,'/**\n * Copyright (c) 2014 The xterm.js authors. All rights reserved.\n * Copyright (c) 2012-2013, Christopher Jeffrey (MIT License)\n * https://github.com/chjj/term.js\n * @license MIT\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this software and associated documentation files (the "Software"), to deal\n * in the Software without restriction, including without limitation the rights\n * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n * copies of the Software, and to permit persons to whom the Software is\n * furnished to do so, subject to the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n * THE SOFTWARE.\n *\n * Originally forked from (with the author\'s permission):\n *   Fabrice Bellard\'s javascript vt100 for jslinux:\n *   http://bellard.org/jslinux/\n *   Copyright (c) 2011 Fabrice Bellard\n *   The original design remains. The terminal itself\n *   has been extended to include xterm CSI codes, among\n *   other features.\n */\n\n/**\n *  Default styles for xterm.js\n */\n\n.xterm {\n    position: relative;\n    -moz-user-select: none;\n         user-select: none;\n    -ms-user-select: none;\n    -webkit-user-select: none;\n}\n\n.xterm.focus,\n.xterm:focus {\n    outline: none;\n}\n\n.xterm .xterm-helpers {\n    position: absolute;\n    top: 0;\n    /**\n     * The z-index of the helpers must be higher than the canvases in order for\n     * IMEs to appear on top.\n     */\n    z-index: 5;\n}\n\n.xterm .xterm-helper-textarea {\n    padding: 0;\n    border: 0;\n    margin: 0;\n    /* Move textarea out of the screen to the far left, so that the cursor is not visible */\n    position: absolute;\n    opacity: 0;\n    left: -9999em;\n    top: 0;\n    width: 0;\n    height: 0;\n    z-index: -5;\n    /** Prevent wrapping so the IME appears against the textarea at the correct position */\n    white-space: nowrap;\n    overflow: hidden;\n    resize: none;\n}\n\n.xterm .composition-view {\n    /* TODO: Composition position got messed up somewhere */\n    background: #000;\n    color: #FFF;\n    display: none;\n    position: absolute;\n    white-space: nowrap;\n    z-index: 1;\n}\n\n.xterm .composition-view.active {\n    display: block;\n}\n\n.xterm .xterm-viewport {\n    /* On OS X this is required in order for the scroll bar to appear fully opaque */\n    background-color: #000;\n    overflow-y: scroll;\n    cursor: default;\n    position: absolute;\n    right: 0;\n    left: 0;\n    top: 0;\n    bottom: 0;\n}\n\n.xterm .xterm-screen {\n    position: relative;\n}\n\n.xterm .xterm-screen canvas {\n    position: absolute;\n    left: 0;\n    top: 0;\n}\n\n.xterm .xterm-scroll-area {\n    visibility: hidden;\n}\n\n.xterm-char-measure-element {\n    display: inline-block;\n    visibility: hidden;\n    position: absolute;\n    top: 0;\n    left: -9999em;\n    line-height: normal;\n}\n\n.xterm {\n    cursor: text;\n}\n\n.xterm.enable-mouse-events {\n    /* When mouse events are enabled (eg. tmux), revert to the standard pointer cursor */\n    cursor: default;\n}\n\n.xterm.xterm-cursor-pointer,\n.xterm .xterm-cursor-pointer {\n    cursor: pointer;\n}\n\n.xterm.column-select.focus {\n    /* Column selection mode */\n    cursor: crosshair;\n}\n\n.xterm .xterm-accessibility,\n.xterm .xterm-message {\n    position: absolute;\n    left: 0;\n    top: 0;\n    bottom: 0;\n    right: 0;\n    z-index: 10;\n    color: transparent;\n}\n\n.xterm .live-region {\n    position: absolute;\n    left: -9999px;\n    width: 1px;\n    height: 1px;\n    overflow: hidden;\n}\n\n.xterm-dim {\n    opacity: 0.5;\n}\n\n.xterm-underline {\n    text-decoration: underline;\n}\n\n.xterm-strikethrough {\n    text-decoration: line-through;\n}\n',""]);const a=s},645:e=>{"use strict";e.exports=function(e){var t=[];return t.toString=function(){return this.map((function(t){var r="",i=void 0!==t[5];return t[4]&&(r+="@supports (".concat(t[4],") {")),t[2]&&(r+="@media ".concat(t[2]," {")),i&&(r+="@layer".concat(t[5].length>0?" ".concat(t[5]):""," {")),r+=e(t),i&&(r+="}"),t[2]&&(r+="}"),t[4]&&(r+="}"),r})).join("")},t.i=function(e,r,i,n,o){"string"==typeof e&&(e=[[null,e,void 0]]);var s={};if(i)for(var a=0;a<this.length;a++){var c=this[a][0];null!=c&&(s[c]=!0)}for(var l=0;l<e.length;l++){var u=[].concat(e[l]);i&&s[u[0]]||(void 0!==o&&(void 0===u[5]||(u[1]="@layer".concat(u[5].length>0?" ".concat(u[5]):""," {").concat(u[1],"}")),u[5]=o),r&&(u[2]?(u[1]="@media ".concat(u[2]," {").concat(u[1],"}"),u[2]=r):u[2]=r),n&&(u[4]?(u[1]="@supports (".concat(u[4],") {").concat(u[1],"}"),u[4]=n):u[4]="".concat(n)),t.push(u))}},t}},81:e=>{"use strict";e.exports=function(e){return e[1]}},486:function(e,t,r){var i;e=r.nmd(e),function(){var n,o="Expected a function",s="__lodash_hash_undefined__",a="__lodash_placeholder__",c=32,l=128,u=1/0,h=9007199254740991,f=NaN,_=4294967295,d=[["ary",l],["bind",1],["bindKey",2],["curry",8],["curryRight",16],["flip",512],["partial",c],["partialRight",64],["rearg",256]],p="[object Arguments]",v="[object Array]",g="[object Boolean]",y="[object Date]",m="[object Error]",b="[object Function]",S="[object GeneratorFunction]",C="[object Map]",w="[object Number]",L="[object Object]",E="[object Promise]",x="[object RegExp]",A="[object Set]",k="[object String]",M="[object Symbol]",R="[object WeakMap]",T="[object ArrayBuffer]",O="[object DataView]",B="[object Float32Array]",D="[object Float64Array]",P="[object Int8Array]",I="[object Int16Array]",H="[object Int32Array]",j="[object Uint8Array]",F="[object Uint8ClampedArray]",W="[object Uint16Array]",U="[object Uint32Array]",q=/\b__p \+= '';/g,N=/\b(__p \+=) '' \+/g,z=/(__e\(.*?\)|\b__t\)) \+\n'';/g,K=/&(?:amp|lt|gt|quot|#39);/g,V=/[&<>"']/g,G=RegExp(K.source),Y=RegExp(V.source),X=/<%-([\s\S]+?)%>/g,Z=/<%([\s\S]+?)%>/g,J=/<%=([\s\S]+?)%>/g,$=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,Q=/^\w*$/,ee=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,te=/[\\^$.*+?()[\]{}|]/g,re=RegExp(te.source),ie=/^\s+/,ne=/\s/,oe=/\{(?:\n\/\* \[wrapped with .+\] \*\/)?\n?/,se=/\{\n\/\* \[wrapped with (.+)\] \*/,ae=/,? & /,ce=/[^\x00-\x2f\x3a-\x40\x5b-\x60\x7b-\x7f]+/g,le=/[()=,{}\[\]\/\s]/,ue=/\\(\\)?/g,he=/\$\{([^\\}]*(?:\\.[^\\}]*)*)\}/g,fe=/\w*$/,_e=/^[-+]0x[0-9a-f]+$/i,de=/^0b[01]+$/i,pe=/^\[object .+?Constructor\]$/,ve=/^0o[0-7]+$/i,ge=/^(?:0|[1-9]\d*)$/,ye=/[\xc0-\xd6\xd8-\xf6\xf8-\xff\u0100-\u017f]/g,me=/($^)/,be=/['\n\r\u2028\u2029\\]/g,Se="\\u0300-\\u036f\\ufe20-\\ufe2f\\u20d0-\\u20ff",Ce="a-z\\xdf-\\xf6\\xf8-\\xff",we="A-Z\\xc0-\\xd6\\xd8-\\xde",Le="\\xac\\xb1\\xd7\\xf7\\x00-\\x2f\\x3a-\\x40\\x5b-\\x60\\x7b-\\xbf\\u2000-\\u206f \\t\\x0b\\f\\xa0\\ufeff\\n\\r\\u2028\\u2029\\u1680\\u180e\\u2000\\u2001\\u2002\\u2003\\u2004\\u2005\\u2006\\u2007\\u2008\\u2009\\u200a\\u202f\\u205f\\u3000",Ee="["+Le+"]",xe="["+Se+"]",Ae="\\d+",ke="["+Ce+"]",Me="[^\\ud800-\\udfff"+Le+Ae+"\\u2700-\\u27bf"+Ce+we+"]",Re="\\ud83c[\\udffb-\\udfff]",Te="[^\\ud800-\\udfff]",Oe="(?:\\ud83c[\\udde6-\\uddff]){2}",Be="[\\ud800-\\udbff][\\udc00-\\udfff]",De="["+we+"]",Pe="(?:"+ke+"|"+Me+")",Ie="(?:"+De+"|"+Me+")",He="(?:['’](?:d|ll|m|re|s|t|ve))?",je="(?:['’](?:D|LL|M|RE|S|T|VE))?",Fe="(?:"+xe+"|"+Re+")?",We="[\\ufe0e\\ufe0f]?",Ue=We+Fe+"(?:\\u200d(?:"+[Te,Oe,Be].join("|")+")"+We+Fe+")*",qe="(?:"+["[\\u2700-\\u27bf]",Oe,Be].join("|")+")"+Ue,Ne="(?:"+[Te+xe+"?",xe,Oe,Be,"[\\ud800-\\udfff]"].join("|")+")",ze=RegExp("['’]","g"),Ke=RegExp(xe,"g"),Ve=RegExp(Re+"(?="+Re+")|"+Ne+Ue,"g"),Ge=RegExp([De+"?"+ke+"+"+He+"(?="+[Ee,De,"$"].join("|")+")",Ie+"+"+je+"(?="+[Ee,De+Pe,"$"].join("|")+")",De+"?"+Pe+"+"+He,De+"+"+je,"\\d*(?:1ST|2ND|3RD|(?![123])\\dTH)(?=\\b|[a-z_])","\\d*(?:1st|2nd|3rd|(?![123])\\dth)(?=\\b|[A-Z_])",Ae,qe].join("|"),"g"),Ye=RegExp("[\\u200d\\ud800-\\udfff"+Se+"\\ufe0e\\ufe0f]"),Xe=/[a-z][A-Z]|[A-Z]{2}[a-z]|[0-9][a-zA-Z]|[a-zA-Z][0-9]|[^a-zA-Z0-9 ]/,Ze=["Array","Buffer","DataView","Date","Error","Float32Array","Float64Array","Function","Int8Array","Int16Array","Int32Array","Map","Math","Object","Promise","RegExp","Set","String","Symbol","TypeError","Uint8Array","Uint8ClampedArray","Uint16Array","Uint32Array","WeakMap","_","clearTimeout","isFinite","parseInt","setTimeout"],Je=-1,$e={};$e[B]=$e[D]=$e[P]=$e[I]=$e[H]=$e[j]=$e[F]=$e[W]=$e[U]=!0,$e[p]=$e[v]=$e[T]=$e[g]=$e[O]=$e[y]=$e[m]=$e[b]=$e[C]=$e[w]=$e[L]=$e[x]=$e[A]=$e[k]=$e[R]=!1;var Qe={};Qe[p]=Qe[v]=Qe[T]=Qe[O]=Qe[g]=Qe[y]=Qe[B]=Qe[D]=Qe[P]=Qe[I]=Qe[H]=Qe[C]=Qe[w]=Qe[L]=Qe[x]=Qe[A]=Qe[k]=Qe[M]=Qe[j]=Qe[F]=Qe[W]=Qe[U]=!0,Qe[m]=Qe[b]=Qe[R]=!1;var et={"\\":"\\","'":"'","\n":"n","\r":"r","\u2028":"u2028","\u2029":"u2029"},tt=parseFloat,rt=parseInt,it="object"==typeof r.g&&r.g&&r.g.Object===Object&&r.g,nt="object"==typeof self&&self&&self.Object===Object&&self,ot=it||nt||Function("return this")(),st=t&&!t.nodeType&&t,at=st&&e&&!e.nodeType&&e,ct=at&&at.exports===st,lt=ct&&it.process,ut=function(){try{return at&&at.require&&at.require("util").types||lt&&lt.binding&&lt.binding("util")}catch(e){}}(),ht=ut&&ut.isArrayBuffer,ft=ut&&ut.isDate,_t=ut&&ut.isMap,dt=ut&&ut.isRegExp,pt=ut&&ut.isSet,vt=ut&&ut.isTypedArray;function gt(e,t,r){switch(r.length){case 0:return e.call(t);case 1:return e.call(t,r[0]);case 2:return e.call(t,r[0],r[1]);case 3:return e.call(t,r[0],r[1],r[2])}return e.apply(t,r)}function yt(e,t,r,i){for(var n=-1,o=null==e?0:e.length;++n<o;){var s=e[n];t(i,s,r(s),e)}return i}function mt(e,t){for(var r=-1,i=null==e?0:e.length;++r<i&&!1!==t(e[r],r,e););return e}function bt(e,t){for(var r=null==e?0:e.length;r--&&!1!==t(e[r],r,e););return e}function St(e,t){for(var r=-1,i=null==e?0:e.length;++r<i;)if(!t(e[r],r,e))return!1;return!0}function Ct(e,t){for(var r=-1,i=null==e?0:e.length,n=0,o=[];++r<i;){var s=e[r];t(s,r,e)&&(o[n++]=s)}return o}function wt(e,t){return!(null==e||!e.length)&&Bt(e,t,0)>-1}function Lt(e,t,r){for(var i=-1,n=null==e?0:e.length;++i<n;)if(r(t,e[i]))return!0;return!1}function Et(e,t){for(var r=-1,i=null==e?0:e.length,n=Array(i);++r<i;)n[r]=t(e[r],r,e);return n}function xt(e,t){for(var r=-1,i=t.length,n=e.length;++r<i;)e[n+r]=t[r];return e}function At(e,t,r,i){var n=-1,o=null==e?0:e.length;for(i&&o&&(r=e[++n]);++n<o;)r=t(r,e[n],n,e);return r}function kt(e,t,r,i){var n=null==e?0:e.length;for(i&&n&&(r=e[--n]);n--;)r=t(r,e[n],n,e);return r}function Mt(e,t){for(var r=-1,i=null==e?0:e.length;++r<i;)if(t(e[r],r,e))return!0;return!1}var Rt=Ht("length");function Tt(e,t,r){var i;return r(e,(function(e,r,n){if(t(e,r,n))return i=r,!1})),i}function Ot(e,t,r,i){for(var n=e.length,o=r+(i?1:-1);i?o--:++o<n;)if(t(e[o],o,e))return o;return-1}function Bt(e,t,r){return t==t?function(e,t,r){for(var i=r-1,n=e.length;++i<n;)if(e[i]===t)return i;return-1}(e,t,r):Ot(e,Pt,r)}function Dt(e,t,r,i){for(var n=r-1,o=e.length;++n<o;)if(i(e[n],t))return n;return-1}function Pt(e){return e!=e}function It(e,t){var r=null==e?0:e.length;return r?Wt(e,t)/r:f}function Ht(e){return function(t){return null==t?n:t[e]}}function jt(e){return function(t){return null==e?n:e[t]}}function Ft(e,t,r,i,n){return n(e,(function(e,n,o){r=i?(i=!1,e):t(r,e,n,o)})),r}function Wt(e,t){for(var r,i=-1,o=e.length;++i<o;){var s=t(e[i]);s!==n&&(r=r===n?s:r+s)}return r}function Ut(e,t){for(var r=-1,i=Array(e);++r<e;)i[r]=t(r);return i}function qt(e){return e?e.slice(0,sr(e)+1).replace(ie,""):e}function Nt(e){return function(t){return e(t)}}function zt(e,t){return Et(t,(function(t){return e[t]}))}function Kt(e,t){return e.has(t)}function Vt(e,t){for(var r=-1,i=e.length;++r<i&&Bt(t,e[r],0)>-1;);return r}function Gt(e,t){for(var r=e.length;r--&&Bt(t,e[r],0)>-1;);return r}function Yt(e,t){for(var r=e.length,i=0;r--;)e[r]===t&&++i;return i}var Xt=jt({À:"A",Á:"A",Â:"A",Ã:"A",Ä:"A",Å:"A",à:"a",á:"a",â:"a",ã:"a",ä:"a",å:"a",Ç:"C",ç:"c",Ð:"D",ð:"d",È:"E",É:"E",Ê:"E",Ë:"E",è:"e",é:"e",ê:"e",ë:"e",Ì:"I",Í:"I",Î:"I",Ï:"I",ì:"i",í:"i",î:"i",ï:"i",Ñ:"N",ñ:"n",Ò:"O",Ó:"O",Ô:"O",Õ:"O",Ö:"O",Ø:"O",ò:"o",ó:"o",ô:"o",õ:"o",ö:"o",ø:"o",Ù:"U",Ú:"U",Û:"U",Ü:"U",ù:"u",ú:"u",û:"u",ü:"u",Ý:"Y",ý:"y",ÿ:"y",Æ:"Ae",æ:"ae",Þ:"Th",þ:"th",ß:"ss",Ā:"A",Ă:"A",Ą:"A",ā:"a",ă:"a",ą:"a",Ć:"C",Ĉ:"C",Ċ:"C",Č:"C",ć:"c",ĉ:"c",ċ:"c",č:"c",Ď:"D",Đ:"D",ď:"d",đ:"d",Ē:"E",Ĕ:"E",Ė:"E",Ę:"E",Ě:"E",ē:"e",ĕ:"e",ė:"e",ę:"e",ě:"e",Ĝ:"G",Ğ:"G",Ġ:"G",Ģ:"G",ĝ:"g",ğ:"g",ġ:"g",ģ:"g",Ĥ:"H",Ħ:"H",ĥ:"h",ħ:"h",Ĩ:"I",Ī:"I",Ĭ:"I",Į:"I",İ:"I",ĩ:"i",ī:"i",ĭ:"i",į:"i",ı:"i",Ĵ:"J",ĵ:"j",Ķ:"K",ķ:"k",ĸ:"k",Ĺ:"L",Ļ:"L",Ľ:"L",Ŀ:"L",Ł:"L",ĺ:"l",ļ:"l",ľ:"l",ŀ:"l",ł:"l",Ń:"N",Ņ:"N",Ň:"N",Ŋ:"N",ń:"n",ņ:"n",ň:"n",ŋ:"n",Ō:"O",Ŏ:"O",Ő:"O",ō:"o",ŏ:"o",ő:"o",Ŕ:"R",Ŗ:"R",Ř:"R",ŕ:"r",ŗ:"r",ř:"r",Ś:"S",Ŝ:"S",Ş:"S",Š:"S",ś:"s",ŝ:"s",ş:"s",š:"s",Ţ:"T",Ť:"T",Ŧ:"T",ţ:"t",ť:"t",ŧ:"t",Ũ:"U",Ū:"U",Ŭ:"U",Ů:"U",Ű:"U",Ų:"U",ũ:"u",ū:"u",ŭ:"u",ů:"u",ű:"u",ų:"u",Ŵ:"W",ŵ:"w",Ŷ:"Y",ŷ:"y",Ÿ:"Y",Ź:"Z",Ż:"Z",Ž:"Z",ź:"z",ż:"z",ž:"z",Ĳ:"IJ",ĳ:"ij",Œ:"Oe",œ:"oe",ŉ:"'n",ſ:"s"}),Zt=jt({"&":"&amp;","<":"&lt;",">":"&gt;",'"':"&quot;","'":"&#39;"});function Jt(e){return"\\"+et[e]}function $t(e){return Ye.test(e)}function Qt(e){var t=-1,r=Array(e.size);return e.forEach((function(e,i){r[++t]=[i,e]})),r}function er(e,t){return function(r){return e(t(r))}}function tr(e,t){for(var r=-1,i=e.length,n=0,o=[];++r<i;){var s=e[r];s!==t&&s!==a||(e[r]=a,o[n++]=r)}return o}function rr(e){var t=-1,r=Array(e.size);return e.forEach((function(e){r[++t]=e})),r}function ir(e){var t=-1,r=Array(e.size);return e.forEach((function(e){r[++t]=[e,e]})),r}function nr(e){return $t(e)?function(e){for(var t=Ve.lastIndex=0;Ve.test(e);)++t;return t}(e):Rt(e)}function or(e){return $t(e)?function(e){return e.match(Ve)||[]}(e):function(e){return e.split("")}(e)}function sr(e){for(var t=e.length;t--&&ne.test(e.charAt(t)););return t}var ar=jt({"&amp;":"&","&lt;":"<","&gt;":">","&quot;":'"',"&#39;":"'"}),cr=function e(t){var r,i=(t=null==t?ot:cr.defaults(ot.Object(),t,cr.pick(ot,Ze))).Array,ne=t.Date,Se=t.Error,Ce=t.Function,we=t.Math,Le=t.Object,Ee=t.RegExp,xe=t.String,Ae=t.TypeError,ke=i.prototype,Me=Ce.prototype,Re=Le.prototype,Te=t["__core-js_shared__"],Oe=Me.toString,Be=Re.hasOwnProperty,De=0,Pe=(r=/[^.]+$/.exec(Te&&Te.keys&&Te.keys.IE_PROTO||""))?"Symbol(src)_1."+r:"",Ie=Re.toString,He=Oe.call(Le),je=ot._,Fe=Ee("^"+Oe.call(Be).replace(te,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$"),We=ct?t.Buffer:n,Ue=t.Symbol,qe=t.Uint8Array,Ne=We?We.allocUnsafe:n,Ve=er(Le.getPrototypeOf,Le),Ye=Le.create,et=Re.propertyIsEnumerable,it=ke.splice,nt=Ue?Ue.isConcatSpreadable:n,st=Ue?Ue.iterator:n,at=Ue?Ue.toStringTag:n,lt=function(){try{var e=lo(Le,"defineProperty");return e({},"",{}),e}catch(e){}}(),ut=t.clearTimeout!==ot.clearTimeout&&t.clearTimeout,Rt=ne&&ne.now!==ot.Date.now&&ne.now,jt=t.setTimeout!==ot.setTimeout&&t.setTimeout,lr=we.ceil,ur=we.floor,hr=Le.getOwnPropertySymbols,fr=We?We.isBuffer:n,_r=t.isFinite,dr=ke.join,pr=er(Le.keys,Le),vr=we.max,gr=we.min,yr=ne.now,mr=t.parseInt,br=we.random,Sr=ke.reverse,Cr=lo(t,"DataView"),wr=lo(t,"Map"),Lr=lo(t,"Promise"),Er=lo(t,"Set"),xr=lo(t,"WeakMap"),Ar=lo(Le,"create"),kr=xr&&new xr,Mr={},Rr=Fo(Cr),Tr=Fo(wr),Or=Fo(Lr),Br=Fo(Er),Dr=Fo(xr),Pr=Ue?Ue.prototype:n,Ir=Pr?Pr.valueOf:n,Hr=Pr?Pr.toString:n;function jr(e){if(ra(e)&&!Ks(e)&&!(e instanceof qr)){if(e instanceof Ur)return e;if(Be.call(e,"__wrapped__"))return Wo(e)}return new Ur(e)}var Fr=function(){function e(){}return function(t){if(!ta(t))return{};if(Ye)return Ye(t);e.prototype=t;var r=new e;return e.prototype=n,r}}();function Wr(){}function Ur(e,t){this.__wrapped__=e,this.__actions__=[],this.__chain__=!!t,this.__index__=0,this.__values__=n}function qr(e){this.__wrapped__=e,this.__actions__=[],this.__dir__=1,this.__filtered__=!1,this.__iteratees__=[],this.__takeCount__=_,this.__views__=[]}function Nr(e){var t=-1,r=null==e?0:e.length;for(this.clear();++t<r;){var i=e[t];this.set(i[0],i[1])}}function zr(e){var t=-1,r=null==e?0:e.length;for(this.clear();++t<r;){var i=e[t];this.set(i[0],i[1])}}function Kr(e){var t=-1,r=null==e?0:e.length;for(this.clear();++t<r;){var i=e[t];this.set(i[0],i[1])}}function Vr(e){var t=-1,r=null==e?0:e.length;for(this.__data__=new Kr;++t<r;)this.add(e[t])}function Gr(e){var t=this.__data__=new zr(e);this.size=t.size}function Yr(e,t){var r=Ks(e),i=!r&&zs(e),n=!r&&!i&&Xs(e),o=!r&&!i&&!n&&ua(e),s=r||i||n||o,a=s?Ut(e.length,xe):[],c=a.length;for(var l in e)!t&&!Be.call(e,l)||s&&("length"==l||n&&("offset"==l||"parent"==l)||o&&("buffer"==l||"byteLength"==l||"byteOffset"==l)||go(l,c))||a.push(l);return a}function Xr(e){var t=e.length;return t?e[Ki(0,t-1)]:n}function Zr(e,t){return Do(An(e),oi(t,0,e.length))}function Jr(e){return Do(An(e))}function $r(e,t,r){(r!==n&&!Us(e[t],r)||r===n&&!(t in e))&&ii(e,t,r)}function Qr(e,t,r){var i=e[t];Be.call(e,t)&&Us(i,r)&&(r!==n||t in e)||ii(e,t,r)}function ei(e,t){for(var r=e.length;r--;)if(Us(e[r][0],t))return r;return-1}function ti(e,t,r,i){return ui(e,(function(e,n,o){t(i,e,r(e),o)})),i}function ri(e,t){return e&&kn(t,Oa(t),e)}function ii(e,t,r){"__proto__"==t&&lt?lt(e,t,{configurable:!0,enumerable:!0,value:r,writable:!0}):e[t]=r}function ni(e,t){for(var r=-1,o=t.length,s=i(o),a=null==e;++r<o;)s[r]=a?n:Aa(e,t[r]);return s}function oi(e,t,r){return e==e&&(r!==n&&(e=e<=r?e:r),t!==n&&(e=e>=t?e:t)),e}function si(e,t,r,i,o,s){var a,c=1&t,l=2&t,u=4&t;if(r&&(a=o?r(e,i,o,s):r(e)),a!==n)return a;if(!ta(e))return e;var h=Ks(e);if(h){if(a=function(e){var t=e.length,r=new e.constructor(t);return t&&"string"==typeof e[0]&&Be.call(e,"index")&&(r.index=e.index,r.input=e.input),r}(e),!c)return An(e,a)}else{var f=fo(e),_=f==b||f==S;if(Xs(e))return Sn(e,c);if(f==L||f==p||_&&!o){if(a=l||_?{}:po(e),!c)return l?function(e,t){return kn(e,ho(e),t)}(e,function(e,t){return e&&kn(t,Ba(t),e)}(a,e)):function(e,t){return kn(e,uo(e),t)}(e,ri(a,e))}else{if(!Qe[f])return o?e:{};a=function(e,t,r){var i,n=e.constructor;switch(t){case T:return Cn(e);case g:case y:return new n(+e);case O:return function(e,t){var r=t?Cn(e.buffer):e.buffer;return new e.constructor(r,e.byteOffset,e.byteLength)}(e,r);case B:case D:case P:case I:case H:case j:case F:case W:case U:return wn(e,r);case C:return new n;case w:case k:return new n(e);case x:return function(e){var t=new e.constructor(e.source,fe.exec(e));return t.lastIndex=e.lastIndex,t}(e);case A:return new n;case M:return i=e,Ir?Le(Ir.call(i)):{}}}(e,f,c)}}s||(s=new Gr);var d=s.get(e);if(d)return d;s.set(e,a),aa(e)?e.forEach((function(i){a.add(si(i,t,r,i,e,s))})):ia(e)&&e.forEach((function(i,n){a.set(n,si(i,t,r,n,e,s))}));var v=h?n:(u?l?ro:to:l?Ba:Oa)(e);return mt(v||e,(function(i,n){v&&(i=e[n=i]),Qr(a,n,si(i,t,r,n,e,s))})),a}function ai(e,t,r){var i=r.length;if(null==e)return!i;for(e=Le(e);i--;){var o=r[i],s=t[o],a=e[o];if(a===n&&!(o in e)||!s(a))return!1}return!0}function ci(e,t,r){if("function"!=typeof e)throw new Ae(o);return Ro((function(){e.apply(n,r)}),t)}function li(e,t,r,i){var n=-1,o=wt,s=!0,a=e.length,c=[],l=t.length;if(!a)return c;r&&(t=Et(t,Nt(r))),i?(o=Lt,s=!1):t.length>=200&&(o=Kt,s=!1,t=new Vr(t));e:for(;++n<a;){var u=e[n],h=null==r?u:r(u);if(u=i||0!==u?u:0,s&&h==h){for(var f=l;f--;)if(t[f]===h)continue e;c.push(u)}else o(t,h,i)||c.push(u)}return c}jr.templateSettings={escape:X,evaluate:Z,interpolate:J,variable:"",imports:{_:jr}},jr.prototype=Wr.prototype,jr.prototype.constructor=jr,Ur.prototype=Fr(Wr.prototype),Ur.prototype.constructor=Ur,qr.prototype=Fr(Wr.prototype),qr.prototype.constructor=qr,Nr.prototype.clear=function(){this.__data__=Ar?Ar(null):{},this.size=0},Nr.prototype.delete=function(e){var t=this.has(e)&&delete this.__data__[e];return this.size-=t?1:0,t},Nr.prototype.get=function(e){var t=this.__data__;if(Ar){var r=t[e];return r===s?n:r}return Be.call(t,e)?t[e]:n},Nr.prototype.has=function(e){var t=this.__data__;return Ar?t[e]!==n:Be.call(t,e)},Nr.prototype.set=function(e,t){var r=this.__data__;return this.size+=this.has(e)?0:1,r[e]=Ar&&t===n?s:t,this},zr.prototype.clear=function(){this.__data__=[],this.size=0},zr.prototype.delete=function(e){var t=this.__data__,r=ei(t,e);return!(r<0||(r==t.length-1?t.pop():it.call(t,r,1),--this.size,0))},zr.prototype.get=function(e){var t=this.__data__,r=ei(t,e);return r<0?n:t[r][1]},zr.prototype.has=function(e){return ei(this.__data__,e)>-1},zr.prototype.set=function(e,t){var r=this.__data__,i=ei(r,e);return i<0?(++this.size,r.push([e,t])):r[i][1]=t,this},Kr.prototype.clear=function(){this.size=0,this.__data__={hash:new Nr,map:new(wr||zr),string:new Nr}},Kr.prototype.delete=function(e){var t=ao(this,e).delete(e);return this.size-=t?1:0,t},Kr.prototype.get=function(e){return ao(this,e).get(e)},Kr.prototype.has=function(e){return ao(this,e).has(e)},Kr.prototype.set=function(e,t){var r=ao(this,e),i=r.size;return r.set(e,t),this.size+=r.size==i?0:1,this},Vr.prototype.add=Vr.prototype.push=function(e){return this.__data__.set(e,s),this},Vr.prototype.has=function(e){return this.__data__.has(e)},Gr.prototype.clear=function(){this.__data__=new zr,this.size=0},Gr.prototype.delete=function(e){var t=this.__data__,r=t.delete(e);return this.size=t.size,r},Gr.prototype.get=function(e){return this.__data__.get(e)},Gr.prototype.has=function(e){return this.__data__.has(e)},Gr.prototype.set=function(e,t){var r=this.__data__;if(r instanceof zr){var i=r.__data__;if(!wr||i.length<199)return i.push([e,t]),this.size=++r.size,this;r=this.__data__=new Kr(i)}return r.set(e,t),this.size=r.size,this};var ui=Tn(yi),hi=Tn(mi,!0);function fi(e,t){var r=!0;return ui(e,(function(e,i,n){return r=!!t(e,i,n)})),r}function _i(e,t,r){for(var i=-1,o=e.length;++i<o;){var s=e[i],a=t(s);if(null!=a&&(c===n?a==a&&!la(a):r(a,c)))var c=a,l=s}return l}function di(e,t){var r=[];return ui(e,(function(e,i,n){t(e,i,n)&&r.push(e)})),r}function pi(e,t,r,i,n){var o=-1,s=e.length;for(r||(r=vo),n||(n=[]);++o<s;){var a=e[o];t>0&&r(a)?t>1?pi(a,t-1,r,i,n):xt(n,a):i||(n[n.length]=a)}return n}var vi=On(),gi=On(!0);function yi(e,t){return e&&vi(e,t,Oa)}function mi(e,t){return e&&gi(e,t,Oa)}function bi(e,t){return Ct(t,(function(t){return $s(e[t])}))}function Si(e,t){for(var r=0,i=(t=gn(t,e)).length;null!=e&&r<i;)e=e[jo(t[r++])];return r&&r==i?e:n}function Ci(e,t,r){var i=t(e);return Ks(e)?i:xt(i,r(e))}function wi(e){return null==e?e===n?"[object Undefined]":"[object Null]":at&&at in Le(e)?function(e){var t=Be.call(e,at),r=e[at];try{e[at]=n;var i=!0}catch(e){}var o=Ie.call(e);return i&&(t?e[at]=r:delete e[at]),o}(e):function(e){return Ie.call(e)}(e)}function Li(e,t){return e>t}function Ei(e,t){return null!=e&&Be.call(e,t)}function xi(e,t){return null!=e&&t in Le(e)}function Ai(e,t,r){for(var o=r?Lt:wt,s=e[0].length,a=e.length,c=a,l=i(a),u=1/0,h=[];c--;){var f=e[c];c&&t&&(f=Et(f,Nt(t))),u=gr(f.length,u),l[c]=!r&&(t||s>=120&&f.length>=120)?new Vr(c&&f):n}f=e[0];var _=-1,d=l[0];e:for(;++_<s&&h.length<u;){var p=f[_],v=t?t(p):p;if(p=r||0!==p?p:0,!(d?Kt(d,v):o(h,v,r))){for(c=a;--c;){var g=l[c];if(!(g?Kt(g,v):o(e[c],v,r)))continue e}d&&d.push(v),h.push(p)}}return h}function ki(e,t,r){var i=null==(e=xo(e,t=gn(t,e)))?e:e[jo(Jo(t))];return null==i?n:gt(i,e,r)}function Mi(e){return ra(e)&&wi(e)==p}function Ri(e,t,r,i,o){return e===t||(null==e||null==t||!ra(e)&&!ra(t)?e!=e&&t!=t:function(e,t,r,i,o,s){var a=Ks(e),c=Ks(t),l=a?v:fo(e),u=c?v:fo(t),h=(l=l==p?L:l)==L,f=(u=u==p?L:u)==L,_=l==u;if(_&&Xs(e)){if(!Xs(t))return!1;a=!0,h=!1}if(_&&!h)return s||(s=new Gr),a||ua(e)?Qn(e,t,r,i,o,s):function(e,t,r,i,n,o,s){switch(r){case O:if(e.byteLength!=t.byteLength||e.byteOffset!=t.byteOffset)return!1;e=e.buffer,t=t.buffer;case T:return!(e.byteLength!=t.byteLength||!o(new qe(e),new qe(t)));case g:case y:case w:return Us(+e,+t);case m:return e.name==t.name&&e.message==t.message;case x:case k:return e==t+"";case C:var a=Qt;case A:var c=1&i;if(a||(a=rr),e.size!=t.size&&!c)return!1;var l=s.get(e);if(l)return l==t;i|=2,s.set(e,t);var u=Qn(a(e),a(t),i,n,o,s);return s.delete(e),u;case M:if(Ir)return Ir.call(e)==Ir.call(t)}return!1}(e,t,l,r,i,o,s);if(!(1&r)){var d=h&&Be.call(e,"__wrapped__"),b=f&&Be.call(t,"__wrapped__");if(d||b){var S=d?e.value():e,E=b?t.value():t;return s||(s=new Gr),o(S,E,r,i,s)}}return!!_&&(s||(s=new Gr),function(e,t,r,i,o,s){var a=1&r,c=to(e),l=c.length;if(l!=to(t).length&&!a)return!1;for(var u=l;u--;){var h=c[u];if(!(a?h in t:Be.call(t,h)))return!1}var f=s.get(e),_=s.get(t);if(f&&_)return f==t&&_==e;var d=!0;s.set(e,t),s.set(t,e);for(var p=a;++u<l;){var v=e[h=c[u]],g=t[h];if(i)var y=a?i(g,v,h,t,e,s):i(v,g,h,e,t,s);if(!(y===n?v===g||o(v,g,r,i,s):y)){d=!1;break}p||(p="constructor"==h)}if(d&&!p){var m=e.constructor,b=t.constructor;m==b||!("constructor"in e)||!("constructor"in t)||"function"==typeof m&&m instanceof m&&"function"==typeof b&&b instanceof b||(d=!1)}return s.delete(e),s.delete(t),d}(e,t,r,i,o,s))}(e,t,r,i,Ri,o))}function Ti(e,t,r,i){var o=r.length,s=o,a=!i;if(null==e)return!s;for(e=Le(e);o--;){var c=r[o];if(a&&c[2]?c[1]!==e[c[0]]:!(c[0]in e))return!1}for(;++o<s;){var l=(c=r[o])[0],u=e[l],h=c[1];if(a&&c[2]){if(u===n&&!(l in e))return!1}else{var f=new Gr;if(i)var _=i(u,h,l,e,t,f);if(!(_===n?Ri(h,u,3,i,f):_))return!1}}return!0}function Oi(e){return!(!ta(e)||(t=e,Pe&&Pe in t))&&($s(e)?Fe:pe).test(Fo(e));var t}function Bi(e){return"function"==typeof e?e:null==e?nc:"object"==typeof e?Ks(e)?ji(e[0],e[1]):Hi(e):_c(e)}function Di(e){if(!Co(e))return pr(e);var t=[];for(var r in Le(e))Be.call(e,r)&&"constructor"!=r&&t.push(r);return t}function Pi(e,t){return e<t}function Ii(e,t){var r=-1,n=Gs(e)?i(e.length):[];return ui(e,(function(e,i,o){n[++r]=t(e,i,o)})),n}function Hi(e){var t=co(e);return 1==t.length&&t[0][2]?Lo(t[0][0],t[0][1]):function(r){return r===e||Ti(r,e,t)}}function ji(e,t){return mo(e)&&wo(t)?Lo(jo(e),t):function(r){var i=Aa(r,e);return i===n&&i===t?ka(r,e):Ri(t,i,3)}}function Fi(e,t,r,i,o){e!==t&&vi(t,(function(s,a){if(o||(o=new Gr),ta(s))!function(e,t,r,i,o,s,a){var c=ko(e,r),l=ko(t,r),u=a.get(l);if(u)$r(e,r,u);else{var h=s?s(c,l,r+"",e,t,a):n,f=h===n;if(f){var _=Ks(l),d=!_&&Xs(l),p=!_&&!d&&ua(l);h=l,_||d||p?Ks(c)?h=c:Ys(c)?h=An(c):d?(f=!1,h=Sn(l,!0)):p?(f=!1,h=wn(l,!0)):h=[]:oa(l)||zs(l)?(h=c,zs(c)?h=ya(c):ta(c)&&!$s(c)||(h=po(l))):f=!1}f&&(a.set(l,h),o(h,l,i,s,a),a.delete(l)),$r(e,r,h)}}(e,t,a,r,Fi,i,o);else{var c=i?i(ko(e,a),s,a+"",e,t,o):n;c===n&&(c=s),$r(e,a,c)}}),Ba)}function Wi(e,t){var r=e.length;if(r)return go(t+=t<0?r:0,r)?e[t]:n}function Ui(e,t,r){t=t.length?Et(t,(function(e){return Ks(e)?function(t){return Si(t,1===e.length?e[0]:e)}:e})):[nc];var i=-1;t=Et(t,Nt(so()));var n=Ii(e,(function(e,r,n){var o=Et(t,(function(t){return t(e)}));return{criteria:o,index:++i,value:e}}));return function(e,t){var i=e.length;for(e.sort((function(e,t){return function(e,t,r){for(var i=-1,n=e.criteria,o=t.criteria,s=n.length,a=r.length;++i<s;){var c=Ln(n[i],o[i]);if(c)return i>=a?c:c*("desc"==r[i]?-1:1)}return e.index-t.index}(e,t,r)}));i--;)e[i]=e[i].value;return e}(n)}function qi(e,t,r){for(var i=-1,n=t.length,o={};++i<n;){var s=t[i],a=Si(e,s);r(a,s)&&Zi(o,gn(s,e),a)}return o}function Ni(e,t,r,i){var n=i?Dt:Bt,o=-1,s=t.length,a=e;for(e===t&&(t=An(t)),r&&(a=Et(e,Nt(r)));++o<s;)for(var c=0,l=t[o],u=r?r(l):l;(c=n(a,u,c,i))>-1;)a!==e&&it.call(a,c,1),it.call(e,c,1);return e}function zi(e,t){for(var r=e?t.length:0,i=r-1;r--;){var n=t[r];if(r==i||n!==o){var o=n;go(n)?it.call(e,n,1):ln(e,n)}}return e}function Ki(e,t){return e+ur(br()*(t-e+1))}function Vi(e,t){var r="";if(!e||t<1||t>h)return r;do{t%2&&(r+=e),(t=ur(t/2))&&(e+=e)}while(t);return r}function Gi(e,t){return To(Eo(e,t,nc),e+"")}function Yi(e){return Xr(Ua(e))}function Xi(e,t){var r=Ua(e);return Do(r,oi(t,0,r.length))}function Zi(e,t,r,i){if(!ta(e))return e;for(var o=-1,s=(t=gn(t,e)).length,a=s-1,c=e;null!=c&&++o<s;){var l=jo(t[o]),u=r;if("__proto__"===l||"constructor"===l||"prototype"===l)return e;if(o!=a){var h=c[l];(u=i?i(h,l,c):n)===n&&(u=ta(h)?h:go(t[o+1])?[]:{})}Qr(c,l,u),c=c[l]}return e}var Ji=kr?function(e,t){return kr.set(e,t),e}:nc,$i=lt?function(e,t){return lt(e,"toString",{configurable:!0,enumerable:!1,value:tc(t),writable:!0})}:nc;function Qi(e){return Do(Ua(e))}function en(e,t,r){var n=-1,o=e.length;t<0&&(t=-t>o?0:o+t),(r=r>o?o:r)<0&&(r+=o),o=t>r?0:r-t>>>0,t>>>=0;for(var s=i(o);++n<o;)s[n]=e[n+t];return s}function tn(e,t){var r;return ui(e,(function(e,i,n){return!(r=t(e,i,n))})),!!r}function rn(e,t,r){var i=0,n=null==e?i:e.length;if("number"==typeof t&&t==t&&n<=2147483647){for(;i<n;){var o=i+n>>>1,s=e[o];null!==s&&!la(s)&&(r?s<=t:s<t)?i=o+1:n=o}return n}return nn(e,t,nc,r)}function nn(e,t,r,i){var o=0,s=null==e?0:e.length;if(0===s)return 0;for(var a=(t=r(t))!=t,c=null===t,l=la(t),u=t===n;o<s;){var h=ur((o+s)/2),f=r(e[h]),_=f!==n,d=null===f,p=f==f,v=la(f);if(a)var g=i||p;else g=u?p&&(i||_):c?p&&_&&(i||!d):l?p&&_&&!d&&(i||!v):!d&&!v&&(i?f<=t:f<t);g?o=h+1:s=h}return gr(s,4294967294)}function on(e,t){for(var r=-1,i=e.length,n=0,o=[];++r<i;){var s=e[r],a=t?t(s):s;if(!r||!Us(a,c)){var c=a;o[n++]=0===s?0:s}}return o}function sn(e){return"number"==typeof e?e:la(e)?f:+e}function an(e){if("string"==typeof e)return e;if(Ks(e))return Et(e,an)+"";if(la(e))return Hr?Hr.call(e):"";var t=e+"";return"0"==t&&1/e==-1/0?"-0":t}function cn(e,t,r){var i=-1,n=wt,o=e.length,s=!0,a=[],c=a;if(r)s=!1,n=Lt;else if(o>=200){var l=t?null:Gn(e);if(l)return rr(l);s=!1,n=Kt,c=new Vr}else c=t?[]:a;e:for(;++i<o;){var u=e[i],h=t?t(u):u;if(u=r||0!==u?u:0,s&&h==h){for(var f=c.length;f--;)if(c[f]===h)continue e;t&&c.push(h),a.push(u)}else n(c,h,r)||(c!==a&&c.push(h),a.push(u))}return a}function ln(e,t){return null==(e=xo(e,t=gn(t,e)))||delete e[jo(Jo(t))]}function un(e,t,r,i){return Zi(e,t,r(Si(e,t)),i)}function hn(e,t,r,i){for(var n=e.length,o=i?n:-1;(i?o--:++o<n)&&t(e[o],o,e););return r?en(e,i?0:o,i?o+1:n):en(e,i?o+1:0,i?n:o)}function fn(e,t){var r=e;return r instanceof qr&&(r=r.value()),At(t,(function(e,t){return t.func.apply(t.thisArg,xt([e],t.args))}),r)}function _n(e,t,r){var n=e.length;if(n<2)return n?cn(e[0]):[];for(var o=-1,s=i(n);++o<n;)for(var a=e[o],c=-1;++c<n;)c!=o&&(s[o]=li(s[o]||a,e[c],t,r));return cn(pi(s,1),t,r)}function dn(e,t,r){for(var i=-1,o=e.length,s=t.length,a={};++i<o;){var c=i<s?t[i]:n;r(a,e[i],c)}return a}function pn(e){return Ys(e)?e:[]}function vn(e){return"function"==typeof e?e:nc}function gn(e,t){return Ks(e)?e:mo(e,t)?[e]:Ho(ma(e))}var yn=Gi;function mn(e,t,r){var i=e.length;return r=r===n?i:r,!t&&r>=i?e:en(e,t,r)}var bn=ut||function(e){return ot.clearTimeout(e)};function Sn(e,t){if(t)return e.slice();var r=e.length,i=Ne?Ne(r):new e.constructor(r);return e.copy(i),i}function Cn(e){var t=new e.constructor(e.byteLength);return new qe(t).set(new qe(e)),t}function wn(e,t){var r=t?Cn(e.buffer):e.buffer;return new e.constructor(r,e.byteOffset,e.length)}function Ln(e,t){if(e!==t){var r=e!==n,i=null===e,o=e==e,s=la(e),a=t!==n,c=null===t,l=t==t,u=la(t);if(!c&&!u&&!s&&e>t||s&&a&&l&&!c&&!u||i&&a&&l||!r&&l||!o)return 1;if(!i&&!s&&!u&&e<t||u&&r&&o&&!i&&!s||c&&r&&o||!a&&o||!l)return-1}return 0}function En(e,t,r,n){for(var o=-1,s=e.length,a=r.length,c=-1,l=t.length,u=vr(s-a,0),h=i(l+u),f=!n;++c<l;)h[c]=t[c];for(;++o<a;)(f||o<s)&&(h[r[o]]=e[o]);for(;u--;)h[c++]=e[o++];return h}function xn(e,t,r,n){for(var o=-1,s=e.length,a=-1,c=r.length,l=-1,u=t.length,h=vr(s-c,0),f=i(h+u),_=!n;++o<h;)f[o]=e[o];for(var d=o;++l<u;)f[d+l]=t[l];for(;++a<c;)(_||o<s)&&(f[d+r[a]]=e[o++]);return f}function An(e,t){var r=-1,n=e.length;for(t||(t=i(n));++r<n;)t[r]=e[r];return t}function kn(e,t,r,i){var o=!r;r||(r={});for(var s=-1,a=t.length;++s<a;){var c=t[s],l=i?i(r[c],e[c],c,r,e):n;l===n&&(l=e[c]),o?ii(r,c,l):Qr(r,c,l)}return r}function Mn(e,t){return function(r,i){var n=Ks(r)?yt:ti,o=t?t():{};return n(r,e,so(i,2),o)}}function Rn(e){return Gi((function(t,r){var i=-1,o=r.length,s=o>1?r[o-1]:n,a=o>2?r[2]:n;for(s=e.length>3&&"function"==typeof s?(o--,s):n,a&&yo(r[0],r[1],a)&&(s=o<3?n:s,o=1),t=Le(t);++i<o;){var c=r[i];c&&e(t,c,i,s)}return t}))}function Tn(e,t){return function(r,i){if(null==r)return r;if(!Gs(r))return e(r,i);for(var n=r.length,o=t?n:-1,s=Le(r);(t?o--:++o<n)&&!1!==i(s[o],o,s););return r}}function On(e){return function(t,r,i){for(var n=-1,o=Le(t),s=i(t),a=s.length;a--;){var c=s[e?a:++n];if(!1===r(o[c],c,o))break}return t}}function Bn(e){return function(t){var r=$t(t=ma(t))?or(t):n,i=r?r[0]:t.charAt(0),o=r?mn(r,1).join(""):t.slice(1);return i[e]()+o}}function Dn(e){return function(t){return At($a(za(t).replace(ze,"")),e,"")}}function Pn(e){return function(){var t=arguments;switch(t.length){case 0:return new e;case 1:return new e(t[0]);case 2:return new e(t[0],t[1]);case 3:return new e(t[0],t[1],t[2]);case 4:return new e(t[0],t[1],t[2],t[3]);case 5:return new e(t[0],t[1],t[2],t[3],t[4]);case 6:return new e(t[0],t[1],t[2],t[3],t[4],t[5]);case 7:return new e(t[0],t[1],t[2],t[3],t[4],t[5],t[6])}var r=Fr(e.prototype),i=e.apply(r,t);return ta(i)?i:r}}function In(e){return function(t,r,i){var o=Le(t);if(!Gs(t)){var s=so(r,3);t=Oa(t),r=function(e){return s(o[e],e,o)}}var a=e(t,r,i);return a>-1?o[s?t[a]:a]:n}}function Hn(e){return eo((function(t){var r=t.length,i=r,s=Ur.prototype.thru;for(e&&t.reverse();i--;){var a=t[i];if("function"!=typeof a)throw new Ae(o);if(s&&!c&&"wrapper"==no(a))var c=new Ur([],!0)}for(i=c?i:r;++i<r;){var l=no(a=t[i]),u="wrapper"==l?io(a):n;c=u&&bo(u[0])&&424==u[1]&&!u[4].length&&1==u[9]?c[no(u[0])].apply(c,u[3]):1==a.length&&bo(a)?c[l]():c.thru(a)}return function(){var e=arguments,i=e[0];if(c&&1==e.length&&Ks(i))return c.plant(i).value();for(var n=0,o=r?t[n].apply(this,e):i;++n<r;)o=t[n].call(this,o);return o}}))}function jn(e,t,r,o,s,a,c,u,h,f){var _=t&l,d=1&t,p=2&t,v=24&t,g=512&t,y=p?n:Pn(e);return function n(){for(var l=arguments.length,m=i(l),b=l;b--;)m[b]=arguments[b];if(v)var S=oo(n),C=Yt(m,S);if(o&&(m=En(m,o,s,v)),a&&(m=xn(m,a,c,v)),l-=C,v&&l<f){var w=tr(m,S);return Kn(e,t,jn,n.placeholder,r,m,w,u,h,f-l)}var L=d?r:this,E=p?L[e]:e;return l=m.length,u?m=Ao(m,u):g&&l>1&&m.reverse(),_&&h<l&&(m.length=h),this&&this!==ot&&this instanceof n&&(E=y||Pn(E)),E.apply(L,m)}}function Fn(e,t){return function(r,i){return function(e,t,r,i){return yi(e,(function(e,n,o){t(i,r(e),n,o)})),i}(r,e,t(i),{})}}function Wn(e,t){return function(r,i){var o;if(r===n&&i===n)return t;if(r!==n&&(o=r),i!==n){if(o===n)return i;"string"==typeof r||"string"==typeof i?(r=an(r),i=an(i)):(r=sn(r),i=sn(i)),o=e(r,i)}return o}}function Un(e){return eo((function(t){return t=Et(t,Nt(so())),Gi((function(r){var i=this;return e(t,(function(e){return gt(e,i,r)}))}))}))}function qn(e,t){var r=(t=t===n?" ":an(t)).length;if(r<2)return r?Vi(t,e):t;var i=Vi(t,lr(e/nr(t)));return $t(t)?mn(or(i),0,e).join(""):i.slice(0,e)}function Nn(e){return function(t,r,o){return o&&"number"!=typeof o&&yo(t,r,o)&&(r=o=n),t=da(t),r===n?(r=t,t=0):r=da(r),function(e,t,r,n){for(var o=-1,s=vr(lr((t-e)/(r||1)),0),a=i(s);s--;)a[n?s:++o]=e,e+=r;return a}(t,r,o=o===n?t<r?1:-1:da(o),e)}}function zn(e){return function(t,r){return"string"==typeof t&&"string"==typeof r||(t=ga(t),r=ga(r)),e(t,r)}}function Kn(e,t,r,i,o,s,a,l,u,h){var f=8&t;t|=f?c:64,4&(t&=~(f?64:c))||(t&=-4);var _=[e,t,o,f?s:n,f?a:n,f?n:s,f?n:a,l,u,h],d=r.apply(n,_);return bo(e)&&Mo(d,_),d.placeholder=i,Oo(d,e,t)}function Vn(e){var t=we[e];return function(e,r){if(e=ga(e),(r=null==r?0:gr(pa(r),292))&&_r(e)){var i=(ma(e)+"e").split("e");return+((i=(ma(t(i[0]+"e"+(+i[1]+r)))+"e").split("e"))[0]+"e"+(+i[1]-r))}return t(e)}}var Gn=Er&&1/rr(new Er([,-0]))[1]==u?function(e){return new Er(e)}:lc;function Yn(e){return function(t){var r=fo(t);return r==C?Qt(t):r==A?ir(t):function(e,t){return Et(t,(function(t){return[t,e[t]]}))}(t,e(t))}}function Xn(e,t,r,s,u,h,f,_){var d=2&t;if(!d&&"function"!=typeof e)throw new Ae(o);var p=s?s.length:0;if(p||(t&=-97,s=u=n),f=f===n?f:vr(pa(f),0),_=_===n?_:pa(_),p-=u?u.length:0,64&t){var v=s,g=u;s=u=n}var y=d?n:io(e),m=[e,t,r,s,u,v,g,h,f,_];if(y&&function(e,t){var r=e[1],i=t[1],n=r|i,o=n<131,s=i==l&&8==r||i==l&&256==r&&e[7].length<=t[8]||384==i&&t[7].length<=t[8]&&8==r;if(!o&&!s)return e;1&i&&(e[2]=t[2],n|=1&r?0:4);var c=t[3];if(c){var u=e[3];e[3]=u?En(u,c,t[4]):c,e[4]=u?tr(e[3],a):t[4]}(c=t[5])&&(u=e[5],e[5]=u?xn(u,c,t[6]):c,e[6]=u?tr(e[5],a):t[6]),(c=t[7])&&(e[7]=c),i&l&&(e[8]=null==e[8]?t[8]:gr(e[8],t[8])),null==e[9]&&(e[9]=t[9]),e[0]=t[0],e[1]=n}(m,y),e=m[0],t=m[1],r=m[2],s=m[3],u=m[4],!(_=m[9]=m[9]===n?d?0:e.length:vr(m[9]-p,0))&&24&t&&(t&=-25),t&&1!=t)b=8==t||16==t?function(e,t,r){var o=Pn(e);return function s(){for(var a=arguments.length,c=i(a),l=a,u=oo(s);l--;)c[l]=arguments[l];var h=a<3&&c[0]!==u&&c[a-1]!==u?[]:tr(c,u);return(a-=h.length)<r?Kn(e,t,jn,s.placeholder,n,c,h,n,n,r-a):gt(this&&this!==ot&&this instanceof s?o:e,this,c)}}(e,t,_):t!=c&&33!=t||u.length?jn.apply(n,m):function(e,t,r,n){var o=1&t,s=Pn(e);return function t(){for(var a=-1,c=arguments.length,l=-1,u=n.length,h=i(u+c),f=this&&this!==ot&&this instanceof t?s:e;++l<u;)h[l]=n[l];for(;c--;)h[l++]=arguments[++a];return gt(f,o?r:this,h)}}(e,t,r,s);else var b=function(e,t,r){var i=1&t,n=Pn(e);return function t(){return(this&&this!==ot&&this instanceof t?n:e).apply(i?r:this,arguments)}}(e,t,r);return Oo((y?Ji:Mo)(b,m),e,t)}function Zn(e,t,r,i){return e===n||Us(e,Re[r])&&!Be.call(i,r)?t:e}function Jn(e,t,r,i,o,s){return ta(e)&&ta(t)&&(s.set(t,e),Fi(e,t,n,Jn,s),s.delete(t)),e}function $n(e){return oa(e)?n:e}function Qn(e,t,r,i,o,s){var a=1&r,c=e.length,l=t.length;if(c!=l&&!(a&&l>c))return!1;var u=s.get(e),h=s.get(t);if(u&&h)return u==t&&h==e;var f=-1,_=!0,d=2&r?new Vr:n;for(s.set(e,t),s.set(t,e);++f<c;){var p=e[f],v=t[f];if(i)var g=a?i(v,p,f,t,e,s):i(p,v,f,e,t,s);if(g!==n){if(g)continue;_=!1;break}if(d){if(!Mt(t,(function(e,t){if(!Kt(d,t)&&(p===e||o(p,e,r,i,s)))return d.push(t)}))){_=!1;break}}else if(p!==v&&!o(p,v,r,i,s)){_=!1;break}}return s.delete(e),s.delete(t),_}function eo(e){return To(Eo(e,n,Vo),e+"")}function to(e){return Ci(e,Oa,uo)}function ro(e){return Ci(e,Ba,ho)}var io=kr?function(e){return kr.get(e)}:lc;function no(e){for(var t=e.name+"",r=Mr[t],i=Be.call(Mr,t)?r.length:0;i--;){var n=r[i],o=n.func;if(null==o||o==e)return n.name}return t}function oo(e){return(Be.call(jr,"placeholder")?jr:e).placeholder}function so(){var e=jr.iteratee||oc;return e=e===oc?Bi:e,arguments.length?e(arguments[0],arguments[1]):e}function ao(e,t){var r,i,n=e.__data__;return("string"==(i=typeof(r=t))||"number"==i||"symbol"==i||"boolean"==i?"__proto__"!==r:null===r)?n["string"==typeof t?"string":"hash"]:n.map}function co(e){for(var t=Oa(e),r=t.length;r--;){var i=t[r],n=e[i];t[r]=[i,n,wo(n)]}return t}function lo(e,t){var r=function(e,t){return null==e?n:e[t]}(e,t);return Oi(r)?r:n}var uo=hr?function(e){return null==e?[]:(e=Le(e),Ct(hr(e),(function(t){return et.call(e,t)})))}:vc,ho=hr?function(e){for(var t=[];e;)xt(t,uo(e)),e=Ve(e);return t}:vc,fo=wi;function _o(e,t,r){for(var i=-1,n=(t=gn(t,e)).length,o=!1;++i<n;){var s=jo(t[i]);if(!(o=null!=e&&r(e,s)))break;e=e[s]}return o||++i!=n?o:!!(n=null==e?0:e.length)&&ea(n)&&go(s,n)&&(Ks(e)||zs(e))}function po(e){return"function"!=typeof e.constructor||Co(e)?{}:Fr(Ve(e))}function vo(e){return Ks(e)||zs(e)||!!(nt&&e&&e[nt])}function go(e,t){var r=typeof e;return!!(t=null==t?h:t)&&("number"==r||"symbol"!=r&&ge.test(e))&&e>-1&&e%1==0&&e<t}function yo(e,t,r){if(!ta(r))return!1;var i=typeof t;return!!("number"==i?Gs(r)&&go(t,r.length):"string"==i&&t in r)&&Us(r[t],e)}function mo(e,t){if(Ks(e))return!1;var r=typeof e;return!("number"!=r&&"symbol"!=r&&"boolean"!=r&&null!=e&&!la(e))||Q.test(e)||!$.test(e)||null!=t&&e in Le(t)}function bo(e){var t=no(e),r=jr[t];if("function"!=typeof r||!(t in qr.prototype))return!1;if(e===r)return!0;var i=io(r);return!!i&&e===i[0]}(Cr&&fo(new Cr(new ArrayBuffer(1)))!=O||wr&&fo(new wr)!=C||Lr&&fo(Lr.resolve())!=E||Er&&fo(new Er)!=A||xr&&fo(new xr)!=R)&&(fo=function(e){var t=wi(e),r=t==L?e.constructor:n,i=r?Fo(r):"";if(i)switch(i){case Rr:return O;case Tr:return C;case Or:return E;case Br:return A;case Dr:return R}return t});var So=Te?$s:gc;function Co(e){var t=e&&e.constructor;return e===("function"==typeof t&&t.prototype||Re)}function wo(e){return e==e&&!ta(e)}function Lo(e,t){return function(r){return null!=r&&r[e]===t&&(t!==n||e in Le(r))}}function Eo(e,t,r){return t=vr(t===n?e.length-1:t,0),function(){for(var n=arguments,o=-1,s=vr(n.length-t,0),a=i(s);++o<s;)a[o]=n[t+o];o=-1;for(var c=i(t+1);++o<t;)c[o]=n[o];return c[t]=r(a),gt(e,this,c)}}function xo(e,t){return t.length<2?e:Si(e,en(t,0,-1))}function Ao(e,t){for(var r=e.length,i=gr(t.length,r),o=An(e);i--;){var s=t[i];e[i]=go(s,r)?o[s]:n}return e}function ko(e,t){if(("constructor"!==t||"function"!=typeof e[t])&&"__proto__"!=t)return e[t]}var Mo=Bo(Ji),Ro=jt||function(e,t){return ot.setTimeout(e,t)},To=Bo($i);function Oo(e,t,r){var i=t+"";return To(e,function(e,t){var r=t.length;if(!r)return e;var i=r-1;return t[i]=(r>1?"& ":"")+t[i],t=t.join(r>2?", ":" "),e.replace(oe,"{\n/* [wrapped with "+t+"] */\n")}(i,function(e,t){return mt(d,(function(r){var i="_."+r[0];t&r[1]&&!wt(e,i)&&e.push(i)})),e.sort()}(function(e){var t=e.match(se);return t?t[1].split(ae):[]}(i),r)))}function Bo(e){var t=0,r=0;return function(){var i=yr(),o=16-(i-r);if(r=i,o>0){if(++t>=800)return arguments[0]}else t=0;return e.apply(n,arguments)}}function Do(e,t){var r=-1,i=e.length,o=i-1;for(t=t===n?i:t;++r<t;){var s=Ki(r,o),a=e[s];e[s]=e[r],e[r]=a}return e.length=t,e}var Po,Io,Ho=(Po=Ps((function(e){var t=[];return 46===e.charCodeAt(0)&&t.push(""),e.replace(ee,(function(e,r,i,n){t.push(i?n.replace(ue,"$1"):r||e)})),t}),(function(e){return 500===Io.size&&Io.clear(),e})),Io=Po.cache,Po);function jo(e){if("string"==typeof e||la(e))return e;var t=e+"";return"0"==t&&1/e==-1/0?"-0":t}function Fo(e){if(null!=e){try{return Oe.call(e)}catch(e){}try{return e+""}catch(e){}}return""}function Wo(e){if(e instanceof qr)return e.clone();var t=new Ur(e.__wrapped__,e.__chain__);return t.__actions__=An(e.__actions__),t.__index__=e.__index__,t.__values__=e.__values__,t}var Uo=Gi((function(e,t){return Ys(e)?li(e,pi(t,1,Ys,!0)):[]})),qo=Gi((function(e,t){var r=Jo(t);return Ys(r)&&(r=n),Ys(e)?li(e,pi(t,1,Ys,!0),so(r,2)):[]})),No=Gi((function(e,t){var r=Jo(t);return Ys(r)&&(r=n),Ys(e)?li(e,pi(t,1,Ys,!0),n,r):[]}));function zo(e,t,r){var i=null==e?0:e.length;if(!i)return-1;var n=null==r?0:pa(r);return n<0&&(n=vr(i+n,0)),Ot(e,so(t,3),n)}function Ko(e,t,r){var i=null==e?0:e.length;if(!i)return-1;var o=i-1;return r!==n&&(o=pa(r),o=r<0?vr(i+o,0):gr(o,i-1)),Ot(e,so(t,3),o,!0)}function Vo(e){return null!=e&&e.length?pi(e,1):[]}function Go(e){return e&&e.length?e[0]:n}var Yo=Gi((function(e){var t=Et(e,pn);return t.length&&t[0]===e[0]?Ai(t):[]})),Xo=Gi((function(e){var t=Jo(e),r=Et(e,pn);return t===Jo(r)?t=n:r.pop(),r.length&&r[0]===e[0]?Ai(r,so(t,2)):[]})),Zo=Gi((function(e){var t=Jo(e),r=Et(e,pn);return(t="function"==typeof t?t:n)&&r.pop(),r.length&&r[0]===e[0]?Ai(r,n,t):[]}));function Jo(e){var t=null==e?0:e.length;return t?e[t-1]:n}var $o=Gi(Qo);function Qo(e,t){return e&&e.length&&t&&t.length?Ni(e,t):e}var es=eo((function(e,t){var r=null==e?0:e.length,i=ni(e,t);return zi(e,Et(t,(function(e){return go(e,r)?+e:e})).sort(Ln)),i}));function ts(e){return null==e?e:Sr.call(e)}var rs=Gi((function(e){return cn(pi(e,1,Ys,!0))})),is=Gi((function(e){var t=Jo(e);return Ys(t)&&(t=n),cn(pi(e,1,Ys,!0),so(t,2))})),ns=Gi((function(e){var t=Jo(e);return t="function"==typeof t?t:n,cn(pi(e,1,Ys,!0),n,t)}));function os(e){if(!e||!e.length)return[];var t=0;return e=Ct(e,(function(e){if(Ys(e))return t=vr(e.length,t),!0})),Ut(t,(function(t){return Et(e,Ht(t))}))}function ss(e,t){if(!e||!e.length)return[];var r=os(e);return null==t?r:Et(r,(function(e){return gt(t,n,e)}))}var as=Gi((function(e,t){return Ys(e)?li(e,t):[]})),cs=Gi((function(e){return _n(Ct(e,Ys))})),ls=Gi((function(e){var t=Jo(e);return Ys(t)&&(t=n),_n(Ct(e,Ys),so(t,2))})),us=Gi((function(e){var t=Jo(e);return t="function"==typeof t?t:n,_n(Ct(e,Ys),n,t)})),hs=Gi(os),fs=Gi((function(e){var t=e.length,r=t>1?e[t-1]:n;return r="function"==typeof r?(e.pop(),r):n,ss(e,r)}));function _s(e){var t=jr(e);return t.__chain__=!0,t}function ds(e,t){return t(e)}var ps=eo((function(e){var t=e.length,r=t?e[0]:0,i=this.__wrapped__,o=function(t){return ni(t,e)};return!(t>1||this.__actions__.length)&&i instanceof qr&&go(r)?((i=i.slice(r,+r+(t?1:0))).__actions__.push({func:ds,args:[o],thisArg:n}),new Ur(i,this.__chain__).thru((function(e){return t&&!e.length&&e.push(n),e}))):this.thru(o)})),vs=Mn((function(e,t,r){Be.call(e,r)?++e[r]:ii(e,r,1)})),gs=In(zo),ys=In(Ko);function ms(e,t){return(Ks(e)?mt:ui)(e,so(t,3))}function bs(e,t){return(Ks(e)?bt:hi)(e,so(t,3))}var Ss=Mn((function(e,t,r){Be.call(e,r)?e[r].push(t):ii(e,r,[t])})),Cs=Gi((function(e,t,r){var n=-1,o="function"==typeof t,s=Gs(e)?i(e.length):[];return ui(e,(function(e){s[++n]=o?gt(t,e,r):ki(e,t,r)})),s})),ws=Mn((function(e,t,r){ii(e,r,t)}));function Ls(e,t){return(Ks(e)?Et:Ii)(e,so(t,3))}var Es=Mn((function(e,t,r){e[r?0:1].push(t)}),(function(){return[[],[]]})),xs=Gi((function(e,t){if(null==e)return[];var r=t.length;return r>1&&yo(e,t[0],t[1])?t=[]:r>2&&yo(t[0],t[1],t[2])&&(t=[t[0]]),Ui(e,pi(t,1),[])})),As=Rt||function(){return ot.Date.now()};function ks(e,t,r){return t=r?n:t,t=e&&null==t?e.length:t,Xn(e,l,n,n,n,n,t)}function Ms(e,t){var r;if("function"!=typeof t)throw new Ae(o);return e=pa(e),function(){return--e>0&&(r=t.apply(this,arguments)),e<=1&&(t=n),r}}var Rs=Gi((function(e,t,r){var i=1;if(r.length){var n=tr(r,oo(Rs));i|=c}return Xn(e,i,t,r,n)})),Ts=Gi((function(e,t,r){var i=3;if(r.length){var n=tr(r,oo(Ts));i|=c}return Xn(t,i,e,r,n)}));function Os(e,t,r){var i,s,a,c,l,u,h=0,f=!1,_=!1,d=!0;if("function"!=typeof e)throw new Ae(o);function p(t){var r=i,o=s;return i=s=n,h=t,c=e.apply(o,r)}function v(e){return h=e,l=Ro(y,t),f?p(e):c}function g(e){var r=e-u;return u===n||r>=t||r<0||_&&e-h>=a}function y(){var e=As();if(g(e))return m(e);l=Ro(y,function(e){var r=t-(e-u);return _?gr(r,a-(e-h)):r}(e))}function m(e){return l=n,d&&i?p(e):(i=s=n,c)}function b(){var e=As(),r=g(e);if(i=arguments,s=this,u=e,r){if(l===n)return v(u);if(_)return bn(l),l=Ro(y,t),p(u)}return l===n&&(l=Ro(y,t)),c}return t=ga(t)||0,ta(r)&&(f=!!r.leading,a=(_="maxWait"in r)?vr(ga(r.maxWait)||0,t):a,d="trailing"in r?!!r.trailing:d),b.cancel=function(){l!==n&&bn(l),h=0,i=u=s=l=n},b.flush=function(){return l===n?c:m(As())},b}var Bs=Gi((function(e,t){return ci(e,1,t)})),Ds=Gi((function(e,t,r){return ci(e,ga(t)||0,r)}));function Ps(e,t){if("function"!=typeof e||null!=t&&"function"!=typeof t)throw new Ae(o);var r=function(){var i=arguments,n=t?t.apply(this,i):i[0],o=r.cache;if(o.has(n))return o.get(n);var s=e.apply(this,i);return r.cache=o.set(n,s)||o,s};return r.cache=new(Ps.Cache||Kr),r}function Is(e){if("function"!=typeof e)throw new Ae(o);return function(){var t=arguments;switch(t.length){case 0:return!e.call(this);case 1:return!e.call(this,t[0]);case 2:return!e.call(this,t[0],t[1]);case 3:return!e.call(this,t[0],t[1],t[2])}return!e.apply(this,t)}}Ps.Cache=Kr;var Hs=yn((function(e,t){var r=(t=1==t.length&&Ks(t[0])?Et(t[0],Nt(so())):Et(pi(t,1),Nt(so()))).length;return Gi((function(i){for(var n=-1,o=gr(i.length,r);++n<o;)i[n]=t[n].call(this,i[n]);return gt(e,this,i)}))})),js=Gi((function(e,t){var r=tr(t,oo(js));return Xn(e,c,n,t,r)})),Fs=Gi((function(e,t){var r=tr(t,oo(Fs));return Xn(e,64,n,t,r)})),Ws=eo((function(e,t){return Xn(e,256,n,n,n,t)}));function Us(e,t){return e===t||e!=e&&t!=t}var qs=zn(Li),Ns=zn((function(e,t){return e>=t})),zs=Mi(function(){return arguments}())?Mi:function(e){return ra(e)&&Be.call(e,"callee")&&!et.call(e,"callee")},Ks=i.isArray,Vs=ht?Nt(ht):function(e){return ra(e)&&wi(e)==T};function Gs(e){return null!=e&&ea(e.length)&&!$s(e)}function Ys(e){return ra(e)&&Gs(e)}var Xs=fr||gc,Zs=ft?Nt(ft):function(e){return ra(e)&&wi(e)==y};function Js(e){if(!ra(e))return!1;var t=wi(e);return t==m||"[object DOMException]"==t||"string"==typeof e.message&&"string"==typeof e.name&&!oa(e)}function $s(e){if(!ta(e))return!1;var t=wi(e);return t==b||t==S||"[object AsyncFunction]"==t||"[object Proxy]"==t}function Qs(e){return"number"==typeof e&&e==pa(e)}function ea(e){return"number"==typeof e&&e>-1&&e%1==0&&e<=h}function ta(e){var t=typeof e;return null!=e&&("object"==t||"function"==t)}function ra(e){return null!=e&&"object"==typeof e}var ia=_t?Nt(_t):function(e){return ra(e)&&fo(e)==C};function na(e){return"number"==typeof e||ra(e)&&wi(e)==w}function oa(e){if(!ra(e)||wi(e)!=L)return!1;var t=Ve(e);if(null===t)return!0;var r=Be.call(t,"constructor")&&t.constructor;return"function"==typeof r&&r instanceof r&&Oe.call(r)==He}var sa=dt?Nt(dt):function(e){return ra(e)&&wi(e)==x},aa=pt?Nt(pt):function(e){return ra(e)&&fo(e)==A};function ca(e){return"string"==typeof e||!Ks(e)&&ra(e)&&wi(e)==k}function la(e){return"symbol"==typeof e||ra(e)&&wi(e)==M}var ua=vt?Nt(vt):function(e){return ra(e)&&ea(e.length)&&!!$e[wi(e)]},ha=zn(Pi),fa=zn((function(e,t){return e<=t}));function _a(e){if(!e)return[];if(Gs(e))return ca(e)?or(e):An(e);if(st&&e[st])return function(e){for(var t,r=[];!(t=e.next()).done;)r.push(t.value);return r}(e[st]());var t=fo(e);return(t==C?Qt:t==A?rr:Ua)(e)}function da(e){return e?(e=ga(e))===u||e===-1/0?17976931348623157e292*(e<0?-1:1):e==e?e:0:0===e?e:0}function pa(e){var t=da(e),r=t%1;return t==t?r?t-r:t:0}function va(e){return e?oi(pa(e),0,_):0}function ga(e){if("number"==typeof e)return e;if(la(e))return f;if(ta(e)){var t="function"==typeof e.valueOf?e.valueOf():e;e=ta(t)?t+"":t}if("string"!=typeof e)return 0===e?e:+e;e=qt(e);var r=de.test(e);return r||ve.test(e)?rt(e.slice(2),r?2:8):_e.test(e)?f:+e}function ya(e){return kn(e,Ba(e))}function ma(e){return null==e?"":an(e)}var ba=Rn((function(e,t){if(Co(t)||Gs(t))kn(t,Oa(t),e);else for(var r in t)Be.call(t,r)&&Qr(e,r,t[r])})),Sa=Rn((function(e,t){kn(t,Ba(t),e)})),Ca=Rn((function(e,t,r,i){kn(t,Ba(t),e,i)})),wa=Rn((function(e,t,r,i){kn(t,Oa(t),e,i)})),La=eo(ni),Ea=Gi((function(e,t){e=Le(e);var r=-1,i=t.length,o=i>2?t[2]:n;for(o&&yo(t[0],t[1],o)&&(i=1);++r<i;)for(var s=t[r],a=Ba(s),c=-1,l=a.length;++c<l;){var u=a[c],h=e[u];(h===n||Us(h,Re[u])&&!Be.call(e,u))&&(e[u]=s[u])}return e})),xa=Gi((function(e){return e.push(n,Jn),gt(Pa,n,e)}));function Aa(e,t,r){var i=null==e?n:Si(e,t);return i===n?r:i}function ka(e,t){return null!=e&&_o(e,t,xi)}var Ma=Fn((function(e,t,r){null!=t&&"function"!=typeof t.toString&&(t=Ie.call(t)),e[t]=r}),tc(nc)),Ra=Fn((function(e,t,r){null!=t&&"function"!=typeof t.toString&&(t=Ie.call(t)),Be.call(e,t)?e[t].push(r):e[t]=[r]}),so),Ta=Gi(ki);function Oa(e){return Gs(e)?Yr(e):Di(e)}function Ba(e){return Gs(e)?Yr(e,!0):function(e){if(!ta(e))return function(e){var t=[];if(null!=e)for(var r in Le(e))t.push(r);return t}(e);var t=Co(e),r=[];for(var i in e)("constructor"!=i||!t&&Be.call(e,i))&&r.push(i);return r}(e)}var Da=Rn((function(e,t,r){Fi(e,t,r)})),Pa=Rn((function(e,t,r,i){Fi(e,t,r,i)})),Ia=eo((function(e,t){var r={};if(null==e)return r;var i=!1;t=Et(t,(function(t){return t=gn(t,e),i||(i=t.length>1),t})),kn(e,ro(e),r),i&&(r=si(r,7,$n));for(var n=t.length;n--;)ln(r,t[n]);return r})),Ha=eo((function(e,t){return null==e?{}:function(e,t){return qi(e,t,(function(t,r){return ka(e,r)}))}(e,t)}));function ja(e,t){if(null==e)return{};var r=Et(ro(e),(function(e){return[e]}));return t=so(t),qi(e,r,(function(e,r){return t(e,r[0])}))}var Fa=Yn(Oa),Wa=Yn(Ba);function Ua(e){return null==e?[]:zt(e,Oa(e))}var qa=Dn((function(e,t,r){return t=t.toLowerCase(),e+(r?Na(t):t)}));function Na(e){return Ja(ma(e).toLowerCase())}function za(e){return(e=ma(e))&&e.replace(ye,Xt).replace(Ke,"")}var Ka=Dn((function(e,t,r){return e+(r?"-":"")+t.toLowerCase()})),Va=Dn((function(e,t,r){return e+(r?" ":"")+t.toLowerCase()})),Ga=Bn("toLowerCase"),Ya=Dn((function(e,t,r){return e+(r?"_":"")+t.toLowerCase()})),Xa=Dn((function(e,t,r){return e+(r?" ":"")+Ja(t)})),Za=Dn((function(e,t,r){return e+(r?" ":"")+t.toUpperCase()})),Ja=Bn("toUpperCase");function $a(e,t,r){return e=ma(e),(t=r?n:t)===n?function(e){return Xe.test(e)}(e)?function(e){return e.match(Ge)||[]}(e):function(e){return e.match(ce)||[]}(e):e.match(t)||[]}var Qa=Gi((function(e,t){try{return gt(e,n,t)}catch(e){return Js(e)?e:new Se(e)}})),ec=eo((function(e,t){return mt(t,(function(t){t=jo(t),ii(e,t,Rs(e[t],e))})),e}));function tc(e){return function(){return e}}var rc=Hn(),ic=Hn(!0);function nc(e){return e}function oc(e){return Bi("function"==typeof e?e:si(e,1))}var sc=Gi((function(e,t){return function(r){return ki(r,e,t)}})),ac=Gi((function(e,t){return function(r){return ki(e,r,t)}}));function cc(e,t,r){var i=Oa(t),n=bi(t,i);null!=r||ta(t)&&(n.length||!i.length)||(r=t,t=e,e=this,n=bi(t,Oa(t)));var o=!(ta(r)&&"chain"in r&&!r.chain),s=$s(e);return mt(n,(function(r){var i=t[r];e[r]=i,s&&(e.prototype[r]=function(){var t=this.__chain__;if(o||t){var r=e(this.__wrapped__),n=r.__actions__=An(this.__actions__);return n.push({func:i,args:arguments,thisArg:e}),r.__chain__=t,r}return i.apply(e,xt([this.value()],arguments))})})),e}function lc(){}var uc=Un(Et),hc=Un(St),fc=Un(Mt);function _c(e){return mo(e)?Ht(jo(e)):function(e){return function(t){return Si(t,e)}}(e)}var dc=Nn(),pc=Nn(!0);function vc(){return[]}function gc(){return!1}var yc,mc=Wn((function(e,t){return e+t}),0),bc=Vn("ceil"),Sc=Wn((function(e,t){return e/t}),1),Cc=Vn("floor"),wc=Wn((function(e,t){return e*t}),1),Lc=Vn("round"),Ec=Wn((function(e,t){return e-t}),0);return jr.after=function(e,t){if("function"!=typeof t)throw new Ae(o);return e=pa(e),function(){if(--e<1)return t.apply(this,arguments)}},jr.ary=ks,jr.assign=ba,jr.assignIn=Sa,jr.assignInWith=Ca,jr.assignWith=wa,jr.at=La,jr.before=Ms,jr.bind=Rs,jr.bindAll=ec,jr.bindKey=Ts,jr.castArray=function(){if(!arguments.length)return[];var e=arguments[0];return Ks(e)?e:[e]},jr.chain=_s,jr.chunk=function(e,t,r){t=(r?yo(e,t,r):t===n)?1:vr(pa(t),0);var o=null==e?0:e.length;if(!o||t<1)return[];for(var s=0,a=0,c=i(lr(o/t));s<o;)c[a++]=en(e,s,s+=t);return c},jr.compact=function(e){for(var t=-1,r=null==e?0:e.length,i=0,n=[];++t<r;){var o=e[t];o&&(n[i++]=o)}return n},jr.concat=function(){var e=arguments.length;if(!e)return[];for(var t=i(e-1),r=arguments[0],n=e;n--;)t[n-1]=arguments[n];return xt(Ks(r)?An(r):[r],pi(t,1))},jr.cond=function(e){var t=null==e?0:e.length,r=so();return e=t?Et(e,(function(e){if("function"!=typeof e[1])throw new Ae(o);return[r(e[0]),e[1]]})):[],Gi((function(r){for(var i=-1;++i<t;){var n=e[i];if(gt(n[0],this,r))return gt(n[1],this,r)}}))},jr.conforms=function(e){return function(e){var t=Oa(e);return function(r){return ai(r,e,t)}}(si(e,1))},jr.constant=tc,jr.countBy=vs,jr.create=function(e,t){var r=Fr(e);return null==t?r:ri(r,t)},jr.curry=function e(t,r,i){var o=Xn(t,8,n,n,n,n,n,r=i?n:r);return o.placeholder=e.placeholder,o},jr.curryRight=function e(t,r,i){var o=Xn(t,16,n,n,n,n,n,r=i?n:r);return o.placeholder=e.placeholder,o},jr.debounce=Os,jr.defaults=Ea,jr.defaultsDeep=xa,jr.defer=Bs,jr.delay=Ds,jr.difference=Uo,jr.differenceBy=qo,jr.differenceWith=No,jr.drop=function(e,t,r){var i=null==e?0:e.length;return i?en(e,(t=r||t===n?1:pa(t))<0?0:t,i):[]},jr.dropRight=function(e,t,r){var i=null==e?0:e.length;return i?en(e,0,(t=i-(t=r||t===n?1:pa(t)))<0?0:t):[]},jr.dropRightWhile=function(e,t){return e&&e.length?hn(e,so(t,3),!0,!0):[]},jr.dropWhile=function(e,t){return e&&e.length?hn(e,so(t,3),!0):[]},jr.fill=function(e,t,r,i){var o=null==e?0:e.length;return o?(r&&"number"!=typeof r&&yo(e,t,r)&&(r=0,i=o),function(e,t,r,i){var o=e.length;for((r=pa(r))<0&&(r=-r>o?0:o+r),(i=i===n||i>o?o:pa(i))<0&&(i+=o),i=r>i?0:va(i);r<i;)e[r++]=t;return e}(e,t,r,i)):[]},jr.filter=function(e,t){return(Ks(e)?Ct:di)(e,so(t,3))},jr.flatMap=function(e,t){return pi(Ls(e,t),1)},jr.flatMapDeep=function(e,t){return pi(Ls(e,t),u)},jr.flatMapDepth=function(e,t,r){return r=r===n?1:pa(r),pi(Ls(e,t),r)},jr.flatten=Vo,jr.flattenDeep=function(e){return null!=e&&e.length?pi(e,u):[]},jr.flattenDepth=function(e,t){return null!=e&&e.length?pi(e,t=t===n?1:pa(t)):[]},jr.flip=function(e){return Xn(e,512)},jr.flow=rc,jr.flowRight=ic,jr.fromPairs=function(e){for(var t=-1,r=null==e?0:e.length,i={};++t<r;){var n=e[t];i[n[0]]=n[1]}return i},jr.functions=function(e){return null==e?[]:bi(e,Oa(e))},jr.functionsIn=function(e){return null==e?[]:bi(e,Ba(e))},jr.groupBy=Ss,jr.initial=function(e){return null!=e&&e.length?en(e,0,-1):[]},jr.intersection=Yo,jr.intersectionBy=Xo,jr.intersectionWith=Zo,jr.invert=Ma,jr.invertBy=Ra,jr.invokeMap=Cs,jr.iteratee=oc,jr.keyBy=ws,jr.keys=Oa,jr.keysIn=Ba,jr.map=Ls,jr.mapKeys=function(e,t){var r={};return t=so(t,3),yi(e,(function(e,i,n){ii(r,t(e,i,n),e)})),r},jr.mapValues=function(e,t){var r={};return t=so(t,3),yi(e,(function(e,i,n){ii(r,i,t(e,i,n))})),r},jr.matches=function(e){return Hi(si(e,1))},jr.matchesProperty=function(e,t){return ji(e,si(t,1))},jr.memoize=Ps,jr.merge=Da,jr.mergeWith=Pa,jr.method=sc,jr.methodOf=ac,jr.mixin=cc,jr.negate=Is,jr.nthArg=function(e){return e=pa(e),Gi((function(t){return Wi(t,e)}))},jr.omit=Ia,jr.omitBy=function(e,t){return ja(e,Is(so(t)))},jr.once=function(e){return Ms(2,e)},jr.orderBy=function(e,t,r,i){return null==e?[]:(Ks(t)||(t=null==t?[]:[t]),Ks(r=i?n:r)||(r=null==r?[]:[r]),Ui(e,t,r))},jr.over=uc,jr.overArgs=Hs,jr.overEvery=hc,jr.overSome=fc,jr.partial=js,jr.partialRight=Fs,jr.partition=Es,jr.pick=Ha,jr.pickBy=ja,jr.property=_c,jr.propertyOf=function(e){return function(t){return null==e?n:Si(e,t)}},jr.pull=$o,jr.pullAll=Qo,jr.pullAllBy=function(e,t,r){return e&&e.length&&t&&t.length?Ni(e,t,so(r,2)):e},jr.pullAllWith=function(e,t,r){return e&&e.length&&t&&t.length?Ni(e,t,n,r):e},jr.pullAt=es,jr.range=dc,jr.rangeRight=pc,jr.rearg=Ws,jr.reject=function(e,t){return(Ks(e)?Ct:di)(e,Is(so(t,3)))},jr.remove=function(e,t){var r=[];if(!e||!e.length)return r;var i=-1,n=[],o=e.length;for(t=so(t,3);++i<o;){var s=e[i];t(s,i,e)&&(r.push(s),n.push(i))}return zi(e,n),r},jr.rest=function(e,t){if("function"!=typeof e)throw new Ae(o);return Gi(e,t=t===n?t:pa(t))},jr.reverse=ts,jr.sampleSize=function(e,t,r){return t=(r?yo(e,t,r):t===n)?1:pa(t),(Ks(e)?Zr:Xi)(e,t)},jr.set=function(e,t,r){return null==e?e:Zi(e,t,r)},jr.setWith=function(e,t,r,i){return i="function"==typeof i?i:n,null==e?e:Zi(e,t,r,i)},jr.shuffle=function(e){return(Ks(e)?Jr:Qi)(e)},jr.slice=function(e,t,r){var i=null==e?0:e.length;return i?(r&&"number"!=typeof r&&yo(e,t,r)?(t=0,r=i):(t=null==t?0:pa(t),r=r===n?i:pa(r)),en(e,t,r)):[]},jr.sortBy=xs,jr.sortedUniq=function(e){return e&&e.length?on(e):[]},jr.sortedUniqBy=function(e,t){return e&&e.length?on(e,so(t,2)):[]},jr.split=function(e,t,r){return r&&"number"!=typeof r&&yo(e,t,r)&&(t=r=n),(r=r===n?_:r>>>0)?(e=ma(e))&&("string"==typeof t||null!=t&&!sa(t))&&!(t=an(t))&&$t(e)?mn(or(e),0,r):e.split(t,r):[]},jr.spread=function(e,t){if("function"!=typeof e)throw new Ae(o);return t=null==t?0:vr(pa(t),0),Gi((function(r){var i=r[t],n=mn(r,0,t);return i&&xt(n,i),gt(e,this,n)}))},jr.tail=function(e){var t=null==e?0:e.length;return t?en(e,1,t):[]},jr.take=function(e,t,r){return e&&e.length?en(e,0,(t=r||t===n?1:pa(t))<0?0:t):[]},jr.takeRight=function(e,t,r){var i=null==e?0:e.length;return i?en(e,(t=i-(t=r||t===n?1:pa(t)))<0?0:t,i):[]},jr.takeRightWhile=function(e,t){return e&&e.length?hn(e,so(t,3),!1,!0):[]},jr.takeWhile=function(e,t){return e&&e.length?hn(e,so(t,3)):[]},jr.tap=function(e,t){return t(e),e},jr.throttle=function(e,t,r){var i=!0,n=!0;if("function"!=typeof e)throw new Ae(o);return ta(r)&&(i="leading"in r?!!r.leading:i,n="trailing"in r?!!r.trailing:n),Os(e,t,{leading:i,maxWait:t,trailing:n})},jr.thru=ds,jr.toArray=_a,jr.toPairs=Fa,jr.toPairsIn=Wa,jr.toPath=function(e){return Ks(e)?Et(e,jo):la(e)?[e]:An(Ho(ma(e)))},jr.toPlainObject=ya,jr.transform=function(e,t,r){var i=Ks(e),n=i||Xs(e)||ua(e);if(t=so(t,4),null==r){var o=e&&e.constructor;r=n?i?new o:[]:ta(e)&&$s(o)?Fr(Ve(e)):{}}return(n?mt:yi)(e,(function(e,i,n){return t(r,e,i,n)})),r},jr.unary=function(e){return ks(e,1)},jr.union=rs,jr.unionBy=is,jr.unionWith=ns,jr.uniq=function(e){return e&&e.length?cn(e):[]},jr.uniqBy=function(e,t){return e&&e.length?cn(e,so(t,2)):[]},jr.uniqWith=function(e,t){return t="function"==typeof t?t:n,e&&e.length?cn(e,n,t):[]},jr.unset=function(e,t){return null==e||ln(e,t)},jr.unzip=os,jr.unzipWith=ss,jr.update=function(e,t,r){return null==e?e:un(e,t,vn(r))},jr.updateWith=function(e,t,r,i){return i="function"==typeof i?i:n,null==e?e:un(e,t,vn(r),i)},jr.values=Ua,jr.valuesIn=function(e){return null==e?[]:zt(e,Ba(e))},jr.without=as,jr.words=$a,jr.wrap=function(e,t){return js(vn(t),e)},jr.xor=cs,jr.xorBy=ls,jr.xorWith=us,jr.zip=hs,jr.zipObject=function(e,t){return dn(e||[],t||[],Qr)},jr.zipObjectDeep=function(e,t){return dn(e||[],t||[],Zi)},jr.zipWith=fs,jr.entries=Fa,jr.entriesIn=Wa,jr.extend=Sa,jr.extendWith=Ca,cc(jr,jr),jr.add=mc,jr.attempt=Qa,jr.camelCase=qa,jr.capitalize=Na,jr.ceil=bc,jr.clamp=function(e,t,r){return r===n&&(r=t,t=n),r!==n&&(r=(r=ga(r))==r?r:0),t!==n&&(t=(t=ga(t))==t?t:0),oi(ga(e),t,r)},jr.clone=function(e){return si(e,4)},jr.cloneDeep=function(e){return si(e,5)},jr.cloneDeepWith=function(e,t){return si(e,5,t="function"==typeof t?t:n)},jr.cloneWith=function(e,t){return si(e,4,t="function"==typeof t?t:n)},jr.conformsTo=function(e,t){return null==t||ai(e,t,Oa(t))},jr.deburr=za,jr.defaultTo=function(e,t){return null==e||e!=e?t:e},jr.divide=Sc,jr.endsWith=function(e,t,r){e=ma(e),t=an(t);var i=e.length,o=r=r===n?i:oi(pa(r),0,i);return(r-=t.length)>=0&&e.slice(r,o)==t},jr.eq=Us,jr.escape=function(e){return(e=ma(e))&&Y.test(e)?e.replace(V,Zt):e},jr.escapeRegExp=function(e){return(e=ma(e))&&re.test(e)?e.replace(te,"\\$&"):e},jr.every=function(e,t,r){var i=Ks(e)?St:fi;return r&&yo(e,t,r)&&(t=n),i(e,so(t,3))},jr.find=gs,jr.findIndex=zo,jr.findKey=function(e,t){return Tt(e,so(t,3),yi)},jr.findLast=ys,jr.findLastIndex=Ko,jr.findLastKey=function(e,t){return Tt(e,so(t,3),mi)},jr.floor=Cc,jr.forEach=ms,jr.forEachRight=bs,jr.forIn=function(e,t){return null==e?e:vi(e,so(t,3),Ba)},jr.forInRight=function(e,t){return null==e?e:gi(e,so(t,3),Ba)},jr.forOwn=function(e,t){return e&&yi(e,so(t,3))},jr.forOwnRight=function(e,t){return e&&mi(e,so(t,3))},jr.get=Aa,jr.gt=qs,jr.gte=Ns,jr.has=function(e,t){return null!=e&&_o(e,t,Ei)},jr.hasIn=ka,jr.head=Go,jr.identity=nc,jr.includes=function(e,t,r,i){e=Gs(e)?e:Ua(e),r=r&&!i?pa(r):0;var n=e.length;return r<0&&(r=vr(n+r,0)),ca(e)?r<=n&&e.indexOf(t,r)>-1:!!n&&Bt(e,t,r)>-1},jr.indexOf=function(e,t,r){var i=null==e?0:e.length;if(!i)return-1;var n=null==r?0:pa(r);return n<0&&(n=vr(i+n,0)),Bt(e,t,n)},jr.inRange=function(e,t,r){return t=da(t),r===n?(r=t,t=0):r=da(r),function(e,t,r){return e>=gr(t,r)&&e<vr(t,r)}(e=ga(e),t,r)},jr.invoke=Ta,jr.isArguments=zs,jr.isArray=Ks,jr.isArrayBuffer=Vs,jr.isArrayLike=Gs,jr.isArrayLikeObject=Ys,jr.isBoolean=function(e){return!0===e||!1===e||ra(e)&&wi(e)==g},jr.isBuffer=Xs,jr.isDate=Zs,jr.isElement=function(e){return ra(e)&&1===e.nodeType&&!oa(e)},jr.isEmpty=function(e){if(null==e)return!0;if(Gs(e)&&(Ks(e)||"string"==typeof e||"function"==typeof e.splice||Xs(e)||ua(e)||zs(e)))return!e.length;var t=fo(e);if(t==C||t==A)return!e.size;if(Co(e))return!Di(e).length;for(var r in e)if(Be.call(e,r))return!1;return!0},jr.isEqual=function(e,t){return Ri(e,t)},jr.isEqualWith=function(e,t,r){var i=(r="function"==typeof r?r:n)?r(e,t):n;return i===n?Ri(e,t,n,r):!!i},jr.isError=Js,jr.isFinite=function(e){return"number"==typeof e&&_r(e)},jr.isFunction=$s,jr.isInteger=Qs,jr.isLength=ea,jr.isMap=ia,jr.isMatch=function(e,t){return e===t||Ti(e,t,co(t))},jr.isMatchWith=function(e,t,r){return r="function"==typeof r?r:n,Ti(e,t,co(t),r)},jr.isNaN=function(e){return na(e)&&e!=+e},jr.isNative=function(e){if(So(e))throw new Se("Unsupported core-js use. Try https://npms.io/search?q=ponyfill.");return Oi(e)},jr.isNil=function(e){return null==e},jr.isNull=function(e){return null===e},jr.isNumber=na,jr.isObject=ta,jr.isObjectLike=ra,jr.isPlainObject=oa,jr.isRegExp=sa,jr.isSafeInteger=function(e){return Qs(e)&&e>=-9007199254740991&&e<=h},jr.isSet=aa,jr.isString=ca,jr.isSymbol=la,jr.isTypedArray=ua,jr.isUndefined=function(e){return e===n},jr.isWeakMap=function(e){return ra(e)&&fo(e)==R},jr.isWeakSet=function(e){return ra(e)&&"[object WeakSet]"==wi(e)},jr.join=function(e,t){return null==e?"":dr.call(e,t)},jr.kebabCase=Ka,jr.last=Jo,jr.lastIndexOf=function(e,t,r){var i=null==e?0:e.length;if(!i)return-1;var o=i;return r!==n&&(o=(o=pa(r))<0?vr(i+o,0):gr(o,i-1)),t==t?function(e,t,r){for(var i=r+1;i--;)if(e[i]===t)return i;return i}(e,t,o):Ot(e,Pt,o,!0)},jr.lowerCase=Va,jr.lowerFirst=Ga,jr.lt=ha,jr.lte=fa,jr.max=function(e){return e&&e.length?_i(e,nc,Li):n},jr.maxBy=function(e,t){return e&&e.length?_i(e,so(t,2),Li):n},jr.mean=function(e){return It(e,nc)},jr.meanBy=function(e,t){return It(e,so(t,2))},jr.min=function(e){return e&&e.length?_i(e,nc,Pi):n},jr.minBy=function(e,t){return e&&e.length?_i(e,so(t,2),Pi):n},jr.stubArray=vc,jr.stubFalse=gc,jr.stubObject=function(){return{}},jr.stubString=function(){return""},jr.stubTrue=function(){return!0},jr.multiply=wc,jr.nth=function(e,t){return e&&e.length?Wi(e,pa(t)):n},jr.noConflict=function(){return ot._===this&&(ot._=je),this},jr.noop=lc,jr.now=As,jr.pad=function(e,t,r){e=ma(e);var i=(t=pa(t))?nr(e):0;if(!t||i>=t)return e;var n=(t-i)/2;return qn(ur(n),r)+e+qn(lr(n),r)},jr.padEnd=function(e,t,r){e=ma(e);var i=(t=pa(t))?nr(e):0;return t&&i<t?e+qn(t-i,r):e},jr.padStart=function(e,t,r){e=ma(e);var i=(t=pa(t))?nr(e):0;return t&&i<t?qn(t-i,r)+e:e},jr.parseInt=function(e,t,r){return r||null==t?t=0:t&&(t=+t),mr(ma(e).replace(ie,""),t||0)},jr.random=function(e,t,r){if(r&&"boolean"!=typeof r&&yo(e,t,r)&&(t=r=n),r===n&&("boolean"==typeof t?(r=t,t=n):"boolean"==typeof e&&(r=e,e=n)),e===n&&t===n?(e=0,t=1):(e=da(e),t===n?(t=e,e=0):t=da(t)),e>t){var i=e;e=t,t=i}if(r||e%1||t%1){var o=br();return gr(e+o*(t-e+tt("1e-"+((o+"").length-1))),t)}return Ki(e,t)},jr.reduce=function(e,t,r){var i=Ks(e)?At:Ft,n=arguments.length<3;return i(e,so(t,4),r,n,ui)},jr.reduceRight=function(e,t,r){var i=Ks(e)?kt:Ft,n=arguments.length<3;return i(e,so(t,4),r,n,hi)},jr.repeat=function(e,t,r){return t=(r?yo(e,t,r):t===n)?1:pa(t),Vi(ma(e),t)},jr.replace=function(){var e=arguments,t=ma(e[0]);return e.length<3?t:t.replace(e[1],e[2])},jr.result=function(e,t,r){var i=-1,o=(t=gn(t,e)).length;for(o||(o=1,e=n);++i<o;){var s=null==e?n:e[jo(t[i])];s===n&&(i=o,s=r),e=$s(s)?s.call(e):s}return e},jr.round=Lc,jr.runInContext=e,jr.sample=function(e){return(Ks(e)?Xr:Yi)(e)},jr.size=function(e){if(null==e)return 0;if(Gs(e))return ca(e)?nr(e):e.length;var t=fo(e);return t==C||t==A?e.size:Di(e).length},jr.snakeCase=Ya,jr.some=function(e,t,r){var i=Ks(e)?Mt:tn;return r&&yo(e,t,r)&&(t=n),i(e,so(t,3))},jr.sortedIndex=function(e,t){return rn(e,t)},jr.sortedIndexBy=function(e,t,r){return nn(e,t,so(r,2))},jr.sortedIndexOf=function(e,t){var r=null==e?0:e.length;if(r){var i=rn(e,t);if(i<r&&Us(e[i],t))return i}return-1},jr.sortedLastIndex=function(e,t){return rn(e,t,!0)},jr.sortedLastIndexBy=function(e,t,r){return nn(e,t,so(r,2),!0)},jr.sortedLastIndexOf=function(e,t){if(null!=e&&e.length){var r=rn(e,t,!0)-1;if(Us(e[r],t))return r}return-1},jr.startCase=Xa,jr.startsWith=function(e,t,r){return e=ma(e),r=null==r?0:oi(pa(r),0,e.length),t=an(t),e.slice(r,r+t.length)==t},jr.subtract=Ec,jr.sum=function(e){return e&&e.length?Wt(e,nc):0},jr.sumBy=function(e,t){return e&&e.length?Wt(e,so(t,2)):0},jr.template=function(e,t,r){var i=jr.templateSettings;r&&yo(e,t,r)&&(t=n),e=ma(e),t=Ca({},t,i,Zn);var o,s,a=Ca({},t.imports,i.imports,Zn),c=Oa(a),l=zt(a,c),u=0,h=t.interpolate||me,f="__p += '",_=Ee((t.escape||me).source+"|"+h.source+"|"+(h===J?he:me).source+"|"+(t.evaluate||me).source+"|$","g"),d="//# sourceURL="+(Be.call(t,"sourceURL")?(t.sourceURL+"").replace(/\s/g," "):"lodash.templateSources["+ ++Je+"]")+"\n";e.replace(_,(function(t,r,i,n,a,c){return i||(i=n),f+=e.slice(u,c).replace(be,Jt),r&&(o=!0,f+="' +\n__e("+r+") +\n'"),a&&(s=!0,f+="';\n"+a+";\n__p += '"),i&&(f+="' +\n((__t = ("+i+")) == null ? '' : __t) +\n'"),u=c+t.length,t})),f+="';\n";var p=Be.call(t,"variable")&&t.variable;if(p){if(le.test(p))throw new Se("Invalid `variable` option passed into `_.template`")}else f="with (obj) {\n"+f+"\n}\n";f=(s?f.replace(q,""):f).replace(N,"$1").replace(z,"$1;"),f="function("+(p||"obj")+") {\n"+(p?"":"obj || (obj = {});\n")+"var __t, __p = ''"+(o?", __e = _.escape":"")+(s?", __j = Array.prototype.join;\nfunction print() { __p += __j.call(arguments, '') }\n":";\n")+f+"return __p\n}";var v=Qa((function(){return Ce(c,d+"return "+f).apply(n,l)}));if(v.source=f,Js(v))throw v;return v},jr.times=function(e,t){if((e=pa(e))<1||e>h)return[];var r=_,i=gr(e,_);t=so(t),e-=_;for(var n=Ut(i,t);++r<e;)t(r);return n},jr.toFinite=da,jr.toInteger=pa,jr.toLength=va,jr.toLower=function(e){return ma(e).toLowerCase()},jr.toNumber=ga,jr.toSafeInteger=function(e){return e?oi(pa(e),-9007199254740991,h):0===e?e:0},jr.toString=ma,jr.toUpper=function(e){return ma(e).toUpperCase()},jr.trim=function(e,t,r){if((e=ma(e))&&(r||t===n))return qt(e);if(!e||!(t=an(t)))return e;var i=or(e),o=or(t);return mn(i,Vt(i,o),Gt(i,o)+1).join("")},jr.trimEnd=function(e,t,r){if((e=ma(e))&&(r||t===n))return e.slice(0,sr(e)+1);if(!e||!(t=an(t)))return e;var i=or(e);return mn(i,0,Gt(i,or(t))+1).join("")},jr.trimStart=function(e,t,r){if((e=ma(e))&&(r||t===n))return e.replace(ie,"");if(!e||!(t=an(t)))return e;var i=or(e);return mn(i,Vt(i,or(t))).join("")},jr.truncate=function(e,t){var r=30,i="...";if(ta(t)){var o="separator"in t?t.separator:o;r="length"in t?pa(t.length):r,i="omission"in t?an(t.omission):i}var s=(e=ma(e)).length;if($t(e)){var a=or(e);s=a.length}if(r>=s)return e;var c=r-nr(i);if(c<1)return i;var l=a?mn(a,0,c).join(""):e.slice(0,c);if(o===n)return l+i;if(a&&(c+=l.length-c),sa(o)){if(e.slice(c).search(o)){var u,h=l;for(o.global||(o=Ee(o.source,ma(fe.exec(o))+"g")),o.lastIndex=0;u=o.exec(h);)var f=u.index;l=l.slice(0,f===n?c:f)}}else if(e.indexOf(an(o),c)!=c){var _=l.lastIndexOf(o);_>-1&&(l=l.slice(0,_))}return l+i},jr.unescape=function(e){return(e=ma(e))&&G.test(e)?e.replace(K,ar):e},jr.uniqueId=function(e){var t=++De;return ma(e)+t},jr.upperCase=Za,jr.upperFirst=Ja,jr.each=ms,jr.eachRight=bs,jr.first=Go,cc(jr,(yc={},yi(jr,(function(e,t){Be.call(jr.prototype,t)||(yc[t]=e)})),yc),{chain:!1}),jr.VERSION="4.17.21",mt(["bind","bindKey","curry","curryRight","partial","partialRight"],(function(e){jr[e].placeholder=jr})),mt(["drop","take"],(function(e,t){qr.prototype[e]=function(r){r=r===n?1:vr(pa(r),0);var i=this.__filtered__&&!t?new qr(this):this.clone();return i.__filtered__?i.__takeCount__=gr(r,i.__takeCount__):i.__views__.push({size:gr(r,_),type:e+(i.__dir__<0?"Right":"")}),i},qr.prototype[e+"Right"]=function(t){return this.reverse()[e](t).reverse()}})),mt(["filter","map","takeWhile"],(function(e,t){var r=t+1,i=1==r||3==r;qr.prototype[e]=function(e){var t=this.clone();return t.__iteratees__.push({iteratee:so(e,3),type:r}),t.__filtered__=t.__filtered__||i,t}})),mt(["head","last"],(function(e,t){var r="take"+(t?"Right":"");qr.prototype[e]=function(){return this[r](1).value()[0]}})),mt(["initial","tail"],(function(e,t){var r="drop"+(t?"":"Right");qr.prototype[e]=function(){return this.__filtered__?new qr(this):this[r](1)}})),qr.prototype.compact=function(){return this.filter(nc)},qr.prototype.find=function(e){return this.filter(e).head()},qr.prototype.findLast=function(e){return this.reverse().find(e)},qr.prototype.invokeMap=Gi((function(e,t){return"function"==typeof e?new qr(this):this.map((function(r){return ki(r,e,t)}))})),qr.prototype.reject=function(e){return this.filter(Is(so(e)))},qr.prototype.slice=function(e,t){e=pa(e);var r=this;return r.__filtered__&&(e>0||t<0)?new qr(r):(e<0?r=r.takeRight(-e):e&&(r=r.drop(e)),t!==n&&(r=(t=pa(t))<0?r.dropRight(-t):r.take(t-e)),r)},qr.prototype.takeRightWhile=function(e){return this.reverse().takeWhile(e).reverse()},qr.prototype.toArray=function(){return this.take(_)},yi(qr.prototype,(function(e,t){var r=/^(?:filter|find|map|reject)|While$/.test(t),i=/^(?:head|last)$/.test(t),o=jr[i?"take"+("last"==t?"Right":""):t],s=i||/^find/.test(t);o&&(jr.prototype[t]=function(){var t=this.__wrapped__,a=i?[1]:arguments,c=t instanceof qr,l=a[0],u=c||Ks(t),h=function(e){var t=o.apply(jr,xt([e],a));return i&&f?t[0]:t};u&&r&&"function"==typeof l&&1!=l.length&&(c=u=!1);var f=this.__chain__,_=!!this.__actions__.length,d=s&&!f,p=c&&!_;if(!s&&u){t=p?t:new qr(this);var v=e.apply(t,a);return v.__actions__.push({func:ds,args:[h],thisArg:n}),new Ur(v,f)}return d&&p?e.apply(this,a):(v=this.thru(h),d?i?v.value()[0]:v.value():v)})})),mt(["pop","push","shift","sort","splice","unshift"],(function(e){var t=ke[e],r=/^(?:push|sort|unshift)$/.test(e)?"tap":"thru",i=/^(?:pop|shift)$/.test(e);jr.prototype[e]=function(){var e=arguments;if(i&&!this.__chain__){var n=this.value();return t.apply(Ks(n)?n:[],e)}return this[r]((function(r){return t.apply(Ks(r)?r:[],e)}))}})),yi(qr.prototype,(function(e,t){var r=jr[t];if(r){var i=r.name+"";Be.call(Mr,i)||(Mr[i]=[]),Mr[i].push({name:t,func:r})}})),Mr[jn(n,2).name]=[{name:"wrapper",func:n}],qr.prototype.clone=function(){var e=new qr(this.__wrapped__);return e.__actions__=An(this.__actions__),e.__dir__=this.__dir__,e.__filtered__=this.__filtered__,e.__iteratees__=An(this.__iteratees__),e.__takeCount__=this.__takeCount__,e.__views__=An(this.__views__),e},qr.prototype.reverse=function(){if(this.__filtered__){var e=new qr(this);e.__dir__=-1,e.__filtered__=!0}else(e=this.clone()).__dir__*=-1;return e},qr.prototype.value=function(){var e=this.__wrapped__.value(),t=this.__dir__,r=Ks(e),i=t<0,n=r?e.length:0,o=function(e,t,r){for(var i=-1,n=r.length;++i<n;){var o=r[i],s=o.size;switch(o.type){case"drop":e+=s;break;case"dropRight":t-=s;break;case"take":t=gr(t,e+s);break;case"takeRight":e=vr(e,t-s)}}return{start:e,end:t}}(0,n,this.__views__),s=o.start,a=o.end,c=a-s,l=i?a:s-1,u=this.__iteratees__,h=u.length,f=0,_=gr(c,this.__takeCount__);if(!r||!i&&n==c&&_==c)return fn(e,this.__actions__);var d=[];e:for(;c--&&f<_;){for(var p=-1,v=e[l+=t];++p<h;){var g=u[p],y=g.iteratee,m=g.type,b=y(v);if(2==m)v=b;else if(!b){if(1==m)continue e;break e}}d[f++]=v}return d},jr.prototype.at=ps,jr.prototype.chain=function(){return _s(this)},jr.prototype.commit=function(){return new Ur(this.value(),this.__chain__)},jr.prototype.next=function(){this.__values__===n&&(this.__values__=_a(this.value()));var e=this.__index__>=this.__values__.length;return{done:e,value:e?n:this.__values__[this.__index__++]}},jr.prototype.plant=function(e){for(var t,r=this;r instanceof Wr;){var i=Wo(r);i.__index__=0,i.__values__=n,t?o.__wrapped__=i:t=i;var o=i;r=r.__wrapped__}return o.__wrapped__=e,t},jr.prototype.reverse=function(){var e=this.__wrapped__;if(e instanceof qr){var t=e;return this.__actions__.length&&(t=new qr(this)),(t=t.reverse()).__actions__.push({func:ds,args:[ts],thisArg:n}),new Ur(t,this.__chain__)}return this.thru(ts)},jr.prototype.toJSON=jr.prototype.valueOf=jr.prototype.value=function(){return fn(this.__wrapped__,this.__actions__)},jr.prototype.first=jr.prototype.head,st&&(jr.prototype[st]=function(){return this}),jr}();ot._=cr,(i=function(){return cr}.call(t,r,t,e))===n||(e.exports=i)}.call(this)},379:e=>{"use strict";var t=[];function r(e){for(var r=-1,i=0;i<t.length;i++)if(t[i].identifier===e){r=i;break}return r}function i(e,i){for(var o={},s=[],a=0;a<e.length;a++){var c=e[a],l=i.base?c[0]+i.base:c[0],u=o[l]||0,h="".concat(l," ").concat(u);o[l]=u+1;var f=r(h),_={css:c[1],media:c[2],sourceMap:c[3],supports:c[4],layer:c[5]};if(-1!==f)t[f].references++,t[f].updater(_);else{var d=n(_,i);i.byIndex=a,t.splice(a,0,{identifier:h,updater:d,references:1})}s.push(h)}return s}function n(e,t){var r=t.domAPI(t);return r.update(e),function(t){if(t){if(t.css===e.css&&t.media===e.media&&t.sourceMap===e.sourceMap&&t.supports===e.supports&&t.layer===e.layer)return;r.update(e=t)}else r.remove()}}e.exports=function(e,n){var o=i(e=e||[],n=n||{});return function(e){e=e||[];for(var s=0;s<o.length;s++){var a=r(o[s]);t[a].references--}for(var c=i(e,n),l=0;l<o.length;l++){var u=r(o[l]);0===t[u].references&&(t[u].updater(),t.splice(u,1))}o=c}}},569:e=>{"use strict";var t={};e.exports=function(e,r){var i=function(e){if(void 0===t[e]){var r=document.querySelector(e);if(window.HTMLIFrameElement&&r instanceof window.HTMLIFrameElement)try{r=r.contentDocument.head}catch(e){r=null}t[e]=r}return t[e]}(e);if(!i)throw new Error("Couldn't find a style target. This probably means that the value for the 'insert' parameter is invalid.");i.appendChild(r)}},216:e=>{"use strict";e.exports=function(e){var t=document.createElement("style");return e.setAttributes(t,e.attributes),e.insert(t,e.options),t}},565:(e,t,r)=>{"use strict";e.exports=function(e){var t=r.nc;t&&e.setAttribute("nonce",t)}},795:e=>{"use strict";e.exports=function(e){var t=e.insertStyleElement(e);return{update:function(r){!function(e,t,r){var i="";r.supports&&(i+="@supports (".concat(r.supports,") {")),r.media&&(i+="@media ".concat(r.media," {"));var n=void 0!==r.layer;n&&(i+="@layer".concat(r.layer.length>0?" ".concat(r.layer):""," {")),i+=r.css,n&&(i+="}"),r.media&&(i+="}"),r.supports&&(i+="}");var o=r.sourceMap;o&&"undefined"!=typeof btoa&&(i+="\n/*# sourceMappingURL=data:application/json;base64,".concat(btoa(unescape(encodeURIComponent(JSON.stringify(o))))," */")),t.styleTagTransform(i,e,t.options)}(t,e,r)},remove:function(){!function(e){if(null===e.parentNode)return!1;e.parentNode.removeChild(e)}(t)}}}},589:e=>{"use strict";e.exports=function(e,t){if(t.styleSheet)t.styleSheet.cssText=e;else{for(;t.firstChild;)t.removeChild(t.firstChild);t.appendChild(document.createTextNode(e))}}},617:e=>{self,e.exports=(()=>{"use strict";var e={775:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.FitAddon=void 0;var r=function(){function e(){}return e.prototype.activate=function(e){this._terminal=e},e.prototype.dispose=function(){},e.prototype.fit=function(){var e=this.proposeDimensions();if(e&&this._terminal){var t=this._terminal._core;this._terminal.rows===e.rows&&this._terminal.cols===e.cols||(t._renderService.clear(),this._terminal.resize(e.cols,e.rows))}},e.prototype.proposeDimensions=function(){if(this._terminal&&this._terminal.element&&this._terminal.element.parentElement){var e=this._terminal._core;if(0!==e._renderService.dimensions.actualCellWidth&&0!==e._renderService.dimensions.actualCellHeight){var t=window.getComputedStyle(this._terminal.element.parentElement),r=parseInt(t.getPropertyValue("height")),i=Math.max(0,parseInt(t.getPropertyValue("width"))),n=window.getComputedStyle(this._terminal.element),o=r-(parseInt(n.getPropertyValue("padding-top"))+parseInt(n.getPropertyValue("padding-bottom"))),s=i-(parseInt(n.getPropertyValue("padding-right"))+parseInt(n.getPropertyValue("padding-left")))-e.viewport.scrollBarWidth;return{cols:Math.max(2,Math.floor(s/e._renderService.dimensions.actualCellWidth)),rows:Math.max(1,Math.floor(o/e._renderService.dimensions.actualCellHeight))}}}},e}();t.FitAddon=r}},t={};return function r(i){if(t[i])return t[i].exports;var n=t[i]={exports:{}};return e[i](n,n.exports,r),n.exports}(775)})()},320:e=>{self,e.exports=(()=>{"use strict";var e={4567:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)});Object.defineProperty(t,"__esModule",{value:!0}),t.AccessibilityManager=void 0;var o=r(9042),s=r(6114),a=r(9924),c=r(3656),l=r(844),u=r(5596),h=r(9631),f=function(e){function t(t,r){var i=e.call(this)||this;i._terminal=t,i._renderService=r,i._liveRegionLineCount=0,i._charsToConsume=[],i._charsToAnnounce="",i._accessibilityTreeRoot=document.createElement("div"),i._accessibilityTreeRoot.setAttribute("role","document"),i._accessibilityTreeRoot.classList.add("xterm-accessibility"),i._accessibilityTreeRoot.tabIndex=0,i._rowContainer=document.createElement("div"),i._rowContainer.setAttribute("role","list"),i._rowContainer.classList.add("xterm-accessibility-tree"),i._rowElements=[];for(var n=0;n<i._terminal.rows;n++)i._rowElements[n]=i._createAccessibilityTreeNode(),i._rowContainer.appendChild(i._rowElements[n]);if(i._topBoundaryFocusListener=function(e){return i._onBoundaryFocus(e,0)},i._bottomBoundaryFocusListener=function(e){return i._onBoundaryFocus(e,1)},i._rowElements[0].addEventListener("focus",i._topBoundaryFocusListener),i._rowElements[i._rowElements.length-1].addEventListener("focus",i._bottomBoundaryFocusListener),i._refreshRowsDimensions(),i._accessibilityTreeRoot.appendChild(i._rowContainer),i._renderRowsDebouncer=new a.TimeBasedDebouncer(i._renderRows.bind(i)),i._refreshRows(),i._liveRegion=document.createElement("div"),i._liveRegion.classList.add("live-region"),i._liveRegion.setAttribute("aria-live","assertive"),i._accessibilityTreeRoot.appendChild(i._liveRegion),!i._terminal.element)throw new Error("Cannot enable accessibility before Terminal.open");return i._terminal.element.insertAdjacentElement("afterbegin",i._accessibilityTreeRoot),i.register(i._renderRowsDebouncer),i.register(i._terminal.onResize((function(e){return i._onResize(e.rows)}))),i.register(i._terminal.onRender((function(e){return i._refreshRows(e.start,e.end)}))),i.register(i._terminal.onScroll((function(){return i._refreshRows()}))),i.register(i._terminal.onA11yChar((function(e){return i._onChar(e)}))),i.register(i._terminal.onLineFeed((function(){return i._onChar("\n")}))),i.register(i._terminal.onA11yTab((function(e){return i._onTab(e)}))),i.register(i._terminal.onKey((function(e){return i._onKey(e.key)}))),i.register(i._terminal.onBlur((function(){return i._clearLiveRegion()}))),i.register(i._renderService.onDimensionsChange((function(){return i._refreshRowsDimensions()}))),i._screenDprMonitor=new u.ScreenDprMonitor,i.register(i._screenDprMonitor),i._screenDprMonitor.setListener((function(){return i._refreshRowsDimensions()})),i.register((0,c.addDisposableDomListener)(window,"resize",(function(){return i._refreshRowsDimensions()}))),i}return n(t,e),t.prototype.dispose=function(){e.prototype.dispose.call(this),(0,h.removeElementFromParent)(this._accessibilityTreeRoot),this._rowElements.length=0},t.prototype._onBoundaryFocus=function(e,t){var r=e.target,i=this._rowElements[0===t?1:this._rowElements.length-2];if(r.getAttribute("aria-posinset")!==(0===t?"1":""+this._terminal.buffer.lines.length)&&e.relatedTarget===i){var n,o;if(0===t?(n=r,o=this._rowElements.pop(),this._rowContainer.removeChild(o)):(n=this._rowElements.shift(),o=r,this._rowContainer.removeChild(n)),n.removeEventListener("focus",this._topBoundaryFocusListener),o.removeEventListener("focus",this._bottomBoundaryFocusListener),0===t){var s=this._createAccessibilityTreeNode();this._rowElements.unshift(s),this._rowContainer.insertAdjacentElement("afterbegin",s)}else s=this._createAccessibilityTreeNode(),this._rowElements.push(s),this._rowContainer.appendChild(s);this._rowElements[0].addEventListener("focus",this._topBoundaryFocusListener),this._rowElements[this._rowElements.length-1].addEventListener("focus",this._bottomBoundaryFocusListener),this._terminal.scrollLines(0===t?-1:1),this._rowElements[0===t?1:this._rowElements.length-2].focus(),e.preventDefault(),e.stopImmediatePropagation()}},t.prototype._onResize=function(e){this._rowElements[this._rowElements.length-1].removeEventListener("focus",this._bottomBoundaryFocusListener);for(var t=this._rowContainer.children.length;t<this._terminal.rows;t++)this._rowElements[t]=this._createAccessibilityTreeNode(),this._rowContainer.appendChild(this._rowElements[t]);for(;this._rowElements.length>e;)this._rowContainer.removeChild(this._rowElements.pop());this._rowElements[this._rowElements.length-1].addEventListener("focus",this._bottomBoundaryFocusListener),this._refreshRowsDimensions()},t.prototype._createAccessibilityTreeNode=function(){var e=document.createElement("div");return e.setAttribute("role","listitem"),e.tabIndex=-1,this._refreshRowDimensions(e),e},t.prototype._onTab=function(e){for(var t=0;t<e;t++)this._onChar(" ")},t.prototype._onChar=function(e){var t=this;this._liveRegionLineCount<21&&(this._charsToConsume.length>0?this._charsToConsume.shift()!==e&&(this._charsToAnnounce+=e):this._charsToAnnounce+=e,"\n"===e&&(this._liveRegionLineCount++,21===this._liveRegionLineCount&&(this._liveRegion.textContent+=o.tooMuchOutput)),s.isMac&&this._liveRegion.textContent&&this._liveRegion.textContent.length>0&&!this._liveRegion.parentNode&&setTimeout((function(){t._accessibilityTreeRoot.appendChild(t._liveRegion)}),0))},t.prototype._clearLiveRegion=function(){this._liveRegion.textContent="",this._liveRegionLineCount=0,s.isMac&&(0,h.removeElementFromParent)(this._liveRegion)},t.prototype._onKey=function(e){this._clearLiveRegion(),this._charsToConsume.push(e)},t.prototype._refreshRows=function(e,t){this._renderRowsDebouncer.refresh(e,t,this._terminal.rows)},t.prototype._renderRows=function(e,t){for(var r=this._terminal.buffer,i=r.lines.length.toString(),n=e;n<=t;n++){var o=r.translateBufferLineToString(r.ydisp+n,!0),s=(r.ydisp+n+1).toString(),a=this._rowElements[n];a&&(0===o.length?a.innerText=" ":a.textContent=o,a.setAttribute("aria-posinset",s),a.setAttribute("aria-setsize",i))}this._announceCharacters()},t.prototype._refreshRowsDimensions=function(){if(this._renderService.dimensions.actualCellHeight){this._rowElements.length!==this._terminal.rows&&this._onResize(this._terminal.rows);for(var e=0;e<this._terminal.rows;e++)this._refreshRowDimensions(this._rowElements[e])}},t.prototype._refreshRowDimensions=function(e){e.style.height=this._renderService.dimensions.actualCellHeight+"px"},t.prototype._announceCharacters=function(){0!==this._charsToAnnounce.length&&(this._liveRegion.textContent+=this._charsToAnnounce,this._charsToAnnounce="")},t}(l.Disposable);t.AccessibilityManager=f},3614:(e,t)=>{function r(e){return e.replace(/\r?\n/g,"\r")}function i(e,t){return t?"[200~"+e+"[201~":e}function n(e,t,n){e=i(e=r(e),n.decPrivateModes.bracketedPasteMode),n.triggerDataEvent(e,!0),t.value=""}function o(e,t,r){var i=r.getBoundingClientRect(),n=e.clientX-i.left-10,o=e.clientY-i.top-10;t.style.width="20px",t.style.height="20px",t.style.left=n+"px",t.style.top=o+"px",t.style.zIndex="1000",t.focus()}Object.defineProperty(t,"__esModule",{value:!0}),t.rightClickHandler=t.moveTextAreaUnderMouseCursor=t.paste=t.handlePasteEvent=t.copyHandler=t.bracketTextForPaste=t.prepareTextForTerminal=void 0,t.prepareTextForTerminal=r,t.bracketTextForPaste=i,t.copyHandler=function(e,t){e.clipboardData&&e.clipboardData.setData("text/plain",t.selectionText),e.preventDefault()},t.handlePasteEvent=function(e,t,r){e.stopPropagation(),e.clipboardData&&n(e.clipboardData.getData("text/plain"),t,r)},t.paste=n,t.moveTextAreaUnderMouseCursor=o,t.rightClickHandler=function(e,t,r,i,n){o(e,t,r),n&&i.rightClickSelect(e),t.value=i.selectionText,t.select()}},4774:(e,t)=>{var r,i,n,o;function s(e){var t=e.toString(16);return t.length<2?"0"+t:t}function a(e,t){return e<t?(t+.05)/(e+.05):(e+.05)/(t+.05)}Object.defineProperty(t,"__esModule",{value:!0}),t.contrastRatio=t.toPaddedHex=t.rgba=t.rgb=t.css=t.color=t.channels=void 0,function(e){e.toCss=function(e,t,r,i){return void 0!==i?"#"+s(e)+s(t)+s(r)+s(i):"#"+s(e)+s(t)+s(r)},e.toRgba=function(e,t,r,i){return void 0===i&&(i=255),(e<<24|t<<16|r<<8|i)>>>0}}(r=t.channels||(t.channels={})),(i=t.color||(t.color={})).blend=function(e,t){var i=(255&t.rgba)/255;if(1===i)return{css:t.css,rgba:t.rgba};var n=t.rgba>>24&255,o=t.rgba>>16&255,s=t.rgba>>8&255,a=e.rgba>>24&255,c=e.rgba>>16&255,l=e.rgba>>8&255,u=a+Math.round((n-a)*i),h=c+Math.round((o-c)*i),f=l+Math.round((s-l)*i);return{css:r.toCss(u,h,f),rgba:r.toRgba(u,h,f)}},i.isOpaque=function(e){return 255==(255&e.rgba)},i.ensureContrastRatio=function(e,t,r){var i=o.ensureContrastRatio(e.rgba,t.rgba,r);if(i)return o.toColor(i>>24&255,i>>16&255,i>>8&255)},i.opaque=function(e){var t=(255|e.rgba)>>>0,i=o.toChannels(t),n=i[0],s=i[1],a=i[2];return{css:r.toCss(n,s,a),rgba:t}},i.opacity=function(e,t){var i=Math.round(255*t),n=o.toChannels(e.rgba),s=n[0],a=n[1],c=n[2];return{css:r.toCss(s,a,c,i),rgba:r.toRgba(s,a,c,i)}},i.toColorRGB=function(e){return[e.rgba>>24&255,e.rgba>>16&255,e.rgba>>8&255]},(t.css||(t.css={})).toColor=function(e){switch(e.length){case 7:return{css:e,rgba:(parseInt(e.slice(1),16)<<8|255)>>>0};case 9:return{css:e,rgba:parseInt(e.slice(1),16)>>>0}}throw new Error("css.toColor: Unsupported css format")},function(e){function t(e,t,r){var i=e/255,n=t/255,o=r/255;return.2126*(i<=.03928?i/12.92:Math.pow((i+.055)/1.055,2.4))+.7152*(n<=.03928?n/12.92:Math.pow((n+.055)/1.055,2.4))+.0722*(o<=.03928?o/12.92:Math.pow((o+.055)/1.055,2.4))}e.relativeLuminance=function(e){return t(e>>16&255,e>>8&255,255&e)},e.relativeLuminance2=t}(n=t.rgb||(t.rgb={})),function(e){function t(e,t,r){for(var i=e>>24&255,o=e>>16&255,s=e>>8&255,c=t>>24&255,l=t>>16&255,u=t>>8&255,h=a(n.relativeLuminance2(c,u,l),n.relativeLuminance2(i,o,s));h<r&&(c>0||l>0||u>0);)c-=Math.max(0,Math.ceil(.1*c)),l-=Math.max(0,Math.ceil(.1*l)),u-=Math.max(0,Math.ceil(.1*u)),h=a(n.relativeLuminance2(c,u,l),n.relativeLuminance2(i,o,s));return(c<<24|l<<16|u<<8|255)>>>0}function i(e,t,r){for(var i=e>>24&255,o=e>>16&255,s=e>>8&255,c=t>>24&255,l=t>>16&255,u=t>>8&255,h=a(n.relativeLuminance2(c,u,l),n.relativeLuminance2(i,o,s));h<r&&(c<255||l<255||u<255);)c=Math.min(255,c+Math.ceil(.1*(255-c))),l=Math.min(255,l+Math.ceil(.1*(255-l))),u=Math.min(255,u+Math.ceil(.1*(255-u))),h=a(n.relativeLuminance2(c,u,l),n.relativeLuminance2(i,o,s));return(c<<24|l<<16|u<<8|255)>>>0}e.ensureContrastRatio=function(e,r,o){var s=n.relativeLuminance(e>>8),c=n.relativeLuminance(r>>8);if(a(s,c)<o)return c<s?t(e,r,o):i(e,r,o)},e.reduceLuminance=t,e.increaseLuminance=i,e.toChannels=function(e){return[e>>24&255,e>>16&255,e>>8&255,255&e]},e.toColor=function(e,t,i){return{css:r.toCss(e,t,i),rgba:r.toRgba(e,t,i)}}}(o=t.rgba||(t.rgba={})),t.toPaddedHex=s,t.contrastRatio=a},7239:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.ColorContrastCache=void 0;var r=function(){function e(){this._color={},this._rgba={}}return e.prototype.clear=function(){this._color={},this._rgba={}},e.prototype.setCss=function(e,t,r){this._rgba[e]||(this._rgba[e]={}),this._rgba[e][t]=r},e.prototype.getCss=function(e,t){return this._rgba[e]?this._rgba[e][t]:void 0},e.prototype.setColor=function(e,t,r){this._color[e]||(this._color[e]={}),this._color[e][t]=r},e.prototype.getColor=function(e,t){return this._color[e]?this._color[e][t]:void 0},e}();t.ColorContrastCache=r},5680:function(e,t,r){var i=this&&this.__spreadArray||function(e,t,r){if(r||2===arguments.length)for(var i,n=0,o=t.length;n<o;n++)!i&&n in t||(i||(i=Array.prototype.slice.call(t,0,n)),i[n]=t[n]);return e.concat(i||Array.prototype.slice.call(t))};Object.defineProperty(t,"__esModule",{value:!0}),t.ColorManager=t.DEFAULT_ANSI_COLORS=void 0;var n=r(4774),o=r(7239),s=n.css.toColor("#ffffff"),a=n.css.toColor("#000000"),c=n.css.toColor("#ffffff"),l=n.css.toColor("#000000"),u={css:"rgba(255, 255, 255, 0.3)",rgba:4294967117};t.DEFAULT_ANSI_COLORS=Object.freeze(function(){for(var e=[n.css.toColor("#2e3436"),n.css.toColor("#cc0000"),n.css.toColor("#4e9a06"),n.css.toColor("#c4a000"),n.css.toColor("#3465a4"),n.css.toColor("#75507b"),n.css.toColor("#06989a"),n.css.toColor("#d3d7cf"),n.css.toColor("#555753"),n.css.toColor("#ef2929"),n.css.toColor("#8ae234"),n.css.toColor("#fce94f"),n.css.toColor("#729fcf"),n.css.toColor("#ad7fa8"),n.css.toColor("#34e2e2"),n.css.toColor("#eeeeec")],t=[0,95,135,175,215,255],r=0;r<216;r++){var i=t[r/36%6|0],o=t[r/6%6|0],s=t[r%6];e.push({css:n.channels.toCss(i,o,s),rgba:n.channels.toRgba(i,o,s)})}for(r=0;r<24;r++){var a=8+10*r;e.push({css:n.channels.toCss(a,a,a),rgba:n.channels.toRgba(a,a,a)})}return e}());var h=function(){function e(e,r){this.allowTransparency=r;var i=e.createElement("canvas");i.width=1,i.height=1;var h=i.getContext("2d");if(!h)throw new Error("Could not get rendering context");this._ctx=h,this._ctx.globalCompositeOperation="copy",this._litmusColor=this._ctx.createLinearGradient(0,0,1,1),this._contrastCache=new o.ColorContrastCache,this.colors={foreground:s,background:a,cursor:c,cursorAccent:l,selectionTransparent:u,selectionOpaque:n.color.blend(a,u),ansi:t.DEFAULT_ANSI_COLORS.slice(),contrastCache:this._contrastCache},this._updateRestoreColors()}return e.prototype.onOptionsChange=function(e){"minimumContrastRatio"===e&&this._contrastCache.clear()},e.prototype.setTheme=function(e){void 0===e&&(e={}),this.colors.foreground=this._parseColor(e.foreground,s),this.colors.background=this._parseColor(e.background,a),this.colors.cursor=this._parseColor(e.cursor,c,!0),this.colors.cursorAccent=this._parseColor(e.cursorAccent,l,!0),this.colors.selectionTransparent=this._parseColor(e.selection,u,!0),this.colors.selectionOpaque=n.color.blend(this.colors.background,this.colors.selectionTransparent),n.color.isOpaque(this.colors.selectionTransparent)&&(this.colors.selectionTransparent=n.color.opacity(this.colors.selectionTransparent,.3)),this.colors.ansi[0]=this._parseColor(e.black,t.DEFAULT_ANSI_COLORS[0]),this.colors.ansi[1]=this._parseColor(e.red,t.DEFAULT_ANSI_COLORS[1]),this.colors.ansi[2]=this._parseColor(e.green,t.DEFAULT_ANSI_COLORS[2]),this.colors.ansi[3]=this._parseColor(e.yellow,t.DEFAULT_ANSI_COLORS[3]),this.colors.ansi[4]=this._parseColor(e.blue,t.DEFAULT_ANSI_COLORS[4]),this.colors.ansi[5]=this._parseColor(e.magenta,t.DEFAULT_ANSI_COLORS[5]),this.colors.ansi[6]=this._parseColor(e.cyan,t.DEFAULT_ANSI_COLORS[6]),this.colors.ansi[7]=this._parseColor(e.white,t.DEFAULT_ANSI_COLORS[7]),this.colors.ansi[8]=this._parseColor(e.brightBlack,t.DEFAULT_ANSI_COLORS[8]),this.colors.ansi[9]=this._parseColor(e.brightRed,t.DEFAULT_ANSI_COLORS[9]),this.colors.ansi[10]=this._parseColor(e.brightGreen,t.DEFAULT_ANSI_COLORS[10]),this.colors.ansi[11]=this._parseColor(e.brightYellow,t.DEFAULT_ANSI_COLORS[11]),this.colors.ansi[12]=this._parseColor(e.brightBlue,t.DEFAULT_ANSI_COLORS[12]),this.colors.ansi[13]=this._parseColor(e.brightMagenta,t.DEFAULT_ANSI_COLORS[13]),this.colors.ansi[14]=this._parseColor(e.brightCyan,t.DEFAULT_ANSI_COLORS[14]),this.colors.ansi[15]=this._parseColor(e.brightWhite,t.DEFAULT_ANSI_COLORS[15]),this._contrastCache.clear(),this._updateRestoreColors()},e.prototype.restoreColor=function(e){if(void 0!==e)switch(e){case 256:this.colors.foreground=this._restoreColors.foreground;break;case 257:this.colors.background=this._restoreColors.background;break;case 258:this.colors.cursor=this._restoreColors.cursor;break;default:this.colors.ansi[e]=this._restoreColors.ansi[e]}else for(var t=0;t<this._restoreColors.ansi.length;++t)this.colors.ansi[t]=this._restoreColors.ansi[t]},e.prototype._updateRestoreColors=function(){this._restoreColors={foreground:this.colors.foreground,background:this.colors.background,cursor:this.colors.cursor,ansi:i([],this.colors.ansi,!0)}},e.prototype._parseColor=function(e,t,r){if(void 0===r&&(r=this.allowTransparency),void 0===e)return t;if(this._ctx.fillStyle=this._litmusColor,this._ctx.fillStyle=e,"string"!=typeof this._ctx.fillStyle)return console.warn("Color: "+e+" is invalid using fallback "+t.css),t;this._ctx.fillRect(0,0,1,1);var i=this._ctx.getImageData(0,0,1,1).data;if(255!==i[3]){if(!r)return console.warn("Color: "+e+" is using transparency, but allowTransparency is false. Using fallback "+t.css+"."),t;var o=this._ctx.fillStyle.substring(5,this._ctx.fillStyle.length-1).split(",").map((function(e){return Number(e)})),s=o[0],a=o[1],c=o[2],l=o[3],u=Math.round(255*l);return{rgba:n.channels.toRgba(s,a,c,u),css:e}}return{css:this._ctx.fillStyle,rgba:n.channels.toRgba(i[0],i[1],i[2],i[3])}},e}();t.ColorManager=h},9631:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.removeElementFromParent=void 0,t.removeElementFromParent=function(){for(var e,t=[],r=0;r<arguments.length;r++)t[r]=arguments[r];for(var i=0,n=t;i<n.length;i++){var o=n[i];null===(e=null==o?void 0:o.parentElement)||void 0===e||e.removeChild(o)}}},3656:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.addDisposableDomListener=void 0,t.addDisposableDomListener=function(e,t,r,i){e.addEventListener(t,r,i);var n=!1;return{dispose:function(){n||(n=!0,e.removeEventListener(t,r,i))}}}},3551:function(e,t,r){var i=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},n=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.MouseZone=t.Linkifier=void 0;var o=r(8460),s=r(2585),a=function(){function e(e,t,r){this._bufferService=e,this._logService=t,this._unicodeService=r,this._linkMatchers=[],this._nextLinkMatcherId=0,this._onShowLinkUnderline=new o.EventEmitter,this._onHideLinkUnderline=new o.EventEmitter,this._onLinkTooltip=new o.EventEmitter,this._rowsToLinkify={start:void 0,end:void 0}}return Object.defineProperty(e.prototype,"onShowLinkUnderline",{get:function(){return this._onShowLinkUnderline.event},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"onHideLinkUnderline",{get:function(){return this._onHideLinkUnderline.event},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"onLinkTooltip",{get:function(){return this._onLinkTooltip.event},enumerable:!1,configurable:!0}),e.prototype.attachToDom=function(e,t){this._element=e,this._mouseZoneManager=t},e.prototype.linkifyRows=function(t,r){var i=this;this._mouseZoneManager&&(void 0===this._rowsToLinkify.start||void 0===this._rowsToLinkify.end?(this._rowsToLinkify.start=t,this._rowsToLinkify.end=r):(this._rowsToLinkify.start=Math.min(this._rowsToLinkify.start,t),this._rowsToLinkify.end=Math.max(this._rowsToLinkify.end,r)),this._mouseZoneManager.clearAll(t,r),this._rowsTimeoutId&&clearTimeout(this._rowsTimeoutId),this._rowsTimeoutId=setTimeout((function(){return i._linkifyRows()}),e._timeBeforeLatency))},e.prototype._linkifyRows=function(){this._rowsTimeoutId=void 0;var e=this._bufferService.buffer;if(void 0!==this._rowsToLinkify.start&&void 0!==this._rowsToLinkify.end){var t=e.ydisp+this._rowsToLinkify.start;if(!(t>=e.lines.length)){for(var r=e.ydisp+Math.min(this._rowsToLinkify.end,this._bufferService.rows)+1,i=Math.ceil(2e3/this._bufferService.cols),n=this._bufferService.buffer.iterator(!1,t,r,i,i);n.hasNext();)for(var o=n.next(),s=0;s<this._linkMatchers.length;s++)this._doLinkifyRow(o.range.first,o.content,this._linkMatchers[s]);this._rowsToLinkify.start=void 0,this._rowsToLinkify.end=void 0}}else this._logService.debug("_rowToLinkify was unset before _linkifyRows was called")},e.prototype.registerLinkMatcher=function(e,t,r){if(void 0===r&&(r={}),!t)throw new Error("handler must be defined");var i={id:this._nextLinkMatcherId++,regex:e,handler:t,matchIndex:r.matchIndex,validationCallback:r.validationCallback,hoverTooltipCallback:r.tooltipCallback,hoverLeaveCallback:r.leaveCallback,willLinkActivate:r.willLinkActivate,priority:r.priority||0};return this._addLinkMatcherToList(i),i.id},e.prototype._addLinkMatcherToList=function(e){if(0!==this._linkMatchers.length){for(var t=this._linkMatchers.length-1;t>=0;t--)if(e.priority<=this._linkMatchers[t].priority)return void this._linkMatchers.splice(t+1,0,e);this._linkMatchers.splice(0,0,e)}else this._linkMatchers.push(e)},e.prototype.deregisterLinkMatcher=function(e){for(var t=0;t<this._linkMatchers.length;t++)if(this._linkMatchers[t].id===e)return this._linkMatchers.splice(t,1),!0;return!1},e.prototype._doLinkifyRow=function(e,t,r){for(var i,n=this,o=new RegExp(r.regex.source,(r.regex.flags||"")+"g"),s=-1,a=function(){var a=i["number"!=typeof r.matchIndex?0:r.matchIndex];if(!a)return c._logService.debug("match found without corresponding matchIndex",i,r),"break";if(s=t.indexOf(a,s+1),o.lastIndex=s+a.length,s<0)return"break";var l=c._bufferService.buffer.stringIndexToBufferIndex(e,s);if(l[0]<0)return"break";var u=c._bufferService.buffer.lines.get(l[0]);if(!u)return"break";var h=u.getFg(l[1]),f=h?h>>9&511:void 0;r.validationCallback?r.validationCallback(a,(function(e){n._rowsTimeoutId||e&&n._addLink(l[1],l[0]-n._bufferService.buffer.ydisp,a,r,f)})):c._addLink(l[1],l[0]-c._bufferService.buffer.ydisp,a,r,f)},c=this;null!==(i=o.exec(t))&&"break"!==a(););},e.prototype._addLink=function(e,t,r,i,n){var o=this;if(this._mouseZoneManager&&this._element){var s=this._unicodeService.getStringCellWidth(r),a=e%this._bufferService.cols,l=t+Math.floor(e/this._bufferService.cols),u=(a+s)%this._bufferService.cols,h=l+Math.floor((a+s)/this._bufferService.cols);0===u&&(u=this._bufferService.cols,h--),this._mouseZoneManager.add(new c(a+1,l+1,u+1,h+1,(function(e){if(i.handler)return i.handler(e,r);var t=window.open();t?(t.opener=null,t.location.href=r):console.warn("Opening link blocked as opener could not be cleared")}),(function(){o._onShowLinkUnderline.fire(o._createLinkHoverEvent(a,l,u,h,n)),o._element.classList.add("xterm-cursor-pointer")}),(function(e){o._onLinkTooltip.fire(o._createLinkHoverEvent(a,l,u,h,n)),i.hoverTooltipCallback&&i.hoverTooltipCallback(e,r,{start:{x:a,y:l},end:{x:u,y:h}})}),(function(){o._onHideLinkUnderline.fire(o._createLinkHoverEvent(a,l,u,h,n)),o._element.classList.remove("xterm-cursor-pointer"),i.hoverLeaveCallback&&i.hoverLeaveCallback()}),(function(e){return!i.willLinkActivate||i.willLinkActivate(e,r)})))}},e.prototype._createLinkHoverEvent=function(e,t,r,i,n){return{x1:e,y1:t,x2:r,y2:i,cols:this._bufferService.cols,fg:n}},e._timeBeforeLatency=200,e=i([n(0,s.IBufferService),n(1,s.ILogService),n(2,s.IUnicodeService)],e)}();t.Linkifier=a;var c=function(e,t,r,i,n,o,s,a,c){this.x1=e,this.y1=t,this.x2=r,this.y2=i,this.clickCallback=n,this.hoverCallback=o,this.tooltipCallback=s,this.leaveCallback=a,this.willLinkActivate=c};t.MouseZone=c},6465:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)}),o=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},s=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.Linkifier2=void 0;var a=r(2585),c=r(8460),l=r(844),u=r(3656),h=function(e){function t(t){var r=e.call(this)||this;return r._bufferService=t,r._linkProviders=[],r._linkCacheDisposables=[],r._isMouseOut=!0,r._activeLine=-1,r._onShowLinkUnderline=r.register(new c.EventEmitter),r._onHideLinkUnderline=r.register(new c.EventEmitter),r.register((0,l.getDisposeArrayDisposable)(r._linkCacheDisposables)),r}return n(t,e),Object.defineProperty(t.prototype,"currentLink",{get:function(){return this._currentLink},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onShowLinkUnderline",{get:function(){return this._onShowLinkUnderline.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onHideLinkUnderline",{get:function(){return this._onHideLinkUnderline.event},enumerable:!1,configurable:!0}),t.prototype.registerLinkProvider=function(e){var t=this;return this._linkProviders.push(e),{dispose:function(){var r=t._linkProviders.indexOf(e);-1!==r&&t._linkProviders.splice(r,1)}}},t.prototype.attachToDom=function(e,t,r){var i=this;this._element=e,this._mouseService=t,this._renderService=r,this.register((0,u.addDisposableDomListener)(this._element,"mouseleave",(function(){i._isMouseOut=!0,i._clearCurrentLink()}))),this.register((0,u.addDisposableDomListener)(this._element,"mousemove",this._onMouseMove.bind(this))),this.register((0,u.addDisposableDomListener)(this._element,"click",this._onClick.bind(this)))},t.prototype._onMouseMove=function(e){if(this._lastMouseEvent=e,this._element&&this._mouseService){var t=this._positionFromMouseEvent(e,this._element,this._mouseService);if(t){this._isMouseOut=!1;for(var r=e.composedPath(),i=0;i<r.length;i++){var n=r[i];if(n.classList.contains("xterm"))break;if(n.classList.contains("xterm-hover"))return}this._lastBufferCell&&t.x===this._lastBufferCell.x&&t.y===this._lastBufferCell.y||(this._onHover(t),this._lastBufferCell=t)}}},t.prototype._onHover=function(e){if(this._activeLine!==e.y)return this._clearCurrentLink(),void this._askForLink(e,!1);this._currentLink&&this._linkAtPosition(this._currentLink.link,e)||(this._clearCurrentLink(),this._askForLink(e,!0))},t.prototype._askForLink=function(e,t){var r,i=this;this._activeProviderReplies&&t||(null===(r=this._activeProviderReplies)||void 0===r||r.forEach((function(e){null==e||e.forEach((function(e){e.link.dispose&&e.link.dispose()}))})),this._activeProviderReplies=new Map,this._activeLine=e.y);var n=!1;this._linkProviders.forEach((function(r,o){var s;t?(null===(s=i._activeProviderReplies)||void 0===s?void 0:s.get(o))&&(n=i._checkLinkProviderResult(o,e,n)):r.provideLinks(e.y,(function(t){var r,s;if(!i._isMouseOut){var a=null==t?void 0:t.map((function(e){return{link:e}}));null===(r=i._activeProviderReplies)||void 0===r||r.set(o,a),n=i._checkLinkProviderResult(o,e,n),(null===(s=i._activeProviderReplies)||void 0===s?void 0:s.size)===i._linkProviders.length&&i._removeIntersectingLinks(e.y,i._activeProviderReplies)}}))}))},t.prototype._removeIntersectingLinks=function(e,t){for(var r=new Set,i=0;i<t.size;i++){var n=t.get(i);if(n)for(var o=0;o<n.length;o++)for(var s=n[o],a=s.link.range.start.y<e?0:s.link.range.start.x,c=s.link.range.end.y>e?this._bufferService.cols:s.link.range.end.x,l=a;l<=c;l++){if(r.has(l)){n.splice(o--,1);break}r.add(l)}}},t.prototype._checkLinkProviderResult=function(e,t,r){var i,n=this;if(!this._activeProviderReplies)return r;for(var o=this._activeProviderReplies.get(e),s=!1,a=0;a<e;a++)this._activeProviderReplies.has(a)&&!this._activeProviderReplies.get(a)||(s=!0);if(!s&&o){var c=o.find((function(e){return n._linkAtPosition(e.link,t)}));c&&(r=!0,this._handleNewLink(c))}if(this._activeProviderReplies.size===this._linkProviders.length&&!r)for(a=0;a<this._activeProviderReplies.size;a++){var l=null===(i=this._activeProviderReplies.get(a))||void 0===i?void 0:i.find((function(e){return n._linkAtPosition(e.link,t)}));if(l){r=!0,this._handleNewLink(l);break}}return r},t.prototype._onClick=function(e){if(this._element&&this._mouseService&&this._currentLink){var t=this._positionFromMouseEvent(e,this._element,this._mouseService);t&&this._linkAtPosition(this._currentLink.link,t)&&this._currentLink.link.activate(e,this._currentLink.link.text)}},t.prototype._clearCurrentLink=function(e,t){this._element&&this._currentLink&&this._lastMouseEvent&&(!e||!t||this._currentLink.link.range.start.y>=e&&this._currentLink.link.range.end.y<=t)&&(this._linkLeave(this._element,this._currentLink.link,this._lastMouseEvent),this._currentLink=void 0,(0,l.disposeArray)(this._linkCacheDisposables))},t.prototype._handleNewLink=function(e){var t=this;if(this._element&&this._lastMouseEvent&&this._mouseService){var r=this._positionFromMouseEvent(this._lastMouseEvent,this._element,this._mouseService);r&&this._linkAtPosition(e.link,r)&&(this._currentLink=e,this._currentLink.state={decorations:{underline:void 0===e.link.decorations||e.link.decorations.underline,pointerCursor:void 0===e.link.decorations||e.link.decorations.pointerCursor},isHovered:!0},this._linkHover(this._element,e.link,this._lastMouseEvent),e.link.decorations={},Object.defineProperties(e.link.decorations,{pointerCursor:{get:function(){var e,r;return null===(r=null===(e=t._currentLink)||void 0===e?void 0:e.state)||void 0===r?void 0:r.decorations.pointerCursor},set:function(e){var r,i;(null===(r=t._currentLink)||void 0===r?void 0:r.state)&&t._currentLink.state.decorations.pointerCursor!==e&&(t._currentLink.state.decorations.pointerCursor=e,t._currentLink.state.isHovered&&(null===(i=t._element)||void 0===i||i.classList.toggle("xterm-cursor-pointer",e)))}},underline:{get:function(){var e,r;return null===(r=null===(e=t._currentLink)||void 0===e?void 0:e.state)||void 0===r?void 0:r.decorations.underline},set:function(r){var i,n,o;(null===(i=t._currentLink)||void 0===i?void 0:i.state)&&(null===(o=null===(n=t._currentLink)||void 0===n?void 0:n.state)||void 0===o?void 0:o.decorations.underline)!==r&&(t._currentLink.state.decorations.underline=r,t._currentLink.state.isHovered&&t._fireUnderlineEvent(e.link,r))}}}),this._renderService&&this._linkCacheDisposables.push(this._renderService.onRenderedBufferChange((function(e){var r=0===e.start?0:e.start+1+t._bufferService.buffer.ydisp;t._clearCurrentLink(r,e.end+1+t._bufferService.buffer.ydisp)}))))}},t.prototype._linkHover=function(e,t,r){var i;(null===(i=this._currentLink)||void 0===i?void 0:i.state)&&(this._currentLink.state.isHovered=!0,this._currentLink.state.decorations.underline&&this._fireUnderlineEvent(t,!0),this._currentLink.state.decorations.pointerCursor&&e.classList.add("xterm-cursor-pointer")),t.hover&&t.hover(r,t.text)},t.prototype._fireUnderlineEvent=function(e,t){var r=e.range,i=this._bufferService.buffer.ydisp,n=this._createLinkUnderlineEvent(r.start.x-1,r.start.y-i-1,r.end.x,r.end.y-i-1,void 0);(t?this._onShowLinkUnderline:this._onHideLinkUnderline).fire(n)},t.prototype._linkLeave=function(e,t,r){var i;(null===(i=this._currentLink)||void 0===i?void 0:i.state)&&(this._currentLink.state.isHovered=!1,this._currentLink.state.decorations.underline&&this._fireUnderlineEvent(t,!1),this._currentLink.state.decorations.pointerCursor&&e.classList.remove("xterm-cursor-pointer")),t.leave&&t.leave(r,t.text)},t.prototype._linkAtPosition=function(e,t){var r=e.range.start.y===e.range.end.y,i=e.range.start.y<t.y,n=e.range.end.y>t.y;return(r&&e.range.start.x<=t.x&&e.range.end.x>=t.x||i&&e.range.end.x>=t.x||n&&e.range.start.x<=t.x||i&&n)&&e.range.start.y<=t.y&&e.range.end.y>=t.y},t.prototype._positionFromMouseEvent=function(e,t,r){var i=r.getCoords(e,t,this._bufferService.cols,this._bufferService.rows);if(i)return{x:i[0],y:i[1]+this._bufferService.buffer.ydisp}},t.prototype._createLinkUnderlineEvent=function(e,t,r,i,n){return{x1:e,y1:t,x2:r,y2:i,cols:this._bufferService.cols,fg:n}},o([s(0,a.IBufferService)],t)}(l.Disposable);t.Linkifier2=h},9042:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.tooMuchOutput=t.promptLabel=void 0,t.promptLabel="Terminal input",t.tooMuchOutput="Too much output to announce, navigate to rows manually to read"},6954:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)}),o=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},s=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.MouseZoneManager=void 0;var a=r(844),c=r(3656),l=r(4725),u=r(2585),h=function(e){function t(t,r,i,n,o,s){var a=e.call(this)||this;return a._element=t,a._screenElement=r,a._bufferService=i,a._mouseService=n,a._selectionService=o,a._optionsService=s,a._zones=[],a._areZonesActive=!1,a._lastHoverCoords=[void 0,void 0],a._initialSelectionLength=0,a.register((0,c.addDisposableDomListener)(a._element,"mousedown",(function(e){return a._onMouseDown(e)}))),a._mouseMoveListener=function(e){return a._onMouseMove(e)},a._mouseLeaveListener=function(e){return a._onMouseLeave(e)},a._clickListener=function(e){return a._onClick(e)},a}return n(t,e),t.prototype.dispose=function(){e.prototype.dispose.call(this),this._deactivate()},t.prototype.add=function(e){this._zones.push(e),1===this._zones.length&&this._activate()},t.prototype.clearAll=function(e,t){if(0!==this._zones.length){e&&t||(e=0,t=this._bufferService.rows-1);for(var r=0;r<this._zones.length;r++){var i=this._zones[r];(i.y1>e&&i.y1<=t+1||i.y2>e&&i.y2<=t+1||i.y1<e&&i.y2>t+1)&&(this._currentZone&&this._currentZone===i&&(this._currentZone.leaveCallback(),this._currentZone=void 0),this._zones.splice(r--,1))}0===this._zones.length&&this._deactivate()}},t.prototype._activate=function(){this._areZonesActive||(this._areZonesActive=!0,this._element.addEventListener("mousemove",this._mouseMoveListener),this._element.addEventListener("mouseleave",this._mouseLeaveListener),this._element.addEventListener("click",this._clickListener))},t.prototype._deactivate=function(){this._areZonesActive&&(this._areZonesActive=!1,this._element.removeEventListener("mousemove",this._mouseMoveListener),this._element.removeEventListener("mouseleave",this._mouseLeaveListener),this._element.removeEventListener("click",this._clickListener))},t.prototype._onMouseMove=function(e){this._lastHoverCoords[0]===e.pageX&&this._lastHoverCoords[1]===e.pageY||(this._onHover(e),this._lastHoverCoords=[e.pageX,e.pageY])},t.prototype._onHover=function(e){var t=this,r=this._findZoneEventAt(e);r!==this._currentZone&&(this._currentZone&&(this._currentZone.leaveCallback(),this._currentZone=void 0,this._tooltipTimeout&&clearTimeout(this._tooltipTimeout)),r&&(this._currentZone=r,r.hoverCallback&&r.hoverCallback(e),this._tooltipTimeout=window.setTimeout((function(){return t._onTooltip(e)}),this._optionsService.options.linkTooltipHoverDuration)))},t.prototype._onTooltip=function(e){this._tooltipTimeout=void 0;var t=this._findZoneEventAt(e);null==t||t.tooltipCallback(e)},t.prototype._onMouseDown=function(e){if(this._initialSelectionLength=this._getSelectionLength(),this._areZonesActive){var t=this._findZoneEventAt(e);(null==t?void 0:t.willLinkActivate(e))&&(e.preventDefault(),e.stopImmediatePropagation())}},t.prototype._onMouseLeave=function(e){this._currentZone&&(this._currentZone.leaveCallback(),this._currentZone=void 0,this._tooltipTimeout&&clearTimeout(this._tooltipTimeout))},t.prototype._onClick=function(e){var t=this._findZoneEventAt(e),r=this._getSelectionLength();t&&r===this._initialSelectionLength&&(t.clickCallback(e),e.preventDefault(),e.stopImmediatePropagation())},t.prototype._getSelectionLength=function(){var e=this._selectionService.selectionText;return e?e.length:0},t.prototype._findZoneEventAt=function(e){var t=this._mouseService.getCoords(e,this._screenElement,this._bufferService.cols,this._bufferService.rows);if(t)for(var r=t[0],i=t[1],n=0;n<this._zones.length;n++){var o=this._zones[n];if(o.y1===o.y2){if(i===o.y1&&r>=o.x1&&r<o.x2)return o}else if(i===o.y1&&r>=o.x1||i===o.y2&&r<o.x2||i>o.y1&&i<o.y2)return o}},o([s(2,u.IBufferService),s(3,l.IMouseService),s(4,l.ISelectionService),s(5,u.IOptionsService)],t)}(a.Disposable);t.MouseZoneManager=h},6193:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.RenderDebouncer=void 0;var r=function(){function e(e){this._renderCallback=e}return e.prototype.dispose=function(){this._animationFrame&&(window.cancelAnimationFrame(this._animationFrame),this._animationFrame=void 0)},e.prototype.refresh=function(e,t,r){var i=this;this._rowCount=r,e=void 0!==e?e:0,t=void 0!==t?t:this._rowCount-1,this._rowStart=void 0!==this._rowStart?Math.min(this._rowStart,e):e,this._rowEnd=void 0!==this._rowEnd?Math.max(this._rowEnd,t):t,this._animationFrame||(this._animationFrame=window.requestAnimationFrame((function(){return i._innerRefresh()})))},e.prototype._innerRefresh=function(){if(void 0!==this._rowStart&&void 0!==this._rowEnd&&void 0!==this._rowCount){var e=Math.max(this._rowStart,0),t=Math.min(this._rowEnd,this._rowCount-1);this._rowStart=void 0,this._rowEnd=void 0,this._animationFrame=void 0,this._renderCallback(e,t)}},e}();t.RenderDebouncer=r},5596:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)});Object.defineProperty(t,"__esModule",{value:!0}),t.ScreenDprMonitor=void 0;var o=function(e){function t(){var t=null!==e&&e.apply(this,arguments)||this;return t._currentDevicePixelRatio=window.devicePixelRatio,t}return n(t,e),t.prototype.setListener=function(e){var t=this;this._listener&&this.clearListener(),this._listener=e,this._outerListener=function(){t._listener&&(t._listener(window.devicePixelRatio,t._currentDevicePixelRatio),t._updateDpr())},this._updateDpr()},t.prototype.dispose=function(){e.prototype.dispose.call(this),this.clearListener()},t.prototype._updateDpr=function(){var e;this._outerListener&&(null===(e=this._resolutionMediaMatchList)||void 0===e||e.removeListener(this._outerListener),this._currentDevicePixelRatio=window.devicePixelRatio,this._resolutionMediaMatchList=window.matchMedia("screen and (resolution: "+window.devicePixelRatio+"dppx)"),this._resolutionMediaMatchList.addListener(this._outerListener))},t.prototype.clearListener=function(){this._resolutionMediaMatchList&&this._listener&&this._outerListener&&(this._resolutionMediaMatchList.removeListener(this._outerListener),this._resolutionMediaMatchList=void 0,this._listener=void 0,this._outerListener=void 0)},t}(r(844).Disposable);t.ScreenDprMonitor=o},3236:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)});Object.defineProperty(t,"__esModule",{value:!0}),t.Terminal=void 0;var o=r(2950),s=r(1680),a=r(3614),c=r(2584),l=r(5435),u=r(3525),h=r(3551),f=r(9312),_=r(6114),d=r(3656),p=r(9042),v=r(357),g=r(6954),y=r(4567),m=r(1296),b=r(7399),S=r(8460),C=r(8437),w=r(5680),L=r(3230),E=r(4725),x=r(428),A=r(8934),k=r(6465),M=r(5114),R=r(8969),T=r(4774),O=r(4269),B=r(5941),D="undefined"!=typeof window?window.document:null,P=function(e){function t(t){void 0===t&&(t={});var r=e.call(this,t)||this;return r.browser=_,r._keyDownHandled=!1,r._keyPressHandled=!1,r._unprocessedDeadKey=!1,r._onCursorMove=new S.EventEmitter,r._onKey=new S.EventEmitter,r._onRender=new S.EventEmitter,r._onSelectionChange=new S.EventEmitter,r._onTitleChange=new S.EventEmitter,r._onBell=new S.EventEmitter,r._onFocus=new S.EventEmitter,r._onBlur=new S.EventEmitter,r._onA11yCharEmitter=new S.EventEmitter,r._onA11yTabEmitter=new S.EventEmitter,r._setup(),r.linkifier=r._instantiationService.createInstance(h.Linkifier),r.linkifier2=r.register(r._instantiationService.createInstance(k.Linkifier2)),r.register(r._inputHandler.onRequestBell((function(){return r.bell()}))),r.register(r._inputHandler.onRequestRefreshRows((function(e,t){return r.refresh(e,t)}))),r.register(r._inputHandler.onRequestSendFocus((function(){return r._reportFocus()}))),r.register(r._inputHandler.onRequestReset((function(){return r.reset()}))),r.register(r._inputHandler.onRequestWindowsOptionsReport((function(e){return r._reportWindowsOptions(e)}))),r.register(r._inputHandler.onColor((function(e){return r._handleColorEvent(e)}))),r.register((0,S.forwardEvent)(r._inputHandler.onCursorMove,r._onCursorMove)),r.register((0,S.forwardEvent)(r._inputHandler.onTitleChange,r._onTitleChange)),r.register((0,S.forwardEvent)(r._inputHandler.onA11yChar,r._onA11yCharEmitter)),r.register((0,S.forwardEvent)(r._inputHandler.onA11yTab,r._onA11yTabEmitter)),r.register(r._bufferService.onResize((function(e){return r._afterResize(e.cols,e.rows)}))),r}return n(t,e),Object.defineProperty(t.prototype,"onCursorMove",{get:function(){return this._onCursorMove.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onKey",{get:function(){return this._onKey.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onRender",{get:function(){return this._onRender.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onSelectionChange",{get:function(){return this._onSelectionChange.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onTitleChange",{get:function(){return this._onTitleChange.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onBell",{get:function(){return this._onBell.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onFocus",{get:function(){return this._onFocus.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onBlur",{get:function(){return this._onBlur.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onA11yChar",{get:function(){return this._onA11yCharEmitter.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onA11yTab",{get:function(){return this._onA11yTabEmitter.event},enumerable:!1,configurable:!0}),t.prototype._handleColorEvent=function(e){var t,r;if(this._colorManager){for(var i=0,n=e;i<n.length;i++){var o=n[i],s=void 0,a="";switch(o.index){case 256:s="foreground",a="10";break;case 257:s="background",a="11";break;case 258:s="cursor",a="12";break;default:s="ansi",a="4;"+o.index}if(s)switch(o.type){case 0:var l=T.color.toColorRGB("ansi"===s?this._colorManager.colors.ansi[o.index]:this._colorManager.colors[s]);this.coreService.triggerDataEvent(c.C0.ESC+"]"+a+";"+(0,B.toRgbString)(l)+c.C0.BEL);break;case 1:"ansi"===s?this._colorManager.colors.ansi[o.index]=T.rgba.toColor.apply(T.rgba,o.color):this._colorManager.colors[s]=T.rgba.toColor.apply(T.rgba,o.color);break;case 2:this._colorManager.restoreColor(o.index)}}null===(t=this._renderService)||void 0===t||t.setColors(this._colorManager.colors),null===(r=this.viewport)||void 0===r||r.onThemeChange(this._colorManager.colors)}},t.prototype.dispose=function(){var t,r,i;this._isDisposed||(e.prototype.dispose.call(this),null===(t=this._renderService)||void 0===t||t.dispose(),this._customKeyEventHandler=void 0,this.write=function(){},null===(i=null===(r=this.element)||void 0===r?void 0:r.parentNode)||void 0===i||i.removeChild(this.element))},t.prototype._setup=function(){e.prototype._setup.call(this),this._customKeyEventHandler=void 0},Object.defineProperty(t.prototype,"buffer",{get:function(){return this.buffers.active},enumerable:!1,configurable:!0}),t.prototype.focus=function(){this.textarea&&this.textarea.focus({preventScroll:!0})},t.prototype._updateOptions=function(t){var r,i,n,o;switch(e.prototype._updateOptions.call(this,t),t){case"fontFamily":case"fontSize":null===(r=this._renderService)||void 0===r||r.clear(),null===(i=this._charSizeService)||void 0===i||i.measure();break;case"cursorBlink":case"cursorStyle":this.refresh(this.buffer.y,this.buffer.y);break;case"customGlyphs":case"drawBoldTextInBrightColors":case"letterSpacing":case"lineHeight":case"fontWeight":case"fontWeightBold":case"minimumContrastRatio":this._renderService&&(this._renderService.clear(),this._renderService.onResize(this.cols,this.rows),this.refresh(0,this.rows-1));break;case"rendererType":this._renderService&&(this._renderService.setRenderer(this._createRenderer()),this._renderService.onResize(this.cols,this.rows));break;case"scrollback":null===(n=this.viewport)||void 0===n||n.syncScrollArea();break;case"screenReaderMode":this.optionsService.options.screenReaderMode?!this._accessibilityManager&&this._renderService&&(this._accessibilityManager=new y.AccessibilityManager(this,this._renderService)):(null===(o=this._accessibilityManager)||void 0===o||o.dispose(),this._accessibilityManager=void 0);break;case"tabStopWidth":this.buffers.setupTabStops();break;case"theme":this._setTheme(this.optionsService.options.theme)}},t.prototype._onTextAreaFocus=function(e){this.coreService.decPrivateModes.sendFocus&&this.coreService.triggerDataEvent(c.C0.ESC+"[I"),this.updateCursorStyle(e),this.element.classList.add("focus"),this._showCursor(),this._onFocus.fire()},t.prototype.blur=function(){var e;return null===(e=this.textarea)||void 0===e?void 0:e.blur()},t.prototype._onTextAreaBlur=function(){this.textarea.value="",this.refresh(this.buffer.y,this.buffer.y),this.coreService.decPrivateModes.sendFocus&&this.coreService.triggerDataEvent(c.C0.ESC+"[O"),this.element.classList.remove("focus"),this._onBlur.fire()},t.prototype._syncTextArea=function(){if(this.textarea&&this.buffer.isCursorInViewport&&!this._compositionHelper.isComposing&&this._renderService){var e=this.buffer.ybase+this.buffer.y,t=this.buffer.lines.get(e);if(t){var r=Math.min(this.buffer.x,this.cols-1),i=this._renderService.dimensions.actualCellHeight,n=t.getWidth(r),o=this._renderService.dimensions.actualCellWidth*n,s=this.buffer.y*this._renderService.dimensions.actualCellHeight,a=r*this._renderService.dimensions.actualCellWidth;this.textarea.style.left=a+"px",this.textarea.style.top=s+"px",this.textarea.style.width=o+"px",this.textarea.style.height=i+"px",this.textarea.style.lineHeight=i+"px",this.textarea.style.zIndex="-5"}}},t.prototype._initGlobal=function(){var e=this;this._bindKeys(),this.register((0,d.addDisposableDomListener)(this.element,"copy",(function(t){e.hasSelection()&&(0,a.copyHandler)(t,e._selectionService)})));var t=function(t){return(0,a.handlePasteEvent)(t,e.textarea,e.coreService)};this.register((0,d.addDisposableDomListener)(this.textarea,"paste",t)),this.register((0,d.addDisposableDomListener)(this.element,"paste",t)),_.isFirefox?this.register((0,d.addDisposableDomListener)(this.element,"mousedown",(function(t){2===t.button&&(0,a.rightClickHandler)(t,e.textarea,e.screenElement,e._selectionService,e.options.rightClickSelectsWord)}))):this.register((0,d.addDisposableDomListener)(this.element,"contextmenu",(function(t){(0,a.rightClickHandler)(t,e.textarea,e.screenElement,e._selectionService,e.options.rightClickSelectsWord)}))),_.isLinux&&this.register((0,d.addDisposableDomListener)(this.element,"auxclick",(function(t){1===t.button&&(0,a.moveTextAreaUnderMouseCursor)(t,e.textarea,e.screenElement)})))},t.prototype._bindKeys=function(){var e=this;this.register((0,d.addDisposableDomListener)(this.textarea,"keyup",(function(t){return e._keyUp(t)}),!0)),this.register((0,d.addDisposableDomListener)(this.textarea,"keydown",(function(t){return e._keyDown(t)}),!0)),this.register((0,d.addDisposableDomListener)(this.textarea,"keypress",(function(t){return e._keyPress(t)}),!0)),this.register((0,d.addDisposableDomListener)(this.textarea,"compositionstart",(function(){return e._compositionHelper.compositionstart()}))),this.register((0,d.addDisposableDomListener)(this.textarea,"compositionupdate",(function(t){return e._compositionHelper.compositionupdate(t)}))),this.register((0,d.addDisposableDomListener)(this.textarea,"compositionend",(function(){return e._compositionHelper.compositionend()}))),this.register((0,d.addDisposableDomListener)(this.textarea,"input",(function(t){return e._inputEvent(t)}),!0)),this.register(this.onRender((function(){return e._compositionHelper.updateCompositionElements()}))),this.register(this.onRender((function(t){return e._queueLinkification(t.start,t.end)})))},t.prototype.open=function(e){var t=this;if(!e)throw new Error("Terminal requires a parent element.");e.isConnected||this._logService.debug("Terminal.open was called on an element that was not attached to the DOM"),this._document=e.ownerDocument,this.element=this._document.createElement("div"),this.element.dir="ltr",this.element.classList.add("terminal"),this.element.classList.add("xterm"),this.element.setAttribute("tabindex","0"),e.appendChild(this.element);var r=D.createDocumentFragment();this._viewportElement=D.createElement("div"),this._viewportElement.classList.add("xterm-viewport"),r.appendChild(this._viewportElement),this._viewportScrollArea=D.createElement("div"),this._viewportScrollArea.classList.add("xterm-scroll-area"),this._viewportElement.appendChild(this._viewportScrollArea),this.screenElement=D.createElement("div"),this.screenElement.classList.add("xterm-screen"),this._helperContainer=D.createElement("div"),this._helperContainer.classList.add("xterm-helpers"),this.screenElement.appendChild(this._helperContainer),r.appendChild(this.screenElement),this.textarea=D.createElement("textarea"),this.textarea.classList.add("xterm-helper-textarea"),this.textarea.setAttribute("aria-label",p.promptLabel),this.textarea.setAttribute("aria-multiline","false"),this.textarea.setAttribute("autocorrect","off"),this.textarea.setAttribute("autocapitalize","off"),this.textarea.setAttribute("spellcheck","false"),this.textarea.tabIndex=0,this.register((0,d.addDisposableDomListener)(this.textarea,"focus",(function(e){return t._onTextAreaFocus(e)}))),this.register((0,d.addDisposableDomListener)(this.textarea,"blur",(function(){return t._onTextAreaBlur()}))),this._helperContainer.appendChild(this.textarea);var i=this._instantiationService.createInstance(M.CoreBrowserService,this.textarea);this._instantiationService.setService(E.ICoreBrowserService,i),this._charSizeService=this._instantiationService.createInstance(x.CharSizeService,this._document,this._helperContainer),this._instantiationService.setService(E.ICharSizeService,this._charSizeService),this._theme=this.options.theme||this._theme,this._colorManager=new w.ColorManager(D,this.options.allowTransparency),this.register(this.optionsService.onOptionChange((function(e){return t._colorManager.onOptionsChange(e)}))),this._colorManager.setTheme(this._theme),this._characterJoinerService=this._instantiationService.createInstance(O.CharacterJoinerService),this._instantiationService.setService(E.ICharacterJoinerService,this._characterJoinerService);var n=this._createRenderer();this._renderService=this.register(this._instantiationService.createInstance(L.RenderService,n,this.rows,this.screenElement)),this._instantiationService.setService(E.IRenderService,this._renderService),this.register(this._renderService.onRenderedBufferChange((function(e){return t._onRender.fire(e)}))),this.onResize((function(e){return t._renderService.resize(e.cols,e.rows)})),this._compositionView=D.createElement("div"),this._compositionView.classList.add("composition-view"),this._compositionHelper=this._instantiationService.createInstance(o.CompositionHelper,this.textarea,this._compositionView),this._helperContainer.appendChild(this._compositionView),this.element.appendChild(r),this._soundService=this._instantiationService.createInstance(v.SoundService),this._instantiationService.setService(E.ISoundService,this._soundService),this._mouseService=this._instantiationService.createInstance(A.MouseService),this._instantiationService.setService(E.IMouseService,this._mouseService),this.viewport=this._instantiationService.createInstance(s.Viewport,(function(e){return t.scrollLines(e,!0,1)}),this._viewportElement,this._viewportScrollArea,this.element),this.viewport.onThemeChange(this._colorManager.colors),this.register(this._inputHandler.onRequestSyncScrollBar((function(){return t.viewport.syncScrollArea()}))),this.register(this.viewport),this.register(this.onCursorMove((function(){t._renderService.onCursorMove(),t._syncTextArea()}))),this.register(this.onResize((function(){return t._renderService.onResize(t.cols,t.rows)}))),this.register(this.onBlur((function(){return t._renderService.onBlur()}))),this.register(this.onFocus((function(){return t._renderService.onFocus()}))),this.register(this._renderService.onDimensionsChange((function(){return t.viewport.syncScrollArea()}))),this._selectionService=this.register(this._instantiationService.createInstance(f.SelectionService,this.element,this.screenElement,this.linkifier2)),this._instantiationService.setService(E.ISelectionService,this._selectionService),this.register(this._selectionService.onRequestScrollLines((function(e){return t.scrollLines(e.amount,e.suppressScrollEvent)}))),this.register(this._selectionService.onSelectionChange((function(){return t._onSelectionChange.fire()}))),this.register(this._selectionService.onRequestRedraw((function(e){return t._renderService.onSelectionChanged(e.start,e.end,e.columnSelectMode)}))),this.register(this._selectionService.onLinuxMouseSelection((function(e){t.textarea.value=e,t.textarea.focus(),t.textarea.select()}))),this.register(this._onScroll.event((function(e){t.viewport.syncScrollArea(),t._selectionService.refresh()}))),this.register((0,d.addDisposableDomListener)(this._viewportElement,"scroll",(function(){return t._selectionService.refresh()}))),this._mouseZoneManager=this._instantiationService.createInstance(g.MouseZoneManager,this.element,this.screenElement),this.register(this._mouseZoneManager),this.register(this.onScroll((function(){return t._mouseZoneManager.clearAll()}))),this.linkifier.attachToDom(this.element,this._mouseZoneManager),this.linkifier2.attachToDom(this.screenElement,this._mouseService,this._renderService),this.register((0,d.addDisposableDomListener)(this.element,"mousedown",(function(e){return t._selectionService.onMouseDown(e)}))),this.coreMouseService.areMouseEventsActive?(this._selectionService.disable(),this.element.classList.add("enable-mouse-events")):this._selectionService.enable(),this.options.screenReaderMode&&(this._accessibilityManager=new y.AccessibilityManager(this,this._renderService)),this._charSizeService.measure(),this.refresh(0,this.rows-1),this._initGlobal(),this.bindMouse()},t.prototype._createRenderer=function(){switch(this.options.rendererType){case"canvas":return this._instantiationService.createInstance(u.Renderer,this._colorManager.colors,this.screenElement,this.linkifier,this.linkifier2);case"dom":return this._instantiationService.createInstance(m.DomRenderer,this._colorManager.colors,this.element,this.screenElement,this._viewportElement,this.linkifier,this.linkifier2);default:throw new Error('Unrecognized rendererType "'+this.options.rendererType+'"')}},t.prototype._setTheme=function(e){var t,r,i;this._theme=e,null===(t=this._colorManager)||void 0===t||t.setTheme(e),null===(r=this._renderService)||void 0===r||r.setColors(this._colorManager.colors),null===(i=this.viewport)||void 0===i||i.onThemeChange(this._colorManager.colors)},t.prototype.bindMouse=function(){var e=this,t=this,r=this.element;function i(e){var r,i,n=t._mouseService.getRawByteCoords(e,t.screenElement,t.cols,t.rows);if(!n)return!1;switch(e.overrideType||e.type){case"mousemove":i=32,void 0===e.buttons?(r=3,void 0!==e.button&&(r=e.button<3?e.button:3)):r=1&e.buttons?0:4&e.buttons?1:2&e.buttons?2:3;break;case"mouseup":i=0,r=e.button<3?e.button:3;break;case"mousedown":i=1,r=e.button<3?e.button:3;break;case"wheel":0!==e.deltaY&&(i=e.deltaY<0?0:1),r=4;break;default:return!1}return!(void 0===i||void 0===r||r>4)&&t.coreMouseService.triggerMouseEvent({col:n.x-33,row:n.y-33,button:r,action:i,ctrl:e.ctrlKey,alt:e.altKey,shift:e.shiftKey})}var n={mouseup:null,wheel:null,mousedrag:null,mousemove:null},o=function(t){return i(t),t.buttons||(e._document.removeEventListener("mouseup",n.mouseup),n.mousedrag&&e._document.removeEventListener("mousemove",n.mousedrag)),e.cancel(t)},s=function(t){return i(t),e.cancel(t,!0)},a=function(e){e.buttons&&i(e)},l=function(e){e.buttons||i(e)};this.register(this.coreMouseService.onProtocolChange((function(t){t?("debug"===e.optionsService.options.logLevel&&e._logService.debug("Binding to mouse events:",e.coreMouseService.explainEvents(t)),e.element.classList.add("enable-mouse-events"),e._selectionService.disable()):(e._logService.debug("Unbinding from mouse events."),e.element.classList.remove("enable-mouse-events"),e._selectionService.enable()),8&t?n.mousemove||(r.addEventListener("mousemove",l),n.mousemove=l):(r.removeEventListener("mousemove",n.mousemove),n.mousemove=null),16&t?n.wheel||(r.addEventListener("wheel",s,{passive:!1}),n.wheel=s):(r.removeEventListener("wheel",n.wheel),n.wheel=null),2&t?n.mouseup||(n.mouseup=o):(e._document.removeEventListener("mouseup",n.mouseup),n.mouseup=null),4&t?n.mousedrag||(n.mousedrag=a):(e._document.removeEventListener("mousemove",n.mousedrag),n.mousedrag=null)}))),this.coreMouseService.activeProtocol=this.coreMouseService.activeProtocol,this.register((0,d.addDisposableDomListener)(r,"mousedown",(function(t){if(t.preventDefault(),e.focus(),e.coreMouseService.areMouseEventsActive&&!e._selectionService.shouldForceSelection(t))return i(t),n.mouseup&&e._document.addEventListener("mouseup",n.mouseup),n.mousedrag&&e._document.addEventListener("mousemove",n.mousedrag),e.cancel(t)}))),this.register((0,d.addDisposableDomListener)(r,"wheel",(function(t){if(!n.wheel){if(!e.buffer.hasScrollback){var r=e.viewport.getLinesScrolled(t);if(0===r)return;for(var i=c.C0.ESC+(e.coreService.decPrivateModes.applicationCursorKeys?"O":"[")+(t.deltaY<0?"A":"B"),o="",s=0;s<Math.abs(r);s++)o+=i;return e.coreService.triggerDataEvent(o,!0),e.cancel(t,!0)}return e.viewport.onWheel(t)?e.cancel(t):void 0}}),{passive:!1})),this.register((0,d.addDisposableDomListener)(r,"touchstart",(function(t){if(!e.coreMouseService.areMouseEventsActive)return e.viewport.onTouchStart(t),e.cancel(t)}),{passive:!0})),this.register((0,d.addDisposableDomListener)(r,"touchmove",(function(t){if(!e.coreMouseService.areMouseEventsActive)return e.viewport.onTouchMove(t)?void 0:e.cancel(t)}),{passive:!1}))},t.prototype.refresh=function(e,t){var r;null===(r=this._renderService)||void 0===r||r.refreshRows(e,t)},t.prototype._queueLinkification=function(e,t){var r;null===(r=this.linkifier)||void 0===r||r.linkifyRows(e,t)},t.prototype.updateCursorStyle=function(e){var t;(null===(t=this._selectionService)||void 0===t?void 0:t.shouldColumnSelect(e))?this.element.classList.add("column-select"):this.element.classList.remove("column-select")},t.prototype._showCursor=function(){this.coreService.isCursorInitialized||(this.coreService.isCursorInitialized=!0,this.refresh(this.buffer.y,this.buffer.y))},t.prototype.scrollLines=function(t,r,i){void 0===i&&(i=0),e.prototype.scrollLines.call(this,t,r,i),this.refresh(0,this.rows-1)},t.prototype.paste=function(e){(0,a.paste)(e,this.textarea,this.coreService)},t.prototype.attachCustomKeyEventHandler=function(e){this._customKeyEventHandler=e},t.prototype.registerLinkMatcher=function(e,t,r){var i=this.linkifier.registerLinkMatcher(e,t,r);return this.refresh(0,this.rows-1),i},t.prototype.deregisterLinkMatcher=function(e){this.linkifier.deregisterLinkMatcher(e)&&this.refresh(0,this.rows-1)},t.prototype.registerLinkProvider=function(e){return this.linkifier2.registerLinkProvider(e)},t.prototype.registerCharacterJoiner=function(e){if(!this._characterJoinerService)throw new Error("Terminal must be opened first");var t=this._characterJoinerService.register(e);return this.refresh(0,this.rows-1),t},t.prototype.deregisterCharacterJoiner=function(e){if(!this._characterJoinerService)throw new Error("Terminal must be opened first");this._characterJoinerService.deregister(e)&&this.refresh(0,this.rows-1)},Object.defineProperty(t.prototype,"markers",{get:function(){return this.buffer.markers},enumerable:!1,configurable:!0}),t.prototype.addMarker=function(e){if(this.buffer===this.buffers.normal)return this.buffer.addMarker(this.buffer.ybase+this.buffer.y+e)},t.prototype.hasSelection=function(){return!!this._selectionService&&this._selectionService.hasSelection},t.prototype.select=function(e,t,r){this._selectionService.setSelection(e,t,r)},t.prototype.getSelection=function(){return this._selectionService?this._selectionService.selectionText:""},t.prototype.getSelectionPosition=function(){if(this._selectionService&&this._selectionService.hasSelection)return{startColumn:this._selectionService.selectionStart[0],startRow:this._selectionService.selectionStart[1],endColumn:this._selectionService.selectionEnd[0],endRow:this._selectionService.selectionEnd[1]}},t.prototype.clearSelection=function(){var e;null===(e=this._selectionService)||void 0===e||e.clearSelection()},t.prototype.selectAll=function(){var e;null===(e=this._selectionService)||void 0===e||e.selectAll()},t.prototype.selectLines=function(e,t){var r;null===(r=this._selectionService)||void 0===r||r.selectLines(e,t)},t.prototype._keyDown=function(e){if(this._keyDownHandled=!1,this._customKeyEventHandler&&!1===this._customKeyEventHandler(e))return!1;if(!this._compositionHelper.keydown(e))return this.buffer.ybase!==this.buffer.ydisp&&this._bufferService.scrollToBottom(),!1;"Dead"!==e.key&&"AltGraph"!==e.key||(this._unprocessedDeadKey=!0);var t=(0,b.evaluateKeyboardEvent)(e,this.coreService.decPrivateModes.applicationCursorKeys,this.browser.isMac,this.options.macOptionIsMeta);if(this.updateCursorStyle(e),3===t.type||2===t.type){var r=this.rows-1;return this.scrollLines(2===t.type?-r:r),this.cancel(e,!0)}return 1===t.type&&this.selectAll(),!!this._isThirdLevelShift(this.browser,e)||(t.cancel&&this.cancel(e,!0),!t.key||(this._unprocessedDeadKey?(this._unprocessedDeadKey=!1,!0):(t.key!==c.C0.ETX&&t.key!==c.C0.CR||(this.textarea.value=""),this._onKey.fire({key:t.key,domEvent:e}),this._showCursor(),this.coreService.triggerDataEvent(t.key,!0),this.optionsService.options.screenReaderMode?void(this._keyDownHandled=!0):this.cancel(e,!0))))},t.prototype._isThirdLevelShift=function(e,t){var r=e.isMac&&!this.options.macOptionIsMeta&&t.altKey&&!t.ctrlKey&&!t.metaKey||e.isWindows&&t.altKey&&t.ctrlKey&&!t.metaKey||e.isWindows&&t.getModifierState("AltGraph");return"keypress"===t.type?r:r&&(!t.keyCode||t.keyCode>47)},t.prototype._keyUp=function(e){this._customKeyEventHandler&&!1===this._customKeyEventHandler(e)||(function(e){return 16===e.keyCode||17===e.keyCode||18===e.keyCode}(e)||this.focus(),this.updateCursorStyle(e),this._keyPressHandled=!1)},t.prototype._keyPress=function(e){var t;if(this._keyPressHandled=!1,this._keyDownHandled)return!1;if(this._customKeyEventHandler&&!1===this._customKeyEventHandler(e))return!1;if(this.cancel(e),e.charCode)t=e.charCode;else if(null===e.which||void 0===e.which)t=e.keyCode;else{if(0===e.which||0===e.charCode)return!1;t=e.which}return!(!t||(e.altKey||e.ctrlKey||e.metaKey)&&!this._isThirdLevelShift(this.browser,e)||(t=String.fromCharCode(t),this._onKey.fire({key:t,domEvent:e}),this._showCursor(),this.coreService.triggerDataEvent(t,!0),this._keyPressHandled=!0,this._unprocessedDeadKey=!1,0))},t.prototype._inputEvent=function(e){if(e.data&&"insertText"===e.inputType&&!e.composed&&!this.optionsService.options.screenReaderMode){if(this._keyPressHandled)return!1;this._unprocessedDeadKey=!1;var t=e.data;return this.coreService.triggerDataEvent(t,!0),this.cancel(e),!0}return!1},t.prototype.bell=function(){var e;this._soundBell()&&(null===(e=this._soundService)||void 0===e||e.playBellSound()),this._onBell.fire()},t.prototype.resize=function(t,r){t!==this.cols||r!==this.rows?e.prototype.resize.call(this,t,r):this._charSizeService&&!this._charSizeService.hasValidSize&&this._charSizeService.measure()},t.prototype._afterResize=function(e,t){var r,i;null===(r=this._charSizeService)||void 0===r||r.measure(),null===(i=this.viewport)||void 0===i||i.syncScrollArea(!0)},t.prototype.clear=function(){if(0!==this.buffer.ybase||0!==this.buffer.y){this.buffer.lines.set(0,this.buffer.lines.get(this.buffer.ybase+this.buffer.y)),this.buffer.lines.length=1,this.buffer.ydisp=0,this.buffer.ybase=0,this.buffer.y=0;for(var e=1;e<this.rows;e++)this.buffer.lines.push(this.buffer.getBlankLine(C.DEFAULT_ATTR_DATA));this.refresh(0,this.rows-1),this._onScroll.fire({position:this.buffer.ydisp,source:0})}},t.prototype.reset=function(){var t,r;this.options.rows=this.rows,this.options.cols=this.cols;var i=this._customKeyEventHandler;this._setup(),e.prototype.reset.call(this),null===(t=this._selectionService)||void 0===t||t.reset(),this._customKeyEventHandler=i,this.refresh(0,this.rows-1),null===(r=this.viewport)||void 0===r||r.syncScrollArea()},t.prototype.clearTextureAtlas=function(){var e;null===(e=this._renderService)||void 0===e||e.clearTextureAtlas()},t.prototype._reportFocus=function(){var e;(null===(e=this.element)||void 0===e?void 0:e.classList.contains("focus"))?this.coreService.triggerDataEvent(c.C0.ESC+"[I"):this.coreService.triggerDataEvent(c.C0.ESC+"[O")},t.prototype._reportWindowsOptions=function(e){if(this._renderService)switch(e){case l.WindowsOptionsReportType.GET_WIN_SIZE_PIXELS:var t=this._renderService.dimensions.scaledCanvasWidth.toFixed(0),r=this._renderService.dimensions.scaledCanvasHeight.toFixed(0);this.coreService.triggerDataEvent(c.C0.ESC+"[4;"+r+";"+t+"t");break;case l.WindowsOptionsReportType.GET_CELL_SIZE_PIXELS:var i=this._renderService.dimensions.scaledCellWidth.toFixed(0),n=this._renderService.dimensions.scaledCellHeight.toFixed(0);this.coreService.triggerDataEvent(c.C0.ESC+"[6;"+n+";"+i+"t")}},t.prototype.cancel=function(e,t){if(this.options.cancelEvents||t)return e.preventDefault(),e.stopPropagation(),!1},t.prototype._visualBell=function(){return!1},t.prototype._soundBell=function(){return"sound"===this.options.bellStyle},t}(R.CoreTerminal);t.Terminal=P},9924:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.TimeBasedDebouncer=void 0;var r=function(){function e(e,t){void 0===t&&(t=1e3),this._renderCallback=e,this._debounceThresholdMS=t,this._lastRefreshMs=0,this._additionalRefreshRequested=!1}return e.prototype.dispose=function(){this._refreshTimeoutID&&clearTimeout(this._refreshTimeoutID)},e.prototype.refresh=function(e,t,r){var i=this;this._rowCount=r,e=void 0!==e?e:0,t=void 0!==t?t:this._rowCount-1,this._rowStart=void 0!==this._rowStart?Math.min(this._rowStart,e):e,this._rowEnd=void 0!==this._rowEnd?Math.max(this._rowEnd,t):t;var n=Date.now();if(n-this._lastRefreshMs>=this._debounceThresholdMS)this._lastRefreshMs=n,this._innerRefresh();else if(!this._additionalRefreshRequested){var o=n-this._lastRefreshMs,s=this._debounceThresholdMS-o;this._additionalRefreshRequested=!0,this._refreshTimeoutID=window.setTimeout((function(){i._lastRefreshMs=Date.now(),i._innerRefresh(),i._additionalRefreshRequested=!1,i._refreshTimeoutID=void 0}),s)}},e.prototype._innerRefresh=function(){if(void 0!==this._rowStart&&void 0!==this._rowEnd&&void 0!==this._rowCount){var e=Math.max(this._rowStart,0),t=Math.min(this._rowEnd,this._rowCount-1);this._rowStart=void 0,this._rowEnd=void 0,this._renderCallback(e,t)}},e}();t.TimeBasedDebouncer=r},1680:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)}),o=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},s=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.Viewport=void 0;var a=r(844),c=r(3656),l=r(4725),u=r(2585),h=function(e){function t(t,r,i,n,o,s,a,l){var u=e.call(this)||this;return u._scrollLines=t,u._viewportElement=r,u._scrollArea=i,u._element=n,u._bufferService=o,u._optionsService=s,u._charSizeService=a,u._renderService=l,u.scrollBarWidth=0,u._currentRowHeight=0,u._currentScaledCellHeight=0,u._lastRecordedBufferLength=0,u._lastRecordedViewportHeight=0,u._lastRecordedBufferHeight=0,u._lastTouchY=0,u._lastScrollTop=0,u._lastHadScrollBar=!1,u._wheelPartialScroll=0,u._refreshAnimationFrame=null,u._ignoreNextScrollEvent=!1,u.scrollBarWidth=u._viewportElement.offsetWidth-u._scrollArea.offsetWidth||15,u._lastHadScrollBar=!0,u.register((0,c.addDisposableDomListener)(u._viewportElement,"scroll",u._onScroll.bind(u))),u._activeBuffer=u._bufferService.buffer,u.register(u._bufferService.buffers.onBufferActivate((function(e){return u._activeBuffer=e.activeBuffer}))),u._renderDimensions=u._renderService.dimensions,u.register(u._renderService.onDimensionsChange((function(e){return u._renderDimensions=e}))),setTimeout((function(){return u.syncScrollArea()}),0),u}return n(t,e),t.prototype.onThemeChange=function(e){this._viewportElement.style.backgroundColor=e.background.css},t.prototype._refresh=function(e){var t=this;if(e)return this._innerRefresh(),void(null!==this._refreshAnimationFrame&&cancelAnimationFrame(this._refreshAnimationFrame));null===this._refreshAnimationFrame&&(this._refreshAnimationFrame=requestAnimationFrame((function(){return t._innerRefresh()})))},t.prototype._innerRefresh=function(){if(this._charSizeService.height>0){this._currentRowHeight=this._renderService.dimensions.scaledCellHeight/window.devicePixelRatio,this._currentScaledCellHeight=this._renderService.dimensions.scaledCellHeight,this._lastRecordedViewportHeight=this._viewportElement.offsetHeight;var e=Math.round(this._currentRowHeight*this._lastRecordedBufferLength)+(this._lastRecordedViewportHeight-this._renderService.dimensions.canvasHeight);this._lastRecordedBufferHeight!==e&&(this._lastRecordedBufferHeight=e,this._scrollArea.style.height=this._lastRecordedBufferHeight+"px")}var t=this._bufferService.buffer.ydisp*this._currentRowHeight;this._viewportElement.scrollTop!==t&&(this._ignoreNextScrollEvent=!0,this._viewportElement.scrollTop=t),0===this._optionsService.options.scrollback?this.scrollBarWidth=0:this.scrollBarWidth=this._viewportElement.offsetWidth-this._scrollArea.offsetWidth||15,this._lastHadScrollBar=this.scrollBarWidth>0;var r=window.getComputedStyle(this._element),i=parseInt(r.paddingLeft)+parseInt(r.paddingRight);this._viewportElement.style.width=(this._renderService.dimensions.actualCellWidth*this._bufferService.cols+this.scrollBarWidth+(this._lastHadScrollBar?i:0)).toString()+"px",this._refreshAnimationFrame=null},t.prototype.syncScrollArea=function(e){if(void 0===e&&(e=!1),this._lastRecordedBufferLength!==this._bufferService.buffer.lines.length)return this._lastRecordedBufferLength=this._bufferService.buffer.lines.length,void this._refresh(e);this._lastRecordedViewportHeight===this._renderService.dimensions.canvasHeight&&this._lastScrollTop===this._activeBuffer.ydisp*this._currentRowHeight&&this._renderDimensions.scaledCellHeight===this._currentScaledCellHeight?this._lastHadScrollBar!==this._optionsService.options.scrollback>0&&this._refresh(e):this._refresh(e)},t.prototype._onScroll=function(e){if(this._lastScrollTop=this._viewportElement.scrollTop,this._viewportElement.offsetParent){if(this._ignoreNextScrollEvent)return this._ignoreNextScrollEvent=!1,void this._scrollLines(0);var t=Math.round(this._lastScrollTop/this._currentRowHeight)-this._bufferService.buffer.ydisp;this._scrollLines(t)}},t.prototype._bubbleScroll=function(e,t){var r=this._viewportElement.scrollTop+this._lastRecordedViewportHeight;return!(t<0&&0!==this._viewportElement.scrollTop||t>0&&r<this._lastRecordedBufferHeight)||(e.cancelable&&e.preventDefault(),!1)},t.prototype.onWheel=function(e){var t=this._getPixelsScrolled(e);return 0!==t&&(this._viewportElement.scrollTop+=t,this._bubbleScroll(e,t))},t.prototype._getPixelsScrolled=function(e){if(0===e.deltaY||e.shiftKey)return 0;var t=this._applyScrollModifier(e.deltaY,e);return e.deltaMode===WheelEvent.DOM_DELTA_LINE?t*=this._currentRowHeight:e.deltaMode===WheelEvent.DOM_DELTA_PAGE&&(t*=this._currentRowHeight*this._bufferService.rows),t},t.prototype.getLinesScrolled=function(e){if(0===e.deltaY||e.shiftKey)return 0;var t=this._applyScrollModifier(e.deltaY,e);return e.deltaMode===WheelEvent.DOM_DELTA_PIXEL?(t/=this._currentRowHeight+0,this._wheelPartialScroll+=t,t=Math.floor(Math.abs(this._wheelPartialScroll))*(this._wheelPartialScroll>0?1:-1),this._wheelPartialScroll%=1):e.deltaMode===WheelEvent.DOM_DELTA_PAGE&&(t*=this._bufferService.rows),t},t.prototype._applyScrollModifier=function(e,t){var r=this._optionsService.options.fastScrollModifier;return"alt"===r&&t.altKey||"ctrl"===r&&t.ctrlKey||"shift"===r&&t.shiftKey?e*this._optionsService.options.fastScrollSensitivity*this._optionsService.options.scrollSensitivity:e*this._optionsService.options.scrollSensitivity},t.prototype.onTouchStart=function(e){this._lastTouchY=e.touches[0].pageY},t.prototype.onTouchMove=function(e){var t=this._lastTouchY-e.touches[0].pageY;return this._lastTouchY=e.touches[0].pageY,0!==t&&(this._viewportElement.scrollTop+=t,this._bubbleScroll(e,t))},o([s(4,u.IBufferService),s(5,u.IOptionsService),s(6,l.ICharSizeService),s(7,l.IRenderService)],t)}(a.Disposable);t.Viewport=h},2950:function(e,t,r){var i=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},n=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.CompositionHelper=void 0;var o=r(4725),s=r(2585),a=function(){function e(e,t,r,i,n,o){this._textarea=e,this._compositionView=t,this._bufferService=r,this._optionsService=i,this._coreService=n,this._renderService=o,this._isComposing=!1,this._isSendingComposition=!1,this._compositionPosition={start:0,end:0},this._dataAlreadySent=""}return Object.defineProperty(e.prototype,"isComposing",{get:function(){return this._isComposing},enumerable:!1,configurable:!0}),e.prototype.compositionstart=function(){this._isComposing=!0,this._compositionPosition.start=this._textarea.value.length,this._compositionView.textContent="",this._dataAlreadySent="",this._compositionView.classList.add("active")},e.prototype.compositionupdate=function(e){var t=this;this._compositionView.textContent=e.data,this.updateCompositionElements(),setTimeout((function(){t._compositionPosition.end=t._textarea.value.length}),0)},e.prototype.compositionend=function(){this._finalizeComposition(!0)},e.prototype.keydown=function(e){if(this._isComposing||this._isSendingComposition){if(229===e.keyCode)return!1;if(16===e.keyCode||17===e.keyCode||18===e.keyCode)return!1;this._finalizeComposition(!1)}return 229!==e.keyCode||(this._handleAnyTextareaChanges(),!1)},e.prototype._finalizeComposition=function(e){var t=this;if(this._compositionView.classList.remove("active"),this._isComposing=!1,e){var r={start:this._compositionPosition.start,end:this._compositionPosition.end};this._isSendingComposition=!0,setTimeout((function(){var e;t._isSendingComposition&&(t._isSendingComposition=!1,r.start+=t._dataAlreadySent.length,(e=t._isComposing?t._textarea.value.substring(r.start,r.end):t._textarea.value.substring(r.start)).length>0&&t._coreService.triggerDataEvent(e,!0))}),0)}else{this._isSendingComposition=!1;var i=this._textarea.value.substring(this._compositionPosition.start,this._compositionPosition.end);this._coreService.triggerDataEvent(i,!0)}},e.prototype._handleAnyTextareaChanges=function(){var e=this,t=this._textarea.value;setTimeout((function(){if(!e._isComposing){var r=e._textarea.value.replace(t,"");r.length>0&&(e._dataAlreadySent=r,e._coreService.triggerDataEvent(r,!0))}}),0)},e.prototype.updateCompositionElements=function(e){var t=this;if(this._isComposing){if(this._bufferService.buffer.isCursorInViewport){var r=Math.min(this._bufferService.buffer.x,this._bufferService.cols-1),i=this._renderService.dimensions.actualCellHeight,n=this._bufferService.buffer.y*this._renderService.dimensions.actualCellHeight,o=r*this._renderService.dimensions.actualCellWidth;this._compositionView.style.left=o+"px",this._compositionView.style.top=n+"px",this._compositionView.style.height=i+"px",this._compositionView.style.lineHeight=i+"px",this._compositionView.style.fontFamily=this._optionsService.options.fontFamily,this._compositionView.style.fontSize=this._optionsService.options.fontSize+"px";var s=this._compositionView.getBoundingClientRect();this._textarea.style.left=o+"px",this._textarea.style.top=n+"px",this._textarea.style.width=Math.max(s.width,1)+"px",this._textarea.style.height=Math.max(s.height,1)+"px",this._textarea.style.lineHeight=s.height+"px"}e||setTimeout((function(){return t.updateCompositionElements(!0)}),0)}},i([n(2,s.IBufferService),n(3,s.IOptionsService),n(4,s.ICoreService),n(5,o.IRenderService)],e)}();t.CompositionHelper=a},9806:(e,t)=>{function r(e,t){var r=t.getBoundingClientRect();return[e.clientX-r.left,e.clientY-r.top]}Object.defineProperty(t,"__esModule",{value:!0}),t.getRawByteCoords=t.getCoords=t.getCoordsRelativeToElement=void 0,t.getCoordsRelativeToElement=r,t.getCoords=function(e,t,i,n,o,s,a,c){if(o){var l=r(e,t);if(l)return l[0]=Math.ceil((l[0]+(c?s/2:0))/s),l[1]=Math.ceil(l[1]/a),l[0]=Math.min(Math.max(l[0],1),i+(c?1:0)),l[1]=Math.min(Math.max(l[1],1),n),l}},t.getRawByteCoords=function(e){if(e)return{x:e[0]+32,y:e[1]+32}}},9504:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.moveToCellSequence=void 0;var i=r(2584);function n(e,t,r,i){var n=e-o(r,e),a=t-o(r,t),u=Math.abs(n-a)-function(e,t,r){for(var i=0,n=e-o(r,e),a=t-o(r,t),c=0;c<Math.abs(n-a);c++){var l="A"===s(e,t)?-1:1,u=r.buffer.lines.get(n+l*c);(null==u?void 0:u.isWrapped)&&i++}return i}(e,t,r);return l(u,c(s(e,t),i))}function o(e,t){for(var r=0,i=e.buffer.lines.get(t),n=null==i?void 0:i.isWrapped;n&&t>=0&&t<e.rows;)r++,n=null==(i=e.buffer.lines.get(--t))?void 0:i.isWrapped;return r}function s(e,t){return e>t?"A":"B"}function a(e,t,r,i,n,o){for(var s=e,a=t,c="";s!==r||a!==i;)s+=n?1:-1,n&&s>o.cols-1?(c+=o.buffer.translateBufferLineToString(a,!1,e,s),s=0,e=0,a++):!n&&s<0&&(c+=o.buffer.translateBufferLineToString(a,!1,0,e+1),e=s=o.cols-1,a--);return c+o.buffer.translateBufferLineToString(a,!1,e,s)}function c(e,t){var r=t?"O":"[";return i.C0.ESC+r+e}function l(e,t){e=Math.floor(e);for(var r="",i=0;i<e;i++)r+=t;return r}t.moveToCellSequence=function(e,t,r,i){var s,u=r.buffer.x,h=r.buffer.y;if(!r.buffer.hasScrollback)return function(e,t,r,i,s,u){return 0===n(t,i,s,u).length?"":l(a(e,t,e,t-o(s,t),!1,s).length,c("D",u))}(u,h,0,t,r,i)+n(h,t,r,i)+function(e,t,r,i,s,u){var h;h=n(t,i,s,u).length>0?i-o(s,i):t;var f=i,_=function(e,t,r,i,s,a){var c;return c=n(r,i,s,a).length>0?i-o(s,i):t,e<r&&c<=i||e>=r&&c<i?"C":"D"}(e,t,r,i,s,u);return l(a(e,h,r,f,"C"===_,s).length,c(_,u))}(u,h,e,t,r,i);if(h===t)return s=u>e?"D":"C",l(Math.abs(u-e),c(s,i));s=h>t?"D":"C";var f=Math.abs(h-t);return l(function(e,t){return t.cols-e}(h>t?e:u,r)+(f-1)*r.cols+1+((h>t?u:e)-1),c(s,i))}},1546:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.BaseRenderLayer=void 0;var i=r(643),n=r(8803),o=r(1420),s=r(3734),a=r(1752),c=r(4774),l=r(9631),u=r(8978),h=function(){function e(e,t,r,i,n,o,s,a){this._container=e,this._alpha=i,this._colors=n,this._rendererId=o,this._bufferService=s,this._optionsService=a,this._scaledCharWidth=0,this._scaledCharHeight=0,this._scaledCellWidth=0,this._scaledCellHeight=0,this._scaledCharLeft=0,this._scaledCharTop=0,this._currentGlyphIdentifier={chars:"",code:0,bg:0,fg:0,bold:!1,dim:!1,italic:!1},this._canvas=document.createElement("canvas"),this._canvas.classList.add("xterm-"+t+"-layer"),this._canvas.style.zIndex=r.toString(),this._initCanvas(),this._container.appendChild(this._canvas)}return e.prototype.dispose=function(){var e;(0,l.removeElementFromParent)(this._canvas),null===(e=this._charAtlas)||void 0===e||e.dispose()},e.prototype._initCanvas=function(){this._ctx=(0,a.throwIfFalsy)(this._canvas.getContext("2d",{alpha:this._alpha})),this._alpha||this._clearAll()},e.prototype.onOptionsChanged=function(){},e.prototype.onBlur=function(){},e.prototype.onFocus=function(){},e.prototype.onCursorMove=function(){},e.prototype.onGridChanged=function(e,t){},e.prototype.onSelectionChanged=function(e,t,r){void 0===r&&(r=!1)},e.prototype.setColors=function(e){this._refreshCharAtlas(e)},e.prototype._setTransparency=function(e){if(e!==this._alpha){var t=this._canvas;this._alpha=e,this._canvas=this._canvas.cloneNode(),this._initCanvas(),this._container.replaceChild(this._canvas,t),this._refreshCharAtlas(this._colors),this.onGridChanged(0,this._bufferService.rows-1)}},e.prototype._refreshCharAtlas=function(e){this._scaledCharWidth<=0&&this._scaledCharHeight<=0||(this._charAtlas=(0,o.acquireCharAtlas)(this._optionsService.options,this._rendererId,e,this._scaledCharWidth,this._scaledCharHeight),this._charAtlas.warmUp())},e.prototype.resize=function(e){this._scaledCellWidth=e.scaledCellWidth,this._scaledCellHeight=e.scaledCellHeight,this._scaledCharWidth=e.scaledCharWidth,this._scaledCharHeight=e.scaledCharHeight,this._scaledCharLeft=e.scaledCharLeft,this._scaledCharTop=e.scaledCharTop,this._canvas.width=e.scaledCanvasWidth,this._canvas.height=e.scaledCanvasHeight,this._canvas.style.width=e.canvasWidth+"px",this._canvas.style.height=e.canvasHeight+"px",this._alpha||this._clearAll(),this._refreshCharAtlas(this._colors)},e.prototype.clearTextureAtlas=function(){var e;null===(e=this._charAtlas)||void 0===e||e.clear()},e.prototype._fillCells=function(e,t,r,i){this._ctx.fillRect(e*this._scaledCellWidth,t*this._scaledCellHeight,r*this._scaledCellWidth,i*this._scaledCellHeight)},e.prototype._fillMiddleLineAtCells=function(e,t,r){void 0===r&&(r=1);var i=Math.ceil(.5*this._scaledCellHeight);this._ctx.fillRect(e*this._scaledCellWidth,(t+1)*this._scaledCellHeight-i-window.devicePixelRatio,r*this._scaledCellWidth,window.devicePixelRatio)},e.prototype._fillBottomLineAtCells=function(e,t,r){void 0===r&&(r=1),this._ctx.fillRect(e*this._scaledCellWidth,(t+1)*this._scaledCellHeight-window.devicePixelRatio-1,r*this._scaledCellWidth,window.devicePixelRatio)},e.prototype._fillLeftLineAtCell=function(e,t,r){this._ctx.fillRect(e*this._scaledCellWidth,t*this._scaledCellHeight,window.devicePixelRatio*r,this._scaledCellHeight)},e.prototype._strokeRectAtCell=function(e,t,r,i){this._ctx.lineWidth=window.devicePixelRatio,this._ctx.strokeRect(e*this._scaledCellWidth+window.devicePixelRatio/2,t*this._scaledCellHeight+window.devicePixelRatio/2,r*this._scaledCellWidth-window.devicePixelRatio,i*this._scaledCellHeight-window.devicePixelRatio)},e.prototype._clearAll=function(){this._alpha?this._ctx.clearRect(0,0,this._canvas.width,this._canvas.height):(this._ctx.fillStyle=this._colors.background.css,this._ctx.fillRect(0,0,this._canvas.width,this._canvas.height))},e.prototype._clearCells=function(e,t,r,i){this._alpha?this._ctx.clearRect(e*this._scaledCellWidth,t*this._scaledCellHeight,r*this._scaledCellWidth,i*this._scaledCellHeight):(this._ctx.fillStyle=this._colors.background.css,this._ctx.fillRect(e*this._scaledCellWidth,t*this._scaledCellHeight,r*this._scaledCellWidth,i*this._scaledCellHeight))},e.prototype._fillCharTrueColor=function(e,t,r){this._ctx.font=this._getFont(!1,!1),this._ctx.textBaseline=n.TEXT_BASELINE,this._clipRow(r);var i=!1;!1!==this._optionsService.options.customGlyphs&&(i=(0,u.tryDrawCustomChar)(this._ctx,e.getChars(),t*this._scaledCellWidth,r*this._scaledCellHeight,this._scaledCellWidth,this._scaledCellHeight)),i||this._ctx.fillText(e.getChars(),t*this._scaledCellWidth+this._scaledCharLeft,r*this._scaledCellHeight+this._scaledCharTop+this._scaledCharHeight)},e.prototype._drawChars=function(e,t,r){var o,s,a,c=this._getContrastColor(e);c||e.isFgRGB()||e.isBgRGB()?this._drawUncachedChars(e,t,r,c):(e.isInverse()?(s=e.isBgDefault()?n.INVERTED_DEFAULT_COLOR:e.getBgColor(),a=e.isFgDefault()?n.INVERTED_DEFAULT_COLOR:e.getFgColor()):(a=e.isBgDefault()?i.DEFAULT_COLOR:e.getBgColor(),s=e.isFgDefault()?i.DEFAULT_COLOR:e.getFgColor()),s+=this._optionsService.options.drawBoldTextInBrightColors&&e.isBold()&&s<8?8:0,this._currentGlyphIdentifier.chars=e.getChars()||i.WHITESPACE_CELL_CHAR,this._currentGlyphIdentifier.code=e.getCode()||i.WHITESPACE_CELL_CODE,this._currentGlyphIdentifier.bg=a,this._currentGlyphIdentifier.fg=s,this._currentGlyphIdentifier.bold=!!e.isBold(),this._currentGlyphIdentifier.dim=!!e.isDim(),this._currentGlyphIdentifier.italic=!!e.isItalic(),(null===(o=this._charAtlas)||void 0===o?void 0:o.draw(this._ctx,this._currentGlyphIdentifier,t*this._scaledCellWidth+this._scaledCharLeft,r*this._scaledCellHeight+this._scaledCharTop))||this._drawUncachedChars(e,t,r))},e.prototype._drawUncachedChars=function(e,t,r,i){if(this._ctx.save(),this._ctx.font=this._getFont(!!e.isBold(),!!e.isItalic()),this._ctx.textBaseline=n.TEXT_BASELINE,e.isInverse())if(i)this._ctx.fillStyle=i.css;else if(e.isBgDefault())this._ctx.fillStyle=c.color.opaque(this._colors.background).css;else if(e.isBgRGB())this._ctx.fillStyle="rgb("+s.AttributeData.toColorRGB(e.getBgColor()).join(",")+")";else{var o=e.getBgColor();this._optionsService.options.drawBoldTextInBrightColors&&e.isBold()&&o<8&&(o+=8),this._ctx.fillStyle=this._colors.ansi[o].css}else if(i)this._ctx.fillStyle=i.css;else if(e.isFgDefault())this._ctx.fillStyle=this._colors.foreground.css;else if(e.isFgRGB())this._ctx.fillStyle="rgb("+s.AttributeData.toColorRGB(e.getFgColor()).join(",")+")";else{var a=e.getFgColor();this._optionsService.options.drawBoldTextInBrightColors&&e.isBold()&&a<8&&(a+=8),this._ctx.fillStyle=this._colors.ansi[a].css}this._clipRow(r),e.isDim()&&(this._ctx.globalAlpha=n.DIM_OPACITY);var l=!1;!1!==this._optionsService.options.customGlyphs&&(l=(0,u.tryDrawCustomChar)(this._ctx,e.getChars(),t*this._scaledCellWidth,r*this._scaledCellHeight,this._scaledCellWidth,this._scaledCellHeight)),l||this._ctx.fillText(e.getChars(),t*this._scaledCellWidth+this._scaledCharLeft,r*this._scaledCellHeight+this._scaledCharTop+this._scaledCharHeight),this._ctx.restore()},e.prototype._clipRow=function(e){this._ctx.beginPath(),this._ctx.rect(0,e*this._scaledCellHeight,this._bufferService.cols*this._scaledCellWidth,this._scaledCellHeight),this._ctx.clip()},e.prototype._getFont=function(e,t){return(t?"italic":"")+" "+(e?this._optionsService.options.fontWeightBold:this._optionsService.options.fontWeight)+" "+this._optionsService.options.fontSize*window.devicePixelRatio+"px "+this._optionsService.options.fontFamily},e.prototype._getContrastColor=function(e){if(1!==this._optionsService.options.minimumContrastRatio){var t=this._colors.contrastCache.getColor(e.bg,e.fg);if(void 0!==t)return t||void 0;var r=e.getFgColor(),i=e.getFgColorMode(),n=e.getBgColor(),o=e.getBgColorMode(),s=!!e.isInverse(),a=!!e.isInverse();if(s){var l=r;r=n,n=l;var u=i;i=o,o=u}var h=this._resolveBackgroundRgba(o,n,s),f=this._resolveForegroundRgba(i,r,s,a),_=c.rgba.ensureContrastRatio(h,f,this._optionsService.options.minimumContrastRatio);if(_){var d={css:c.channels.toCss(_>>24&255,_>>16&255,_>>8&255),rgba:_};return this._colors.contrastCache.setColor(e.bg,e.fg,d),d}this._colors.contrastCache.setColor(e.bg,e.fg,null)}},e.prototype._resolveBackgroundRgba=function(e,t,r){switch(e){case 16777216:case 33554432:return this._colors.ansi[t].rgba;case 50331648:return t<<8;default:return r?this._colors.foreground.rgba:this._colors.background.rgba}},e.prototype._resolveForegroundRgba=function(e,t,r,i){switch(e){case 16777216:case 33554432:return this._optionsService.options.drawBoldTextInBrightColors&&i&&t<8&&(t+=8),this._colors.ansi[t].rgba;case 50331648:return t<<8;default:return r?this._colors.background.rgba:this._colors.foreground.rgba}},e}();t.BaseRenderLayer=h},2512:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)}),o=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},s=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.CursorRenderLayer=void 0;var a=r(1546),c=r(511),l=r(2585),u=r(4725),h=600,f=function(e){function t(t,r,i,n,o,s,a,l,u){var h=e.call(this,t,"cursor",r,!0,i,n,s,a)||this;return h._onRequestRedraw=o,h._coreService=l,h._coreBrowserService=u,h._cell=new c.CellData,h._state={x:0,y:0,isFocused:!1,style:"",width:0},h._cursorRenderers={bar:h._renderBarCursor.bind(h),block:h._renderBlockCursor.bind(h),underline:h._renderUnderlineCursor.bind(h)},h}return n(t,e),t.prototype.dispose=function(){this._cursorBlinkStateManager&&(this._cursorBlinkStateManager.dispose(),this._cursorBlinkStateManager=void 0),e.prototype.dispose.call(this)},t.prototype.resize=function(t){e.prototype.resize.call(this,t),this._state={x:0,y:0,isFocused:!1,style:"",width:0}},t.prototype.reset=function(){var e;this._clearCursor(),null===(e=this._cursorBlinkStateManager)||void 0===e||e.restartBlinkAnimation(),this.onOptionsChanged()},t.prototype.onBlur=function(){var e;null===(e=this._cursorBlinkStateManager)||void 0===e||e.pause(),this._onRequestRedraw.fire({start:this._bufferService.buffer.y,end:this._bufferService.buffer.y})},t.prototype.onFocus=function(){var e;null===(e=this._cursorBlinkStateManager)||void 0===e||e.resume(),this._onRequestRedraw.fire({start:this._bufferService.buffer.y,end:this._bufferService.buffer.y})},t.prototype.onOptionsChanged=function(){var e,t=this;this._optionsService.options.cursorBlink?this._cursorBlinkStateManager||(this._cursorBlinkStateManager=new _(this._coreBrowserService.isFocused,(function(){t._render(!0)}))):(null===(e=this._cursorBlinkStateManager)||void 0===e||e.dispose(),this._cursorBlinkStateManager=void 0),this._onRequestRedraw.fire({start:this._bufferService.buffer.y,end:this._bufferService.buffer.y})},t.prototype.onCursorMove=function(){var e;null===(e=this._cursorBlinkStateManager)||void 0===e||e.restartBlinkAnimation()},t.prototype.onGridChanged=function(e,t){!this._cursorBlinkStateManager||this._cursorBlinkStateManager.isPaused?this._render(!1):this._cursorBlinkStateManager.restartBlinkAnimation()},t.prototype._render=function(e){if(this._coreService.isCursorInitialized&&!this._coreService.isCursorHidden){var t=this._bufferService.buffer.ybase+this._bufferService.buffer.y,r=t-this._bufferService.buffer.ydisp;if(r<0||r>=this._bufferService.rows)this._clearCursor();else{var i=Math.min(this._bufferService.buffer.x,this._bufferService.cols-1);if(this._bufferService.buffer.lines.get(t).loadCell(i,this._cell),void 0!==this._cell.content){if(!this._coreBrowserService.isFocused){this._clearCursor(),this._ctx.save(),this._ctx.fillStyle=this._colors.cursor.css;var n=this._optionsService.options.cursorStyle;return n&&"block"!==n?this._cursorRenderers[n](i,r,this._cell):this._renderBlurCursor(i,r,this._cell),this._ctx.restore(),this._state.x=i,this._state.y=r,this._state.isFocused=!1,this._state.style=n,void(this._state.width=this._cell.getWidth())}if(!this._cursorBlinkStateManager||this._cursorBlinkStateManager.isCursorVisible){if(this._state){if(this._state.x===i&&this._state.y===r&&this._state.isFocused===this._coreBrowserService.isFocused&&this._state.style===this._optionsService.options.cursorStyle&&this._state.width===this._cell.getWidth())return;this._clearCursor()}this._ctx.save(),this._cursorRenderers[this._optionsService.options.cursorStyle||"block"](i,r,this._cell),this._ctx.restore(),this._state.x=i,this._state.y=r,this._state.isFocused=!1,this._state.style=this._optionsService.options.cursorStyle,this._state.width=this._cell.getWidth()}else this._clearCursor()}}}else this._clearCursor()},t.prototype._clearCursor=function(){this._state&&(window.devicePixelRatio<1?this._clearAll():this._clearCells(this._state.x,this._state.y,this._state.width,1),this._state={x:0,y:0,isFocused:!1,style:"",width:0})},t.prototype._renderBarCursor=function(e,t,r){this._ctx.save(),this._ctx.fillStyle=this._colors.cursor.css,this._fillLeftLineAtCell(e,t,this._optionsService.options.cursorWidth),this._ctx.restore()},t.prototype._renderBlockCursor=function(e,t,r){this._ctx.save(),this._ctx.fillStyle=this._colors.cursor.css,this._fillCells(e,t,r.getWidth(),1),this._ctx.fillStyle=this._colors.cursorAccent.css,this._fillCharTrueColor(r,e,t),this._ctx.restore()},t.prototype._renderUnderlineCursor=function(e,t,r){this._ctx.save(),this._ctx.fillStyle=this._colors.cursor.css,this._fillBottomLineAtCells(e,t),this._ctx.restore()},t.prototype._renderBlurCursor=function(e,t,r){this._ctx.save(),this._ctx.strokeStyle=this._colors.cursor.css,this._strokeRectAtCell(e,t,r.getWidth(),1),this._ctx.restore()},o([s(5,l.IBufferService),s(6,l.IOptionsService),s(7,l.ICoreService),s(8,u.ICoreBrowserService)],t)}(a.BaseRenderLayer);t.CursorRenderLayer=f;var _=function(){function e(e,t){this._renderCallback=t,this.isCursorVisible=!0,e&&this._restartInterval()}return Object.defineProperty(e.prototype,"isPaused",{get:function(){return!(this._blinkStartTimeout||this._blinkInterval)},enumerable:!1,configurable:!0}),e.prototype.dispose=function(){this._blinkInterval&&(window.clearInterval(this._blinkInterval),this._blinkInterval=void 0),this._blinkStartTimeout&&(window.clearTimeout(this._blinkStartTimeout),this._blinkStartTimeout=void 0),this._animationFrame&&(window.cancelAnimationFrame(this._animationFrame),this._animationFrame=void 0)},e.prototype.restartBlinkAnimation=function(){var e=this;this.isPaused||(this._animationTimeRestarted=Date.now(),this.isCursorVisible=!0,this._animationFrame||(this._animationFrame=window.requestAnimationFrame((function(){e._renderCallback(),e._animationFrame=void 0}))))},e.prototype._restartInterval=function(e){var t=this;void 0===e&&(e=h),this._blinkInterval&&(window.clearInterval(this._blinkInterval),this._blinkInterval=void 0),this._blinkStartTimeout=window.setTimeout((function(){if(t._animationTimeRestarted){var e=h-(Date.now()-t._animationTimeRestarted);if(t._animationTimeRestarted=void 0,e>0)return void t._restartInterval(e)}t.isCursorVisible=!1,t._animationFrame=window.requestAnimationFrame((function(){t._renderCallback(),t._animationFrame=void 0})),t._blinkInterval=window.setInterval((function(){if(t._animationTimeRestarted){var e=h-(Date.now()-t._animationTimeRestarted);return t._animationTimeRestarted=void 0,void t._restartInterval(e)}t.isCursorVisible=!t.isCursorVisible,t._animationFrame=window.requestAnimationFrame((function(){t._renderCallback(),t._animationFrame=void 0}))}),h)}),e)},e.prototype.pause=function(){this.isCursorVisible=!0,this._blinkInterval&&(window.clearInterval(this._blinkInterval),this._blinkInterval=void 0),this._blinkStartTimeout&&(window.clearTimeout(this._blinkStartTimeout),this._blinkStartTimeout=void 0),this._animationFrame&&(window.cancelAnimationFrame(this._animationFrame),this._animationFrame=void 0)},e.prototype.resume=function(){this.pause(),this._animationTimeRestarted=void 0,this._restartInterval(),this.restartBlinkAnimation()},e}()},8978:(e,t,r)=>{var i,n,o,s,a,c,l,u,h,f,_,d,p,v,g,y,m,b,S,C,w,L,E,x,A,k,M,R,T,O,B,D,P,I,H,j,F,W,U,q,N,z,K,V,G,Y,X,Z,J,$,Q,ee,te,re,ie,ne,oe,se,ae,ce,le,ue,he,fe,_e,de,pe,ve,ge,ye,me,be,Se,Ce,we,Le,Ee,xe,Ae,ke,Me,Re,Te,Oe,Be,De,Pe,Ie,He,je,Fe,We,Ue,qe,Ne,ze,Ke,Ve,Ge,Ye,Xe,Ze,Je,$e,Qe,et,tt,rt,it,nt,ot,st,at,ct,lt,ut,ht,ft,_t,dt,pt,vt,gt,yt,mt,bt,St,Ct;Object.defineProperty(t,"__esModule",{value:!0}),t.tryDrawCustomChar=t.boxDrawingDefinitions=t.blockElementDefinitions=void 0;var wt=r(1752);t.blockElementDefinitions={"▀":[{x:0,y:0,w:8,h:4}],"▁":[{x:0,y:7,w:8,h:1}],"▂":[{x:0,y:6,w:8,h:2}],"▃":[{x:0,y:5,w:8,h:3}],"▄":[{x:0,y:4,w:8,h:4}],"▅":[{x:0,y:3,w:8,h:5}],"▆":[{x:0,y:2,w:8,h:6}],"▇":[{x:0,y:1,w:8,h:7}],"█":[{x:0,y:0,w:8,h:8}],"▉":[{x:0,y:0,w:7,h:8}],"▊":[{x:0,y:0,w:6,h:8}],"▋":[{x:0,y:0,w:5,h:8}],"▌":[{x:0,y:0,w:4,h:8}],"▍":[{x:0,y:0,w:3,h:8}],"▎":[{x:0,y:0,w:2,h:8}],"▏":[{x:0,y:0,w:1,h:8}],"▐":[{x:4,y:0,w:4,h:8}],"▔":[{x:0,y:0,w:9,h:1}],"▕":[{x:7,y:0,w:1,h:8}],"▖":[{x:0,y:4,w:4,h:4}],"▗":[{x:4,y:4,w:4,h:4}],"▘":[{x:0,y:0,w:4,h:4}],"▙":[{x:0,y:0,w:4,h:8},{x:0,y:4,w:8,h:4}],"▚":[{x:0,y:0,w:4,h:4},{x:4,y:4,w:4,h:4}],"▛":[{x:0,y:0,w:4,h:8},{x:0,y:0,w:4,h:8}],"▜":[{x:0,y:0,w:8,h:4},{x:4,y:0,w:4,h:8}],"▝":[{x:4,y:0,w:4,h:4}],"▞":[{x:4,y:0,w:4,h:4},{x:0,y:4,w:4,h:4}],"▟":[{x:4,y:0,w:4,h:8},{x:0,y:4,w:8,h:4}],"🭰":[{x:1,y:0,w:1,h:8}],"🭱":[{x:2,y:0,w:1,h:8}],"🭲":[{x:3,y:0,w:1,h:8}],"🭳":[{x:4,y:0,w:1,h:8}],"🭴":[{x:5,y:0,w:1,h:8}],"🭵":[{x:6,y:0,w:1,h:8}],"🭶":[{x:0,y:1,w:8,h:1}],"🭷":[{x:0,y:2,w:8,h:1}],"🭸":[{x:0,y:3,w:8,h:1}],"🭹":[{x:0,y:4,w:8,h:1}],"🭺":[{x:0,y:5,w:8,h:1}],"🭻":[{x:0,y:6,w:8,h:1}],"🭼":[{x:0,y:0,w:1,h:8},{x:0,y:7,w:8,h:1}],"🭽":[{x:0,y:0,w:1,h:8},{x:0,y:0,w:8,h:1}],"🭾":[{x:7,y:0,w:1,h:8},{x:0,y:0,w:8,h:1}],"🭿":[{x:7,y:0,w:1,h:8},{x:0,y:7,w:8,h:1}],"🮀":[{x:0,y:0,w:8,h:1},{x:0,y:7,w:8,h:1}],"🮁":[{x:0,y:0,w:8,h:1},{x:0,y:2,w:8,h:1},{x:0,y:4,w:8,h:1},{x:0,y:7,w:8,h:1}],"🮂":[{x:0,y:0,w:8,h:2}],"🮃":[{x:0,y:0,w:8,h:3}],"🮄":[{x:0,y:0,w:8,h:5}],"🮅":[{x:0,y:0,w:8,h:6}],"🮆":[{x:0,y:0,w:8,h:7}],"🮇":[{x:6,y:0,w:2,h:8}],"🮈":[{x:5,y:0,w:3,h:8}],"🮉":[{x:3,y:0,w:5,h:8}],"🮊":[{x:2,y:0,w:6,h:8}],"🮋":[{x:1,y:0,w:7,h:8}],"🮕":[{x:0,y:0,w:2,h:2},{x:4,y:0,w:2,h:2},{x:2,y:2,w:2,h:2},{x:6,y:2,w:2,h:2},{x:0,y:4,w:2,h:2},{x:4,y:4,w:2,h:2},{x:2,y:6,w:2,h:2},{x:6,y:6,w:2,h:2}],"🮖":[{x:2,y:0,w:2,h:2},{x:6,y:0,w:2,h:2},{x:0,y:2,w:2,h:2},{x:4,y:2,w:2,h:2},{x:2,y:4,w:2,h:2},{x:6,y:4,w:2,h:2},{x:0,y:6,w:2,h:2},{x:4,y:6,w:2,h:2}],"🮗":[{x:0,y:2,w:8,h:2},{x:0,y:6,w:8,h:2}]};var Lt={"░":[[1,0,0,0],[0,0,0,0],[0,0,1,0],[0,0,0,0]],"▒":[[1,0],[0,0],[0,1],[0,0]],"▓":[[0,1],[1,1],[1,0],[1,1]]};t.boxDrawingDefinitions={"─":(i={},i[1]="M0,.5 L1,.5",i),"━":(n={},n[3]="M0,.5 L1,.5",n),"│":(o={},o[1]="M.5,0 L.5,1",o),"┃":(s={},s[3]="M.5,0 L.5,1",s),"┌":(a={},a[1]="M0.5,1 L.5,.5 L1,.5",a),"┏":(c={},c[3]="M0.5,1 L.5,.5 L1,.5",c),"┐":(l={},l[1]="M0,.5 L.5,.5 L.5,1",l),"┓":(u={},u[3]="M0,.5 L.5,.5 L.5,1",u),"└":(h={},h[1]="M.5,0 L.5,.5 L1,.5",h),"┗":(f={},f[3]="M.5,0 L.5,.5 L1,.5",f),"┘":(_={},_[1]="M.5,0 L.5,.5 L0,.5",_),"┛":(d={},d[3]="M.5,0 L.5,.5 L0,.5",d),"├":(p={},p[1]="M.5,0 L.5,1 M.5,.5 L1,.5",p),"┣":(v={},v[3]="M.5,0 L.5,1 M.5,.5 L1,.5",v),"┤":(g={},g[1]="M.5,0 L.5,1 M.5,.5 L0,.5",g),"┫":(y={},y[3]="M.5,0 L.5,1 M.5,.5 L0,.5",y),"┬":(m={},m[1]="M0,.5 L1,.5 M.5,.5 L.5,1",m),"┳":(b={},b[3]="M0,.5 L1,.5 M.5,.5 L.5,1",b),"┴":(S={},S[1]="M0,.5 L1,.5 M.5,.5 L.5,0",S),"┻":(C={},C[3]="M0,.5 L1,.5 M.5,.5 L.5,0",C),"┼":(w={},w[1]="M0,.5 L1,.5 M.5,0 L.5,1",w),"╋":(L={},L[3]="M0,.5 L1,.5 M.5,0 L.5,1",L),"╴":(E={},E[1]="M.5,.5 L0,.5",E),"╸":(x={},x[3]="M.5,.5 L0,.5",x),"╵":(A={},A[1]="M.5,.5 L.5,0",A),"╹":(k={},k[3]="M.5,.5 L.5,0",k),"╶":(M={},M[1]="M.5,.5 L1,.5",M),"╺":(R={},R[3]="M.5,.5 L1,.5",R),"╷":(T={},T[1]="M.5,.5 L.5,1",T),"╻":(O={},O[3]="M.5,.5 L.5,1",O),"═":(B={},B[1]=function(e,t){return"M0,"+(.5-t)+" L1,"+(.5-t)+" M0,"+(.5+t)+" L1,"+(.5+t)},B),"║":(D={},D[1]=function(e,t){return"M"+(.5-e)+",0 L"+(.5-e)+",1 M"+(.5+e)+",0 L"+(.5+e)+",1"},D),"╒":(P={},P[1]=function(e,t){return"M.5,1 L.5,"+(.5-t)+" L1,"+(.5-t)+" M.5,"+(.5+t)+" L1,"+(.5+t)},P),"╓":(I={},I[1]=function(e,t){return"M"+(.5-e)+",1 L"+(.5-e)+",.5 L1,.5 M"+(.5+e)+",.5 L"+(.5+e)+",1"},I),"╔":(H={},H[1]=function(e,t){return"M1,"+(.5-t)+" L"+(.5-e)+","+(.5-t)+" L"+(.5-e)+",1 M1,"+(.5+t)+" L"+(.5+e)+","+(.5+t)+" L"+(.5+e)+",1"},H),"╕":(j={},j[1]=function(e,t){return"M0,"+(.5-t)+" L.5,"+(.5-t)+" L.5,1 M0,"+(.5+t)+" L.5,"+(.5+t)},j),"╖":(F={},F[1]=function(e,t){return"M"+(.5+e)+",1 L"+(.5+e)+",.5 L0,.5 M"+(.5-e)+",.5 L"+(.5-e)+",1"},F),"╗":(W={},W[1]=function(e,t){return"M0,"+(.5+t)+" L"+(.5-e)+","+(.5+t)+" L"+(.5-e)+",1 M0,"+(.5-t)+" L"+(.5+e)+","+(.5-t)+" L"+(.5+e)+",1"},W),"╘":(U={},U[1]=function(e,t){return"M.5,0 L.5,"+(.5+t)+" L1,"+(.5+t)+" M.5,"+(.5-t)+" L1,"+(.5-t)},U),"╙":(q={},q[1]=function(e,t){return"M1,.5 L"+(.5-e)+",.5 L"+(.5-e)+",0 M"+(.5+e)+",.5 L"+(.5+e)+",0"},q),"╚":(N={},N[1]=function(e,t){return"M1,"+(.5-t)+" L"+(.5+e)+","+(.5-t)+" L"+(.5+e)+",0 M1,"+(.5+t)+" L"+(.5-e)+","+(.5+t)+" L"+(.5-e)+",0"},N),"╛":(z={},z[1]=function(e,t){return"M0,"+(.5+t)+" L.5,"+(.5+t)+" L.5,0 M0,"+(.5-t)+" L.5,"+(.5-t)},z),"╜":(K={},K[1]=function(e,t){return"M0,.5 L"+(.5+e)+",.5 L"+(.5+e)+",0 M"+(.5-e)+",.5 L"+(.5-e)+",0"},K),"╝":(V={},V[1]=function(e,t){return"M0,"+(.5-t)+" L"+(.5-e)+","+(.5-t)+" L"+(.5-e)+",0 M0,"+(.5+t)+" L"+(.5+e)+","+(.5+t)+" L"+(.5+e)+",0"},V),"╞":(G={},G[1]=function(e,t){return"M.5,0 L.5,1 M.5,"+(.5-t)+" L1,"+(.5-t)+" M.5,"+(.5+t)+" L1,"+(.5+t)},G),"╟":(Y={},Y[1]=function(e,t){return"M"+(.5-e)+",0 L"+(.5-e)+",1 M"+(.5+e)+",0 L"+(.5+e)+",1 M"+(.5+e)+",.5 L1,.5"},Y),"╠":(X={},X[1]=function(e,t){return"M"+(.5-e)+",0 L"+(.5-e)+",1 M1,"+(.5+t)+" L"+(.5+e)+","+(.5+t)+" L"+(.5+e)+",1 M1,"+(.5-t)+" L"+(.5+e)+","+(.5-t)+" L"+(.5+e)+",0"},X),"╡":(Z={},Z[1]=function(e,t){return"M.5,0 L.5,1 M0,"+(.5-t)+" L.5,"+(.5-t)+" M0,"+(.5+t)+" L.5,"+(.5+t)},Z),"╢":(J={},J[1]=function(e,t){return"M0,.5 L"+(.5-e)+",.5 M"+(.5-e)+",0 L"+(.5-e)+",1 M"+(.5+e)+",0 L"+(.5+e)+",1"},J),"╣":($={},$[1]=function(e,t){return"M"+(.5+e)+",0 L"+(.5+e)+",1 M0,"+(.5+t)+" L"+(.5-e)+","+(.5+t)+" L"+(.5-e)+",1 M0,"+(.5-t)+" L"+(.5-e)+","+(.5-t)+" L"+(.5-e)+",0"},$),"╤":(Q={},Q[1]=function(e,t){return"M0,"+(.5-t)+" L1,"+(.5-t)+" M0,"+(.5+t)+" L1,"+(.5+t)+" M.5,"+(.5+t)+" L.5,1"},Q),"╥":(ee={},ee[1]=function(e,t){return"M0,.5 L1,.5 M"+(.5-e)+",.5 L"+(.5-e)+",1 M"+(.5+e)+",.5 L"+(.5+e)+",1"},ee),"╦":(te={},te[1]=function(e,t){return"M0,"+(.5-t)+" L1,"+(.5-t)+" M0,"+(.5+t)+" L"+(.5-e)+","+(.5+t)+" L"+(.5-e)+",1 M1,"+(.5+t)+" L"+(.5+e)+","+(.5+t)+" L"+(.5+e)+",1"},te),"╧":(re={},re[1]=function(e,t){return"M.5,0 L.5,"+(.5-t)+" M0,"+(.5-t)+" L1,"+(.5-t)+" M0,"+(.5+t)+" L1,"+(.5+t)},re),"╨":(ie={},ie[1]=function(e,t){return"M0,.5 L1,.5 M"+(.5-e)+",.5 L"+(.5-e)+",0 M"+(.5+e)+",.5 L"+(.5+e)+",0"},ie),"╩":(ne={},ne[1]=function(e,t){return"M0,"+(.5+t)+" L1,"+(.5+t)+" M0,"+(.5-t)+" L"+(.5-e)+","+(.5-t)+" L"+(.5-e)+",0 M1,"+(.5-t)+" L"+(.5+e)+","+(.5-t)+" L"+(.5+e)+",0"},ne),"╪":(oe={},oe[1]=function(e,t){return"M.5,0 L.5,1 M0,"+(.5-t)+" L1,"+(.5-t)+" M0,"+(.5+t)+" L1,"+(.5+t)},oe),"╫":(se={},se[1]=function(e,t){return"M0,.5 L1,.5 M"+(.5-e)+",0 L"+(.5-e)+",1 M"+(.5+e)+",0 L"+(.5+e)+",1"},se),"╬":(ae={},ae[1]=function(e,t){return"M0,"+(.5+t)+" L"+(.5-e)+","+(.5+t)+" L"+(.5-e)+",1 M1,"+(.5+t)+" L"+(.5+e)+","+(.5+t)+" L"+(.5+e)+",1 M0,"+(.5-t)+" L"+(.5-e)+","+(.5-t)+" L"+(.5-e)+",0 M1,"+(.5-t)+" L"+(.5+e)+","+(.5-t)+" L"+(.5+e)+",0"},ae),"╱":(ce={},ce[1]="M1,0 L0,1",ce),"╲":(le={},le[1]="M0,0 L1,1",le),"╳":(ue={},ue[1]="M1,0 L0,1 M0,0 L1,1",ue),"╼":(he={},he[1]="M.5,.5 L0,.5",he[3]="M.5,.5 L1,.5",he),"╽":(fe={},fe[1]="M.5,.5 L.5,0",fe[3]="M.5,.5 L.5,1",fe),"╾":(_e={},_e[1]="M.5,.5 L1,.5",_e[3]="M.5,.5 L0,.5",_e),"╿":(de={},de[1]="M.5,.5 L.5,1",de[3]="M.5,.5 L.5,0",de),"┍":(pe={},pe[1]="M.5,.5 L.5,1",pe[3]="M.5,.5 L1,.5",pe),"┎":(ve={},ve[1]="M.5,.5 L1,.5",ve[3]="M.5,.5 L.5,1",ve),"┑":(ge={},ge[1]="M.5,.5 L.5,1",ge[3]="M.5,.5 L0,.5",ge),"┒":(ye={},ye[1]="M.5,.5 L0,.5",ye[3]="M.5,.5 L.5,1",ye),"┕":(me={},me[1]="M.5,.5 L.5,0",me[3]="M.5,.5 L1,.5",me),"┖":(be={},be[1]="M.5,.5 L1,.5",be[3]="M.5,.5 L.5,0",be),"┙":(Se={},Se[1]="M.5,.5 L.5,0",Se[3]="M.5,.5 L0,.5",Se),"┚":(Ce={},Ce[1]="M.5,.5 L0,.5",Ce[3]="M.5,.5 L.5,0",Ce),"┝":(we={},we[1]="M.5,0 L.5,1",we[3]="M.5,.5 L1,.5",we),"┞":(Le={},Le[1]="M0.5,1 L.5,.5 L1,.5",Le[3]="M.5,.5 L.5,0",Le),"┟":(Ee={},Ee[1]="M.5,0 L.5,.5 L1,.5",Ee[3]="M.5,.5 L.5,1",Ee),"┠":(xe={},xe[1]="M.5,.5 L1,.5",xe[3]="M.5,0 L.5,1",xe),"┡":(Ae={},Ae[1]="M.5,.5 L.5,1",Ae[3]="M.5,0 L.5,.5 L1,.5",Ae),"┢":(ke={},ke[1]="M.5,.5 L.5,0",ke[3]="M0.5,1 L.5,.5 L1,.5",ke),"┥":(Me={},Me[1]="M.5,0 L.5,1",Me[3]="M.5,.5 L0,.5",Me),"┦":(Re={},Re[1]="M0,.5 L.5,.5 L.5,1",Re[3]="M.5,.5 L.5,0",Re),"┧":(Te={},Te[1]="M.5,0 L.5,.5 L0,.5",Te[3]="M.5,.5 L.5,1",Te),"┨":(Oe={},Oe[1]="M.5,.5 L0,.5",Oe[3]="M.5,0 L.5,1",Oe),"┩":(Be={},Be[1]="M.5,.5 L.5,1",Be[3]="M.5,0 L.5,.5 L0,.5",Be),"┪":(De={},De[1]="M.5,.5 L.5,0",De[3]="M0,.5 L.5,.5 L.5,1",De),"┭":(Pe={},Pe[1]="M0.5,1 L.5,.5 L1,.5",Pe[3]="M.5,.5 L0,.5",Pe),"┮":(Ie={},Ie[1]="M0,.5 L.5,.5 L.5,1",Ie[3]="M.5,.5 L1,.5",Ie),"┯":(He={},He[1]="M.5,.5 L.5,1",He[3]="M0,.5 L1,.5",He),"┰":(je={},je[1]="M0,.5 L1,.5",je[3]="M.5,.5 L.5,1",je),"┱":(Fe={},Fe[1]="M.5,.5 L1,.5",Fe[3]="M0,.5 L.5,.5 L.5,1",Fe),"┲":(We={},We[1]="M.5,.5 L0,.5",We[3]="M0.5,1 L.5,.5 L1,.5",We),"┵":(Ue={},Ue[1]="M.5,0 L.5,.5 L1,.5",Ue[3]="M.5,.5 L0,.5",Ue),"┶":(qe={},qe[1]="M.5,0 L.5,.5 L0,.5",qe[3]="M.5,.5 L1,.5",qe),"┷":(Ne={},Ne[1]="M.5,.5 L.5,0",Ne[3]="M0,.5 L1,.5",Ne),"┸":(ze={},ze[1]="M0,.5 L1,.5",ze[3]="M.5,.5 L.5,0",ze),"┹":(Ke={},Ke[1]="M.5,.5 L1,.5",Ke[3]="M.5,0 L.5,.5 L0,.5",Ke),"┺":(Ve={},Ve[1]="M.5,.5 L0,.5",Ve[3]="M.5,0 L.5,.5 L1,.5",Ve),"┽":(Ge={},Ge[1]="M.5,0 L.5,1 M.5,.5 L1,.5",Ge[3]="M.5,.5 L0,.5",Ge),"┾":(Ye={},Ye[1]="M.5,0 L.5,1 M.5,.5 L0,.5",Ye[3]="M.5,.5 L1,.5",Ye),"┿":(Xe={},Xe[1]="M.5,0 L.5,1",Xe[3]="M0,.5 L1,.5",Xe),"╀":(Ze={},Ze[1]="M0,.5 L1,.5 M.5,.5 L.5,1",Ze[3]="M.5,.5 L.5,0",Ze),"╁":(Je={},Je[1]="M.5,.5 L.5,0 M0,.5 L1,.5",Je[3]="M.5,.5 L.5,1",Je),"╂":($e={},$e[1]="M0,.5 L1,.5",$e[3]="M.5,0 L.5,1",$e),"╃":(Qe={},Qe[1]="M0.5,1 L.5,.5 L1,.5",Qe[3]="M.5,0 L.5,.5 L0,.5",Qe),"╄":(et={},et[1]="M0,.5 L.5,.5 L.5,1",et[3]="M.5,0 L.5,.5 L1,.5",et),"╅":(tt={},tt[1]="M.5,0 L.5,.5 L1,.5",tt[3]="M0,.5 L.5,.5 L.5,1",tt),"╆":(rt={},rt[1]="M.5,0 L.5,.5 L0,.5",rt[3]="M0.5,1 L.5,.5 L1,.5",rt),"╇":(it={},it[1]="M.5,.5 L.5,1",it[3]="M.5,.5 L.5,0 M0,.5 L1,.5",it),"╈":(nt={},nt[1]="M.5,.5 L.5,0",nt[3]="M0,.5 L1,.5 M.5,.5 L.5,1",nt),"╉":(ot={},ot[1]="M.5,.5 L1,.5",ot[3]="M.5,0 L.5,1 M.5,.5 L0,.5",ot),"╊":(st={},st[1]="M.5,.5 L0,.5",st[3]="M.5,0 L.5,1 M.5,.5 L1,.5",st),"╌":(at={},at[1]="M.1,.5 L.4,.5 M.6,.5 L.9,.5",at),"╍":(ct={},ct[3]="M.1,.5 L.4,.5 M.6,.5 L.9,.5",ct),"┄":(lt={},lt[1]="M.0667,.5 L.2667,.5 M.4,.5 L.6,.5 M.7333,.5 L.9333,.5",lt),"┅":(ut={},ut[3]="M.0667,.5 L.2667,.5 M.4,.5 L.6,.5 M.7333,.5 L.9333,.5",ut),"┈":(ht={},ht[1]="M.05,.5 L.2,.5 M.3,.5 L.45,.5 M.55,.5 L.7,.5 M.8,.5 L.95,.5",ht),"┉":(ft={},ft[3]="M.05,.5 L.2,.5 M.3,.5 L.45,.5 M.55,.5 L.7,.5 M.8,.5 L.95,.5",ft),"╎":(_t={},_t[1]="M.5,.1 L.5,.4 M.5,.6 L.5,.9",_t),"╏":(dt={},dt[3]="M.5,.1 L.5,.4 M.5,.6 L.5,.9",dt),"┆":(pt={},pt[1]="M.5,.0667 L.5,.2667 M.5,.4 L.5,.6 M.5,.7333 L.5,.9333",pt),"┇":(vt={},vt[3]="M.5,.0667 L.5,.2667 M.5,.4 L.5,.6 M.5,.7333 L.5,.9333",vt),"┊":(gt={},gt[1]="M.5,.05 L.5,.2 M.5,.3 L.5,.45 L.5,.55 M.5,.7 L.5,.95",gt),"┋":(yt={},yt[3]="M.5,.05 L.5,.2 M.5,.3 L.5,.45 L.5,.55 M.5,.7 L.5,.95",yt),"╭":(mt={},mt[1]="C.5,1,.5,.5,1,.5",mt),"╮":(bt={},bt[1]="C.5,1,.5,.5,0,.5",bt),"╯":(St={},St[1]="C.5,0,.5,.5,0,.5",St),"╰":(Ct={},Ct[1]="C.5,0,.5,.5,1,.5",Ct)},t.tryDrawCustomChar=function(e,r,i,n,o,s){var a=t.blockElementDefinitions[r];if(a)return function(e,t,r,i,n,o){for(var s=0;s<t.length;s++){var a=t[s],c=n/8,l=o/8;e.fillRect(r+a.x*c,i+a.y*l,a.w*c,a.h*l)}}(e,a,i,n,o,s),!0;var c=Lt[r];if(c)return function(e,t,r,i,n,o){var s,a=Et.get(t);a||(a=new Map,Et.set(t,a));var c=e.fillStyle;if("string"!=typeof c)throw new Error('Unexpected fillStyle type "'+c+'"');var l=a.get(c);if(!l){var u=t[0].length,h=t.length,f=document.createElement("canvas");f.width=u,f.height=h;var _=(0,wt.throwIfFalsy)(f.getContext("2d")),d=new ImageData(u,h),p=void 0,v=void 0,g=void 0,y=void 0;if(c.startsWith("#"))p=parseInt(c.substr(1,2),16),v=parseInt(c.substr(3,2),16),g=parseInt(c.substr(5,2),16),y=c.length>7&&parseInt(c.substr(7,2),16)||1;else{if(!c.startsWith("rgba"))throw new Error('Unexpected fillStyle color format "'+c+'" when drawing pattern glyph');p=(s=c.substring(5,c.length-1).split(",").map((function(e){return parseFloat(e)})))[0],v=s[1],g=s[2],y=s[3]}for(var m=0;m<h;m++)for(var b=0;b<u;b++)d.data[4*(m*u+b)]=p,d.data[4*(m*u+b)+1]=v,d.data[4*(m*u+b)+2]=g,d.data[4*(m*u+b)+3]=t[m][b]*(255*y);_.putImageData(d,0,0),l=(0,wt.throwIfFalsy)(e.createPattern(f,null)),a.set(c,l)}e.fillStyle=l,e.fillRect(r,i,n,o)}(e,c,i,n,o,s),!0;var l=t.boxDrawingDefinitions[r];return!!l&&(function(e,t,r,i,n,o){e.strokeStyle=e.fillStyle;for(var s=0,a=Object.entries(t);s<a.length;s++){var c=a[s],l=c[0],u=c[1];e.beginPath(),e.lineWidth=window.devicePixelRatio*Number.parseInt(l);for(var h=0,f=("function"==typeof u?u(.15,.15/o*n):u).split(" ");h<f.length;h++){var _=f[h],d=_[0],p=At[d];if(p){var v=_.substring(1).split(",");v[0]&&v[1]&&p(e,kt(v,n,o,r,i))}else console.error('Could not find drawing instructions for "'+d+'"')}e.stroke(),e.closePath()}}(e,l,i,n,o,s),!0)};var Et=new Map;function xt(e,t,r){return void 0===r&&(r=0),Math.max(Math.min(e,t),r)}var At={C:function(e,t){return e.bezierCurveTo(t[0],t[1],t[2],t[3],t[4],t[5])},L:function(e,t){return e.lineTo(t[0],t[1])},M:function(e,t){return e.moveTo(t[0],t[1])}};function kt(e,t,r,i,n){var o=e.map((function(e){return parseFloat(e)||parseInt(e)}));if(o.length<2)throw new Error("Too few arguments for instruction");for(var s=0;s<o.length;s+=2)o[s]*=t,0!==o[s]&&(o[s]=xt(Math.round(o[s]+.5)-.5,t,0)),o[s]+=i;for(var a=1;a<o.length;a+=2)o[a]*=r,0!==o[a]&&(o[a]=xt(Math.round(o[a]+.5)-.5,r,0)),o[a]+=n;return o}},3700:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.GridCache=void 0;var r=function(){function e(){this.cache=[]}return e.prototype.resize=function(e,t){for(var r=0;r<e;r++){this.cache.length<=r&&this.cache.push([]);for(var i=this.cache[r].length;i<t;i++)this.cache[r].push(void 0);this.cache[r].length=t}this.cache.length=e},e.prototype.clear=function(){for(var e=0;e<this.cache.length;e++)for(var t=0;t<this.cache[e].length;t++)this.cache[e][t]=void 0},e}();t.GridCache=r},5098:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)}),o=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},s=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.LinkRenderLayer=void 0;var a=r(1546),c=r(8803),l=r(2040),u=r(2585),h=function(e){function t(t,r,i,n,o,s,a,c){var l=e.call(this,t,"link",r,!0,i,n,a,c)||this;return o.onShowLinkUnderline((function(e){return l._onShowLinkUnderline(e)})),o.onHideLinkUnderline((function(e){return l._onHideLinkUnderline(e)})),s.onShowLinkUnderline((function(e){return l._onShowLinkUnderline(e)})),s.onHideLinkUnderline((function(e){return l._onHideLinkUnderline(e)})),l}return n(t,e),t.prototype.resize=function(t){e.prototype.resize.call(this,t),this._state=void 0},t.prototype.reset=function(){this._clearCurrentLink()},t.prototype._clearCurrentLink=function(){if(this._state){this._clearCells(this._state.x1,this._state.y1,this._state.cols-this._state.x1,1);var e=this._state.y2-this._state.y1-1;e>0&&this._clearCells(0,this._state.y1+1,this._state.cols,e),this._clearCells(0,this._state.y2,this._state.x2,1),this._state=void 0}},t.prototype._onShowLinkUnderline=function(e){if(e.fg===c.INVERTED_DEFAULT_COLOR?this._ctx.fillStyle=this._colors.background.css:e.fg&&(0,l.is256Color)(e.fg)?this._ctx.fillStyle=this._colors.ansi[e.fg].css:this._ctx.fillStyle=this._colors.foreground.css,e.y1===e.y2)this._fillBottomLineAtCells(e.x1,e.y1,e.x2-e.x1);else{this._fillBottomLineAtCells(e.x1,e.y1,e.cols-e.x1);for(var t=e.y1+1;t<e.y2;t++)this._fillBottomLineAtCells(0,t,e.cols);this._fillBottomLineAtCells(0,e.y2,e.x2)}this._state=e},t.prototype._onHideLinkUnderline=function(e){this._clearCurrentLink()},o([s(6,u.IBufferService),s(7,u.IOptionsService)],t)}(a.BaseRenderLayer);t.LinkRenderLayer=h},3525:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)}),o=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},s=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.Renderer=void 0;var a=r(9596),c=r(4149),l=r(2512),u=r(5098),h=r(844),f=r(4725),_=r(2585),d=r(1420),p=r(8460),v=1,g=function(e){function t(t,r,i,n,o,s,h,f){var _=e.call(this)||this;_._colors=t,_._screenElement=r,_._bufferService=s,_._charSizeService=h,_._optionsService=f,_._id=v++,_._onRequestRedraw=new p.EventEmitter;var d=_._optionsService.options.allowTransparency;return _._renderLayers=[o.createInstance(a.TextRenderLayer,_._screenElement,0,_._colors,d,_._id),o.createInstance(c.SelectionRenderLayer,_._screenElement,1,_._colors,_._id),o.createInstance(u.LinkRenderLayer,_._screenElement,2,_._colors,_._id,i,n),o.createInstance(l.CursorRenderLayer,_._screenElement,3,_._colors,_._id,_._onRequestRedraw)],_.dimensions={scaledCharWidth:0,scaledCharHeight:0,scaledCellWidth:0,scaledCellHeight:0,scaledCharLeft:0,scaledCharTop:0,scaledCanvasWidth:0,scaledCanvasHeight:0,canvasWidth:0,canvasHeight:0,actualCellWidth:0,actualCellHeight:0},_._devicePixelRatio=window.devicePixelRatio,_._updateDimensions(),_.onOptionsChanged(),_}return n(t,e),Object.defineProperty(t.prototype,"onRequestRedraw",{get:function(){return this._onRequestRedraw.event},enumerable:!1,configurable:!0}),t.prototype.dispose=function(){for(var t=0,r=this._renderLayers;t<r.length;t++)r[t].dispose();e.prototype.dispose.call(this),(0,d.removeTerminalFromCache)(this._id)},t.prototype.onDevicePixelRatioChange=function(){this._devicePixelRatio!==window.devicePixelRatio&&(this._devicePixelRatio=window.devicePixelRatio,this.onResize(this._bufferService.cols,this._bufferService.rows))},t.prototype.setColors=function(e){this._colors=e;for(var t=0,r=this._renderLayers;t<r.length;t++){var i=r[t];i.setColors(this._colors),i.reset()}},t.prototype.onResize=function(e,t){this._updateDimensions();for(var r=0,i=this._renderLayers;r<i.length;r++)i[r].resize(this.dimensions);this._screenElement.style.width=this.dimensions.canvasWidth+"px",this._screenElement.style.height=this.dimensions.canvasHeight+"px"},t.prototype.onCharSizeChanged=function(){this.onResize(this._bufferService.cols,this._bufferService.rows)},t.prototype.onBlur=function(){this._runOperation((function(e){return e.onBlur()}))},t.prototype.onFocus=function(){this._runOperation((function(e){return e.onFocus()}))},t.prototype.onSelectionChanged=function(e,t,r){void 0===r&&(r=!1),this._runOperation((function(i){return i.onSelectionChanged(e,t,r)}))},t.prototype.onCursorMove=function(){this._runOperation((function(e){return e.onCursorMove()}))},t.prototype.onOptionsChanged=function(){this._runOperation((function(e){return e.onOptionsChanged()}))},t.prototype.clear=function(){this._runOperation((function(e){return e.reset()}))},t.prototype._runOperation=function(e){for(var t=0,r=this._renderLayers;t<r.length;t++)e(r[t])},t.prototype.renderRows=function(e,t){for(var r=0,i=this._renderLayers;r<i.length;r++)i[r].onGridChanged(e,t)},t.prototype.clearTextureAtlas=function(){for(var e=0,t=this._renderLayers;e<t.length;e++)t[e].clearTextureAtlas()},t.prototype._updateDimensions=function(){this._charSizeService.hasValidSize&&(this.dimensions.scaledCharWidth=Math.floor(this._charSizeService.width*window.devicePixelRatio),this.dimensions.scaledCharHeight=Math.ceil(this._charSizeService.height*window.devicePixelRatio),this.dimensions.scaledCellHeight=Math.floor(this.dimensions.scaledCharHeight*this._optionsService.options.lineHeight),this.dimensions.scaledCharTop=1===this._optionsService.options.lineHeight?0:Math.round((this.dimensions.scaledCellHeight-this.dimensions.scaledCharHeight)/2),this.dimensions.scaledCellWidth=this.dimensions.scaledCharWidth+Math.round(this._optionsService.options.letterSpacing),this.dimensions.scaledCharLeft=Math.floor(this._optionsService.options.letterSpacing/2),this.dimensions.scaledCanvasHeight=this._bufferService.rows*this.dimensions.scaledCellHeight,this.dimensions.scaledCanvasWidth=this._bufferService.cols*this.dimensions.scaledCellWidth,this.dimensions.canvasHeight=Math.round(this.dimensions.scaledCanvasHeight/window.devicePixelRatio),this.dimensions.canvasWidth=Math.round(this.dimensions.scaledCanvasWidth/window.devicePixelRatio),this.dimensions.actualCellHeight=this.dimensions.canvasHeight/this._bufferService.rows,this.dimensions.actualCellWidth=this.dimensions.canvasWidth/this._bufferService.cols)},o([s(4,_.IInstantiationService),s(5,_.IBufferService),s(6,f.ICharSizeService),s(7,_.IOptionsService)],t)}(h.Disposable);t.Renderer=g},1752:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.throwIfFalsy=void 0,t.throwIfFalsy=function(e){if(!e)throw new Error("value must not be falsy");return e}},4149:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)}),o=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},s=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.SelectionRenderLayer=void 0;var a=r(1546),c=r(2585),l=function(e){function t(t,r,i,n,o,s){var a=e.call(this,t,"selection",r,!0,i,n,o,s)||this;return a._clearState(),a}return n(t,e),t.prototype._clearState=function(){this._state={start:void 0,end:void 0,columnSelectMode:void 0,ydisp:void 0}},t.prototype.resize=function(t){e.prototype.resize.call(this,t),this._clearState()},t.prototype.reset=function(){this._state.start&&this._state.end&&(this._clearState(),this._clearAll())},t.prototype.onSelectionChanged=function(e,t,r){if(this._didStateChange(e,t,r,this._bufferService.buffer.ydisp))if(this._clearAll(),e&&t){var i=e[1]-this._bufferService.buffer.ydisp,n=t[1]-this._bufferService.buffer.ydisp,o=Math.max(i,0),s=Math.min(n,this._bufferService.rows-1);if(o>=this._bufferService.rows||s<0)this._state.ydisp=this._bufferService.buffer.ydisp;else{if(this._ctx.fillStyle=this._colors.selectionTransparent.css,r){var a=e[0],c=t[0]-a,l=s-o+1;this._fillCells(a,o,c,l)}else{a=i===o?e[0]:0;var u=o===n?t[0]:this._bufferService.cols;this._fillCells(a,o,u-a,1);var h=Math.max(s-o-1,0);if(this._fillCells(0,o+1,this._bufferService.cols,h),o!==s){var f=n===s?t[0]:this._bufferService.cols;this._fillCells(0,s,f,1)}}this._state.start=[e[0],e[1]],this._state.end=[t[0],t[1]],this._state.columnSelectMode=r,this._state.ydisp=this._bufferService.buffer.ydisp}}else this._clearState()},t.prototype._didStateChange=function(e,t,r,i){return!this._areCoordinatesEqual(e,this._state.start)||!this._areCoordinatesEqual(t,this._state.end)||r!==this._state.columnSelectMode||i!==this._state.ydisp},t.prototype._areCoordinatesEqual=function(e,t){return!(!e||!t)&&e[0]===t[0]&&e[1]===t[1]},o([s(4,c.IBufferService),s(5,c.IOptionsService)],t)}(a.BaseRenderLayer);t.SelectionRenderLayer=l},9596:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)}),o=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},s=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.TextRenderLayer=void 0;var a=r(3700),c=r(1546),l=r(3734),u=r(643),h=r(511),f=r(2585),_=r(4725),d=r(4269),p=function(e){function t(t,r,i,n,o,s,c,l){var u=e.call(this,t,"text",r,n,i,o,s,c)||this;return u._characterJoinerService=l,u._characterWidth=0,u._characterFont="",u._characterOverlapCache={},u._workCell=new h.CellData,u._state=new a.GridCache,u}return n(t,e),t.prototype.resize=function(t){e.prototype.resize.call(this,t);var r=this._getFont(!1,!1);this._characterWidth===t.scaledCharWidth&&this._characterFont===r||(this._characterWidth=t.scaledCharWidth,this._characterFont=r,this._characterOverlapCache={}),this._state.clear(),this._state.resize(this._bufferService.cols,this._bufferService.rows)},t.prototype.reset=function(){this._state.clear(),this._clearAll()},t.prototype._forEachCell=function(e,t,r){for(var i=e;i<=t;i++)for(var n=i+this._bufferService.buffer.ydisp,o=this._bufferService.buffer.lines.get(n),s=this._characterJoinerService.getJoinedCharacters(n),a=0;a<this._bufferService.cols;a++){o.loadCell(a,this._workCell);var c=this._workCell,l=!1,h=a;if(0!==c.getWidth()){if(s.length>0&&a===s[0][0]){l=!0;var f=s.shift();c=new d.JoinedCellData(this._workCell,o.translateToString(!0,f[0],f[1]),f[1]-f[0]),h=f[1]-1}!l&&this._isOverlapping(c)&&h<o.length-1&&o.getCodePoint(h+1)===u.NULL_CELL_CODE&&(c.content&=-12582913,c.content|=2<<22),r(c,a,i),a=h}}},t.prototype._drawBackground=function(e,t){var r=this,i=this._ctx,n=this._bufferService.cols,o=0,s=0,a=null;i.save(),this._forEachCell(e,t,(function(e,t,c){var u=null;e.isInverse()?u=e.isFgDefault()?r._colors.foreground.css:e.isFgRGB()?"rgb("+l.AttributeData.toColorRGB(e.getFgColor()).join(",")+")":r._colors.ansi[e.getFgColor()].css:e.isBgRGB()?u="rgb("+l.AttributeData.toColorRGB(e.getBgColor()).join(",")+")":e.isBgPalette()&&(u=r._colors.ansi[e.getBgColor()].css),null===a&&(o=t,s=c),c!==s?(i.fillStyle=a||"",r._fillCells(o,s,n-o,1),o=t,s=c):a!==u&&(i.fillStyle=a||"",r._fillCells(o,s,t-o,1),o=t,s=c),a=u})),null!==a&&(i.fillStyle=a,this._fillCells(o,s,n-o,1)),i.restore()},t.prototype._drawForeground=function(e,t){var r=this;this._forEachCell(e,t,(function(e,t,i){if(!e.isInvisible()&&(r._drawChars(e,t,i),e.isUnderline()||e.isStrikethrough())){if(r._ctx.save(),e.isInverse())if(e.isBgDefault())r._ctx.fillStyle=r._colors.background.css;else if(e.isBgRGB())r._ctx.fillStyle="rgb("+l.AttributeData.toColorRGB(e.getBgColor()).join(",")+")";else{var n=e.getBgColor();r._optionsService.options.drawBoldTextInBrightColors&&e.isBold()&&n<8&&(n+=8),r._ctx.fillStyle=r._colors.ansi[n].css}else if(e.isFgDefault())r._ctx.fillStyle=r._colors.foreground.css;else if(e.isFgRGB())r._ctx.fillStyle="rgb("+l.AttributeData.toColorRGB(e.getFgColor()).join(",")+")";else{var o=e.getFgColor();r._optionsService.options.drawBoldTextInBrightColors&&e.isBold()&&o<8&&(o+=8),r._ctx.fillStyle=r._colors.ansi[o].css}e.isStrikethrough()&&r._fillMiddleLineAtCells(t,i,e.getWidth()),e.isUnderline()&&r._fillBottomLineAtCells(t,i,e.getWidth()),r._ctx.restore()}}))},t.prototype.onGridChanged=function(e,t){0!==this._state.cache.length&&(this._charAtlas&&this._charAtlas.beginFrame(),this._clearCells(0,e,this._bufferService.cols,t-e+1),this._drawBackground(e,t),this._drawForeground(e,t))},t.prototype.onOptionsChanged=function(){this._setTransparency(this._optionsService.options.allowTransparency)},t.prototype._isOverlapping=function(e){if(1!==e.getWidth())return!1;if(e.getCode()<256)return!1;var t=e.getChars();if(this._characterOverlapCache.hasOwnProperty(t))return this._characterOverlapCache[t];this._ctx.save(),this._ctx.font=this._characterFont;var r=Math.floor(this._ctx.measureText(t).width)>this._characterWidth;return this._ctx.restore(),this._characterOverlapCache[t]=r,r},o([s(5,f.IBufferService),s(6,f.IOptionsService),s(7,_.ICharacterJoinerService)],t)}(c.BaseRenderLayer);t.TextRenderLayer=p},9616:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.BaseCharAtlas=void 0;var r=function(){function e(){this._didWarmUp=!1}return e.prototype.dispose=function(){},e.prototype.warmUp=function(){this._didWarmUp||(this._doWarmUp(),this._didWarmUp=!0)},e.prototype._doWarmUp=function(){},e.prototype.clear=function(){},e.prototype.beginFrame=function(){},e}();t.BaseCharAtlas=r},1420:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.removeTerminalFromCache=t.acquireCharAtlas=void 0;var i=r(2040),n=r(1906),o=[];t.acquireCharAtlas=function(e,t,r,s,a){for(var c=(0,i.generateConfig)(s,a,e,r),l=0;l<o.length;l++){var u=(h=o[l]).ownedBy.indexOf(t);if(u>=0){if((0,i.configEquals)(h.config,c))return h.atlas;1===h.ownedBy.length?(h.atlas.dispose(),o.splice(l,1)):h.ownedBy.splice(u,1);break}}for(l=0;l<o.length;l++){var h=o[l];if((0,i.configEquals)(h.config,c))return h.ownedBy.push(t),h.atlas}var f={atlas:new n.DynamicCharAtlas(document,c),config:c,ownedBy:[t]};return o.push(f),f.atlas},t.removeTerminalFromCache=function(e){for(var t=0;t<o.length;t++){var r=o[t].ownedBy.indexOf(e);if(-1!==r){1===o[t].ownedBy.length?(o[t].atlas.dispose(),o.splice(t,1)):o[t].ownedBy.splice(r,1);break}}}},2040:function(e,t,r){var i=this&&this.__spreadArray||function(e,t,r){if(r||2===arguments.length)for(var i,n=0,o=t.length;n<o;n++)!i&&n in t||(i||(i=Array.prototype.slice.call(t,0,n)),i[n]=t[n]);return e.concat(i||Array.prototype.slice.call(t))};Object.defineProperty(t,"__esModule",{value:!0}),t.is256Color=t.configEquals=t.generateConfig=void 0;var n=r(643);t.generateConfig=function(e,t,r,n){var o={foreground:n.foreground,background:n.background,cursor:void 0,cursorAccent:void 0,selection:void 0,ansi:i([],n.ansi,!0)};return{devicePixelRatio:window.devicePixelRatio,scaledCharWidth:e,scaledCharHeight:t,fontFamily:r.fontFamily,fontSize:r.fontSize,fontWeight:r.fontWeight,fontWeightBold:r.fontWeightBold,allowTransparency:r.allowTransparency,colors:o}},t.configEquals=function(e,t){for(var r=0;r<e.colors.ansi.length;r++)if(e.colors.ansi[r].rgba!==t.colors.ansi[r].rgba)return!1;return e.devicePixelRatio===t.devicePixelRatio&&e.fontFamily===t.fontFamily&&e.fontSize===t.fontSize&&e.fontWeight===t.fontWeight&&e.fontWeightBold===t.fontWeightBold&&e.allowTransparency===t.allowTransparency&&e.scaledCharWidth===t.scaledCharWidth&&e.scaledCharHeight===t.scaledCharHeight&&e.colors.foreground===t.colors.foreground&&e.colors.background===t.colors.background},t.is256Color=function(e){return e<n.DEFAULT_COLOR}},8803:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.CHAR_ATLAS_CELL_SPACING=t.TEXT_BASELINE=t.DIM_OPACITY=t.INVERTED_DEFAULT_COLOR=void 0;var i=r(6114);t.INVERTED_DEFAULT_COLOR=257,t.DIM_OPACITY=.5,t.TEXT_BASELINE=i.isFirefox?"bottom":"ideographic",t.CHAR_ATLAS_CELL_SPACING=1},1906:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)});Object.defineProperty(t,"__esModule",{value:!0}),t.NoneCharAtlas=t.DynamicCharAtlas=t.getGlyphCacheKey=void 0;var o=r(8803),s=r(9616),a=r(5680),c=r(7001),l=r(6114),u=r(1752),h=r(4774),f=1024,_=1024,d={css:"rgba(0, 0, 0, 0)",rgba:0};function p(e){return e.code<<21|e.bg<<12|e.fg<<3|(e.bold?0:4)+(e.dim?0:2)+(e.italic?0:1)}t.getGlyphCacheKey=p;var v=function(e){function t(t,r){var i=e.call(this)||this;i._config=r,i._drawToCacheCount=0,i._glyphsWaitingOnBitmap=[],i._bitmapCommitTimeout=null,i._bitmap=null,i._cacheCanvas=t.createElement("canvas"),i._cacheCanvas.width=f,i._cacheCanvas.height=_,i._cacheCtx=(0,u.throwIfFalsy)(i._cacheCanvas.getContext("2d",{alpha:!0}));var n=t.createElement("canvas");n.width=i._config.scaledCharWidth,n.height=i._config.scaledCharHeight,i._tmpCtx=(0,u.throwIfFalsy)(n.getContext("2d",{alpha:i._config.allowTransparency})),i._width=Math.floor(f/i._config.scaledCharWidth),i._height=Math.floor(_/i._config.scaledCharHeight);var o=i._width*i._height;return i._cacheMap=new c.LRUMap(o),i._cacheMap.prealloc(o),i}return n(t,e),t.prototype.dispose=function(){null!==this._bitmapCommitTimeout&&(window.clearTimeout(this._bitmapCommitTimeout),this._bitmapCommitTimeout=null)},t.prototype.beginFrame=function(){this._drawToCacheCount=0},t.prototype.clear=function(){if(this._cacheMap.size>0){var e=this._width*this._height;this._cacheMap=new c.LRUMap(e),this._cacheMap.prealloc(e)}this._cacheCtx.clearRect(0,0,f,_),this._tmpCtx.clearRect(0,0,this._config.scaledCharWidth,this._config.scaledCharHeight)},t.prototype.draw=function(e,t,r,i){if(32===t.code)return!0;if(!this._canCache(t))return!1;var n=p(t),o=this._cacheMap.get(n);if(null!=o)return this._drawFromCache(e,o,r,i),!0;if(this._drawToCacheCount<100){var s;s=this._cacheMap.size<this._cacheMap.capacity?this._cacheMap.size:this._cacheMap.peek().index;var a=this._drawToCache(t,s);return this._cacheMap.set(n,a),this._drawFromCache(e,a,r,i),!0}return!1},t.prototype._canCache=function(e){return e.code<256},t.prototype._toCoordinateX=function(e){return e%this._width*this._config.scaledCharWidth},t.prototype._toCoordinateY=function(e){return Math.floor(e/this._width)*this._config.scaledCharHeight},t.prototype._drawFromCache=function(e,t,r,i){if(!t.isEmpty){var n=this._toCoordinateX(t.index),o=this._toCoordinateY(t.index);e.drawImage(t.inBitmap?this._bitmap:this._cacheCanvas,n,o,this._config.scaledCharWidth,this._config.scaledCharHeight,r,i,this._config.scaledCharWidth,this._config.scaledCharHeight)}},t.prototype._getColorFromAnsiIndex=function(e){return e<this._config.colors.ansi.length?this._config.colors.ansi[e]:a.DEFAULT_ANSI_COLORS[e]},t.prototype._getBackgroundColor=function(e){return this._config.allowTransparency?d:e.bg===o.INVERTED_DEFAULT_COLOR?this._config.colors.foreground:e.bg<256?this._getColorFromAnsiIndex(e.bg):this._config.colors.background},t.prototype._getForegroundColor=function(e){return e.fg===o.INVERTED_DEFAULT_COLOR?h.color.opaque(this._config.colors.background):e.fg<256?this._getColorFromAnsiIndex(e.fg):this._config.colors.foreground},t.prototype._drawToCache=function(e,t){this._drawToCacheCount++,this._tmpCtx.save();var r=this._getBackgroundColor(e);this._tmpCtx.globalCompositeOperation="copy",this._tmpCtx.fillStyle=r.css,this._tmpCtx.fillRect(0,0,this._config.scaledCharWidth,this._config.scaledCharHeight),this._tmpCtx.globalCompositeOperation="source-over";var i=e.bold?this._config.fontWeightBold:this._config.fontWeight,n=e.italic?"italic":"";this._tmpCtx.font=n+" "+i+" "+this._config.fontSize*this._config.devicePixelRatio+"px "+this._config.fontFamily,this._tmpCtx.textBaseline=o.TEXT_BASELINE,this._tmpCtx.fillStyle=this._getForegroundColor(e).css,e.dim&&(this._tmpCtx.globalAlpha=o.DIM_OPACITY),this._tmpCtx.fillText(e.chars,0,this._config.scaledCharHeight);var s=this._tmpCtx.getImageData(0,0,this._config.scaledCharWidth,this._config.scaledCharHeight),a=!1;if(this._config.allowTransparency||(a=y(s,r)),a&&"_"===e.chars&&!this._config.allowTransparency)for(var c=1;c<=5&&(this._tmpCtx.fillText(e.chars,0,this._config.scaledCharHeight-c),a=y(s=this._tmpCtx.getImageData(0,0,this._config.scaledCharWidth,this._config.scaledCharHeight),r));c++);this._tmpCtx.restore();var l=this._toCoordinateX(t),u=this._toCoordinateY(t);this._cacheCtx.putImageData(s,l,u);var h={index:t,isEmpty:a,inBitmap:!1};return this._addGlyphToBitmap(h),h},t.prototype._addGlyphToBitmap=function(e){var t=this;!("createImageBitmap"in window)||l.isFirefox||l.isSafari||(this._glyphsWaitingOnBitmap.push(e),null===this._bitmapCommitTimeout&&(this._bitmapCommitTimeout=window.setTimeout((function(){return t._generateBitmap()}),100)))},t.prototype._generateBitmap=function(){var e=this,t=this._glyphsWaitingOnBitmap;this._glyphsWaitingOnBitmap=[],window.createImageBitmap(this._cacheCanvas).then((function(r){e._bitmap=r;for(var i=0;i<t.length;i++)t[i].inBitmap=!0})),this._bitmapCommitTimeout=null},t}(s.BaseCharAtlas);t.DynamicCharAtlas=v;var g=function(e){function t(t,r){return e.call(this)||this}return n(t,e),t.prototype.draw=function(e,t,r,i){return!1},t}(s.BaseCharAtlas);function y(e,t){for(var r=!0,i=t.rgba>>>24,n=t.rgba>>>16&255,o=t.rgba>>>8&255,s=0;s<e.data.length;s+=4)e.data[s]===i&&e.data[s+1]===n&&e.data[s+2]===o?e.data[s+3]=0:r=!1;return r}t.NoneCharAtlas=g},7001:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.LRUMap=void 0;var r=function(){function e(e){this.capacity=e,this._map={},this._head=null,this._tail=null,this._nodePool=[],this.size=0}return e.prototype._unlinkNode=function(e){var t=e.prev,r=e.next;e===this._head&&(this._head=r),e===this._tail&&(this._tail=t),null!==t&&(t.next=r),null!==r&&(r.prev=t)},e.prototype._appendNode=function(e){var t=this._tail;null!==t&&(t.next=e),e.prev=t,e.next=null,this._tail=e,null===this._head&&(this._head=e)},e.prototype.prealloc=function(e){for(var t=this._nodePool,r=0;r<e;r++)t.push({prev:null,next:null,key:null,value:null})},e.prototype.get=function(e){var t=this._map[e];return void 0!==t?(this._unlinkNode(t),this._appendNode(t),t.value):null},e.prototype.peekValue=function(e){var t=this._map[e];return void 0!==t?t.value:null},e.prototype.peek=function(){var e=this._head;return null===e?null:e.value},e.prototype.set=function(e,t){var r=this._map[e];if(void 0!==r)r=this._map[e],this._unlinkNode(r),r.value=t;else if(this.size>=this.capacity)r=this._head,this._unlinkNode(r),delete this._map[r.key],r.key=e,r.value=t,this._map[e]=r;else{var i=this._nodePool;i.length>0?((r=i.pop()).key=e,r.value=t):r={prev:null,next:null,key:e,value:t},this._map[e]=r,this.size++}this._appendNode(r)},e}();t.LRUMap=r},1296:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)}),o=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},s=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.DomRenderer=void 0;var a=r(3787),c=r(8803),l=r(844),u=r(4725),h=r(2585),f=r(8460),_=r(4774),d=r(9631),p="xterm-dom-renderer-owner-",v="xterm-fg-",g="xterm-bg-",y="xterm-focus",m=1,b=function(e){function t(t,r,i,n,o,s,c,l,u,h){var f=e.call(this)||this;return f._colors=t,f._element=r,f._screenElement=i,f._viewportElement=n,f._linkifier=o,f._linkifier2=s,f._charSizeService=l,f._optionsService=u,f._bufferService=h,f._terminalClass=m++,f._rowElements=[],f._rowContainer=document.createElement("div"),f._rowContainer.classList.add("xterm-rows"),f._rowContainer.style.lineHeight="normal",f._rowContainer.setAttribute("aria-hidden","true"),f._refreshRowElements(f._bufferService.cols,f._bufferService.rows),f._selectionContainer=document.createElement("div"),f._selectionContainer.classList.add("xterm-selection"),f._selectionContainer.setAttribute("aria-hidden","true"),f.dimensions={scaledCharWidth:0,scaledCharHeight:0,scaledCellWidth:0,scaledCellHeight:0,scaledCharLeft:0,scaledCharTop:0,scaledCanvasWidth:0,scaledCanvasHeight:0,canvasWidth:0,canvasHeight:0,actualCellWidth:0,actualCellHeight:0},f._updateDimensions(),f._injectCss(),f._rowFactory=c.createInstance(a.DomRendererRowFactory,document,f._colors),f._element.classList.add(p+f._terminalClass),f._screenElement.appendChild(f._rowContainer),f._screenElement.appendChild(f._selectionContainer),f._linkifier.onShowLinkUnderline((function(e){return f._onLinkHover(e)})),f._linkifier.onHideLinkUnderline((function(e){return f._onLinkLeave(e)})),f._linkifier2.onShowLinkUnderline((function(e){return f._onLinkHover(e)})),f._linkifier2.onHideLinkUnderline((function(e){return f._onLinkLeave(e)})),f}return n(t,e),Object.defineProperty(t.prototype,"onRequestRedraw",{get:function(){return(new f.EventEmitter).event},enumerable:!1,configurable:!0}),t.prototype.dispose=function(){this._element.classList.remove(p+this._terminalClass),(0,d.removeElementFromParent)(this._rowContainer,this._selectionContainer,this._themeStyleElement,this._dimensionsStyleElement),e.prototype.dispose.call(this)},t.prototype._updateDimensions=function(){this.dimensions.scaledCharWidth=this._charSizeService.width*window.devicePixelRatio,this.dimensions.scaledCharHeight=Math.ceil(this._charSizeService.height*window.devicePixelRatio),this.dimensions.scaledCellWidth=this.dimensions.scaledCharWidth+Math.round(this._optionsService.options.letterSpacing),this.dimensions.scaledCellHeight=Math.floor(this.dimensions.scaledCharHeight*this._optionsService.options.lineHeight),this.dimensions.scaledCharLeft=0,this.dimensions.scaledCharTop=0,this.dimensions.scaledCanvasWidth=this.dimensions.scaledCellWidth*this._bufferService.cols,this.dimensions.scaledCanvasHeight=this.dimensions.scaledCellHeight*this._bufferService.rows,this.dimensions.canvasWidth=Math.round(this.dimensions.scaledCanvasWidth/window.devicePixelRatio),this.dimensions.canvasHeight=Math.round(this.dimensions.scaledCanvasHeight/window.devicePixelRatio),this.dimensions.actualCellWidth=this.dimensions.canvasWidth/this._bufferService.cols,this.dimensions.actualCellHeight=this.dimensions.canvasHeight/this._bufferService.rows;for(var e=0,t=this._rowElements;e<t.length;e++){var r=t[e];r.style.width=this.dimensions.canvasWidth+"px",r.style.height=this.dimensions.actualCellHeight+"px",r.style.lineHeight=this.dimensions.actualCellHeight+"px",r.style.overflow="hidden"}this._dimensionsStyleElement||(this._dimensionsStyleElement=document.createElement("style"),this._screenElement.appendChild(this._dimensionsStyleElement));var i=this._terminalSelector+" .xterm-rows span { display: inline-block; height: 100%; vertical-align: top; width: "+this.dimensions.actualCellWidth+"px}";this._dimensionsStyleElement.textContent=i,this._selectionContainer.style.height=this._viewportElement.style.height,this._screenElement.style.width=this.dimensions.canvasWidth+"px",this._screenElement.style.height=this.dimensions.canvasHeight+"px"},t.prototype.setColors=function(e){this._colors=e,this._injectCss()},t.prototype._injectCss=function(){var e=this;this._themeStyleElement||(this._themeStyleElement=document.createElement("style"),this._screenElement.appendChild(this._themeStyleElement));var t=this._terminalSelector+" .xterm-rows { color: "+this._colors.foreground.css+"; font-family: "+this._optionsService.options.fontFamily+"; font-size: "+this._optionsService.options.fontSize+"px;}";t+=this._terminalSelector+" span:not(."+a.BOLD_CLASS+") { font-weight: "+this._optionsService.options.fontWeight+";}"+this._terminalSelector+" span."+a.BOLD_CLASS+" { font-weight: "+this._optionsService.options.fontWeightBold+";}"+this._terminalSelector+" span."+a.ITALIC_CLASS+" { font-style: italic;}",t+="@keyframes blink_box_shadow_"+this._terminalClass+" { 50% {  box-shadow: none; }}",t+="@keyframes blink_block_"+this._terminalClass+" { 0% {  background-color: "+this._colors.cursor.css+";  color: "+this._colors.cursorAccent.css+"; } 50% {  background-color: "+this._colors.cursorAccent.css+";  color: "+this._colors.cursor.css+"; }}",t+=this._terminalSelector+" .xterm-rows:not(.xterm-focus) ."+a.CURSOR_CLASS+"."+a.CURSOR_STYLE_BLOCK_CLASS+" { outline: 1px solid "+this._colors.cursor.css+"; outline-offset: -1px;}"+this._terminalSelector+" .xterm-rows.xterm-focus ."+a.CURSOR_CLASS+"."+a.CURSOR_BLINK_CLASS+":not(."+a.CURSOR_STYLE_BLOCK_CLASS+") { animation: blink_box_shadow_"+this._terminalClass+" 1s step-end infinite;}"+this._terminalSelector+" .xterm-rows.xterm-focus ."+a.CURSOR_CLASS+"."+a.CURSOR_BLINK_CLASS+"."+a.CURSOR_STYLE_BLOCK_CLASS+" { animation: blink_block_"+this._terminalClass+" 1s step-end infinite;}"+this._terminalSelector+" .xterm-rows.xterm-focus ."+a.CURSOR_CLASS+"."+a.CURSOR_STYLE_BLOCK_CLASS+" { background-color: "+this._colors.cursor.css+"; color: "+this._colors.cursorAccent.css+";}"+this._terminalSelector+" .xterm-rows ."+a.CURSOR_CLASS+"."+a.CURSOR_STYLE_BAR_CLASS+" { box-shadow: "+this._optionsService.options.cursorWidth+"px 0 0 "+this._colors.cursor.css+" inset;}"+this._terminalSelector+" .xterm-rows ."+a.CURSOR_CLASS+"."+a.CURSOR_STYLE_UNDERLINE_CLASS+" { box-shadow: 0 -1px 0 "+this._colors.cursor.css+" inset;}",t+=this._terminalSelector+" .xterm-selection { position: absolute; top: 0; left: 0; z-index: 1; pointer-events: none;}"+this._terminalSelector+" .xterm-selection div { position: absolute; background-color: "+this._colors.selectionTransparent.css+";}",this._colors.ansi.forEach((function(r,i){t+=e._terminalSelector+" ."+v+i+" { color: "+r.css+"; }"+e._terminalSelector+" ."+g+i+" { background-color: "+r.css+"; }"})),t+=this._terminalSelector+" ."+v+c.INVERTED_DEFAULT_COLOR+" { color: "+_.color.opaque(this._colors.background).css+"; }"+this._terminalSelector+" ."+g+c.INVERTED_DEFAULT_COLOR+" { background-color: "+this._colors.foreground.css+"; }",this._themeStyleElement.textContent=t},t.prototype.onDevicePixelRatioChange=function(){this._updateDimensions()},t.prototype._refreshRowElements=function(e,t){for(var r=this._rowElements.length;r<=t;r++){var i=document.createElement("div");this._rowContainer.appendChild(i),this._rowElements.push(i)}for(;this._rowElements.length>t;)this._rowContainer.removeChild(this._rowElements.pop())},t.prototype.onResize=function(e,t){this._refreshRowElements(e,t),this._updateDimensions()},t.prototype.onCharSizeChanged=function(){this._updateDimensions()},t.prototype.onBlur=function(){this._rowContainer.classList.remove(y)},t.prototype.onFocus=function(){this._rowContainer.classList.add(y)},t.prototype.onSelectionChanged=function(e,t,r){for(;this._selectionContainer.children.length;)this._selectionContainer.removeChild(this._selectionContainer.children[0]);if(e&&t){var i=e[1]-this._bufferService.buffer.ydisp,n=t[1]-this._bufferService.buffer.ydisp,o=Math.max(i,0),s=Math.min(n,this._bufferService.rows-1);if(!(o>=this._bufferService.rows||s<0)){var a=document.createDocumentFragment();if(r)a.appendChild(this._createSelectionElement(o,e[0],t[0],s-o+1));else{var c=i===o?e[0]:0,l=o===n?t[0]:this._bufferService.cols;a.appendChild(this._createSelectionElement(o,c,l));var u=s-o-1;if(a.appendChild(this._createSelectionElement(o+1,0,this._bufferService.cols,u)),o!==s){var h=n===s?t[0]:this._bufferService.cols;a.appendChild(this._createSelectionElement(s,0,h))}}this._selectionContainer.appendChild(a)}}},t.prototype._createSelectionElement=function(e,t,r,i){void 0===i&&(i=1);var n=document.createElement("div");return n.style.height=i*this.dimensions.actualCellHeight+"px",n.style.top=e*this.dimensions.actualCellHeight+"px",n.style.left=t*this.dimensions.actualCellWidth+"px",n.style.width=this.dimensions.actualCellWidth*(r-t)+"px",n},t.prototype.onCursorMove=function(){},t.prototype.onOptionsChanged=function(){this._updateDimensions(),this._injectCss()},t.prototype.clear=function(){for(var e=0,t=this._rowElements;e<t.length;e++)t[e].innerText=""},t.prototype.renderRows=function(e,t){for(var r=this._bufferService.buffer.ybase+this._bufferService.buffer.y,i=Math.min(this._bufferService.buffer.x,this._bufferService.cols-1),n=this._optionsService.options.cursorBlink,o=e;o<=t;o++){var s=this._rowElements[o];s.innerText="";var a=o+this._bufferService.buffer.ydisp,c=this._bufferService.buffer.lines.get(a),l=this._optionsService.options.cursorStyle;s.appendChild(this._rowFactory.createRow(c,a,a===r,l,i,n,this.dimensions.actualCellWidth,this._bufferService.cols))}},Object.defineProperty(t.prototype,"_terminalSelector",{get:function(){return"."+p+this._terminalClass},enumerable:!1,configurable:!0}),t.prototype._onLinkHover=function(e){this._setCellUnderline(e.x1,e.x2,e.y1,e.y2,e.cols,!0)},t.prototype._onLinkLeave=function(e){this._setCellUnderline(e.x1,e.x2,e.y1,e.y2,e.cols,!1)},t.prototype._setCellUnderline=function(e,t,r,i,n,o){for(;e!==t||r!==i;){var s=this._rowElements[r];if(!s)return;var a=s.children[e];a&&(a.style.textDecoration=o?"underline":"none"),++e>=n&&(e=0,r++)}},o([s(6,h.IInstantiationService),s(7,u.ICharSizeService),s(8,h.IOptionsService),s(9,h.IBufferService)],t)}(l.Disposable);t.DomRenderer=b},3787:function(e,t,r){var i=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},n=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.DomRendererRowFactory=t.CURSOR_STYLE_UNDERLINE_CLASS=t.CURSOR_STYLE_BAR_CLASS=t.CURSOR_STYLE_BLOCK_CLASS=t.CURSOR_BLINK_CLASS=t.CURSOR_CLASS=t.STRIKETHROUGH_CLASS=t.UNDERLINE_CLASS=t.ITALIC_CLASS=t.DIM_CLASS=t.BOLD_CLASS=void 0;var o=r(8803),s=r(643),a=r(511),c=r(2585),l=r(4774),u=r(4725),h=r(4269);t.BOLD_CLASS="xterm-bold",t.DIM_CLASS="xterm-dim",t.ITALIC_CLASS="xterm-italic",t.UNDERLINE_CLASS="xterm-underline",t.STRIKETHROUGH_CLASS="xterm-strikethrough",t.CURSOR_CLASS="xterm-cursor",t.CURSOR_BLINK_CLASS="xterm-cursor-blink",t.CURSOR_STYLE_BLOCK_CLASS="xterm-cursor-block",t.CURSOR_STYLE_BAR_CLASS="xterm-cursor-bar",t.CURSOR_STYLE_UNDERLINE_CLASS="xterm-cursor-underline";var f=function(){function e(e,t,r,i,n){this._document=e,this._colors=t,this._characterJoinerService=r,this._optionsService=i,this._coreService=n,this._workCell=new a.CellData}return e.prototype.setColors=function(e){this._colors=e},e.prototype.createRow=function(e,r,i,n,a,c,u,f){for(var d=this._document.createDocumentFragment(),p=this._characterJoinerService.getJoinedCharacters(r),v=0,g=Math.min(e.length,f)-1;g>=0;g--)if(e.loadCell(g,this._workCell).getCode()!==s.NULL_CELL_CODE||i&&g===a){v=g+1;break}for(g=0;g<v;g++){e.loadCell(g,this._workCell);var y=this._workCell.getWidth();if(0!==y){var m=!1,b=g,S=this._workCell;if(p.length>0&&g===p[0][0]){m=!0;var C=p.shift();S=new h.JoinedCellData(this._workCell,e.translateToString(!0,C[0],C[1]),C[1]-C[0]),b=C[1]-1,y=S.getWidth()}var w=this._document.createElement("span");if(y>1&&(w.style.width=u*y+"px"),m&&(w.style.display="inline",a>=g&&a<=b&&(a=g)),!this._coreService.isCursorHidden&&i&&g===a)switch(w.classList.add(t.CURSOR_CLASS),c&&w.classList.add(t.CURSOR_BLINK_CLASS),n){case"bar":w.classList.add(t.CURSOR_STYLE_BAR_CLASS);break;case"underline":w.classList.add(t.CURSOR_STYLE_UNDERLINE_CLASS);break;default:w.classList.add(t.CURSOR_STYLE_BLOCK_CLASS)}S.isBold()&&w.classList.add(t.BOLD_CLASS),S.isItalic()&&w.classList.add(t.ITALIC_CLASS),S.isDim()&&w.classList.add(t.DIM_CLASS),S.isUnderline()&&w.classList.add(t.UNDERLINE_CLASS),S.isInvisible()?w.textContent=s.WHITESPACE_CELL_CHAR:w.textContent=S.getChars()||s.WHITESPACE_CELL_CHAR,S.isStrikethrough()&&w.classList.add(t.STRIKETHROUGH_CLASS);var L=S.getFgColor(),E=S.getFgColorMode(),x=S.getBgColor(),A=S.getBgColorMode(),k=!!S.isInverse();if(k){var M=L;L=x,x=M;var R=E;E=A,A=R}switch(E){case 16777216:case 33554432:S.isBold()&&L<8&&this._optionsService.options.drawBoldTextInBrightColors&&(L+=8),this._applyMinimumContrast(w,this._colors.background,this._colors.ansi[L])||w.classList.add("xterm-fg-"+L);break;case 50331648:var T=l.rgba.toColor(L>>16&255,L>>8&255,255&L);this._applyMinimumContrast(w,this._colors.background,T)||this._addStyle(w,"color:#"+_(L.toString(16),"0",6));break;default:this._applyMinimumContrast(w,this._colors.background,this._colors.foreground)||k&&w.classList.add("xterm-fg-"+o.INVERTED_DEFAULT_COLOR)}switch(A){case 16777216:case 33554432:w.classList.add("xterm-bg-"+x);break;case 50331648:this._addStyle(w,"background-color:#"+_(x.toString(16),"0",6));break;default:k&&w.classList.add("xterm-bg-"+o.INVERTED_DEFAULT_COLOR)}d.appendChild(w),g=b}}return d},e.prototype._applyMinimumContrast=function(e,t,r){if(1===this._optionsService.options.minimumContrastRatio)return!1;var i=this._colors.contrastCache.getColor(this._workCell.bg,this._workCell.fg);return void 0===i&&(i=l.color.ensureContrastRatio(t,r,this._optionsService.options.minimumContrastRatio),this._colors.contrastCache.setColor(this._workCell.bg,this._workCell.fg,null!=i?i:null)),!!i&&(this._addStyle(e,"color:"+i.css),!0)},e.prototype._addStyle=function(e,t){e.setAttribute("style",""+(e.getAttribute("style")||"")+t+";")},i([n(2,u.ICharacterJoinerService),n(3,c.IOptionsService),n(4,c.ICoreService)],e)}();function _(e,t,r){for(;e.length<r;)e=t+e;return e}t.DomRendererRowFactory=f},456:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.SelectionModel=void 0;var r=function(){function e(e){this._bufferService=e,this.isSelectAllActive=!1,this.selectionStartLength=0}return e.prototype.clearSelection=function(){this.selectionStart=void 0,this.selectionEnd=void 0,this.isSelectAllActive=!1,this.selectionStartLength=0},Object.defineProperty(e.prototype,"finalSelectionStart",{get:function(){return this.isSelectAllActive?[0,0]:this.selectionEnd&&this.selectionStart&&this.areSelectionValuesReversed()?this.selectionEnd:this.selectionStart},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"finalSelectionEnd",{get:function(){if(this.isSelectAllActive)return[this._bufferService.cols,this._bufferService.buffer.ybase+this._bufferService.rows-1];if(this.selectionStart){if(!this.selectionEnd||this.areSelectionValuesReversed()){var e=this.selectionStart[0]+this.selectionStartLength;return e>this._bufferService.cols?e%this._bufferService.cols==0?[this._bufferService.cols,this.selectionStart[1]+Math.floor(e/this._bufferService.cols)-1]:[e%this._bufferService.cols,this.selectionStart[1]+Math.floor(e/this._bufferService.cols)]:[e,this.selectionStart[1]]}return this.selectionStartLength&&this.selectionEnd[1]===this.selectionStart[1]?[Math.max(this.selectionStart[0]+this.selectionStartLength,this.selectionEnd[0]),this.selectionEnd[1]]:this.selectionEnd}},enumerable:!1,configurable:!0}),e.prototype.areSelectionValuesReversed=function(){var e=this.selectionStart,t=this.selectionEnd;return!(!e||!t)&&(e[1]>t[1]||e[1]===t[1]&&e[0]>t[0])},e.prototype.onTrim=function(e){return this.selectionStart&&(this.selectionStart[1]-=e),this.selectionEnd&&(this.selectionEnd[1]-=e),this.selectionEnd&&this.selectionEnd[1]<0?(this.clearSelection(),!0):(this.selectionStart&&this.selectionStart[1]<0&&(this.selectionStart[1]=0),!1)},e}();t.SelectionModel=r},428:function(e,t,r){var i=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},n=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.CharSizeService=void 0;var o=r(2585),s=r(8460),a=function(){function e(e,t,r){this._optionsService=r,this.width=0,this.height=0,this._onCharSizeChange=new s.EventEmitter,this._measureStrategy=new c(e,t,this._optionsService)}return Object.defineProperty(e.prototype,"hasValidSize",{get:function(){return this.width>0&&this.height>0},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"onCharSizeChange",{get:function(){return this._onCharSizeChange.event},enumerable:!1,configurable:!0}),e.prototype.measure=function(){var e=this._measureStrategy.measure();e.width===this.width&&e.height===this.height||(this.width=e.width,this.height=e.height,this._onCharSizeChange.fire())},i([n(2,o.IOptionsService)],e)}();t.CharSizeService=a;var c=function(){function e(e,t,r){this._document=e,this._parentElement=t,this._optionsService=r,this._result={width:0,height:0},this._measureElement=this._document.createElement("span"),this._measureElement.classList.add("xterm-char-measure-element"),this._measureElement.textContent="W",this._measureElement.setAttribute("aria-hidden","true"),this._parentElement.appendChild(this._measureElement)}return e.prototype.measure=function(){this._measureElement.style.fontFamily=this._optionsService.options.fontFamily,this._measureElement.style.fontSize=this._optionsService.options.fontSize+"px";var e=this._measureElement.getBoundingClientRect();return 0!==e.width&&0!==e.height&&(this._result.width=e.width,this._result.height=Math.ceil(e.height)),this._result},e}()},4269:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)}),o=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},s=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.CharacterJoinerService=t.JoinedCellData=void 0;var a=r(3734),c=r(643),l=r(511),u=r(2585),h=function(e){function t(t,r,i){var n=e.call(this)||this;return n.content=0,n.combinedData="",n.fg=t.fg,n.bg=t.bg,n.combinedData=r,n._width=i,n}return n(t,e),t.prototype.isCombined=function(){return 2097152},t.prototype.getWidth=function(){return this._width},t.prototype.getChars=function(){return this.combinedData},t.prototype.getCode=function(){return 2097151},t.prototype.setFromCharData=function(e){throw new Error("not implemented")},t.prototype.getAsCharData=function(){return[this.fg,this.getChars(),this.getWidth(),this.getCode()]},t}(a.AttributeData);t.JoinedCellData=h;var f=function(){function e(e){this._bufferService=e,this._characterJoiners=[],this._nextCharacterJoinerId=0,this._workCell=new l.CellData}return e.prototype.register=function(e){var t={id:this._nextCharacterJoinerId++,handler:e};return this._characterJoiners.push(t),t.id},e.prototype.deregister=function(e){for(var t=0;t<this._characterJoiners.length;t++)if(this._characterJoiners[t].id===e)return this._characterJoiners.splice(t,1),!0;return!1},e.prototype.getJoinedCharacters=function(e){if(0===this._characterJoiners.length)return[];var t=this._bufferService.buffer.lines.get(e);if(!t||0===t.length)return[];for(var r=[],i=t.translateToString(!0),n=0,o=0,s=0,a=t.getFg(0),l=t.getBg(0),u=0;u<t.getTrimmedLength();u++)if(t.loadCell(u,this._workCell),0!==this._workCell.getWidth()){if(this._workCell.fg!==a||this._workCell.bg!==l){if(u-n>1)for(var h=this._getJoinedRanges(i,s,o,t,n),f=0;f<h.length;f++)r.push(h[f]);n=u,s=o,a=this._workCell.fg,l=this._workCell.bg}o+=this._workCell.getChars().length||c.WHITESPACE_CELL_CHAR.length}if(this._bufferService.cols-n>1)for(h=this._getJoinedRanges(i,s,o,t,n),f=0;f<h.length;f++)r.push(h[f]);return r},e.prototype._getJoinedRanges=function(t,r,i,n,o){var s=t.substring(r,i),a=[];try{a=this._characterJoiners[0].handler(s)}catch(e){console.error(e)}for(var c=1;c<this._characterJoiners.length;c++)try{for(var l=this._characterJoiners[c].handler(s),u=0;u<l.length;u++)e._mergeRanges(a,l[u])}catch(e){console.error(e)}return this._stringRangesToCellRanges(a,n,o),a},e.prototype._stringRangesToCellRanges=function(e,t,r){var i=0,n=!1,o=0,s=e[i];if(s){for(var a=r;a<this._bufferService.cols;a++){var l=t.getWidth(a),u=t.getString(a).length||c.WHITESPACE_CELL_CHAR.length;if(0!==l){if(!n&&s[0]<=o&&(s[0]=a,n=!0),s[1]<=o){if(s[1]=a,!(s=e[++i]))break;s[0]<=o?(s[0]=a,n=!0):n=!1}o+=u}}s&&(s[1]=this._bufferService.cols)}},e._mergeRanges=function(e,t){for(var r=!1,i=0;i<e.length;i++){var n=e[i];if(r){if(t[1]<=n[0])return e[i-1][1]=t[1],e;if(t[1]<=n[1])return e[i-1][1]=Math.max(t[1],n[1]),e.splice(i,1),e;e.splice(i,1),i--}else{if(t[1]<=n[0])return e.splice(i,0,t),e;if(t[1]<=n[1])return n[0]=Math.min(t[0],n[0]),e;t[0]<n[1]&&(n[0]=Math.min(t[0],n[0]),r=!0)}}return r?e[e.length-1][1]=t[1]:e.push(t),e},e=o([s(0,u.IBufferService)],e)}();t.CharacterJoinerService=f},5114:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.CoreBrowserService=void 0;var r=function(){function e(e){this._textarea=e}return Object.defineProperty(e.prototype,"isFocused",{get:function(){return(this._textarea.getRootNode?this._textarea.getRootNode():document).activeElement===this._textarea&&document.hasFocus()},enumerable:!1,configurable:!0}),e}();t.CoreBrowserService=r},8934:function(e,t,r){var i=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},n=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.MouseService=void 0;var o=r(4725),s=r(9806),a=function(){function e(e,t){this._renderService=e,this._charSizeService=t}return e.prototype.getCoords=function(e,t,r,i,n){return(0,s.getCoords)(e,t,r,i,this._charSizeService.hasValidSize,this._renderService.dimensions.actualCellWidth,this._renderService.dimensions.actualCellHeight,n)},e.prototype.getRawByteCoords=function(e,t,r,i){var n=this.getCoords(e,t,r,i);return(0,s.getRawByteCoords)(n)},i([n(0,o.IRenderService),n(1,o.ICharSizeService)],e)}();t.MouseService=a},3230:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)}),o=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},s=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.RenderService=void 0;var a=r(6193),c=r(8460),l=r(844),u=r(5596),h=r(3656),f=r(2585),_=r(4725),d=function(e){function t(t,r,i,n,o,s){var l=e.call(this)||this;if(l._renderer=t,l._rowCount=r,l._charSizeService=o,l._isPaused=!1,l._needsFullRefresh=!1,l._isNextRenderRedrawOnly=!0,l._needsSelectionRefresh=!1,l._canvasWidth=0,l._canvasHeight=0,l._selectionState={start:void 0,end:void 0,columnSelectMode:!1},l._onDimensionsChange=new c.EventEmitter,l._onRender=new c.EventEmitter,l._onRefreshRequest=new c.EventEmitter,l.register({dispose:function(){return l._renderer.dispose()}}),l._renderDebouncer=new a.RenderDebouncer((function(e,t){return l._renderRows(e,t)})),l.register(l._renderDebouncer),l._screenDprMonitor=new u.ScreenDprMonitor,l._screenDprMonitor.setListener((function(){return l.onDevicePixelRatioChange()})),l.register(l._screenDprMonitor),l.register(s.onResize((function(e){return l._fullRefresh()}))),l.register(n.onOptionChange((function(){return l._renderer.onOptionsChanged()}))),l.register(l._charSizeService.onCharSizeChange((function(){return l.onCharSizeChanged()}))),l._renderer.onRequestRedraw((function(e){return l.refreshRows(e.start,e.end,!0)})),l.register((0,h.addDisposableDomListener)(window,"resize",(function(){return l.onDevicePixelRatioChange()}))),"IntersectionObserver"in window){var f=new IntersectionObserver((function(e){return l._onIntersectionChange(e[e.length-1])}),{threshold:0});f.observe(i),l.register({dispose:function(){return f.disconnect()}})}return l}return n(t,e),Object.defineProperty(t.prototype,"onDimensionsChange",{get:function(){return this._onDimensionsChange.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onRenderedBufferChange",{get:function(){return this._onRender.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onRefreshRequest",{get:function(){return this._onRefreshRequest.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"dimensions",{get:function(){return this._renderer.dimensions},enumerable:!1,configurable:!0}),t.prototype._onIntersectionChange=function(e){this._isPaused=void 0===e.isIntersecting?0===e.intersectionRatio:!e.isIntersecting,this._isPaused||this._charSizeService.hasValidSize||this._charSizeService.measure(),!this._isPaused&&this._needsFullRefresh&&(this.refreshRows(0,this._rowCount-1),this._needsFullRefresh=!1)},t.prototype.refreshRows=function(e,t,r){void 0===r&&(r=!1),this._isPaused?this._needsFullRefresh=!0:(r||(this._isNextRenderRedrawOnly=!1),this._renderDebouncer.refresh(e,t,this._rowCount))},t.prototype._renderRows=function(e,t){this._renderer.renderRows(e,t),this._needsSelectionRefresh&&(this._renderer.onSelectionChanged(this._selectionState.start,this._selectionState.end,this._selectionState.columnSelectMode),this._needsSelectionRefresh=!1),this._isNextRenderRedrawOnly||this._onRender.fire({start:e,end:t}),this._isNextRenderRedrawOnly=!0},t.prototype.resize=function(e,t){this._rowCount=t,this._fireOnCanvasResize()},t.prototype.changeOptions=function(){this._renderer.onOptionsChanged(),this.refreshRows(0,this._rowCount-1),this._fireOnCanvasResize()},t.prototype._fireOnCanvasResize=function(){this._renderer.dimensions.canvasWidth===this._canvasWidth&&this._renderer.dimensions.canvasHeight===this._canvasHeight||this._onDimensionsChange.fire(this._renderer.dimensions)},t.prototype.dispose=function(){e.prototype.dispose.call(this)},t.prototype.setRenderer=function(e){var t=this;this._renderer.dispose(),this._renderer=e,this._renderer.onRequestRedraw((function(e){return t.refreshRows(e.start,e.end,!0)})),this._needsSelectionRefresh=!0,this._fullRefresh()},t.prototype._fullRefresh=function(){this._isPaused?this._needsFullRefresh=!0:this.refreshRows(0,this._rowCount-1)},t.prototype.clearTextureAtlas=function(){var e,t;null===(t=null===(e=this._renderer)||void 0===e?void 0:e.clearTextureAtlas)||void 0===t||t.call(e),this._fullRefresh()},t.prototype.setColors=function(e){this._renderer.setColors(e),this._fullRefresh()},t.prototype.onDevicePixelRatioChange=function(){this._charSizeService.measure(),this._renderer.onDevicePixelRatioChange(),this.refreshRows(0,this._rowCount-1)},t.prototype.onResize=function(e,t){this._renderer.onResize(e,t),this._fullRefresh()},t.prototype.onCharSizeChanged=function(){this._renderer.onCharSizeChanged()},t.prototype.onBlur=function(){this._renderer.onBlur()},t.prototype.onFocus=function(){this._renderer.onFocus()},t.prototype.onSelectionChanged=function(e,t,r){this._selectionState.start=e,this._selectionState.end=t,this._selectionState.columnSelectMode=r,this._renderer.onSelectionChanged(e,t,r)},t.prototype.onCursorMove=function(){this._renderer.onCursorMove()},t.prototype.clear=function(){this._renderer.clear()},o([s(3,f.IOptionsService),s(4,_.ICharSizeService),s(5,f.IBufferService)],t)}(l.Disposable);t.RenderService=d},9312:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)}),o=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},s=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.SelectionService=void 0;var a=r(6114),c=r(456),l=r(511),u=r(8460),h=r(4725),f=r(2585),_=r(9806),d=r(9504),p=r(844),v=r(4841),g=String.fromCharCode(160),y=new RegExp(g,"g"),m=function(e){function t(t,r,i,n,o,s,a,h){var f=e.call(this)||this;return f._element=t,f._screenElement=r,f._linkifier=i,f._bufferService=n,f._coreService=o,f._mouseService=s,f._optionsService=a,f._renderService=h,f._dragScrollAmount=0,f._enabled=!0,f._workCell=new l.CellData,f._mouseDownTimeStamp=0,f._oldHasSelection=!1,f._oldSelectionStart=void 0,f._oldSelectionEnd=void 0,f._onLinuxMouseSelection=f.register(new u.EventEmitter),f._onRedrawRequest=f.register(new u.EventEmitter),f._onSelectionChange=f.register(new u.EventEmitter),f._onRequestScrollLines=f.register(new u.EventEmitter),f._mouseMoveListener=function(e){return f._onMouseMove(e)},f._mouseUpListener=function(e){return f._onMouseUp(e)},f._coreService.onUserInput((function(){f.hasSelection&&f.clearSelection()})),f._trimListener=f._bufferService.buffer.lines.onTrim((function(e){return f._onTrim(e)})),f.register(f._bufferService.buffers.onBufferActivate((function(e){return f._onBufferActivate(e)}))),f.enable(),f._model=new c.SelectionModel(f._bufferService),f._activeSelectionMode=0,f}return n(t,e),Object.defineProperty(t.prototype,"onLinuxMouseSelection",{get:function(){return this._onLinuxMouseSelection.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onRequestRedraw",{get:function(){return this._onRedrawRequest.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onSelectionChange",{get:function(){return this._onSelectionChange.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onRequestScrollLines",{get:function(){return this._onRequestScrollLines.event},enumerable:!1,configurable:!0}),t.prototype.dispose=function(){this._removeMouseDownListeners()},t.prototype.reset=function(){this.clearSelection()},t.prototype.disable=function(){this.clearSelection(),this._enabled=!1},t.prototype.enable=function(){this._enabled=!0},Object.defineProperty(t.prototype,"selectionStart",{get:function(){return this._model.finalSelectionStart},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"selectionEnd",{get:function(){return this._model.finalSelectionEnd},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"hasSelection",{get:function(){var e=this._model.finalSelectionStart,t=this._model.finalSelectionEnd;return!(!e||!t||e[0]===t[0]&&e[1]===t[1])},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"selectionText",{get:function(){var e=this._model.finalSelectionStart,t=this._model.finalSelectionEnd;if(!e||!t)return"";var r=this._bufferService.buffer,i=[];if(3===this._activeSelectionMode){if(e[0]===t[0])return"";for(var n=e[1];n<=t[1];n++){var o=r.translateBufferLineToString(n,!0,e[0],t[0]);i.push(o)}}else{var s=e[1]===t[1]?t[0]:void 0;for(i.push(r.translateBufferLineToString(e[1],!0,e[0],s)),n=e[1]+1;n<=t[1]-1;n++){var c=r.lines.get(n);o=r.translateBufferLineToString(n,!0),(null==c?void 0:c.isWrapped)?i[i.length-1]+=o:i.push(o)}e[1]!==t[1]&&(c=r.lines.get(t[1]),o=r.translateBufferLineToString(t[1],!0,0,t[0]),c&&c.isWrapped?i[i.length-1]+=o:i.push(o))}return i.map((function(e){return e.replace(y," ")})).join(a.isWindows?"\r\n":"\n")},enumerable:!1,configurable:!0}),t.prototype.clearSelection=function(){this._model.clearSelection(),this._removeMouseDownListeners(),this.refresh(),this._onSelectionChange.fire()},t.prototype.refresh=function(e){var t=this;this._refreshAnimationFrame||(this._refreshAnimationFrame=window.requestAnimationFrame((function(){return t._refresh()}))),a.isLinux&&e&&this.selectionText.length&&this._onLinuxMouseSelection.fire(this.selectionText)},t.prototype._refresh=function(){this._refreshAnimationFrame=void 0,this._onRedrawRequest.fire({start:this._model.finalSelectionStart,end:this._model.finalSelectionEnd,columnSelectMode:3===this._activeSelectionMode})},t.prototype._isClickInSelection=function(e){var t=this._getMouseBufferCoords(e),r=this._model.finalSelectionStart,i=this._model.finalSelectionEnd;return!!(r&&i&&t)&&this._areCoordsInSelection(t,r,i)},t.prototype._areCoordsInSelection=function(e,t,r){return e[1]>t[1]&&e[1]<r[1]||t[1]===r[1]&&e[1]===t[1]&&e[0]>=t[0]&&e[0]<r[0]||t[1]<r[1]&&e[1]===r[1]&&e[0]<r[0]||t[1]<r[1]&&e[1]===t[1]&&e[0]>=t[0]},t.prototype._selectWordAtCursor=function(e,t){var r,i,n=null===(i=null===(r=this._linkifier.currentLink)||void 0===r?void 0:r.link)||void 0===i?void 0:i.range;if(n)return this._model.selectionStart=[n.start.x-1,n.start.y-1],this._model.selectionStartLength=(0,v.getRangeLength)(n,this._bufferService.cols),this._model.selectionEnd=void 0,!0;var o=this._getMouseBufferCoords(e);return!!o&&(this._selectWordAt(o,t),this._model.selectionEnd=void 0,!0)},t.prototype.selectAll=function(){this._model.isSelectAllActive=!0,this.refresh(),this._onSelectionChange.fire()},t.prototype.selectLines=function(e,t){this._model.clearSelection(),e=Math.max(e,0),t=Math.min(t,this._bufferService.buffer.lines.length-1),this._model.selectionStart=[0,e],this._model.selectionEnd=[this._bufferService.cols,t],this.refresh(),this._onSelectionChange.fire()},t.prototype._onTrim=function(e){this._model.onTrim(e)&&this.refresh()},t.prototype._getMouseBufferCoords=function(e){var t=this._mouseService.getCoords(e,this._screenElement,this._bufferService.cols,this._bufferService.rows,!0);if(t)return t[0]--,t[1]--,t[1]+=this._bufferService.buffer.ydisp,t},t.prototype._getMouseEventScrollAmount=function(e){var t=(0,_.getCoordsRelativeToElement)(e,this._screenElement)[1],r=this._renderService.dimensions.canvasHeight;return t>=0&&t<=r?0:(t>r&&(t-=r),t=Math.min(Math.max(t,-50),50),(t/=50)/Math.abs(t)+Math.round(14*t))},t.prototype.shouldForceSelection=function(e){return a.isMac?e.altKey&&this._optionsService.options.macOptionClickForcesSelection:e.shiftKey},t.prototype.onMouseDown=function(e){if(this._mouseDownTimeStamp=e.timeStamp,(2!==e.button||!this.hasSelection)&&0===e.button){if(!this._enabled){if(!this.shouldForceSelection(e))return;e.stopPropagation()}e.preventDefault(),this._dragScrollAmount=0,this._enabled&&e.shiftKey?this._onIncrementalClick(e):1===e.detail?this._onSingleClick(e):2===e.detail?this._onDoubleClick(e):3===e.detail&&this._onTripleClick(e),this._addMouseDownListeners(),this.refresh(!0)}},t.prototype._addMouseDownListeners=function(){var e=this;this._screenElement.ownerDocument&&(this._screenElement.ownerDocument.addEventListener("mousemove",this._mouseMoveListener),this._screenElement.ownerDocument.addEventListener("mouseup",this._mouseUpListener)),this._dragScrollIntervalTimer=window.setInterval((function(){return e._dragScroll()}),50)},t.prototype._removeMouseDownListeners=function(){this._screenElement.ownerDocument&&(this._screenElement.ownerDocument.removeEventListener("mousemove",this._mouseMoveListener),this._screenElement.ownerDocument.removeEventListener("mouseup",this._mouseUpListener)),clearInterval(this._dragScrollIntervalTimer),this._dragScrollIntervalTimer=void 0},t.prototype._onIncrementalClick=function(e){this._model.selectionStart&&(this._model.selectionEnd=this._getMouseBufferCoords(e))},t.prototype._onSingleClick=function(e){if(this._model.selectionStartLength=0,this._model.isSelectAllActive=!1,this._activeSelectionMode=this.shouldColumnSelect(e)?3:0,this._model.selectionStart=this._getMouseBufferCoords(e),this._model.selectionStart){this._model.selectionEnd=void 0;var t=this._bufferService.buffer.lines.get(this._model.selectionStart[1]);t&&t.length!==this._model.selectionStart[0]&&0===t.hasWidth(this._model.selectionStart[0])&&this._model.selectionStart[0]++}},t.prototype._onDoubleClick=function(e){this._selectWordAtCursor(e,!0)&&(this._activeSelectionMode=1)},t.prototype._onTripleClick=function(e){var t=this._getMouseBufferCoords(e);t&&(this._activeSelectionMode=2,this._selectLineAt(t[1]))},t.prototype.shouldColumnSelect=function(e){return e.altKey&&!(a.isMac&&this._optionsService.options.macOptionClickForcesSelection)},t.prototype._onMouseMove=function(e){if(e.stopImmediatePropagation(),this._model.selectionStart){var t=this._model.selectionEnd?[this._model.selectionEnd[0],this._model.selectionEnd[1]]:null;if(this._model.selectionEnd=this._getMouseBufferCoords(e),this._model.selectionEnd){2===this._activeSelectionMode?this._model.selectionEnd[1]<this._model.selectionStart[1]?this._model.selectionEnd[0]=0:this._model.selectionEnd[0]=this._bufferService.cols:1===this._activeSelectionMode&&this._selectToWordAt(this._model.selectionEnd),this._dragScrollAmount=this._getMouseEventScrollAmount(e),3!==this._activeSelectionMode&&(this._dragScrollAmount>0?this._model.selectionEnd[0]=this._bufferService.cols:this._dragScrollAmount<0&&(this._model.selectionEnd[0]=0));var r=this._bufferService.buffer;if(this._model.selectionEnd[1]<r.lines.length){var i=r.lines.get(this._model.selectionEnd[1]);i&&0===i.hasWidth(this._model.selectionEnd[0])&&this._model.selectionEnd[0]++}t&&t[0]===this._model.selectionEnd[0]&&t[1]===this._model.selectionEnd[1]||this.refresh(!0)}else this.refresh(!0)}},t.prototype._dragScroll=function(){if(this._model.selectionEnd&&this._model.selectionStart&&this._dragScrollAmount){this._onRequestScrollLines.fire({amount:this._dragScrollAmount,suppressScrollEvent:!1});var e=this._bufferService.buffer;this._dragScrollAmount>0?(3!==this._activeSelectionMode&&(this._model.selectionEnd[0]=this._bufferService.cols),this._model.selectionEnd[1]=Math.min(e.ydisp+this._bufferService.rows,e.lines.length-1)):(3!==this._activeSelectionMode&&(this._model.selectionEnd[0]=0),this._model.selectionEnd[1]=e.ydisp),this.refresh()}},t.prototype._onMouseUp=function(e){var t=e.timeStamp-this._mouseDownTimeStamp;if(this._removeMouseDownListeners(),this.selectionText.length<=1&&t<500&&e.altKey&&this._optionsService.getOption("altClickMovesCursor")){if(this._bufferService.buffer.ybase===this._bufferService.buffer.ydisp){var r=this._mouseService.getCoords(e,this._element,this._bufferService.cols,this._bufferService.rows,!1);if(r&&void 0!==r[0]&&void 0!==r[1]){var i=(0,d.moveToCellSequence)(r[0]-1,r[1]-1,this._bufferService,this._coreService.decPrivateModes.applicationCursorKeys);this._coreService.triggerDataEvent(i,!0)}}}else this._fireEventIfSelectionChanged()},t.prototype._fireEventIfSelectionChanged=function(){var e=this._model.finalSelectionStart,t=this._model.finalSelectionEnd,r=!(!e||!t||e[0]===t[0]&&e[1]===t[1]);r?e&&t&&(this._oldSelectionStart&&this._oldSelectionEnd&&e[0]===this._oldSelectionStart[0]&&e[1]===this._oldSelectionStart[1]&&t[0]===this._oldSelectionEnd[0]&&t[1]===this._oldSelectionEnd[1]||this._fireOnSelectionChange(e,t,r)):this._oldHasSelection&&this._fireOnSelectionChange(e,t,r)},t.prototype._fireOnSelectionChange=function(e,t,r){this._oldSelectionStart=e,this._oldSelectionEnd=t,this._oldHasSelection=r,this._onSelectionChange.fire()},t.prototype._onBufferActivate=function(e){var t=this;this.clearSelection(),this._trimListener.dispose(),this._trimListener=e.activeBuffer.lines.onTrim((function(e){return t._onTrim(e)}))},t.prototype._convertViewportColToCharacterIndex=function(e,t){for(var r=t[0],i=0;t[0]>=i;i++){var n=e.loadCell(i,this._workCell).getChars().length;0===this._workCell.getWidth()?r--:n>1&&t[0]!==i&&(r+=n-1)}return r},t.prototype.setSelection=function(e,t,r){this._model.clearSelection(),this._removeMouseDownListeners(),this._model.selectionStart=[e,t],this._model.selectionStartLength=r,this.refresh()},t.prototype.rightClickSelect=function(e){this._isClickInSelection(e)||(this._selectWordAtCursor(e,!1)&&this.refresh(!0),this._fireEventIfSelectionChanged())},t.prototype._getWordAt=function(e,t,r,i){if(void 0===r&&(r=!0),void 0===i&&(i=!0),!(e[0]>=this._bufferService.cols)){var n=this._bufferService.buffer,o=n.lines.get(e[1]);if(o){var s=n.translateBufferLineToString(e[1],!1),a=this._convertViewportColToCharacterIndex(o,e),c=a,l=e[0]-a,u=0,h=0,f=0,_=0;if(" "===s.charAt(a)){for(;a>0&&" "===s.charAt(a-1);)a--;for(;c<s.length&&" "===s.charAt(c+1);)c++}else{var d=e[0],p=e[0];0===o.getWidth(d)&&(u++,d--),2===o.getWidth(p)&&(h++,p++);var v=o.getString(p).length;for(v>1&&(_+=v-1,c+=v-1);d>0&&a>0&&!this._isCharWordSeparator(o.loadCell(d-1,this._workCell));){o.loadCell(d-1,this._workCell);var g=this._workCell.getChars().length;0===this._workCell.getWidth()?(u++,d--):g>1&&(f+=g-1,a-=g-1),a--,d--}for(;p<o.length&&c+1<s.length&&!this._isCharWordSeparator(o.loadCell(p+1,this._workCell));){o.loadCell(p+1,this._workCell);var y=this._workCell.getChars().length;2===this._workCell.getWidth()?(h++,p++):y>1&&(_+=y-1,c+=y-1),c++,p++}}c++;var m=a+l-u+f,b=Math.min(this._bufferService.cols,c-a+u+h-f-_);if(t||""!==s.slice(a,c).trim()){if(r&&0===m&&32!==o.getCodePoint(0)){var S=n.lines.get(e[1]-1);if(S&&o.isWrapped&&32!==S.getCodePoint(this._bufferService.cols-1)){var C=this._getWordAt([this._bufferService.cols-1,e[1]-1],!1,!0,!1);if(C){var w=this._bufferService.cols-C.start;m-=w,b+=w}}}if(i&&m+b===this._bufferService.cols&&32!==o.getCodePoint(this._bufferService.cols-1)){var L=n.lines.get(e[1]+1);if((null==L?void 0:L.isWrapped)&&32!==L.getCodePoint(0)){var E=this._getWordAt([0,e[1]+1],!1,!1,!0);E&&(b+=E.length)}}return{start:m,length:b}}}}},t.prototype._selectWordAt=function(e,t){var r=this._getWordAt(e,t);if(r){for(;r.start<0;)r.start+=this._bufferService.cols,e[1]--;this._model.selectionStart=[r.start,e[1]],this._model.selectionStartLength=r.length}},t.prototype._selectToWordAt=function(e){var t=this._getWordAt(e,!0);if(t){for(var r=e[1];t.start<0;)t.start+=this._bufferService.cols,r--;if(!this._model.areSelectionValuesReversed())for(;t.start+t.length>this._bufferService.cols;)t.length-=this._bufferService.cols,r++;this._model.selectionEnd=[this._model.areSelectionValuesReversed()?t.start:t.start+t.length,r]}},t.prototype._isCharWordSeparator=function(e){return 0!==e.getWidth()&&this._optionsService.options.wordSeparator.indexOf(e.getChars())>=0},t.prototype._selectLineAt=function(e){var t=this._bufferService.buffer.getWrappedRangeForLine(e);this._model.selectionStart=[0,t.first],this._model.selectionEnd=[this._bufferService.cols,t.last],this._model.selectionStartLength=0},o([s(3,f.IBufferService),s(4,f.ICoreService),s(5,h.IMouseService),s(6,f.IOptionsService),s(7,h.IRenderService)],t)}(p.Disposable);t.SelectionService=m},4725:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.ICharacterJoinerService=t.ISoundService=t.ISelectionService=t.IRenderService=t.IMouseService=t.ICoreBrowserService=t.ICharSizeService=void 0;var i=r(8343);t.ICharSizeService=(0,i.createDecorator)("CharSizeService"),t.ICoreBrowserService=(0,i.createDecorator)("CoreBrowserService"),t.IMouseService=(0,i.createDecorator)("MouseService"),t.IRenderService=(0,i.createDecorator)("RenderService"),t.ISelectionService=(0,i.createDecorator)("SelectionService"),t.ISoundService=(0,i.createDecorator)("SoundService"),t.ICharacterJoinerService=(0,i.createDecorator)("CharacterJoinerService")},357:function(e,t,r){var i=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},n=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.SoundService=void 0;var o=r(2585),s=function(){function e(e){this._optionsService=e}return Object.defineProperty(e,"audioContext",{get:function(){if(!e._audioContext){var t=window.AudioContext||window.webkitAudioContext;if(!t)return console.warn("Web Audio API is not supported by this browser. Consider upgrading to the latest version"),null;e._audioContext=new t}return e._audioContext},enumerable:!1,configurable:!0}),e.prototype.playBellSound=function(){var t=e.audioContext;if(t){var r=t.createBufferSource();t.decodeAudioData(this._base64ToArrayBuffer(this._removeMimeType(this._optionsService.options.bellSound)),(function(e){r.buffer=e,r.connect(t.destination),r.start(0)}))}},e.prototype._base64ToArrayBuffer=function(e){for(var t=window.atob(e),r=t.length,i=new Uint8Array(r),n=0;n<r;n++)i[n]=t.charCodeAt(n);return i.buffer},e.prototype._removeMimeType=function(e){return e.split(",")[1]},e=i([n(0,o.IOptionsService)],e)}();t.SoundService=s},6349:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.CircularList=void 0;var i=r(8460),n=function(){function e(e){this._maxLength=e,this.onDeleteEmitter=new i.EventEmitter,this.onInsertEmitter=new i.EventEmitter,this.onTrimEmitter=new i.EventEmitter,this._array=new Array(this._maxLength),this._startIndex=0,this._length=0}return Object.defineProperty(e.prototype,"onDelete",{get:function(){return this.onDeleteEmitter.event},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"onInsert",{get:function(){return this.onInsertEmitter.event},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"onTrim",{get:function(){return this.onTrimEmitter.event},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"maxLength",{get:function(){return this._maxLength},set:function(e){if(this._maxLength!==e){for(var t=new Array(e),r=0;r<Math.min(e,this.length);r++)t[r]=this._array[this._getCyclicIndex(r)];this._array=t,this._maxLength=e,this._startIndex=0}},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"length",{get:function(){return this._length},set:function(e){if(e>this._length)for(var t=this._length;t<e;t++)this._array[t]=void 0;this._length=e},enumerable:!1,configurable:!0}),e.prototype.get=function(e){return this._array[this._getCyclicIndex(e)]},e.prototype.set=function(e,t){this._array[this._getCyclicIndex(e)]=t},e.prototype.push=function(e){this._array[this._getCyclicIndex(this._length)]=e,this._length===this._maxLength?(this._startIndex=++this._startIndex%this._maxLength,this.onTrimEmitter.fire(1)):this._length++},e.prototype.recycle=function(){if(this._length!==this._maxLength)throw new Error("Can only recycle when the buffer is full");return this._startIndex=++this._startIndex%this._maxLength,this.onTrimEmitter.fire(1),this._array[this._getCyclicIndex(this._length-1)]},Object.defineProperty(e.prototype,"isFull",{get:function(){return this._length===this._maxLength},enumerable:!1,configurable:!0}),e.prototype.pop=function(){return this._array[this._getCyclicIndex(this._length---1)]},e.prototype.splice=function(e,t){for(var r=[],i=2;i<arguments.length;i++)r[i-2]=arguments[i];if(t){for(var n=e;n<this._length-t;n++)this._array[this._getCyclicIndex(n)]=this._array[this._getCyclicIndex(n+t)];this._length-=t,this.onDeleteEmitter.fire({index:e,amount:t})}for(n=this._length-1;n>=e;n--)this._array[this._getCyclicIndex(n+r.length)]=this._array[this._getCyclicIndex(n)];for(n=0;n<r.length;n++)this._array[this._getCyclicIndex(e+n)]=r[n];if(r.length&&this.onInsertEmitter.fire({index:e,amount:r.length}),this._length+r.length>this._maxLength){var o=this._length+r.length-this._maxLength;this._startIndex+=o,this._length=this._maxLength,this.onTrimEmitter.fire(o)}else this._length+=r.length},e.prototype.trimStart=function(e){e>this._length&&(e=this._length),this._startIndex+=e,this._length-=e,this.onTrimEmitter.fire(e)},e.prototype.shiftElements=function(e,t,r){if(!(t<=0)){if(e<0||e>=this._length)throw new Error("start argument out of range");if(e+r<0)throw new Error("Cannot shift elements in list beyond index 0");if(r>0){for(var i=t-1;i>=0;i--)this.set(e+i+r,this.get(e+i));var n=e+t+r-this._length;if(n>0)for(this._length+=n;this._length>this._maxLength;)this._length--,this._startIndex++,this.onTrimEmitter.fire(1)}else for(i=0;i<t;i++)this.set(e+i+r,this.get(e+i))}},e.prototype._getCyclicIndex=function(e){return(this._startIndex+e)%this._maxLength},e}();t.CircularList=n},1439:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.clone=void 0,t.clone=function e(t,r){if(void 0===r&&(r=5),"object"!=typeof t)return t;var i=Array.isArray(t)?[]:{};for(var n in t)i[n]=r<=1?t[n]:t[n]&&e(t[n],r-1);return i}},8969:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)});Object.defineProperty(t,"__esModule",{value:!0}),t.CoreTerminal=void 0;var o=r(844),s=r(2585),a=r(4348),c=r(7866),l=r(744),u=r(7302),h=r(6975),f=r(8460),_=r(1753),d=r(3730),p=r(1480),v=r(7994),g=r(9282),y=r(5435),m=r(5981),b=!1,S=function(e){function t(t){var r=e.call(this)||this;return r._onBinary=new f.EventEmitter,r._onData=new f.EventEmitter,r._onLineFeed=new f.EventEmitter,r._onResize=new f.EventEmitter,r._onScroll=new f.EventEmitter,r._instantiationService=new a.InstantiationService,r.optionsService=new u.OptionsService(t),r._instantiationService.setService(s.IOptionsService,r.optionsService),r._bufferService=r.register(r._instantiationService.createInstance(l.BufferService)),r._instantiationService.setService(s.IBufferService,r._bufferService),r._logService=r._instantiationService.createInstance(c.LogService),r._instantiationService.setService(s.ILogService,r._logService),r.coreService=r.register(r._instantiationService.createInstance(h.CoreService,(function(){return r.scrollToBottom()}))),r._instantiationService.setService(s.ICoreService,r.coreService),r.coreMouseService=r._instantiationService.createInstance(_.CoreMouseService),r._instantiationService.setService(s.ICoreMouseService,r.coreMouseService),r._dirtyRowService=r._instantiationService.createInstance(d.DirtyRowService),r._instantiationService.setService(s.IDirtyRowService,r._dirtyRowService),r.unicodeService=r._instantiationService.createInstance(p.UnicodeService),r._instantiationService.setService(s.IUnicodeService,r.unicodeService),r._charsetService=r._instantiationService.createInstance(v.CharsetService),r._instantiationService.setService(s.ICharsetService,r._charsetService),r._inputHandler=new y.InputHandler(r._bufferService,r._charsetService,r.coreService,r._dirtyRowService,r._logService,r.optionsService,r.coreMouseService,r.unicodeService),r.register((0,f.forwardEvent)(r._inputHandler.onLineFeed,r._onLineFeed)),r.register(r._inputHandler),r.register((0,f.forwardEvent)(r._bufferService.onResize,r._onResize)),r.register((0,f.forwardEvent)(r.coreService.onData,r._onData)),r.register((0,f.forwardEvent)(r.coreService.onBinary,r._onBinary)),r.register(r.optionsService.onOptionChange((function(e){return r._updateOptions(e)}))),r.register(r._bufferService.onScroll((function(e){r._onScroll.fire({position:r._bufferService.buffer.ydisp,source:0}),r._dirtyRowService.markRangeDirty(r._bufferService.buffer.scrollTop,r._bufferService.buffer.scrollBottom)}))),r.register(r._inputHandler.onScroll((function(e){r._onScroll.fire({position:r._bufferService.buffer.ydisp,source:0}),r._dirtyRowService.markRangeDirty(r._bufferService.buffer.scrollTop,r._bufferService.buffer.scrollBottom)}))),r._writeBuffer=new m.WriteBuffer((function(e,t){return r._inputHandler.parse(e,t)})),r}return n(t,e),Object.defineProperty(t.prototype,"onBinary",{get:function(){return this._onBinary.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onData",{get:function(){return this._onData.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onLineFeed",{get:function(){return this._onLineFeed.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onResize",{get:function(){return this._onResize.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onScroll",{get:function(){var e=this;return this._onScrollApi||(this._onScrollApi=new f.EventEmitter,this.register(this._onScroll.event((function(t){var r;null===(r=e._onScrollApi)||void 0===r||r.fire(t.position)})))),this._onScrollApi.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"cols",{get:function(){return this._bufferService.cols},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"rows",{get:function(){return this._bufferService.rows},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"buffers",{get:function(){return this._bufferService.buffers},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"options",{get:function(){return this.optionsService.options},set:function(e){for(var t in e)this.optionsService.options[t]=e[t]},enumerable:!1,configurable:!0}),t.prototype.dispose=function(){var t;this._isDisposed||(e.prototype.dispose.call(this),null===(t=this._windowsMode)||void 0===t||t.dispose(),this._windowsMode=void 0)},t.prototype.write=function(e,t){this._writeBuffer.write(e,t)},t.prototype.writeSync=function(e,t){this._logService.logLevel<=s.LogLevelEnum.WARN&&!b&&(this._logService.warn("writeSync is unreliable and will be removed soon."),b=!0),this._writeBuffer.writeSync(e,t)},t.prototype.resize=function(e,t){isNaN(e)||isNaN(t)||(e=Math.max(e,l.MINIMUM_COLS),t=Math.max(t,l.MINIMUM_ROWS),this._bufferService.resize(e,t))},t.prototype.scroll=function(e,t){void 0===t&&(t=!1),this._bufferService.scroll(e,t)},t.prototype.scrollLines=function(e,t,r){this._bufferService.scrollLines(e,t,r)},t.prototype.scrollPages=function(e){this._bufferService.scrollPages(e)},t.prototype.scrollToTop=function(){this._bufferService.scrollToTop()},t.prototype.scrollToBottom=function(){this._bufferService.scrollToBottom()},t.prototype.scrollToLine=function(e){this._bufferService.scrollToLine(e)},t.prototype.registerEscHandler=function(e,t){return this._inputHandler.registerEscHandler(e,t)},t.prototype.registerDcsHandler=function(e,t){return this._inputHandler.registerDcsHandler(e,t)},t.prototype.registerCsiHandler=function(e,t){return this._inputHandler.registerCsiHandler(e,t)},t.prototype.registerOscHandler=function(e,t){return this._inputHandler.registerOscHandler(e,t)},t.prototype._setup=function(){this.optionsService.options.windowsMode&&this._enableWindowsMode()},t.prototype.reset=function(){this._inputHandler.reset(),this._bufferService.reset(),this._charsetService.reset(),this.coreService.reset(),this.coreMouseService.reset()},t.prototype._updateOptions=function(e){var t;switch(e){case"scrollback":this.buffers.resize(this.cols,this.rows);break;case"windowsMode":this.optionsService.options.windowsMode?this._enableWindowsMode():(null===(t=this._windowsMode)||void 0===t||t.dispose(),this._windowsMode=void 0)}},t.prototype._enableWindowsMode=function(){var e=this;if(!this._windowsMode){var t=[];t.push(this.onLineFeed(g.updateWindowsModeWrappedState.bind(null,this._bufferService))),t.push(this.registerCsiHandler({final:"H"},(function(){return(0,g.updateWindowsModeWrappedState)(e._bufferService),!1}))),this._windowsMode={dispose:function(){for(var e=0,r=t;e<r.length;e++)r[e].dispose()}}}},t}(o.Disposable);t.CoreTerminal=S},8460:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.forwardEvent=t.EventEmitter=void 0;var r=function(){function e(){this._listeners=[],this._disposed=!1}return Object.defineProperty(e.prototype,"event",{get:function(){var e=this;return this._event||(this._event=function(t){return e._listeners.push(t),{dispose:function(){if(!e._disposed)for(var r=0;r<e._listeners.length;r++)if(e._listeners[r]===t)return void e._listeners.splice(r,1)}}}),this._event},enumerable:!1,configurable:!0}),e.prototype.fire=function(e,t){for(var r=[],i=0;i<this._listeners.length;i++)r.push(this._listeners[i]);for(i=0;i<r.length;i++)r[i].call(void 0,e,t)},e.prototype.dispose=function(){this._listeners&&(this._listeners.length=0),this._disposed=!0},e}();t.EventEmitter=r,t.forwardEvent=function(e,t){return e((function(e){return t.fire(e)}))}},5435:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)});Object.defineProperty(t,"__esModule",{value:!0}),t.InputHandler=t.WindowsOptionsReportType=void 0;var o,s=r(2584),a=r(7116),c=r(2015),l=r(844),u=r(8273),h=r(482),f=r(8437),_=r(8460),d=r(643),p=r(511),v=r(3734),g=r(2585),y=r(6242),m=r(6351),b=r(5941),S={"(":0,")":1,"*":2,"+":3,"-":1,".":2},C=131072;function w(e,t){if(e>24)return t.setWinLines||!1;switch(e){case 1:return!!t.restoreWin;case 2:return!!t.minimizeWin;case 3:return!!t.setWinPosition;case 4:return!!t.setWinSizePixels;case 5:return!!t.raiseWin;case 6:return!!t.lowerWin;case 7:return!!t.refreshWin;case 8:return!!t.setWinSizeChars;case 9:return!!t.maximizeWin;case 10:return!!t.fullscreenWin;case 11:return!!t.getWinState;case 13:return!!t.getWinPosition;case 14:return!!t.getWinSizePixels;case 15:return!!t.getScreenSizePixels;case 16:return!!t.getCellSizePixels;case 18:return!!t.getWinSizeChars;case 19:return!!t.getScreenSizeChars;case 20:return!!t.getIconTitle;case 21:return!!t.getWinTitle;case 22:return!!t.pushTitle;case 23:return!!t.popTitle;case 24:return!!t.setWinLines}return!1}!function(e){e[e.GET_WIN_SIZE_PIXELS=0]="GET_WIN_SIZE_PIXELS",e[e.GET_CELL_SIZE_PIXELS=1]="GET_CELL_SIZE_PIXELS"}(o=t.WindowsOptionsReportType||(t.WindowsOptionsReportType={}));var L=function(){function e(e,t,r,i){this._bufferService=e,this._coreService=t,this._logService=r,this._optionsService=i,this._data=new Uint32Array(0)}return e.prototype.hook=function(e){this._data=new Uint32Array(0)},e.prototype.put=function(e,t,r){this._data=(0,u.concat)(this._data,e.subarray(t,r))},e.prototype.unhook=function(e){if(!e)return this._data=new Uint32Array(0),!0;var t=(0,h.utf32ToString)(this._data);switch(this._data=new Uint32Array(0),t){case'"q':this._coreService.triggerDataEvent(s.C0.ESC+'P1$r0"q'+s.C0.ESC+"\\");break;case'"p':this._coreService.triggerDataEvent(s.C0.ESC+'P1$r61;1"p'+s.C0.ESC+"\\");break;case"r":var r=this._bufferService.buffer.scrollTop+1+";"+(this._bufferService.buffer.scrollBottom+1)+"r";this._coreService.triggerDataEvent(s.C0.ESC+"P1$r"+r+s.C0.ESC+"\\");break;case"m":this._coreService.triggerDataEvent(s.C0.ESC+"P1$r0m"+s.C0.ESC+"\\");break;case" q":var i={block:2,underline:4,bar:6}[this._optionsService.options.cursorStyle];i-=this._optionsService.options.cursorBlink?1:0,this._coreService.triggerDataEvent(s.C0.ESC+"P1$r"+i+" q"+s.C0.ESC+"\\");break;default:this._logService.debug("Unknown DCS $q %s",t),this._coreService.triggerDataEvent(s.C0.ESC+"P0$r"+s.C0.ESC+"\\")}return!0},e}(),E=function(e){function t(t,r,i,n,o,l,u,d,v){void 0===v&&(v=new c.EscapeSequenceParser);var g=e.call(this)||this;g._bufferService=t,g._charsetService=r,g._coreService=i,g._dirtyRowService=n,g._logService=o,g._optionsService=l,g._coreMouseService=u,g._unicodeService=d,g._parser=v,g._parseBuffer=new Uint32Array(4096),g._stringDecoder=new h.StringToUtf32,g._utf8Decoder=new h.Utf8ToUtf32,g._workCell=new p.CellData,g._windowTitle="",g._iconName="",g._windowTitleStack=[],g._iconNameStack=[],g._curAttrData=f.DEFAULT_ATTR_DATA.clone(),g._eraseAttrDataInternal=f.DEFAULT_ATTR_DATA.clone(),g._onRequestBell=new _.EventEmitter,g._onRequestRefreshRows=new _.EventEmitter,g._onRequestReset=new _.EventEmitter,g._onRequestSendFocus=new _.EventEmitter,g._onRequestSyncScrollBar=new _.EventEmitter,g._onRequestWindowsOptionsReport=new _.EventEmitter,g._onA11yChar=new _.EventEmitter,g._onA11yTab=new _.EventEmitter,g._onCursorMove=new _.EventEmitter,g._onLineFeed=new _.EventEmitter,g._onScroll=new _.EventEmitter,g._onTitleChange=new _.EventEmitter,g._onColor=new _.EventEmitter,g._parseStack={paused:!1,cursorStartX:0,cursorStartY:0,decodedLength:0,position:0},g._specialColors=[256,257,258],g.register(g._parser),g._activeBuffer=g._bufferService.buffer,g.register(g._bufferService.buffers.onBufferActivate((function(e){return g._activeBuffer=e.activeBuffer}))),g._parser.setCsiHandlerFallback((function(e,t){g._logService.debug("Unknown CSI code: ",{identifier:g._parser.identToString(e),params:t.toArray()})})),g._parser.setEscHandlerFallback((function(e){g._logService.debug("Unknown ESC code: ",{identifier:g._parser.identToString(e)})})),g._parser.setExecuteHandlerFallback((function(e){g._logService.debug("Unknown EXECUTE code: ",{code:e})})),g._parser.setOscHandlerFallback((function(e,t,r){g._logService.debug("Unknown OSC code: ",{identifier:e,action:t,data:r})})),g._parser.setDcsHandlerFallback((function(e,t,r){"HOOK"===t&&(r=r.toArray()),g._logService.debug("Unknown DCS code: ",{identifier:g._parser.identToString(e),action:t,payload:r})})),g._parser.setPrintHandler((function(e,t,r){return g.print(e,t,r)})),g._parser.registerCsiHandler({final:"@"},(function(e){return g.insertChars(e)})),g._parser.registerCsiHandler({intermediates:" ",final:"@"},(function(e){return g.scrollLeft(e)})),g._parser.registerCsiHandler({final:"A"},(function(e){return g.cursorUp(e)})),g._parser.registerCsiHandler({intermediates:" ",final:"A"},(function(e){return g.scrollRight(e)})),g._parser.registerCsiHandler({final:"B"},(function(e){return g.cursorDown(e)})),g._parser.registerCsiHandler({final:"C"},(function(e){return g.cursorForward(e)})),g._parser.registerCsiHandler({final:"D"},(function(e){return g.cursorBackward(e)})),g._parser.registerCsiHandler({final:"E"},(function(e){return g.cursorNextLine(e)})),g._parser.registerCsiHandler({final:"F"},(function(e){return g.cursorPrecedingLine(e)})),g._parser.registerCsiHandler({final:"G"},(function(e){return g.cursorCharAbsolute(e)})),g._parser.registerCsiHandler({final:"H"},(function(e){return g.cursorPosition(e)})),g._parser.registerCsiHandler({final:"I"},(function(e){return g.cursorForwardTab(e)})),g._parser.registerCsiHandler({final:"J"},(function(e){return g.eraseInDisplay(e)})),g._parser.registerCsiHandler({prefix:"?",final:"J"},(function(e){return g.eraseInDisplay(e)})),g._parser.registerCsiHandler({final:"K"},(function(e){return g.eraseInLine(e)})),g._parser.registerCsiHandler({prefix:"?",final:"K"},(function(e){return g.eraseInLine(e)})),g._parser.registerCsiHandler({final:"L"},(function(e){return g.insertLines(e)})),g._parser.registerCsiHandler({final:"M"},(function(e){return g.deleteLines(e)})),g._parser.registerCsiHandler({final:"P"},(function(e){return g.deleteChars(e)})),g._parser.registerCsiHandler({final:"S"},(function(e){return g.scrollUp(e)})),g._parser.registerCsiHandler({final:"T"},(function(e){return g.scrollDown(e)})),g._parser.registerCsiHandler({final:"X"},(function(e){return g.eraseChars(e)})),g._parser.registerCsiHandler({final:"Z"},(function(e){return g.cursorBackwardTab(e)})),g._parser.registerCsiHandler({final:"`"},(function(e){return g.charPosAbsolute(e)})),g._parser.registerCsiHandler({final:"a"},(function(e){return g.hPositionRelative(e)})),g._parser.registerCsiHandler({final:"b"},(function(e){return g.repeatPrecedingCharacter(e)})),g._parser.registerCsiHandler({final:"c"},(function(e){return g.sendDeviceAttributesPrimary(e)})),g._parser.registerCsiHandler({prefix:">",final:"c"},(function(e){return g.sendDeviceAttributesSecondary(e)})),g._parser.registerCsiHandler({final:"d"},(function(e){return g.linePosAbsolute(e)})),g._parser.registerCsiHandler({final:"e"},(function(e){return g.vPositionRelative(e)})),g._parser.registerCsiHandler({final:"f"},(function(e){return g.hVPosition(e)})),g._parser.registerCsiHandler({final:"g"},(function(e){return g.tabClear(e)})),g._parser.registerCsiHandler({final:"h"},(function(e){return g.setMode(e)})),g._parser.registerCsiHandler({prefix:"?",final:"h"},(function(e){return g.setModePrivate(e)})),g._parser.registerCsiHandler({final:"l"},(function(e){return g.resetMode(e)})),g._parser.registerCsiHandler({prefix:"?",final:"l"},(function(e){return g.resetModePrivate(e)})),g._parser.registerCsiHandler({final:"m"},(function(e){return g.charAttributes(e)})),g._parser.registerCsiHandler({final:"n"},(function(e){return g.deviceStatus(e)})),g._parser.registerCsiHandler({prefix:"?",final:"n"},(function(e){return g.deviceStatusPrivate(e)})),g._parser.registerCsiHandler({intermediates:"!",final:"p"},(function(e){return g.softReset(e)})),g._parser.registerCsiHandler({intermediates:" ",final:"q"},(function(e){return g.setCursorStyle(e)})),g._parser.registerCsiHandler({final:"r"},(function(e){return g.setScrollRegion(e)})),g._parser.registerCsiHandler({final:"s"},(function(e){return g.saveCursor(e)})),g._parser.registerCsiHandler({final:"t"},(function(e){return g.windowOptions(e)})),g._parser.registerCsiHandler({final:"u"},(function(e){return g.restoreCursor(e)})),g._parser.registerCsiHandler({intermediates:"'",final:"}"},(function(e){return g.insertColumns(e)})),g._parser.registerCsiHandler({intermediates:"'",final:"~"},(function(e){return g.deleteColumns(e)})),g._parser.setExecuteHandler(s.C0.BEL,(function(){return g.bell()})),g._parser.setExecuteHandler(s.C0.LF,(function(){return g.lineFeed()})),g._parser.setExecuteHandler(s.C0.VT,(function(){return g.lineFeed()})),g._parser.setExecuteHandler(s.C0.FF,(function(){return g.lineFeed()})),g._parser.setExecuteHandler(s.C0.CR,(function(){return g.carriageReturn()})),g._parser.setExecuteHandler(s.C0.BS,(function(){return g.backspace()})),g._parser.setExecuteHandler(s.C0.HT,(function(){return g.tab()})),g._parser.setExecuteHandler(s.C0.SO,(function(){return g.shiftOut()})),g._parser.setExecuteHandler(s.C0.SI,(function(){return g.shiftIn()})),g._parser.setExecuteHandler(s.C1.IND,(function(){return g.index()})),g._parser.setExecuteHandler(s.C1.NEL,(function(){return g.nextLine()})),g._parser.setExecuteHandler(s.C1.HTS,(function(){return g.tabSet()})),g._parser.registerOscHandler(0,new y.OscHandler((function(e){return g.setTitle(e),g.setIconName(e),!0}))),g._parser.registerOscHandler(1,new y.OscHandler((function(e){return g.setIconName(e)}))),g._parser.registerOscHandler(2,new y.OscHandler((function(e){return g.setTitle(e)}))),g._parser.registerOscHandler(4,new y.OscHandler((function(e){return g.setOrReportIndexedColor(e)}))),g._parser.registerOscHandler(10,new y.OscHandler((function(e){return g.setOrReportFgColor(e)}))),g._parser.registerOscHandler(11,new y.OscHandler((function(e){return g.setOrReportBgColor(e)}))),g._parser.registerOscHandler(12,new y.OscHandler((function(e){return g.setOrReportCursorColor(e)}))),g._parser.registerOscHandler(104,new y.OscHandler((function(e){return g.restoreIndexedColor(e)}))),g._parser.registerOscHandler(110,new y.OscHandler((function(e){return g.restoreFgColor(e)}))),g._parser.registerOscHandler(111,new y.OscHandler((function(e){return g.restoreBgColor(e)}))),g._parser.registerOscHandler(112,new y.OscHandler((function(e){return g.restoreCursorColor(e)}))),g._parser.registerEscHandler({final:"7"},(function(){return g.saveCursor()})),g._parser.registerEscHandler({final:"8"},(function(){return g.restoreCursor()})),g._parser.registerEscHandler({final:"D"},(function(){return g.index()})),g._parser.registerEscHandler({final:"E"},(function(){return g.nextLine()})),g._parser.registerEscHandler({final:"H"},(function(){return g.tabSet()})),g._parser.registerEscHandler({final:"M"},(function(){return g.reverseIndex()})),g._parser.registerEscHandler({final:"="},(function(){return g.keypadApplicationMode()})),g._parser.registerEscHandler({final:">"},(function(){return g.keypadNumericMode()})),g._parser.registerEscHandler({final:"c"},(function(){return g.fullReset()})),g._parser.registerEscHandler({final:"n"},(function(){return g.setgLevel(2)})),g._parser.registerEscHandler({final:"o"},(function(){return g.setgLevel(3)})),g._parser.registerEscHandler({final:"|"},(function(){return g.setgLevel(3)})),g._parser.registerEscHandler({final:"}"},(function(){return g.setgLevel(2)})),g._parser.registerEscHandler({final:"~"},(function(){return g.setgLevel(1)})),g._parser.registerEscHandler({intermediates:"%",final:"@"},(function(){return g.selectDefaultCharset()})),g._parser.registerEscHandler({intermediates:"%",final:"G"},(function(){return g.selectDefaultCharset()}));var m=function(e){b._parser.registerEscHandler({intermediates:"(",final:e},(function(){return g.selectCharset("("+e)})),b._parser.registerEscHandler({intermediates:")",final:e},(function(){return g.selectCharset(")"+e)})),b._parser.registerEscHandler({intermediates:"*",final:e},(function(){return g.selectCharset("*"+e)})),b._parser.registerEscHandler({intermediates:"+",final:e},(function(){return g.selectCharset("+"+e)})),b._parser.registerEscHandler({intermediates:"-",final:e},(function(){return g.selectCharset("-"+e)})),b._parser.registerEscHandler({intermediates:".",final:e},(function(){return g.selectCharset("."+e)})),b._parser.registerEscHandler({intermediates:"/",final:e},(function(){return g.selectCharset("/"+e)}))},b=this;for(var S in a.CHARSETS)m(S);return g._parser.registerEscHandler({intermediates:"#",final:"8"},(function(){return g.screenAlignmentPattern()})),g._parser.setErrorHandler((function(e){return g._logService.error("Parsing error: ",e),e})),g._parser.registerDcsHandler({intermediates:"$",final:"q"},new L(g._bufferService,g._coreService,g._logService,g._optionsService)),g}return n(t,e),Object.defineProperty(t.prototype,"onRequestBell",{get:function(){return this._onRequestBell.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onRequestRefreshRows",{get:function(){return this._onRequestRefreshRows.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onRequestReset",{get:function(){return this._onRequestReset.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onRequestSendFocus",{get:function(){return this._onRequestSendFocus.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onRequestSyncScrollBar",{get:function(){return this._onRequestSyncScrollBar.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onRequestWindowsOptionsReport",{get:function(){return this._onRequestWindowsOptionsReport.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onA11yChar",{get:function(){return this._onA11yChar.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onA11yTab",{get:function(){return this._onA11yTab.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onCursorMove",{get:function(){return this._onCursorMove.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onLineFeed",{get:function(){return this._onLineFeed.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onScroll",{get:function(){return this._onScroll.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onTitleChange",{get:function(){return this._onTitleChange.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onColor",{get:function(){return this._onColor.event},enumerable:!1,configurable:!0}),t.prototype.dispose=function(){e.prototype.dispose.call(this)},t.prototype._preserveStack=function(e,t,r,i){this._parseStack.paused=!0,this._parseStack.cursorStartX=e,this._parseStack.cursorStartY=t,this._parseStack.decodedLength=r,this._parseStack.position=i},t.prototype._logSlowResolvingAsync=function(e){this._logService.logLevel<=g.LogLevelEnum.WARN&&Promise.race([e,new Promise((function(e,t){return setTimeout((function(){return t("#SLOW_TIMEOUT")}),5e3)}))]).catch((function(e){if("#SLOW_TIMEOUT"!==e)throw e;console.warn("async parser handler taking longer than 5000 ms")}))},t.prototype.parse=function(e,t){var r,i=this._activeBuffer.x,n=this._activeBuffer.y,o=0,s=this._parseStack.paused;if(s){if(r=this._parser.parse(this._parseBuffer,this._parseStack.decodedLength,t))return this._logSlowResolvingAsync(r),r;i=this._parseStack.cursorStartX,n=this._parseStack.cursorStartY,this._parseStack.paused=!1,e.length>C&&(o=this._parseStack.position+C)}if(this._logService.logLevel<=g.LogLevelEnum.DEBUG&&this._logService.debug("parsing data"+("string"==typeof e?' "'+e+'"':""),"string"==typeof e?e.split("").map((function(e){return e.charCodeAt(0)})):e),this._parseBuffer.length<e.length&&this._parseBuffer.length<C&&(this._parseBuffer=new Uint32Array(Math.min(e.length,C))),s||this._dirtyRowService.clearRange(),e.length>C)for(var a=o;a<e.length;a+=C){var c=a+C<e.length?a+C:e.length,l="string"==typeof e?this._stringDecoder.decode(e.substring(a,c),this._parseBuffer):this._utf8Decoder.decode(e.subarray(a,c),this._parseBuffer);if(r=this._parser.parse(this._parseBuffer,l))return this._preserveStack(i,n,l,a),this._logSlowResolvingAsync(r),r}else if(!s&&(l="string"==typeof e?this._stringDecoder.decode(e,this._parseBuffer):this._utf8Decoder.decode(e,this._parseBuffer),r=this._parser.parse(this._parseBuffer,l)))return this._preserveStack(i,n,l,0),this._logSlowResolvingAsync(r),r;this._activeBuffer.x===i&&this._activeBuffer.y===n||this._onCursorMove.fire(),this._onRequestRefreshRows.fire(this._dirtyRowService.start,this._dirtyRowService.end)},t.prototype.print=function(e,t,r){var i,n,o=this._charsetService.charset,s=this._optionsService.options.screenReaderMode,a=this._bufferService.cols,c=this._coreService.decPrivateModes.wraparound,l=this._coreService.modes.insertMode,u=this._curAttrData,f=this._activeBuffer.lines.get(this._activeBuffer.ybase+this._activeBuffer.y);this._dirtyRowService.markDirty(this._activeBuffer.y),this._activeBuffer.x&&r-t>0&&2===f.getWidth(this._activeBuffer.x-1)&&f.setCellFromCodePoint(this._activeBuffer.x-1,0,1,u.fg,u.bg,u.extended);for(var _=t;_<r;++_){if(i=e[_],n=this._unicodeService.wcwidth(i),i<127&&o){var p=o[String.fromCharCode(i)];p&&(i=p.charCodeAt(0))}if(s&&this._onA11yChar.fire((0,h.stringFromCodePoint)(i)),n||!this._activeBuffer.x){if(this._activeBuffer.x+n-1>=a)if(c){for(;this._activeBuffer.x<a;)f.setCellFromCodePoint(this._activeBuffer.x++,0,1,u.fg,u.bg,u.extended);this._activeBuffer.x=0,this._activeBuffer.y++,this._activeBuffer.y===this._activeBuffer.scrollBottom+1?(this._activeBuffer.y--,this._bufferService.scroll(this._eraseAttrData(),!0)):(this._activeBuffer.y>=this._bufferService.rows&&(this._activeBuffer.y=this._bufferService.rows-1),this._activeBuffer.lines.get(this._activeBuffer.ybase+this._activeBuffer.y).isWrapped=!0),f=this._activeBuffer.lines.get(this._activeBuffer.ybase+this._activeBuffer.y)}else if(this._activeBuffer.x=a-1,2===n)continue;if(l&&(f.insertCells(this._activeBuffer.x,n,this._activeBuffer.getNullCell(u),u),2===f.getWidth(a-1)&&f.setCellFromCodePoint(a-1,d.NULL_CELL_CODE,d.NULL_CELL_WIDTH,u.fg,u.bg,u.extended)),f.setCellFromCodePoint(this._activeBuffer.x++,i,n,u.fg,u.bg,u.extended),n>0)for(;--n;)f.setCellFromCodePoint(this._activeBuffer.x++,0,0,u.fg,u.bg,u.extended)}else f.getWidth(this._activeBuffer.x-1)?f.addCodepointToCell(this._activeBuffer.x-1,i):f.addCodepointToCell(this._activeBuffer.x-2,i)}r-t>0&&(f.loadCell(this._activeBuffer.x-1,this._workCell),2===this._workCell.getWidth()||this._workCell.getCode()>65535?this._parser.precedingCodepoint=0:this._workCell.isCombined()?this._parser.precedingCodepoint=this._workCell.getChars().charCodeAt(0):this._parser.precedingCodepoint=this._workCell.content),this._activeBuffer.x<a&&r-t>0&&0===f.getWidth(this._activeBuffer.x)&&!f.hasContent(this._activeBuffer.x)&&f.setCellFromCodePoint(this._activeBuffer.x,0,1,u.fg,u.bg,u.extended),this._dirtyRowService.markDirty(this._activeBuffer.y)},t.prototype.registerCsiHandler=function(e,t){var r=this;return"t"!==e.final||e.prefix||e.intermediates?this._parser.registerCsiHandler(e,t):this._parser.registerCsiHandler(e,(function(e){return!w(e.params[0],r._optionsService.options.windowOptions)||t(e)}))},t.prototype.registerDcsHandler=function(e,t){return this._parser.registerDcsHandler(e,new m.DcsHandler(t))},t.prototype.registerEscHandler=function(e,t){return this._parser.registerEscHandler(e,t)},t.prototype.registerOscHandler=function(e,t){return this._parser.registerOscHandler(e,new y.OscHandler(t))},t.prototype.bell=function(){return this._onRequestBell.fire(),!0},t.prototype.lineFeed=function(){return this._dirtyRowService.markDirty(this._activeBuffer.y),this._optionsService.options.convertEol&&(this._activeBuffer.x=0),this._activeBuffer.y++,this._activeBuffer.y===this._activeBuffer.scrollBottom+1?(this._activeBuffer.y--,this._bufferService.scroll(this._eraseAttrData())):this._activeBuffer.y>=this._bufferService.rows&&(this._activeBuffer.y=this._bufferService.rows-1),this._activeBuffer.x>=this._bufferService.cols&&this._activeBuffer.x--,this._dirtyRowService.markDirty(this._activeBuffer.y),this._onLineFeed.fire(),!0},t.prototype.carriageReturn=function(){return this._activeBuffer.x=0,!0},t.prototype.backspace=function(){var e;if(!this._coreService.decPrivateModes.reverseWraparound)return this._restrictCursor(),this._activeBuffer.x>0&&this._activeBuffer.x--,!0;if(this._restrictCursor(this._bufferService.cols),this._activeBuffer.x>0)this._activeBuffer.x--;else if(0===this._activeBuffer.x&&this._activeBuffer.y>this._activeBuffer.scrollTop&&this._activeBuffer.y<=this._activeBuffer.scrollBottom&&(null===(e=this._activeBuffer.lines.get(this._activeBuffer.ybase+this._activeBuffer.y))||void 0===e?void 0:e.isWrapped)){this._activeBuffer.lines.get(this._activeBuffer.ybase+this._activeBuffer.y).isWrapped=!1,this._activeBuffer.y--,this._activeBuffer.x=this._bufferService.cols-1;var t=this._activeBuffer.lines.get(this._activeBuffer.ybase+this._activeBuffer.y);t.hasWidth(this._activeBuffer.x)&&!t.hasContent(this._activeBuffer.x)&&this._activeBuffer.x--}return this._restrictCursor(),!0},t.prototype.tab=function(){if(this._activeBuffer.x>=this._bufferService.cols)return!0;var e=this._activeBuffer.x;return this._activeBuffer.x=this._activeBuffer.nextStop(),this._optionsService.options.screenReaderMode&&this._onA11yTab.fire(this._activeBuffer.x-e),!0},t.prototype.shiftOut=function(){return this._charsetService.setgLevel(1),!0},t.prototype.shiftIn=function(){return this._charsetService.setgLevel(0),!0},t.prototype._restrictCursor=function(e){void 0===e&&(e=this._bufferService.cols-1),this._activeBuffer.x=Math.min(e,Math.max(0,this._activeBuffer.x)),this._activeBuffer.y=this._coreService.decPrivateModes.origin?Math.min(this._activeBuffer.scrollBottom,Math.max(this._activeBuffer.scrollTop,this._activeBuffer.y)):Math.min(this._bufferService.rows-1,Math.max(0,this._activeBuffer.y)),this._dirtyRowService.markDirty(this._activeBuffer.y)},t.prototype._setCursor=function(e,t){this._dirtyRowService.markDirty(this._activeBuffer.y),this._coreService.decPrivateModes.origin?(this._activeBuffer.x=e,this._activeBuffer.y=this._activeBuffer.scrollTop+t):(this._activeBuffer.x=e,this._activeBuffer.y=t),this._restrictCursor(),this._dirtyRowService.markDirty(this._activeBuffer.y)},t.prototype._moveCursor=function(e,t){this._restrictCursor(),this._setCursor(this._activeBuffer.x+e,this._activeBuffer.y+t)},t.prototype.cursorUp=function(e){var t=this._activeBuffer.y-this._activeBuffer.scrollTop;return t>=0?this._moveCursor(0,-Math.min(t,e.params[0]||1)):this._moveCursor(0,-(e.params[0]||1)),!0},t.prototype.cursorDown=function(e){var t=this._activeBuffer.scrollBottom-this._activeBuffer.y;return t>=0?this._moveCursor(0,Math.min(t,e.params[0]||1)):this._moveCursor(0,e.params[0]||1),!0},t.prototype.cursorForward=function(e){return this._moveCursor(e.params[0]||1,0),!0},t.prototype.cursorBackward=function(e){return this._moveCursor(-(e.params[0]||1),0),!0},t.prototype.cursorNextLine=function(e){return this.cursorDown(e),this._activeBuffer.x=0,!0},t.prototype.cursorPrecedingLine=function(e){return this.cursorUp(e),this._activeBuffer.x=0,!0},t.prototype.cursorCharAbsolute=function(e){return this._setCursor((e.params[0]||1)-1,this._activeBuffer.y),!0},t.prototype.cursorPosition=function(e){return this._setCursor(e.length>=2?(e.params[1]||1)-1:0,(e.params[0]||1)-1),!0},t.prototype.charPosAbsolute=function(e){return this._setCursor((e.params[0]||1)-1,this._activeBuffer.y),!0},t.prototype.hPositionRelative=function(e){return this._moveCursor(e.params[0]||1,0),!0},t.prototype.linePosAbsolute=function(e){return this._setCursor(this._activeBuffer.x,(e.params[0]||1)-1),!0},t.prototype.vPositionRelative=function(e){return this._moveCursor(0,e.params[0]||1),!0},t.prototype.hVPosition=function(e){return this.cursorPosition(e),!0},t.prototype.tabClear=function(e){var t=e.params[0];return 0===t?delete this._activeBuffer.tabs[this._activeBuffer.x]:3===t&&(this._activeBuffer.tabs={}),!0},t.prototype.cursorForwardTab=function(e){if(this._activeBuffer.x>=this._bufferService.cols)return!0;for(var t=e.params[0]||1;t--;)this._activeBuffer.x=this._activeBuffer.nextStop();return!0},t.prototype.cursorBackwardTab=function(e){if(this._activeBuffer.x>=this._bufferService.cols)return!0;for(var t=e.params[0]||1;t--;)this._activeBuffer.x=this._activeBuffer.prevStop();return!0},t.prototype._eraseInBufferLine=function(e,t,r,i){void 0===i&&(i=!1);var n=this._activeBuffer.lines.get(this._activeBuffer.ybase+e);n.replaceCells(t,r,this._activeBuffer.getNullCell(this._eraseAttrData()),this._eraseAttrData()),i&&(n.isWrapped=!1)},t.prototype._resetBufferLine=function(e){var t=this._activeBuffer.lines.get(this._activeBuffer.ybase+e);t.fill(this._activeBuffer.getNullCell(this._eraseAttrData())),t.isWrapped=!1},t.prototype.eraseInDisplay=function(e){var t;switch(this._restrictCursor(this._bufferService.cols),e.params[0]){case 0:for(t=this._activeBuffer.y,this._dirtyRowService.markDirty(t),this._eraseInBufferLine(t++,this._activeBuffer.x,this._bufferService.cols,0===this._activeBuffer.x);t<this._bufferService.rows;t++)this._resetBufferLine(t);this._dirtyRowService.markDirty(t);break;case 1:for(t=this._activeBuffer.y,this._dirtyRowService.markDirty(t),this._eraseInBufferLine(t,0,this._activeBuffer.x+1,!0),this._activeBuffer.x+1>=this._bufferService.cols&&(this._activeBuffer.lines.get(t+1).isWrapped=!1);t--;)this._resetBufferLine(t);this._dirtyRowService.markDirty(0);break;case 2:for(t=this._bufferService.rows,this._dirtyRowService.markDirty(t-1);t--;)this._resetBufferLine(t);this._dirtyRowService.markDirty(0);break;case 3:var r=this._activeBuffer.lines.length-this._bufferService.rows;r>0&&(this._activeBuffer.lines.trimStart(r),this._activeBuffer.ybase=Math.max(this._activeBuffer.ybase-r,0),this._activeBuffer.ydisp=Math.max(this._activeBuffer.ydisp-r,0),this._onScroll.fire(0))}return!0},t.prototype.eraseInLine=function(e){switch(this._restrictCursor(this._bufferService.cols),e.params[0]){case 0:this._eraseInBufferLine(this._activeBuffer.y,this._activeBuffer.x,this._bufferService.cols,0===this._activeBuffer.x);break;case 1:this._eraseInBufferLine(this._activeBuffer.y,0,this._activeBuffer.x+1,!1);break;case 2:this._eraseInBufferLine(this._activeBuffer.y,0,this._bufferService.cols,!0)}return this._dirtyRowService.markDirty(this._activeBuffer.y),!0},t.prototype.insertLines=function(e){this._restrictCursor();var t=e.params[0]||1;if(this._activeBuffer.y>this._activeBuffer.scrollBottom||this._activeBuffer.y<this._activeBuffer.scrollTop)return!0;for(var r=this._activeBuffer.ybase+this._activeBuffer.y,i=this._bufferService.rows-1-this._activeBuffer.scrollBottom,n=this._bufferService.rows-1+this._activeBuffer.ybase-i+1;t--;)this._activeBuffer.lines.splice(n-1,1),this._activeBuffer.lines.splice(r,0,this._activeBuffer.getBlankLine(this._eraseAttrData()));return this._dirtyRowService.markRangeDirty(this._activeBuffer.y,this._activeBuffer.scrollBottom),this._activeBuffer.x=0,!0},t.prototype.deleteLines=function(e){this._restrictCursor();var t=e.params[0]||1;if(this._activeBuffer.y>this._activeBuffer.scrollBottom||this._activeBuffer.y<this._activeBuffer.scrollTop)return!0;var r,i=this._activeBuffer.ybase+this._activeBuffer.y;for(r=this._bufferService.rows-1-this._activeBuffer.scrollBottom,r=this._bufferService.rows-1+this._activeBuffer.ybase-r;t--;)this._activeBuffer.lines.splice(i,1),this._activeBuffer.lines.splice(r,0,this._activeBuffer.getBlankLine(this._eraseAttrData()));return this._dirtyRowService.markRangeDirty(this._activeBuffer.y,this._activeBuffer.scrollBottom),this._activeBuffer.x=0,!0},t.prototype.insertChars=function(e){this._restrictCursor();var t=this._activeBuffer.lines.get(this._activeBuffer.ybase+this._activeBuffer.y);return t&&(t.insertCells(this._activeBuffer.x,e.params[0]||1,this._activeBuffer.getNullCell(this._eraseAttrData()),this._eraseAttrData()),this._dirtyRowService.markDirty(this._activeBuffer.y)),!0},t.prototype.deleteChars=function(e){this._restrictCursor();var t=this._activeBuffer.lines.get(this._activeBuffer.ybase+this._activeBuffer.y);return t&&(t.deleteCells(this._activeBuffer.x,e.params[0]||1,this._activeBuffer.getNullCell(this._eraseAttrData()),this._eraseAttrData()),this._dirtyRowService.markDirty(this._activeBuffer.y)),!0},t.prototype.scrollUp=function(e){for(var t=e.params[0]||1;t--;)this._activeBuffer.lines.splice(this._activeBuffer.ybase+this._activeBuffer.scrollTop,1),this._activeBuffer.lines.splice(this._activeBuffer.ybase+this._activeBuffer.scrollBottom,0,this._activeBuffer.getBlankLine(this._eraseAttrData()));return this._dirtyRowService.markRangeDirty(this._activeBuffer.scrollTop,this._activeBuffer.scrollBottom),!0},t.prototype.scrollDown=function(e){for(var t=e.params[0]||1;t--;)this._activeBuffer.lines.splice(this._activeBuffer.ybase+this._activeBuffer.scrollBottom,1),this._activeBuffer.lines.splice(this._activeBuffer.ybase+this._activeBuffer.scrollTop,0,this._activeBuffer.getBlankLine(f.DEFAULT_ATTR_DATA));return this._dirtyRowService.markRangeDirty(this._activeBuffer.scrollTop,this._activeBuffer.scrollBottom),!0},t.prototype.scrollLeft=function(e){if(this._activeBuffer.y>this._activeBuffer.scrollBottom||this._activeBuffer.y<this._activeBuffer.scrollTop)return!0;for(var t=e.params[0]||1,r=this._activeBuffer.scrollTop;r<=this._activeBuffer.scrollBottom;++r){var i=this._activeBuffer.lines.get(this._activeBuffer.ybase+r);i.deleteCells(0,t,this._activeBuffer.getNullCell(this._eraseAttrData()),this._eraseAttrData()),i.isWrapped=!1}return this._dirtyRowService.markRangeDirty(this._activeBuffer.scrollTop,this._activeBuffer.scrollBottom),!0},t.prototype.scrollRight=function(e){if(this._activeBuffer.y>this._activeBuffer.scrollBottom||this._activeBuffer.y<this._activeBuffer.scrollTop)return!0;for(var t=e.params[0]||1,r=this._activeBuffer.scrollTop;r<=this._activeBuffer.scrollBottom;++r){var i=this._activeBuffer.lines.get(this._activeBuffer.ybase+r);i.insertCells(0,t,this._activeBuffer.getNullCell(this._eraseAttrData()),this._eraseAttrData()),i.isWrapped=!1}return this._dirtyRowService.markRangeDirty(this._activeBuffer.scrollTop,this._activeBuffer.scrollBottom),!0},t.prototype.insertColumns=function(e){if(this._activeBuffer.y>this._activeBuffer.scrollBottom||this._activeBuffer.y<this._activeBuffer.scrollTop)return!0;for(var t=e.params[0]||1,r=this._activeBuffer.scrollTop;r<=this._activeBuffer.scrollBottom;++r){var i=this._activeBuffer.lines.get(this._activeBuffer.ybase+r);i.insertCells(this._activeBuffer.x,t,this._activeBuffer.getNullCell(this._eraseAttrData()),this._eraseAttrData()),i.isWrapped=!1}return this._dirtyRowService.markRangeDirty(this._activeBuffer.scrollTop,this._activeBuffer.scrollBottom),!0},t.prototype.deleteColumns=function(e){if(this._activeBuffer.y>this._activeBuffer.scrollBottom||this._activeBuffer.y<this._activeBuffer.scrollTop)return!0;for(var t=e.params[0]||1,r=this._activeBuffer.scrollTop;r<=this._activeBuffer.scrollBottom;++r){var i=this._activeBuffer.lines.get(this._activeBuffer.ybase+r);i.deleteCells(this._activeBuffer.x,t,this._activeBuffer.getNullCell(this._eraseAttrData()),this._eraseAttrData()),i.isWrapped=!1}return this._dirtyRowService.markRangeDirty(this._activeBuffer.scrollTop,this._activeBuffer.scrollBottom),!0},t.prototype.eraseChars=function(e){this._restrictCursor();var t=this._activeBuffer.lines.get(this._activeBuffer.ybase+this._activeBuffer.y);return t&&(t.replaceCells(this._activeBuffer.x,this._activeBuffer.x+(e.params[0]||1),this._activeBuffer.getNullCell(this._eraseAttrData()),this._eraseAttrData()),this._dirtyRowService.markDirty(this._activeBuffer.y)),!0},t.prototype.repeatPrecedingCharacter=function(e){if(!this._parser.precedingCodepoint)return!0;for(var t=e.params[0]||1,r=new Uint32Array(t),i=0;i<t;++i)r[i]=this._parser.precedingCodepoint;return this.print(r,0,r.length),!0},t.prototype.sendDeviceAttributesPrimary=function(e){return e.params[0]>0||(this._is("xterm")||this._is("rxvt-unicode")||this._is("screen")?this._coreService.triggerDataEvent(s.C0.ESC+"[?1;2c"):this._is("linux")&&this._coreService.triggerDataEvent(s.C0.ESC+"[?6c")),!0},t.prototype.sendDeviceAttributesSecondary=function(e){return e.params[0]>0||(this._is("xterm")?this._coreService.triggerDataEvent(s.C0.ESC+"[>0;276;0c"):this._is("rxvt-unicode")?this._coreService.triggerDataEvent(s.C0.ESC+"[>85;95;0c"):this._is("linux")?this._coreService.triggerDataEvent(e.params[0]+"c"):this._is("screen")&&this._coreService.triggerDataEvent(s.C0.ESC+"[>83;40003;0c")),!0},t.prototype._is=function(e){return 0===(this._optionsService.options.termName+"").indexOf(e)},t.prototype.setMode=function(e){for(var t=0;t<e.length;t++)4===e.params[t]&&(this._coreService.modes.insertMode=!0);return!0},t.prototype.setModePrivate=function(e){for(var t=0;t<e.length;t++)switch(e.params[t]){case 1:this._coreService.decPrivateModes.applicationCursorKeys=!0;break;case 2:this._charsetService.setgCharset(0,a.DEFAULT_CHARSET),this._charsetService.setgCharset(1,a.DEFAULT_CHARSET),this._charsetService.setgCharset(2,a.DEFAULT_CHARSET),this._charsetService.setgCharset(3,a.DEFAULT_CHARSET);break;case 3:this._optionsService.options.windowOptions.setWinLines&&(this._bufferService.resize(132,this._bufferService.rows),this._onRequestReset.fire());break;case 6:this._coreService.decPrivateModes.origin=!0,this._setCursor(0,0);break;case 7:this._coreService.decPrivateModes.wraparound=!0;break;case 12:break;case 45:this._coreService.decPrivateModes.reverseWraparound=!0;break;case 66:this._logService.debug("Serial port requested application keypad."),this._coreService.decPrivateModes.applicationKeypad=!0,this._onRequestSyncScrollBar.fire();break;case 9:this._coreMouseService.activeProtocol="X10";break;case 1e3:this._coreMouseService.activeProtocol="VT200";break;case 1002:this._coreMouseService.activeProtocol="DRAG";break;case 1003:this._coreMouseService.activeProtocol="ANY";break;case 1004:this._coreService.decPrivateModes.sendFocus=!0,this._onRequestSendFocus.fire();break;case 1005:this._logService.debug("DECSET 1005 not supported (see #2507)");break;case 1006:this._coreMouseService.activeEncoding="SGR";break;case 1015:this._logService.debug("DECSET 1015 not supported (see #2507)");break;case 25:this._coreService.isCursorHidden=!1;break;case 1048:this.saveCursor();break;case 1049:this.saveCursor();case 47:case 1047:this._bufferService.buffers.activateAltBuffer(this._eraseAttrData()),this._coreService.isCursorInitialized=!0,this._onRequestRefreshRows.fire(0,this._bufferService.rows-1),this._onRequestSyncScrollBar.fire();break;case 2004:this._coreService.decPrivateModes.bracketedPasteMode=!0}return!0},t.prototype.resetMode=function(e){for(var t=0;t<e.length;t++)4===e.params[t]&&(this._coreService.modes.insertMode=!1);return!0},t.prototype.resetModePrivate=function(e){for(var t=0;t<e.length;t++)switch(e.params[t]){case 1:this._coreService.decPrivateModes.applicationCursorKeys=!1;break;case 3:this._optionsService.options.windowOptions.setWinLines&&(this._bufferService.resize(80,this._bufferService.rows),this._onRequestReset.fire());break;case 6:this._coreService.decPrivateModes.origin=!1,this._setCursor(0,0);break;case 7:this._coreService.decPrivateModes.wraparound=!1;break;case 12:break;case 45:this._coreService.decPrivateModes.reverseWraparound=!1;break;case 66:this._logService.debug("Switching back to normal keypad."),this._coreService.decPrivateModes.applicationKeypad=!1,this._onRequestSyncScrollBar.fire();break;case 9:case 1e3:case 1002:case 1003:this._coreMouseService.activeProtocol="NONE";break;case 1004:this._coreService.decPrivateModes.sendFocus=!1;break;case 1005:this._logService.debug("DECRST 1005 not supported (see #2507)");break;case 1006:this._coreMouseService.activeEncoding="DEFAULT";break;case 1015:this._logService.debug("DECRST 1015 not supported (see #2507)");break;case 25:this._coreService.isCursorHidden=!0;break;case 1048:this.restoreCursor();break;case 1049:case 47:case 1047:this._bufferService.buffers.activateNormalBuffer(),1049===e.params[t]&&this.restoreCursor(),this._coreService.isCursorInitialized=!0,this._onRequestRefreshRows.fire(0,this._bufferService.rows-1),this._onRequestSyncScrollBar.fire();break;case 2004:this._coreService.decPrivateModes.bracketedPasteMode=!1}return!0},t.prototype._updateAttrColor=function(e,t,r,i,n){return 2===t?(e|=50331648,e&=-16777216,e|=v.AttributeData.fromColorRGB([r,i,n])):5===t&&(e&=-50331904,e|=33554432|255&r),e},t.prototype._extractColor=function(e,t,r){var i=[0,0,-1,0,0,0],n=0,o=0;do{if(i[o+n]=e.params[t+o],e.hasSubParams(t+o)){var s=e.getSubParams(t+o),a=0;do{5===i[1]&&(n=1),i[o+a+1+n]=s[a]}while(++a<s.length&&a+o+1+n<i.length);break}if(5===i[1]&&o+n>=2||2===i[1]&&o+n>=5)break;i[1]&&(n=1)}while(++o+t<e.length&&o+n<i.length);for(a=2;a<i.length;++a)-1===i[a]&&(i[a]=0);switch(i[0]){case 38:r.fg=this._updateAttrColor(r.fg,i[1],i[3],i[4],i[5]);break;case 48:r.bg=this._updateAttrColor(r.bg,i[1],i[3],i[4],i[5]);break;case 58:r.extended=r.extended.clone(),r.extended.underlineColor=this._updateAttrColor(r.extended.underlineColor,i[1],i[3],i[4],i[5])}return o},t.prototype._processUnderline=function(e,t){t.extended=t.extended.clone(),(!~e||e>5)&&(e=1),t.extended.underlineStyle=e,t.fg|=268435456,0===e&&(t.fg&=-268435457),t.updateExtended()},t.prototype.charAttributes=function(e){if(1===e.length&&0===e.params[0])return this._curAttrData.fg=f.DEFAULT_ATTR_DATA.fg,this._curAttrData.bg=f.DEFAULT_ATTR_DATA.bg,!0;for(var t,r=e.length,i=this._curAttrData,n=0;n<r;n++)(t=e.params[n])>=30&&t<=37?(i.fg&=-50331904,i.fg|=16777216|t-30):t>=40&&t<=47?(i.bg&=-50331904,i.bg|=16777216|t-40):t>=90&&t<=97?(i.fg&=-50331904,i.fg|=16777224|t-90):t>=100&&t<=107?(i.bg&=-50331904,i.bg|=16777224|t-100):0===t?(i.fg=f.DEFAULT_ATTR_DATA.fg,i.bg=f.DEFAULT_ATTR_DATA.bg):1===t?i.fg|=134217728:3===t?i.bg|=67108864:4===t?(i.fg|=268435456,this._processUnderline(e.hasSubParams(n)?e.getSubParams(n)[0]:1,i)):5===t?i.fg|=536870912:7===t?i.fg|=67108864:8===t?i.fg|=1073741824:9===t?i.fg|=2147483648:2===t?i.bg|=134217728:21===t?this._processUnderline(2,i):22===t?(i.fg&=-134217729,i.bg&=-134217729):23===t?i.bg&=-67108865:24===t?i.fg&=-268435457:25===t?i.fg&=-536870913:27===t?i.fg&=-67108865:28===t?i.fg&=-1073741825:29===t?i.fg&=2147483647:39===t?(i.fg&=-67108864,i.fg|=16777215&f.DEFAULT_ATTR_DATA.fg):49===t?(i.bg&=-67108864,i.bg|=16777215&f.DEFAULT_ATTR_DATA.bg):38===t||48===t||58===t?n+=this._extractColor(e,n,i):59===t?(i.extended=i.extended.clone(),i.extended.underlineColor=-1,i.updateExtended()):100===t?(i.fg&=-67108864,i.fg|=16777215&f.DEFAULT_ATTR_DATA.fg,i.bg&=-67108864,i.bg|=16777215&f.DEFAULT_ATTR_DATA.bg):this._logService.debug("Unknown SGR attribute: %d.",t);return!0},t.prototype.deviceStatus=function(e){switch(e.params[0]){case 5:this._coreService.triggerDataEvent(s.C0.ESC+"[0n");break;case 6:var t=this._activeBuffer.y+1,r=this._activeBuffer.x+1;this._coreService.triggerDataEvent(s.C0.ESC+"["+t+";"+r+"R")}return!0},t.prototype.deviceStatusPrivate=function(e){if(6===e.params[0]){var t=this._activeBuffer.y+1,r=this._activeBuffer.x+1;this._coreService.triggerDataEvent(s.C0.ESC+"[?"+t+";"+r+"R")}return!0},t.prototype.softReset=function(e){return this._coreService.isCursorHidden=!1,this._onRequestSyncScrollBar.fire(),this._activeBuffer.scrollTop=0,this._activeBuffer.scrollBottom=this._bufferService.rows-1,this._curAttrData=f.DEFAULT_ATTR_DATA.clone(),this._coreService.reset(),this._charsetService.reset(),this._activeBuffer.savedX=0,this._activeBuffer.savedY=this._activeBuffer.ybase,this._activeBuffer.savedCurAttrData.fg=this._curAttrData.fg,this._activeBuffer.savedCurAttrData.bg=this._curAttrData.bg,this._activeBuffer.savedCharset=this._charsetService.charset,this._coreService.decPrivateModes.origin=!1,!0},t.prototype.setCursorStyle=function(e){var t=e.params[0]||1;switch(t){case 1:case 2:this._optionsService.options.cursorStyle="block";break;case 3:case 4:this._optionsService.options.cursorStyle="underline";break;case 5:case 6:this._optionsService.options.cursorStyle="bar"}var r=t%2==1;return this._optionsService.options.cursorBlink=r,!0},t.prototype.setScrollRegion=function(e){var t,r=e.params[0]||1;return(e.length<2||(t=e.params[1])>this._bufferService.rows||0===t)&&(t=this._bufferService.rows),t>r&&(this._activeBuffer.scrollTop=r-1,this._activeBuffer.scrollBottom=t-1,this._setCursor(0,0)),!0},t.prototype.windowOptions=function(e){if(!w(e.params[0],this._optionsService.options.windowOptions))return!0;var t=e.length>1?e.params[1]:0;switch(e.params[0]){case 14:2!==t&&this._onRequestWindowsOptionsReport.fire(o.GET_WIN_SIZE_PIXELS);break;case 16:this._onRequestWindowsOptionsReport.fire(o.GET_CELL_SIZE_PIXELS);break;case 18:this._bufferService&&this._coreService.triggerDataEvent(s.C0.ESC+"[8;"+this._bufferService.rows+";"+this._bufferService.cols+"t");break;case 22:0!==t&&2!==t||(this._windowTitleStack.push(this._windowTitle),this._windowTitleStack.length>10&&this._windowTitleStack.shift()),0!==t&&1!==t||(this._iconNameStack.push(this._iconName),this._iconNameStack.length>10&&this._iconNameStack.shift());break;case 23:0!==t&&2!==t||this._windowTitleStack.length&&this.setTitle(this._windowTitleStack.pop()),0!==t&&1!==t||this._iconNameStack.length&&this.setIconName(this._iconNameStack.pop())}return!0},t.prototype.saveCursor=function(e){return this._activeBuffer.savedX=this._activeBuffer.x,this._activeBuffer.savedY=this._activeBuffer.ybase+this._activeBuffer.y,this._activeBuffer.savedCurAttrData.fg=this._curAttrData.fg,this._activeBuffer.savedCurAttrData.bg=this._curAttrData.bg,this._activeBuffer.savedCharset=this._charsetService.charset,!0},t.prototype.restoreCursor=function(e){return this._activeBuffer.x=this._activeBuffer.savedX||0,this._activeBuffer.y=Math.max(this._activeBuffer.savedY-this._activeBuffer.ybase,0),this._curAttrData.fg=this._activeBuffer.savedCurAttrData.fg,this._curAttrData.bg=this._activeBuffer.savedCurAttrData.bg,this._charsetService.charset=this._savedCharset,this._activeBuffer.savedCharset&&(this._charsetService.charset=this._activeBuffer.savedCharset),this._restrictCursor(),!0},t.prototype.setTitle=function(e){return this._windowTitle=e,this._onTitleChange.fire(e),!0},t.prototype.setIconName=function(e){return this._iconName=e,!0},t.prototype.setOrReportIndexedColor=function(e){for(var t=[],r=e.split(";");r.length>1;){var i=r.shift(),n=r.shift();if(/^\d+$/.exec(i)){var o=parseInt(i);if(0<=o&&o<256)if("?"===n)t.push({type:0,index:o});else{var s=(0,b.parseColor)(n);s&&t.push({type:1,index:o,color:s})}}}return t.length&&this._onColor.fire(t),!0},t.prototype._setOrReportSpecialColor=function(e,t){for(var r=e.split(";"),i=0;i<r.length&&!(t>=this._specialColors.length);++i,++t)if("?"===r[i])this._onColor.fire([{type:0,index:this._specialColors[t]}]);else{var n=(0,b.parseColor)(r[i]);n&&this._onColor.fire([{type:1,index:this._specialColors[t],color:n}])}return!0},t.prototype.setOrReportFgColor=function(e){return this._setOrReportSpecialColor(e,0)},t.prototype.setOrReportBgColor=function(e){return this._setOrReportSpecialColor(e,1)},t.prototype.setOrReportCursorColor=function(e){return this._setOrReportSpecialColor(e,2)},t.prototype.restoreIndexedColor=function(e){if(!e)return this._onColor.fire([{type:2}]),!0;for(var t=[],r=e.split(";"),i=0;i<r.length;++i)if(/^\d+$/.exec(r[i])){var n=parseInt(r[i]);0<=n&&n<256&&t.push({type:2,index:n})}return t.length&&this._onColor.fire(t),!0},t.prototype.restoreFgColor=function(e){return this._onColor.fire([{type:2,index:256}]),!0},t.prototype.restoreBgColor=function(e){return this._onColor.fire([{type:2,index:257}]),!0},t.prototype.restoreCursorColor=function(e){return this._onColor.fire([{type:2,index:258}]),!0},t.prototype.nextLine=function(){return this._activeBuffer.x=0,this.index(),!0},t.prototype.keypadApplicationMode=function(){return this._logService.debug("Serial port requested application keypad."),this._coreService.decPrivateModes.applicationKeypad=!0,this._onRequestSyncScrollBar.fire(),!0},t.prototype.keypadNumericMode=function(){return this._logService.debug("Switching back to normal keypad."),this._coreService.decPrivateModes.applicationKeypad=!1,this._onRequestSyncScrollBar.fire(),!0},t.prototype.selectDefaultCharset=function(){return this._charsetService.setgLevel(0),this._charsetService.setgCharset(0,a.DEFAULT_CHARSET),!0},t.prototype.selectCharset=function(e){return 2!==e.length?(this.selectDefaultCharset(),!0):("/"===e[0]||this._charsetService.setgCharset(S[e[0]],a.CHARSETS[e[1]]||a.DEFAULT_CHARSET),!0)},t.prototype.index=function(){return this._restrictCursor(),this._activeBuffer.y++,this._activeBuffer.y===this._activeBuffer.scrollBottom+1?(this._activeBuffer.y--,this._bufferService.scroll(this._eraseAttrData())):this._activeBuffer.y>=this._bufferService.rows&&(this._activeBuffer.y=this._bufferService.rows-1),this._restrictCursor(),!0},t.prototype.tabSet=function(){return this._activeBuffer.tabs[this._activeBuffer.x]=!0,!0},t.prototype.reverseIndex=function(){if(this._restrictCursor(),this._activeBuffer.y===this._activeBuffer.scrollTop){var e=this._activeBuffer.scrollBottom-this._activeBuffer.scrollTop;this._activeBuffer.lines.shiftElements(this._activeBuffer.ybase+this._activeBuffer.y,e,1),this._activeBuffer.lines.set(this._activeBuffer.ybase+this._activeBuffer.y,this._activeBuffer.getBlankLine(this._eraseAttrData())),this._dirtyRowService.markRangeDirty(this._activeBuffer.scrollTop,this._activeBuffer.scrollBottom)}else this._activeBuffer.y--,this._restrictCursor();return!0},t.prototype.fullReset=function(){return this._parser.reset(),this._onRequestReset.fire(),!0},t.prototype.reset=function(){this._curAttrData=f.DEFAULT_ATTR_DATA.clone(),this._eraseAttrDataInternal=f.DEFAULT_ATTR_DATA.clone()},t.prototype._eraseAttrData=function(){return this._eraseAttrDataInternal.bg&=-67108864,this._eraseAttrDataInternal.bg|=67108863&this._curAttrData.bg,this._eraseAttrDataInternal},t.prototype.setgLevel=function(e){return this._charsetService.setgLevel(e),!0},t.prototype.screenAlignmentPattern=function(){var e=new p.CellData;e.content=1<<22|"E".charCodeAt(0),e.fg=this._curAttrData.fg,e.bg=this._curAttrData.bg,this._setCursor(0,0);for(var t=0;t<this._bufferService.rows;++t){var r=this._activeBuffer.ybase+this._activeBuffer.y+t,i=this._activeBuffer.lines.get(r);i&&(i.fill(e),i.isWrapped=!1)}return this._dirtyRowService.markAllDirty(),this._setCursor(0,0),!0},t}(l.Disposable);t.InputHandler=E},844:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.getDisposeArrayDisposable=t.disposeArray=t.Disposable=void 0;var r=function(){function e(){this._disposables=[],this._isDisposed=!1}return e.prototype.dispose=function(){this._isDisposed=!0;for(var e=0,t=this._disposables;e<t.length;e++)t[e].dispose();this._disposables.length=0},e.prototype.register=function(e){return this._disposables.push(e),e},e.prototype.unregister=function(e){var t=this._disposables.indexOf(e);-1!==t&&this._disposables.splice(t,1)},e}();function i(e){for(var t=0,r=e;t<r.length;t++)r[t].dispose();e.length=0}t.Disposable=r,t.disposeArray=i,t.getDisposeArrayDisposable=function(e){return{dispose:function(){return i(e)}}}},6114:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.isLinux=t.isWindows=t.isIphone=t.isIpad=t.isMac=t.isSafari=t.isFirefox=void 0;var r="undefined"==typeof navigator,i=r?"node":navigator.userAgent,n=r?"node":navigator.platform;t.isFirefox=i.includes("Firefox"),t.isSafari=/^((?!chrome|android).)*safari/i.test(i),t.isMac=["Macintosh","MacIntel","MacPPC","Mac68K"].includes(n),t.isIpad="iPad"===n,t.isIphone="iPhone"===n,t.isWindows=["Windows","Win16","Win32","WinCE"].includes(n),t.isLinux=n.indexOf("Linux")>=0},8273:(e,t)=>{function r(e,t,r,i){if(void 0===r&&(r=0),void 0===i&&(i=e.length),r>=e.length)return e;r=(e.length+r)%e.length,i=i>=e.length?e.length:(e.length+i)%e.length;for(var n=r;n<i;++n)e[n]=t;return e}Object.defineProperty(t,"__esModule",{value:!0}),t.concat=t.fillFallback=t.fill=void 0,t.fill=function(e,t,i,n){return e.fill?e.fill(t,i,n):r(e,t,i,n)},t.fillFallback=r,t.concat=function(e,t){var r=new e.constructor(e.length+t.length);return r.set(e),r.set(t,e.length),r}},9282:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.updateWindowsModeWrappedState=void 0;var i=r(643);t.updateWindowsModeWrappedState=function(e){var t=e.buffer.lines.get(e.buffer.ybase+e.buffer.y-1),r=null==t?void 0:t.get(e.cols-1),n=e.buffer.lines.get(e.buffer.ybase+e.buffer.y);n&&r&&(n.isWrapped=r[i.CHAR_DATA_CODE_INDEX]!==i.NULL_CELL_CODE&&r[i.CHAR_DATA_CODE_INDEX]!==i.WHITESPACE_CELL_CODE)}},3734:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.ExtendedAttrs=t.AttributeData=void 0;var r=function(){function e(){this.fg=0,this.bg=0,this.extended=new i}return e.toColorRGB=function(e){return[e>>>16&255,e>>>8&255,255&e]},e.fromColorRGB=function(e){return(255&e[0])<<16|(255&e[1])<<8|255&e[2]},e.prototype.clone=function(){var t=new e;return t.fg=this.fg,t.bg=this.bg,t.extended=this.extended.clone(),t},e.prototype.isInverse=function(){return 67108864&this.fg},e.prototype.isBold=function(){return 134217728&this.fg},e.prototype.isUnderline=function(){return 268435456&this.fg},e.prototype.isBlink=function(){return 536870912&this.fg},e.prototype.isInvisible=function(){return 1073741824&this.fg},e.prototype.isItalic=function(){return 67108864&this.bg},e.prototype.isDim=function(){return 134217728&this.bg},e.prototype.isStrikethrough=function(){return 2147483648&this.fg},e.prototype.getFgColorMode=function(){return 50331648&this.fg},e.prototype.getBgColorMode=function(){return 50331648&this.bg},e.prototype.isFgRGB=function(){return 50331648==(50331648&this.fg)},e.prototype.isBgRGB=function(){return 50331648==(50331648&this.bg)},e.prototype.isFgPalette=function(){return 16777216==(50331648&this.fg)||33554432==(50331648&this.fg)},e.prototype.isBgPalette=function(){return 16777216==(50331648&this.bg)||33554432==(50331648&this.bg)},e.prototype.isFgDefault=function(){return 0==(50331648&this.fg)},e.prototype.isBgDefault=function(){return 0==(50331648&this.bg)},e.prototype.isAttributeDefault=function(){return 0===this.fg&&0===this.bg},e.prototype.getFgColor=function(){switch(50331648&this.fg){case 16777216:case 33554432:return 255&this.fg;case 50331648:return 16777215&this.fg;default:return-1}},e.prototype.getBgColor=function(){switch(50331648&this.bg){case 16777216:case 33554432:return 255&this.bg;case 50331648:return 16777215&this.bg;default:return-1}},e.prototype.hasExtendedAttrs=function(){return 268435456&this.bg},e.prototype.updateExtended=function(){this.extended.isEmpty()?this.bg&=-268435457:this.bg|=268435456},e.prototype.getUnderlineColor=function(){if(268435456&this.bg&&~this.extended.underlineColor)switch(50331648&this.extended.underlineColor){case 16777216:case 33554432:return 255&this.extended.underlineColor;case 50331648:return 16777215&this.extended.underlineColor;default:return this.getFgColor()}return this.getFgColor()},e.prototype.getUnderlineColorMode=function(){return 268435456&this.bg&&~this.extended.underlineColor?50331648&this.extended.underlineColor:this.getFgColorMode()},e.prototype.isUnderlineColorRGB=function(){return 268435456&this.bg&&~this.extended.underlineColor?50331648==(50331648&this.extended.underlineColor):this.isFgRGB()},e.prototype.isUnderlineColorPalette=function(){return 268435456&this.bg&&~this.extended.underlineColor?16777216==(50331648&this.extended.underlineColor)||33554432==(50331648&this.extended.underlineColor):this.isFgPalette()},e.prototype.isUnderlineColorDefault=function(){return 268435456&this.bg&&~this.extended.underlineColor?0==(50331648&this.extended.underlineColor):this.isFgDefault()},e.prototype.getUnderlineStyle=function(){return 268435456&this.fg?268435456&this.bg?this.extended.underlineStyle:1:0},e}();t.AttributeData=r;var i=function(){function e(e,t){void 0===e&&(e=0),void 0===t&&(t=-1),this.underlineStyle=e,this.underlineColor=t}return e.prototype.clone=function(){return new e(this.underlineStyle,this.underlineColor)},e.prototype.isEmpty=function(){return 0===this.underlineStyle},e}();t.ExtendedAttrs=i},9092:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.BufferStringIterator=t.Buffer=t.MAX_BUFFER_SIZE=void 0;var i=r(6349),n=r(8437),o=r(511),s=r(643),a=r(4634),c=r(4863),l=r(7116),u=r(3734);t.MAX_BUFFER_SIZE=4294967295;var h=function(){function e(e,t,r){this._hasScrollback=e,this._optionsService=t,this._bufferService=r,this.ydisp=0,this.ybase=0,this.y=0,this.x=0,this.savedY=0,this.savedX=0,this.savedCurAttrData=n.DEFAULT_ATTR_DATA.clone(),this.savedCharset=l.DEFAULT_CHARSET,this.markers=[],this._nullCell=o.CellData.fromCharData([0,s.NULL_CELL_CHAR,s.NULL_CELL_WIDTH,s.NULL_CELL_CODE]),this._whitespaceCell=o.CellData.fromCharData([0,s.WHITESPACE_CELL_CHAR,s.WHITESPACE_CELL_WIDTH,s.WHITESPACE_CELL_CODE]),this._cols=this._bufferService.cols,this._rows=this._bufferService.rows,this.lines=new i.CircularList(this._getCorrectBufferLength(this._rows)),this.scrollTop=0,this.scrollBottom=this._rows-1,this.setupTabStops()}return e.prototype.getNullCell=function(e){return e?(this._nullCell.fg=e.fg,this._nullCell.bg=e.bg,this._nullCell.extended=e.extended):(this._nullCell.fg=0,this._nullCell.bg=0,this._nullCell.extended=new u.ExtendedAttrs),this._nullCell},e.prototype.getWhitespaceCell=function(e){return e?(this._whitespaceCell.fg=e.fg,this._whitespaceCell.bg=e.bg,this._whitespaceCell.extended=e.extended):(this._whitespaceCell.fg=0,this._whitespaceCell.bg=0,this._whitespaceCell.extended=new u.ExtendedAttrs),this._whitespaceCell},e.prototype.getBlankLine=function(e,t){return new n.BufferLine(this._bufferService.cols,this.getNullCell(e),t)},Object.defineProperty(e.prototype,"hasScrollback",{get:function(){return this._hasScrollback&&this.lines.maxLength>this._rows},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"isCursorInViewport",{get:function(){var e=this.ybase+this.y-this.ydisp;return e>=0&&e<this._rows},enumerable:!1,configurable:!0}),e.prototype._getCorrectBufferLength=function(e){if(!this._hasScrollback)return e;var r=e+this._optionsService.options.scrollback;return r>t.MAX_BUFFER_SIZE?t.MAX_BUFFER_SIZE:r},e.prototype.fillViewportRows=function(e){if(0===this.lines.length){void 0===e&&(e=n.DEFAULT_ATTR_DATA);for(var t=this._rows;t--;)this.lines.push(this.getBlankLine(e))}},e.prototype.clear=function(){this.ydisp=0,this.ybase=0,this.y=0,this.x=0,this.lines=new i.CircularList(this._getCorrectBufferLength(this._rows)),this.scrollTop=0,this.scrollBottom=this._rows-1,this.setupTabStops()},e.prototype.resize=function(e,t){var r=this.getNullCell(n.DEFAULT_ATTR_DATA),i=this._getCorrectBufferLength(t);if(i>this.lines.maxLength&&(this.lines.maxLength=i),this.lines.length>0){if(this._cols<e)for(var o=0;o<this.lines.length;o++)this.lines.get(o).resize(e,r);var s=0;if(this._rows<t)for(var a=this._rows;a<t;a++)this.lines.length<t+this.ybase&&(this._optionsService.options.windowsMode?this.lines.push(new n.BufferLine(e,r)):this.ybase>0&&this.lines.length<=this.ybase+this.y+s+1?(this.ybase--,s++,this.ydisp>0&&this.ydisp--):this.lines.push(new n.BufferLine(e,r)));else for(a=this._rows;a>t;a--)this.lines.length>t+this.ybase&&(this.lines.length>this.ybase+this.y+1?this.lines.pop():(this.ybase++,this.ydisp++));if(i<this.lines.maxLength){var c=this.lines.length-i;c>0&&(this.lines.trimStart(c),this.ybase=Math.max(this.ybase-c,0),this.ydisp=Math.max(this.ydisp-c,0),this.savedY=Math.max(this.savedY-c,0)),this.lines.maxLength=i}this.x=Math.min(this.x,e-1),this.y=Math.min(this.y,t-1),s&&(this.y+=s),this.savedX=Math.min(this.savedX,e-1),this.scrollTop=0}if(this.scrollBottom=t-1,this._isReflowEnabled&&(this._reflow(e,t),this._cols>e))for(o=0;o<this.lines.length;o++)this.lines.get(o).resize(e,r);this._cols=e,this._rows=t},Object.defineProperty(e.prototype,"_isReflowEnabled",{get:function(){return this._hasScrollback&&!this._optionsService.options.windowsMode},enumerable:!1,configurable:!0}),e.prototype._reflow=function(e,t){this._cols!==e&&(e>this._cols?this._reflowLarger(e,t):this._reflowSmaller(e,t))},e.prototype._reflowLarger=function(e,t){var r=(0,a.reflowLargerGetLinesToRemove)(this.lines,this._cols,e,this.ybase+this.y,this.getNullCell(n.DEFAULT_ATTR_DATA));if(r.length>0){var i=(0,a.reflowLargerCreateNewLayout)(this.lines,r);(0,a.reflowLargerApplyNewLayout)(this.lines,i.layout),this._reflowLargerAdjustViewport(e,t,i.countRemoved)}},e.prototype._reflowLargerAdjustViewport=function(e,t,r){for(var i=this.getNullCell(n.DEFAULT_ATTR_DATA),o=r;o-- >0;)0===this.ybase?(this.y>0&&this.y--,this.lines.length<t&&this.lines.push(new n.BufferLine(e,i))):(this.ydisp===this.ybase&&this.ydisp--,this.ybase--);this.savedY=Math.max(this.savedY-r,0)},e.prototype._reflowSmaller=function(e,t){for(var r=this.getNullCell(n.DEFAULT_ATTR_DATA),i=[],o=0,s=this.lines.length-1;s>=0;s--){var c=this.lines.get(s);if(!(!c||!c.isWrapped&&c.getTrimmedLength()<=e)){for(var l=[c];c.isWrapped&&s>0;)c=this.lines.get(--s),l.unshift(c);var u=this.ybase+this.y;if(!(u>=s&&u<s+l.length)){var h,f=l[l.length-1].getTrimmedLength(),_=(0,a.reflowSmallerGetNewLineLengths)(l,this._cols,e),d=_.length-l.length;h=0===this.ybase&&this.y!==this.lines.length-1?Math.max(0,this.y-this.lines.maxLength+d):Math.max(0,this.lines.length-this.lines.maxLength+d);for(var p=[],v=0;v<d;v++){var g=this.getBlankLine(n.DEFAULT_ATTR_DATA,!0);p.push(g)}p.length>0&&(i.push({start:s+l.length+o,newLines:p}),o+=p.length),l.push.apply(l,p);var y=_.length-1,m=_[y];0===m&&(m=_[--y]);for(var b=l.length-d-1,S=f;b>=0;){var C=Math.min(S,m);if(l[y].copyCellsFrom(l[b],S-C,m-C,C,!0),0==(m-=C)&&(m=_[--y]),0==(S-=C)){b--;var w=Math.max(b,0);S=(0,a.getWrappedLineTrimmedLength)(l,w,this._cols)}}for(v=0;v<l.length;v++)_[v]<e&&l[v].setCell(_[v],r);for(var L=d-h;L-- >0;)0===this.ybase?this.y<t-1?(this.y++,this.lines.pop()):(this.ybase++,this.ydisp++):this.ybase<Math.min(this.lines.maxLength,this.lines.length+o)-t&&(this.ybase===this.ydisp&&this.ydisp++,this.ybase++);this.savedY=Math.min(this.savedY+d,this.ybase+t-1)}}}if(i.length>0){var E=[],x=[];for(v=0;v<this.lines.length;v++)x.push(this.lines.get(v));var A=this.lines.length,k=A-1,M=0,R=i[M];this.lines.length=Math.min(this.lines.maxLength,this.lines.length+o);var T=0;for(v=Math.min(this.lines.maxLength-1,A+o-1);v>=0;v--)if(R&&R.start>k+T){for(var O=R.newLines.length-1;O>=0;O--)this.lines.set(v--,R.newLines[O]);v++,E.push({index:k+1,amount:R.newLines.length}),T+=R.newLines.length,R=i[++M]}else this.lines.set(v,x[k--]);var B=0;for(v=E.length-1;v>=0;v--)E[v].index+=B,this.lines.onInsertEmitter.fire(E[v]),B+=E[v].amount;var D=Math.max(0,A+o-this.lines.maxLength);D>0&&this.lines.onTrimEmitter.fire(D)}},e.prototype.stringIndexToBufferIndex=function(e,t,r){for(void 0===r&&(r=!1);t;){var i=this.lines.get(e);if(!i)return[-1,-1];for(var n=r?i.getTrimmedLength():i.length,o=0;o<n;++o)if(i.get(o)[s.CHAR_DATA_WIDTH_INDEX]&&(t-=i.get(o)[s.CHAR_DATA_CHAR_INDEX].length||1),t<0)return[e,o];e++}return[e,0]},e.prototype.translateBufferLineToString=function(e,t,r,i){void 0===r&&(r=0);var n=this.lines.get(e);return n?n.translateToString(t,r,i):""},e.prototype.getWrappedRangeForLine=function(e){for(var t=e,r=e;t>0&&this.lines.get(t).isWrapped;)t--;for(;r+1<this.lines.length&&this.lines.get(r+1).isWrapped;)r++;return{first:t,last:r}},e.prototype.setupTabStops=function(e){for(null!=e?this.tabs[e]||(e=this.prevStop(e)):(this.tabs={},e=0);e<this._cols;e+=this._optionsService.options.tabStopWidth)this.tabs[e]=!0},e.prototype.prevStop=function(e){for(null==e&&(e=this.x);!this.tabs[--e]&&e>0;);return e>=this._cols?this._cols-1:e<0?0:e},e.prototype.nextStop=function(e){for(null==e&&(e=this.x);!this.tabs[++e]&&e<this._cols;);return e>=this._cols?this._cols-1:e<0?0:e},e.prototype.addMarker=function(e){var t=this,r=new c.Marker(e);return this.markers.push(r),r.register(this.lines.onTrim((function(e){r.line-=e,r.line<0&&r.dispose()}))),r.register(this.lines.onInsert((function(e){r.line>=e.index&&(r.line+=e.amount)}))),r.register(this.lines.onDelete((function(e){r.line>=e.index&&r.line<e.index+e.amount&&r.dispose(),r.line>e.index&&(r.line-=e.amount)}))),r.register(r.onDispose((function(){return t._removeMarker(r)}))),r},e.prototype._removeMarker=function(e){this.markers.splice(this.markers.indexOf(e),1)},e.prototype.iterator=function(e,t,r,i,n){return new f(this,e,t,r,i,n)},e}();t.Buffer=h;var f=function(){function e(e,t,r,i,n,o){void 0===r&&(r=0),void 0===i&&(i=e.lines.length),void 0===n&&(n=0),void 0===o&&(o=0),this._buffer=e,this._trimRight=t,this._startIndex=r,this._endIndex=i,this._startOverscan=n,this._endOverscan=o,this._startIndex<0&&(this._startIndex=0),this._endIndex>this._buffer.lines.length&&(this._endIndex=this._buffer.lines.length),this._current=this._startIndex}return e.prototype.hasNext=function(){return this._current<this._endIndex},e.prototype.next=function(){var e=this._buffer.getWrappedRangeForLine(this._current);e.first<this._startIndex-this._startOverscan&&(e.first=this._startIndex-this._startOverscan),e.last>this._endIndex+this._endOverscan&&(e.last=this._endIndex+this._endOverscan),e.first=Math.max(e.first,0),e.last=Math.min(e.last,this._buffer.lines.length);for(var t="",r=e.first;r<=e.last;++r)t+=this._buffer.translateBufferLineToString(r,this._trimRight);return this._current=e.last+1,{range:e,content:t}},e}();t.BufferStringIterator=f},8437:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.BufferLine=t.DEFAULT_ATTR_DATA=void 0;var i=r(482),n=r(643),o=r(511),s=r(3734);t.DEFAULT_ATTR_DATA=Object.freeze(new s.AttributeData);var a=function(){function e(e,t,r){void 0===r&&(r=!1),this.isWrapped=r,this._combined={},this._extendedAttrs={},this._data=new Uint32Array(3*e);for(var i=t||o.CellData.fromCharData([0,n.NULL_CELL_CHAR,n.NULL_CELL_WIDTH,n.NULL_CELL_CODE]),s=0;s<e;++s)this.setCell(s,i);this.length=e}return e.prototype.get=function(e){var t=this._data[3*e+0],r=2097151&t;return[this._data[3*e+1],2097152&t?this._combined[e]:r?(0,i.stringFromCodePoint)(r):"",t>>22,2097152&t?this._combined[e].charCodeAt(this._combined[e].length-1):r]},e.prototype.set=function(e,t){this._data[3*e+1]=t[n.CHAR_DATA_ATTR_INDEX],t[n.CHAR_DATA_CHAR_INDEX].length>1?(this._combined[e]=t[1],this._data[3*e+0]=2097152|e|t[n.CHAR_DATA_WIDTH_INDEX]<<22):this._data[3*e+0]=t[n.CHAR_DATA_CHAR_INDEX].charCodeAt(0)|t[n.CHAR_DATA_WIDTH_INDEX]<<22},e.prototype.getWidth=function(e){return this._data[3*e+0]>>22},e.prototype.hasWidth=function(e){return 12582912&this._data[3*e+0]},e.prototype.getFg=function(e){return this._data[3*e+1]},e.prototype.getBg=function(e){return this._data[3*e+2]},e.prototype.hasContent=function(e){return 4194303&this._data[3*e+0]},e.prototype.getCodePoint=function(e){var t=this._data[3*e+0];return 2097152&t?this._combined[e].charCodeAt(this._combined[e].length-1):2097151&t},e.prototype.isCombined=function(e){return 2097152&this._data[3*e+0]},e.prototype.getString=function(e){var t=this._data[3*e+0];return 2097152&t?this._combined[e]:2097151&t?(0,i.stringFromCodePoint)(2097151&t):""},e.prototype.loadCell=function(e,t){var r=3*e;return t.content=this._data[r+0],t.fg=this._data[r+1],t.bg=this._data[r+2],2097152&t.content&&(t.combinedData=this._combined[e]),268435456&t.bg&&(t.extended=this._extendedAttrs[e]),t},e.prototype.setCell=function(e,t){2097152&t.content&&(this._combined[e]=t.combinedData),268435456&t.bg&&(this._extendedAttrs[e]=t.extended),this._data[3*e+0]=t.content,this._data[3*e+1]=t.fg,this._data[3*e+2]=t.bg},e.prototype.setCellFromCodePoint=function(e,t,r,i,n,o){268435456&n&&(this._extendedAttrs[e]=o),this._data[3*e+0]=t|r<<22,this._data[3*e+1]=i,this._data[3*e+2]=n},e.prototype.addCodepointToCell=function(e,t){var r=this._data[3*e+0];2097152&r?this._combined[e]+=(0,i.stringFromCodePoint)(t):(2097151&r?(this._combined[e]=(0,i.stringFromCodePoint)(2097151&r)+(0,i.stringFromCodePoint)(t),r&=-2097152,r|=2097152):r=t|1<<22,this._data[3*e+0]=r)},e.prototype.insertCells=function(e,t,r,i){if((e%=this.length)&&2===this.getWidth(e-1)&&this.setCellFromCodePoint(e-1,0,1,(null==i?void 0:i.fg)||0,(null==i?void 0:i.bg)||0,(null==i?void 0:i.extended)||new s.ExtendedAttrs),t<this.length-e){for(var n=new o.CellData,a=this.length-e-t-1;a>=0;--a)this.setCell(e+t+a,this.loadCell(e+a,n));for(a=0;a<t;++a)this.setCell(e+a,r)}else for(a=e;a<this.length;++a)this.setCell(a,r);2===this.getWidth(this.length-1)&&this.setCellFromCodePoint(this.length-1,0,1,(null==i?void 0:i.fg)||0,(null==i?void 0:i.bg)||0,(null==i?void 0:i.extended)||new s.ExtendedAttrs)},e.prototype.deleteCells=function(e,t,r,i){if(e%=this.length,t<this.length-e){for(var n=new o.CellData,a=0;a<this.length-e-t;++a)this.setCell(e+a,this.loadCell(e+t+a,n));for(a=this.length-t;a<this.length;++a)this.setCell(a,r)}else for(a=e;a<this.length;++a)this.setCell(a,r);e&&2===this.getWidth(e-1)&&this.setCellFromCodePoint(e-1,0,1,(null==i?void 0:i.fg)||0,(null==i?void 0:i.bg)||0,(null==i?void 0:i.extended)||new s.ExtendedAttrs),0!==this.getWidth(e)||this.hasContent(e)||this.setCellFromCodePoint(e,0,1,(null==i?void 0:i.fg)||0,(null==i?void 0:i.bg)||0,(null==i?void 0:i.extended)||new s.ExtendedAttrs)},e.prototype.replaceCells=function(e,t,r,i){for(e&&2===this.getWidth(e-1)&&this.setCellFromCodePoint(e-1,0,1,(null==i?void 0:i.fg)||0,(null==i?void 0:i.bg)||0,(null==i?void 0:i.extended)||new s.ExtendedAttrs),t<this.length&&2===this.getWidth(t-1)&&this.setCellFromCodePoint(t,0,1,(null==i?void 0:i.fg)||0,(null==i?void 0:i.bg)||0,(null==i?void 0:i.extended)||new s.ExtendedAttrs);e<t&&e<this.length;)this.setCell(e++,r)},e.prototype.resize=function(e,t){if(e!==this.length){if(e>this.length){var r=new Uint32Array(3*e);this.length&&(3*e<this._data.length?r.set(this._data.subarray(0,3*e)):r.set(this._data)),this._data=r;for(var i=this.length;i<e;++i)this.setCell(i,t)}else if(e){(r=new Uint32Array(3*e)).set(this._data.subarray(0,3*e)),this._data=r;var n=Object.keys(this._combined);for(i=0;i<n.length;i++){var o=parseInt(n[i],10);o>=e&&delete this._combined[o]}}else this._data=new Uint32Array(0),this._combined={};this.length=e}},e.prototype.fill=function(e){this._combined={},this._extendedAttrs={};for(var t=0;t<this.length;++t)this.setCell(t,e)},e.prototype.copyFrom=function(e){for(var t in this.length!==e.length?this._data=new Uint32Array(e._data):this._data.set(e._data),this.length=e.length,this._combined={},e._combined)this._combined[t]=e._combined[t];for(var t in this._extendedAttrs={},e._extendedAttrs)this._extendedAttrs[t]=e._extendedAttrs[t];this.isWrapped=e.isWrapped},e.prototype.clone=function(){var t=new e(0);for(var r in t._data=new Uint32Array(this._data),t.length=this.length,this._combined)t._combined[r]=this._combined[r];for(var r in this._extendedAttrs)t._extendedAttrs[r]=this._extendedAttrs[r];return t.isWrapped=this.isWrapped,t},e.prototype.getTrimmedLength=function(){for(var e=this.length-1;e>=0;--e)if(4194303&this._data[3*e+0])return e+(this._data[3*e+0]>>22);return 0},e.prototype.copyCellsFrom=function(e,t,r,i,n){var o=e._data;if(n)for(var s=i-1;s>=0;s--)for(var a=0;a<3;a++)this._data[3*(r+s)+a]=o[3*(t+s)+a];else for(s=0;s<i;s++)for(a=0;a<3;a++)this._data[3*(r+s)+a]=o[3*(t+s)+a];var c=Object.keys(e._combined);for(a=0;a<c.length;a++){var l=parseInt(c[a],10);l>=t&&(this._combined[l-t+r]=e._combined[l])}},e.prototype.translateToString=function(e,t,r){void 0===e&&(e=!1),void 0===t&&(t=0),void 0===r&&(r=this.length),e&&(r=Math.min(r,this.getTrimmedLength()));for(var o="";t<r;){var s=this._data[3*t+0],a=2097151&s;o+=2097152&s?this._combined[t]:a?(0,i.stringFromCodePoint)(a):n.WHITESPACE_CELL_CHAR,t+=s>>22||1}return o},e}();t.BufferLine=a},4841:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.getRangeLength=void 0,t.getRangeLength=function(e,t){if(e.start.y>e.end.y)throw new Error("Buffer range end ("+e.end.x+", "+e.end.y+") cannot be before start ("+e.start.x+", "+e.start.y+")");return t*(e.end.y-e.start.y)+(e.end.x-e.start.x+1)}},4634:(e,t)=>{function r(e,t,r){if(t===e.length-1)return e[t].getTrimmedLength();var i=!e[t].hasContent(r-1)&&1===e[t].getWidth(r-1),n=2===e[t+1].getWidth(0);return i&&n?r-1:r}Object.defineProperty(t,"__esModule",{value:!0}),t.getWrappedLineTrimmedLength=t.reflowSmallerGetNewLineLengths=t.reflowLargerApplyNewLayout=t.reflowLargerCreateNewLayout=t.reflowLargerGetLinesToRemove=void 0,t.reflowLargerGetLinesToRemove=function(e,t,i,n,o){for(var s=[],a=0;a<e.length-1;a++){var c=a,l=e.get(++c);if(l.isWrapped){for(var u=[e.get(a)];c<e.length&&l.isWrapped;)u.push(l),l=e.get(++c);if(n>=a&&n<c)a+=u.length-1;else{for(var h=0,f=r(u,h,t),_=1,d=0;_<u.length;){var p=r(u,_,t),v=p-d,g=i-f,y=Math.min(v,g);u[h].copyCellsFrom(u[_],d,f,y,!1),(f+=y)===i&&(h++,f=0),(d+=y)===p&&(_++,d=0),0===f&&0!==h&&2===u[h-1].getWidth(i-1)&&(u[h].copyCellsFrom(u[h-1],i-1,f++,1,!1),u[h-1].setCell(i-1,o))}u[h].replaceCells(f,i,o);for(var m=0,b=u.length-1;b>0&&(b>h||0===u[b].getTrimmedLength());b--)m++;m>0&&(s.push(a+u.length-m),s.push(m)),a+=u.length-1}}}return s},t.reflowLargerCreateNewLayout=function(e,t){for(var r=[],i=0,n=t[i],o=0,s=0;s<e.length;s++)if(n===s){var a=t[++i];e.onDeleteEmitter.fire({index:s-o,amount:a}),s+=a-1,o+=a,n=t[++i]}else r.push(s);return{layout:r,countRemoved:o}},t.reflowLargerApplyNewLayout=function(e,t){for(var r=[],i=0;i<t.length;i++)r.push(e.get(t[i]));for(i=0;i<r.length;i++)e.set(i,r[i]);e.length=t.length},t.reflowSmallerGetNewLineLengths=function(e,t,i){for(var n=[],o=e.map((function(i,n){return r(e,n,t)})).reduce((function(e,t){return e+t})),s=0,a=0,c=0;c<o;){if(o-c<i){n.push(o-c);break}s+=i;var l=r(e,a,t);s>l&&(s-=l,a++);var u=2===e[a].getWidth(s-1);u&&s--;var h=u?i-1:i;n.push(h),c+=h}return n},t.getWrappedLineTrimmedLength=r},5295:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)});Object.defineProperty(t,"__esModule",{value:!0}),t.BufferSet=void 0;var o=r(9092),s=r(8460),a=function(e){function t(t,r){var i=e.call(this)||this;return i._optionsService=t,i._bufferService=r,i._onBufferActivate=i.register(new s.EventEmitter),i.reset(),i}return n(t,e),Object.defineProperty(t.prototype,"onBufferActivate",{get:function(){return this._onBufferActivate.event},enumerable:!1,configurable:!0}),t.prototype.reset=function(){this._normal=new o.Buffer(!0,this._optionsService,this._bufferService),this._normal.fillViewportRows(),this._alt=new o.Buffer(!1,this._optionsService,this._bufferService),this._activeBuffer=this._normal,this._onBufferActivate.fire({activeBuffer:this._normal,inactiveBuffer:this._alt}),this.setupTabStops()},Object.defineProperty(t.prototype,"alt",{get:function(){return this._alt},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"active",{get:function(){return this._activeBuffer},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"normal",{get:function(){return this._normal},enumerable:!1,configurable:!0}),t.prototype.activateNormalBuffer=function(){this._activeBuffer!==this._normal&&(this._normal.x=this._alt.x,this._normal.y=this._alt.y,this._alt.clear(),this._activeBuffer=this._normal,this._onBufferActivate.fire({activeBuffer:this._normal,inactiveBuffer:this._alt}))},t.prototype.activateAltBuffer=function(e){this._activeBuffer!==this._alt&&(this._alt.fillViewportRows(e),this._alt.x=this._normal.x,this._alt.y=this._normal.y,this._activeBuffer=this._alt,this._onBufferActivate.fire({activeBuffer:this._alt,inactiveBuffer:this._normal}))},t.prototype.resize=function(e,t){this._normal.resize(e,t),this._alt.resize(e,t)},t.prototype.setupTabStops=function(e){this._normal.setupTabStops(e),this._alt.setupTabStops(e)},t}(r(844).Disposable);t.BufferSet=a},511:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)});Object.defineProperty(t,"__esModule",{value:!0}),t.CellData=void 0;var o=r(482),s=r(643),a=r(3734),c=function(e){function t(){var t=null!==e&&e.apply(this,arguments)||this;return t.content=0,t.fg=0,t.bg=0,t.extended=new a.ExtendedAttrs,t.combinedData="",t}return n(t,e),t.fromCharData=function(e){var r=new t;return r.setFromCharData(e),r},t.prototype.isCombined=function(){return 2097152&this.content},t.prototype.getWidth=function(){return this.content>>22},t.prototype.getChars=function(){return 2097152&this.content?this.combinedData:2097151&this.content?(0,o.stringFromCodePoint)(2097151&this.content):""},t.prototype.getCode=function(){return this.isCombined()?this.combinedData.charCodeAt(this.combinedData.length-1):2097151&this.content},t.prototype.setFromCharData=function(e){this.fg=e[s.CHAR_DATA_ATTR_INDEX],this.bg=0;var t=!1;if(e[s.CHAR_DATA_CHAR_INDEX].length>2)t=!0;else if(2===e[s.CHAR_DATA_CHAR_INDEX].length){var r=e[s.CHAR_DATA_CHAR_INDEX].charCodeAt(0);if(55296<=r&&r<=56319){var i=e[s.CHAR_DATA_CHAR_INDEX].charCodeAt(1);56320<=i&&i<=57343?this.content=1024*(r-55296)+i-56320+65536|e[s.CHAR_DATA_WIDTH_INDEX]<<22:t=!0}else t=!0}else this.content=e[s.CHAR_DATA_CHAR_INDEX].charCodeAt(0)|e[s.CHAR_DATA_WIDTH_INDEX]<<22;t&&(this.combinedData=e[s.CHAR_DATA_CHAR_INDEX],this.content=2097152|e[s.CHAR_DATA_WIDTH_INDEX]<<22)},t.prototype.getAsCharData=function(){return[this.fg,this.getChars(),this.getWidth(),this.getCode()]},t}(a.AttributeData);t.CellData=c},643:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.WHITESPACE_CELL_CODE=t.WHITESPACE_CELL_WIDTH=t.WHITESPACE_CELL_CHAR=t.NULL_CELL_CODE=t.NULL_CELL_WIDTH=t.NULL_CELL_CHAR=t.CHAR_DATA_CODE_INDEX=t.CHAR_DATA_WIDTH_INDEX=t.CHAR_DATA_CHAR_INDEX=t.CHAR_DATA_ATTR_INDEX=t.DEFAULT_ATTR=t.DEFAULT_COLOR=void 0,t.DEFAULT_COLOR=256,t.DEFAULT_ATTR=256|t.DEFAULT_COLOR<<9,t.CHAR_DATA_ATTR_INDEX=0,t.CHAR_DATA_CHAR_INDEX=1,t.CHAR_DATA_WIDTH_INDEX=2,t.CHAR_DATA_CODE_INDEX=3,t.NULL_CELL_CHAR="",t.NULL_CELL_WIDTH=1,t.NULL_CELL_CODE=0,t.WHITESPACE_CELL_CHAR=" ",t.WHITESPACE_CELL_WIDTH=1,t.WHITESPACE_CELL_CODE=32},4863:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)});Object.defineProperty(t,"__esModule",{value:!0}),t.Marker=void 0;var o=r(8460),s=function(e){function t(r){var i=e.call(this)||this;return i.line=r,i._id=t._nextId++,i.isDisposed=!1,i._onDispose=new o.EventEmitter,i}return n(t,e),Object.defineProperty(t.prototype,"id",{get:function(){return this._id},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onDispose",{get:function(){return this._onDispose.event},enumerable:!1,configurable:!0}),t.prototype.dispose=function(){this.isDisposed||(this.isDisposed=!0,this.line=-1,this._onDispose.fire(),e.prototype.dispose.call(this))},t._nextId=1,t}(r(844).Disposable);t.Marker=s},7116:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.DEFAULT_CHARSET=t.CHARSETS=void 0,t.CHARSETS={},t.DEFAULT_CHARSET=t.CHARSETS.B,t.CHARSETS[0]={"`":"◆",a:"▒",b:"␉",c:"␌",d:"␍",e:"␊",f:"°",g:"±",h:"␤",i:"␋",j:"┘",k:"┐",l:"┌",m:"└",n:"┼",o:"⎺",p:"⎻",q:"─",r:"⎼",s:"⎽",t:"├",u:"┤",v:"┴",w:"┬",x:"│",y:"≤",z:"≥","{":"π","|":"≠","}":"£","~":"·"},t.CHARSETS.A={"#":"£"},t.CHARSETS.B=void 0,t.CHARSETS[4]={"#":"£","@":"¾","[":"ij","\\":"½","]":"|","{":"¨","|":"f","}":"¼","~":"´"},t.CHARSETS.C=t.CHARSETS[5]={"[":"Ä","\\":"Ö","]":"Å","^":"Ü","`":"é","{":"ä","|":"ö","}":"å","~":"ü"},t.CHARSETS.R={"#":"£","@":"à","[":"°","\\":"ç","]":"§","{":"é","|":"ù","}":"è","~":"¨"},t.CHARSETS.Q={"@":"à","[":"â","\\":"ç","]":"ê","^":"î","`":"ô","{":"é","|":"ù","}":"è","~":"û"},t.CHARSETS.K={"@":"§","[":"Ä","\\":"Ö","]":"Ü","{":"ä","|":"ö","}":"ü","~":"ß"},t.CHARSETS.Y={"#":"£","@":"§","[":"°","\\":"ç","]":"é","`":"ù","{":"à","|":"ò","}":"è","~":"ì"},t.CHARSETS.E=t.CHARSETS[6]={"@":"Ä","[":"Æ","\\":"Ø","]":"Å","^":"Ü","`":"ä","{":"æ","|":"ø","}":"å","~":"ü"},t.CHARSETS.Z={"#":"£","@":"§","[":"¡","\\":"Ñ","]":"¿","{":"°","|":"ñ","}":"ç"},t.CHARSETS.H=t.CHARSETS[7]={"@":"É","[":"Ä","\\":"Ö","]":"Å","^":"Ü","`":"é","{":"ä","|":"ö","}":"å","~":"ü"},t.CHARSETS["="]={"#":"ù","@":"à","[":"é","\\":"ç","]":"ê","^":"î",_:"è","`":"ô","{":"ä","|":"ö","}":"ü","~":"û"}},2584:(e,t)=>{var r,i;Object.defineProperty(t,"__esModule",{value:!0}),t.C1=t.C0=void 0,(i=t.C0||(t.C0={})).NUL="\0",i.SOH="",i.STX="",i.ETX="",i.EOT="",i.ENQ="",i.ACK="",i.BEL="",i.BS="\b",i.HT="\t",i.LF="\n",i.VT="\v",i.FF="\f",i.CR="\r",i.SO="",i.SI="",i.DLE="",i.DC1="",i.DC2="",i.DC3="",i.DC4="",i.NAK="",i.SYN="",i.ETB="",i.CAN="",i.EM="",i.SUB="",i.ESC="",i.FS="",i.GS="",i.RS="",i.US="",i.SP=" ",i.DEL="",(r=t.C1||(t.C1={})).PAD="",r.HOP="",r.BPH="",r.NBH="",r.IND="",r.NEL="",r.SSA="",r.ESA="",r.HTS="",r.HTJ="",r.VTS="",r.PLD="",r.PLU="",r.RI="",r.SS2="",r.SS3="",r.DCS="",r.PU1="",r.PU2="",r.STS="",r.CCH="",r.MW="",r.SPA="",r.EPA="",r.SOS="",r.SGCI="",r.SCI="",r.CSI="",r.ST="",r.OSC="",r.PM="",r.APC=""},7399:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.evaluateKeyboardEvent=void 0;var i=r(2584),n={48:["0",")"],49:["1","!"],50:["2","@"],51:["3","#"],52:["4","$"],53:["5","%"],54:["6","^"],55:["7","&"],56:["8","*"],57:["9","("],186:[";",":"],187:["=","+"],188:[",","<"],189:["-","_"],190:[".",">"],191:["/","?"],192:["`","~"],219:["[","{"],220:["\\","|"],221:["]","}"],222:["'",'"']};t.evaluateKeyboardEvent=function(e,t,r,o){var s={type:0,cancel:!1,key:void 0},a=(e.shiftKey?1:0)|(e.altKey?2:0)|(e.ctrlKey?4:0)|(e.metaKey?8:0);switch(e.keyCode){case 0:"UIKeyInputUpArrow"===e.key?s.key=t?i.C0.ESC+"OA":i.C0.ESC+"[A":"UIKeyInputLeftArrow"===e.key?s.key=t?i.C0.ESC+"OD":i.C0.ESC+"[D":"UIKeyInputRightArrow"===e.key?s.key=t?i.C0.ESC+"OC":i.C0.ESC+"[C":"UIKeyInputDownArrow"===e.key&&(s.key=t?i.C0.ESC+"OB":i.C0.ESC+"[B");break;case 8:if(e.shiftKey){s.key=i.C0.BS;break}if(e.altKey){s.key=i.C0.ESC+i.C0.DEL;break}s.key=i.C0.DEL;break;case 9:if(e.shiftKey){s.key=i.C0.ESC+"[Z";break}s.key=i.C0.HT,s.cancel=!0;break;case 13:s.key=e.altKey?i.C0.ESC+i.C0.CR:i.C0.CR,s.cancel=!0;break;case 27:s.key=i.C0.ESC,e.altKey&&(s.key=i.C0.ESC+i.C0.ESC),s.cancel=!0;break;case 37:if(e.metaKey)break;a?(s.key=i.C0.ESC+"[1;"+(a+1)+"D",s.key===i.C0.ESC+"[1;3D"&&(s.key=i.C0.ESC+(r?"b":"[1;5D"))):s.key=t?i.C0.ESC+"OD":i.C0.ESC+"[D";break;case 39:if(e.metaKey)break;a?(s.key=i.C0.ESC+"[1;"+(a+1)+"C",s.key===i.C0.ESC+"[1;3C"&&(s.key=i.C0.ESC+(r?"f":"[1;5C"))):s.key=t?i.C0.ESC+"OC":i.C0.ESC+"[C";break;case 38:if(e.metaKey)break;a?(s.key=i.C0.ESC+"[1;"+(a+1)+"A",r||s.key!==i.C0.ESC+"[1;3A"||(s.key=i.C0.ESC+"[1;5A")):s.key=t?i.C0.ESC+"OA":i.C0.ESC+"[A";break;case 40:if(e.metaKey)break;a?(s.key=i.C0.ESC+"[1;"+(a+1)+"B",r||s.key!==i.C0.ESC+"[1;3B"||(s.key=i.C0.ESC+"[1;5B")):s.key=t?i.C0.ESC+"OB":i.C0.ESC+"[B";break;case 45:e.shiftKey||e.ctrlKey||(s.key=i.C0.ESC+"[2~");break;case 46:s.key=a?i.C0.ESC+"[3;"+(a+1)+"~":i.C0.ESC+"[3~";break;case 36:s.key=a?i.C0.ESC+"[1;"+(a+1)+"H":t?i.C0.ESC+"OH":i.C0.ESC+"[H";break;case 35:s.key=a?i.C0.ESC+"[1;"+(a+1)+"F":t?i.C0.ESC+"OF":i.C0.ESC+"[F";break;case 33:e.shiftKey?s.type=2:s.key=i.C0.ESC+"[5~";break;case 34:e.shiftKey?s.type=3:s.key=i.C0.ESC+"[6~";break;case 112:s.key=a?i.C0.ESC+"[1;"+(a+1)+"P":i.C0.ESC+"OP";break;case 113:s.key=a?i.C0.ESC+"[1;"+(a+1)+"Q":i.C0.ESC+"OQ";break;case 114:s.key=a?i.C0.ESC+"[1;"+(a+1)+"R":i.C0.ESC+"OR";break;case 115:s.key=a?i.C0.ESC+"[1;"+(a+1)+"S":i.C0.ESC+"OS";break;case 116:s.key=a?i.C0.ESC+"[15;"+(a+1)+"~":i.C0.ESC+"[15~";break;case 117:s.key=a?i.C0.ESC+"[17;"+(a+1)+"~":i.C0.ESC+"[17~";break;case 118:s.key=a?i.C0.ESC+"[18;"+(a+1)+"~":i.C0.ESC+"[18~";break;case 119:s.key=a?i.C0.ESC+"[19;"+(a+1)+"~":i.C0.ESC+"[19~";break;case 120:s.key=a?i.C0.ESC+"[20;"+(a+1)+"~":i.C0.ESC+"[20~";break;case 121:s.key=a?i.C0.ESC+"[21;"+(a+1)+"~":i.C0.ESC+"[21~";break;case 122:s.key=a?i.C0.ESC+"[23;"+(a+1)+"~":i.C0.ESC+"[23~";break;case 123:s.key=a?i.C0.ESC+"[24;"+(a+1)+"~":i.C0.ESC+"[24~";break;default:if(!e.ctrlKey||e.shiftKey||e.altKey||e.metaKey)if(r&&!o||!e.altKey||e.metaKey)!r||e.altKey||e.ctrlKey||e.shiftKey||!e.metaKey?e.key&&!e.ctrlKey&&!e.altKey&&!e.metaKey&&e.keyCode>=48&&1===e.key.length?s.key=e.key:e.key&&e.ctrlKey&&"_"===e.key&&(s.key=i.C0.US):65===e.keyCode&&(s.type=1);else{var c=n[e.keyCode],l=null==c?void 0:c[e.shiftKey?1:0];if(l)s.key=i.C0.ESC+l;else if(e.keyCode>=65&&e.keyCode<=90){var u=e.ctrlKey?e.keyCode-64:e.keyCode+32;s.key=i.C0.ESC+String.fromCharCode(u)}}else e.keyCode>=65&&e.keyCode<=90?s.key=String.fromCharCode(e.keyCode-64):32===e.keyCode?s.key=i.C0.NUL:e.keyCode>=51&&e.keyCode<=55?s.key=String.fromCharCode(e.keyCode-51+27):56===e.keyCode?s.key=i.C0.DEL:219===e.keyCode?s.key=i.C0.ESC:220===e.keyCode?s.key=i.C0.FS:221===e.keyCode&&(s.key=i.C0.GS)}return s}},482:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.Utf8ToUtf32=t.StringToUtf32=t.utf32ToString=t.stringFromCodePoint=void 0,t.stringFromCodePoint=function(e){return e>65535?(e-=65536,String.fromCharCode(55296+(e>>10))+String.fromCharCode(e%1024+56320)):String.fromCharCode(e)},t.utf32ToString=function(e,t,r){void 0===t&&(t=0),void 0===r&&(r=e.length);for(var i="",n=t;n<r;++n){var o=e[n];o>65535?(o-=65536,i+=String.fromCharCode(55296+(o>>10))+String.fromCharCode(o%1024+56320)):i+=String.fromCharCode(o)}return i};var r=function(){function e(){this._interim=0}return e.prototype.clear=function(){this._interim=0},e.prototype.decode=function(e,t){var r=e.length;if(!r)return 0;var i=0,n=0;this._interim&&(56320<=(a=e.charCodeAt(n++))&&a<=57343?t[i++]=1024*(this._interim-55296)+a-56320+65536:(t[i++]=this._interim,t[i++]=a),this._interim=0);for(var o=n;o<r;++o){var s=e.charCodeAt(o);if(55296<=s&&s<=56319){if(++o>=r)return this._interim=s,i;var a;56320<=(a=e.charCodeAt(o))&&a<=57343?t[i++]=1024*(s-55296)+a-56320+65536:(t[i++]=s,t[i++]=a)}else 65279!==s&&(t[i++]=s)}return i},e}();t.StringToUtf32=r;var i=function(){function e(){this.interim=new Uint8Array(3)}return e.prototype.clear=function(){this.interim.fill(0)},e.prototype.decode=function(e,t){var r=e.length;if(!r)return 0;var i,n,o,s,a=0,c=0,l=0;if(this.interim[0]){var u=!1,h=this.interim[0];h&=192==(224&h)?31:224==(240&h)?15:7;for(var f=0,_=void 0;(_=63&this.interim[++f])&&f<4;)h<<=6,h|=_;for(var d=192==(224&this.interim[0])?2:224==(240&this.interim[0])?3:4,p=d-f;l<p;){if(l>=r)return 0;if(128!=(192&(_=e[l++]))){l--,u=!0;break}this.interim[f++]=_,h<<=6,h|=63&_}u||(2===d?h<128?l--:t[a++]=h:3===d?h<2048||h>=55296&&h<=57343||65279===h||(t[a++]=h):h<65536||h>1114111||(t[a++]=h)),this.interim.fill(0)}for(var v=r-4,g=l;g<r;){for(;!(!(g<v)||128&(i=e[g])||128&(n=e[g+1])||128&(o=e[g+2])||128&(s=e[g+3]));)t[a++]=i,t[a++]=n,t[a++]=o,t[a++]=s,g+=4;if((i=e[g++])<128)t[a++]=i;else if(192==(224&i)){if(g>=r)return this.interim[0]=i,a;if(128!=(192&(n=e[g++]))){g--;continue}if((c=(31&i)<<6|63&n)<128){g--;continue}t[a++]=c}else if(224==(240&i)){if(g>=r)return this.interim[0]=i,a;if(128!=(192&(n=e[g++]))){g--;continue}if(g>=r)return this.interim[0]=i,this.interim[1]=n,a;if(128!=(192&(o=e[g++]))){g--;continue}if((c=(15&i)<<12|(63&n)<<6|63&o)<2048||c>=55296&&c<=57343||65279===c)continue;t[a++]=c}else if(240==(248&i)){if(g>=r)return this.interim[0]=i,a;if(128!=(192&(n=e[g++]))){g--;continue}if(g>=r)return this.interim[0]=i,this.interim[1]=n,a;if(128!=(192&(o=e[g++]))){g--;continue}if(g>=r)return this.interim[0]=i,this.interim[1]=n,this.interim[2]=o,a;if(128!=(192&(s=e[g++]))){g--;continue}if((c=(7&i)<<18|(63&n)<<12|(63&o)<<6|63&s)<65536||c>1114111)continue;t[a++]=c}}return a},e}();t.Utf8ToUtf32=i},225:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.UnicodeV6=void 0;var i,n=r(8273),o=[[768,879],[1155,1158],[1160,1161],[1425,1469],[1471,1471],[1473,1474],[1476,1477],[1479,1479],[1536,1539],[1552,1557],[1611,1630],[1648,1648],[1750,1764],[1767,1768],[1770,1773],[1807,1807],[1809,1809],[1840,1866],[1958,1968],[2027,2035],[2305,2306],[2364,2364],[2369,2376],[2381,2381],[2385,2388],[2402,2403],[2433,2433],[2492,2492],[2497,2500],[2509,2509],[2530,2531],[2561,2562],[2620,2620],[2625,2626],[2631,2632],[2635,2637],[2672,2673],[2689,2690],[2748,2748],[2753,2757],[2759,2760],[2765,2765],[2786,2787],[2817,2817],[2876,2876],[2879,2879],[2881,2883],[2893,2893],[2902,2902],[2946,2946],[3008,3008],[3021,3021],[3134,3136],[3142,3144],[3146,3149],[3157,3158],[3260,3260],[3263,3263],[3270,3270],[3276,3277],[3298,3299],[3393,3395],[3405,3405],[3530,3530],[3538,3540],[3542,3542],[3633,3633],[3636,3642],[3655,3662],[3761,3761],[3764,3769],[3771,3772],[3784,3789],[3864,3865],[3893,3893],[3895,3895],[3897,3897],[3953,3966],[3968,3972],[3974,3975],[3984,3991],[3993,4028],[4038,4038],[4141,4144],[4146,4146],[4150,4151],[4153,4153],[4184,4185],[4448,4607],[4959,4959],[5906,5908],[5938,5940],[5970,5971],[6002,6003],[6068,6069],[6071,6077],[6086,6086],[6089,6099],[6109,6109],[6155,6157],[6313,6313],[6432,6434],[6439,6440],[6450,6450],[6457,6459],[6679,6680],[6912,6915],[6964,6964],[6966,6970],[6972,6972],[6978,6978],[7019,7027],[7616,7626],[7678,7679],[8203,8207],[8234,8238],[8288,8291],[8298,8303],[8400,8431],[12330,12335],[12441,12442],[43014,43014],[43019,43019],[43045,43046],[64286,64286],[65024,65039],[65056,65059],[65279,65279],[65529,65531]],s=[[68097,68099],[68101,68102],[68108,68111],[68152,68154],[68159,68159],[119143,119145],[119155,119170],[119173,119179],[119210,119213],[119362,119364],[917505,917505],[917536,917631],[917760,917999]],a=function(){function e(){if(this.version="6",!i){i=new Uint8Array(65536),(0,n.fill)(i,1),i[0]=0,(0,n.fill)(i,0,1,32),(0,n.fill)(i,0,127,160),(0,n.fill)(i,2,4352,4448),i[9001]=2,i[9002]=2,(0,n.fill)(i,2,11904,42192),i[12351]=1,(0,n.fill)(i,2,44032,55204),(0,n.fill)(i,2,63744,64256),(0,n.fill)(i,2,65040,65050),(0,n.fill)(i,2,65072,65136),(0,n.fill)(i,2,65280,65377),(0,n.fill)(i,2,65504,65511);for(var e=0;e<o.length;++e)(0,n.fill)(i,0,o[e][0],o[e][1]+1)}}return e.prototype.wcwidth=function(e){return e<32?0:e<127?1:e<65536?i[e]:function(e,t){var r,i=0,n=t.length-1;if(e<t[0][0]||e>t[n][1])return!1;for(;n>=i;)if(e>t[r=i+n>>1][1])i=r+1;else{if(!(e<t[r][0]))return!0;n=r-1}return!1}(e,s)?0:e>=131072&&e<=196605||e>=196608&&e<=262141?2:1},e}();t.UnicodeV6=a},5981:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.WriteBuffer=void 0;var r="undefined"==typeof queueMicrotask?function(e){Promise.resolve().then(e)}:queueMicrotask,i=function(){function e(e){this._action=e,this._writeBuffer=[],this._callbacks=[],this._pendingData=0,this._bufferOffset=0,this._isSyncWriting=!1,this._syncCalls=0}return e.prototype.writeSync=function(e,t){if(void 0!==t&&this._syncCalls>t)this._syncCalls=0;else if(this._pendingData+=e.length,this._writeBuffer.push(e),this._callbacks.push(void 0),this._syncCalls++,!this._isSyncWriting){var r;for(this._isSyncWriting=!0;r=this._writeBuffer.shift();){this._action(r);var i=this._callbacks.shift();i&&i()}this._pendingData=0,this._bufferOffset=2147483647,this._isSyncWriting=!1,this._syncCalls=0}},e.prototype.write=function(e,t){var r=this;if(this._pendingData>5e7)throw new Error("write data discarded, use flow control to avoid losing data");this._writeBuffer.length||(this._bufferOffset=0,setTimeout((function(){return r._innerWrite()}))),this._pendingData+=e.length,this._writeBuffer.push(e),this._callbacks.push(t)},e.prototype._innerWrite=function(e,t){var i=this;void 0===e&&(e=0),void 0===t&&(t=!0);for(var n=e||Date.now();this._writeBuffer.length>this._bufferOffset;){var o=this._writeBuffer[this._bufferOffset],s=this._action(o,t);if(s)return void s.catch((function(e){return r((function(){throw e})),Promise.resolve(!1)})).then((function(e){return Date.now()-n>=12?setTimeout((function(){return i._innerWrite(0,e)})):i._innerWrite(n,e)}));var a=this._callbacks[this._bufferOffset];if(a&&a(),this._bufferOffset++,this._pendingData-=o.length,Date.now()-n>=12)break}this._writeBuffer.length>this._bufferOffset?(this._bufferOffset>50&&(this._writeBuffer=this._writeBuffer.slice(this._bufferOffset),this._callbacks=this._callbacks.slice(this._bufferOffset),this._bufferOffset=0),setTimeout((function(){return i._innerWrite()}))):(this._writeBuffer.length=0,this._callbacks.length=0,this._pendingData=0,this._bufferOffset=0)},e}();t.WriteBuffer=i},5941:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.toRgbString=t.parseColor=void 0;var r=/^([\da-f]{1})\/([\da-f]{1})\/([\da-f]{1})$|^([\da-f]{2})\/([\da-f]{2})\/([\da-f]{2})$|^([\da-f]{3})\/([\da-f]{3})\/([\da-f]{3})$|^([\da-f]{4})\/([\da-f]{4})\/([\da-f]{4})$/,i=/^[\da-f]+$/;function n(e,t){var r=e.toString(16),i=r.length<2?"0"+r:r;switch(t){case 4:return r[0];case 8:return i;case 12:return(i+i).slice(0,3);default:return i+i}}t.parseColor=function(e){if(e){var t=e.toLowerCase();if(0===t.indexOf("rgb:")){t=t.slice(4);var n=r.exec(t);if(n){var o=n[1]?15:n[4]?255:n[7]?4095:65535;return[Math.round(parseInt(n[1]||n[4]||n[7]||n[10],16)/o*255),Math.round(parseInt(n[2]||n[5]||n[8]||n[11],16)/o*255),Math.round(parseInt(n[3]||n[6]||n[9]||n[12],16)/o*255)]}}else if(0===t.indexOf("#")&&(t=t.slice(1),i.exec(t)&&[3,6,9,12].includes(t.length))){for(var s=t.length/3,a=[0,0,0],c=0;c<3;++c){var l=parseInt(t.slice(s*c,s*c+s),16);a[c]=1===s?l<<4:2===s?l:3===s?l>>4:l>>8}return a}}},t.toRgbString=function(e,t){void 0===t&&(t=16);var r=e[0],i=e[1],o=e[2];return"rgb:"+n(r,t)+"/"+n(i,t)+"/"+n(o,t)}},5770:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.PAYLOAD_LIMIT=void 0,t.PAYLOAD_LIMIT=1e7},6351:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.DcsHandler=t.DcsParser=void 0;var i=r(482),n=r(8742),o=r(5770),s=[],a=function(){function e(){this._handlers=Object.create(null),this._active=s,this._ident=0,this._handlerFb=function(){},this._stack={paused:!1,loopPosition:0,fallThrough:!1}}return e.prototype.dispose=function(){this._handlers=Object.create(null),this._handlerFb=function(){},this._active=s},e.prototype.registerHandler=function(e,t){void 0===this._handlers[e]&&(this._handlers[e]=[]);var r=this._handlers[e];return r.push(t),{dispose:function(){var e=r.indexOf(t);-1!==e&&r.splice(e,1)}}},e.prototype.clearHandler=function(e){this._handlers[e]&&delete this._handlers[e]},e.prototype.setHandlerFallback=function(e){this._handlerFb=e},e.prototype.reset=function(){if(this._active.length)for(var e=this._stack.paused?this._stack.loopPosition-1:this._active.length-1;e>=0;--e)this._active[e].unhook(!1);this._stack.paused=!1,this._active=s,this._ident=0},e.prototype.hook=function(e,t){if(this.reset(),this._ident=e,this._active=this._handlers[e]||s,this._active.length)for(var r=this._active.length-1;r>=0;r--)this._active[r].hook(t);else this._handlerFb(this._ident,"HOOK",t)},e.prototype.put=function(e,t,r){if(this._active.length)for(var n=this._active.length-1;n>=0;n--)this._active[n].put(e,t,r);else this._handlerFb(this._ident,"PUT",(0,i.utf32ToString)(e,t,r))},e.prototype.unhook=function(e,t){if(void 0===t&&(t=!0),this._active.length){var r=!1,i=this._active.length-1,n=!1;if(this._stack.paused&&(i=this._stack.loopPosition-1,r=t,n=this._stack.fallThrough,this._stack.paused=!1),!n&&!1===r){for(;i>=0&&!0!==(r=this._active[i].unhook(e));i--)if(r instanceof Promise)return this._stack.paused=!0,this._stack.loopPosition=i,this._stack.fallThrough=!1,r;i--}for(;i>=0;i--)if((r=this._active[i].unhook(!1))instanceof Promise)return this._stack.paused=!0,this._stack.loopPosition=i,this._stack.fallThrough=!0,r}else this._handlerFb(this._ident,"UNHOOK",e);this._active=s,this._ident=0},e}();t.DcsParser=a;var c=new n.Params;c.addParam(0);var l=function(){function e(e){this._handler=e,this._data="",this._params=c,this._hitLimit=!1}return e.prototype.hook=function(e){this._params=e.length>1||e.params[0]?e.clone():c,this._data="",this._hitLimit=!1},e.prototype.put=function(e,t,r){this._hitLimit||(this._data+=(0,i.utf32ToString)(e,t,r),this._data.length>o.PAYLOAD_LIMIT&&(this._data="",this._hitLimit=!0))},e.prototype.unhook=function(e){var t=this,r=!1;if(this._hitLimit)r=!1;else if(e&&(r=this._handler(this._data,this._params))instanceof Promise)return r.then((function(e){return t._params=c,t._data="",t._hitLimit=!1,e}));return this._params=c,this._data="",this._hitLimit=!1,r},e}();t.DcsHandler=l},2015:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)});Object.defineProperty(t,"__esModule",{value:!0}),t.EscapeSequenceParser=t.VT500_TRANSITION_TABLE=t.TransitionTable=void 0;var o=r(844),s=r(8273),a=r(8742),c=r(6242),l=r(6351),u=function(){function e(e){this.table=new Uint8Array(e)}return e.prototype.setDefault=function(e,t){(0,s.fill)(this.table,e<<4|t)},e.prototype.add=function(e,t,r,i){this.table[t<<8|e]=r<<4|i},e.prototype.addMany=function(e,t,r,i){for(var n=0;n<e.length;n++)this.table[t<<8|e[n]]=r<<4|i},e}();t.TransitionTable=u;var h=160;t.VT500_TRANSITION_TABLE=function(){var e=new u(4095),t=Array.apply(null,Array(256)).map((function(e,t){return t})),r=function(e,r){return t.slice(e,r)},i=r(32,127),n=r(0,24);n.push(25),n.push.apply(n,r(28,32));var o,s=r(0,14);for(o in e.setDefault(1,0),e.addMany(i,0,2,0),s)e.addMany([24,26,153,154],o,3,0),e.addMany(r(128,144),o,3,0),e.addMany(r(144,152),o,3,0),e.add(156,o,0,0),e.add(27,o,11,1),e.add(157,o,4,8),e.addMany([152,158,159],o,0,7),e.add(155,o,11,3),e.add(144,o,11,9);return e.addMany(n,0,3,0),e.addMany(n,1,3,1),e.add(127,1,0,1),e.addMany(n,8,0,8),e.addMany(n,3,3,3),e.add(127,3,0,3),e.addMany(n,4,3,4),e.add(127,4,0,4),e.addMany(n,6,3,6),e.addMany(n,5,3,5),e.add(127,5,0,5),e.addMany(n,2,3,2),e.add(127,2,0,2),e.add(93,1,4,8),e.addMany(i,8,5,8),e.add(127,8,5,8),e.addMany([156,27,24,26,7],8,6,0),e.addMany(r(28,32),8,0,8),e.addMany([88,94,95],1,0,7),e.addMany(i,7,0,7),e.addMany(n,7,0,7),e.add(156,7,0,0),e.add(127,7,0,7),e.add(91,1,11,3),e.addMany(r(64,127),3,7,0),e.addMany(r(48,60),3,8,4),e.addMany([60,61,62,63],3,9,4),e.addMany(r(48,60),4,8,4),e.addMany(r(64,127),4,7,0),e.addMany([60,61,62,63],4,0,6),e.addMany(r(32,64),6,0,6),e.add(127,6,0,6),e.addMany(r(64,127),6,0,0),e.addMany(r(32,48),3,9,5),e.addMany(r(32,48),5,9,5),e.addMany(r(48,64),5,0,6),e.addMany(r(64,127),5,7,0),e.addMany(r(32,48),4,9,5),e.addMany(r(32,48),1,9,2),e.addMany(r(32,48),2,9,2),e.addMany(r(48,127),2,10,0),e.addMany(r(48,80),1,10,0),e.addMany(r(81,88),1,10,0),e.addMany([89,90,92],1,10,0),e.addMany(r(96,127),1,10,0),e.add(80,1,11,9),e.addMany(n,9,0,9),e.add(127,9,0,9),e.addMany(r(28,32),9,0,9),e.addMany(r(32,48),9,9,12),e.addMany(r(48,60),9,8,10),e.addMany([60,61,62,63],9,9,10),e.addMany(n,11,0,11),e.addMany(r(32,128),11,0,11),e.addMany(r(28,32),11,0,11),e.addMany(n,10,0,10),e.add(127,10,0,10),e.addMany(r(28,32),10,0,10),e.addMany(r(48,60),10,8,10),e.addMany([60,61,62,63],10,0,11),e.addMany(r(32,48),10,9,12),e.addMany(n,12,0,12),e.add(127,12,0,12),e.addMany(r(28,32),12,0,12),e.addMany(r(32,48),12,9,12),e.addMany(r(48,64),12,0,11),e.addMany(r(64,127),12,12,13),e.addMany(r(64,127),10,12,13),e.addMany(r(64,127),9,12,13),e.addMany(n,13,13,13),e.addMany(i,13,13,13),e.add(127,13,0,13),e.addMany([27,156,24,26],13,14,0),e.add(h,0,2,0),e.add(h,8,5,8),e.add(h,6,0,6),e.add(h,11,0,11),e.add(h,13,13,13),e}();var f=function(e){function r(r){void 0===r&&(r=t.VT500_TRANSITION_TABLE);var i=e.call(this)||this;return i._transitions=r,i._parseStack={state:0,handlers:[],handlerPos:0,transition:0,chunkPos:0},i.initialState=0,i.currentState=i.initialState,i._params=new a.Params,i._params.addParam(0),i._collect=0,i.precedingCodepoint=0,i._printHandlerFb=function(e,t,r){},i._executeHandlerFb=function(e){},i._csiHandlerFb=function(e,t){},i._escHandlerFb=function(e){},i._errorHandlerFb=function(e){return e},i._printHandler=i._printHandlerFb,i._executeHandlers=Object.create(null),i._csiHandlers=Object.create(null),i._escHandlers=Object.create(null),i._oscParser=new c.OscParser,i._dcsParser=new l.DcsParser,i._errorHandler=i._errorHandlerFb,i.registerEscHandler({final:"\\"},(function(){return!0})),i}return n(r,e),r.prototype._identifier=function(e,t){void 0===t&&(t=[64,126]);var r=0;if(e.prefix){if(e.prefix.length>1)throw new Error("only one byte as prefix supported");if((r=e.prefix.charCodeAt(0))&&60>r||r>63)throw new Error("prefix must be in range 0x3c .. 0x3f")}if(e.intermediates){if(e.intermediates.length>2)throw new Error("only two bytes as intermediates are supported");for(var i=0;i<e.intermediates.length;++i){var n=e.intermediates.charCodeAt(i);if(32>n||n>47)throw new Error("intermediate must be in range 0x20 .. 0x2f");r<<=8,r|=n}}if(1!==e.final.length)throw new Error("final must be a single byte");var o=e.final.charCodeAt(0);if(t[0]>o||o>t[1])throw new Error("final must be in range "+t[0]+" .. "+t[1]);return(r<<=8)|o},r.prototype.identToString=function(e){for(var t=[];e;)t.push(String.fromCharCode(255&e)),e>>=8;return t.reverse().join("")},r.prototype.dispose=function(){this._csiHandlers=Object.create(null),this._executeHandlers=Object.create(null),this._escHandlers=Object.create(null),this._oscParser.dispose(),this._dcsParser.dispose()},r.prototype.setPrintHandler=function(e){this._printHandler=e},r.prototype.clearPrintHandler=function(){this._printHandler=this._printHandlerFb},r.prototype.registerEscHandler=function(e,t){var r=this._identifier(e,[48,126]);void 0===this._escHandlers[r]&&(this._escHandlers[r]=[]);var i=this._escHandlers[r];return i.push(t),{dispose:function(){var e=i.indexOf(t);-1!==e&&i.splice(e,1)}}},r.prototype.clearEscHandler=function(e){this._escHandlers[this._identifier(e,[48,126])]&&delete this._escHandlers[this._identifier(e,[48,126])]},r.prototype.setEscHandlerFallback=function(e){this._escHandlerFb=e},r.prototype.setExecuteHandler=function(e,t){this._executeHandlers[e.charCodeAt(0)]=t},r.prototype.clearExecuteHandler=function(e){this._executeHandlers[e.charCodeAt(0)]&&delete this._executeHandlers[e.charCodeAt(0)]},r.prototype.setExecuteHandlerFallback=function(e){this._executeHandlerFb=e},r.prototype.registerCsiHandler=function(e,t){var r=this._identifier(e);void 0===this._csiHandlers[r]&&(this._csiHandlers[r]=[]);var i=this._csiHandlers[r];return i.push(t),{dispose:function(){var e=i.indexOf(t);-1!==e&&i.splice(e,1)}}},r.prototype.clearCsiHandler=function(e){this._csiHandlers[this._identifier(e)]&&delete this._csiHandlers[this._identifier(e)]},r.prototype.setCsiHandlerFallback=function(e){this._csiHandlerFb=e},r.prototype.registerDcsHandler=function(e,t){return this._dcsParser.registerHandler(this._identifier(e),t)},r.prototype.clearDcsHandler=function(e){this._dcsParser.clearHandler(this._identifier(e))},r.prototype.setDcsHandlerFallback=function(e){this._dcsParser.setHandlerFallback(e)},r.prototype.registerOscHandler=function(e,t){return this._oscParser.registerHandler(e,t)},r.prototype.clearOscHandler=function(e){this._oscParser.clearHandler(e)},r.prototype.setOscHandlerFallback=function(e){this._oscParser.setHandlerFallback(e)},r.prototype.setErrorHandler=function(e){this._errorHandler=e},r.prototype.clearErrorHandler=function(){this._errorHandler=this._errorHandlerFb},r.prototype.reset=function(){this.currentState=this.initialState,this._oscParser.reset(),this._dcsParser.reset(),this._params.reset(),this._params.addParam(0),this._collect=0,this.precedingCodepoint=0,0!==this._parseStack.state&&(this._parseStack.state=2,this._parseStack.handlers=[])},r.prototype._preserveStack=function(e,t,r,i,n){this._parseStack.state=e,this._parseStack.handlers=t,this._parseStack.handlerPos=r,this._parseStack.transition=i,this._parseStack.chunkPos=n},r.prototype.parse=function(e,t,r){var i,n=0,o=0,s=0;if(this._parseStack.state)if(2===this._parseStack.state)this._parseStack.state=0,s=this._parseStack.chunkPos+1;else{if(void 0===r||1===this._parseStack.state)throw this._parseStack.state=1,new Error("improper continuation due to previous async handler, giving up parsing");var a=this._parseStack.handlers,c=this._parseStack.handlerPos-1;switch(this._parseStack.state){case 3:if(!1===r&&c>-1)for(;c>=0&&!0!==(i=a[c](this._params));c--)if(i instanceof Promise)return this._parseStack.handlerPos=c,i;this._parseStack.handlers=[];break;case 4:if(!1===r&&c>-1)for(;c>=0&&!0!==(i=a[c]());c--)if(i instanceof Promise)return this._parseStack.handlerPos=c,i;this._parseStack.handlers=[];break;case 6:if(n=e[this._parseStack.chunkPos],i=this._dcsParser.unhook(24!==n&&26!==n,r))return i;27===n&&(this._parseStack.transition|=1),this._params.reset(),this._params.addParam(0),this._collect=0;break;case 5:if(n=e[this._parseStack.chunkPos],i=this._oscParser.end(24!==n&&26!==n,r))return i;27===n&&(this._parseStack.transition|=1),this._params.reset(),this._params.addParam(0),this._collect=0}this._parseStack.state=0,s=this._parseStack.chunkPos+1,this.precedingCodepoint=0,this.currentState=15&this._parseStack.transition}for(var l=s;l<t;++l){switch(n=e[l],(o=this._transitions.table[this.currentState<<8|(n<160?n:h)])>>4){case 2:for(var u=l+1;;++u){if(u>=t||(n=e[u])<32||n>126&&n<h){this._printHandler(e,l,u),l=u-1;break}if(++u>=t||(n=e[u])<32||n>126&&n<h){this._printHandler(e,l,u),l=u-1;break}if(++u>=t||(n=e[u])<32||n>126&&n<h){this._printHandler(e,l,u),l=u-1;break}if(++u>=t||(n=e[u])<32||n>126&&n<h){this._printHandler(e,l,u),l=u-1;break}}break;case 3:this._executeHandlers[n]?this._executeHandlers[n]():this._executeHandlerFb(n),this.precedingCodepoint=0;break;case 0:break;case 1:if(this._errorHandler({position:l,code:n,currentState:this.currentState,collect:this._collect,params:this._params,abort:!1}).abort)return;break;case 7:for(var f=(a=this._csiHandlers[this._collect<<8|n])?a.length-1:-1;f>=0&&!0!==(i=a[f](this._params));f--)if(i instanceof Promise)return this._preserveStack(3,a,f,o,l),i;f<0&&this._csiHandlerFb(this._collect<<8|n,this._params),this.precedingCodepoint=0;break;case 8:do{switch(n){case 59:this._params.addParam(0);break;case 58:this._params.addSubParam(-1);break;default:this._params.addDigit(n-48)}}while(++l<t&&(n=e[l])>47&&n<60);l--;break;case 9:this._collect<<=8,this._collect|=n;break;case 10:for(var _=this._escHandlers[this._collect<<8|n],d=_?_.length-1:-1;d>=0&&!0!==(i=_[d]());d--)if(i instanceof Promise)return this._preserveStack(4,_,d,o,l),i;d<0&&this._escHandlerFb(this._collect<<8|n),this.precedingCodepoint=0;break;case 11:this._params.reset(),this._params.addParam(0),this._collect=0;break;case 12:this._dcsParser.hook(this._collect<<8|n,this._params);break;case 13:for(var p=l+1;;++p)if(p>=t||24===(n=e[p])||26===n||27===n||n>127&&n<h){this._dcsParser.put(e,l,p),l=p-1;break}break;case 14:if(i=this._dcsParser.unhook(24!==n&&26!==n))return this._preserveStack(6,[],0,o,l),i;27===n&&(o|=1),this._params.reset(),this._params.addParam(0),this._collect=0,this.precedingCodepoint=0;break;case 4:this._oscParser.start();break;case 5:for(var v=l+1;;v++)if(v>=t||(n=e[v])<32||n>127&&n<h){this._oscParser.put(e,l,v),l=v-1;break}break;case 6:if(i=this._oscParser.end(24!==n&&26!==n))return this._preserveStack(5,[],0,o,l),i;27===n&&(o|=1),this._params.reset(),this._params.addParam(0),this._collect=0,this.precedingCodepoint=0}this.currentState=15&o}},r}(o.Disposable);t.EscapeSequenceParser=f},6242:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.OscHandler=t.OscParser=void 0;var i=r(5770),n=r(482),o=[],s=function(){function e(){this._state=0,this._active=o,this._id=-1,this._handlers=Object.create(null),this._handlerFb=function(){},this._stack={paused:!1,loopPosition:0,fallThrough:!1}}return e.prototype.registerHandler=function(e,t){void 0===this._handlers[e]&&(this._handlers[e]=[]);var r=this._handlers[e];return r.push(t),{dispose:function(){var e=r.indexOf(t);-1!==e&&r.splice(e,1)}}},e.prototype.clearHandler=function(e){this._handlers[e]&&delete this._handlers[e]},e.prototype.setHandlerFallback=function(e){this._handlerFb=e},e.prototype.dispose=function(){this._handlers=Object.create(null),this._handlerFb=function(){},this._active=o},e.prototype.reset=function(){if(2===this._state)for(var e=this._stack.paused?this._stack.loopPosition-1:this._active.length-1;e>=0;--e)this._active[e].end(!1);this._stack.paused=!1,this._active=o,this._id=-1,this._state=0},e.prototype._start=function(){if(this._active=this._handlers[this._id]||o,this._active.length)for(var e=this._active.length-1;e>=0;e--)this._active[e].start();else this._handlerFb(this._id,"START")},e.prototype._put=function(e,t,r){if(this._active.length)for(var i=this._active.length-1;i>=0;i--)this._active[i].put(e,t,r);else this._handlerFb(this._id,"PUT",(0,n.utf32ToString)(e,t,r))},e.prototype.start=function(){this.reset(),this._state=1},e.prototype.put=function(e,t,r){if(3!==this._state){if(1===this._state)for(;t<r;){var i=e[t++];if(59===i){this._state=2,this._start();break}if(i<48||57<i)return void(this._state=3);-1===this._id&&(this._id=0),this._id=10*this._id+i-48}2===this._state&&r-t>0&&this._put(e,t,r)}},e.prototype.end=function(e,t){if(void 0===t&&(t=!0),0!==this._state){if(3!==this._state)if(1===this._state&&this._start(),this._active.length){var r=!1,i=this._active.length-1,n=!1;if(this._stack.paused&&(i=this._stack.loopPosition-1,r=t,n=this._stack.fallThrough,this._stack.paused=!1),!n&&!1===r){for(;i>=0&&!0!==(r=this._active[i].end(e));i--)if(r instanceof Promise)return this._stack.paused=!0,this._stack.loopPosition=i,this._stack.fallThrough=!1,r;i--}for(;i>=0;i--)if((r=this._active[i].end(!1))instanceof Promise)return this._stack.paused=!0,this._stack.loopPosition=i,this._stack.fallThrough=!0,r}else this._handlerFb(this._id,"END",e);this._active=o,this._id=-1,this._state=0}},e}();t.OscParser=s;var a=function(){function e(e){this._handler=e,this._data="",this._hitLimit=!1}return e.prototype.start=function(){this._data="",this._hitLimit=!1},e.prototype.put=function(e,t,r){this._hitLimit||(this._data+=(0,n.utf32ToString)(e,t,r),this._data.length>i.PAYLOAD_LIMIT&&(this._data="",this._hitLimit=!0))},e.prototype.end=function(e){var t=this,r=!1;if(this._hitLimit)r=!1;else if(e&&(r=this._handler(this._data))instanceof Promise)return r.then((function(e){return t._data="",t._hitLimit=!1,e}));return this._data="",this._hitLimit=!1,r},e}();t.OscHandler=a},8742:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.Params=void 0;var r=2147483647,i=function(){function e(e,t){if(void 0===e&&(e=32),void 0===t&&(t=32),this.maxLength=e,this.maxSubParamsLength=t,t>256)throw new Error("maxSubParamsLength must not be greater than 256");this.params=new Int32Array(e),this.length=0,this._subParams=new Int32Array(t),this._subParamsLength=0,this._subParamsIdx=new Uint16Array(e),this._rejectDigits=!1,this._rejectSubDigits=!1,this._digitIsSub=!1}return e.fromArray=function(t){var r=new e;if(!t.length)return r;for(var i=Array.isArray(t[0])?1:0;i<t.length;++i){var n=t[i];if(Array.isArray(n))for(var o=0;o<n.length;++o)r.addSubParam(n[o]);else r.addParam(n)}return r},e.prototype.clone=function(){var t=new e(this.maxLength,this.maxSubParamsLength);return t.params.set(this.params),t.length=this.length,t._subParams.set(this._subParams),t._subParamsLength=this._subParamsLength,t._subParamsIdx.set(this._subParamsIdx),t._rejectDigits=this._rejectDigits,t._rejectSubDigits=this._rejectSubDigits,t._digitIsSub=this._digitIsSub,t},e.prototype.toArray=function(){for(var e=[],t=0;t<this.length;++t){e.push(this.params[t]);var r=this._subParamsIdx[t]>>8,i=255&this._subParamsIdx[t];i-r>0&&e.push(Array.prototype.slice.call(this._subParams,r,i))}return e},e.prototype.reset=function(){this.length=0,this._subParamsLength=0,this._rejectDigits=!1,this._rejectSubDigits=!1,this._digitIsSub=!1},e.prototype.addParam=function(e){if(this._digitIsSub=!1,this.length>=this.maxLength)this._rejectDigits=!0;else{if(e<-1)throw new Error("values lesser than -1 are not allowed");this._subParamsIdx[this.length]=this._subParamsLength<<8|this._subParamsLength,this.params[this.length++]=e>r?r:e}},e.prototype.addSubParam=function(e){if(this._digitIsSub=!0,this.length)if(this._rejectDigits||this._subParamsLength>=this.maxSubParamsLength)this._rejectSubDigits=!0;else{if(e<-1)throw new Error("values lesser than -1 are not allowed");this._subParams[this._subParamsLength++]=e>r?r:e,this._subParamsIdx[this.length-1]++}},e.prototype.hasSubParams=function(e){return(255&this._subParamsIdx[e])-(this._subParamsIdx[e]>>8)>0},e.prototype.getSubParams=function(e){var t=this._subParamsIdx[e]>>8,r=255&this._subParamsIdx[e];return r-t>0?this._subParams.subarray(t,r):null},e.prototype.getSubParamsAll=function(){for(var e={},t=0;t<this.length;++t){var r=this._subParamsIdx[t]>>8,i=255&this._subParamsIdx[t];i-r>0&&(e[t]=this._subParams.slice(r,i))}return e},e.prototype.addDigit=function(e){var t;if(!(this._rejectDigits||!(t=this._digitIsSub?this._subParamsLength:this.length)||this._digitIsSub&&this._rejectSubDigits)){var i=this._digitIsSub?this._subParams:this.params,n=i[t-1];i[t-1]=~n?Math.min(10*n+e,r):e}},e}();t.Params=i},5741:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.AddonManager=void 0;var r=function(){function e(){this._addons=[]}return e.prototype.dispose=function(){for(var e=this._addons.length-1;e>=0;e--)this._addons[e].instance.dispose()},e.prototype.loadAddon=function(e,t){var r=this,i={instance:t,dispose:t.dispose,isDisposed:!1};this._addons.push(i),t.dispose=function(){return r._wrappedAddonDispose(i)},t.activate(e)},e.prototype._wrappedAddonDispose=function(e){if(!e.isDisposed){for(var t=-1,r=0;r<this._addons.length;r++)if(this._addons[r]===e){t=r;break}if(-1===t)throw new Error("Could not dispose an addon that has not been loaded");e.isDisposed=!0,e.dispose.apply(e.instance),this._addons.splice(t,1)}},e}();t.AddonManager=r},8771:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.BufferApiView=void 0;var i=r(3785),n=r(511),o=function(){function e(e,t){this._buffer=e,this.type=t}return e.prototype.init=function(e){return this._buffer=e,this},Object.defineProperty(e.prototype,"cursorY",{get:function(){return this._buffer.y},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"cursorX",{get:function(){return this._buffer.x},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"viewportY",{get:function(){return this._buffer.ydisp},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"baseY",{get:function(){return this._buffer.ybase},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"length",{get:function(){return this._buffer.lines.length},enumerable:!1,configurable:!0}),e.prototype.getLine=function(e){var t=this._buffer.lines.get(e);if(t)return new i.BufferLineApiView(t)},e.prototype.getNullCell=function(){return new n.CellData},e}();t.BufferApiView=o},3785:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.BufferLineApiView=void 0;var i=r(511),n=function(){function e(e){this._line=e}return Object.defineProperty(e.prototype,"isWrapped",{get:function(){return this._line.isWrapped},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"length",{get:function(){return this._line.length},enumerable:!1,configurable:!0}),e.prototype.getCell=function(e,t){if(!(e<0||e>=this._line.length))return t?(this._line.loadCell(e,t),t):this._line.loadCell(e,new i.CellData)},e.prototype.translateToString=function(e,t,r){return this._line.translateToString(e,t,r)},e}();t.BufferLineApiView=n},8285:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.BufferNamespaceApi=void 0;var i=r(8771),n=r(8460),o=function(){function e(e){var t=this;this._core=e,this._onBufferChange=new n.EventEmitter,this._normal=new i.BufferApiView(this._core.buffers.normal,"normal"),this._alternate=new i.BufferApiView(this._core.buffers.alt,"alternate"),this._core.buffers.onBufferActivate((function(){return t._onBufferChange.fire(t.active)}))}return Object.defineProperty(e.prototype,"onBufferChange",{get:function(){return this._onBufferChange.event},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"active",{get:function(){if(this._core.buffers.active===this._core.buffers.normal)return this.normal;if(this._core.buffers.active===this._core.buffers.alt)return this.alternate;throw new Error("Active buffer is neither normal nor alternate")},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"normal",{get:function(){return this._normal.init(this._core.buffers.normal)},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"alternate",{get:function(){return this._alternate.init(this._core.buffers.alt)},enumerable:!1,configurable:!0}),e}();t.BufferNamespaceApi=o},7975:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.ParserApi=void 0;var r=function(){function e(e){this._core=e}return e.prototype.registerCsiHandler=function(e,t){return this._core.registerCsiHandler(e,(function(e){return t(e.toArray())}))},e.prototype.addCsiHandler=function(e,t){return this.registerCsiHandler(e,t)},e.prototype.registerDcsHandler=function(e,t){return this._core.registerDcsHandler(e,(function(e,r){return t(e,r.toArray())}))},e.prototype.addDcsHandler=function(e,t){return this.registerDcsHandler(e,t)},e.prototype.registerEscHandler=function(e,t){return this._core.registerEscHandler(e,t)},e.prototype.addEscHandler=function(e,t){return this.registerEscHandler(e,t)},e.prototype.registerOscHandler=function(e,t){return this._core.registerOscHandler(e,t)},e.prototype.addOscHandler=function(e,t){return this.registerOscHandler(e,t)},e}();t.ParserApi=r},7090:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.UnicodeApi=void 0;var r=function(){function e(e){this._core=e}return e.prototype.register=function(e){this._core.unicodeService.register(e)},Object.defineProperty(e.prototype,"versions",{get:function(){return this._core.unicodeService.versions},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"activeVersion",{get:function(){return this._core.unicodeService.activeVersion},set:function(e){this._core.unicodeService.activeVersion=e},enumerable:!1,configurable:!0}),e}();t.UnicodeApi=r},744:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)}),o=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},s=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.BufferService=t.MINIMUM_ROWS=t.MINIMUM_COLS=void 0;var a=r(2585),c=r(5295),l=r(8460),u=r(844);t.MINIMUM_COLS=2,t.MINIMUM_ROWS=1;var h=function(e){function r(r){var i=e.call(this)||this;return i._optionsService=r,i.isUserScrolling=!1,i._onResize=new l.EventEmitter,i._onScroll=new l.EventEmitter,i.cols=Math.max(r.options.cols||0,t.MINIMUM_COLS),i.rows=Math.max(r.options.rows||0,t.MINIMUM_ROWS),i.buffers=new c.BufferSet(r,i),i}return n(r,e),Object.defineProperty(r.prototype,"onResize",{get:function(){return this._onResize.event},enumerable:!1,configurable:!0}),Object.defineProperty(r.prototype,"onScroll",{get:function(){return this._onScroll.event},enumerable:!1,configurable:!0}),Object.defineProperty(r.prototype,"buffer",{get:function(){return this.buffers.active},enumerable:!1,configurable:!0}),r.prototype.dispose=function(){e.prototype.dispose.call(this),this.buffers.dispose()},r.prototype.resize=function(e,t){this.cols=e,this.rows=t,this.buffers.resize(e,t),this.buffers.setupTabStops(this.cols),this._onResize.fire({cols:e,rows:t})},r.prototype.reset=function(){this.buffers.reset(),this.isUserScrolling=!1},r.prototype.scroll=function(e,t){void 0===t&&(t=!1);var r,i=this.buffer;(r=this._cachedBlankLine)&&r.length===this.cols&&r.getFg(0)===e.fg&&r.getBg(0)===e.bg||(r=i.getBlankLine(e,t),this._cachedBlankLine=r),r.isWrapped=t;var n=i.ybase+i.scrollTop,o=i.ybase+i.scrollBottom;if(0===i.scrollTop){var s=i.lines.isFull;o===i.lines.length-1?s?i.lines.recycle().copyFrom(r):i.lines.push(r.clone()):i.lines.splice(o+1,0,r.clone()),s?this.isUserScrolling&&(i.ydisp=Math.max(i.ydisp-1,0)):(i.ybase++,this.isUserScrolling||i.ydisp++)}else{var a=o-n+1;i.lines.shiftElements(n+1,a-1,-1),i.lines.set(o,r.clone())}this.isUserScrolling||(i.ydisp=i.ybase),this._onScroll.fire(i.ydisp)},r.prototype.scrollLines=function(e,t,r){var i=this.buffer;if(e<0){if(0===i.ydisp)return;this.isUserScrolling=!0}else e+i.ydisp>=i.ybase&&(this.isUserScrolling=!1);var n=i.ydisp;i.ydisp=Math.max(Math.min(i.ydisp+e,i.ybase),0),n!==i.ydisp&&(t||this._onScroll.fire(i.ydisp))},r.prototype.scrollPages=function(e){this.scrollLines(e*(this.rows-1))},r.prototype.scrollToTop=function(){this.scrollLines(-this.buffer.ydisp)},r.prototype.scrollToBottom=function(){this.scrollLines(this.buffer.ybase-this.buffer.ydisp)},r.prototype.scrollToLine=function(e){var t=e-this.buffer.ydisp;0!==t&&this.scrollLines(t)},o([s(0,a.IOptionsService)],r)}(u.Disposable);t.BufferService=h},7994:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.CharsetService=void 0;var r=function(){function e(){this.glevel=0,this._charsets=[]}return e.prototype.reset=function(){this.charset=void 0,this._charsets=[],this.glevel=0},e.prototype.setgLevel=function(e){this.glevel=e,this.charset=this._charsets[e]},e.prototype.setgCharset=function(e,t){this._charsets[e]=t,this.glevel===e&&(this.charset=t)},e}();t.CharsetService=r},1753:function(e,t,r){var i=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},n=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.CoreMouseService=void 0;var o=r(2585),s=r(8460),a={NONE:{events:0,restrict:function(){return!1}},X10:{events:1,restrict:function(e){return 4!==e.button&&1===e.action&&(e.ctrl=!1,e.alt=!1,e.shift=!1,!0)}},VT200:{events:19,restrict:function(e){return 32!==e.action}},DRAG:{events:23,restrict:function(e){return 32!==e.action||3!==e.button}},ANY:{events:31,restrict:function(e){return!0}}};function c(e,t){var r=(e.ctrl?16:0)|(e.shift?4:0)|(e.alt?8:0);return 4===e.button?(r|=64,r|=e.action):(r|=3&e.button,4&e.button&&(r|=64),8&e.button&&(r|=128),32===e.action?r|=32:0!==e.action||t||(r|=3)),r}var l=String.fromCharCode,u={DEFAULT:function(e){var t=[c(e,!1)+32,e.col+32,e.row+32];return t[0]>255||t[1]>255||t[2]>255?"":"[M"+l(t[0])+l(t[1])+l(t[2])},SGR:function(e){var t=0===e.action&&4!==e.button?"m":"M";return"[<"+c(e,!0)+";"+e.col+";"+e.row+t}},h=function(){function e(e,t){this._bufferService=e,this._coreService=t,this._protocols={},this._encodings={},this._activeProtocol="",this._activeEncoding="",this._onProtocolChange=new s.EventEmitter,this._lastEvent=null;for(var r=0,i=Object.keys(a);r<i.length;r++){var n=i[r];this.addProtocol(n,a[n])}for(var o=0,c=Object.keys(u);o<c.length;o++){var l=c[o];this.addEncoding(l,u[l])}this.reset()}return e.prototype.addProtocol=function(e,t){this._protocols[e]=t},e.prototype.addEncoding=function(e,t){this._encodings[e]=t},Object.defineProperty(e.prototype,"activeProtocol",{get:function(){return this._activeProtocol},set:function(e){if(!this._protocols[e])throw new Error('unknown protocol "'+e+'"');this._activeProtocol=e,this._onProtocolChange.fire(this._protocols[e].events)},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"areMouseEventsActive",{get:function(){return 0!==this._protocols[this._activeProtocol].events},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"activeEncoding",{get:function(){return this._activeEncoding},set:function(e){if(!this._encodings[e])throw new Error('unknown encoding "'+e+'"');this._activeEncoding=e},enumerable:!1,configurable:!0}),e.prototype.reset=function(){this.activeProtocol="NONE",this.activeEncoding="DEFAULT",this._lastEvent=null},Object.defineProperty(e.prototype,"onProtocolChange",{get:function(){return this._onProtocolChange.event},enumerable:!1,configurable:!0}),e.prototype.triggerMouseEvent=function(e){if(e.col<0||e.col>=this._bufferService.cols||e.row<0||e.row>=this._bufferService.rows)return!1;if(4===e.button&&32===e.action)return!1;if(3===e.button&&32!==e.action)return!1;if(4!==e.button&&(2===e.action||3===e.action))return!1;if(e.col++,e.row++,32===e.action&&this._lastEvent&&this._compareEvents(this._lastEvent,e))return!1;if(!this._protocols[this._activeProtocol].restrict(e))return!1;var t=this._encodings[this._activeEncoding](e);return t&&("DEFAULT"===this._activeEncoding?this._coreService.triggerBinaryEvent(t):this._coreService.triggerDataEvent(t,!0)),this._lastEvent=e,!0},e.prototype.explainEvents=function(e){return{down:!!(1&e),up:!!(2&e),drag:!!(4&e),move:!!(8&e),wheel:!!(16&e)}},e.prototype._compareEvents=function(e,t){return e.col===t.col&&e.row===t.row&&e.button===t.button&&e.action===t.action&&e.ctrl===t.ctrl&&e.alt===t.alt&&e.shift===t.shift},i([n(0,o.IBufferService),n(1,o.ICoreService)],e)}();t.CoreMouseService=h},6975:function(e,t,r){var i,n=this&&this.__extends||(i=function(e,t){return i=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,t){e.__proto__=t}||function(e,t){for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])},i(e,t)},function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Class extends value "+String(t)+" is not a constructor or null");function r(){this.constructor=e}i(e,t),e.prototype=null===t?Object.create(t):(r.prototype=t.prototype,new r)}),o=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},s=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.CoreService=void 0;var a=r(2585),c=r(8460),l=r(1439),u=r(844),h=Object.freeze({insertMode:!1}),f=Object.freeze({applicationCursorKeys:!1,applicationKeypad:!1,bracketedPasteMode:!1,origin:!1,reverseWraparound:!1,sendFocus:!1,wraparound:!0}),_=function(e){function t(t,r,i,n){var o=e.call(this)||this;return o._bufferService=r,o._logService=i,o._optionsService=n,o.isCursorInitialized=!1,o.isCursorHidden=!1,o._onData=o.register(new c.EventEmitter),o._onUserInput=o.register(new c.EventEmitter),o._onBinary=o.register(new c.EventEmitter),o._scrollToBottom=t,o.register({dispose:function(){return o._scrollToBottom=void 0}}),o.modes=(0,l.clone)(h),o.decPrivateModes=(0,l.clone)(f),o}return n(t,e),Object.defineProperty(t.prototype,"onData",{get:function(){return this._onData.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onUserInput",{get:function(){return this._onUserInput.event},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"onBinary",{get:function(){return this._onBinary.event},enumerable:!1,configurable:!0}),t.prototype.reset=function(){this.modes=(0,l.clone)(h),this.decPrivateModes=(0,l.clone)(f)},t.prototype.triggerDataEvent=function(e,t){if(void 0===t&&(t=!1),!this._optionsService.options.disableStdin){var r=this._bufferService.buffer;r.ybase!==r.ydisp&&this._scrollToBottom(),t&&this._onUserInput.fire(),this._logService.debug('sending data "'+e+'"',(function(){return e.split("").map((function(e){return e.charCodeAt(0)}))})),this._onData.fire(e)}},t.prototype.triggerBinaryEvent=function(e){this._optionsService.options.disableStdin||(this._logService.debug('sending binary "'+e+'"',(function(){return e.split("").map((function(e){return e.charCodeAt(0)}))})),this._onBinary.fire(e))},o([s(1,a.IBufferService),s(2,a.ILogService),s(3,a.IOptionsService)],t)}(u.Disposable);t.CoreService=_},3730:function(e,t,r){var i=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},n=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}};Object.defineProperty(t,"__esModule",{value:!0}),t.DirtyRowService=void 0;var o=r(2585),s=function(){function e(e){this._bufferService=e,this.clearRange()}return Object.defineProperty(e.prototype,"start",{get:function(){return this._start},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"end",{get:function(){return this._end},enumerable:!1,configurable:!0}),e.prototype.clearRange=function(){this._start=this._bufferService.buffer.y,this._end=this._bufferService.buffer.y},e.prototype.markDirty=function(e){e<this._start?this._start=e:e>this._end&&(this._end=e)},e.prototype.markRangeDirty=function(e,t){if(e>t){var r=e;e=t,t=r}e<this._start&&(this._start=e),t>this._end&&(this._end=t)},e.prototype.markAllDirty=function(){this.markRangeDirty(0,this._bufferService.rows-1)},i([n(0,o.IBufferService)],e)}();t.DirtyRowService=s},4348:function(e,t,r){var i=this&&this.__spreadArray||function(e,t,r){if(r||2===arguments.length)for(var i,n=0,o=t.length;n<o;n++)!i&&n in t||(i||(i=Array.prototype.slice.call(t,0,n)),i[n]=t[n]);return e.concat(i||Array.prototype.slice.call(t))};Object.defineProperty(t,"__esModule",{value:!0}),t.InstantiationService=t.ServiceCollection=void 0;var n=r(2585),o=r(8343),s=function(){function e(){for(var e=[],t=0;t<arguments.length;t++)e[t]=arguments[t];this._entries=new Map;for(var r=0,i=e;r<i.length;r++){var n=i[r],o=n[0],s=n[1];this.set(o,s)}}return e.prototype.set=function(e,t){var r=this._entries.get(e);return this._entries.set(e,t),r},e.prototype.forEach=function(e){this._entries.forEach((function(t,r){return e(r,t)}))},e.prototype.has=function(e){return this._entries.has(e)},e.prototype.get=function(e){return this._entries.get(e)},e}();t.ServiceCollection=s;var a=function(){function e(){this._services=new s,this._services.set(n.IInstantiationService,this)}return e.prototype.setService=function(e,t){this._services.set(e,t)},e.prototype.getService=function(e){return this._services.get(e)},e.prototype.createInstance=function(e){for(var t=[],r=1;r<arguments.length;r++)t[r-1]=arguments[r];for(var n=(0,o.getServiceDependencies)(e).sort((function(e,t){return e.index-t.index})),s=[],a=0,c=n;a<c.length;a++){var l=c[a],u=this._services.get(l.id);if(!u)throw new Error("[createInstance] "+e.name+" depends on UNKNOWN service "+l.id+".");s.push(u)}var h=n.length>0?n[0].index:t.length;if(t.length!==h)throw new Error("[createInstance] First service dependency of "+e.name+" at position "+(h+1)+" conflicts with "+t.length+" static arguments");return new(e.bind.apply(e,i([void 0],i(i([],t,!0),s,!0),!1)))},e}();t.InstantiationService=a},7866:function(e,t,r){var i=this&&this.__decorate||function(e,t,r,i){var n,o=arguments.length,s=o<3?t:null===i?i=Object.getOwnPropertyDescriptor(t,r):i;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)s=Reflect.decorate(e,t,r,i);else for(var a=e.length-1;a>=0;a--)(n=e[a])&&(s=(o<3?n(s):o>3?n(t,r,s):n(t,r))||s);return o>3&&s&&Object.defineProperty(t,r,s),s},n=this&&this.__param||function(e,t){return function(r,i){t(r,i,e)}},o=this&&this.__spreadArray||function(e,t,r){if(r||2===arguments.length)for(var i,n=0,o=t.length;n<o;n++)!i&&n in t||(i||(i=Array.prototype.slice.call(t,0,n)),i[n]=t[n]);return e.concat(i||Array.prototype.slice.call(t))};Object.defineProperty(t,"__esModule",{value:!0}),t.LogService=void 0;var s=r(2585),a={debug:s.LogLevelEnum.DEBUG,info:s.LogLevelEnum.INFO,warn:s.LogLevelEnum.WARN,error:s.LogLevelEnum.ERROR,off:s.LogLevelEnum.OFF},c=function(){function e(e){var t=this;this._optionsService=e,this.logLevel=s.LogLevelEnum.OFF,this._updateLogLevel(),this._optionsService.onOptionChange((function(e){"logLevel"===e&&t._updateLogLevel()}))}return e.prototype._updateLogLevel=function(){this.logLevel=a[this._optionsService.options.logLevel]},e.prototype._evalLazyOptionalParams=function(e){for(var t=0;t<e.length;t++)"function"==typeof e[t]&&(e[t]=e[t]())},e.prototype._log=function(e,t,r){this._evalLazyOptionalParams(r),e.call.apply(e,o([console,"xterm.js: "+t],r,!1))},e.prototype.debug=function(e){for(var t=[],r=1;r<arguments.length;r++)t[r-1]=arguments[r];this.logLevel<=s.LogLevelEnum.DEBUG&&this._log(console.log,e,t)},e.prototype.info=function(e){for(var t=[],r=1;r<arguments.length;r++)t[r-1]=arguments[r];this.logLevel<=s.LogLevelEnum.INFO&&this._log(console.info,e,t)},e.prototype.warn=function(e){for(var t=[],r=1;r<arguments.length;r++)t[r-1]=arguments[r];this.logLevel<=s.LogLevelEnum.WARN&&this._log(console.warn,e,t)},e.prototype.error=function(e){for(var t=[],r=1;r<arguments.length;r++)t[r-1]=arguments[r];this.logLevel<=s.LogLevelEnum.ERROR&&this._log(console.error,e,t)},i([n(0,s.IOptionsService)],e)}();t.LogService=c},7302:function(e,t,r){var i=this&&this.__assign||function(){return i=Object.assign||function(e){for(var t,r=1,i=arguments.length;r<i;r++)for(var n in t=arguments[r])Object.prototype.hasOwnProperty.call(t,n)&&(e[n]=t[n]);return e},i.apply(this,arguments)};Object.defineProperty(t,"__esModule",{value:!0}),t.OptionsService=t.DEFAULT_OPTIONS=t.DEFAULT_BELL_SOUND=void 0;var n=r(8460),o=r(6114);t.DEFAULT_BELL_SOUND="data:audio/mp3;base64,SUQzBAAAAAAAI1RTU0UAAAAPAAADTGF2ZjU4LjMyLjEwNAAAAAAAAAAAAAAA//tQxAADB8AhSmxhIIEVCSiJrDCQBTcu3UrAIwUdkRgQbFAZC1CQEwTJ9mjRvBA4UOLD8nKVOWfh+UlK3z/177OXrfOdKl7pyn3Xf//WreyTRUoAWgBgkOAGbZHBgG1OF6zM82DWbZaUmMBptgQhGjsyYqc9ae9XFz280948NMBWInljyzsNRFLPWdnZGWrddDsjK1unuSrVN9jJsK8KuQtQCtMBjCEtImISdNKJOopIpBFpNSMbIHCSRpRR5iakjTiyzLhchUUBwCgyKiweBv/7UsQbg8isVNoMPMjAAAA0gAAABEVFGmgqK////9bP/6XCykxBTUUzLjEwMKqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq",t.DEFAULT_OPTIONS={cols:80,rows:24,cursorBlink:!1,cursorStyle:"block",cursorWidth:1,customGlyphs:!0,bellSound:t.DEFAULT_BELL_SOUND,bellStyle:"none",drawBoldTextInBrightColors:!0,fastScrollModifier:"alt",fastScrollSensitivity:5,fontFamily:"courier-new, courier, monospace",fontSize:15,fontWeight:"normal",fontWeightBold:"bold",lineHeight:1,linkTooltipHoverDuration:500,letterSpacing:0,logLevel:"info",scrollback:1e3,scrollSensitivity:1,screenReaderMode:!1,macOptionIsMeta:!1,macOptionClickForcesSelection:!1,minimumContrastRatio:1,disableStdin:!1,allowProposedApi:!0,allowTransparency:!1,tabStopWidth:8,theme:{},rightClickSelectsWord:o.isMac,rendererType:"canvas",windowOptions:{},windowsMode:!1,wordSeparator:" ()[]{}',\"`",altClickMovesCursor:!0,convertEol:!1,termName:"xterm",cancelEvents:!1};var s=["normal","bold","100","200","300","400","500","600","700","800","900"],a=function(){function e(e){for(var r in this._onOptionChange=new n.EventEmitter,this._options=i({},t.DEFAULT_OPTIONS),e)if(r in this._options)try{var o=e[r];this._options[r]=this._sanitizeAndValidateOption(r,o)}catch(e){console.error(e)}this.options=this._setupOptions(this._options)}return Object.defineProperty(e.prototype,"onOptionChange",{get:function(){return this._onOptionChange.event},enumerable:!1,configurable:!0}),e.prototype._setupOptions=function(e){var r=this,n=i({},e),o=function(e){Object.defineProperty(n,e,{get:function(){if(!(e in t.DEFAULT_OPTIONS))throw new Error('No option with key "'+e+'"');return r._options[e]},set:function(i){if(!(e in t.DEFAULT_OPTIONS))throw new Error('No option with key "'+e+'"');i=r._sanitizeAndValidateOption(e,i),r._options[e]!==i&&(r._options[e]=i,r._onOptionChange.fire(e))}})};for(var s in n)o(s);return n},e.prototype.setOption=function(e,t){this.options[e]=t},e.prototype._sanitizeAndValidateOption=function(e,r){switch(e){case"bellStyle":case"cursorStyle":case"rendererType":case"wordSeparator":r||(r=t.DEFAULT_OPTIONS[e]);break;case"fontWeight":case"fontWeightBold":if("number"==typeof r&&1<=r&&r<=1e3)break;r=s.includes(r)?r:t.DEFAULT_OPTIONS[e];break;case"cursorWidth":r=Math.floor(r);case"lineHeight":case"tabStopWidth":if(r<1)throw new Error(e+" cannot be less than 1, value: "+r);break;case"minimumContrastRatio":r=Math.max(1,Math.min(21,Math.round(10*r)/10));break;case"scrollback":if((r=Math.min(r,4294967295))<0)throw new Error(e+" cannot be less than 0, value: "+r);break;case"fastScrollSensitivity":case"scrollSensitivity":if(r<=0)throw new Error(e+" cannot be less than or equal to 0, value: "+r);case"rows":case"cols":if(!r&&0!==r)throw new Error(e+" must be numeric, value: "+r)}return r},e.prototype.getOption=function(e){return this.options[e]},e}();t.OptionsService=a},8343:(e,t)=>{function r(e,t,r){t.di$target===t?t.di$dependencies.push({id:e,index:r}):(t.di$dependencies=[{id:e,index:r}],t.di$target=t)}Object.defineProperty(t,"__esModule",{value:!0}),t.createDecorator=t.getServiceDependencies=t.serviceRegistry=void 0,t.serviceRegistry=new Map,t.getServiceDependencies=function(e){return e.di$dependencies||[]},t.createDecorator=function(e){if(t.serviceRegistry.has(e))return t.serviceRegistry.get(e);var i=function(e,t,n){if(3!==arguments.length)throw new Error("@IServiceName-decorator can only be used to decorate a parameter");r(i,e,n)};return i.toString=function(){return e},t.serviceRegistry.set(e,i),i}},2585:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.IUnicodeService=t.IOptionsService=t.ILogService=t.LogLevelEnum=t.IInstantiationService=t.IDirtyRowService=t.ICharsetService=t.ICoreService=t.ICoreMouseService=t.IBufferService=void 0;var i,n=r(8343);t.IBufferService=(0,n.createDecorator)("BufferService"),t.ICoreMouseService=(0,n.createDecorator)("CoreMouseService"),t.ICoreService=(0,n.createDecorator)("CoreService"),t.ICharsetService=(0,n.createDecorator)("CharsetService"),t.IDirtyRowService=(0,n.createDecorator)("DirtyRowService"),t.IInstantiationService=(0,n.createDecorator)("InstantiationService"),(i=t.LogLevelEnum||(t.LogLevelEnum={}))[i.DEBUG=0]="DEBUG",i[i.INFO=1]="INFO",i[i.WARN=2]="WARN",i[i.ERROR=3]="ERROR",i[i.OFF=4]="OFF",t.ILogService=(0,n.createDecorator)("LogService"),t.IOptionsService=(0,n.createDecorator)("OptionsService"),t.IUnicodeService=(0,n.createDecorator)("UnicodeService")},1480:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.UnicodeService=void 0;var i=r(8460),n=r(225),o=function(){function e(){this._providers=Object.create(null),this._active="",this._onChange=new i.EventEmitter;var e=new n.UnicodeV6;this.register(e),this._active=e.version,this._activeProvider=e}return Object.defineProperty(e.prototype,"onChange",{get:function(){return this._onChange.event},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"versions",{get:function(){return Object.keys(this._providers)},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"activeVersion",{get:function(){return this._active},set:function(e){if(!this._providers[e])throw new Error('unknown Unicode version "'+e+'"');this._active=e,this._activeProvider=this._providers[e],this._onChange.fire(e)},enumerable:!1,configurable:!0}),e.prototype.register=function(e){this._providers[e.version]=e},e.prototype.wcwidth=function(e){return this._activeProvider.wcwidth(e)},e.prototype.getStringCellWidth=function(e){for(var t=0,r=e.length,i=0;i<r;++i){var n=e.charCodeAt(i);if(55296<=n&&n<=56319){if(++i>=r)return t+this.wcwidth(n);var o=e.charCodeAt(i);56320<=o&&o<=57343?n=1024*(n-55296)+o-56320+65536:t+=this.wcwidth(o)}t+=this.wcwidth(n)}return t},e}();t.UnicodeService=o}},t={};function r(i){var n=t[i];if(void 0!==n)return n.exports;var o=t[i]={exports:{}};return e[i].call(o.exports,o,o.exports,r),o.exports}var i={};return(()=>{var e=i;Object.defineProperty(e,"__esModule",{value:!0}),e.Terminal=void 0;var t=r(3236),n=r(9042),o=r(7975),s=r(7090),a=r(5741),c=r(8285),l=["cols","rows"],u=function(){function e(e){var r=this;this._core=new t.Terminal(e),this._addonManager=new a.AddonManager,this._publicOptions={};var i=function(e){Object.defineProperty(n._publicOptions,e,{get:function(){return r._core.options[e]},set:function(t){r._checkReadonlyOptions(e),r._core.options[e]=t}})},n=this;for(var o in this._core.options)i(o)}return e.prototype._checkReadonlyOptions=function(e){if(l.includes(e))throw new Error('Option "'+e+'" can only be set in the constructor')},e.prototype._checkProposedApi=function(){if(!this._core.optionsService.options.allowProposedApi)throw new Error("You must set the allowProposedApi option to true to use proposed API")},Object.defineProperty(e.prototype,"onBell",{get:function(){return this._core.onBell},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"onBinary",{get:function(){return this._core.onBinary},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"onCursorMove",{get:function(){return this._core.onCursorMove},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"onData",{get:function(){return this._core.onData},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"onKey",{get:function(){return this._core.onKey},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"onLineFeed",{get:function(){return this._core.onLineFeed},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"onRender",{get:function(){return this._core.onRender},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"onResize",{get:function(){return this._core.onResize},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"onScroll",{get:function(){return this._core.onScroll},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"onSelectionChange",{get:function(){return this._core.onSelectionChange},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"onTitleChange",{get:function(){return this._core.onTitleChange},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"element",{get:function(){return this._core.element},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"parser",{get:function(){return this._checkProposedApi(),this._parser||(this._parser=new o.ParserApi(this._core)),this._parser},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"unicode",{get:function(){return this._checkProposedApi(),new s.UnicodeApi(this._core)},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"textarea",{get:function(){return this._core.textarea},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"rows",{get:function(){return this._core.rows},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"cols",{get:function(){return this._core.cols},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"buffer",{get:function(){return this._checkProposedApi(),this._buffer||(this._buffer=new c.BufferNamespaceApi(this._core)),this._buffer},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"markers",{get:function(){return this._checkProposedApi(),this._core.markers},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"modes",{get:function(){var e=this._core.coreService.decPrivateModes,t="none";switch(this._core.coreMouseService.activeProtocol){case"X10":t="x10";break;case"VT200":t="vt200";break;case"DRAG":t="drag";break;case"ANY":t="any"}return{applicationCursorKeysMode:e.applicationCursorKeys,applicationKeypadMode:e.applicationKeypad,bracketedPasteMode:e.bracketedPasteMode,insertMode:this._core.coreService.modes.insertMode,mouseTrackingMode:t,originMode:e.origin,reverseWraparoundMode:e.reverseWraparound,sendFocusMode:e.sendFocus,wraparoundMode:e.wraparound}},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"options",{get:function(){return this._publicOptions},set:function(e){for(var t in e)this._publicOptions[t]=e[t]},enumerable:!1,configurable:!0}),e.prototype.blur=function(){this._core.blur()},e.prototype.focus=function(){this._core.focus()},e.prototype.resize=function(e,t){this._verifyIntegers(e,t),this._core.resize(e,t)},e.prototype.open=function(e){this._core.open(e)},e.prototype.attachCustomKeyEventHandler=function(e){this._core.attachCustomKeyEventHandler(e)},e.prototype.registerLinkMatcher=function(e,t,r){return this._checkProposedApi(),this._core.registerLinkMatcher(e,t,r)},e.prototype.deregisterLinkMatcher=function(e){this._checkProposedApi(),this._core.deregisterLinkMatcher(e)},e.prototype.registerLinkProvider=function(e){return this._checkProposedApi(),this._core.registerLinkProvider(e)},e.prototype.registerCharacterJoiner=function(e){return this._checkProposedApi(),this._core.registerCharacterJoiner(e)},e.prototype.deregisterCharacterJoiner=function(e){this._checkProposedApi(),this._core.deregisterCharacterJoiner(e)},e.prototype.registerMarker=function(e){return this._checkProposedApi(),this._verifyIntegers(e),this._core.addMarker(e)},e.prototype.addMarker=function(e){return this.registerMarker(e)},e.prototype.hasSelection=function(){return this._core.hasSelection()},e.prototype.select=function(e,t,r){this._verifyIntegers(e,t,r),this._core.select(e,t,r)},e.prototype.getSelection=function(){return this._core.getSelection()},e.prototype.getSelectionPosition=function(){return this._core.getSelectionPosition()},e.prototype.clearSelection=function(){this._core.clearSelection()},e.prototype.selectAll=function(){this._core.selectAll()},e.prototype.selectLines=function(e,t){this._verifyIntegers(e,t),this._core.selectLines(e,t)},e.prototype.dispose=function(){this._addonManager.dispose(),this._core.dispose()},e.prototype.scrollLines=function(e){this._verifyIntegers(e),this._core.scrollLines(e)},e.prototype.scrollPages=function(e){this._verifyIntegers(e),this._core.scrollPages(e)},e.prototype.scrollToTop=function(){this._core.scrollToTop()},e.prototype.scrollToBottom=function(){this._core.scrollToBottom()},e.prototype.scrollToLine=function(e){this._verifyIntegers(e),this._core.scrollToLine(e)},e.prototype.clear=function(){this._core.clear()},e.prototype.write=function(e,t){this._core.write(e,t)},e.prototype.writeUtf8=function(e,t){this._core.write(e,t)},e.prototype.writeln=function(e,t){this._core.write(e),this._core.write("\r\n",t)},e.prototype.paste=function(e){this._core.paste(e)},e.prototype.getOption=function(e){return this._core.optionsService.getOption(e)},e.prototype.setOption=function(e,t){this._checkReadonlyOptions(e),this._core.optionsService.setOption(e,t)},e.prototype.refresh=function(e,t){this._verifyIntegers(e,t),this._core.refresh(e,t)},e.prototype.reset=function(){this._core.reset()},e.prototype.clearTextureAtlas=function(){this._core.clearTextureAtlas()},e.prototype.loadAddon=function(e){return this._addonManager.loadAddon(this,e)},Object.defineProperty(e,"strings",{get:function(){return n},enumerable:!1,configurable:!0}),e.prototype._verifyIntegers=function(){for(var e=[],t=0;t<arguments.length;t++)e[t]=arguments[t];for(var r=0,i=e;r<i.length;r++){var n=i[r];if(n===1/0||isNaN(n)||n%1!=0)throw new Error("This API only accepts integers")}},e}();e.Terminal=u})(),i})()}},t={};function r(i){var n=t[i];if(void 0!==n)return n.exports;var o=t[i]={id:i,loaded:!1,exports:{}};return e[i].call(o.exports,o,o.exports,r),o.loaded=!0,o.exports}r.n=e=>{var t=e&&e.__esModule?()=>e.default:()=>e;return r.d(t,{a:t}),t},r.d=(e,t)=>{for(var i in t)r.o(t,i)&&!r.o(e,i)&&Object.defineProperty(e,i,{enumerable:!0,get:t[i]})},r.g=function(){if("object"==typeof globalThis)return globalThis;try{return this||new Function("return this")()}catch(e){if("object"==typeof window)return window}}(),r.o=(e,t)=>Object.prototype.hasOwnProperty.call(e,t),r.nmd=e=>(e.paths=[],e.children||(e.children=[]),e),(()=>{"use strict";var e=r(379),t=r.n(e),i=r(795),n=r.n(i),o=r(569),s=r.n(o),a=r(565),c=r.n(a),l=r(216),u=r.n(l),h=r(589),f=r.n(h),_=r(102),d={};d.styleTagTransform=f(),d.setAttributes=c(),d.insert=s().bind(null,"head"),d.domAPI=n(),d.insertStyleElement=u(),t()(_.Z,d),_.Z&&_.Z.locals&&_.Z.locals;var p=r(320),v=r(617),g=r(486),y=r.n(g),m=function(e,t,r,i){return new(r||(r=Promise))((function(n,o){function s(e){try{c(i.next(e))}catch(e){o(e)}}function a(e){try{c(i.throw(e))}catch(e){o(e)}}function c(e){var t;e.done?n(e.value):(t=e.value,t instanceof r?t:new r((function(e){e(t)}))).then(s,a)}c((i=i.apply(e,t||[])).next())}))},b=function(e,t){var r,i,n,o,s={label:0,sent:function(){if(1&n[0])throw n[1];return n[1]},trys:[],ops:[]};return o={next:a(0),throw:a(1),return:a(2)},"function"==typeof Symbol&&(o[Symbol.iterator]=function(){return this}),o;function a(o){return function(a){return function(o){if(r)throw new TypeError("Generator is already executing.");for(;s;)try{if(r=1,i&&(n=2&o[0]?i.return:o[0]?i.throw||((n=i.return)&&n.call(i),0):i.next)&&!(n=n.call(i,o[1])).done)return n;switch(i=0,n&&(o=[2&o[0],n.value]),o[0]){case 0:case 1:n=o;break;case 4:return s.label++,{value:o[1],done:!1};case 5:s.label++,i=o[1],o=[0];continue;case 7:o=s.ops.pop(),s.trys.pop();continue;default:if(!((n=(n=s.trys).length>0&&n[n.length-1])||6!==o[0]&&2!==o[0])){s=0;continue}if(3===o[0]&&(!n||o[1]>n[0]&&o[1]<n[3])){s.label=o[1];break}if(6===o[0]&&s.label<n[1]){s.label=n[1],n=o;break}if(n&&s.label<n[2]){s.label=n[2],s.ops.push(o);break}n[2]&&s.ops.pop(),s.trys.pop();continue}o=t.call(e,s)}catch(e){o=[6,e],i=0}finally{r=n=0}if(5&o[0])throw o[1];return{value:o[0]?o[1]:void 0,done:!0}}([o,a])}}};window.onload=function(){var e=new p.Terminal,t=new v.FitAddon;window.term=e,window.fitAddon=t,e.loadAddon(t),e.open(document.getElementById("terminal"));var r=function(){e.element.parentElement.style.height=window.innerHeight-16+"px",t.fit(),fetch("/resize?rows="+e.rows+"&cols="+e.cols)};r(),window.onresize=r;var i=[];e.onData((function(e){i.push(e)})),m(this,void 0,void 0,(function(){var e,t,r;return b(this,(function(n){switch(n.label){case 0:e=function(e){return new Promise((function(t){return setTimeout(t,e)}))},n.label=1;case 1:n.trys.push([1,,7,8]),n.label=2;case 2:return[4,e(100)];case 3:return n.sent(),y().isEmpty(i)?[3,5]:(t=i.join(""),r=window.btoa(t),i.length=0,[4,fetch("/in/"+r)]);case 4:n.sent(),n.label=5;case 5:return[3,2];case 6:return[3,8];case 7:return console.log("input disconnect!"),[7];case 8:return[2]}}))})),function(){m(this,void 0,void 0,(function(){var t,r,i;return b(this,(function(n){switch(n.label){case 0:n.trys.push([0,,5,6]),n.label=1;case 1:return[4,fetch("/out")];case 2:return t=n.sent(),i=Uint8Array.bind,[4,t.arrayBuffer()];case 3:return r=new(i.apply(Uint8Array,[void 0,n.sent()])),t&&e.write(r),[3,1];case 4:return[3,6];case 5:return console.log("input disconnect!"),[7];case 6:return[2]}}))}))}()}})()})();",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/out": {
              "data": "W0dJTl0gMjAyNS8wNy8xMyAtIDA4OjU1OjIxIHwbWzk3OzQybSAyMDAgG1swbXwgIDQuOTk3MTQzMzIycyB8ICAgICAgIDEyNy4wLjAuMSB8G1s5Nzs0Nm0gUE9TVCAgICAbWzBtICIvYXBpL2dlbmVyYXRlIg0K",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/resize?rows=42&cols=66": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/Fg==": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/G1syMDB+Y3VybCAtZnNTTCBodHRwczovL29sbGFtYS5jb20vaW5zdGFsbC5zaCB8IHNoG1syMDF+": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/Gg==": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/fw==": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/f39/fw==": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/DQ==": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/G1syMDB+b2xsYW1hIHNlcnZlICYgb2xsYW1hIHB1bGwgbGxhbWEzICYgb2xsYW1hIHB1bGwgbm9taWMtZW1iZWQtdGV4dBtbMjAxfg==": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/f39/": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/f39/f39/fw==": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/f38=": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/resize?rows=42&cols=112": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/f39/f39/f39/f39/f39/fw==": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/f39/f39/f39/f39/f39/f38=": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/f39/f39/f39/f39/f38=": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/f39/f39/f39/f39/f39/": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/G1syMDB+b2xsYW1hIHNlcnZlG1syMDF+": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/f39/f39/f39/f39/f39/f39/": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/f39/f38=": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/dg==": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/ZQ==": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/G1syMDB+b2xsYW1hIHB1bGwgbGxhbWEzG1syMDF+": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "https://localhost:10000/in/G1syMDB+b2xsYW1hIHB1bGwgbm9taWMtZW1iZWQtdGV4dBtbMjAxfg==": {
              "data": "",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/html; charset=UTF-8"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "id": "IFwEJjrsMAfT",
        "outputId": "50927e56-e448-4b0f-aa7c-e7a9a02d07de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Launching Xterm..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(10000, {'cache': true}));\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -qq install langchain\n",
        "!pip -qq install langchain-core\n",
        "!pip -qq install langchain-community\n",
        "!pip install -qqq langchain-openai\n",
        "!pip install pypdf\n",
        "!pip install docarray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eierbnMSOE70",
        "outputId": "b4550c4b-0c39-463b-d802-5ff4cdd4676a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/2.5 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf\n",
            "  Downloading pypdf-5.7.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Downloading pypdf-5.7.0-py3-none-any.whl (305 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.5/305.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.7.0\n",
            "Collecting docarray\n",
            "  Downloading docarray-0.41.0-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from docarray) (2.0.2)\n",
            "Requirement already satisfied: orjson>=3.8.2 in /usr/local/lib/python3.11/dist-packages (from docarray) (3.10.18)\n",
            "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from docarray) (2.11.7)\n",
            "Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.11/dist-packages (from docarray) (13.9.4)\n",
            "Collecting types-requests>=2.28.11.6 (from docarray)\n",
            "  Downloading types_requests-2.32.4.20250611-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from docarray) (0.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.8->docarray) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.8->docarray) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.8->docarray) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.8->docarray) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->docarray) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->docarray) (2.19.2)\n",
            "Requirement already satisfied: urllib3>=2 in /usr/local/lib/python3.11/dist-packages (from types-requests>=2.28.11.6->docarray) (2.4.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->docarray) (1.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray) (0.1.2)\n",
            "Downloading docarray-0.41.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250611-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: types-requests, docarray\n",
            "Successfully installed docarray-0.41.0 types-requests-2.32.4.20250611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import Ollama\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain_community.embeddings import OllamaEmbeddings\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "\n",
        "# --- Settings ---\n",
        "MODEL = \"llama3\"\n",
        "model = Ollama(model=MODEL)\n",
        "OPENAI_API_KEY = \"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\"\n",
        "PDF_PATH = \"/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Is98g57POmCR",
        "outputId": "cd494acd-67da-44a7-89d8-de166526a9da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4-894134318.py:8: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
            "  model = Ollama(model=MODEL)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "chain = model | parser\n",
        "chain.invoke(\"Tell me a joke\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "C9QzUm2zPzJv",
        "outputId": "9c470121-cbe0-4633-89b4-1103b64ca2e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Here's one:\\n\\nWhy couldn't the bicycle stand up by itself?\\n\\n(Wait for it...)\\n\\nBecause it was two-tired!\\n\\nHope that made you smile!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader=PyPDFLoader(\"/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf\")\n",
        "pages=loader.load_and_split()\n",
        "pages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1rnITINZJJL",
        "outputId": "caa23e22-e7e5-4b0e-8383-751295dd3375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 0, 'page_label': '1'}, page_content='Contents\\nPreface   vii\\nAbout the Authors   xxx\\n■ part 1\\nIntroduction to Databases ■ \\nchapter 1 Databases and Database Users   3\\n1.1 Introduction    4\\n1.2 An Example    6\\n1.3 Characteristics of the Database Approach    10\\n1.4 Actors on the Scene    15\\n1.5 Workers behind the Scene    17\\n1.6 Advantages of Using the DBMS Approach    17\\n1.7 A Brief History of Database Applications    23\\n1.8 When Not to Use a DBMS    27\\n1.9 Summary    27\\nReview Questions   28\\nExercises   28\\nSelected Bibliography   29\\nchapter 2  Database System Concepts  \\nand Architecture   31\\n2.1 Data Models, Schemas, and Instances    32\\n2.2 Three-Schema Architecture and Data Independence    36\\n2.3 Database Languages and Interfaces    38\\n2.4 The Database System Environment    42\\n2.5 Centralized and Client/Server Architectures for DBMSs    46\\n2.6 Classification of Database Management Systems    51\\n2.7 Summary    54\\nReview Questions   55\\nExercises   55\\nSelected Bibliography   56\\nxvii'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 1, 'page_label': '2'}, page_content='xviii Contents\\n■ part 2\\nConceptual Data Modeling and Database Design ■ \\nchapter 3  Data Modeling Using the Entity–Relationship (ER) \\nModel   59\\n3.1  Using High-Level Conceptual Data Models  \\nfor Database Design    60\\n3.2 A Sample Database Application    62\\n3.3 Entity Types, Entity Sets, Attributes, and Keys    63\\n3.4  Relationship Types, Relationship Sets, Roles, and Structural \\nConstraints    72\\n3.5 Weak Entity Types    79\\n3.6 Refining the ER Design for the COMPANY Database    80\\n3.7 ER Diagrams, Naming Conventions, and Design Issues    81\\n3.8 Example of Other Notation: UML Class Diagrams    85\\n3.9 Relationship Types of Degree Higher than Two    88\\n3.10 Another Example: A UNIVERSITY Database    92\\n3.11 Summary    94\\nReview Questions   96\\nExercises   96\\nLaboratory Exercises   103\\nSelected Bibliography   104\\nchapter 4  The Enhanced Entity–Relationship (EER) \\nModel   107\\n4.1 Subclasses, Superclasses, and Inheritance    108\\n4.2 Specialization and Generalization    110\\n4.3  Constraints and Characteristics of Specialization and Generalization \\nHierarchies    113\\n4.4 Modeling of UNION Types Using Categories    120\\n4.5  A Sample UNIVERSITY EER Schema, Design Choices, and Formal \\nDefinitions    122\\n4.6  Example of Other Notation: Representing Specialization and \\nGeneralization in UML Class Diagrams    127\\n4.7  Data Abstraction, Knowledge Representation, and Ontology \\nConcepts    128\\n4.8 Summary    135\\nReview Questions   135\\nExercises   136\\nLaboratory Exercises   143\\nSelected Bibliography   146'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 2, 'page_label': '3'}, page_content='Contents xix\\n■ part 3\\nThe Relational Data Model and SQL ■ \\nchapter 5  The Relational Data Model and Relational \\nDatabase Constraints   149\\n5.1 Relational Model Concepts    150\\n5.2 Relational Model Constraints and Relational Database Schemas    157\\n5.3  Update Operations, Transactions, and Dealing with Constraint \\nViolations    165\\n5.4 Summary    169\\nReview Questions   170\\nExercises   170\\nSelected Bibliography   175\\nchapter 6 Basic SQL   177\\n6.1 SQL Data Definition and Data Types    179\\n6.2 Specifying Constraints in SQL    184\\n6.3 Basic Retrieval Queries in SQL    187\\n6.4  INSERT, DELETE, and UPDATE Statements in SQL    198\\n6.5 Additional Features of SQL    201\\n6.6 Summary    202\\nReview Questions   203\\nExercises   203\\nSelected Bibliography   205\\nchapter 7  More SQL: Complex Queries, Triggers, Views,  \\nand Schema Modification   207\\n7.1 More Complex SQL Retrieval Queries    207\\n7.2 Specifying Constraints as Assertions and Actions as Triggers    225\\n7.3 Views (Virtual Tables) in SQL    228\\n7.4 Schema Change Statements in SQL    232\\n7.5 Summary    234\\nReview Questions   236\\nExercises   236\\nSelected Bibliography   238\\nchapter 8  The Relational Algebra and Relational Calculus   239\\n8.1  Unary Relational Operations: SELECT and PROJECT    241\\n8.2  Relational Algebra Operations from Set Theory    246'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 3, 'page_label': '4'}, page_content='8.3 Binary Relational Operations: JOIN and DIVISION    251\\n8.4 Additional Relational Operations    259\\n8.5 Examples of Queries in Relational Algebra    265\\n8.6 The Tuple Relational Calculus    268\\n8.7 The Domain Relational Calculus    277\\n8.8 Summary    279\\nReview Questions   280\\nExercises   281\\nLaboratory Exercises   286\\nSelected Bibliography   288\\nchapter 9  Relational Database Design by ER- and  \\nEER-to-Relational Mapping   289\\n9.1  Relational Database Design Using ER-to-Relational Mapping    290\\n9.2 Mapping EER Model Constructs to Relations    298\\n9.3 Summary    303\\nReview Questions   303\\nExercises   303\\nLaboratory Exercises   305\\nSelected Bibliography   306\\n■ part 4\\nDatabase Programming Techniques ■ \\nchapter 10  Introduction to SQL Programming \\nTechniques   309\\n10.1  Overview of Database Programming Techniques and Issues    310\\n10.2 Embedded SQL, Dynamic SQL, and SQLJ    314\\n10.3  Database Programming with Function Calls and Class  \\nLibraries: SQL/CLI and JDBC    326\\n10.4 Database Stored Procedures and SQL/PSM    335\\n10.5 Comparing the Three Approaches    338\\n10.6 Summary    339\\nReview Questions   340\\nExercises   340\\nSelected Bibliography   341\\nchapter 11 Web Database Programming Using PHP   343\\n11.1 A Simple PHP Example    344\\n11.2 Overview of Basic Features of PHP    346\\nxx Contents'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 4, 'page_label': '5'}, page_content='11.3 Overview of PHP Database Programming    353\\n11.4  Brief Overview of Java Technologies for Database Web \\nProgramming    358\\n11.5 Summary    358\\nReview Questions   359\\nExercises   359\\nSelected Bibliography   359\\n■ part 5\\nObject, Object-Relational, and XML: Concepts, Models, \\nLanguages, and Standards ■ \\nchapter 12  Object and Object-Relational  \\nDatabases   363\\n12.1 Overview of Object Database Concepts    365\\n12.2 Object Database Extensions to SQL    379\\n12.3  The ODMG Object Model and the Object Definition Language \\nODL    386\\n12.4 Object Database Conceptual Design    405\\n12.5 The Object Query Language OQL    408\\n12.6  Overview of the C++ Language Binding in the ODMG \\nStandard    417\\n12.7 Summary    418\\nReview Questions   420\\nExercises   421\\nSelected Bibliography   422\\nchapter 13 XML: Extensible Markup Language   425\\n13.1 Structured, Semistructured, and Unstructured Data    426\\n13.2 XML Hierarchical (Tree) Data Model    430\\n13.3 XML Documents, DTD, and XML Schema    433\\n13.4  Storing and Extracting XML Documents  \\nfrom Databases    442\\n13.5 XML Languages    443\\n13.6 Extracting XML Documents from Relational Databases    447\\n13.7 XML/SQL: SQL Functions for Creating XML Data    453\\n13.8 Summary    455\\nReview Questions   456\\nExercises   456\\nSelected Bibliography   456\\n Contents xxi'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 5, 'page_label': '6'}, page_content='■ part 6\\nDatabase Design Theory and Normalization ■ \\nchapter 14  Basics of Functional Dependencies  \\nand Normalization for Relational \\nDatabases   459\\n14.1  Informal Design Guidelines for Relation  \\nSchemas    461\\n14.2 Functional Dependencies    471\\n14.3 Normal Forms Based on Primary Keys    474\\n14.4  General Definitions of Second and Third Normal  \\nForms    483\\n14.5 Boyce-Codd Normal Form    487\\n14.6  Multivalued Dependency and Fourth  \\nNormal Form    491\\n14.7 Join Dependencies and Fifth Normal Form    494\\n14.8 Summary    495\\nReview Questions   496\\nExercises   497\\nLaboratory Exercises   501\\nSelected Bibliography   502\\nchapter 15  Relational Database Design Algorithms  \\nand Further Dependencies   503\\n15.1  Further Topics in Functional Dependencies: Inference Rules, \\nEquivalence, and Minimal Cover    505\\n15.2 Properties of Relational Decompositions    513\\n15.3  Algorithms for Relational Database Schema  \\nDesign    519\\n15.4  About Nulls, Dangling Tuples, and Alternative Relational \\nDesigns    523\\n15.5  Further Discussion of Multivalued Dependencies  \\nand 4NF    527\\n15.6 Other Dependencies and Normal Forms    530\\n15.7 Summary    533\\nReview Questions   534\\nExercises   535\\nLaboratory Exercises   536\\nSelected Bibliography   537\\nxxii Contents'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 6, 'page_label': '7'}, page_content='■ part 7\\nFile Structures, Hashing, Indexing, and Physical \\nDatabase Design ■ \\nchapter 16  Disk Storage, Basic File Structures,  \\nHashing, and Modern Storage \\nArchitectures   541\\n16.1 Introduction    542\\n16.2 Secondary Storage Devices    547\\n16.3 Buffering of Blocks    556\\n16.4 Placing File Records on Disk    560\\n16.5 Operations on Files    564\\n16.6 Files of Unordered Records (Heap Files)    567\\n16.7 Files of Ordered Records (Sorted Files)    568\\n16.8 Hashing Techniques    572\\n16.9 Other Primary File Organizations    582\\n16.10  Parallelizing Disk Access Using RAID  \\nTechnology    584\\n16.11 Modern Storage Architectures    588\\n16.12 Summary    592\\nReview Questions   593\\nExercises   595\\nSelected Bibliography   598\\nchapter 17  Indexing Structures for Files and Physical \\nDatabase Design   601\\n17.1 Types of Single-Level Ordered Indexes    602\\n17.2 Multilevel Indexes    613\\n17.3  Dynamic Multilevel Indexes Using B-Trees  \\nand B\\n+-Trees    617\\n17.4 Indexes on Multiple Keys    631\\n17.5 Other Types of Indexes    633\\n17.6 Some General Issues Concerning Indexing    638\\n17.7  Physical Database Design in Relational  \\nDatabases    643\\n17.8 Summary    646\\nReview Questions   647\\nExercises   648\\nSelected Bibliography   650\\n Contents xxiii'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 7, 'page_label': '8'}, page_content='■ part 8\\nQuery Processing and Optimization ■ \\nchapter 18 Strategies for Query Processing   655\\n18.1  Translating SQL Queries into Relational Algebra  \\nand Other Operators    657\\n18.2 Algorithms for External Sorting    660\\n18.3 Algorithms for SELECT Operation    663\\n18.4 Implementing the JOIN Operation    668\\n18.5 Algorithms for PROJECT and Set Operations    676\\n18.6  Implementing Aggregate Operations and Different  \\nTypes of JOINs    678\\n18.7 Combining Operations Using Pipelining    681\\n18.8 Parallel Algorithms for Query Processing    683\\n18.9 Summary    688\\nReview Questions   688\\nExercises   689\\nSelected Bibliography   689\\nchapter 19 Query Optimization   691\\n19.1  Query Trees and Heuristics for Query  \\nOptimization    692\\n19.2 Choice of Query Execution Plans    701\\n19.3  Use of Selectivities in Cost-Based  \\nOptimization    710\\n19.4 Cost Functions for SELECT Operation    714\\n19.5 Cost Functions for the JOIN Operation    717\\n19.6  Example to Illustrate Cost-Based Query  \\nOptimization    726\\n19.7  Additional Issues Related to Query  \\nOptimization    728\\n19.8  An Example of Query Optimization in Data  \\nWarehouses    731\\n19.9 Overview of Query Optimization in Oracle    733\\n19.10 Semantic Query Optimization    737\\n19.11 Summary    738\\nReview Questions   739\\nExercises   740\\nSelected Bibliography   740\\nxxiv Contents'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 8, 'page_label': '9'}, page_content='■ part 9\\nTransaction Processing, Concurrency Control,  \\nand Recovery ■ \\nchapter 20  Introduction to Transaction Processing  \\nConcepts and Theory   745\\n20.1 Introduction to Transaction Processing    746\\n20.2 Transaction and System Concepts    753\\n20.3 Desirable Properties of Transactions    757\\n20.4 Characterizing Schedules Based on Recoverability    759\\n20.5 Characterizing Schedules Based on Serializability    763\\n20.6 Transaction Support in SQL    773\\n20.7 Summary    776\\nReview Questions   777\\nExercises   777\\nSelected Bibliography   779\\nchapter 21 Concurrency Control Techniques   781\\n21.1  Two-Phase Locking Techniques for Concurrency  \\nControl    782\\n21.2 Concurrency Control Based on Timestamp Ordering    792\\n21.3 Multiversion Concurrency Control Techniques    795\\n21.4  Validation (Optimistic) Techniques and Snapshot Isolation  \\nConcurrency Control    798\\n21.5  Granularity of Data Items and Multiple Granularity  \\nLocking    800\\n21.6 Using Locks for Concurrency Control in Indexes    805\\n21.7 Other Concurrency Control Issues    806\\n21.8 Summary    807\\nReview Questions   808\\nExercises   809\\nSelected Bibliography   810\\nchapter 22 Database Recovery Techniques   813\\n22.1 Recovery Concepts    814\\n22.2  NO-UNDO/REDO Recovery Based on Deferred  \\nUpdate    821\\n22.3 Recovery Techniques Based on Immediate Update    823\\n Contents xxv'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 9, 'page_label': '10'}, page_content='22.4 Shadow Paging    826\\n22.5 The ARIES Recovery Algorithm    827\\n22.6 Recovery in Multidatabase Systems    831\\n22.7 Database Backup and Recovery from Catastrophic Failures    832\\n22.8 Summary    833\\nReview Questions   834\\nExercises   835\\nSelected Bibliography   838\\n■ part 10\\nDistributed Databases, NOSQL Systems,  \\nand Big Data ■ \\nchapter 23 Distributed Database Concepts   841\\n23.1 Distributed Database Concepts    842\\n23.2  Data Fragmentation, Replication, and Allocation Techniques for \\nDistributed Database Design    847\\n23.3  Overview of Concurrency Control and Recovery in Distributed \\nDatabases    854\\n23.4  Overview of Transaction Management in Distributed Databases    857\\n23.5 Query Processing and Optimization in Distributed Databases    859\\n23.6 Types of Distributed Database Systems    865\\n23.7 Distributed Database Architectures    868\\n23.8 Distributed Catalog Management    875\\n23.9 Summary    876\\nReview Questions   877\\nExercises   878\\nSelected Bibliography   880\\nchapter 24  NOSQL Databases and Big Data Storage \\nSystems   883\\n24.1 Introduction to NOSQL Systems    884\\n24.2 The CAP Theorem    888\\n24.3  Document-Based NOSQL Systems and MongoDB    890\\n24.4 NOSQL Key-Value Stores    895\\n24.5  Column-Based or Wide Column NOSQL Systems    900\\n24.6 NOSQL Graph Databases and Neo4j    903\\n24.7 Summary    909\\nReview Questions   909\\nSelected Bibliography   910\\nxxvi Contents'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 10, 'page_label': '11'}, page_content='chapter 25  Big Data Technologies Based on MapReduce \\nand Hadoop   911\\n25.1 What Is Big Data?    914\\n25.2 Introduction to MapReduce and Hadoop    916\\n25.3 Hadoop Distributed File System (HDFS)    921\\n25.4 MapReduce: Additional Details    926\\n25.5 Hadoop v2 alias YARN    936\\n25.6 General Discussion    944\\n25.7 Summary    953\\nReview Questions   954\\nSelected Bibliography   956\\n■ part 11\\nAdvanced Database Models, Systems, and \\nApplications ■ \\nchapter 26  Enhanced Data Models: Introduction to Active, \\nTemporal, Spatial, Multimedia, and Deductive \\nDatabases   961\\n26.1 Active Database Concepts and Triggers    963\\n26.2 Temporal Database Concepts    974\\n26.3 Spatial Database Concepts    987\\n26.4 Multimedia Database Concepts    994\\n26.5 Introduction to Deductive Databases    999\\n26.6 Summary    1012\\nReview Questions   1014\\nExercises   1015\\nSelected Bibliography   1018\\nchapter 27  Introduction to Information Retrieval  \\nand Web Search   1021\\n27.1 Information Retrieval (IR) Concepts    1022\\n27.2 Retrieval Models    1029\\n27.3 Types of Queries in IR Systems    1035\\n27.4 Text Preprocessing    1037\\n27.5 Inverted Indexing    1040\\n27.6  Evaluation Measures of Search Relevance    1044\\n27.7 Web Search and Analysis    1047\\n Contents xxvii'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 11, 'page_label': '12'}, page_content='27.8 Trends in Information Retrieval    1057\\n27.9 Summary    1063\\nReview Questions   1064\\nSelected Bibliography   1066\\nchapter 28 Data Mining Concepts   1069\\n28.1 Overview of Data Mining Technology    1070\\n28.2 Association Rules    1073\\n28.3 Classification    1085\\n28.4 Clustering    1088\\n28.5 Approaches to Other Data Mining Problems    1091\\n28.6 Applications of Data Mining    1094\\n28.7 Commercial Data Mining Tools    1094\\n28.8 Summary    1097\\nReview Questions   1097\\nExercises   1098\\nSelected Bibliography   1099\\nchapter 29  Overview of Data Warehousing  \\nand OLAP   1101\\n29.1  Introduction, Definitions, and Terminology    1102\\n29.2 Characteristics of Data Warehouses    1103\\n29.3 Data Modeling for Data Warehouses    1105\\n29.4 Building a Data Warehouse    1111\\n29.5 Typical Functionality of a Data Warehouse    1114\\n29.6 Data Warehouse versus Views    1115\\n29.7 Difficulties of Implementing Data Warehouses    1116\\n29.8 Summary    1117\\nReview Questions   1117\\nSelected Bibliography   1118\\n■ part 12\\nAdditional Database Topics: Security ■ \\nchapter 30 Database Security   1121\\n30.1 Introduction to Database Security Issues    1122\\n30.2  Discretionary Access Control Based on Granting and Revoking \\nPrivileges    1129\\n30.3  Mandatory Access Control and Role-Based Access Control for \\nMultilevel Security    1134\\nxxviii Contents'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 12, 'page_label': '13'}, page_content='30.4 SQL Injection    1143\\n30.5 Introduction to Statistical Database Security    1146\\n30.6 Introduction to Flow Control    1147\\n30.7 Encryption and Public Key Infrastructures    1149\\n30.8 Privacy Issues and Preservation    1153\\n30.9 Challenges to Maintaining Database Security    1154\\n30.10 Oracle Label-Based Security    1155\\n30.11 Summary    1158\\nReview Questions   1159\\nExercises   1160\\nSelected Bibliography   1161\\nappendix A  Alternative Diagrammatic Notations for ER \\nModels   1163\\nappendix B Parameters of Disks   1167\\nappendix C Overview of the QBE Language   1171\\nC.1 Basic Retrievals in QBE   1171\\nC.2 Grouping, Aggregation, and Database Modification in QBE   1175\\nappendix D  Overview of the Hierarchical Data Model \\n(located on the Companion Website at \\nhttp://www.pearsonhighered.com/elmasri) \\nappendix E  Overview of the Network Data Model \\n(located on the Companion Website at \\nhttp://www.pearsonhighered.com/elmasri) \\nSelected Bibliography   1179\\nIndex   1215\\n Contents xxix'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 13, 'page_label': '14'}, page_content='About the Authors\\nRamez Elmasri is a professor and the associate chairperson of the Department of \\nComputer Science and Engineering at the University of Texas at Arlington. He has \\nover 140 refereed research publications, and has supervised 16 PhD students and \\nover 100 MS students. His research has covered many areas of database manage-\\nment and big data, including conceptual modeling and data integration, query \\nlanguages and indexing techniques, temporal and spatio-temporal databases, bio-\\ninformatics databases, data collection from sensor networks, and mining/analysis \\nof spatial and spatio-temporal data. He has worked as a consultant to various com-\\npanies, including Digital, Honeywell, Hewlett Packard, and Action Technologies, \\nas well as consulting with law firms on patents. He was the Program Chair of the \\n1993 International Conference on Conceptual Modeling (ER conference) and pro-\\ngram vice-chair of the 1994 IEEE International Conference on Data Engineering. \\nHe has served on the ER conference steering committee and has been on the pro-\\ngram committees of many conferences. He has given several tutorials at the VLDB, \\nICDE, and ER conferences. He also co-authored the book “Operating Systems: A \\nSpiral Approach” (McGraw-Hill, 2009) with Gil Carrick and David Levine. Elmasri \\nis a recipient of the UTA College of Engineering Outstanding Teaching Award in \\n1999. He holds a BS degree in Engineering from Alexandria University, and MS \\nand PhD degrees in Computer Science from Stanford University.\\nShamkant B. Navathe is a professor and the founder of the database research group \\nat the College of Computing, Georgia Institute of Technology, Atlanta. He has \\nworked with IBM and Siemens in their research divisions and has been a consultant \\nto various companies including Digital, Computer Corporation of America, \\nHewlett Packard, Equifax, and Persistent Systems. He was the General Co-chairman \\nof the 1996 International VLDB (Very Large Data Base) conference in Bombay, \\nIndia. He was also program co-chair of ACM SIGMOD 1985 International Confer-\\nence and General Co-chair of the IFIP WG 2.6 Data Semantics Workshop in 1995. \\nHe has served on the VLDB foundation and has been on the steering committees of \\nseveral conferences. He has been an associate editor of a number of journals \\nincluding ACM Computing Surveys , and IEEE Transactions on Knowledge and \\nData Engineering . He also co-authored the book “Conceptual Design: An Entity \\nRelationship Approach” (Addison Wesley, 1992) with Carlo Batini and Stefano \\nCeri. Navathe is a fellow of the Association for Computing Machinery (ACM) and \\nrecipient of the IEEE TCDE Computer Science, Engineering and Education Impact \\naward in 2015. Navathe holds a PhD from the University of Michigan and has over \\n150 refereed publications in journals and conferences.\\nxxx'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 14, 'page_label': '15'}, page_content='part 1 \\nIntroduction  \\nto Databases'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 15, 'page_label': '16'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 16, 'page_label': '17'}, page_content='3\\n1chapter 1\\nDatabases and \\nDatabase Users\\nD\\natabases and database systems are an essential \\ncomponent of life in modern society: most of us \\nencounter several activities every day that involve some interaction with a database. \\nFor example, if we go to the bank to deposit or withdraw funds, if we make a hotel \\nor airline reservation, if we access a computerized library catalog to search for a \\nbibliographic item, or if we purchase something online—such as a book, toy, or \\ncomputer—chances are that our activities will involve someone or some computer \\nprogram accessing a database. Even purchasing items at a supermarket often auto-\\nmatically updates the database that holds the inventory of grocery items.\\nThese interactions are examples of what we may call traditional database \\n applications, in which most of the information that is stored and accessed is either \\ntextual or numeric. In the past few years, advances in technology have led to exciting \\nnew applications of database systems. The proliferation of social media Web sites, \\nsuch as Facebook, Twitter, and Flickr, among many others, has required the cre-\\nation of huge databases that store nontraditional data, such as posts, tweets, \\nimages, and video clips. New types of database systems, often referred to as big data \\nstorage systems, or NOSQL systems, have been created to manage data for social \\nmedia applications. These types of systems are also used by companies such as \\nGoogle, Amazon, and Yahoo, to manage the data required in their Web search \\nengines, as well as to provide cloud storage, whereby users are provided with stor-\\nage capabilities on the Web for managing all types of data including documents, \\nprograms, images, videos and emails. We will give an overview of these new types \\nof database systems in Chapter 24.\\nWe now mention some other applications of databases. The wide availability of \\nphoto and video technology on cellphones and other devices has made it possible to'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 17, 'page_label': '18'}, page_content='4 Chapter 1 Databases and Database Users\\nstore images, audio clips, and video streams digitally. These types of files are becom-\\ning an important component of multimedia databases. Geographic information \\nsystems (GISs)  can store and analyze maps, weather data, and satellite images. \\nData warehouses  and online analytical processing (OLAP)  systems are used in \\nmany companies to extract and analyze useful business information from very large \\ndatabases to support decision making. Real-time and active database technology \\nis used to control industrial and manufacturing processes. And database search \\ntechniques are being applied to the World Wide Web to improve the search for \\ninformation that is needed by users browsing the Internet.\\nTo understand the fundamentals of database technology, however, we must start \\nfrom the basics of traditional database applications. In Section 1.1 we start by defin-\\ning a database, and then we explain other basic terms. In Section 1.2, we provide a \\nsimple UNIVERSITY database example to illustrate our discussion. Section 1.3 \\ndescribes some of the main characteristics of database systems, and Sections 1.4 \\nand 1.5 categorize the types of personnel whose jobs involve using and interacting \\nwith database systems. Sections 1.6, 1.7, and 1.8 offer a more thorough discussion \\nof the various capabilities provided by database systems and discuss some typical \\ndatabase applications. Section 1.9 summarizes the chapter.\\nThe reader who desires a quick introduction to database systems can study \\n Sections 1.1 through 1.5, then skip or browse through Sections 1.6 through 1.8 and \\ngo on to Chapter 2.\\n1.1 Introduction\\nDatabases and database technology have had a major impact on the growing use of \\ncomputers. It is fair to say that databases play a critical role in almost all areas where \\ncomputers are used, including business, electronic commerce, social media, engi-\\nneering, medicine, genetics, law, education, and library science. The word database \\nis so commonly used that we must begin by defining what a database is. Our initial \\ndefinition is quite general.\\nA database is a collection of related data.\\n1 By data, we mean known facts that can \\nbe recorded and that have implicit meaning. For example, consider the names, \\ntelephone numbers, and addresses of the people you know. Nowadays, this data is \\ntypically stored in mobile phones, which have their own simple database software. \\nThis data can also be recorded in an indexed address book or stored on a hard \\ndrive, using a personal computer and software such as Microsoft Access or Excel. \\nThis collection of related data with an implicit meaning is a database.\\nThe preceding definition of database is quite general; for example, we may consider \\nthe collection of words that make up this page of text to be related data and hence to \\n1We will use the word data as both singular and plural, as is common in database literature; the context \\nwill determine whether it is singular or plural. In standard English, data is used for plural and datum for \\nsingular.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 18, 'page_label': '19'}, page_content='1.1 Introduction  5\\nconstitute a database. However, the common use of the term database is usually \\nmore restricted. A database has the following implicit properties:\\n■ A database represents some aspect of the real world, sometimes called the \\nminiworld or the universe of discourse (UoD) . Changes to the miniworld \\nare reflected in the database.\\n■ A database is a logically coherent collection of data with some inherent \\nmeaning. A random assortment of data cannot correctly be referred to as a \\ndatabase.\\n■ A database is designed, built, and populated with data for a specific purpose. \\nIt has an intended group of users and some preconceived applications in \\nwhich these users are interested.\\nIn other words, a database has some source from which data is derived, some degree \\nof interaction with events in the real world, and an audience that is actively inter-\\nested in its contents. The end users of a database may perform business transactions \\n(for example, a customer buys a camera) or events may happen (for example, an \\nemployee has a baby) that cause the information in the database to change. In order \\nfor a database to be accurate and reliable at all times, it must be a true reflection of \\nthe miniworld that it represents; therefore, changes must be reflected in the data-\\nbase as soon as possible.\\nA database can be of any size and complexity. For example, the list of names and \\naddresses referred to earlier may consist of only a few hundred records, each with a \\nsimple structure. On the other hand, the computerized catalog of a large library \\nmay contain half a million entries organized under different categories—by pri-\\nmary author’s last name, by subject, by book title—with each category organized \\nalphabetically. A database of even greater size and complexity would be maintained \\nby a social media company such as Facebook, which has more than a billion users. \\nThe database has to maintain information on which users are related to one another \\nas friends, the postings of each user, which users are allowed to see each posting, \\nand a vast amount of other types of information needed for the correct operation of \\ntheir Web site. For such Web sites, a large number of databases are needed to keep \\ntrack of the constantly changing information required by the social media Web site.\\nAn example of a large commercial database is Amazon.com. It contains data for \\nover 60 million active users, and millions of books, CDs, videos, DVDs, games, \\nelectronics, apparel, and other items. The database occupies over 42 terabytes \\n(a\\xa0terabyte is 10\\n12 bytes worth of storage) and is stored on hundreds of computers \\n(called servers). Millions of visitors access Amazon.com each day and use the \\ndatabase to make purchases. The database is continually updated as new books \\nand other items are added to the inventory, and stock quantities are updated as \\npurchases are transacted.\\nA database may be generated and maintained manually or it may be computer-\\nized. For example, a library card catalog is a database that may be created and \\nmaintained manually. A computerized database may be created and maintained \\neither by a group of application programs written specifically for that task or by a'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 19, 'page_label': '20'}, page_content='6 Chapter 1 Databases and Database Users\\ndatabase management system. Of course, we are only concerned with computer-\\nized databases in this text.\\nA database management system (DBMS)  is a computerized system that enables \\nusers to create and maintain a database. The DBMS is a general-purpose software \\nsystem that facilitates the processes of defining, constructing, manipulating,  and \\nsharing  databases among various users and applications. Defining  a database \\ninvolves specifying the data types, structures, and constraints of the data to be \\nstored in the database. The database definition or descriptive information is also \\nstored by the DBMS in the form of a database catalog or dictionary; it is called \\nmeta-data. Constructing the database is the process of storing the data on some \\nstorage medium that is controlled by the DBMS. Manipulating a database includes \\nfunctions such as querying the database to retrieve specific data, updating the data-\\nbase to reflect changes in the miniworld, and generating reports from the data. \\nSharing a database allows multiple users and programs to access the database \\nsimultaneously.\\nAn application program accesses the database by sending queries or requests for \\ndata to the DBMS. A query\\n2 typically causes some data to be retrieved; a transaction \\nmay cause some data to be read and some data to be written into the database.\\nOther important functions provided by the DBMS include protecting the database \\nand maintaining it over a long period of time. Protection includes system protec-\\ntion against hardware or software malfunction (or crashes) and security protection \\nagainst unauthorized or malicious access. A typical large database may have a life \\ncycle of many years, so the DBMS must be able to maintain the database system by \\nallowing the system to evolve as requirements change over time.\\nIt is not absolutely necessary to use general-purpose DBMS software to implement \\na computerized database. It is possible to write a customized set of programs to cre-\\nate and maintain the database, in effect creating a special-purpose DBMS software \\nfor a specific application, such as airlines reservations. In either case—whether we \\nuse a general-purpose DBMS or not—a considerable amount of complex software \\nis deployed. In fact, most DBMSs are very complex software systems.\\nTo complete our initial definitions, we will call the database and DBMS software \\ntogether a database system . Figure 1.1 illustrates some of the concepts we have \\ndiscussed so far.\\n1.2 An Example\\nLet us consider a simple example that most readers may be familiar with: a \\n UNIVERSITY database for maintaining information concerning students, courses, \\nand grades in a university environment. Figure 1.2 shows the database structure \\nand a few sample data records. The database is organized as five files, each of which \\n2The term query, originally meaning a question or an inquiry, is sometimes loosely used for all types of \\ninteractions with databases, including modifying the data.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 20, 'page_label': '21'}, page_content='1.2 An Example  7\\nstores data records of the same type. 3 The STUDENT file stores data on each stu-\\ndent, the COURSE file stores data on each course, the SECTION file stores data on \\neach section of a course, the GRADE_REPORT file stores the grades that students \\nreceive in the various sections they have completed, and the PREREQUISITE  file \\nstores the prerequisites of each course.\\nTo define this database, we must specify the structure of the records of each file by \\nspecifying the different types of data elements  to be stored in each record. In \\nFigure 1.2, each STUDENT record includes data to represent the student’s Name, \\nStudent_number, Class (such as freshman or ‘1’, sophomore or ‘2’, and so forth), \\nand Major (such as mathematics or ‘MATH’ and computer science or ‘CS’); each \\nCOURSE record includes data to represent the Course_name, Course_number , \\nCredit_hours , and Department  (the department that offers the course), and so  \\non. We must also specify a data type  for each data element within a record. For \\nexample, we can specify that Name of STUDENT is a string of alphabetic characters, \\nStudent_number  of STUDENT is an integer, and Grade of GRADE_REPORT  is a  \\n3We use the term file informally here. At a conceptual level, a file is a collection of records that may or \\nmay not be ordered.\\nDatabase\\nSystem\\nUsers/Programmers \\nApplication Programs/Queries \\nSoftware to Process \\nQueries/Programs \\nSoftware to Access \\nStored Data \\nStored Database \\nStored Database \\nDefinition \\n(Meta-Data) \\nDBMS\\nSoftware\\nFigure 1.1 \\nA simplified database \\nsystem environment.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 21, 'page_label': '22'}, page_content='8 Chapter 1 Databases and Database Users\\nName Student_number Class Major\\nSmith 17 1 CS\\nBrown 8 2 CS\\nSTUDENT\\nCourse_name Course_number Credit_hours Department\\nIntro to Computer Science CS1310 4 CS\\nData Structures CS3320 4 CS\\nDiscrete Mathematics MATH2410 3 MATH\\nDatabase CS3380 3 CS\\nCOURSE\\nSection_identifier Course_number Semester Year Instructor\\n85 MATH2410 Fall 07 King\\n92 CS1310 Fall 07 Anderson\\n102 CS3320 Spring 08 Knuth\\n112 MATH2410 Fall 08 Chang\\n119 CS1310 Fall 08 Anderson\\n135 CS3380 Fall 08 Stone\\nSECTION\\nStudent_number Section_identifier Grade\\n17 112 B\\n17 119 C\\n8 85 A\\n8 92 A\\n8 102 B\\n8 135 A\\nGRADE_REPORT\\nCourse_number Prerequisite_number\\nCS3380 CS3320\\nCS3380 MATH2410\\nCS3320 CS1310\\nPREREQUISITE\\nFigure 1.2 \\nA database that stores \\nstudent and course \\ninformation.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 22, 'page_label': '23'}, page_content='1.2 An Example  9\\nsingle character from the set {‘A’, ‘B’, ‘C’, ‘D’, ‘F’, ‘I’}. We may also use a coding \\nscheme to represent the values of a data item. For example, in Figure 1.2 we rep-\\nresent the \\nClass of a STUDENT as 1 for freshman, 2 for sophomore, 3 for junior,  \\n4 for senior, and 5 for graduate student.\\nTo construct the UNIVERSITY database, we store data to represent each student, \\ncourse, section, grade report, and prerequisite as a record in the appropriate file. \\nNotice that records in the various files may be related. For example, the record for \\nSmith in the STUDENT file is related to two records in the GRADE_REPORT file that \\nspecify Smith’s grades in two sections. Similarly, each record in the PREREQUISITE  \\nfile relates two course records: one representing the course and the other represent-\\ning the prerequisite. Most medium-size and large databases include many types of \\nrecords and have many relationships among the records.\\nDatabase manipulation involves querying and updating. Examples of queries are as \\nfollows:\\n■ Retrieve the transcript—a list of all courses and grades—of ‘Smith’\\n■ List the names of students who took the section of the ‘Database’ course \\noffered in fall 2008 and their grades in that section\\n■ List the prerequisites of the ‘Database’ course\\nExamples of updates include the following:\\n■ Change the class of ‘Smith’ to sophomore\\n■ Create a new section for the ‘Database’ course for this semester\\n■ Enter a grade of ‘A’ for ‘Smith’ in the ‘Database’ section of last semester\\nThese informal queries and updates must be specified precisely in the query lan-\\nguage of the DBMS before they can be processed.\\nAt this stage, it is useful to describe the database as part of a larger undertaking \\nknown as an information system within an organization. The Information Tech-\\nnology (IT) department within an organization designs and maintains an informa-\\ntion system consisting of various computers, storage systems, application software, \\nand databases. Design of a new application for an existing database or design of a \\nbrand new database starts off with a phase called requirements specification and \\nanalysis. These requirements are documented in detail and transformed into a \\n conceptual design that can be represented and manipulated using some comput-\\nerized tools so that it can be easily maintained, modified, and transformed into a \\ndatabase implementation. (We will introduce a model called the Entity-Relation-\\nship model in Chapter 3 that is used for this purpose.) The design is then translated \\nto a logical design that can be expressed in a data model implemented in a com-\\nmercial DBMS. (Various types of DBMSs are discussed throughout the text, with an \\nemphasis on relational DBMSs in Chapters 5 through 9.)\\nThe final stage is physical design, during which further specifications are provided for \\nstoring and accessing the database. The database design is implemented, populated \\nwith actual data, and continuously maintained to reflect the state of the miniworld.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 23, 'page_label': '24'}, page_content='10 Chapter 1 Databases and Database Users\\n1.3 Characteristics of the Database Approach\\nA number of characteristics distinguish the database approach from the much \\nolder approach of writing customized programs to access data stored in files. In \\ntraditional file processing, each user defines and implements the files needed for a \\nspecific software application as part of programming the application. For example, \\none user, the grade reporting office,  may keep files on students and their grades. \\nPrograms to print a student’s transcript and to enter new grades are implemented \\nas part of the application. A second user, the accounting office , may keep track of \\nstudents’ fees and their payments. Although both users are interested in data about \\nstudents, each user maintains separate files—and programs to manipulate these \\nfiles—because each requires some data not available from the other user’s files. \\nThis redundancy in defining and storing data results in wasted storage space and \\nin redundant efforts to maintain common up-to-date data.\\nIn the database approach, a single repository maintains data that is defined once \\nand then accessed by various users repeatedly through queries, transactions, and \\napplication programs. The main characteristics of the database approach versus the \\nfile-processing approach are the following:\\n■ Self-describing nature of a database system\\n■ Insulation between programs and data, and data abstraction\\n■ Support of multiple views of the data\\n■ Sharing of data and multiuser transaction processing\\nWe describe each of these characteristics in a separate section. We will discuss addi-\\ntional characteristics of database systems in Sections 1.6 through 1.8.\\n1.3.1 Self-Describing Nature of a Database System\\nA fundamental characteristic of the database approach is that the database system \\ncontains not only the database itself but also a complete definition or description of \\nthe database structure and constraints. This definition is stored in the DBMS cata-\\nlog, which contains information such as the structure of each file, the type and stor-\\nage format of each data item, and various constraints on the data. The information \\nstored in the catalog is called meta-data, and it describes the structure of the pri-\\nmary database (Figure 1.1). It is important to note that some newer types of data-\\nbase systems, known as NOSQL systems, do not require meta-data. Rather the data \\nis stored as self-describing data that includes the data item names and data values \\ntogether in one structure (see Chapter 24).\\nThe catalog is used by the DBMS software and also by database users who need \\ninformation about the database structure. A general-purpose DBMS software \\npackage is not written for a specific database application. Therefore, it must refer \\nto the catalog to know the structure of the files in a specific database, such as the \\ntype and format of data it will access. The DBMS software must work equally well \\nwith any number of database applications— for example, a university database, a'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 24, 'page_label': '25'}, page_content='1.3 Characteristics of the Database Approach  11\\nbanking database, or a company database—as long as the database definition is \\nstored in the catalog.\\nIn traditional file processing, data definition is typically part of the application pro-\\ngrams themselves. Hence, these programs are constrained to work with only one \\nspecific database,  whose structure is declared in the application programs. For \\nexample, an application program written in C++ may have struct or class declara-\\ntions. Whereas file-processing software can access only specific databases, DBMS \\nsoftware can access diverse databases by extracting the database definitions from \\nthe catalog and using these definitions.\\nFor the example shown in Figure 1.2, the DBMS catalog will store the definitions of \\nall the files shown. Figure 1.3 shows some entries in a database catalog. Whenever a \\nrequest is made to access, say, the \\nName of a STUDENT record, the DBMS software \\nrefers to the catalog to determine the structure of the STUDENT file and the position \\nand size of the Name data item within a STUDENT record. By contrast, in a typical \\nfile-processing application, the file structure and, in the extreme case, the exact \\nlocation of \\nName within a STUDENT record are already coded within each program \\nthat accesses this data item.\\nFigure 1.3 \\nAn example of a \\n database catalog for \\nthe database in \\n Figure 1.2.\\nRelation_name No_of_columns\\nSTUDENT 4\\nCOURSE 4\\nSECTION 5\\nGRADE_REPORT 3\\nPREREQUISITE 2\\nColumn_name Data_type Belongs_to_relation\\nName Character (30) STUDENT\\nStudent_number Character (4) STUDENT\\nClass Integer (1) STUDENT\\nMajor Major_type STUDENT\\nCourse_name Character (10) COURSE\\nCourse_number XXXXNNNN COURSE\\n…. …. …..\\n…. …. …..\\n…. …. …..\\nPrerequisite_number XXXXNNNN PREREQUISITE\\nRELATIONS\\nCOLUMNS\\nNote: Major_type is defined as an enumerated type with all known majors.  \\nXXXXNNNN is used to define a type with four alphabetic characters followed by four numeric digits.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 25, 'page_label': '26'}, page_content='12 Chapter 1 Databases and Database Users\\n1.3.2  Insulation between Programs and Data,  \\nand Data Abstraction\\nIn traditional file processing, the structure of data files is embedded in the applica-\\ntion programs, so any changes to the structure of a file may require changing all \\nprograms that access that file. By contrast, DBMS access programs do not require \\nsuch changes in most cases. The structure of data files is stored in the DBMS cata-\\nlog separately from the access programs. We call this property program-data \\nindependence.\\nFor example, a file access program may be written in such a way that it can access \\nonly STUDENT records of the structure shown in Figure 1.4. If we want to add \\nanother piece of data to each STUDENT record, say the Birth_date, such a program \\nwill no longer work and must be changed. By contrast, in a DBMS environment, we \\nonly need to change the description of \\nSTUDENT records in the catalog (Figure 1.3) \\nto reflect the inclusion of the new data item Birth_date; no programs are changed. \\nThe next time a DBMS program refers to the catalog, the new structure of  \\nSTUDENT records will be accessed and used.\\nIn some types of database systems, such as object-oriented and object-relational \\nsystems (see Chapter 12), users can define operations on data as part of the database \\ndefinitions. An operation (also called a function or method) is specified in two \\nparts. The interface (or signature) of an operation includes the operation name and \\nthe data types of its arguments (or parameters). The implementation (or method) of \\nthe operation is specified separately and can be changed without affecting the inter-\\nface. User application programs can operate on the data by invoking these opera-\\ntions through their names and arguments, regardless of how the operations are \\nimplemented. This may be termed program-operation independence.\\nThe characteristic that allows program-data independence and program-operation \\nindependence is called data abstraction. A DBMS provides users with a conceptual \\nrepresentation of data that does not include many of the details of how the data is \\nstored or how the operations are implemented. Informally, a data model is a type of \\ndata abstraction that is used to provide this conceptual representation. The data \\nmodel uses logical concepts, such as objects, their properties, and their interrela-\\ntionships, that may be easier for most users to understand than computer storage \\nconcepts. Hence, the data model hides storage and implementation details that are \\nnot of interest to most database users.\\nLooking at the example in Figures 1.2 and 1.3, the internal implementation of the \\nSTUDENT file may be defined by its record length—the number of characters \\n(bytes) in each record—and each data item may be specified by its starting byte \\nwithin a record and its length in bytes. The \\nSTUDENT record would thus be repre-\\nsented as shown in Figure 1.4. But a typical database user is not concerned with the \\nlocation of each data item within a record or its length; rather, the user is concerned \\nthat when a reference is made to \\nName of STUDENT, the correct value is returned.  \\nA conceptual representation of the STUDENT records is shown in Figure 1.2. Many \\nother details of file storage organization—such as the access paths specified on a'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 26, 'page_label': '27'}, page_content='1.3 Characteristics of the Database Approach  13\\nfile—can be hidden from database users by the DBMS; we discuss storage details in \\nChapters 16 and 17.\\nIn the database approach, the detailed structure and organization of each file are \\nstored in the catalog. Database users and application programs refer to the concep-\\ntual representation of the files, and the DBMS extracts the details of file storage \\nfrom the catalog when these are needed by the DBMS file access modules. Many \\ndata models can be used to provide this data abstraction to database users. A major \\npart of this text is devoted to presenting various data models and the concepts they \\nuse to abstract the representation of data.\\nIn object-oriented and object-relational databases, the abstraction process includes \\nnot only the data structure but also the operations on the data. These operations \\nprovide an abstraction of miniworld activities commonly understood by the users. \\nFor example, an operation \\nCALCULATE_GPA can be applied to a STUDENT object  \\nto calculate the grade point average. Such operations can be invoked by the user \\nqueries or application programs without having to know the details of how the \\noperations are implemented.\\n1.3.3 Support of Multiple Views of the Data\\nA database typically has many types of users, each of whom may require a different \\nperspective or view of the database. A view may be a subset of the database or it may \\ncontain virtual data that is derived from the database files but is not explicitly stored. \\nSome users may not need to be aware of whether the data they refer to is stored or \\nderived. A multiuser DBMS whose users have a variety of distinct applications must \\nprovide facilities for defining multiple views. For example, one user of the database \\nof Figure 1.2 may be interested only in accessing and printing the transcript of each \\nstudent; the view for this user is shown in Figure 1.5(a). A second user, who is inter-\\nested only in checking that students have taken all the prerequisites of each course \\nfor which the student registers, may require the view shown in Figure 1.5(b).\\n1.3.4 Sharing of Data and Multiuser Transaction Processing\\nA multiuser DBMS, as its name implies, must allow multiple users to access the \\ndatabase at the same time. This is essential if data for multiple applications is to be \\nintegrated and maintained in a single database. The DBMS must include  concurrency \\ncontrol  software to ensure that several users trying to update the same data  \\nData Item Name Starting Position in Record Length in Characters (bytes)\\nName 1 30\\nStudent_number 31 4\\nClass 35 1\\nMajor 36 4\\nFigure 1.4 \\nInternal storage format \\nfor a STUDENT record, \\nbased on the database \\ncatalog in Figure 1.3.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 27, 'page_label': '28'}, page_content='14 Chapter 1 Databases and Database Users\\ndo so in a controlled manner so that the result of the updates is correct. For exam-\\nple, when several reservation agents try to assign a seat on an airline flight, the \\nDBMS should ensure that each seat can be accessed by only one agent at a time for \\nassignment to a passenger. These types of applications are generally called online \\ntransaction processing (OLTP)  applications. A fundamental role of multiuser \\nDBMS software is to ensure that concurrent transactions operate correctly and \\nefficiently.\\nThe concept of a transaction has become central to many database applications. A \\ntransaction is an executing program or process that includes one or more database \\naccesses, such as reading or updating of database records. Each transaction is sup-\\nposed to execute a logically correct database access if executed in its entirety with-\\nout interference from other transactions. The DBMS must enforce several \\ntransaction properties. The isolation  property ensures that each transaction \\nappears to execute in isolation from other transactions, even though hundreds of \\ntransactions may be executing concurrently. The atomicity property ensures that \\neither all the database operations in a transaction are executed or none are. We dis-\\ncuss transactions in detail in Part 9.\\nThe preceding characteristics are important in distinguishing a DBMS from tradi-\\ntional file-processing software. In Section 1.6 we discuss additional features that \\ncharacterize a DBMS. First, however, we categorize the different types of people \\nwho work in a database system environment.\\nStudent_name\\nStudent_transcript\\nCourse_number Grade Semester Year Section_id\\nSmith\\nCS1310 C Fall 08 119\\nMATH2410 B Fall 08 112\\nBrown\\nMATH2410 A Fall 07 85\\nCS1310 A Fall 07 92\\nCS3320 B Spring 08 102\\nCS3380 A Fall 08 135\\nTRANSCRIPT\\nCourse_name Course_number Prerequisites\\nDatabase CS3380\\nCS3320\\nMATH2410\\nData Structures CS3320 CS1310\\nCOURSE_PREREQ UISITES\\n(a)\\n(b)\\nFigure 1.5 \\nTwo views derived from the database in Figure 1.2. (a) The TRANSCRIPT view.  \\n(b) The COURSE_PREREQUISITES view.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 28, 'page_label': '29'}, page_content='1.4 Actors on the Scene  15\\n1.4 Actors on the Scene\\nFor a small personal database, such as the list of addresses discussed in Section 1.1, \\none person typically defines, constructs, and manipulates the database, and there is \\nno sharing. However, in large organizations, many people are involved in the \\ndesign, use, and maintenance of a large database with hundreds or thousands of \\nusers. In this section we identify the people whose jobs involve the day-to-day use \\nof a large database; we call them the actors on the scene. In Section 1.5 we consider \\npeople who may be called workers behind the scene —those who work to maintain \\nthe database system environment but who are not actively interested in the data-\\nbase contents as part of their daily job.\\n1.4.1 Database Administrators\\nIn any organization where many people use the same resources, there is a need for \\na chief administrator to oversee and manage these resources. In a database environ-\\nment, the primary resource is the database itself, and the secondary resource is the \\nDBMS and related software. Administering these resources is the responsibility of \\nthe database administrator (DBA). The DBA is responsible for authorizing access \\nto the database, coordinating and monitoring its use, and acquiring software and \\nhardware resources as needed. The DBA is accountable for problems such as secu-\\nrity breaches and poor system response time. In large organizations, the DBA is \\nassisted by a staff that carries out these functions.\\n1.4.2 Database Designers\\nDatabase designers are responsible for identifying the data to be stored in the data-\\nbase and for choosing appropriate structures to represent and store this data. These \\ntasks are mostly undertaken before the database is actually implemented and popu-\\nlated with data. It is the responsibility of database designers to communicate with \\nall prospective database users in order to understand their requirements and to cre-\\nate a design that meets these requirements. In many cases, the designers are on the \\nstaff of the DBA and may be assigned other staff responsibilities after the database \\ndesign is completed. Database designers typically interact with each potential group \\nof users and develop views of the database that meet the data and processing \\nrequirements of these groups. Each view is then analyzed and integrated with the \\nviews of other user groups. The final database design must be capable of supporting \\nthe requirements of all user groups.\\n1.4.3 End Users\\nEnd users are the people whose jobs require access to the database for querying, \\nupdating, and generating reports; the database primarily exists for their use. There \\nare several categories of end users:\\n■ Casual end users occasionally access the database, but they may need differ-\\nent information each time. They use a sophisticated database query interface'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 29, 'page_label': '30'}, page_content='16 Chapter 1 Databases and Database Users\\nto specify their requests and are typically middle- or high-level managers or \\nother occasional browsers.\\n■ Naive  or parametric end users  make up a sizable portion of database \\nend users. Their main job function revolves around constantly querying \\nand updating the database, using standard types of queries and updates—\\ncalled canned transactions —that have been carefully programmed and \\ntested. Many of these tasks are now available as mobile apps  for use with \\nmobile devices. The tasks that such users perform are varied. A few \\nexamples are:\\n/box4 Bank customers and tellers check account balances and post withdrawals \\nand deposits.\\n/box4 Reservation agents or customers for airlines, hotels, and car rental com-\\npanies check availability for a given request and make reservations.\\n/box4 Employees at receiving stations for shipping companies enter package \\nidentifications via bar codes and descriptive information through buttons \\nto update a central database of received and in-transit packages.\\n/box4 Social media users post and read items on social media Web sites.\\n■ Sophisticated end users include engineers, scientists, business analysts, and \\nothers who thoroughly familiarize themselves with the facilities of the DBMS \\nin order to implement their own applications to meet their complex require-\\nments.\\n■ Standalone users  maintain personal databases by using ready-made pro-\\ngram packages that provide easy-to-use menu-based or graphics-based \\ninterfaces. An example is the user of a financial software package that stores \\na variety of personal financial data.\\nA typical DBMS provides multiple facilities to access a database. Naive end users \\nneed to learn very little about the facilities provided by the DBMS; they simply have \\nto understand the user interfaces of the mobile apps or standard transactions \\ndesigned and implemented for their use. Casual users learn only a few facilities that \\nthey may use repeatedly. Sophisticated users try to learn most of the DBMS facilities \\nin order to achieve their complex requirements. Standalone users typically become \\nvery proficient in using a specific software package.\\n1.4.4  System Analysts and Application Programmers  \\n(Software Engineers)\\nSystem analysts  determine the requirements of end users, especially naive and \\nparametric end users, and develop specifications for standard canned transactions \\nthat meet these requirements. Application programmers implement these specifi-\\ncations as programs; then they test, debug, document, and maintain these canned \\ntransactions. Such analysts and programmers—commonly referred to as software \\ndevelopers or software engineers—should be familiar with the full range of capa-\\nbilities provided by the DBMS to accomplish their tasks.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 30, 'page_label': '31'}, page_content='1.6 Advantages of Using the DBMS Approach  17\\n1.5 Workers behind the Scene\\nIn addition to those who design, use, and administer a database, others are associ-\\nated with the design, development, and operation of the DBMS software and system \\nenvironment.  These persons are typically not interested in the database content \\nitself. We call them the workers behind the scene , and they include the following \\ncategories:\\n■ DBMS system designers and implementers  design and implement the \\nDBMS modules and interfaces as a software package. A DBMS is a very \\ncomplex software system that consists of many components, or modules, \\nincluding modules for implementing the catalog, query language process-\\ning, interface processing, accessing and buffering data, controlling concur-\\nrency, and handling data recovery and security. The DBMS must interface \\nwith other system software, such as the operating system and compilers for \\nvarious programming languages.\\n■ Tool developers  design and implement tools—the software packages that \\nfacilitate database modeling and design, database system design, and \\nimproved performance. Tools are optional packages that are often pur-\\nchased separately. They include packages for database design, performance \\nmonitoring, natural language or graphical interfaces, prototyping, simula-\\ntion, and test data generation. In many cases, independent software vendors \\ndevelop and market these tools.\\n■ Operators and maintenance personnel (system administration personnel) \\nare responsible for the actual running and maintenance of the hardware and \\nsoftware environment for the database system.\\nAlthough these categories of workers behind the scene are instrumental in making \\nthe database system available to end users, they typically do not use the database \\ncontents for their own purposes.\\n1.6 Advantages of Using the DB MS Approach\\nIn this section we discuss some additional advantages of using a DBMS and the \\ncapabilities that a good DBMS should possess. These capabilities are in addition to \\nthe four main characteristics discussed in Section 1.3. The DBA must utilize these \\ncapabilities to accomplish a variety of objectives related to the design, administra-\\ntion, and use of a large multiuser database.\\n1.6.1 Controlling Redundancy\\nIn traditional software development utilizing file processing, every user group \\nmaintains its own files for handling its data-processing applications. For example, \\nconsider the \\nUNIVERSITY  database example of Section 1.2; here, two groups of  \\nusers might be the course registration personnel and the accounting office. In the \\ntraditional approach, each group independently keeps files on students. The'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 31, 'page_label': '32'}, page_content='18 Chapter 1 Databases and Database Users\\naccounting office keeps data on registration and related billing information, \\nwhereas the registration office keeps track of student courses and grades. Other \\ngroups may further duplicate some or all of the same data in their own files.\\nThis redundancy in storing the same data multiple times leads to several problems. \\nFirst, there is the need to perform a single logical update—such as entering data on \\na new student—multiple times: once for each file where student data is recorded. \\nThis leads to duplication of effort.  Second, storage space is wasted  when the same \\ndata is stored repeatedly, and this problem may be serious for large databases. \\nThird, files that represent the same data may become inconsistent. This may happen \\nbecause an update is applied to some of the files but not to others. Even if an \\nupdate—such as adding a new student—is applied to all the appropriate files, the \\ndata concerning the student may still be inconsistent because the updates are applied \\nindependently by each user group. For example, one user group may enter a stu-\\ndent’s birth date erroneously as ‘JAN-19-1988’, whereas the other user groups may \\nenter the correct value of ‘JAN-29-1988’.\\nIn the database approach, the views of different user groups are integrated during \\ndatabase design. Ideally, we should have a database design that stores each logical \\ndata item—such as a student’s name or birth date—in only one place  in the data-\\nbase. This is known as data normalization , and it ensures consistency and saves \\nstorage space (data normalization is described in Part 6 of the text).\\nHowever, in practice, it is sometimes necessary to use controlled redundancy  to \\nimprove the performance of queries. For example, we may store \\nStudent_name and \\nCourse_number  redundantly in a GRADE_REPORT  file (Figure 1.6(a)) because  \\nwhenever we retrieve a GRADE_REPORT record, we want to retrieve the student \\nname and course number along with the grade, student number, and section identi-\\nfier. By placing all the data together, we do not have to search multiple files to col-\\nlect this data. This is known as denormalization. In such cases, the DBMS should \\nStudent_number Student_name Section_identifier Course_number Grade\\n17 Smith 112 MATH2410 B\\n17 Smith 119 CS1310 C\\n8 Brown 85 MATH2410 A\\n8 Brown 92 CS1310 A\\n8 Brown 102 CS3320 B\\n8 Brown 135 CS3380 A\\nGRADE_REPORT\\nStudent_number Student_name Section_identifier Course_number Grade\\n17 Brown 112 MATH2410 B\\nGRADE_REPORT\\n(a)\\n(b)\\nFigure 1.6 \\nRedundant storage \\nof Student_name \\nand Course_name in  \\nGRADE_REPORT. \\n(a) Consistent data. \\n(b) Inconsistent \\nrecord.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 32, 'page_label': '33'}, page_content='1.6 Advantages of Using the DBMS Approach  19\\nhave the capability to control this redundancy in order to prohibit inconsisten-\\ncies among the files. This may be done by automatically checking that the \\n \\nStudent_name–Student_number  values in any GRADE_REPORT  record in Fig- \\nure 1.6(a) match one of the Name–Student_number values of a STUDENT record (Fig- \\nure 1.2). Similarly, the Section_identifier–Course_number  values in GRADE_REPORT \\ncan be checked against SECTION records. Such checks can be specified to the DBMS \\nduring database design and automatically enforced by the DBMS whenever the \\nGRADE_REPORT file is updated. Figure 1.6(b) shows a GRADE_REPORT record that \\nis inconsistent with the STUDENT file in Figure 1.2; this kind of error may be entered \\nif the redundancy is not controlled. Can you tell which part is inconsistent?\\n1.6.2 Restricting Unauthorized Access\\nWhen multiple users share a large database, it is likely that most users will not be \\nauthorized to access all information in the database. For example, financial data \\nsuch as salaries and bonuses is often considered confidential, and only autho-\\nrized persons are allowed to access such data. In addition, some users may only \\nbe permitted to retrieve data, whereas others are allowed to retrieve and update. \\nHence, the type of access operation—retrieval or update—must also be con-\\ntrolled. Typically, users or user groups are given account numbers protected by \\npasswords, which they can use to gain access to the database. A DBMS should \\nprovide a security and authorization subsystem , which the DBA uses to create \\naccounts and to specify account restrictions. Then, the DBMS should enforce \\nthese restrictions automatically. Notice that we can apply similar controls to the \\nDBMS software. For example, only the DBA’s staff may be allowed to use certain \\nprivileged software , such as the software for creating new accounts. Similarly, \\nparametric users may be allowed to access the database only through the pre-\\ndefined apps or canned transactions developed for their use. We discuss data-\\nbase security and authorization in Chapter 30.\\n1.6.3 Providing Persistent Storage for Program Objects\\nDatabases can be used to provide persistent storage for program objects and data \\nstructures. This is one of the main reasons for object-oriented database systems  \\n(see Chapter 12). Programming languages typically have complex data structures, \\nsuch as structs or class definitions in C++ or Java. The values of program variables \\nor objects are discarded once a program terminates, unless the programmer explic-\\nitly stores them in permanent files, which often involves converting these complex \\nstructures into a format suitable for file storage. When the need arises to read this \\ndata once more, the programmer must convert from the file format to the program \\nvariable or object structure. Object-oriented database systems are compatible with \\nprogramming languages such as C++ and Java, and the DBMS software auto-\\nmatically performs any necessary conversions. Hence, a complex object in C++ \\ncan be stored permanently in an object-oriented DBMS. Such an object is said to \\nbe persistent , since it survives the termination of program execution and can \\nlater be directly retrieved by another program.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 33, 'page_label': '34'}, page_content='20 Chapter 1 Databases and Database Users\\nThe persistent storage of program objects and data structures is an important func-\\ntion of database systems. Traditional database systems often suffered from the so-\\ncalled impedance mismatch problem , since the data structures provided by the \\nDBMS were incompatible with the programming language’s data structures. \\nObject-oriented database systems typically offer data structure compatibility with \\none or more object-oriented programming languages.\\n1.6.4  Providing Storage Structures and Search  \\nTechniques for Efficient Query Processing\\nDatabase systems must provide capabilities for efficiently executing queries and \\nupdates. Because the database is typically stored on disk, the DBMS must provide \\nspecialized data structures and search techniques to speed up disk search for the \\ndesired records. Auxiliary files called indexes are often used for this purpose. \\nIndexes are typically based on tree data structures or hash data structures that are \\nsuitably modified for disk search. In order to process the database records needed \\nby a particular query, those records must be copied from disk to main memory. \\nTherefore, the DBMS often has a buffering or caching module that maintains parts \\nof the database in main memory buffers. In general, the operating system is respon-\\nsible for disk-to-memory buffering. However, because data buffering is crucial to \\nthe DBMS performance, most DBMSs do their own data buffering.\\nThe query processing and optimization  module of the DBMS is responsible for \\nchoosing an efficient query execution plan for each query based on the existing \\nstorage structures. The choice of which indexes to create and maintain is part of \\nphysical database design and tuning, which is one of the responsibilities of the DBA \\nstaff. We discuss query processing and optimization in Part 8 of the text.\\n1.6.5 Providing Backup and Recovery\\nA DBMS must provide facilities for recovering from hardware or software failures. \\nThe backup and recovery subsystem of the DBMS is responsible for recovery. For \\nexample, if the computer system fails in the middle of a complex update transac-\\ntion, the recovery subsystem is responsible for making sure that the database is \\nrestored to the state it was in before the transaction started executing. Disk backup \\nis also necessary in case of a catastrophic disk failure. We discuss recovery and \\nbackup in Chapter 22.\\n1.6.6 Providing Multiple User Interfaces\\nBecause many types of users with varying levels of technical knowledge use a data-\\nbase, a DBMS should provide a variety of user interfaces. These include apps for \\nmobile users, query languages for casual users, programming language interfaces \\nfor application programmers, forms and command codes for parametric users, \\nand menu-driven interfaces and natural language interfaces for standalone users. \\nBoth forms-style interfaces and menu-driven interfaces are commonly known as'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 34, 'page_label': '35'}, page_content='1.6 Advantages of Using the DBMS Approach  21\\ngraphical user interfaces (GUIs) . Many specialized languages and environments \\nexist for specifying GUIs. Capabilities for providing Web GUI interfaces to a \\ndatabase—or Web-enabling a database—are also quite common.\\n1.6.7 Representing Complex Relationships among Data\\nA database may include numerous varieties of data that are interrelated in many \\nways. Consider the example shown in Figure 1.2. The record for ‘Brown’ in the \\nSTUDENT file is related to four records in the GRADE_REPORT file. Similarly, \\neach section record is related to one course record and to a number of  \\nGRADE_REPORT records—one for each student who completed that section. A \\nDBMS must have the capability to represent a variety of complex relationships \\namong the data, to define new relationships as they arise, and to retrieve and \\nupdate related data easily and efficiently.\\n1.6.8 Enforcing Integrity Constraints\\nMost database applications have certain integrity constraints  that must hold for \\nthe data. A DBMS should provide capabilities for defining and enforcing these \\nconstraints. The simplest type of integrity constraint involves specifying a data \\ntype for each data item. For example, in Figure 1.3, we specified that the value of \\nthe Class data item within each STUDENT record must be a one-digit integer and \\nthat the value of Name must be a string of no more than 30 alphabetic characters. \\nTo restrict the value of Class between 1 and 5 would be an additional constraint \\nthat is not shown in the current catalog. A more complex type of constraint that \\nfrequently occurs involves specifying that a record in one file must be related to \\nrecords in other files. For example, in Figure 1.2, we can specify that every section \\nrecord must be related to a course record . This is known as a referential integrity  \\nconstraint. Another type of constraint specifies uniqueness on data item values, \\nsuch as every course record must have a unique value for \\nCourse_number. This is \\nknown as a key or uniqueness constraint. These constraints are derived from the \\nmeaning or semantics  of the data and of the miniworld it represents. It is the \\nresponsibility of the database designers to identify integrity constraints during \\ndatabase design. Some constraints can be specified to the DBMS and automatically \\nenforced. Other constraints may have to be checked by update programs or at the \\ntime of data entry. For typical large applications, it is customary to call such con-\\nstraints business rules.\\nA data item may be entered erroneously and still satisfy the specified integrity con-\\nstraints. For example, if a student receives a grade of ‘A’ but a grade of ‘C’ is entered \\nin the database, the DBMS cannot discover this error automatically because ‘C’ is a \\nvalid value for the \\nGrade data type. Such data entry errors can only be discovered \\nmanually (when the student receives the grade and complains) and corrected later \\nby updating the database. However, a grade of ‘Z’ would be rejected automatically \\nby the DBMS because ‘Z’ is not a valid value for the Grade data type. When we dis-\\ncuss each data model in subsequent chapters, we will introduce rules that pertain to'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 35, 'page_label': '36'}, page_content='22 Chapter 1 Databases and Database Users\\nthat model implicitly. For example, in the Entity-Relationship model in Chapter 3, \\na relationship must involve at least two entities. Rules that pertain to a specific data \\nmodel are called inherent rules of the data model.\\n1.6.9  Permitting Inferencing and Actions  \\nUsing Rules and Triggers\\nSome database systems provide capabilities for defining deduction rules for infer-\\nencing new information from the stored database facts. Such systems are called \\ndeductive database systems. For example, there may be complex rules in the mini-\\nworld application for determining when a student is on probation. These can be \\nspecified declaratively as rules, which when compiled and maintained by the DBMS \\ncan determine all students on probation. In a traditional DBMS, an explicit proce-\\ndural program code  would have to be written to support such applications. But if \\nthe miniworld rules change, it is generally more convenient to change the declared \\ndeduction rules than to recode procedural programs. In today’s relational database \\nsystems, it is possible to associate triggers with tables. A trigger is a form of a rule \\nactivated by updates to the table, which results in performing some additional oper-\\nations to some other tables, sending messages, and so on. More involved proce-\\ndures to enforce rules are popularly called stored procedures; they become a part of \\nthe overall database definition and are invoked appropriately when certain condi-\\ntions are met. More powerful functionality is provided by active database systems, \\nwhich provide active rules that can automatically initiate actions when certain \\nevents and conditions occur (see Chapter 26 for introductions to active databases in \\nSection 26.1 and deductive databases in Section 26.5).\\n1.6.10  Additional Implications of Using  \\nthe Database Approach\\nThis section discusses a few additional implications of using the database approach \\nthat can benefit most organizations.\\nPotential for Enforcing Standards. The database approach permits the DBA to \\ndefine and enforce standards among database users in a large organization. This facil-\\nitates communication and cooperation among various departments, projects, and \\nusers within the organization. Standards can be defined for names and formats of \\ndata elements, display formats, report structures, terminology, and so on. The DBA \\ncan enforce standards in a centralized database environment more easily than in an \\nenvironment where each user group has control of its own data files and software.\\nReduced Application Development Time. A prime selling feature of the data-\\nbase approach is that developing a new application—such as the retrieval of certain \\ndata from the database for printing a new report—takes very little time. Designing \\nand implementing a large multiuser database from scratch may take more time \\nthan writing a single specialized file application. However, once a database is up \\nand running, substantially less time is generally required to create new applications'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 36, 'page_label': '37'}, page_content='1.7 A Brief History of Database Applications  23\\nusing DBMS facilities. Development time using a DBMS is estimated to be one-\\nsixth to one-fourth of that for a file system.\\nFlexibility. It may be necessary to change the structure of a database as require-\\nments change. For example, a new user group may emerge that needs information \\nnot currently in the database. In response, it may be necessary to add a file to the \\ndatabase or to extend the data elements in an existing file. Modern DBMSs allow \\ncertain types of evolutionary changes to the structure of the database without affect-\\ning the stored data and the existing application programs.\\nAvailability of Up-to-Date Information. A DBMS makes the database available \\nto all users. As soon as one user’s update is applied to the database, all other users \\ncan immediately see this update. This availability of up-to-date information is \\nessential for many transaction-processing applications, such as reservation systems \\nor banking databases, and it is made possible by the concurrency control and recov-\\nery subsystems of a DBMS.\\nEconomies of Scale. The DBMS approach permits consolidation of data and \\napplications, thus reducing the amount of wasteful overlap between activities of \\ndata-processing personnel in different projects or departments as well as redundan-\\ncies among applications. This enables the whole organization to invest in more \\npowerful processors, storage devices, or networking gear, rather than having each \\ndepartment purchase its own (lower performance) equipment. This reduces overall \\ncosts of operation and management.\\n1.7 A Brief History of Database Applications\\nWe now give a brief historical overview of the applications that use DBMSs and \\nhow these applications provided the impetus for new types of database systems.\\n1.7.1  Early Database Applications Using Hierarchical  \\nand Network Systems\\nMany early database applications maintained records in large organizations such as \\ncorporations, universities, hospitals, and banks. In many of these applications, \\nthere were large numbers of records of similar structure. For example, in a univer-\\nsity application, similar information would be kept for each student, each course, \\neach grade record, and so on. There were also many types of records and many \\ninterrelationships among them.\\nOne of the main problems with early database systems was the intermixing of con-\\nceptual relationships with the physical storage and placement of records on disk. \\nHence, these systems did not provide sufficient data abstraction and program-data \\nindependence capabilities. For example, the grade records of a particular student \\ncould be physically stored next to the student record. Although this provided very'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 37, 'page_label': '38'}, page_content='24 Chapter 1 Databases and Database Users\\nefficient access for the original queries and transactions that the database was \\ndesigned to handle, it did not provide enough flexibility to access records efficiently \\nwhen new queries and transactions were identified. In particular, new queries that \\nrequired a different storage organization for efficient processing were quite difficult \\nto implement efficiently. It was also laborious to reorganize the database when \\nchanges were made to the application’s requirements.\\nAnother shortcoming of early systems was that they provided only programming \\nlanguage interfaces. This made it time-consuming and expensive to implement \\nnew queries and transactions, since new programs had to be written, tested, and \\ndebugged. Most of these database systems were implemented on large and \\nexpensive mainframe computers starting in the mid-1960s and continuing \\nthrough the 1970s and 1980s. The main types of early systems were based on \\nthree main paradigms: hierarchical systems, network model–based systems, and \\ninverted file systems.\\n1.7.2  Providing Data Abstraction and Application Flexibility  \\nwith Relational Databases\\nRelational databases were originally proposed to separate the physical storage of \\ndata from its conceptual representation and to provide a mathematical foundation \\nfor data representation and querying. The relational data model also introduced \\nhigh-level query languages that provided an alternative to programming language \\ninterfaces, making it much faster to write new queries. Relational representation of \\ndata somewhat resembles the example we presented in Figure 1.2. Relational sys-\\ntems were initially targeted to the same applications as earlier systems, and pro-\\nvided flexibility to develop new queries quickly and to reorganize the database as \\nrequirements changed. Hence, data abstraction  and program-data independence  \\nwere much improved when compared to earlier systems.\\nEarly experimental relational systems developed in the late 1970s and the com-\\nmercial relational database management systems (RDBMS) introduced in the \\nearly 1980s were quite slow, since they did not use physical storage pointers or \\nrecord placement to access related data records. With the development of new \\nstorage and indexing techniques and better query processing and optimization, \\ntheir performance improved. Eventually, relational databases became the domi-\\nnant type of database system for traditional database applications. Relational data-\\nbases now exist on almost all types of computers, from small personal computers \\nto large servers.\\n1.7.3  Object-Oriented Applications and the Need  \\nfor More Complex Databases\\nThe emergence of object-oriented programming languages in the 1980s and the \\nneed to store and share complex, structured objects led to the development of \\nobject-oriented databases (OODBs). Initially, OODBs were considered a competitor'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 38, 'page_label': '39'}, page_content='1.7 A Brief History of Database Applications  25\\nto relational databases, since they provided more general data structures. They also \\nincorporated many of the useful object-oriented paradigms, such as abstract data \\ntypes, encapsulation of operations, inheritance, and object identity. However, the \\ncomplexity of the model and the lack of an early standard contributed to their lim-\\nited use. They are now mainly used in specialized applications, such as engineering \\ndesign, multimedia publishing, and manufacturing systems. Despite expectations \\nthat they will make a big impact, their overall penetration into the database prod-\\nucts market remains low. In addition, many object-oriented concepts were incor-\\nporated into the newer versions of relational DBMSs, leading to object-relational \\ndatabase management systems, known as ORDBMSs.\\n1.7.4  Interchanging Data on the Web  \\nfor E-Commerce Using XML\\nThe World Wide Web provides a large network of interconnected computers. \\nUsers can create static Web pages using a Web publishing language, such as Hyper-\\nText Markup Language (HTML), and store these documents on Web servers where \\nother users (clients) can access them and view them through Web browsers. Docu-\\nments can be linked through hyperlinks, which are pointers to other documents. \\nStarting in the 1990s, electronic commerce (e-commerce) emerged as a major \\napplication on the Web. Much of the critical information on e-commerce Web \\npages is dynamically extracted data from DBMSs, such as flight information, prod-\\nuct prices, and product availability. A variety of techniques were developed to allow \\nthe interchange of dynamically extracted data on the Web for display on Web \\npages. The eXtended Markup Language (XML) is one standard for interchanging \\ndata among various types of databases and Web pages. XML combines concepts \\nfrom the models used in document systems with database modeling concepts. \\nChapter 13 is devoted to an overview of XML.\\n1.7.5  Extending Database Capabilities  \\nfor New Applications\\nThe success of database systems in traditional applications encouraged devel-\\nopers of other types of applications to attempt to use them. Such applications \\ntraditionally used their own specialized software and file and data structures. \\nDatabase systems now offer extensions to better support the specialized require-\\nments for some of these applications. The following are some examples of these \\napplications:\\n■ Scientific applications that store large amounts of data resulting from scien-\\ntific experiments in areas such as high-energy physics, the mapping of the \\nhuman genome, and the discovery of protein structures\\n■ Storage and retrieval of images, including scanned news or personal photo-\\ngraphs, satellite photographic images, and images from medical procedures \\nsuch as x-rays and MRI (magnetic resonance imaging) tests'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 39, 'page_label': '40'}, page_content='26 Chapter 1 Databases and Database Users\\n■ Storage and retrieval of videos, such as movies, and video clips from news \\nor personal digital cameras\\n■ Data mining applications that analyze large amounts of data to search for \\nthe occurrences of specific patterns or relationships, and for identifying \\nunusual patterns in areas such as credit card fraud detection\\n■ Spatial applications that store and analyze spatial locations of data, such as \\nweather information, maps used in geographical information systems, and \\nautomobile navigational systems\\n■ Time series  applications that store information such as economic data at \\nregular points in time, such as daily sales and monthly gross national \\nproduct figures\\nIt was quickly apparent that basic relational systems were not very suitable for many \\nof these applications, usually for one or more of the following reasons:\\n■ More complex data structures were needed for modeling the application \\nthan the simple relational representation.\\n■ New data types were needed in addition to the basic numeric and character \\nstring types.\\n■ New operations and query language constructs were necessary to manipu-\\nlate the new data types.\\n■ New storage and indexing structures were needed for efficient searching on \\nthe new data types.\\nThis led DBMS developers to add functionality to their systems. Some functionality \\nwas general purpose, such as incorporating concepts from object-oriented data-\\nbases into relational systems. Other functionality was special purpose, in the form \\nof optional modules that could be used for specific applications. For example, users \\ncould buy a time series module to use with their relational DBMS for their time \\nseries application.\\n1.7.6  Emergence of Big Data Storage Systems  \\nand NOSQL Databases\\nIn the first decade of the twenty-first century, the proliferation of applications and \\nplatforms such as social media Web sites, large e-commerce companies, Web search \\nindexes, and cloud storage/backup led to a surge in the amount of data stored on \\nlarge databases and massive servers. New types of database systems were necessary \\nto manage these huge databases—systems that would provide fast search and \\nretrieval as well as reliable and safe storage of nontraditional types of data, such as \\nsocial media posts and tweets. Some of the requirements of these new systems were \\nnot compatible with SQL relational DBMSs (SQL is the standard data model and \\nlanguage for relational databases). The term NOSQL is generally interpreted as Not \\nOnly SQL, meaning that in systems than manage large amounts of data, some of the \\ndata is stored using SQL systems, whereas other data would be stored using NOSQL, \\ndepending on the application requirements.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 40, 'page_label': '41'}, page_content='1.9 Summary  27\\n1.8 When Not to Use a DBMS\\nIn spite of the advantages of using a DBMS, there are a few situations in which a \\nDBMS may involve unnecessary overhead costs that would not be incurred in \\ntraditional file processing. The overhead costs of using a DBMS are due to the \\nfollowing:\\n■ High initial investment in hardware, software, and training\\n■ The generality that a DBMS provides for defining and processing data\\n■ Overhead for providing security, concurrency control, recovery, and integ-\\nrity functions\\nTherefore, it may be more desirable to develop customized database applications \\nunder the following circumstances:\\n■ Simple, well-defined database applications that are not expected to change \\nat all\\n■ Stringent, real-time requirements for some application programs that may \\nnot be met because of DBMS overhead\\n■ Embedded systems with limited storage capacity, where a general-purpose \\nDBMS would not fit\\n■ No multiple-user access to data\\nCertain industries and applications have elected not to use general-purpose \\nDBMSs. For example, many computer-aided design (CAD) tools used by mechan-\\nical and civil engineers have proprietary file and data management software that \\nis geared for the internal manipulations of drawings and 3D objects. Similarly, \\ncommunication and switching systems designed by companies like AT&T were \\nearly manifestations of database software that was made to run very fast with \\nhierarchically organized data for quick access and routing of calls. GIS imple-\\nmentations often implement their own data organization schemes for efficiently \\nimplementing functions related to processing maps, physical contours, lines, \\npolygons, and so on.\\n1.9 Summary\\nIn this chapter we defined a database as a collection of related data, where data \\nmeans recorded facts. A typical database represents some aspect of the real world \\nand is used for specific purposes by one or more groups of users. A DBMS is a \\ngeneralized software package for implementing and maintaining a computerized \\ndatabase. The database and software together form a database system. We identi-\\nfied several characteristics that distinguish the database approach from traditional \\nfile-processing applications, and we discussed the main categories of database \\nusers, or the actors on the scene. We noted that in addition to database users, there \\nare several categories of support personnel, or workers behind the scene , in a data-\\nbase environment.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 41, 'page_label': '42'}, page_content='28 Chapter 1 Databases and Database Users\\nWe presented a list of capabilities that should be provided by the DBMS software to \\nthe DBA, database designers, and end users to help them design, administer, and \\nuse a database. Then we gave a brief historical perspective on the evolution of data-\\nbase applications. We pointed out the recent rapid growth of the amounts and types \\nof data that must be stored in databases, and we discussed the emergence of new \\nsystems for handling “big data” applications. Finally, we discussed the overhead \\ncosts of using a DBMS and discussed some situations in which it may not be advan-\\ntageous to use one.\\nReview Questions\\n 1.1. Define the following terms: data, database, DBMS, database system , data-\\nbase catalog, program-data independence, user view, DBA, end user, canned \\ntransaction , deductive database system , persistent object , meta-data , and \\ntransaction-processing application.\\n 1.2. What four main types of actions involve databases? Briefly discuss each.\\n 1.3. Discuss the main characteristics of the database approach and how it differs \\nfrom traditional file systems.\\n 1.4. What are the responsibilities of the DBA and the database designers?\\n 1.5. What are the different types of database end users? Discuss the main activi-\\nties of each.\\n 1.6. Discuss the capabilities that should be provided by a DBMS.\\n 1.7. Discuss the differences between database systems and information retrieval \\nsystems.\\nExercises\\n 1.8. Identify some informal queries and update operations that you would expect \\nto apply to the database shown in Figure 1.2.\\n 1.9. What is the difference between controlled and uncontrolled redundancy? \\nIllustrate with examples.\\n 1.10. Specify all the relationships among the records of the database shown in \\nFigure 1.2.\\n 1.11. Give some additional views that may be needed by other user groups for the \\ndatabase shown in Figure 1.2.\\n 1.12. Cite some examples of integrity constraints that you think can apply to the \\ndatabase shown in Figure 1.2.\\n 1.13. Give examples of systems in which it may make sense to use traditional file \\nprocessing instead of a database approach.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 42, 'page_label': '43'}, page_content='Selected Bibliography 29\\n 1.14. Consider Figure 1.2.\\n a. If the name of the ‘CS’ (Computer Science) Department changes to ‘CSSE’ \\n(Computer Science and Software Engineering) Department and the cor-\\nresponding prefix for the course number also changes, identify the col-\\numns in the database that would need to be updated.\\n \\nb. Can you restructure the columns in the COURSE , SECTION , and  \\nPREREQUISITE tables so that only one column will need to be updated?\\nSelected Bibliography\\nThe October 1991 issue of Communications of the ACM  and Kim (1995) include \\nseveral articles describing next-generation DBMSs; many of the database features \\ndiscussed in the former are now commercially available. The March 1976 issue of \\nACM Computing Surveys offers an early introduction to database systems and may \\nprovide a historical perspective for the interested reader. We will include references \\nto other concepts, systems, and applications introduced in this chapter in the later \\ntext chapters that discuss each topic in more detail.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 43, 'page_label': '44'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 44, 'page_label': '45'}, page_content='31\\n2chapter 2\\nDatabase System Concepts  \\nand Architecture\\nT\\nhe architecture of DBMS packages has evolved \\nfrom the early monolithic systems, where the whole \\nDBMS software package was one tightly integrated system, to the modern DBMS \\npackages that are modular in design, with a client/server system architecture. The \\nrecent growth in the amount of data requiring storage has led to database systems \\nwith distributed architectures comprised of thousands of computers that manage \\nthe data stores. This evolution mirrors the trends in computing, where large cen-\\ntralized mainframe computers are replaced by hundreds of distributed worksta-\\ntions and personal computers connected via communications networks to various \\ntypes of server machines—Web servers, database servers, file servers, application \\nservers, and so on. The current cloud computing  environments consist of thou-\\nsands of large servers managing so-called big data for users on the Web.\\nIn a basic client/server DBMS architecture, the system functionality is distributed \\nbetween two types of modules.\\n1 A client module  is typically designed so that it \\nwill run on a mobile device, user workstation, or personal computer (PC). Typi-\\ncally, application programs and user interfaces that access the database run in the \\nclient module. Hence, the client module handles user interaction and provides \\nthe user-friendly interfaces such as apps for mobile devices, or forms- or menu-\\nbased GUIs (graphical user interfaces) for PCs. The other kind of module, called \\na server module , typically handles data storage, access, search, and other func-\\ntions. We discuss client/server architectures in more detail in Section 2.5. First, \\nwe must study more basic concepts that will give us a better understanding of \\nmodern database architectures.\\n1As we shall see in Section 2.5, there are variations on this simple two-tier client/server architecture.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 45, 'page_label': '46'}, page_content='32 Chapter 2 Database System Concepts and Architecture\\nIn this chapter we present the terminology and basic concepts that will be used \\nthroughout the text. Section 2.1 discusses data models and defines the concepts \\nof schemas and instances, which are fundamental to the study of database sys-\\ntems. We discuss the three-schema DBMS architecture and data independence \\nin Section 2.2; this provides a user’s perspective on what a DBMS is supposed to \\ndo. In Section 2.3 we describe the types of interfaces and languages that are typi-\\ncally provided by a DBMS. Section 2.4 discusses the database system software \\nenvironment. Section 2.5 gives an overview of various types of client/server \\narchitectures. Finally, Section 2.6 presents a classification of the types of DBMS \\npackages. Section 2.7 summarizes the chapter.\\nThe material in Sections 2.4 through 2.6 provides detailed concepts that may be \\nconsidered as supplementary to the basic introductory material.\\n2.1 Data Models, Schemas, and Instances\\nOne fundamental characteristic of the database approach is that it provides some \\nlevel of data abstraction. Data abstraction  generally refers to the suppression of \\ndetails of data organization and storage, and the highlighting of the essential fea-\\ntures for an improved understanding of data. One of the main characteristics of the \\ndatabase approach is to support data abstraction so that different users can perceive \\ndata at their preferred level of detail. A data model—a collection of concepts that \\ncan be used to describe the structure of a database—provides the necessary means \\nto achieve this abstraction.\\n2 By structure of a database we mean the data types, rela-\\ntionships, and constraints that apply to the data. Most data models also include a \\nset of basic operations for specifying retrievals and updates on the database.\\nIn addition to the basic operations provided by the data model, it is becoming more \\ncommon to include concepts in the data model to specify the dynamic aspect or \\nbehavior of a database application. This allows the database designer to specify a set \\nof valid user-defined operations that are allowed on the database objects.\\n3 An \\nexample of a user-defined operation could be COMPUTE_GPA , which can be  \\napplied to a STUDENT object. On the other hand, generic operations to insert, \\ndelete, modify, or retrieve any kind of object are often included in the basic data \\nmodel operations. Concepts to specify behavior are fundamental to object-oriented \\ndata models (see Chapter 12) but are also being incorporated in more traditional \\ndata models. For example, object-relational models (see Chapter 12) extend the basic \\nrelational model to include such concepts, among others. In the basic relational data \\nmodel, there is a provision to attach behavior to the relations in the form of persis-\\ntent stored modules, popularly known as stored procedures (see Chapter 10).\\n2Sometimes the word model is used to denote a specific database description, or schema—for example, \\nthe marketing data model. We will not use this interpretation.\\n3The inclusion of concepts to describe behavior reflects a trend whereby database design and software \\ndesign activities are increasingly being combined into a single activity. Traditionally, specifying behavior is \\nassociated with software design.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 46, 'page_label': '47'}, page_content='2.1 Data Models, Schemas, and Instances  33\\n2.1.1 Categories of Data Models\\nMany data models have been proposed, which we can categorize according to  \\nthe types of concepts they use to describe the database structure. High-level or \\n conceptual data models provide concepts that are close to the way many users per-\\nceive data, whereas low-level or physical data models provide concepts that describe \\nthe details of how data is stored on the computer storage media, typically magnetic \\ndisks. Concepts provided by physical data models are generally meant for computer \\nspecialists, not for end users. Between these two extremes is a class of representational \\n(or implementation ) data models ,\\n4 which provide concepts that may be easily \\nunderstood by end users but that are not too far removed from the way data is orga-\\nnized in computer storage. Representational data models hide many details of data \\nstorage on disk but can be implemented on a computer system directly.\\nConceptual data models use concepts such as entities, attributes, and relationships. \\nAn entity represents a real-world object or concept, such as an employee or a project \\nfrom the miniworld that is described in the database. An attribute represents some \\nproperty of interest that further describes an entity, such as the employee’s name or \\nsalary. A relationship among two or more entities represents an association among \\nthe entities, for example, a works-on relationship between an employee and a \\nproject. Chapter 3 presents the entity–relationship model —a popular high-level \\nconceptual data model. Chapter 4 describes additional abstractions used for advanced \\nmodeling, such as generalization, specialization, and categories (union types).\\nRepresentational or implementation data models are the models used most fre-\\nquently in traditional commercial DBMSs. These include the widely used relational \\ndata model , as well as the so-called legacy data models—the network  and \\n hierarchical models—that have been widely used in the past. Part 3 of the text is \\ndevoted to the relational data model, and its constraints, operations, and languages.\\n5 \\nThe SQL standard for relational databases is described in Chapters 6 and 7. Repre-\\nsentational data models represent data by using record structures and hence are \\nsometimes called record-based data models.\\nWe can regard the object data model as an example of a new family of higher-level \\nimplementation data models that are closer to conceptual data models. A standard \\nfor object databases called the ODMG object model has been proposed by the \\nObject Data Management Group (ODMG). We describe the general characteristics \\nof object databases and the object model proposed standard in Chapter 12. Object \\ndata models are also frequently utilized as high-level conceptual models, particu-\\nlarly in the software engineering domain.\\nPhysical data models describe how data is stored as files in the computer by repre-\\nsenting information such as record formats, record orderings, and access paths. An \\n4The term implementation data model is not a standard term; we have introduced it to refer to the avail-\\nable data models in commercial database systems.\\n5A summary of the hierarchical and network data models is included in Appendices D and E. They are \\naccessible from the book’s Web site.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 47, 'page_label': '48'}, page_content='34 Chapter 2 Database System Concepts and Architecture\\naccess path  is a search structure that makes the search for particular database \\nrecords efficient, such as indexing or hashing. We discuss physical storage tech-\\nniques and access structures in Chapters 16 and 17. An index is an example of an \\naccess path that allows direct access to data using an index term or a keyword. It is \\nsimilar to the index at the end of this text, except that it may be organized in a lin-\\near, hierarchical (tree-structured), or some other fashion.\\nAnother class of data models is known as self-describing data models . The data \\nstorage in systems based on these models combines the description of the data with \\nthe data values themselves. In traditional DBMSs, the description (schema) is sepa-\\nrated from the data. These models include XML (see Chapter 12) as well as many of \\nthe key-value stores and NOSQL systems (see Chapter 24) that were recently cre-\\nated for managing big data.\\n2.1.2 Schemas, Instances, and Database State\\nIn a data model, it is important to distinguish between the description  of the \\ndatabase and the database itself . The description of a database is called the \\n database schema , which is specified during database design and is not expected \\nto change frequently. 6 Most data models have certain conventions for displaying \\nschemas as diagrams. 7 A displayed schema is called a schema diagram . Figure 2.1 \\nshows a schema diagram for the database shown in Figure 1.2; the diagram dis-\\nplays the structure of each record type but not the actual instances of records. \\n6Schema changes are usually needed as the requirements of the database applications change. Most \\ndatabase systems include operations for allowing schema changes.\\n7It is customary in database parlance to use schemas as the plural for schema, even though schemata is \\nthe proper plural form. The word scheme is also sometimes used to refer to a schema.\\nSection_identifier SemesterCourse_number Instructor Year\\nSECTION\\nCourse_name Course_number Credit_hours Department\\nCOURSE\\nName Student_number Class Major\\nSTUDENT\\nCourse_number Prerequisite_number\\nPREREQUISITE\\nStudent_number GradeSection_identifier\\nGRADE_REPORT\\nFigure 2.1 \\nSchema diagram for \\nthe database in  \\nFigure 1.2.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 48, 'page_label': '49'}, page_content='2.1 Data Models, Schemas, and Instances  35\\nWe call each object in the schema—such as STUDENT or COURSE—a schema \\nconstruct .\\nA schema diagram displays only some aspects  of a schema, such as the names of \\nrecord types and data items, and some types of constraints. Other aspects are not \\nspecified in the schema diagram; for example, Figure 2.1 shows neither the data \\ntype of each data item nor the relationships among the various files. Many types of \\nconstraints are not represented in schema diagrams. A constraint such as students \\nmajoring in computer science must take CS1310 before the end of their sophomore \\nyear is quite difficult to represent diagrammatically.\\nThe actual data in a database may change quite frequently. For example, the data-\\nbase shown in Figure 1.2 changes every time we add a new student or enter a new \\ngrade. The data in the database at a particular moment in time is called a database \\nstate or snapshot. It is also called the current set of occurrences or instances in \\nthe database. In a given database state, each schema construct has its own current \\nset of instances; for example, the \\nSTUDENT construct will contain the set of indi-\\nvidual student entities (records) as its instances. Many database states can be con-\\nstructed to correspond to a particular database schema. Every time we insert or \\ndelete a record or change the value of a data item in a record, we change one state \\nof the database into another state.\\nThe distinction between database schema and database state is very important. \\nWhen we define  a new database, we specify its database schema only to the \\nDBMS. At this point, the corresponding database state is the empty state  with \\nno data. We get the initial state  of the database when the database is first \\n populated  or loaded  with the initial data. From then on, every time an update \\noperation is applied to the database, we get another database state. At any point \\nin time, the database has a current state .\\n8 The DBMS is partly responsible for \\nensuring that every state of the database is a valid state —that is, a state that \\nsatisfies the structure and constraints specified in the schema. Hence, specify-\\ning a correct schema to the DBMS is extremely important and the schema must \\nbe designed with utmost care. The DBMS stores the descriptions of the schema \\nconstructs and constraints—also called the meta-data —in the DBMS catalog so \\nthat DBMS software can refer to the schema whenever it needs to. The schema \\nis sometimes called the intension , and a database state is called an extension  of \\nthe schema.\\nAlthough, as mentioned earlier, the schema is not supposed to change frequently, \\nit is not uncommon that changes occasionally need to be applied to the schema as \\nthe application requirements change. For example, we may decide that another \\ndata item needs to be stored for each record in a file, such as adding the Date_of_birth \\nto the \\nSTUDENT schema in Figure 2.1. This is known as schema evolution . Most \\nmodern DBMSs include some operations for schema evolution that can be applied \\nwhile the database is operational.\\n8The current state is also called the current snapshot of the database. It has also been called a database \\ninstance, but we prefer to use the term instance to refer to individual records.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 49, 'page_label': '50'}, page_content='36 Chapter 2 Database System Concepts and Architecture\\n2.2  Three-Schema Architecture  \\nand Data Independence\\nThree of the four important characteristics of the database approach, listed in \\nSection 1.3, are (1) use of a catalog to store the database description (schema) so \\nas to make it self-describing, (2) insulation of programs and data (program-data \\nand program-operation independence), and (3) support of multiple user views. \\nIn this section we specify an architecture for database systems, called the \\n three-schema architecture ,\\n9 that was proposed to help achieve and visualize \\nthese characteristics. Then we discuss further the concept of data independence.\\n2.2.1 The Three-Schema Architecture\\nThe goal of the three-schema architecture, illustrated in Figure 2.2, is to separate \\nthe user applications from the physical database. In this architecture, schemas can \\nbe defined at the following three levels:\\n \\n1. The internal level  has an internal schema , which describes the physical \\nstorage structure of the database. The internal schema uses a physical data \\nmodel and describes the complete details of data storage and access paths for \\nthe database.\\n9This is also known as the ANSI/SPARC (American National Standards Institute/ Standards Planning \\nAnd Requirements Committee) architecture, after the committee that proposed it (Tsichritzis & Klug, 1978).\\nExternal\\nView\\nConceptual Schema\\nInternal Schema\\nStored Database\\nExternal\\nView\\nInternal Level\\nConceptual/Internal\\nMapping\\nConceptual Level\\nExternal/Conceptual\\nMapping\\nExternal Level\\nEnd Users\\n.  .  .\\nFigure 2.2 \\nThe three-schema \\narchitecture.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 50, 'page_label': '51'}, page_content='2.2 Three-Schema Architecture and Data Independence  37\\n 2. The conceptual level has a conceptual schema, which describes the structure \\nof the whole database for a community of users. The conceptual schema hides \\nthe details of physical storage structures and concentrates on describing enti-\\nties, data types, relationships, user operations, and constraints. Usually, a rep-\\nresentational data model is used to describe the conceptual schema when a \\ndatabase system is implemented. This implementation conceptual schema is \\noften based on a conceptual schema design in a high-level data model.\\n \\n3. The external or view level includes a number of external schemas or user \\nviews. Each external schema describes the part of the database that a partic-\\nular user group is interested in and hides the rest of the database from that \\nuser group. As in the previous level, each external schema is typically imple-\\nmented using a representational data model, possibly based on an external \\nschema design in a high-level conceptual data model.\\nThe three-schema architecture is a convenient tool with which the user can visual-\\nize the schema levels in a database system. Most DBMSs do not separate the three \\nlevels completely and explicitly, but they support the three-schema architecture to \\nsome extent. Some older DBMSs may include physical-level details in the concep-\\ntual schema. The three-level ANSI architecture has an important place in database \\ntechnology development because it clearly separates the users’ external level, the \\ndatabase’s conceptual level, and the internal storage level for designing a database. \\nIt is very much applicable in the design of DBMSs, even today. In most DBMSs that \\nsupport user views, external schemas are specified in the same data model that \\ndescribes the conceptual-level information (for example, a relational DBMS like \\nOracle or SQLServer uses SQL for this).\\nNotice that the three schemas are only descriptions of data; the actual data is stored \\nat the physical level only. In the three-schema architecture, each user group refers \\nto its own external schema. Hence, the DBMS must transform a request specified \\non an external schema into a request against the conceptual schema, and then into \\na request on the internal schema for processing over the stored database. If the \\nrequest is a database retrieval, the data extracted from the stored database must be \\nreformatted to match the user’s external view. The processes of transforming \\nrequests and results between levels are called mappings. These mappings may be \\ntime-consuming, so some DBMSs—especially those that are meant to support small \\ndatabases—do not support external views. Even in such systems, however, it is nec-\\nessary to transform requests between the conceptual and internal levels.\\n2.2.2 Data Independence\\nThe three-schema architecture can be used to further explain the concept of data \\nindependence, which can be defined as the capacity to change the schema at one \\nlevel of a database system without having to change the schema at the next higher \\nlevel. We can define two types of data independence:\\n 1. Logical data independence is the capacity to change the conceptual schema \\nwithout having to change external schemas or application programs. We'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 51, 'page_label': '52'}, page_content='38 Chapter 2 Database System Concepts and Architecture\\nmay change the conceptual schema to expand the database (by adding a \\nrecord type or data item), to change constraints, or to reduce the database \\n(by removing a record type or data item). In the last case, external schemas \\nthat refer only to the remaining data should not be affected. For example, \\nthe external schema of Figure 1.5(a) should not be affected by changing the \\nGRADE_REPORT  file (or record type) shown in Figure 1.2 into the one \\nshown in Figure 1.6(a). Only the view definition and the mappings need to \\nbe changed in a DBMS that supports logical data independence. After the \\nconceptual schema undergoes a logical reorganization, application pro-\\ngrams that reference the external schema constructs must work as before. \\nChanges to constraints can be applied to the conceptual schema without \\naffecting the external schemas or application programs.\\n \\n2. Physical data independence  is the capacity to change the internal schema \\nwithout having to change the conceptual schema. Hence, the external sche-\\nmas need not be changed as well. Changes to the internal schema may be \\nneeded because some physical files were reorganized—for example, by cre-\\nating additional access structures—to improve the performance of retrieval \\nor update. If the same data as before remains in the database, we should not \\nhave to change the conceptual schema. For example, providing an access \\npath to improve retrieval speed of SECTION records (Figure 1.2) by semes-\\nter and year should not require a query such as list all sections offered in fall \\n2008 to be changed, although the query would be executed more efficiently \\nby the DBMS by utilizing the new access path.\\nGenerally, physical data independence exists in most databases and file environ-\\nments where physical details, such as the exact location of data on disk, and hard-\\nware details of storage encoding, placement, compression, splitting, merging of \\nrecords, and so on are hidden from the user. Applications remain unaware of these \\ndetails. On the other hand, logical data independence is harder to achieve because it \\nallows structural and constraint changes without affecting application programs—a \\nmuch stricter requirement.\\nWhenever we have a multiple-level DBMS, its catalog must be expanded to include \\ninformation on how to map requests and data among the various levels. The DBMS \\nuses additional software to accomplish these mappings by referring to the mapping \\ninformation in the catalog. Data independence occurs because when the schema is \\nchanged at some level, the schema at the next higher level remains unchanged; only \\nthe mapping between the two levels is changed. Hence, application programs refer-\\nring to the higher-level schema need not be changed.\\n2.3 Database Languages and Interfaces\\nIn Section 1.4 we discussed the variety of users supported by a DBMS. The DBMS \\nmust provide appropriate languages and interfaces for each category of users. In \\nthis section we discuss the types of languages and interfaces provided by a DBMS \\nand the user categories targeted by each interface.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 52, 'page_label': '53'}, page_content='2.3 Database Languages and Interfaces  39\\n2.3.1 DBMS Languages\\nOnce the design of a database is completed and a DBMS is chosen to implement the \\ndatabase, the first step is to specify conceptual and internal schemas for the data-\\nbase and any mappings between the two. In many DBMSs where no strict separa-\\ntion of levels is maintained, one language, called the data definition language  \\n(DDL), is used by the DBA and by database designers to define both schemas. The \\nDBMS will have a DDL compiler whose function is to process DDL statements in \\norder to identify descriptions of the schema constructs and to store the schema \\ndescription in the DBMS catalog.\\nIn DBMSs where a clear separation is maintained between the conceptual and \\ninternal levels, the DDL is used to specify the conceptual schema only. Another \\nlanguage, the storage definition language  (SDL), is used to specify the internal \\nschema. The mappings between the two schemas may be specified in either one of \\nthese languages. In most relational DBMSs today, there is no specific language that \\nperforms the role of SDL. Instead, the internal schema is specified by a combination \\nof functions, parameters, and specifications related to storage of files. These permit \\nthe DBA staff to control indexing choices and mapping of data to storage. For a true \\nthree-schema architecture, we would need a third language, the view definition \\nlanguage  ( VDL), to specify user views and their mappings to the conceptual \\nschema, but in most DBMSs the DDL is used to define both conceptual and external \\nschemas. In relational DBMSs, SQL is used in the role of VDL to define user or \\napplication views as results of predefined queries (see Chapters 6 and 7).\\nOnce the database schemas are compiled and the database is populated with data, \\nusers must have some means to manipulate the database. Typical manipulations \\ninclude retrieval, insertion, deletion, and modification of the data. The DBMS pro-\\nvides a set of operations or a language called the data manipulation language  \\n(DML) for these purposes.\\nIn current DBMSs, the preceding types of languages are usually not considered dis-\\ntinct languages; rather, a comprehensive integrated language is used that includes \\nconstructs for conceptual schema definition, view definition, and data manipula-\\ntion. Storage definition is typically kept separate, since it is used for defining physi-\\ncal storage structures to fine-tune the performance of the database system, which is \\nusually done by the DBA staff. A typical example of a comprehensive database lan-\\nguage is the SQL relational database language (see Chapters 6 and 7), which repre-\\nsents a combination of DDL, VDL, and DML, as well as statements for constraint \\nspecification, schema evolution, and many other features. The SDL was a compo-\\nnent in early versions of SQL but has been removed from the language to keep it at \\nthe conceptual and external levels only.\\nThere are two main types of DMLs. A high-level or nonprocedural DML can be \\nused on its own to specify complex database operations concisely. Many DBMSs \\nallow high-level DML statements either to be entered interactively from a display \\nmonitor or terminal or to be embedded in a general-purpose programming lan-\\nguage. In the latter case, DML statements must be identified within the program so'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 53, 'page_label': '54'}, page_content='40 Chapter 2 Database System Concepts and Architecture\\nthat they can be extracted by a precompiler and processed by the DBMS. A low-\\nlevel or procedural DML must be embedded in a general-purpose programming \\nlanguage. This type of DML typically retrieves individual records or objects from \\nthe database and processes each separately. Therefore, it needs to use programming \\nlanguage constructs, such as looping, to retrieve and process each record from a set \\nof records. Low-level DMLs are also called record-at-a-time DMLs because of this \\nproperty. High-level DMLs, such as SQL, can specify and retrieve many records in \\na single DML statement; therefore, they are called set-at-a-time or set-oriented \\nDMLs. A query in a high-level DML often specifies which data to retrieve rather \\nthan how to retrieve it; therefore, such languages are also called declarative.\\nWhenever DML commands, whether high level or low level, are embedded in a \\ngeneral-purpose programming language, that language is called the host language \\nand the DML is called the data sublanguage .\\n10 On the other hand, a high-level \\nDML used in a standalone interactive manner is called a query language. In gen-\\neral, both retrieval and update commands of a high-level DML may be used inter-\\nactively and are hence considered part of the query language.\\n11\\nCasual end users typically use a high-level query language to specify their requests, \\nwhereas programmers use the DML in its embedded form. For naive and paramet-\\nric users, there usually are user-friendly interfaces  for interacting with the data-\\nbase; these can also be used by casual users or others who do not want to learn the \\ndetails of a high-level query language. We discuss these types of interfaces next.\\n2.3.2 DBMS Interfaces\\nUser-friendly interfaces provided by a DBMS may include the following:\\nMenu-based Interfaces for Web Clients or Browsing.  These interfaces pres-\\nent the user with lists of options (called menus) that lead the user through the for-\\nmulation of a request. Menus do away with the need to memorize the specific \\ncommands and syntax of a query language; rather, the query is composed step-by-\\nstep by picking options from a menu that is displayed by the system. Pull-down \\nmenus are a very popular technique in Web-based user interfaces . They are also \\noften used in browsing interfaces, which allow a user to look through the contents \\nof a database in an exploratory and unstructured manner.\\nApps for Mobile Devices.  These interfaces present mobile users with access to \\ntheir data. For example, banking, reservations, and insurance companies, among \\nmany others, provide apps that allow users to access their data through a mobile \\nphone or mobile device. The apps have built-in programmed interfaces that typically \\n10In object databases, the host and data sublanguages typically form one integrated language—for \\nexample, C++ with some extensions to support database functionality. Some relational systems also \\nprovide integrated languages—for example, Oracle’s PL/SQL.\\n11According to the English meaning of the word query, it should really be used to describe retrievals \\nonly, not updates.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 54, 'page_label': '55'}, page_content='2.3 Database Languages and Interfaces  41\\nallow users to login using their account name and password; the apps then provide \\na limited menu of options for mobile access to the user data, as well as options such \\nas paying bills (for banks) or making reservations (for reservation Web sites).\\nForms-based Interfaces. A forms-based interface displays a form to each user. \\nUsers can fill out all of the form entries to insert new data, or they can fill out only \\ncertain entries, in which case the DBMS will retrieve matching data for the remain-\\ning entries. Forms are usually designed and programmed for naive users as inter-\\nfaces to canned transactions. Many DBMSs have forms specification languages , \\nwhich are special languages that help programmers specify such forms. SQL*Forms \\nis a form-based language that specifies queries using a form designed in conjunc-\\ntion with the relational database schema. Oracle Forms is a component of the Ora-\\ncle product suite that provides an extensive set of features to design and build \\napplications using forms. Some systems have utilities that define a form by letting \\nthe end user interactively construct a sample form on the screen.\\nGraphical User Interfaces. A GUI typically displays a schema to the user in dia-\\ngrammatic form. The user then can specify a query by manipulating the diagram. \\nIn many cases, GUIs utilize both menus and forms.\\nNatural Language Interfaces.  These interfaces accept requests written in Eng-\\nlish or some other language and attempt to understand them. A natural language \\ninterface usually has its own schema, which is similar to the database conceptual \\nschema, as well as a dictionary of important words. The natural language interface \\nrefers to the words in its schema, as well as to the set of standard words in its dic-\\ntionary, that are used to interpret the request. If the interpretation is successful, the \\ninterface generates a high-level query corresponding to the natural language request \\nand submits it to the DBMS for processing; otherwise, a dialogue is started with the \\nuser to clarify the request.\\nKeyword-based Database Search. These are somewhat similar to Web search \\nengines, which accept strings of natural language (like English or Spanish) words \\nand match them with documents at specific sites (for local search engines) or Web \\npages on the Web at large (for engines like Google or Ask). They use predefined \\nindexes on words and use ranking functions to retrieve and present resulting docu-\\nments in a decreasing degree of match. Such “free form” textual query interfaces are \\nnot yet common in structured relational databases, although a research area called \\nkeyword-based querying has emerged recently for relational databases.\\nSpeech Input and Output.  Limited use of speech as an input query and speech \\nas an answer to a question or result of a request is becoming commonplace. Appli-\\ncations with limited vocabularies, such as inquiries for telephone directory, flight \\narrival/departure, and credit card account information, are allowing speech for \\ninput and output to enable customers to access this information. The speech input \\nis detected using a library of predefined words and used to set up the parameters \\nthat are supplied to the queries. For output, a similar conversion from text or num-\\nbers into speech takes place.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 55, 'page_label': '56'}, page_content='42 Chapter 2 Database System Concepts and Architecture\\nInterfaces for Parametric Users.  Parametric users, such as bank tellers, often \\nhave a small set of operations that they must perform repeatedly. For example, a \\nteller is able to use single function keys to invoke routine and repetitive transactions \\nsuch as account deposits or withdrawals, or balance inquiries. Systems analysts and \\nprogrammers design and implement a special interface for each known class of \\nnaive users. Usually a small set of abbreviated commands is included, with the goal \\nof minimizing the number of keystrokes required for each request.\\nInterfaces for the DBA.  Most database systems contain privileged commands \\nthat can be used only by the DBA staff. These include commands for creating \\naccounts, setting system parameters, granting account authorization, changing a \\nschema, and reorganizing the storage structures of a database.\\n2.4 The Database System Environment\\nA DBMS is a complex software system. In this section we discuss the types of soft-\\nware components that constitute a DBMS and the types of computer system soft-\\nware with which the DBMS interacts.\\n2.4.1 DBMS Component Modules\\nFigure 2.3 illustrates, in a simplified form, the typical DBMS components. The \\nfigure is divided into two parts. The top part of the figure refers to the various \\nusers of the database environment and their interfaces. The lower part shows the \\ninternal modules of the DBMS responsible for storage of data and processing of \\ntransactions.\\nThe database and the DBMS catalog are usually stored on disk. Access to the \\ndisk is controlled primarily by the operating system  (OS), which schedules disk \\nread/write. Many DBMSs have their own buffer management  module to sched-\\nule disk read/write, because management of buffer storage has a considerable \\neffect on performance. Reducing disk read/write improves performance consid-\\nerably. A higher-level stored data manager  module of the DBMS controls access \\nto DBMS information that is stored on disk, whether it is part of the database or \\nthe catalog.\\nLet us consider the top part of Figure 2.3 first. It shows interfaces for the DBA staff, \\ncasual users who work with interactive interfaces to formulate queries, application \\nprogrammers who create programs using some host programming languages, and \\nparametric users who do data entry work by supplying parameters to predefined \\ntransactions. The DBA staff works on defining the database and tuning it by mak-\\ning changes to its definition using the DDL and other privileged commands.\\nThe DDL compiler processes schema definitions, specified in the DDL, and stores \\ndescriptions of the schemas (meta-data) in the DBMS catalog. The catalog includes \\ninformation such as the names and sizes of files, names and data types of data items, \\nstorage details of each file, mapping information among schemas, and constraints.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 56, 'page_label': '57'}, page_content='2.4 The Database System Environment  43\\nIn addition, the catalog stores many other types of information that are needed by \\nthe DBMS modules, which can then look up the catalog information as needed.\\nCasual users and persons with occasional need for information from the database \\ninteract using the interactive query interface in Figure 2.3. We have not explicitly \\nshown any menu-based or form-based or mobile interactions that are typically used \\nto generate the interactive query automatically or to access canned transactions. \\nThese queries are parsed and validated for correctness of the query syntax, the \\nnames of files and data elements, and so on by a query compiler  that compiles \\nQuery\\nCompiler\\nRuntime\\nDatabase\\nProcessor\\nPrecompiler\\nSystem\\nCatalog/\\nData\\nDictionary\\nQuery\\nOptimizer\\nDML\\nCompiler\\nHost\\nLanguage\\nCompiler\\nConcurrency Control/\\nBackup/Recovery\\nSubsystems\\nStored\\nData\\nManager\\nCompiled\\nTransactions\\nStored Database\\nDBA Commands,\\nQueries, and Transactions\\nInput/Output\\nfrom DatabaseQuery and Transaction\\nExecution:\\nDDL\\nCompiler\\nDDL\\nStatements\\nPrivileged\\nCommands\\nInteractive\\nQuery\\nApplication\\nPrograms\\nDBA Staff Casual Users Application\\nProgrammers\\nParametric UsersUsers:\\nFigure 2.3 \\nComponent modules of a DBMS and their interactions.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 57, 'page_label': '58'}, page_content='44 Chapter 2 Database System Concepts and Architecture\\nthem into an internal form. This internal query is subjected to query optimization \\n(discussed in Chapters 18 and 19). Among other things, the query optimizer  is \\nconcerned with the rearrangement and possible reordering of operations, elimina-\\ntion of redundancies, and use of efficient search algorithms during execution. It \\nconsults the system catalog for statistical and other physical information about the \\nstored data and generates executable code that performs the necessary operations \\nfor the query and makes calls on the runtime processor.\\nApplication programmers write programs in host languages such as Java, C, or C++ \\nthat are submitted to a precompiler. The precompiler extracts DML commands \\nfrom an application program written in a host programming language. These com-\\nmands are sent to the DML compiler for compilation into object code for database \\naccess. The rest of the program is sent to the host language compiler. The object \\ncodes for the DML commands and the rest of the program are linked, forming a \\ncanned transaction whose executable code includes calls to the runtime database \\nprocessor. It is also becoming increasingly common to use scripting languages such \\nas PHP and Python to write database programs. Canned transactions are executed \\nrepeatedly by parametric users via PCs or mobile apps; these users simply supply \\nthe parameters to the transactions. Each execution is considered to be a separate \\ntransaction. An example is a bank payment transaction where the account number, \\npayee, and amount may be supplied as parameters.\\nIn the lower part of Figure 2.3, the runtime database processor  executes (1) the \\nprivileged commands, (2) the executable query plans, and (3) the canned transac-\\ntions with runtime parameters. It works with the system catalog and may update it \\nwith statistics. It also works with the stored data manager, which in turn uses basic \\noperating system services for carrying out low-level input/output (read/write) \\noperations between the disk and main memory. The runtime database processor \\nhandles other aspects of data transfer, such as management of buffers in the main \\nmemory. Some DBMSs have their own buffer management module whereas others \\ndepend on the OS for buffer management. We have shown concurrency control  \\nand backup and recovery systems  separately as a module in this figure. They are \\nintegrated into the working of the runtime database processor for purposes of \\ntransaction management.\\nIt is common to have the client program  that accesses the DBMS running on a \\nseparate computer or device from the computer on which the database resides. The \\nformer is called the client computer running DBMS client software and the latter is \\ncalled the database server. In many cases, the client accesses a middle computer, \\ncalled the application server, which in turn accesses the database server. We elabo-\\nrate on this topic in Section 2.5.\\nFigure 2.3 is not meant to describe a specific DBMS; rather, it illustrates typical \\nDBMS modules. The DBMS interacts with the operating system when disk accesses—\\nto the database or to the catalog—are needed. If the computer system is shared by \\nmany users, the OS will schedule DBMS disk access requests and DBMS processing \\nalong with other processes. On the other hand, if the computer system is mainly \\ndedicated to running the database server, the DBMS will control main memory'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 58, 'page_label': '59'}, page_content='2.4 The Database System Environment  45\\n buffering of disk pages. The DBMS also interfaces with compilers for general- \\npurpose host programming languages, and with application servers and client pro-\\ngrams running on separate machines through the system network interface.\\n2.4.2 Database System Utilities\\nIn addition to possessing the software modules just described, most DBMSs have \\ndatabase utilities that help the DBA manage the database system. Common utili-\\nties have the following types of functions:\\n■ Loading. A loading utility is used to load existing data files—such as text \\nfiles or sequential files—into the database. Usually, the current (source) for-\\nmat of the data file and the desired (target) database file structure are speci-\\nfied to the utility, which then automatically reformats the data and stores it \\nin the database. With the proliferation of DBMSs, transferring data from \\none DBMS to another is becoming common in many organizations. Some \\nvendors offer conversion tools that generate the appropriate loading pro-\\ngrams, given the existing source and target database storage descriptions \\n(internal schemas).\\n■ Backup. A backup utility creates a backup copy of the database, usually by \\ndumping the entire database onto tape or other mass storage medium. The \\nbackup copy can be used to restore the database in case of catastrophic disk \\nfailure. Incremental backups are also often used, where only changes since \\nthe previous backup are recorded. Incremental backup is more complex, but \\nsaves storage space.\\n■ Database storage reorganization. This utility can be used to reorganize a \\nset of database files into different file organizations and create new access \\npaths to improve performance.\\n■ Performance monitoring. Such a utility monitors database usage and pro-\\nvides statistics to the DBA. The DBA uses the statistics in making decisions \\nsuch as whether or not to reorganize files or whether to add or drop indexes \\nto improve performance.\\nOther utilities may be available for sorting files, handling data compression, \\nmonitoring access by users, interfacing with the network, and performing other \\nfunctions.\\n2.4.3  Tools, Application Environments,  \\nand Communications Facilities\\nOther tools are often available to database designers, users, and the DBMS. CASE \\ntools12 are used in the design phase of database systems. Another tool that can be \\nquite useful in large organizations is an expanded data dictionary (or data repository) \\n12Although CASE stands for computer-aided software engineering, many CASE tools are used primarily \\nfor database design.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 59, 'page_label': '60'}, page_content='46 Chapter 2 Database System Concepts and Architecture\\nsystem. In addition to storing catalog information about schemas and  constraints, \\nthe data dictionary stores other information, such as design decisions, usage stan-\\ndards, application program descriptions, and user information. Such a system is \\nalso called an information repository. This information can be accessed directly by \\nusers or the DBA when needed. A data dictionary utility is similar to the DBMS \\ncatalog, but it includes a wider variety of information and is accessed mainly by \\nusers rather than by the DBMS software.\\nApplication development environments , such as PowerBuilder (Sybase)  \\nor JBuilder (Borland), have been quite popular. These systems provide an environ-\\nment for developing database applications and include facilities that help in many \\nfacets of database systems, including database design, GUI development, querying \\nand updating, and application program development.\\nThe DBMS also needs to interface with communications software, whose function \\nis to allow users at locations remote from the database system site to access the \\ndatabase through computer terminals, workstations, or personal computers. These \\nare connected to the database site through data communications hardware such as \\nInternet routers, phone lines, long-haul networks, local networks, or satellite com-\\nmunication devices. Many commercial database systems have communication \\npackages that work with the DBMS. The integrated DBMS and data communica-\\ntions system is called a DB/DC system. In addition, some distributed DBMSs are \\nphysically distributed over multiple machines. In this case, communications net-\\nworks are needed to connect the machines. These are often local area networks \\n(LANs), but they can also be other types of networks.\\n2.5  Centralized and Client/Server  \\nArchitectures for DBMSs\\n2.5.1 Centralized DBMSs Architecture\\nArchitectures for DBMSs have followed trends similar to those for general com-\\nputer system architectures. Older architectures used mainframe computers to pro-\\nvide the main processing for all system functions, including user application \\nprograms and user interface programs, as well as all the DBMS functionality. The \\nreason was that in older systems, most users accessed the DBMS via computer ter-\\nminals that did not have processing power and only provided display capabilities. \\nTherefore, all processing was performed remotely on the computer system housing \\nthe DBMS, and only display information and controls were sent from the computer \\nto the display terminals, which were connected to the central computer via various \\ntypes of communications networks.\\nAs prices of hardware declined, most users replaced their terminals with PCs and \\nworkstations, and more recently with mobile devices. At first, database systems \\nused these computers similarly to how they had used display terminals, so that the \\nDBMS itself was still a centralized DBMS in which all the DBMS functionality,'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 60, 'page_label': '61'}, page_content='2.5 Centralized and Client/Server Architectures for DBMSs  47\\napplication program execution, and user interface processing were carried out on \\none machine. Figure 2.4 illustrates the physical components in a centralized archi-\\ntecture. Gradually, DBMS systems started to exploit the available processing power \\nat the user side, which led to client/server DBMS architectures.\\n2.5.2 Basic Client/Server Architectures\\nFirst, we discuss client/server architecture in general; then we discuss how it is \\napplied to DBMSs. The client/server architecture was developed to deal with com-\\nputing environments in which a large number of PCs, workstations, file servers, \\nprinters, database servers, Web servers, e-mail servers, and other software and \\nequipment are connected via a network. The idea is to define specialized servers \\nwith specific functionalities. For example, it is possible to connect a number of PCs \\nor small workstations as clients to a file server that maintains the files of the client \\nmachines. Another machine can be designated as a printer server  by being con-\\nnected to various printers; all print requests by the clients are forwarded to this \\nmachine. Web servers or e-mail servers also fall into the specialized server cate-\\ngory. The resources provided by specialized servers can be accessed by many client \\nmachines. The client machines provide the user with the appropriate interfaces to \\nutilize these servers, as well as with local processing power to run local applications. \\nThis concept can be carried over to other software packages, with specialized pro-\\ngrams—such as a CAD (computer-aided design) package—being stored on specific \\nserver machines and being made accessible to multiple clients. Figure 2.5 illustrates \\nDisplay\\nMonitor\\nDisplay\\nMonitor\\nNetwork\\nSoftware\\nHardware/Firmware\\nOperating System\\nDisplay\\nMonitor\\nApplication\\nPrograms\\nDBMS\\nController\\nCPU\\nController\\n. . .\\n. . .\\n. . .\\nController\\nMemory Disk\\nI/O Devices\\n(Printers,\\nTape Drives, . . .)\\nCompilers\\nText\\nEditors\\nTerminal\\nDisplay Control\\nSystem Bus\\nTerminals . . .\\n. . .\\nFigure 2.4 \\nA physical centralized \\narchitecture.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 61, 'page_label': '62'}, page_content='48 Chapter 2 Database System Concepts and Architecture\\nclient/server architecture at the logical level; Figure 2.6 is a simplified diagram that \\nshows the physical architecture. Some machines would be client sites only (for \\nexample, mobile devices or workstations/PCs that have only client software \\ninstalled). Other machines would be dedicated servers, and others would have both \\nclient and server functionality.\\nThe concept of client/server architecture assumes an underlying framework that \\nconsists of many PCs/workstations and mobile devices as well as a smaller number \\nof server machines, connected via wireless networks or LANs and other types of \\ncomputer networks. A client in this framework is typically a user machine that pro-\\nvides user interface capabilities and local processing. When a client requires access \\nto additional functionality—such as database access—that does not exist at the cli-\\nent, it connects to a server that provides the needed functionality. A server is a sys-\\ntem containing both hardware and software that can provide services to the client \\nmachines, such as file access, printing, archiving, or database access. In general, \\nsome machines install only client software, others only server software, and still \\nothers may include both client and server software, as illustrated in Figure 2.6. \\nHowever, it is more common that client and server software usually run on separate \\nClient Client Client\\nPrint\\nServer\\nDBMS\\nServer\\nFile\\nServer\\n. . .\\n. . .\\nNetwork\\nFigure 2.5 \\nLogical two-tier  \\nclient/server  \\narchitecture.\\nClient CLIENT\\nSite 2\\nClient\\nwith Disk\\nClient\\nSite 1\\nDiskless\\nClient\\nServer\\nSite 3\\nServer\\nCommunication\\nNetwork\\nSite n\\nServer\\nand Client\\n. . .\\nClient\\nServer\\nFigure 2.6 \\nPhysical two-tier \\n client/server \\n architecture.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 62, 'page_label': '63'}, page_content='2.5 Centralized and Client/Server Architectures for DBMSs  49\\nmachines. Two main types of basic DBMS architectures were created on this under-\\nlying client/server framework: two-tier and three-tier.13 We discuss them next.\\n2.5.3 Two-Tier Client/Server Architectures for DBMSs\\nIn relational database management systems (RDBMSs), many of which started \\nas centralized systems, the system components that were first moved to the \\n client side were the user interface and application programs. Because SQL (see \\nChapters 6 and 7) provided a standard language for RDBMSs, this created a \\nlogical dividing point between client and server. Hence, the query and transac-\\ntion functionality related to SQL processing remained on the server side. In \\nsuch an architecture, the server is often called a query server  or transaction \\nserver  because it provides these two functionalities. In an RDBMS, the server is \\nalso often called an SQL server .\\nThe user interface programs and application programs can run on the client side. \\nWhen DBMS access is required, the program establishes a connection to the \\nDBMS (which is on the server side); once the connection is created, the client \\nprogram can communicate with the DBMS. A standard called Open Database \\nConnectivity  (ODBC) provides an application programming interface  (API), \\nwhich allows client-side programs to call the DBMS, as long as both client and \\nserver machines have the necessary software installed. Most DBMS vendors pro-\\nvide ODBC drivers for their systems. A client program can actually connect to \\nseveral RDBMSs and send query and transaction requests using the ODBC API, \\nwhich are then processed at the server sites. Any query results are sent back to the \\nclient program, which can process and display the results as needed. A related \\nstandard for the Java programming language, called JDBC, has also been defined. \\nThis allows Java client programs to access one or more DBMSs through a stan-\\ndard interface.\\nThe architectures described here are called two-tier architectures because the soft-\\nware components are distributed over two systems: client and server. The advan-\\ntages of this architecture are its simplicity and seamless compatibility with existing \\nsystems. The emergence of the Web changed the roles of clients and servers, leading \\nto the three-tier architecture.\\n2.5.4  Three-Tier and n-Tier Architectures  \\nfor Web Applications\\nMany Web applications use an architecture called the three-tier architecture , \\nwhich adds an intermediate layer between the client and the database server, as \\nillustrated in Figure 2.7(a).\\n13There are many other variations of client/server architectures. We discuss the two most basic ones \\nhere.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 63, 'page_label': '64'}, page_content='50 Chapter 2 Database System Concepts and Architecture\\nThis intermediate layer or middle tier is called the application server or the Web \\nserver, depending on the application. This server plays an intermediary role by \\nrunning application programs and storing business rules (procedures or con-\\nstraints) that are used to access data from the database server. It can also improve \\ndatabase security by checking a client’s credentials before forwarding a request to \\nthe database server. Clients contain user interfaces and Web browsers. The inter-\\nmediate server accepts requests from the client, processes the request and sends \\ndatabase queries and commands to the database server, and then acts as a conduit \\nfor passing (partially) processed data from the database server to the clients, where \\nit may be processed further and filtered to be presented to the users. Thus, the user \\ninterface, application rules, and data access act as the three tiers. Figure 2.7(b) shows \\nanother view of the three-tier architecture used by database and other application \\npackage vendors. The presentation layer displays information to the user and allows \\ndata entry. The business logic layer handles intermediate rules and constraints before \\ndata is passed up to the user or down to the DBMS. The bottom layer includes all \\ndata management services. The middle layer can also act as a Web server, which \\nretrieves query results from the database server and formats them into dynamic \\nWeb pages that are viewed by the Web browser at the client side. The client machine \\nis typically a PC or mobile device connected to the Web.\\nOther architectures have also been proposed. It is possible to divide the layers \\nbetween the user and the stored data further into finer components, thereby giving \\nrise to n-tier architectures, where n may be four or five tiers. Typically, the business \\nlogic layer is divided into multiple layers. Besides distributing programming and \\ndata throughout a network, n-tier applications afford the advantage that any one \\ntier can run on an appropriate processor or operating system platform and can be \\nhandled independently. Vendors of ERP (enterprise resource planning) and CRM \\n(customer relationship management) packages often use a middleware layer, which \\nGUI,\\nWeb InterfaceClient\\nApplication Server\\nor\\nWeb Server\\nDatabase\\nServer\\nApplication\\nPrograms,\\nWeb Pages\\nDatabase\\nManagement\\nSystem\\nPresentation\\nLayer\\nBusiness\\nLogic Layer\\nDatabase\\nServices\\nLayer\\n(a) (b)\\nFigure 2.7 \\nLogical three-tier \\n client/server \\n architecture, with a \\ncouple of commonly \\nused nomenclatures.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 64, 'page_label': '65'}, page_content='2.6 Classification of Database Management Systems  51\\naccounts for the front-end modules (clients) communicating with a number of \\nback-end databases (servers).\\nAdvances in encryption and decryption technology make it safer to transfer sensi-\\ntive data from server to client in encrypted form, where it will be decrypted. The \\nlatter can be done by the hardware or by advanced software. This technology gives \\nhigher levels of data security, but the network security issues remain a major con-\\ncern. Various technologies for data compression also help to transfer large amounts \\nof data from servers to clients over wired and wireless networks.\\n2.6  Classification of Database \\nManagement Systems\\nSeveral criteria can be used to classify DBMSs. The first is the data model  on  \\nwhich the DBMS is based. The main data model used in many current commercial \\nDBMSs is the relational data model , and the systems based on this model are \\nknown as SQL systems.  The object data model  has been implemented in some \\ncommercial systems but has not had widespread use. Recently, so-called big data \\nsystems, also known as key-value storage systems and NOSQL systems, use vari-\\nous data models: document-based,  graph-based, column-based, and key-value \\ndata models. Many legacy applications still run on database systems based on the \\nhierarchical and network data models.\\nThe relational DBMSs are evolving continuously, and, in particular, have been \\nincorporating many of the concepts that were developed in object databases. This \\nhas led to a new class of DBMSs called object-relational DBMSs. We can catego-\\nrize DBMSs based on the data model: relational, object, object-relational, NOSQL, \\nkey-value, hierarchical, network, and other.\\nSome experimental DBMSs are based on the XML (eXtended Markup Language) \\nmodel, which is a tree-structured data model. These have been called native XML \\nDBMSs. Several commercial relational DBMSs have added XML interfaces and \\nstorage to their products.\\nThe second criterion used to classify DBMSs is the number of users supported by \\nthe system. Single-user systems  support only one user at a time and are mostly \\nused with PCs. Multiuser systems, which include the majority of DBMSs, support \\nconcurrent multiple users.\\nThe third criterion is the number of sites over which the database is distributed. A \\nDBMS is centralized if the data is stored at a single computer site. A centralized \\nDBMS can support multiple users, but the DBMS and the database reside totally at \\na single computer site. A distributed DBMS (DDBMS) can have the actual database \\nand DBMS software distributed over many sites connected by a computer network. \\nBig data systems are often massively distributed, with hundreds of sites. The data is \\noften replicated on multiple sites so that failure of a site will not make some data \\nunavailable.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 65, 'page_label': '66'}, page_content='52 Chapter 2 Database System Concepts and Architecture\\nHomogeneous  DDBMSs use the same DBMS software at all the sites, whereas \\nheterogeneous  DDBMSs can use different DBMS software at each site. It is also \\npossible to develop middleware software to access several autonomous preexisting \\ndatabases stored under heterogeneous DBMSs. This leads to a federated DBMS (or \\nmultidatabase system), in which the participating DBMSs are loosely coupled and \\nhave a degree of local autonomy. Many DDBMSs use client-server architecture, as \\nwe described in Section 2.5.\\nThe fourth criterion is cost. It is difficult to propose a classification of DBMSs \\nbased on cost. Today we have open source (free) DBMS products like MySQL and \\nPostgreSQL that are supported by third-party vendors with additional services. \\nThe main RDBMS products are available as free examination 30-day copy versions \\nas well as personal versions, which may cost under $100 and allow a fair amount of \\nfunctionality. The giant systems are being sold in modular form with components \\nto handle distribution, replication, parallel processing, mobile capability, and so \\non, and with a large number of parameters that must be defined for the configura-\\ntion. Furthermore, they are sold in the form of licenses—site licenses allow unlim-\\nited use of the database system with any number of copies running at the customer \\nsite. Another type of license limits the number of concurrent users or the number \\nof user seats at a location. Standalone single-user versions of some systems like \\nMicrosoft Access are sold per copy or included in the overall configuration of a \\ndesktop or laptop. In addition, data warehousing and mining features, as well as \\nsupport for additional data types, are made available at extra cost. It is possible to \\npay millions of dollars for the installation and maintenance of large database sys-\\ntems annually.\\nWe can also classify a DBMS on the basis of the types of access path  options for \\nstoring files. One well-known family of DBMSs is based on inverted file structures. \\nFinally, a DBMS can be general purpose or special purpose. When performance is \\na primary consideration, a special-purpose DBMS can be designed and built for a \\nspecific application; such a system cannot be used for other applications without \\nmajor changes. Many airline reservations and telephone directory systems devel-\\noped in the past are special-purpose DBMSs. These fall into the category of online \\ntransaction processing  (OLTP) systems, which must support a large number of \\nconcurrent transactions without imposing excessive delays.\\nLet us briefly elaborate on the main criterion for classifying DBMSs: the data \\nmodel. The relational data model  represents a database as a collection of tables, \\nwhere each table can be stored as a separate file. The database in Figure 1.2 resem-\\nbles a basic relational representation. Most relational databases use the high-level \\nquery language called SQL and support a limited form of user views. We discuss \\nthe relational model and its languages and operations in Chapters 5 through 8, and \\ntechniques for programming relational applications in Chapters 10 and 11.\\nThe object data model defines a database in terms of objects, their properties, and \\ntheir operations. Objects with the same structure and behavior belong to a class, \\nand classes are organized into hierarchies (or acyclic graphs). The operations of'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 66, 'page_label': '67'}, page_content='2.6 Classification of Database Management Systems  53\\neach class are specified in terms of predefined procedures called methods. Rela-\\ntional DBMSs have been extending their models to incorporate object database \\nconcepts and other capabilities; these systems are referred to as object-relational or \\nextended relational systems . We discuss object databases and object-relational \\nsystems in Chapter 12.\\nBig data systems are based on various data models, with the following four data \\nmodels most common. The key-value data model  associates a unique key with \\neach value (which can be a record or object) and provides very fast access to a \\nvalue given its key. The document data model  is based on JSON (Java Script \\nObject Notation) and stores the data as documents, which somewhat resemble \\ncomplex objects. The graph data model  stores objects as graph nodes and rela-\\ntionships among objects as directed graph edges. Finally, the column-based data \\nmodels  store the columns of rows clustered on disk pages for fast access and \\nallow multiple versions of the data. We will discuss some of these in more detail \\nin Chapter 24.\\nThe XML model has emerged as a standard for exchanging data over the Web and \\nhas been used as a basis for implementing several prototype native XML systems. \\nXML uses hierarchical tree structures. It combines database concepts with concepts \\nfrom document representation models. Data is represented as elements; with the \\nuse of tags, data can be nested to create complex tree structures. This model con-\\nceptually resembles the object model but uses different terminology. XML capabili-\\nties have been added to many commercial DBMS products. We present an overview \\nof XML in Chapter 13.\\nTwo older, historically important data models, now known as legacy data models, \\nare the network and hierarchical models. The network model  represents data as \\nrecord types and also represents a limited type of 1:N relationship, called a set type. \\nA 1:N, or one-to-many, relationship relates one instance of a record to many record \\ninstances using some pointer linking mechanism in these models. The network \\nmodel, also known as the CODASYL DBTG model,\\n14 has an associated record-at-\\na-time language that must be embedded in a host programming language. The net-\\nwork DML was proposed in the 1971 Database Task Group (DBTG) Report as an \\nextension of the COBOL language.\\nThe hierarchical model represents data as hierarchical tree structures. Each hierar-\\nchy represents a number of related records. There is no standard language for the \\nhierarchical model. A popular hierarchical DML is DL/1 of the IMS system. It dom-\\ninated the DBMS market for over 20 years between 1965 and 1985. Its DML, called \\nDL/1, was a de facto industry standard for a long time.\\n15\\n14CODASYL DBTG stands for Conference on Data Systems Languages Database Task Group, which is \\nthe committee that specified the network model and its language.\\n15The full chapters on the network and hierarchical models from the second edition of this book are \\navailable from this book’s Companion Web site at http://www.aw.com/elmasri.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 67, 'page_label': '68'}, page_content='54 Chapter 2 Database System Concepts and Architecture\\n2.7 Summary\\nIn this chapter we introduced the main concepts used in database systems. We \\ndefined a data model and we distinguished three main categories:\\n■ High-level or conceptual data models (based on entities and relationships)\\n■ Low-level or physical data models\\n■ Representational or implementation data models (record-based, object-\\noriented)\\nWe distinguished the schema, or description of a database, from the database itself. \\nThe schema does not change very often, whereas the database state changes every \\ntime data is inserted, deleted, or modified. Then we described the three-schema \\nDBMS architecture, which allows three schema levels:\\n■ An internal schema describes the physical storage structure of the database.\\n■ A conceptual schema is a high-level description of the whole database.\\n■ External schemas describe the views of different user groups.\\nA DBMS that cleanly separates the three levels must have mappings among \\nthe\\xa0 schemas to transform requests and query results from one level to the \\nnext.\\xa0Most DBMSs do not separate the three levels completely. We used the \\nthree-schema architecture to define the concepts of logical and physical data \\nindependence.\\nThen we discussed the main types of languages and interfaces that DBMSs support. \\nA data definition language (DDL) is used to define the database conceptual schema. \\nIn most DBMSs, the DDL also defines user views and, sometimes, storage struc-\\ntures; in other DBMSs, separate languages or functions exist for specifying storage \\nstructures. This distinction is fading away in today’s relational implementations, \\nwith SQL serving as a catchall language to perform multiple roles, including view \\ndefinition. The storage definition part (SDL) was included in SQL’s early versions, \\nbut is now typically implemented as special commands for the DBA in relational \\nDBMSs. The DBMS compiles all schema definitions and stores their descriptions in \\nthe DBMS catalog.\\nA data manipulation language (DML) is used for specifying database retrievals and \\nupdates. DMLs can be high level (set-oriented, nonprocedural) or low level (record-\\noriented, procedural). A high-level DML can be embedded in a host programming \\nlanguage, or it can be used as a standalone language; in the latter case it is often \\ncalled a query language.\\nWe discussed different types of interfaces provided by DBMSs and the types of \\nDBMS users with which each interface is associated. Then we discussed the \\ndatabase system environment, typical DBMS software modules, and DBMS \\nutilities for helping users and the DBA staff perform their tasks. We continued \\nwith an overview of the two-tier and three-tier architectures for database \\n applications.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 68, 'page_label': '69'}, page_content='Exercises 55\\nFinally, we classified DBMSs according to several criteria: data model, number of \\nusers, number of sites, types of access paths, and cost. We discussed the availabil-\\nity of DBMSs and additional modules—from no cost in the form of open source \\nsoftware to configurations that annually cost millions to maintain. We also \\npointed out the variety of licensing arrangements for DBMS and related prod-\\nucts. The main classification of DBMSs is based on the data model. We briefly \\ndiscussed the main data models used in current commercial DBMSs.\\nReview Questions\\n 2.1. Define the following terms: data model, database schema, database state, \\ninternal schema, conceptual schema, external schema, data independence, \\nDDL, DML, SDL, VDL, query language, host language, data sublanguage, \\ndatabase utility, catalog, client/server architecture, three-tier architecture,  \\nand n-tier architecture.\\n 2.2. Discuss the main categories of data models. What are the basic differences \\namong the relational model, the object model, and the XML model?\\n 2.3. What is the difference between a database schema and a database state?\\n 2.4. Describe the three-schema architecture. Why do we need mappings among \\nschema levels? How do different schema definition languages support this \\narchitecture?\\n 2.5. What is the difference between logical data independence and physical data \\nindependence? Which one is harder to achieve? Why?\\n 2.6. What is the difference between procedural and nonprocedural DMLs?\\n 2.7. Discuss the different types of user-friendly interfaces and the types of users \\nwho typically use each.\\n 2.8. With what other computer system software does a DBMS interact?\\n 2.9. What is the difference between the two-tier and three-tier client/server \\narchitectures?\\n 2.10. Discuss some types of database utilities and tools and their functions.\\n 2.11. What is the additional functionality incorporated in n-tier architecture \\n(n . 3)?\\nExercises\\n 2.12. Think of different users for the database shown in Figure 1.2. What types of \\napplications would each user need? To which user category would each \\nbelong, and what type of interface would each need?'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 69, 'page_label': '70'}, page_content='56 Chapter 2 Database System Concepts and Architecture\\n 2.13. Choose a database application with which you are familiar. Design a schema \\nand show a sample database for that application, using the notation of Fig-\\nures 1.2 and 2.1. What types of additional information and constraints \\nwould you like to represent in the schema? Think of several users of your \\ndatabase, and design a view for each.\\n 2.14. If you were designing a Web-based system to make airline reservations and sell \\nairline tickets, which DBMS architecture would you choose from Section 2.5? \\nWhy? Why would the other architectures not be a good choice?\\n 2.15. Consider Figure 2.1. In addition to constraints relating the values of col-\\numns in one table to columns in another table, there are also constraints that \\nimpose restrictions on values in a column or a combination of columns \\nwithin a table. One such constraint dictates that a column or a group of col-\\numns must be unique across all rows in the table. For example, in the \\n \\nSTUDENT table, the Student_number column must be unique (to prevent two \\ndifferent students from having the same Student_number). Identify the col-\\numn or the group of columns in the other tables that must be unique across \\nall rows in the table.\\nSelected Bibliography\\nMany database textbooks, including Date (2004), Silberschatz et al. (2011), Ramak-\\nrishnan and Gehrke (2003), Garcia-Molina et al. (2002, 2009), and Abiteboul et al. \\n(1995), provide a discussion of the various database concepts presented here. \\n Tsichritzis and Lochovsky (1982) is an early textbook on data models. Tsichritzis \\nand Klug (1978) and Jardine (1977) present the three-schema architecture, which \\nwas first suggested in the DBTG CODASYL report (1971) and later in an American \\nNational Standards Institute (ANSI) report (1975). An in-depth analysis of the rela-\\ntional data model and some of its possible extensions is given in Codd (1990). The \\nproposed standard for object-oriented databases is described in Cattell et al. (2000). \\nMany documents describing XML are available on the Web, such as XML (2005).\\nExamples of database utilities are the ETI Connect, Analyze and Transform tools \\n(http://www.eti.com) and the database administration tool, DBArtisan, from \\nEmbarcadero Technologies (http://www.embarcadero.com).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 70, 'page_label': '71'}, page_content='part  2\\nConceptual Data Modeling and \\nDatabase Design'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 71, 'page_label': '72'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 72, 'page_label': '73'}, page_content='59\\n Data Modeling Using the Entity–\\nRelationship (ER) Model\\nC\\nonceptual modeling is a very important phase in \\ndesigning a successful database application. Gener-\\nally, the term database application refers to a particular database and the associ-\\nated programs that implement the database queries and updates. For example, a \\nBANK database application that keeps track of customer accounts would include \\nprograms that implement database updates corresponding to customer deposits \\nand withdrawals. These programs would provide user-friendly graphical user inter-\\nfaces (GUIs) utilizing forms and menus for the end users of the application—the \\nbank customers or bank tellers in this example. In addition, it is now common to \\nprovide interfaces to these programs to \\nBANK customers via mobile devices using \\nmobile apps . Hence, a major part of the database application will require the \\ndesign, implementation, and testing of these application programs. Traditionally, \\nthe design and testing of application programs has been considered to be part of \\nsoftware engineering rather than database design. In many software design tools, the \\ndatabase design methodologies and software engineering methodologies are inter-\\ntwined since these activities are strongly related.\\nIn this chapter, we follow the traditional approach of concentrating on the database \\nstructures and constraints during conceptual database design. The design of appli-\\ncation programs is typically covered in software engineering courses. We present \\nthe modeling concepts of the entity–relationship (ER) model, which is a popular \\nhigh-level conceptual data model. This model and its variations are frequently used \\nfor the conceptual design of database applications, and many database design tools \\nemploy its concepts. We describe the basic data-structuring concepts and con-\\nstraints of the ER model and discuss their use in the design of conceptual schemas \\nfor database applications. We also present the diagrammatic notation associated \\nwith the ER model, known as ER diagrams.\\n3chapter  3'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 73, 'page_label': '74'}, page_content='60 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\nObject modeling methodologies such as the Unified Modeling Language  (UML) \\nare becoming increasingly popular in both database and software design. These \\nmethodologies go beyond database design to specify detailed design of software \\nmodules and their interactions using various types of diagrams. An important part \\nof these methodologies—namely, class diagrams\\n1—is similar in many ways to the \\nER diagrams. In class diagrams, operations on objects are specified, in addition to \\nspecifying the database schema structure. Operations can be used to specify the \\nfunctional requirements  during database design, as we will discuss in Section 3.1. \\nWe present some of the UML notation and concepts for class diagrams that are \\nparticularly relevant to database design in Section 3.8, and we briefly compare these \\nto ER notation and concepts. Additional UML notation and concepts are presented \\nin Section 4.6.\\nThis chapter is organized as follows: Section 3.1 discusses the role of high-level con-\\nceptual data models in database design. We introduce the requirements for a sam-\\nple database application in Section 3.2 to illustrate the use of concepts from the ER \\nmodel. This sample database is used throughout the text. In Section 3.3 we present \\nthe concepts of entities and attributes, and we gradually introduce the diagram-\\nmatic technique for displaying an ER schema. In Section 3.4 we introduce the con-\\ncepts of binary relationships and their roles and structural constraints. Section 3.5 \\nintroduces weak entity types. Section 3.6 shows how a schema design is refined to \\ninclude relationships. Section 3.7 reviews the notation for ER diagrams, summa-\\nrizes the issues and common pitfalls that occur in schema design, and discusses \\nhow to choose the names for database schema constructs such as entity types and \\nrelationship types. Section 3.8 introduces some UML class diagram concepts, com-\\npares them to ER model concepts, and applies them to the same COMPANY data-\\nbase example. Section 3.9 discusses more complex types of relationships. Sec - \\ntion  3.10 summarizes the chapter.\\nThe material in Sections 3.8 and 3.9 may be excluded from an introductory course. If \\na more thorough coverage of data modeling concepts and conceptual database design \\nis desired, the reader should continue to Chapter 4, where we describe extensions to \\nthe ER model that lead to the enhanced–ER (EER) model, which includes concepts \\nsuch as specialization, generalization, inheritance, and union types (categories).\\n3.1  Using High-Level Conceptual Data Models \\nfor Database Design\\nFigure 3.1 shows a simplified overview of the database design process. The first step \\nshown is requirements collection and analysis . During this step, the database \\ndesigners interview prospective database users to understand and document their \\ndata requirements. The result of this step is a concisely written set of users’ require-\\nments. These requirements should be specified in as detailed and complete a form \\nas possible. In parallel with specifying the data requirements, it is useful to specify \\n1A class is similar to an entity type in many ways.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 74, 'page_label': '75'}, page_content='3.1 Using High-Level Conceptual Data Models for Database Design  61\\nthe known functional requirements of the application. These consist of the user-\\ndefined operations (or transactions) that will be applied to the database, including \\nboth retrievals and updates. In software design, it is common to use data flow dia-\\ngrams, sequence diagrams , scenarios, and other techniques to specify functional \\nrequirements. We will not discuss any of these techniques here; they are usually \\ndescribed in detail in software engineering texts.\\nOnce the requirements have been collected and analyzed, the next step is to create a \\nconceptual schema for the database, using a high-level conceptual data model. This \\nFunctional Requirements\\nREQUIRE MENTS\\nCOLLECTION AND\\nANAL YSIS\\nMiniworld\\nData Requirements\\nCONCEPTUAL DESIGN\\nConceptual Schema\\n(In a high-level data model)\\nLOGICAL DESIGN\\n(DATA MODEL MAPPING)\\nLogical (Conceptual) Schema\\n(In the data model of a specific DBMS)\\nPHYSICAL DESIGN\\nInternal Schema\\nApplication Programs\\nTRANSACTION\\nIMPLEMENTATION\\nAPPLICATION PROGRAM\\nDESIGN\\nDBMS-specific\\nDBMS-independent\\nHigh-Level Transaction\\nSpecification\\nFUNCTIONAL ANAL YSIS\\nFigure 3.1\\nA simplified diagram to illustrate the main phases of database design.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 75, 'page_label': '76'}, page_content='62 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\nstep is called conceptual design. The conceptual schema is a concise description of \\nthe data requirements of the users and includes detailed descriptions of the entity \\ntypes, relationships, and constraints; these are expressed using the concepts pro-\\nvided by the high-level data model. Because these concepts do not include imple-\\nmentation details, they are usually easier to understand and can be used to \\ncommunicate with nontechnical users. The high-level conceptual schema can also \\nbe used as a reference to ensure that all users’ data requirements are met and that \\nthe requirements do not conflict. This approach enables database designers to con-\\ncentrate on specifying the properties of the data, without being concerned with \\nstorage and implementation details, which makes it is easier to create a good con-\\nceptual database design.\\nDuring or after the conceptual schema design, the basic data model operations can \\nbe used to specify the high-level user queries and operations identified during \\nfunctional analysis. This also serves to confirm that the conceptual schema meets \\nall the identified functional requirements. Modifications to the conceptual schema \\ncan be introduced if some functional requirements cannot be specified using the \\ninitial schema.\\nThe next step in database design is the actual implementation of the database, using \\na commercial DBMS. Most current commercial DBMSs use an implementation \\ndata model—such as the relational (SQL) model—so the conceptual schema is \\ntransformed from the high-level data model into the implementation data model. \\nThis step is called logical design or data model mapping ; its result is a database \\nschema in the implementation data model of the DBMS. Data model mapping is \\noften automated or semiautomated within the database design tools.\\nThe last step is the physical design phase, during which the internal storage struc-\\ntures, file organizations, indexes, access paths, and physical design parameters for \\nthe database files are specified. In parallel with these activities, application pro-\\ngrams are designed and implemented as database transactions corresponding to the \\nhigh-level transaction specifications.\\nWe present only the basic ER model concepts for conceptual schema design in this \\nchapter. Additional modeling concepts are discussed in Chapter 4, when we intro-\\nduce the EER model.\\n3.2 A Sample Database Application\\nIn this section we describe a sample database application, called COMPANY, which \\nserves to illustrate the basic ER model concepts and their use in schema design. We \\nlist the data requirements for the database here, and then create its conceptual \\nschema step-by-step as we introduce the modeling concepts of the ER model. The \\nCOMPANY  database keeps track of a company’s employees, departments, and  \\nprojects. Suppose that after the requirements collection and analysis phase, the \\ndatabase designers provide the following description of the miniworld—the part of \\nthe company that will be represented in the database.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 76, 'page_label': '77'}, page_content='3.3 Entity Types, Entity Sets, Attributes, and Keys  63\\n■ The company is organized into departments. Each department has a unique \\nname, a unique number, and a particular employee who manages the depart-\\nment. We keep track of the start date when that employee began managing \\nthe department. A department may have several locations.\\n■ A department controls a number of projects, each of which has a unique \\nname, a unique number, and a single location.\\n■ The database will store each employee’s name, Social Security number, 2 \\naddress, salary, sex (gender), and birth date. An employee is assigned to one \\ndepartment, but may work on several projects, which are not necessarily \\ncontrolled by the same department. It is required to keep track of the cur-\\nrent number of hours per week that an employee works on each project, as \\nwell as the direct supervisor of each employee (who is another employee).\\n■ The database will keep track of the dependents of each employee for insur-\\nance purposes, including each dependent’s first name, sex, birth date, and \\nrelationship to the employee.\\nFigure 3.2 shows how the schema for this database application can be displayed by \\nmeans of the graphical notation known as ER diagrams . This figure will be \\nexplained gradually as the ER model concepts are presented. We describe the step-\\nby-step process of deriving this schema from the stated requirements—and explain \\nthe ER diagrammatic notation—as we introduce the ER model concepts.\\n3.3  Entity Types, Entity Sets, Attributes,  \\nand Keys\\nThe ER model describes data as entities, relationships, and attributes. In  Section\\xa03.3.1 \\nwe introduce the concepts of entities and their attributes. We discuss entity types \\nand key attributes in Section 3.3.2. Then, in Section 3.3.3, we specify the initial con-\\nceptual design of the entity types for the \\nCOMPANY database. We describe relation-\\nships in Section 3.4.\\n3.3.1 Entities and Attributes\\nEntities and Their Attributes. The basic concept that the ER model represents is \\nan entity, which is a thing or object in the real world with an independent existence. \\nAn entity may be an object with a physical existence (for example, a particular per-\\nson, car, house, or employee) or it may be an object with a conceptual existence (for \\ninstance, a company, a job, or a university course). Each entity has attributes—the \\nparticular properties that describe it. For example, an \\nEMPLOYEE entity may be \\ndescribed by the employee’s name, age, address, salary, and job. A particular entity \\n2The Social Security number, or SSN, is a unique nine-digit identifier assigned to each individual in the \\nUnited States to keep track of his or her employment, benefits, and taxes. Other countries may have \\nsimilar identification schemes, such as personal identification card numbers.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 77, 'page_label': '78'}, page_content='64 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\nwill have a value for each of its attributes. The attribute values that describe each \\nentity become a major part of the data stored in the database.\\nFigure 3.3 shows two entities and the values of their attributes. The EMPLOYEE \\nentity e1 has four attributes: Name, Address, Age, and Home_phone ; their values  \\nare ‘John Smith,’ ‘2311 Kirby, Houston, Texas 77001’, ‘55’, and ‘713-749-2630’, \\nrespectively. The COMPANY entity c1 has three attributes: Name, Headquarters, and \\nPresident; their values are ‘Sunco Oil’, ‘Houston’, and ‘John Smith’, respectively.\\nEMPLOYEE\\nFname Minit Lname\\nName Address\\nSex\\nSalary\\nSsn\\nBdate\\nSupervisor Supervisee\\nSUPERVISION1 N\\nHours\\nWORKS_ON\\nCONTROLS\\nM N\\n1\\nDEPENDENTS_OF\\nName\\nLocation\\nN\\n1\\n1 1\\nPROJECT\\nDEPARTMENT\\nLocations\\nName Number\\nNumber\\nNumber_of_employees\\nMANAGES\\nStart_date\\nWORKS_FOR 1N\\nN\\nDEPENDENT\\nSex Birth_date RelationshipName\\nFigure 3.2\\nAn ER schema diagram for the COMPANY database. The diagrammatic notation is introduced gradually throughout \\nthis chapter and is summarized in Figure 3.14.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 78, 'page_label': '79'}, page_content='3.3 Entity Types, Entity Sets, Attributes, and Keys  65\\nSeveral types of attributes occur in the ER model: simple versus composite, single-\\nvalued versus multivalued, and stored versus derived. First we define these attribute \\ntypes and illustrate their use via examples. Then we discuss the concept of a NULL \\nvalue for an attribute.\\nComposite versus Simple (Atomic) Attributes. Composite attributes can be \\ndivided into smaller subparts, which represent more basic attributes with indepen-\\ndent meanings. For example, the \\nAddress attribute of the EMPLOYEE entity shown \\nin Figure 3.3 can be subdivided into Street_address, City, State, and Zip,3 with the \\nvalues ‘2311 Kirby’, ‘Houston’, ‘Texas’, and ‘77001’. Attributes that are not divisible \\nare called simple or atomic attributes. Composite attributes can form a hierarchy; \\nfor example, \\nStreet_address can be further subdivided into three simple component \\nattributes: Number, Street, and Apartment_number, as shown in Figure 3.4. The value \\nof a composite attribute is the concatenation of the values of its component simple \\nattributes.\\nComposite attributes are useful to model situations in which a user sometimes \\nrefers to the composite attribute as a unit but at other times refers specifically to its \\nName = John Smith Name = Sunco Oil\\nHeadquarters = Houston\\nPresident = John Smith\\nAddress = 2311 Kirby\\nHouston, Texas 77001\\nAge = 55\\ne1 c1\\nHome_phone = 713-749-2630\\nFigure 3.3\\nTwo entities, \\nEMPLOYEE e\\n1, and \\nCOMPANY c1, and \\ntheir attributes.\\n3Zip Code is the name used in the United States for a five-digit postal code, such as 76019, which can \\nbe extended to nine digits, such as 76019-0015. We use the five-digit Zip in our examples.\\nAddress\\nCityStreet_address\\nNumber Street Apartment_number\\nState Zip\\nFigure 3.4\\nA hierarchy of  \\ncomposite attributes.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 79, 'page_label': '80'}, page_content='66 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\ncomponents. If the composite attribute is referenced only as a whole, there is no \\nneed to subdivide it into component attributes. For example, if there is no need to \\nrefer to the individual components of an address (Zip Code, street, and so on), then \\nthe whole address can be designated as a simple attribute.\\nSingle-Valued versus Multivalued Attributes. Most attributes have a single \\nvalue for a particular entity; such attributes are called single-valued. For example,  \\nAge is a single-valued attribute of a person. In some cases an attribute can have a  \\nset of values for the same entity—for instance, a Colors attribute for a car, or a  \\nCollege_degrees  attribute for a person. Cars with one color have a single value, \\nwhereas two-tone cars have two color values. Similarly, one person may not have any \\ncollege degrees, another person may have one, and a third person may have two or \\nmore degrees; therefore, different people can have different numbers of values for the \\nCollege_degrees  attribute. Such attributes are called multivalued. A multivalued  \\nattribute may have lower and upper bounds to constrain the number of values allowed \\nfor each individual entity. For example, the Colors attribute of a car may be restricted to \\nhave between one and two values, if we assume that a car can have two colors at most.\\nStored versus Derived Attributes. In some cases, two (or more) attribute val-\\nues are related—for example, the Age and Birth_date attributes of a person. For a \\nparticular person entity, the value of Age can be determined from the current \\n(today’s) date and the value of that person’s Birth_date. The Age attribute is hence \\ncalled a derived attribute and is said to be derivable from the Birth_date attribute, \\nwhich is called a stored attribute. Some attribute values can be derived from related \\nentities; for example, an attribute Number_of_employees  of a DEPARTMENT entity  \\ncan be derived by counting the number of employees related to (working for) that \\ndepartment.\\nNULL Values. In some cases, a particular entity may not have an applicable value \\nfor an attribute. For example, the Apartment_number attribute of an address applies \\nonly to addresses that are in apartment buildings and not to other types of resi-\\ndences, such as single-family homes. Similarly, a \\nCollege_degrees attribute applies \\nonly to people with college degrees. For such situations, a special value called NULL  \\nis created. An address of a single-family home would have NULL  for its  \\nApartment_number  attribute, and a person with no college degree would have  \\nNULL for College_degrees. NULL can also be used if we do not know the value of an \\nattribute for a particular entity—for example, if we do not know the home phone \\nnumber of ‘John Smith’ in Figure 3.3. The meaning of the former type of NULL is  \\nnot applicable, whereas the meaning of the latter is unknown. The unknown category \\nof NULL can be further classified into two cases. The first case arises when it is known \\nthat the attribute value exists but is missing—for instance, if the Height attribute of a \\nperson is listed as NULL. The second case arises when it is not known whether the \\nattribute value exists—for example, if the Home_phone attribute of a person is NULL.\\nComplex Attributes. Notice that, in general, composite and multivalued attri-\\nbutes can be nested arbitrarily. We can represent arbitrary nesting by grouping'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 80, 'page_label': '81'}, page_content='3.3 Entity Types, Entity Sets, Attributes, and Keys  67\\ncomponents of a composite attribute between parentheses ( ) and separating  \\nthe components with commas, and by displaying multivalued attributes between \\nbraces { }. Such attributes are called complex attributes. For example, if a person \\ncan have more than one residence and each residence can have a single address and \\nmultiple phones, an attribute \\nAddress_phone for a person can be specified as shown \\nin Figure 3.5.4 Both Phone and Address are themselves composite attributes.\\n3.3.2 Entity Types, Entity Sets, Keys, and Value Sets\\nEntity Types and Entity Sets. A database usually contains groups of entities that \\nare similar. For example, a company employing hundreds of employees may want to \\nstore similar information concerning each of the employees. These employee entities \\nshare the same attributes, but each entity has its own value(s) for each attribute. An \\nentity type defines a collection (or set) of entities that have the same attributes. Each \\nentity type in the database is described by its name and attributes. Figure 3.6 shows \\ntwo entity types: \\nEMPLOYEE and COMPANY, and a list of some of the attributes  \\nfor each. A few individual entities of each type are also illustrated, along with the \\nvalues of their attributes. The collection of all entities of a particular entity type in the \\n4For those familiar with XML, we should note that complex attributes are similar to complex elements in \\nXML (see Chapter 13).\\n{Address_phone( {Phone(Area_code,Phone_number)},Address(Street_address\\n(Number,Street,Apartment_number),City,State,Zip) )} \\nFigure 3.5\\nA complex attribute: \\nAddress_phone.\\nEntity Type Name:\\nEntity Set:\\n(Extension)\\nCOMPANY\\nName, Headquarters, President\\nEMPLOYEE\\nName, Age, Salary \\n(John Smith, 55, 80k)\\n(Fred Brown, 40, 30K)\\n(Judy Clark, 25, 20K)\\ne1 c1\\nc2e2\\ne3\\n(Sunco Oil, Houston, John Smith)\\n(Fast Computer, Dallas, Bob King)\\nFigure 3.6\\nTwo entity types, \\nEMPLOYEE and \\nCOMPANY, and some \\nmember entities of \\neach.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 81, 'page_label': '82'}, page_content='68 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\ndatabase at any point in time is called an entity set or entity collection; the entity set \\nis usually referred to using the same name as the entity type, even though they are \\ntwo separate concepts. For example, \\nEMPLOYEE refers to both a type of entity  as  \\nwell as the current collection of all employee entities in the database. It is now more \\ncommon to give separate names to the entity type and entity collection; for example \\nin object and object-relational data models (see Chapter 12).\\nAn entity type is represented in ER diagrams\\n5 (see Figure 3.2) as a rectangular box \\nenclosing the entity type name. Attribute names are enclosed in ovals and are \\nattached to their entity type by straight lines. Composite attributes are attached to \\ntheir component attributes by straight lines. Multivalued attributes are displayed in \\ndouble ovals. Figure 3.7(a) shows a \\nCAR entity type in this notation.\\nAn entity type describes the schema or intension for a set of entities that share the \\nsame structure. The collection of entities of a particular entity type is grouped into \\nan entity set, which is also called the extension of the entity type.\\nKey Attributes of an Entity Type. An important constraint on the entities of an \\nentity type is the key or uniqueness constraint on attributes. An entity type usually \\nhas one or more attributes whose values are distinct for each individual entity in the \\nentity set. Such an attribute is called a key attribute, and its values can be used to \\nidentify each entity uniquely. For example, the Name attribute is a key of the  \\nCOMPANY entity type in Figure 3.6 because no two companies are allowed to have \\nthe same name. For the PERSON entity type, a typical key attribute is Ssn (Social Secu-\\nrity number). Sometimes several attributes together form a key, meaning that the \\ncombination of the attribute values must be distinct for each entity. If a set of attri-\\nbutes possesses this property, the proper way to represent this in the ER model that \\nwe describe here is to define a composite attribute and designate it as a key attribute \\nof the entity type. Notice that such a composite key must be minimal; that is, all \\ncomponent attributes must be included in the composite attribute to have the \\nuniqueness property. Superfluous attributes must not be included in a key. In ER \\ndiagrammatic notation, each key attribute has its name underlined inside the oval, \\nas illustrated in Figure 3.7(a).\\nSpecifying that an attribute is a key of an entity type means that the preceding \\nuniqueness property must hold for every entity set of the entity type. Hence, it is a \\nconstraint that prohibits any two entities from having the same value for the key \\nattribute at the same time. It is not the property of a particular entity set; rather, it is \\na constraint on any entity set of the entity type at any point in time. This key con-\\nstraint (and other constraints we discuss later) is derived from the constraints of the \\nminiworld that the database represents.\\nSome entity types have more than one  key attribute. For example, each of the  \\nVehicle_id and Registration attributes of the entity type CAR (Figure 3.7) is a key in  \\n5We use a notation for ER diagrams that is close to the original proposed notation (Chen, 1976). Many \\nother notations are in use; we illustrate some of them later in this chapter when we present UML class \\ndiagrams, and some additional diagrammatic notations are given in Appendix A.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 82, 'page_label': '83'}, page_content='3.3 Entity Types, Entity Sets, Attributes, and Keys  69\\nits own right. The Registration attribute is an example of a composite key formed \\nfrom two simple component attributes, State and Number, neither of which is a key \\non its own. An entity type may also have no key, in which case it is called a weak \\nentity type (see Section 3.5).\\nIn our diagrammatic notation, if two attributes are underlined separately, then each \\nis a key on its own . Unlike the relational model (see Section 5.2.2), there is no con-\\ncept of primary key in the ER model that we present here; the primary key will be \\nchosen during mapping to a relational schema (see Chapter 9).\\nValue Sets (Domains) of Attributes. Each simple attribute of an entity type is \\nassociated with a value set (or domain of values), which specifies the set of values \\nthat may be assigned to that attribute for each individual entity. In Figure 3.6, if the \\nrange of ages allowed for employees is between 16 and 70, we can specify the value \\nset of the \\nAge attribute of EMPLOYEE to be the set of integer numbers between 16 \\nand 70. Similarly, we can specify the value set for the Name attribute to be the set of \\nstrings of alphabetic characters separated by blank characters, and so on. Value sets \\nare not typically displayed in basic ER diagrams and are similar to the basic data \\ntypes available in most programming languages, such as integer, string, Boolean, \\nfloat, enumerated type, subrange, and so on. However, data types of attributes can \\nModel\\nMake\\nVehicle_id\\nYear\\nColor\\nRegistration\\nState(a)\\n(b)\\nNumber\\nCAR\\nCAR1  \\n((ABC 123, TEXAS), TK629, Ford Mustang, convertible, 2004 {red, black})\\nCAR2  \\n((ABC 123, NEW YORK), WP9872, Nissan Maxima, 4-door, 2005, {blue})\\nCAR3  \\n((VSY 720, TEXAS), TD729, Chrysler LeBaron, 4-door, 2002, {white, blue})\\n \\nCAR\\nRegistration (Number, State), Vehicle_id, Make, Model, Year, {Color} \\nFigure 3.7\\nThe CAR entity type \\nwith two key attributes, \\nRegistration and  \\nVehicle_id. (a) ER  \\ndiagram notation.  \\n(b) Entity set with \\nthree entities.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 83, 'page_label': '84'}, page_content='70 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\nbe specified in UML class diagrams (see Section 3.8) and in other diagrammatic \\nnotations used in database design tools. Additional data types to represent common \\ndatabase types, such as date, time, and other concepts, are also employed.\\nMathematically, an attribute A of entity set E whose value set is V can be defined as \\na function from E to the power set\\n6 P(V) of V:\\nA : E → P(V)\\nWe refer to the value of attribute A for entity e as A(e). The previous definition cov-\\ners both single-valued and multivalued attributes, as well as NULLs. A NULL value  \\nis represented by the empty set . For single-valued attributes, A(e) is restricted to \\nbeing a singleton set for each entity e in E, whereas there is no restriction on multi-\\nvalued attributes.7 For a composite attribute A, the value set V is the power set of \\nthe Cartesian product of P(V1), P(V2),\\xa0.\\xa0.\\xa0.\\xa0, P(Vn), where V1, V2,\\xa0.\\xa0.\\xa0.\\xa0, Vn are the \\nvalue sets of the simple component attributes that form A:\\nV\\xa0=\\xa0P(P(V1)\\xa0×\\xa0P(V2)\\xa0×\\xa0.\\xa0.\\xa0.\\xa0×\\xa0P(Vn))\\nThe value set provides all possible values. Usually only a small number of these val-\\nues exist in the database at a particular time. Those values represent the data from \\nthe current state of the miniworld and correspond to the data as it actually exists in \\nthe miniworld.\\n3.3.3 Initial Conceptual Design of the COMPANY Database\\nWe can now define the entity types for the COMPANY database, based on the \\nrequirements described in Section 3.2. After defining several entity types and their \\nattributes here, we refine our design in Section 3.4 after we introduce the concept of \\na relationship. According to the requirements listed in Section 3.2, we can identify \\nfour entity types—one corresponding to each of the four items in the specification \\n(see Figure 3.8):\\n \\n1. An entity type DEPARTMENT  with attributes Name, Number , Locations ,  \\nManager, and Manager_start_date. Locations is the only multivalued attribute. \\nWe can specify that both Name and Number are (separate) key attributes \\nbecause each was specified to be unique.\\n 2. An entity type PROJECT  with attributes Name , Number , Location , and \\n Controlling_department. Both Name and Number are (separate) key  attributes.\\n 3. An entity type EMPLOYEE with attributes Name, Ssn, Sex, Address, Salary, \\nBirth_date , Department , and Supervisor . Both Name and Address  may be  \\ncomposite attributes; however, this was not specified in the requirements. \\nWe must go back to the users to see if any of them will refer to the individual \\ncomponents of \\nName—First_name, Middle_initial, Last_name—or of Address. In \\n6The power set P(V ) of a set V is the set of all subsets of V.\\n7A singleton set is a set with only one element (value).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 84, 'page_label': '85'}, page_content='3.3 Entity Types, Entity Sets, Attributes, and Keys  71\\nour example, Name is modeled as a composite attribute, whereas Address is \\nnot, presumably after consultation with the users.\\n 4. An entity type DEPENDENT with attributes Employee, Dependent_name, Sex, \\nBirth_date, and Relationship (to the employee).\\nAnother requirement is that an employee can work on several projects, and the \\ndatabase has to store the number of hours per week an employee works on each \\nproject. This requirement is listed as part of the third requirement in Section 3.2, \\nand it can be represented by a multivalued composite attribute of EMPLOYEE  \\ncalled Works_on  with the simple components ( Project , Hours). Alternatively, it  \\ncan be represented as a multivalued composite attribute of PROJECT  called   \\nWorkers  with the simple components ( Employee , Hours). We choose the first \\nAddress\\nSex\\nBirth_date\\nProject Hours\\nWorks_on\\nFname Minit Lname\\nDepartment\\nSalary\\nSupervisor\\nName\\nEMPLOYEE\\nSsn\\nSex\\nRelationship\\nEmployee\\nDependent_name\\nDEPENDENT\\nBirth_date\\nLocation\\nNumber\\nControlling_department\\nName\\nPROJECT\\nManager_start_date\\nNumber\\nManagerDEPARTMENT\\nName\\nLocations\\nFigure 3.8\\nPreliminary design of \\nentity types for the \\nCOMPANY database. \\nSome of the shown \\nattributes will be refined \\ninto  relationships.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 85, 'page_label': '86'}, page_content='72 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\n alternative in Figure 3.8; we shall see in the next section that this will be refined into \\na many-to-many relationship, once we introduce the concepts of relationships.\\n3.4  Relationship Types, Relationship Sets, \\nRoles, and Structural Constraints\\nIn Figure 3.8 there are several implicit relationships among the various entity types. \\nIn fact, whenever an attribute of one entity type refers to another entity type, some \\nrelationship exists. For example, the attribute \\nManager of DEPARTMENT refers to  \\nan employee who manages the department; the attribute Controlling_department   \\nof PROJECT  refers to the department that controls the project; the attribute  \\nSupervisor of EMPLOYEE refers to another employee (the one who supervises this \\nemployee); the attribute Department  of EMPLOYEE refers to the department for \\nwhich the employee works; and so on. In the ER model, these references should not \\nbe represented as attributes but as relationships. The initial \\nCOMPANY database \\nschema from Figure 3.8 will be refined in Section 3.6 to represent relationships \\nexplicitly. In the initial design of entity types, relationships are typically captured in \\nthe form of attributes. As the design is refined, these attributes get converted into \\nrelationships between entity types.\\nThis section is organized as follows: Section 3.4.1 introduces the concepts of rela-\\ntionship types, relationship sets, and relationship instances. We define the concepts \\nof relationship degree, role names, and recursive relationships in Section 3.4.2, and \\nthen we discuss structural constraints on relationships—such as cardinality ratios \\nand existence dependencies—in Section 3.4.3. Section 3.4.4 shows how relationship \\ntypes can also have attributes.\\n3.4.1 Relationship Types, Sets, and Instances\\nA relationship type R among n entity types E1, E2, .\\xa0.\\xa0. , En defines a set of associa-\\ntions—or a relationship set—among entities from these entity types. Similar to the \\ncase of entity types and entity sets, a relationship type and its corresponding rela-\\ntionship set are customarily referred to by the same name, R. Mathematically, the \\nrelationship set R is a set of relationship instances  ri, where each ri associates n \\nindividual entities (e1, e2, .\\xa0.\\xa0. , en), and each entity ej in ri is a member of entity set Ej, \\n1 ≤ j ≤ n. Hence, a relationship set is a mathematical relation on E1, E2, .\\xa0.\\xa0. , En; \\n alternatively, it can be defined as a subset of the Cartesian product of the entity sets \\nE1 × E2 × .\\xa0.\\xa0. × En. Each of the entity types E1, E2, .\\xa0.\\xa0. , En is said to participate in the \\nrelationship type R; similarly, each of the individual entities e1, e2, .\\xa0.\\xa0. , en is said to \\nparticipate in the relationship instance ri = (e1, e2, .\\xa0.\\xa0. , en).\\nInformally, each relationship instance ri in R is an association of entities, where the \\nassociation includes exactly one entity from each participating entity type. Each \\nsuch relationship instance ri represents the fact that the entities participating in ri \\nare related in some way in the corresponding miniworld situation. For example, \\nconsider a relationship type WORKS_FOR  between the two entity types'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 86, 'page_label': '87'}, page_content='3.4 Relationship Types, Relationship Sets, Roles, and Structural Constraints  73\\nEMPLOYEE and DEPARTMENT, which associates each employee with the depart-\\nment for which the employee works. Each relationship instance in the relationship \\nset \\nWORKS_FOR  associates one EMPLOYEE  entity and one DEPARTMENT   \\nentity. Figure 3.9 illustrates this example, where each relationship instance ri is \\nshown connected to the EMPLOYEE and DEPARTMENT  entities that participate  \\nin ri. In the miniworld represented by Figure 3.9, the employees e1, e3, and e6 work \\nfor department d1; the employees e2 and e4 work for department d2; and the employ-\\nees e5 and e7 work for department d3.\\nIn ER diagrams, relationship types are displayed as diamond-shaped boxes, which \\nare connected by straight lines to the rectangular boxes representing the participat-\\ning entity types. The relationship name is displayed in the diamond-shaped box \\n(see Figure 3.2).\\n3.4.2  Relationship Degree, Role Names, and Recursive \\nRelationships\\nDegree of a Relationship Type. The degree of a relationship type is the number \\nof participating entity types. Hence, the WORKS_FOR  relationship is of degree  \\ntwo. A relationship type of degree two is called binary, and one of degree three is \\ncalled ternary. An example of a ternary relationship is SUPPLY, shown in Fig-\\nure\\xa03.10, where each relationship instance ri associates three entities—a supplier s, a \\npart p, and a project j—whenever s supplies part p to project j. Relationships can \\nEMPLOYEE WORKS_FOR DEPART MENT\\ne1\\ne2\\ne3\\ne4\\ne5\\ne6\\ne7\\nr1\\nr2\\nr3\\nr4\\nr5\\nr6\\nr7\\nd1\\nd2\\nd3\\nFigure 3.9\\nSome instances in  \\nthe WORKS_FOR \\nrelationship set,  \\nwhich represents a \\nrelationship type \\nWORKS_FOR \\nbetween EMPLOYEE \\nand DEPARTMENT.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 87, 'page_label': '88'}, page_content='74 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\ngenerally be of any degree, but the ones most common are binary relationships. \\nHigher-degree relationships are generally more complex than binary relationships; \\nwe characterize them further in Section 3.9.\\nRelationships as Attributes. It is sometimes convenient to think of a binary rela-\\ntionship type in terms of attributes, as we discussed in Section 3.3.3. Consider the \\nWORKS_FOR relationship type in Figure 3.9. One can think of an attribute called \\nDepartment  of the EMPLOYEE entity type, where the value of Department  for each \\nEMPLOYEE  entity is (a reference to) the DEPARTMENT  entity for which that  \\nemployee works. Hence, the value set for this Department  attribute is the set of all \\nDEPARTMENT entities, which is the DEPARTMENT entity set. This is what we did in \\nFigure 3.8 when we specified the initial design of the entity type EMPLOYEE for the \\nCOMPANY database. However, when we think of a binary relationship as an attribute, \\nwe always have two options or two points of view. In this example, the alternative point \\nof view is to think of a multivalued attribute \\nEmployees  of the entity type  \\nDEPARTMENT whose value for each DEPARTMENT entity is the set of EMPLOYEE enti-\\nties who work for that department. The value set of this Employees attribute is the power \\nset of the EMPLOYEE  entity set. Either of these two attributes— Department  of \\nEMPLOYEE or Employees of DEPARTMENT—can represent the WORKS_FOR relation-\\nship type. If both are represented, they are constrained to be inverses of each other.8\\nSUPPLIER\\nPART\\nSUPPLY PROJECT\\np1\\np2\\np3\\nr1\\nr2\\nr3\\nr4\\nr5\\nr6\\nr7\\nj1\\nj2\\nj3\\ns1\\ns2\\nFigure 3.10\\nSome relationship \\ninstances in the \\n SUPPLY ternary \\n relationship set.\\n8This concept of representing relationship types as attributes is used in a class of data models called \\nfunctional data models. In object databases (see Chapter 12), relationships can be represented by \\n reference attributes, either in one direction or in both directions as inverses. In relational databases  \\n(see Chapter 5), foreign keys are a type of reference attribute used to represent relationships.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 88, 'page_label': '89'}, page_content='3.4 Relationship Types, Relationship Sets, Roles, and Structural Constraints  75\\nRole Names and Recursive Relationships. Each entity type that participates \\nin a relationship type plays a particular role in the relationship. The role name sig-\\nnifies the role that a participating entity from the entity type plays in each relation-\\nship instance, and it helps to explain what the relationship means. For example, in \\nthe \\nWORKS_FOR relationship type, EMPLOYEE plays the role of employee or worker \\nand DEPARTMENT plays the role of department or employer.\\nRole names are not technically necessary in relationship types where all the partici-\\npating entity types are distinct, since each participating entity type name can be used \\nas the role name. However, in some cases the same entity type participates more than \\nonce in a relationship type in different roles. In such cases the role name becomes \\nessential for distinguishing the meaning of the role that each participating entity \\nplays. Such relationship types are called recursive relationships or self-referencing \\nrelationships. Figure 3.11 shows an example. The \\nSUPERVISION relationship type \\nrelates an employee to a supervisor, where both employee and supervisor entities are \\nmembers of the same \\nEMPLOYEE  entity set. Hence, the EMPLOYEE  entity type  \\nparticipates twice  in SUPERVISION : once in the role of supervisor (or boss), and  \\nonce in the role of supervisee (or subordinate). Each relationship instance ri in \\nSUPERVISION  associates two different employee entities ej and ek, one of which  \\nplays the role of supervisor and the other the role of supervisee. In Figure 3.11, the \\nlines marked ‘1’ represent the supervisor role, and those marked ‘2’ represent the \\nsupervisee role; hence, e1 supervises e2 and e3, e4 supervises e6 and e7, and e5 super-\\nvises e1 and e4. In this example, each relationship instance must be connected with \\ntwo lines, one marked with ‘1’ (supervisor) and the other with ‘2’ (supervisee).\\nEMPLOYEE\\n2\\n2\\n2\\nSUPERVISION\\ne1\\ne2\\ne3\\ne4\\ne5\\ne6\\ne7\\nr1\\nr2\\nr3\\nr4\\nr5\\nr6\\n2\\n2\\n2\\n1\\n1\\n1\\n1\\n1\\n1\\nFigure 3.11\\nA recursive relationship \\nSUPERVISION \\nbetween EMPLOYEE \\nin the supervisor role \\n(1) and EMPLOYEE in \\nthe subordinate role (2).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 89, 'page_label': '90'}, page_content='76 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\n3.4.3 Constraints on Binary Relationship Types\\nRelationship types usually have certain constraints that limit the possible combina-\\ntions of entities that may participate in the corresponding relationship set. These \\nconstraints are determined from the miniworld situation that the relationships rep-\\nresent. For example, in Figure 3.9, if the company has a rule that each employee \\nmust work for exactly one department, then we would like to describe this con-\\nstraint in the schema. We can distinguish two main types of binary relationship \\nconstraints: cardinality ratio and participation.\\nCardinality Ratios for Binary Relationships. The cardinality ratio for a binary \\nrelationship specifies the maximum number of relationship instances that an entity \\ncan participate in. For example, in the \\nWORKS_FOR  binary relationship type, \\nDEPARTMENT:EMPLOYEE is of cardinality ratio 1:N, meaning that each department \\ncan be related to (that is, employs) any number of employees (N),9 but an employee \\ncan be related to (work for) at most one department (1). This means that for  \\nthis particular relationship type \\nWORKS_FOR, a particular department entity can \\nbe related to any number of employees (N indicates there is no maximum number). \\nOn the other hand, an employee can be related to a maximum of one department. \\nThe possible cardinality ratios for binary relationship types are 1:1, 1:N, N:1,  \\nand M:N.\\nAn example of a 1:1 binary relationship is \\nMANAGES (Figure 3.12), which relates a \\ndepartment entity to the employee who manages that department. This represents \\nthe miniworld constraints that—at any point in time—an employee can manage at \\n9N stands for any number of related entities (zero or more). In some notations, the asterisk symbol (*) is \\nused instead of N.\\nEMPLOYEE MANAGES DEPART MENT\\ne1\\ne2\\ne3\\ne4\\ne5\\ne6\\ne7\\nd1\\nd2\\nd3\\nr1\\nr2\\nr3\\nFigure 3.12\\nA 1:1 relationship, \\nMANAGES.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 90, 'page_label': '91'}, page_content='3.4 Relationship Types, Relationship Sets, Roles, and Structural Constraints  77\\nmost one department and a department can have at most one manager. The rela-\\ntionship type WORKS_ON (Figure 3.13) is of cardinality ratio M:N, because the \\nminiworld rule is that an employee can work on several projects and a project can \\nhave several employees.\\nCardinality ratios for binary relationships are represented on ER diagrams by dis-\\nplaying 1, M, and N on the diamonds as shown in Figure 3.2. Notice that in this \\nnotation, we can either specify no maximum (N) or a maximum of one (1) on par-\\nticipation. An alternative notation (see Section 3.7.4) allows the designer to specify \\na specific maximum number on participation, such as 4 or 5.\\nParticipation Constraints and Existence Dependencies. The participation \\nconstraint specifies whether the existence of an entity depends on its being related \\nto another entity via the relationship type. This constraint specifies the minimum \\nnumber of relationship instances that each entity can participate in and is some-\\ntimes called the minimum cardinality constraint. There are two types of participa-\\ntion constraints—total and partial—that we illustrate by example. If a company \\npolicy states that every employee must work for a department, then an employee \\nentity can exist only if it participates in at least one \\nWORKS_FOR  relationship \\ninstance (Figure 3.9). Thus, the participation of EMPLOYEE in WORKS_FOR  is \\ncalled total participation , meaning that every entity in the total set  of employee \\nentities must be related to a department entity via WORKS_FOR. Total participation \\nis also called existence dependency . In Figure 3.12 we do not expect every  \\nemployee to manage a department, so the participation of EMPLOYEE  in the  \\nEMPLOYEE WORKS_ON PROJECT\\ne1\\ne2\\ne3\\ne4\\nr1\\nr2\\nr3\\nr4\\nr5\\nr6\\nr7\\np1\\np2\\np3\\np4\\nFigure 3.13\\nAn M:N relationship, \\nWORKS_ON.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 91, 'page_label': '92'}, page_content='78 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\nMANAGES relationship type is partial, meaning that some or part of the set of  \\nemployee entities are related to some department entity via MANAGES, but not \\n necessarily all. We will refer to the cardinality ratio and participation constraints, \\ntaken together, as the structural constraints of a relationship type.\\nIn ER diagrams, total participation (or existence dependency) is displayed as a double \\nline connecting the participating entity type to the relationship, whereas partial par-\\nticipation is represented by a single line (see Figure 3.2). Notice that in this notation, \\nwe can either specify no minimum (partial participation) or a minimum of one (total \\nparticipation). An alternative notation (see Section 3.7.4) allows the designer to spec-\\nify a specific minimum number on participation in the relationship, such as 4 or 5.\\nWe will discuss constraints on higher-degree relationships in Section 3.9.\\n3.4.4 Attributes of Relationship Types\\nRelationship types can also have attributes, similar to those of entity types. For \\nexample, to record the number of hours per week that a particular employee works \\non a particular project, we can include an attribute Hours for the WORKS_ON  \\nrelationship type in Figure 3.13. Another example is to include the date on which  \\na manager started managing a department via an attribute Start_date  for the  \\nMANAGES relationship type in Figure 3.12.\\nNotice that attributes of 1:1 or 1:N relationship types can be migrated to one of the \\nparticipating entity types. For example, the Start_date attribute for the MANAGES \\nrelationship can be an attribute of either EMPLOYEE (manager)  or DEPARTMENT , \\nalthough conceptually it belongs to MANAGES. This is because MANAGES is a 1:1 \\nrelationship, so every department or employee entity participates in at most one  \\nrelationship instance. Hence, the value of the Start_date attribute can be determined \\nseparately, either by the participating department entity or by the participating \\nemployee (manager) entity.\\nFor a 1:N relationship type, a relationship attribute can be migrated only to the \\nentity type on the N-side of the relationship. For example, in Figure 3.9, if the \\nWORKS_FOR relationship also has an attribute Start_date that indicates when an \\nemployee started working for a department, this attribute can be included as an \\nattribute of \\nEMPLOYEE . This is because each employee works for at most one \\ndepartment, and hence participates in at most one relationship instance in  \\nWORKS_FOR, but a department can have many employees, each with a different start date. \\nIn both 1:1 and 1:N relationship types, the decision where to place a relationship \\nattribute—as a relationship type attribute or as an attribute of a participating entity \\ntype—is determined subjectively by the schema designer.\\nFor M:N (many-to-many) relationship types, some attributes may be determined \\nby the combination of participating entities  in a relationship instance, not by any \\nsingle entity. Such attributes must be specified as relationship attributes. An example \\nis the Hours attribute of the M:N relationship WORKS_ON (Figure 3.13); the  number \\nof hours per week an employee currently works on a project is determined by an \\nemployee-project combination and not separately by either entity.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 92, 'page_label': '93'}, page_content='3.5 Weak Entity Types  79\\n3.5 Weak Entity Types\\nEntity types that do not have key attributes of their own are called weak entity types. In \\ncontrast, regular entity types that do have a key attribute—which include all the exam-\\nples discussed so far—are called strong entity types. Entities belonging to a weak entity \\ntype are identified by being related to specific entities from another entity type in com-\\nbination with one of their attribute values. We call this other entity type the identifying \\nor owner entity type,\\n10 and we call the relationship type that relates a weak entity type \\nto its owner the identifying relationship of the weak entity type.11 A weak entity type \\nalways has a total participation constraint (existence dependency) with respect to its \\nidentifying relationship because a weak entity cannot be identified without an owner \\nentity. However, not every existence dependency results in a weak entity type. For \\nexample, a \\nDRIVER_LICENSE entity cannot exist unless it is related to a PERSON entity, \\neven though it has its own key (License_number) and hence is not a weak entity.\\nConsider the entity type DEPENDENT, related to EMPLOYEE, which is used to keep \\ntrack of the dependents of each employee via a 1:N relationship (Figure 3.2). In our \\nexample, the attributes of \\nDEPENDENT are Name (the first name of the dependent), \\nBirth_date, Sex, and Relationship (to the employee). Two dependents of two distinct \\nemployees may, by chance, have the same values for Name, Birth_date , Sex, and  \\nRelationship, but they are still distinct entities. They are identified as distinct entities \\nonly after determining the particular employee entity  to which each dependent is \\nrelated. Each employee entity is said to own the dependent entities that are related to it.\\nA weak entity type normally has a partial key , which is the attribute that can \\nuniquely identify weak entities that are related to the same owner entity .12 In our \\nexample, if we assume that no two dependents of the same employee ever have the \\nsame first name, the \\nattribute Name of DEPENDENT is the partial key. In the worst \\ncase, a composite attribute of all the weak entity’s attributes will be the partial key.\\nIn ER diagrams, both a weak entity type and its identifying relationship are distin-\\nguished by surrounding their boxes and diamonds with double lines (see Fig-\\nure\\xa03.2). The partial key attribute is underlined with a dashed or dotted line.\\nWeak entity types can sometimes be represented as complex (composite, multival-\\nued) attributes. In the preceding example, we could specify a multivalued attribute \\nDependents  for EMPLOYEE, which is a multivalued composite attribute with the \\ncomponent attributes Name, Birth_date, Sex, and Relationship. The choice of which \\nrepresentation to use is made by the database designer. One criterion that may be \\nused is to choose the weak entity type representation if the weak entity type partici-\\npates independently in relationship types other than its identifying relationship type.\\nIn general, any number of levels of weak entity types can be defined; an owner \\nentity type may itself be a weak entity type. In addition, a weak entity type may have \\nmore than one identifying entity type and an identifying relationship type of degree \\nhigher than two, as we illustrate in Section 3.9.\\n10The identifying entity type is also sometimes called the parent entity type or the dominant entity type.\\n11The weak entity type is also sometimes called the child entity type or the subordinate entity type.\\n12The partial key is sometimes called the discriminator.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 93, 'page_label': '94'}, page_content='80 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\n3.6  Refining the ER Design for  \\nthe COMPANY Database\\nWe can now refine the database design in Figure 3.8 by changing the attributes that \\nrepresent relationships into relationship types. The cardinality ratio and participa-\\ntion constraint of each relationship type are determined from the requirements \\nlisted in Section 3.2. If some cardinality ratio or dependency cannot be determined \\nfrom the requirements, the users must be questioned further to determine these \\nstructural constraints.\\nIn our example, we specify the following relationship types:\\n■ MANAGES, which is a 1:1(one-to-one) relationship type between EMPLOYEE \\nand DEPARTMENT . EMPLOYEE  participation is partial. DEPARTMENT   \\nparticipation is not clear from the requirements. We question the users, who \\nsay that a department must have a manager at all times, which implies total \\nparticipation.\\n13 The attribute Start_date is assigned to this relationship type.\\n■ WORKS_FOR , a 1:N (one-to-many) relationship type between  \\nDEPARTMENT and EMPLOYEE. Both participations are total.\\n■ CONTROLS, a 1:N relationship type between DEPARTMENT and PROJECT. \\nThe participation of PROJECT is total, whereas that of DEPARTMENT is deter-\\nmined to be partial, after consultation with the users indicates that some \\ndepartments may control no projects.\\n■ SUPERVISION, a 1:N relationship type between EMPLOYEE (in the supervi-\\nsor role) and EMPLOYEE (in the supervisee role). Both participations are \\ndetermined to be partial, after the users indicate that not every employee is a \\nsupervisor and not every employee has a supervisor.\\n■ WORKS_ON, determined to be an M:N (many-to-many) relationship type \\nwith attribute Hours, after the users indicate that a project can have several \\nemployees working on it. Both participations are determined to be total.\\n■ DEPENDENTS_OF , a 1:N relationship type between EMPLOYEE  and  \\nDEPENDENT, which is also the identifying relationship for the weak entity \\ntype DEPENDENT. The participation of EMPLOYEE is partial, whereas that of \\nDEPENDENT is total.\\nAfter specifying the previous six relationship types, we remove from the entity types in \\nFigure 3.8 all attributes that have been refined into relationships. These include Manager \\nand Manager_start_date  from DEPARTMENT ; Controlling_department  from  \\nPROJECT; Department, Supervisor, and Works_on from EMPLOYEE; and Employee from \\nDEPENDENT. It is important to have the least possible redundancy when we design the \\nconceptual schema of a database. If some redundancy is\\xa0desired at the storage level or at \\nthe user view level, it can be introduced later, as discussed in Section 1.6.1.\\n13The rules in the miniworld that determine the constraints are sometimes called the business rules, \\nsince they are determined by the business or organization that will utilize the database.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 94, 'page_label': '95'}, page_content='3.7 ER Diagrams, Naming Conventions, and Design Issues  81\\n3.7  ER Diagrams, Naming Conventions,  \\nand Design Issues\\n3.7.1 Summary of Notation for ER Diagrams\\nFigures 3.9 through 3.13 illustrate examples of the participation of entity types in \\nrelationship types by displaying their entity sets and relationship sets (or \\n extensions)—the individual entity instances in an entity set and the individual rela-\\ntionship instances in a relationship set. In ER diagrams the emphasis is on repre-\\nsenting the schemas rather than the instances. This is more useful in database \\ndesign because a database schema changes rarely, whereas the contents of the entity \\nsets may change frequently. In addition, the schema is obviously easier to display, \\nbecause it is much smaller.\\nFigure 3.2 displays the \\nCOMPANY ER database schema as an ER diagram. We now \\nreview the full ER diagram notation. Regular (strong) entity types such as \\nEMPLOYEE, DEPARTMENT, and PROJECT are shown in rectangular boxes. Relation-\\nship types such as WORKS_FOR , MANAGES, CONTROLS , and WORKS_ON  are \\nshown in diamond-shaped boxes attached to the participating entity types with \\nstraight lines. Attributes are shown in ovals, and each attribute is attached by a straight \\nline to its entity type or relationship type. Component attributes of a composite attri-\\nbute are attached to the oval representing the composite attribute, as illustrated by the \\nName attribute of EMPLOYEE. Multivalued attributes are shown in double ovals, as \\nillustrated by the Locations attribute of DEPARTMENT. Key attributes have their names \\nunderlined. Derived attributes are shown in dotted ovals, as illustrated by the  \\nNumber_of_employees attribute of DEPARTMENT.\\nWeak entity types are distinguished by being placed in double rectangles and by \\nhaving their identifying relationship placed in double diamonds, as illustrated by \\nthe \\nDEPENDENT entity type and the DEPENDENTS_OF identifying relationship type. \\nThe partial key of the weak entity type is underlined with a dotted line.\\nIn Figure 3.2 the cardinality ratio of each binary relationship type is specified  \\nby attaching a 1, M, or N on each participating edge. The cardinality ratio  \\nof \\nDEPARTMENT:EMPLOYEE  in MANAGES  is 1:1, whereas it is 1:N for  \\nDEPARTMENT: EMPLOYEE in WORKS_FOR, and M:N for WORKS_ON. The partici-\\npation constraint is specified by a single line for partial participation and by double \\nlines for total participation (existence dependency).\\nIn Figure 3.2 we show the role names for the \\nSUPERVISION  relationship type \\nbecause the same EMPLOYEE entity type plays two distinct roles in that relation-\\nship. Notice that the cardinality ratio is 1:N from supervisor to supervisee because \\neach employee in the role of supervisee has at most one direct supervisor, whereas \\nan employee in the role of supervisor can supervise zero or more employees.\\nFigure 3.14 summarizes the conventions for ER diagrams. It is important to note \\nthat there are many other alternative diagrammatic notations (see Section 3.7.4 and \\nAppendix A).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 95, 'page_label': '96'}, page_content='82 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\n3.7.2 Proper Naming of Schema Constructs\\nWhen designing a database schema, the choice of names for entity types, attributes, \\nrelationship types, and (particularly) roles is not always straightforward. One \\nshould choose names that convey, as much as possible, the meanings attached to \\nthe different constructs in the schema. We choose to use singular names for entity \\ntypes, rather than plural ones, because the entity type name applies to each indi-\\nvidual entity belonging to that entity type. In our ER diagrams, we will use the con-\\nvention that entity type and relationship type names are in uppercase letters, \\nattribute names have their initial letter capitalized, and role names are in lowercase \\nletters. We have used this convention in Figure 3.2.\\nAs a general practice, given a narrative description of the database requirements, \\nthe nouns appearing in the narrative tend to give rise to entity type names, and the \\nverbs tend to indicate names of relationship types. Attribute names generally arise \\nfrom additional nouns that describe the nouns corresponding to entity types.\\nAnother naming consideration involves choosing binary relationship names to \\nmake the ER diagram of the schema readable from left to right and from top to bot-\\ntom. We have generally followed this guideline in Figure 3.2. To explain this nam-\\ning convention further, we have one exception to the convention in Figure 3.2—the \\nDEPENDENTS_OF  relationship type, which reads from bottom to top. When we \\ndescribe this relationship, we can say that the DEPENDENT entities (bottom entity \\ntype) are DEPENDENTS_OF (relationship name) an EMPLOYEE (top entity type). To \\nchange this to read from top to bottom, we could rename the relationship type to \\nHAS_DEPENDENTS, which would then read as follows: An EMPLOYEE entity (top \\nentity type) HAS_DEPENDENTS (relationship name) of type DEPENDENT (bottom \\nentity type). Notice that this issue arises because each binary relationship can be \\ndescribed starting from either of the two participating entity types, as discussed in \\nthe beginning of Section 3.4.\\n3.7.3 Design Choices for ER Conceptual Design\\nIt is occasionally difficult to decide whether a particular concept in the miniworld \\nshould be modeled as an entity type, an attribute, or a relationship type. In this \\n section, we give some brief guidelines as to which construct should be chosen in \\nparticular situations.\\nIn general, the schema design process should be considered an iterative refinement \\nprocess, where an initial design is created and then iteratively refined until the most \\nsuitable design is reached. Some of the refinements that are often used include the \\nfollowing:\\n■ A concept may be first modeled as an attribute and then refined into a rela-\\ntionship because it is determined that the attribute is a reference to another \\nentity type. It is often the case that a pair of such attributes that are inverses of \\none another are refined into a binary relationship. We discussed this type of \\nrefinement in detail in Section 3.6. It is important to note that in our  notation,'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 96, 'page_label': '97'}, page_content='3.7 ER Diagrams, Naming Conventions, and Design Issues  83\\nMeaningSymbol\\nEntity\\nWeak Entity\\nIndentifying Relationship\\nRelationship\\nComposite Attribute\\n. . .\\nKey Attribute\\nAttribute\\nDerived Attribute\\nMultivalued Attribute\\nTotal Participation of E2 in RRE1 E2\\nCardinality Ratio 1: N for E1 : E2 in RRE1 E2\\nN1\\nStructural Constraint (min, max)\\non Participation of E in RRE\\n(min, max)\\nFigure 3.14\\nSummary of the  \\nnotation for ER  \\ndiagrams.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 97, 'page_label': '98'}, page_content='84 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\nonce an attribute is replaced by a relationship, the attribute itself should be \\nremoved from the entity type to avoid duplication and redundancy.\\n■ Similarly, an attribute that exists in several entity types may be elevated or \\npromoted to an independent entity type. For example, suppose that each \\nof several entity types in a \\nUNIVERSITY  database, such as STUDENT , \\nINSTRUCTOR , and COURSE , has an attribute Department in the  \\ninitial design; the designer may then choose to create an entity type  \\nDEPARTMENT with a single attribute Dept_name and relate it to the three \\nentity types ( STUDENT, INSTRUCTOR, and COURSE) via appropriate rela-\\ntionships. Other attributes/relationships of DEPARTMENT may be discov-\\nered later.\\n■ An inverse refinement to the previous case may be applied—for example, if \\nan entity type DEPARTMENT exists in the initial design with a single attribute \\nDept_name  and is related to only one other entity type, STUDENT . In  \\nthis case, DEPARTMENT  may be reduced or demoted to an attribute of  \\nSTUDENT.\\n■ Section 3.9 discusses choices concerning the degree of a relationship. In Chap-\\nter 4, we discuss other refinements concerning specialization/generalization.\\n3.7.4 Alternative Notations for ER Diagrams\\nThere are many alternative diagrammatic notations for displaying ER diagrams. \\nAppendix A gives some of the more popular notations. In Section 3.8, we introduce \\nthe Unified Modeling Language (UML) notation for class diagrams, which has been \\nproposed as a standard for conceptual object modeling.\\nIn this section, we describe one alternative ER notation for specifying structural \\nconstraints on relationships, which replaces the cardinality ratio (1:1, 1:N, M:N) \\nand single/double-line notation for participation constraints. This notation \\ninvolves associating a pair of integer numbers (min, max) with each participation  \\nof an entity type E in a relationship type R, where 0 ≤ min ≤ max and max ≥ 1. The \\nnumbers mean that for each entity e in E, e must participate in at least min and at \\nmost max relationship instances in R at any point in time . In this method,  \\nmin = 0 implies partial participation, whereas min > 0 implies total participation.\\nFigure 3.15 displays the \\nCOMPANY database schema using the (min, max) nota-\\ntion.14 Usually, one uses either the cardinality ratio/single-line/double-line nota-\\ntion or the (min, max) notation. The (min, max) notation is more precise, and we \\ncan use it to specify some structural constraints for relationship types of higher \\ndegree. However, it is not sufficient for specifying some key constraints on higher-\\ndegree relationships, as discussed in Section 3.9.\\nFigure 3.15 also displays all the role names for the COMPANY database schema.\\n14In some notations, particularly those used in object modeling methodologies such as UML, the (min, \\nmax) is placed on the opposite sides to the ones we have shown. For example, for the WORKS_FOR  \\nrelationship in Figure 3.15, the (1,1) would be on the DEPARTMENT side, and the (4,N) would be on the \\nEMPLOYEE side. Here we used the original notation from Abrial (1974).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 98, 'page_label': '99'}, page_content='3.8 Example of Other Notation: UML Class Diagrams  85\\n3.8  Example of Other Notation:  \\nUML Class Diagrams\\nThe UML methodology is being used extensively in software design and has many \\ntypes of diagrams for various software design purposes. We only briefly present the \\nbasics of UML class diagrams here and compare them with ER diagrams. In some \\nEMPLOYEE\\nMinit Lname\\nName Address\\nSex\\nSalary\\nSsn\\nBdate\\nSupervisor\\n(0,N) (0,1)\\n(1,1)\\nEmployee\\n(1,1)\\n(1,N)\\n(1,1)\\n(0,N)Department\\nManaged\\n(4,N)\\nDepartment\\n(0,1)\\nManager\\nSupervisee\\nSUPERVISION\\nHours\\nWORKS_ON\\nCONTROLS\\nDEPENDENTS_OF\\nName\\nLocation\\nPROJECT\\nDEPARTMENT\\nLocations\\nName Number\\nNumber\\nNumber_of_employees\\nMANAGES\\nStart_date\\nWORKS_FOR\\nDEPENDENT\\nSex Birth_date RelationshipName\\nControlling\\nDepartment\\nControlled\\nProject\\nProject\\n(1,N)\\nWorker\\n(0,N)\\nEmployee\\n(1,1) Dependent\\nFname\\nFigure 3.15\\nER diagrams for the company schema, with structural constraints specified using  \\n(min, max) notation and role names.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 99, 'page_label': '100'}, page_content='86 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\nways, class diagrams can be considered as an alternative notation to ER diagrams. \\nAdditional UML notation and concepts are presented in Section 8.6. Figure 3.16 \\nshows how the COMPANY ER database schema in Figure 3.15 can be displayed \\nusing UML class diagram notation. The entity types in Figure 3.15 are modeled as \\nclasses in Figure 3.16. An entity in ER corresponds to an object in UML.\\nIn UML class diagrams, a class (similar to an entity type in ER) is displayed as a box \\n(see Figure 3.16) that includes three sections: The top section gives the class name \\n(similar to entity type name); the middle section includes the attributes; and the \\nlast section includes operations that can be applied to individual objects (similar to \\nindividual entities in an entity set) of the class. Operations are not specified in ER \\ndiagrams. Consider the EMPLOYEE class in Figure 3.16. Its attributes are Name, Ssn, \\nBdate, Sex, Address, and Salary. The designer can optionally specify the domain (or \\ndata type) of an attribute if desired, by placing a colon (:) followed by the domain \\nname or description, as illustrated by the Name, Sex, and Bdate  attributes  \\nof EMPLOYEE  in Figure 3.16. A composite attribute is modeled as a  \\nstructured domain, as illustrated by the Name attribute of EMPLOYEE. A multival-\\nued attribute will generally be modeled as a separate class, as illustrated by the \\nLOCATION class in Figure 3.16.\\nsupervisee\\nName: Name_dom\\nFname\\nMinit\\nLname\\nSsn\\nBdate: Date\\nSex: {M,F}\\nAddress\\nSalary\\n4.. *\\n1.. *\\n1.. * *\\n*\\n1..1\\n1..1\\n1..1\\n1..1\\n1.. *\\n0..1\\n0.. *\\n0.. *\\nage\\nchange_department\\nchange_projects\\n. . .\\nSex: {M,F}\\nBirth_date: Date\\nRelationship\\nDEPENDENT\\n. . .\\n0..1\\nsupervisor\\nDependent_name\\nEMPLOYEE\\nName\\nNumber\\nadd_employee\\nnumber_of_employees\\nchange_manager\\n. . .\\nDEPARTMENT\\nName\\nNumber\\nadd_employee\\nadd_project\\nchange_manager\\n. . .\\nPROJECT\\nStart_date\\nMANAGES\\nCONTROLS\\nHours\\nWORKS_ON Name\\nLOCATION\\n1..1\\n0.. *\\n0..1\\nMultiplicity\\nNotation in OMT:\\nAggregation\\nNotation in UML:\\nWhole Part\\nWORKS_FOR\\nFigure 3.16\\nThe COMPANY conceptual schema in UML class diagram notation.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 100, 'page_label': '101'}, page_content='3.8 Example of Other Notation: UML Class Diagrams  87\\nRelationship types are called associations in UML terminology, and relationship \\ninstances are called links. A binary association (binary relationship type) is repre-\\nsented as a line connecting the participating classes (entity types), and may option-\\nally have a name. A relationship attribute, called a link attribute, is placed in a box \\nthat is connected to the association’s line by a dashed line. The (min, max) notation \\ndescribed in Section 3.7.4 is used to specify relationship constraints, which are \\ncalled multiplicities in UML terminology. Multiplicities are specified in the form \\nmin..max, and an asterisk (*) indicates no maximum limit on participation. How-\\never, the multiplicities are placed on the opposite ends of the relationship when com-\\npared with the (min, max) notation discussed in Section 3.7.4 (compare Fig - \\nures 3.15 and 3.16). In UML, a single asterisk indicates a multiplicity of 0 ..*, and a \\nsingle 1 indicates a multiplicity of 1..1. A recursive relationship type (see Section 3.4.2) \\nis called a reflexive association in UML, and the role names—like the multiplicities—\\nare placed at the opposite ends of an association when compared with the placing of \\nrole names in Figure 3.15.\\nIn UML, there are two types of relationships: association and aggregation. \\n Aggregation is meant to represent a relationship between a whole object and its com-\\nponent parts, and it has a distinct diagrammatic notation. In Figure 3.16, we modeled \\nthe locations of a department and the single location of a project as aggregations. \\nHowever, aggregation and association do not have different structural properties, and \\nthe choice as to which type of relationship to use—aggregation or association—is \\nsomewhat subjective. In the ER model, both are represented as relationships.\\nUML also distinguishes between unidirectional  and bidirectional  associations \\n(or aggregations). In the unidirectional case, the line connecting the classes is dis-\\nplayed with an arrow to indicate that only one direction for accessing related \\nobjects is needed. If no arrow is displayed, the bidirectional case is assumed, which \\nis the default. For example, if we always expect to access the manager of a depart-\\nment starting from a \\nDEPARTMENT object, we would draw the association line rep-\\nresenting the MANAGES  association with an arrow from DEPARTMENT  to \\nEMPLOYEE. In addition, relationship instances may be specified to be ordered.  \\nFor example, we could specify that the employee objects related to each depart-\\nment through the WORKS_FOR association (relationship) should be ordered by \\ntheir Start_date attribute value. Association (relationship) names are optional in \\nUML, and relationship attributes are displayed in a box attached with a dashed \\nline to the line representing the association/aggregation (see Start_date and Hours \\nin Figure 3.16).\\nThe operations given in each class are derived from the functional requirements of \\nthe application, as we discussed in Section 3.1. It is generally sufficient to specify the \\noperation names initially for the logical operations that are expected to be applied \\nto individual objects of a class, as shown in Figure 3.16. As the design is refined, \\nmore details are added, such as the exact argument types (parameters) for each \\noperation, plus a functional description of each operation. UML has function \\ndescriptions and sequence diagrams  to specify some of the operation details, but \\nthese are beyond the scope of our discussion.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 101, 'page_label': '102'}, page_content='88 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\nWeak entities can be modeled using the UML construct called qualified association \\n(or qualified aggregation ); this can represent both the identifying relationship  \\nand the partial key, which is placed in a box attached to the owner class. This is \\nillustrated by the \\nDEPENDENT class and its qualified aggregation to EMPLOYEE in \\nFigure 3.16. In UML terminology, the partial key attribute Dependent_name is called \\nthe discriminator , because its value distinguishes the objects associated with \\n(related to) the same EMPLOYEE entity. Qualified associations are not restricted to \\nmodeling weak entities, and they can be used to model other situations in UML.\\nThis section is not meant to be a complete description of UML class diagrams, but \\nrather to illustrate one popular type of alternative diagrammatic notation that can \\nbe used for representing ER modeling concepts.\\n3.9  Relationship Types of Degree  \\nHigher than Two\\nIn Section 3.4.2 we defined the degree of a relationship type as the number of par-\\nticipating entity types and called a relationship type of degree two binary and a \\nrelationship type of degree three ternary. In this section, we elaborate on the differ-\\nences between binary and higher-degree relationships, when to choose higher-\\ndegree versus binary relationships, and how to specify constraints on higher-degree \\nrelationships.\\n3.9.1  Choosing between Binary and Ternary  \\n(or Higher-Degree) Relationships\\nThe ER diagram notation for a ternary relationship type is shown in Figure 3.17(a), \\nwhich displays the schema for the SUPPLY relationship type that was displayed at the \\ninstance level in Figure 3.10. Recall that the relationship set of SUPPLY is a set of rela-\\ntionship instances (s, j, p), where the meaning is that s is a SUPPLIER who is currently \\nsupplying a PART p to a PROJECT j. In general, a relationship type R of degree n will \\nhave n edges in an ER diagram, one connecting R to each participating entity type.\\nFigure 3.17(b) shows an ER diagram for three binary relationship types CAN_SUPPLY, \\nUSES, and SUPPLIES. In general, a ternary relationship type represents different \\ninformation than do three binary relationship types. Consider the three binary \\nrelationship types \\nCAN_SUPPLY , USES , and SUPPLIES . Suppose that  \\nCAN_SUPPLY, between SUPPLIER and PART, includes an instance ( s, p) whenever \\nsupplier s can supply  part p (to any project); USES, between PROJECT and PART, \\nincludes an instance ( j, p) whenever project j uses part p; and SUPPLIES, between \\nSUPPLIER and PROJECT, includes an instance ( s, j) whenever supplier s supplies \\nsome part  to project j. The existence of three relationship instances ( s, p),  \\n(j, p), and (s, j) in CAN_SUPPLY, USES, and SUPPLIES, respectively, does not neces-\\nsarily imply that an instance ( s, j, p) exists in the ternary relationship SUPPLY, \\nbecause the meaning is different . It is often tricky to decide whether a particular \\nrelationship should be represented as a relationship type of degree n or should be'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 102, 'page_label': '103'}, page_content='3.9 Relationship Types of Degree Higher than Two  89\\nbroken down into several relationship types of smaller degrees. The designer must \\nbase this decision on the semantics or meaning of the particular situation being \\nrepresented. The typical solution is to include the ternary relationship plus one or \\nmore of the binary relationships, if they represent different meanings and if all are \\nneeded by the application.\\n(a) SUPPLY\\nSname\\nPart_no\\nSUPPLIER\\nQuantity\\nPROJECT\\nPART\\nProj_name\\n(b)\\n(c)\\nPart_no\\nPART\\nN\\nSname\\nSUPPLIER\\nProj_name\\nPROJECT\\nN\\nQuantity\\nSUPPLYN1\\nPart_no\\nM N\\nCAN_SUPPLY\\nN\\nM\\nSname\\nSUPPLIER\\nProj_name\\nPROJECT\\nUSES\\nPART\\nM\\nN\\nSUPPLIES\\nSP\\nSPJSS 1\\n1\\nFigure 3.17\\nTernary relationship types. (a) The SUPPLY relationship. (b) Three binary relationships not  \\nequivalent to SUPPLY. (c) SUPPLY represented as a weak entity type.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 103, 'page_label': '104'}, page_content='90 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\nSome database design tools are based on variations of the ER model that permit \\nonly binary relationships. In this case, a ternary relationship such as SUPPLY must \\nbe represented as a weak entity type, with no partial key and with three identifying \\nrelationships. The three participating entity types \\nSUPPLIER, PART, and PROJECT \\nare together the owner entity types (see Figure 3.17(c)). Hence, an entity in the \\nweak entity type \\nSUPPLY in Figure 3.17(c) is identified by the combination of its \\nthree owner entities from SUPPLIER, PART, and PROJECT.\\nIt is also possible to represent the ternary relationship as a regular entity type by \\nintroducing an artificial or surrogate key. In this example, a key attribute Supply_id \\ncould be used for the supply entity type, converting it into a regular entity type. \\nThree binary N:1 relationships relate \\nSUPPLY to each of the three participating \\nentity types.\\nAnother example is shown in Figure 3.18. The ternary relationship type OFFERS \\nrepresents information on instructors offering courses during particular semesters; \\nhence it includes a relationship instance ( i, s, c) whenever \\nINSTRUCTOR i offers \\nCOURSE c during SEMESTER s. The three binary relationship types shown in Fig-\\nure 3.18 have the following meanings: CAN_TEACH relates a course to the instruc-\\ntors who can teach that course, TAUGHT_DURING relates a semester to the instructors \\nwho taught some course  during that semester, and OFFERED_DURING  relates a \\nsemester to the courses offered during that semester by any instructor . These ter-\\nnary and binary relationships represent different information, but certain  \\nconstraints should hold among the relationships. For example, a relationship \\ninstance ( i, s, c) should not exist in \\nOFFERS unless an instance ( i, s) exists in \\nTAUGHT_DURING, an instance ( s, c) exists in OFFERED_DURING, and an instance  \\n(i, c) exists in CAN_TEACH . However, the reverse is not always true;  \\nwe may have instances ( i, s), (s, c), and (i, c) in the three binary relationship types \\nwith no corresponding instance ( i, s, c) in OFFERS. Note that in this example,  \\nbased on the meanings of the relationships, we can infer the instances of  \\nTAUGHT_DURING  and OFFERED_DURING  from the instances in OFFERS , but  \\nCnumber\\nCAN_TEACH\\nLname\\nINSTRUCTOR\\nSem_year\\nYearSemester\\nSEMESTER\\nOFFERED_DURING\\nCOURSE\\nOFFERS\\nTAUGHT_DURING\\nFigure 3.18\\nAnother example of \\nternary versus binary \\nrelationship types.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 104, 'page_label': '105'}, page_content='3.9 Relationship Types of Degree Higher than Two  91\\nwe cannot infer the instances of CAN_TEACH ; therefore, TAUGHT_DURING  and \\nOFFERED_DURING are redundant and can be left out.\\nAlthough in general three binary relationships cannot replace a ternary relation-\\nship, they may do so under certain additional constraints . In our example, if the \\nCAN_TEACH relationship is 1:1 (an instructor can teach only one course, and a \\ncourse can be taught by only one instructor), then the ternary relationship OFFERS \\ncan be left out because it can be inferred from the three binary relationships  \\nCAN_TEACH , TAUGHT_DURING , and OFFERED_DURING . The schema designer \\nmust analyze the meaning of each specific situation to decide which of the binary \\nand ternary relationship types are needed.\\nNotice that it is possible to have a weak entity type with a ternary (or n-ary) identi-\\nfying relationship type. In this case, the weak entity type can have several owner \\nentity types. An example is shown in Figure 3.19. This example shows part of a \\ndatabase that keeps track of candidates interviewing for jobs at various companies, \\nwhich may be part of an employment agency database. In the requirements, a can-\\ndidate can have multiple interviews with the same company (for example, with dif-\\nferent company departments or on separate dates), but a job offer is made based on \\none of the interviews. Here, \\nINTERVIEW is represented as a weak entity with two \\nowners CANDIDATE  and COMPANY , and with the partial key Dept_date . An  \\nINTERVIEW entity is uniquely identified by a candidate, a company, and the combi-\\nnation of the date and department of the interview.\\n3.9.2  Constraints on Ternary (or Higher-Degree)  \\nRelationships\\nThere are two notations for specifying structural constraints on n-ary relationships, \\nand they specify different constraints. They should thus both be used if it is impor-\\ntant to fully specify the structural constraints on a ternary or higher-degree rela-\\ntionship. The first notation is based on the cardinality ratio notation of binary \\nrelationships displayed in Figure 3.2. Here, a 1, M, or N is specified on each \\nDept_date\\nDateDepartment\\nRESULTS_IN\\nName\\nCANDIDATE\\nCname\\nCOMPANY\\nINTERVIEW JOB_OFFER\\nCCI\\nFigure 3.19\\nA weak entity type \\nINTERVIEW with a \\n ternary identifying \\n relationship type.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 105, 'page_label': '106'}, page_content='92 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\n participation arc (both M and N symbols stand for many or any number).15 Let us \\n illustrate this constraint using the SUPPLY relationship in Figure 3.17.\\nRecall that the relationship set of SUPPLY is a set of relationship instances ( s, j, p), \\nwhere s is a SUPPLIER, j is a PROJECT, and p is a PART. Suppose that the constraint \\nexists that for a particular project-part combination, only one supplier will be used \\n(only one supplier supplies a particular part to a particular project). In this case, we \\nplace 1 on the \\nSUPPLIER participation, and M, N on the PROJECT, PART participa-\\ntions in Figure 3.17. This specifies the constraint that a particular (j, p) combination \\ncan appear at most once in the relationship set because each such (PROJECT, PART) \\ncombination uniquely determines a single supplier. Hence, any relationship \\ninstance (s, j, p) is uniquely identified in the relationship set by its ( j, p) combina-\\ntion, which makes (j, p) a key for the relationship set. In this notation, the participa-\\ntions that have a 1 specified on them are not required to be part of the identifying \\nkey for the relationship set.\\n16 If all three cardinalities are M or N, then the key will \\nbe the combination of all three participants.\\nThe second notation is based on the (min, max) notation displayed in Figure 3.15 \\nfor binary relationships. A (min, max) on a participation here specifies that each \\nentity is related to at least min and at most max relationship instances  in the rela-\\ntionship set. These constraints have no bearing on determining the key of an n-ary \\nrelationship, where n > 2,17 but specify a different type of constraint that places \\nrestrictions on how many relationship instances each entity can participate in.\\n3.10 Another Example: A U NIVERSITY Database\\nWe now present another example, a UNIVERSITY database, to illustrate the ER \\nmodeling concepts. Suppose that a database is needed to keep track of student \\nenrollments in classes and students’ final grades. After analyzing the miniworld \\nrules and the users’ needs, the requirements for this database were determined to be \\nas follows (for brevity, we show the chosen entity type names and attribute names \\nfor the conceptual schema in parentheses as we describe the requirements; relation-\\nship type names are only shown in the ER schema diagram):\\n■ The university is organized into colleges (COLLEGE), and each college has a \\nunique name (CName), a main office (COffice) and phone (CPhone), and a \\nparticular faculty member who is dean of the college. Each college adminis-\\nters a number of academic departments (DEPT). Each department has a \\nunique name (DName), a unique code number (DCode), a main office \\n(DOffice) and phone (DPhone), and a particular faculty member who chairs \\nthe department. We keep track of the start date (CStartDate) when that fac-\\nulty member began chairing the department.\\n15This notation allows us to determine the key of the relationship relation, as we discuss in Chapter 9.\\n16This is also true for cardinality ratios of binary relationships.\\n17The (min, max) constraints can determine the keys for binary relationships.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 106, 'page_label': '107'}, page_content='3.10 Another Example: A UNIVERSITY Database  93\\n■ A department offers a number of courses (COURSE), each of which has a \\nunique course name (CoName), a unique code number (CCode), a course \\nlevel (Level: this can be coded as 1 for freshman level, 2 for sophomore, 3 for \\njunior, 4 for senior, 5 for MS level, and 6 for PhD level), a course credit \\nhours (Credits), and a course description (CDesc). The database also keeps \\ntrack of instructors (INSTRUCTOR); and each instructor has a unique iden-\\ntifier (Id), name (IName), office (IOffice), phone (IPhone), and rank (Rank); \\nin addition, each instructor works for one primary academic department.\\n■ The database will keep student data (STUDENT) and stores each student’s \\nname (SName, composed of first name (FName), middle name (MName), \\nlast name (LName)), student id (Sid, unique for every student), address \\n(Addr), phone (Phone), major code (Major), and date of birth (DoB). A stu-\\ndent is assigned to one primary academic department. It is required to keep \\ntrack of the student’s grades in each section the student has completed.\\n■ Courses are offered as sections (SECTION). Each section is related to a single \\ncourse and a single instructor and has a unique section identifier (SecId). A \\nsection also has a section number (SecNo: this is coded as 1, 2, 3, .\\xa0.\\xa0. for mul-\\ntiple sections offered during the same semester/year), semester (Sem), year \\n(Year), classroom (CRoom: this is coded as a combination of building code \\n(Bldg) and room number (RoomNo) within the building), and days/times \\n(DaysTime: for example, ‘MWF 9am-9.50am’ or ‘TR 3.30pm-5.20pm’—\\nrestricted to only allowed days/time values). ( Note: The database will keep \\ntrack of all the sections offered for the past several years, in addition to the \\ncurrent offerings. The SecId is unique for all sections, not just the sections for \\na particular semester.) The database keeps track of the students in each section, \\nand the grade is recorded when available (this is a many-to-many relationship \\nbetween students and sections). A section must have at least five students.\\nThe ER diagram for these requirements is shown in Figure 3.20 using the min-max ER \\ndiagrammatic notation. Notice that for the SECTION entity type, we only showed \\nSecID as an underlined key, but because of the miniworld constraints, several other \\ncombinations of values have to be unique for each section entity. For example, each of \\nthe following combinations must be unique based on the typical miniworld constraints:\\n \\n1. (SecNo, Sem, Year, CCode (of the COURSE related to the SECTION)): This \\nspecifies that the section numbers of a particular course must be different \\nduring each particular semester and year.\\n 2. (Sem, Year, CRoom, DaysTime): This specifies that in a particular semester \\nand year, a classroom cannot be used by two different sections at the same \\ndays/time.\\n 3. (Sem, Year, DaysTime, Id (of the INSTRUCTOR teaching the SECTION)): \\nThis specifies that in a particular semester and year, an instructor cannot \\nteach two sections at the same days/time. Note that this rule will not apply if \\nan instructor is allowed to teach two combined sections together in the par-\\nticular university.\\nCan you think of any other attribute combinations that have to be unique?'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 107, 'page_label': '108'}, page_content='94 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\nCOLLEGE\\nDEPT\\nCOURSE SECTION SecNoSECS\\nGrade\\nTAKES\\nSemYear\\nINSTRUCTOR\\nCOffice\\nTEACHES\\nADMINS\\nDEAN\\nMName\\nSName\\nAddr\\nPhone\\nMajor\\nDOB\\nFName\\nSTUDENT\\nLName\\nCHAIR\\nCStartDate\\nEMPLOYS\\nHAS\\n(1,1)\\n(1,1)\\n(1,1)\\n(1,1)\\n(1,1)\\n(1,1)\\n(1,1)\\n(0,N)\\n(0,N)\\n(0,N)\\n(0,N)\\n(0,N)\\n(0,N)\\n(0,N)\\n(0,1)\\n(0,1)\\n(0,1)\\n(5,N)\\nCName\\nDName\\nCCode SecId\\nIOffice\\nIName\\nRank\\nCPhone\\nDCode\\nDOffice\\nCoName\\nCredits\\nCDesc\\nLevel\\nDPhone\\nIPhoneId\\nSId\\nOFFERS\\nCRoom\\nBldg RoomNo\\nDaysTime\\nFigure 3.20\\nAn ER diagram for a UNIVERSITY database schema.\\n3.11 Summary\\nIn this chapter we presented the modeling concepts of a high-level conceptual data \\nmodel, the entity–relationship (ER) model. We started by discussing the role that a \\nhigh-level data model plays in the database design process, and then we presented a \\nsample set of database requirements for the COMPANY database, which is one of the'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 108, 'page_label': '109'}, page_content='3.11 Summary  95\\nexamples that is used throughout this text. We defined the basic ER model  concepts \\nof entities and their attributes. Then we discussed NULL values and presented the \\nvarious types of attributes, which can be nested arbitrarily to produce complex \\nattributes:\\n■ Simple or atomic\\n■ Composite\\n■ Multivalued\\nWe also briefly discussed stored versus derived attributes. Then we discussed the \\nER model concepts at the schema or “intension” level:\\n■ Entity types and their corresponding entity sets\\n■ Key attributes of entity types\\n■ Value sets (domains) of attributes\\n■ Relationship types and their corresponding relationship sets\\n■ Participation roles of entity types in relationship types\\nWe presented two methods for specifying the structural constraints on relationship \\ntypes. The first method distinguished two types of structural constraints:\\n■ Cardinality ratios (1:1, 1:N, M:N for binary relationships)\\n■ Participation constraints (total, partial)\\nWe noted that, alternatively, another method of specifying structural constraints is \\nto specify minimum and maximum numbers (min, max) on the participation of \\neach entity type in a relationship type. We discussed weak entity types and the \\nrelated concepts of owner entity types, identifying relationship types and partial key \\nattributes.\\nEntity–relationship schemas can be represented diagrammatically as ER diagrams. \\nWe showed how to design an ER schema for the \\nCOMPANY database by first defin-\\ning the entity types and their attributes and then refining the design to include rela-\\ntionship types. We displayed the ER diagram for the COMPANY database schema. \\nWe discussed some of the basic concepts of UML class diagrams and how they \\nrelate to ER modeling concepts. We also described ternary and higher-degree  \\nrelationship types in more detail, and we discussed the circumstances under which \\nthey are distinguished from binary relationships. Finally, we presented require-\\nments for a UNIVERSITY database schema as another example, and we showed the \\nER schema design.\\nThe ER modeling concepts we have presented thus far—entity types, relationship \\ntypes, attributes, keys, and structural constraints—can model many database appli-\\ncations. However, more complex applications—such as engineering design, medi-\\ncal information systems, and telecommunications—require additional concepts if \\nwe want to model them with greater accuracy. We discuss some advanced model-\\ning concepts in Chapter 8 and revisit further advanced data modeling techniques in \\nChapter 26.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 109, 'page_label': '110'}, page_content='96 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\nReview Questions\\n 3.1. Discuss the role of a high-level data model in the database design process.\\n 3.2. List the various cases where use of a NULL value would be appropriate.\\n 3.3. Define the following terms: entity, attribute, attribute value, relationship \\ninstance, composite attribute, multivalued attribute, derived attribute, com-\\nplex attribute, key attribute, and value set (domain).\\n 3.4. What is an entity type? What is an entity set? Explain the differences among \\nan entity, an entity type, and an entity set.\\n 3.5. Explain the difference between an attribute and a value set.\\n 3.6. What is a relationship type? Explain the differences among a relationship \\ninstance, a relationship type, and a relationship set.\\n 3.7. What is a participation role? When is it necessary to use role names in the \\ndescription of relationship types?\\n 3.8. Describe the two alternatives for specifying structural constraints on rela-\\ntionship types. What are the advantages and disadvantages of each?\\n 3.9. Under what conditions can an attribute of a binary relationship type be \\nmigrated to become an attribute of one of the participating entity types?\\n 3.10. When we think of relationships as attributes, what are the value sets of these \\nattributes? What class of data models is based on this concept?\\n 3.11. What is meant by a recursive relationship type? Give some examples of \\nrecursive relationship types.\\n 3.12. When is the concept of a weak entity used in data modeling? Define the \\nterms owner entity type, weak entity type, identifying relationship type,  and \\npartial key.\\n 3.13. Can an identifying relationship of a weak entity type be of a degree greater \\nthan two? Give examples to illustrate your answer.\\n 3.14. Discuss the conventions for displaying an ER schema as an ER diagram.\\n 3.15. Discuss the naming conventions used for ER schema diagrams.\\nExercises\\n 3.16. Which combinations of attributes have to be unique for each individual \\nSECTION entity in the \\nUNIVERSITY database shown in Figure 3.20 to enforce \\neach of the following miniworld constraints:\\n a. During a particular semester and year, only one section can use a particu-\\nlar classroom at a particular DaysTime value.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 110, 'page_label': '111'}, page_content='Exercises 97\\n b. During a particular semester and year, an instructor can teach only one \\nsection at a particular DaysTime value.\\n c. During a particular semester and year, the section numbers for sections \\noffered for the same course must all be different.\\n  Can you think of any other similar constraints?\\n 3.17. Composite and multivalued attributes can be nested to any number of lev-\\nels. Suppose we want to design an attribute for a STUDENT entity type to \\nkeep track of previous college education. Such an attribute will have one \\nentry for each college previously attended, and each such entry will be com-\\nposed of college name, start and end dates, degree entries (degrees awarded \\nat that college, if any), and transcript entries (courses completed at that col-\\nlege, if any). Each degree entry contains the degree name and the month and \\nyear the degree was awarded, and each transcript entry contains a course \\nname, semester, year, and grade. Design an attribute to hold this informa-\\ntion. Use the conventions in Figure 3.5.\\n 3.18. Show an alternative design for the attribute described in Exercise 3.17 that \\nuses only entity types (including weak entity types, if needed) and relation-\\nship types.\\n 3.19. Consider the ER diagram in Figure 3.21, which shows a simplified schema \\nfor an airline reservations system. Extract from the ER diagram the require-\\nments and constraints that produced this schema. Try to be as precise as \\npossible in your requirements and constraints specification.\\n 3.20. In Chapters 1 and 2, we discussed the database environment and database \\nusers. We can consider many entity types to describe such an environment, \\nsuch as DBMS, stored database, DBA, and catalog/data dictionary. Try to \\nspecify all the entity types that can fully describe a database system and its \\nenvironment; then specify the relationship types among them, and draw an \\nER diagram to describe such a general database environment.\\n 3.21. Design an ER schema for keeping track of information about votes taken in \\nthe U.S. House of Representatives during the current two-year congress-\\nional session. The database needs to keep track of each U.S.\\n STATE’s Name  \\n(e.g., ‘Texas’, ‘New York’, ‘California’) and include the Region of the state \\n(whose domain is {‘Northeast’, ‘Midwest’, ‘Southeast’, ‘Southwest’, ‘West’}). \\nEach \\nCONGRESS_PERSON in the House of Representatives is described by \\nhis or her Name, plus the District represented, the Start_date when the con-\\ngressperson was first elected, and the political Party to which he or she \\nbelongs (whose domain is {‘Republican’, ‘Democrat’, ‘Independent’, \\n‘Other’}). The database keeps track of each BILL (i.e., proposed law),  \\nincluding the Bill_name , the Date_of_vote  on the bill, whether the bill  \\nPassed_or_failed  (whose domain is {‘Yes’, ‘No’}), and the Sponsor  (the \\ncongressperson(s) who sponsored—that is, proposed—the bill). The data-\\nbase also keeps track of how each congressperson voted on each bill (domain'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 111, 'page_label': '112'}, page_content='98 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\nRestrictions\\nM\\nN\\nN\\n1\\nN\\nN\\n1\\n1N\\nAIRPORT\\nCity State\\nAIRPLANE_\\nTYPE\\nDep_time\\nArr_time\\nName\\nScheduled_dep_time\\nINSTANCE_OF\\nWeekdays\\nAirline\\nInstances\\nN\\n1\\n1 N\\nAirport_code\\nNumber\\nScheduled_arr_time\\nCAN_\\nLAND\\nTYPE\\nN\\n1\\nDEPARTS\\nN\\n1\\nARRIVES\\nN1 ASSIGNED\\nARRIVAL_\\nAIRPORT\\nDEPARTURE_\\nAIRPORT N1\\nSEAT\\nMax_seatsType_name\\nCode\\nAIRPLANE\\nAirplane_id Total_no_of_seats\\nLEGS\\nFLIGHT\\nFLIGHT_LEG\\nLeg_no\\nFARES\\nFARE\\nAmount\\nCphoneCustomer_name\\nDate\\nNo_of_avail_seats\\nRESERVATION\\nSeat_no\\nCompany\\nLEG_INSTANCE\\nNotes:\\nA LEG (segment) is a nonstop portion of a flight.\\nA LEG_INSTANCE is a particular occurrence \\n   of a LEG on a particular date.\\n      \\n1\\nFigure 3.21\\nAn ER diagram for an AIRLINE database schema.\\nof Vote attribute is {‘Yes’, ‘No’, ‘Abstain’, ‘Absent’}). Draw an ER schema \\ndiagram for this application. State clearly any assumptions you make.\\n 3.22. A database is being constructed to keep track of the teams and games of a \\nsports league. A team has a number of players, not all of whom participate in \\neach game. It is desired to keep track of the players participating in each \\ngame for each team, the positions they played in that game, and the result of'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 112, 'page_label': '113'}, page_content='Exercises 99\\nthe game. Design an ER schema diagram for this application, stating any \\nassumptions you make. Choose your favorite sport (e.g., soccer, baseball, \\nfootball).\\n 3.23. Consider the ER diagram shown in Figure 3.22 for part of a BANK database. \\nEach bank can have multiple branches, and each branch can have multiple \\naccounts and loans.\\n \\na. List the strong (nonweak) entity types in the ER diagram.\\n b. Is there a weak entity type? If so, give its name, partial key, and identify-\\ning relationship.\\n c. What constraints do the partial key and the identifying relationship of the \\nweak entity type specify in this diagram?\\n d. List the names of all relationship types, and specify the (min, max) \\n constraint on each participation of an entity type in a relationship type. \\nJustify your choices.\\nBANK \\nLOAN\\nBalance\\nType\\nAmountLoan_no\\n1\\nN\\n1\\nN\\nN\\nN\\nM M\\nNameCode\\n1N BANK_BRANCH\\nL_CA_C\\nACCTSL O A N S\\nBRANCHES\\nACCOUNT\\nCUSTOMER\\nAcct_no\\nName\\nAddrPhone\\nType\\nAddr Branch_noAddr\\nSsn\\nFigure 3.22\\nAn ER diagram for a BANK database schema.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 113, 'page_label': '114'}, page_content='100 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\n e. List concisely the user requirements that led to this ER schema design.\\n f. Suppose that every customer must have at least one account but is \\nrestricted to at most two loans at a time, and that a bank branch cannot \\nhave more than 1,000 loans. How does this show up on the (min, max) \\nconstraints?\\n 3.24. Consider the ER diagram in Figure 3.23. Assume that an employee may \\nwork in up to two departments or may not be assigned to any department. \\nAssume that each department must have one and may have up to three \\nphone numbers. Supply (min, max) constraints on this diagram. State clearly \\nany additional assumptions you make.  Under what conditions would the \\nrelationship \\nHAS_PHONE be redundant in this example?\\n 3.25. Consider the ER diagram in Figure 3.24. Assume that a course may or may \\nnot use a textbook, but that a text by definition is a book that is used in some \\ncourse. A course may not use more than five books. Instructors teach from \\ntwo to four courses. Supply (min, max) constraints on this diagram. State \\nclearly any additional assumptions you make.  If we add the relationship \\nADOPTS, to indicate the textbook(s) that an instructor uses for a course, \\nshould it be a binary relationship between INSTRUCTOR  and TEXT, or a  \\nternary relationship among all three entity types? What (min, max) con-\\nstraints would you put on the relationship? Why?\\nEMPLOYEE DEPART MENT\\nCONTAINSHAS_PHONE\\nWORKS_IN\\nPHONE\\nFigure 3.23\\nPart of an ER diagram \\nfor a COMPANY \\n database.\\nINSTRUCTOR COURSE\\nUSES\\nTEACHES\\nTEXT\\nFigure 3.24\\nPart of an ER diagram \\nfor a COURSES \\n database.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 114, 'page_label': '115'}, page_content='Exercises 101\\n 3.26. Consider an entity type SECTION in a UNIVERSITY database, which describes \\nthe section offerings of courses. The attributes of SECTION  are  \\nSection_number, Semester, Year, Course_number, Instructor, Room_no (where \\nsection is taught), Building (where section is taught), Weekdays (domain is \\nthe possible combinations of weekdays in which a section can be offered \\n{‘MWF’, ‘MW’, ‘TT’, and so on}), and \\nHours (domain is all possible  \\ntime periods during which sections are offered {‘9–9:50 a.m.’, ‘10–10:50 \\na.m.’, .\\xa0.\\xa0. , ‘3:30–4:50 p.m.’, ‘5:30–6:20 p.m.’, and so on}). Assume that  \\nSection_number  is unique for each course within a particular semes-\\nter/ year combination (that is, if a course is offered multiple times during \\na particular semester, its section offerings are numbered 1, 2, 3, and so \\non). There are several composite keys for section, and some attributes \\nare components of more than one key. Identify three composite keys, \\nand show how they can be represented in an ER schema diagram.\\n 3.27. Cardinality ratios often dictate the detailed design of a database. The cardi-\\nnality ratio depends on the real-world meaning of the entity types involved \\nand is defined by the specific application. For the following binary relation-\\nships, suggest cardinality ratios based on the common-sense meaning of the \\nentity types. Clearly state any assumptions you make.\\nEntity 1 Cardinality Ratio Entity 2\\n1. STUDENT ______________ SOCIAL_SECURITY_CARD\\n2. STUDENT ______________ TEACHER\\n3. CLASSROOM ______________ WALL\\n4. COUNTRY ______________ CURRENT_PRESIDENT\\n5. COURSE ______________ TEXTBOOK\\n6. ITEM (that can be found \\nin an order)\\n______________ ORDER\\n7. STUDENT ______________ CLASS\\n8. CLASS ______________ INSTRUCTOR\\n9. INSTRUCTOR ______________ OFFICE\\n10. EBAY_AUCTION_ITEM ______________ EBAY_BID\\n 3.28. Consider the ER schema for the MOVIES database in Figure 3.25.\\n  Assume that MOVIES is a populated database. ACTOR is used as a generic term \\nand includes actresses. Given the constraints shown in the ER schema, respond \\nto the following statements with True, False, or Maybe. Assign a response of \\nMaybe to statements that, although not explicitly shown to be True, cannot be \\nproven False based on the schema as shown. Justify each answer.\\n a. There are no actors in this database that have been in no movies.\\n b. There are some actors who have acted in more than ten movies.\\n c. Some actors have done a lead role in multiple movies.\\n d. A movie can have only a maximum of two lead actors.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 115, 'page_label': '116'}, page_content='102 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\n e. Every director has been an actor in some movie.\\n f. No producer has ever been an actor.\\n g. A producer cannot be an actor in some other movie.\\n h. There are movies with more than a dozen actors.\\n i. Some producers have been a director as well.\\n j. Most movies have one director and one producer.\\n k. Some movies have one director but several producers.\\n l. There are some actors who have done a lead role, directed a movie, and \\nproduced a movie.\\n m. No movie has a director who also acted in that movie.\\n 3.29. Given the ER schema for the MOVIES database in Figure 3.25, draw an \\ninstance diagram using three movies that have been released recently.  \\nDraw instances of each entity type: MOVIES , ACTORS , PRODUCERS ,  \\nDIRECTORS involved; make up instances of the relationships as they exist in \\nreality for those movies.\\nACTOR\\nMOVIE\\nLEAD_ROLE\\nPERFOR MS_IN\\nDIRECTSDIRECTOR\\nALSO_A_\\nDIRECTOR\\nPRODUCESPRODUCER\\nACTOR_\\nPRODUCER\\n1\\n1\\n1\\n1\\n1\\nM\\nM\\n2 N\\nN\\nN\\nN\\nFigure 3.25\\nAn ER diagram for a MOVIES database schema.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 116, 'page_label': '117'}, page_content='Laboratory Exercises 103\\n 3.30. Illustrate the UML diagram for Exercise 3.16. Your UML design should \\nobserve the following requirements:\\n a. A student should have the ability to compute his/her GPA and add or \\ndrop majors and minors.\\n b. Each department should be able to add or delete courses and hire or ter-\\nminate faculty.\\n c. Each instructor should be able to assign or change a student’s grade for a \\ncourse.\\n  Note: Some of these functions may be spread over multiple classes.\\nLaboratory Exercises\\n 3.31. Consider the UNIVERSITY database described in Exercise 3.16. Build the ER \\nschema for this database using a data modeling tool such as ERwin or  \\nRational Rose.\\n 3.32. Consider a MAIL_ORDER database in which employees take orders for parts \\nfrom customers. The data requirements are summarized as follows:\\n■ The mail order company has employees, each identified by a unique em-\\nployee number, first and last name, and Zip Code.\\n■ Each customer of the company is identified by a unique customer number, \\nfirst and last name, and Zip Code.\\n■ Each part sold by the company is identified by a unique part number, a \\npart name, price, and quantity in stock.\\n■ Each order placed by a customer is taken by an employee and is given a \\nunique order number. Each order contains specified quantities of one or \\nmore parts. Each order has a date of receipt as well as an expected ship \\ndate. The actual ship date is also recorded.\\n  Design an entity–relationship diagram for the mail order database and build \\nthe design using a data modeling tool such as ERwin or Rational Rose.\\n 3.33. Consider a MOVIE database in which data is recorded about the movie  \\nindustry. The data requirements are summarized as follows:\\n■ Each movie is identified by title and year of release. Each movie has a \\nlength in minutes. Each has a production company, and each is classified \\nunder one or more genres (such as horror, action, drama, and so forth). \\nEach movie has one or more directors and one or more actors appear in it. \\nEach movie also has a plot outline. Finally, each movie has zero or more \\nquotable quotes, each of which is spoken by a particular actor appearing \\nin the movie.\\n■ Actors are identified by name and date of birth and appear in one or more \\nmovies. Each actor has a role in the movie.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 117, 'page_label': '118'}, page_content='104 Chapter 3 Data Modeling Using the Entity–Relationship (ER) Model\\n■ Directors are also identified by name and date of birth and direct one or \\nmore movies. It is possible for a director to act in a movie (including one \\nthat he or she may also direct).\\n■ Production companies are identified by name and each has an address. A \\nproduction company produces one or more movies.\\n  Design an entity–relationship diagram for the movie database and enter the \\ndesign using a data modeling tool such as ERwin or Rational Rose.\\n 3.34. Consider a CONFERENCE_REVIEW  database in which researchers submit \\ntheir research papers for consideration. Reviews by reviewers are recorded \\nfor use in the paper selection process. The database system caters primarily \\nto reviewers who record answers to evaluation questions for each paper they \\nreview and make recommendations regarding whether to accept or reject \\nthe paper. The data requirements are summarized as follows:\\n■ Authors of papers are uniquely identified by e-mail id. First and last names \\nare also recorded.\\n■ Each paper is assigned a unique identifier by the system and is described \\nby a title, abstract, and the name of the electronic file containing the paper.\\n■ A paper may have multiple authors, but one of the authors is designated as \\nthe contact author.\\n■ Reviewers of papers are uniquely identified by e-mail address. Each re-\\nviewer’s first name, last name, phone number, affiliation, and topics of in-\\nterest are also recorded.\\n■ Each paper is assigned between two and four reviewers. A reviewer rates \\neach paper assigned to him or her on a scale of 1 to 10 in four categories: \\ntechnical merit, readability, originality, and relevance to the conference. \\nFinally, each reviewer provides an overall recommendation regarding \\neach paper.\\n■ Each review contains two types of written comments: one to be seen by \\nthe review committee only and the other as feedback to the author(s).\\n  Design an entity–relationship diagram for the CONFERENCE_REVIEW data-\\nbase and build the design using a data modeling tool such as ERwin or \\nRational Rose.\\n 3.35. Consider the ER diagram for the AIRLINE database shown in Figure 3.21. \\nBuild this design using a data modeling tool such as ERwin or Rational Rose.\\nSelected Bibliography\\nThe entity–relationship model was introduced by Chen (1976), and related work \\nappears in Schmidt and Swenson (1975), Wiederhold and Elmasri (1979), and \\nSenko (1975). Since then, numerous modifications to the ER model have been \\n suggested. We have incorporated some of these in our presentation. Structural'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 118, 'page_label': '119'}, page_content='Selected Bibliography 105\\n constraints on relationships are discussed in Abrial (1974), Elmasri and Wieder-\\nhold (1980), and Lenzerini and Santucci (1983). Multivalued and composite attri-\\nbutes are incorporated in the ER model in Elmasri et al. (1985). Although we did \\nnot discuss languages for the ER model and its extensions, there have been several \\nproposals for such languages. Elmasri and Wiederhold (1981) proposed the  \\nGORDAS query language for the ER model. Another ER query language was pro-\\nposed by Markowitz and Raz (1983). Senko (1980) presented a query language for \\nSenko’s DIAM model. A formal set of operations called the ER algebra was \\n presented by Parent and Spaccapietra (1985). Gogolla and Hohenstein (1991) pre-\\nsented another formal language for the ER model. Campbell et al. (1985) presented \\na set of ER operations and showed that they are relationally complete. A conference \\nfor the dissemination of research results related to the ER model has been held reg-\\nularly since 1979. The conference, now known as the International Conference on \\nConceptual Modeling, has been held in Los Angeles (ER 1979, ER 1983, ER 1997), \\nWashington, D.C. (ER 1981), Chicago (ER 1985), Dijon, France (ER 1986), New \\nYork City (ER 1987), Rome (ER 1988), Toronto (ER 1989), Lausanne, Switzerland \\n(ER 1990), San Mateo, California (ER 1991), Karlsruhe, Germany (ER 1992), \\nArlington, Texas (ER 1993), Manchester, England (ER 1994), Brisbane, Australia \\n(ER 1995), Cottbus, Germany (ER 1996), Singapore (ER 1998), Paris, France (ER \\n1999), Salt Lake City, Utah (ER 2000), Yokohama, Japan (ER 2001), Tampere, Fin-\\nland (ER 2002), Chicago, Illinois (ER 2003), Shanghai, China (ER 2004), Klagen-\\nfurt, Austria (ER 2005), Tucson, Arizona (ER 2006), Auckland, New Zealand (ER \\n2007), Barcelona, Catalonia, Spain (ER 2008), and Gramado, RS, Brazil (ER 2009). \\nThe 2010 conference was held in Vancouver, British Columbia, Canada (ER2010), \\n2011 in Brussels, Belgium (ER2011), 2012 in Florence, Italy (ER2012) , 2013 in \\nHong Kong, China (ER2013), and the 2014 conference was held in Atlanta, Georgia \\n(ER 2014). The 2015 conference is to be held in Stockholm, Sweden.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 119, 'page_label': '120'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 120, 'page_label': '121'}, page_content='107\\n4\\nThe Enhanced Entity–Relationship \\n(EER) Model\\nT\\nhe ER modeling concepts discussed in Chapter 3 \\nare sufficient for representing many database sche-\\nmas for traditional  database applications, which include many data-processing \\napplications in business and industry. Since the late 1970s, however, designers of \\ndatabase applications have tried to design more accurate database schemas that \\nreflect the data properties and constraints more precisely. This was particularly \\nimportant for newer applications of database technology, such as databases for \\nengineering design and manufacturing (CAD/CAM),\\n1 telecommunications, com-\\nplex software systems, and geographic information systems (GISs), among many \\nother applications. These types of databases have requirements that are more com-\\nplex than the more traditional applications. This led to the development of addi-\\ntional semantic data modeling  concepts that were incorporated into conceptual \\ndata models such as the ER model. Various semantic data models have been pro-\\nposed in the literature. Many of these concepts were also developed independently \\nin related areas of computer science, such as the knowledge representation area of \\nartificial intelligence and the object modeling area in software engineering.\\nIn this chapter, we describe features that have been proposed for semantic data \\nmodels and show how the ER model can be enhanced to include these concepts, \\nwhich leads to the enhanced ER (EER) model.\\n2 We start in Section 4.1 by incorpo-\\nrating the concepts of class/subclass relationships and type inheritance into the ER \\nmodel. Then, in Section 4.2, we add the concepts of specialization and generalization. \\nSection 4.3 discusses the various types of constraints on specialization/generalization, \\nand Section 4.4 shows how the UNION construct can be modeled by including the \\nchapter 4\\n1CAD/CAM stands for computer-aided design/computer-aided manufacturing.\\n2EER has also been used to stand for extended ER model.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 121, 'page_label': '122'}, page_content='108 Chapter 4 The Enhanced Entity–Relationship (EER) Model\\nconcept of category  in the EER model. Section 4.5 gives a sample UNIVERSITY \\ndatabase schema in the EER model and summarizes the EER model concepts by \\ngiving formal definitions. We will use the terms object and entity interchangeably \\nin this chapter, because many of these concepts are commonly used in object-\\noriented models.\\nWe present the UML class diagram notation for representing specialization and \\ngeneralization in Section 4.6, and we briefly compare these with EER notation and \\nconcepts. This serves as an example of alternative notation, and is a continuation \\nof Section 3.8, which presented basic UML class diagram notation that corre-\\nsponds to the basic ER model. In Section 4.7, we discuss the fundamental abstrac-\\ntions that are used as the basis of many semantic data models. Section 4.8 \\nsummarizes the chapter.\\nFor a detailed introduction to conceptual modeling, Chapter 4 should be consid-\\nered a continuation of Chapter 3. However, if only a basic introduction to ER mod-\\neling is desired, this chapter may be omitted. Alternatively, the reader may choose \\nto skip some or all of the later sections of this chapter (Sections 4.4 through 4.8).\\n4.1 Subclasses, Superclasses, and Inheritance\\nThe EER model includes all the modeling concepts of the ER model  that were pre-\\nsented in Chapter 3. In addition, it includes the concepts of subclass and superclass \\nand the related concepts of specialization  and generalization  (see Sections 4.2  \\nand 4.3). Another concept included in the EER model is that of a category or union \\ntype (see Section 4.4), which is used to represent a collection of objects (entities) \\nthat is the union of objects of different entity types. Associated with these concepts \\nis the important mechanism of attribute and relationship inheritance . Unfortu-\\nnately, no standard terminology exists for these concepts, so we use the most com-\\nmon terminology. Alternative terminology is given in footnotes. We also describe a \\ndiagrammatic technique for displaying these concepts when they arise in an EER \\nschema. We call the resulting schema diagrams enhanced ER or EER diagrams.\\nThe first enhanced ER (EER) model concept we take up is that of a subtype or  \\nsubclass of an entity type. As we discussed in Chapter 3, the name of an entity type is \\nused to represent both a type of entity and the entity set or collection of entities of that \\ntype that exist in the database. For example, the entity type \\nEMPLOYEE describes the \\ntype (that is, the attributes and relationships) of each employee entity, and also refers \\nto the current set of EMPLOYEE entities in the COMPANY database. In many cases an \\nentity type has numerous subgroupings or subtypes of its entities that are meaningful \\nand need to be represented explicitly because of their significance to the database \\napplication. For example, the entities that are members of the EMPLOYEE  entity \\ntype may be distinguished further into SECRETARY , ENGINEER , MANAGER , \\nTECHNICIAN, SALARIED_EMPLOYEE , HOURLY_EMPLOYEE , and so on. The set or \\ncollection of entities in each of the latter groupings is a subset of the entities that \\nbelong to the EMPLOYEE entity set, meaning that every entity that is a member of \\none of these subgroupings is also an employee. We call each of these subgroupings a'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 122, 'page_label': '123'}, page_content='4.1 Subclasses, Superclasses, and Inheritance  109\\nsubclass or subtype of the EMPLOYEE entity type, and the EMPLOYEE entity type is \\ncalled the superclass or supertype for each of these subclasses. Figure 4.1 shows how \\nto represent these concepts diagramatically in EER diagrams. (The circle notation in \\nFigure 4.1 will be explained in Section 4.2.)\\nWe call the relationship between a superclass and any one of its subclasses a  \\nsuperclass/subclass or supertype/subtype or simply class/subclass relationship .\\n3 \\nIn our previous example, EMPLOYEE/SECRETARY  and EMPLOYEE/TECHNICIAN  \\nare two class/subclass relationships. Notice that a member entity of the subclass \\nrepresents the same real-world entity  as some member of the superclass; for \\nexample, a \\nSECRETARY entity ‘Joan Logano’ is also the EMPLOYEE ‘Joan Logano.’ \\nHence, the subclass member is the same as the entity in the superclass, but in a \\ndistinct specific role.  When we implement a superclass/subclass relationship in \\nthe database system, however, we may represent a member of the subclass as a \\ndistinct database object—say, a distinct record that is related via the key attribute \\nto its superclass entity. In Section 9.2, we discuss various options for representing \\nsuperclass/subclass relationships in relational databases.\\nAn entity cannot exist in the database merely by being a member of a subclass; it \\nmust also be a member of the superclass. Such an entity can be included optionally \\n3A class/subclass relationship is often called an IS-A (or IS-AN) relationship because of the way we \\nrefer to the concept. We say a SECRETARY is an EMPLOYEE, a TECHNICIAN is an EMPLOYEE, and \\nso on.\\nMANAGES\\nd\\nMinit Lname\\nName Birth_date AddressSsn\\nFname\\nEng_typeTgradeTyping_speed Pay_scale\\nHOURL Y_EMPLOYEE\\nSALARIED_E MPLOYEE\\nSalary\\nPROJECT\\nSECRETARY TECHNICIAN ENGINEER MANAGER\\nEMPLOYEE\\nTRADE_UNION\\nBELONGS_TO\\nd\\nThree specializations of EMPLOYEE:\\n{SECRETARY, TECHNICIAN, ENGINEER}\\n{MANAGER}\\n{HOURL Y_EMPLOYEE, SALARIED_EMPLOYEE}\\nFigure 4.1 \\nEER diagram  \\nnotation to represent \\nsubclasses and  \\nspecialization.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 123, 'page_label': '124'}, page_content='110 Chapter 4 The Enhanced Entity–Relationship (EER) Model\\nas a member of any number of subclasses. For example, a salaried employee who is \\nalso an engineer belongs to the two subclasses ENGINEER and SALARIED_EMPLOYEE \\nof the EMPLOYEE entity type. However, it is not necessary that every entity in a \\nsuperclass is a member of some subclass.\\nAn important concept associated with subclasses (subtypes) is that of type  \\ninheritance. Recall that the type of an entity is defined by the attributes it possesses \\nand the relationship types in which it participates. Because an entity in the subclass \\nrepresents the same real-world entity from the superclass, it should possess values \\nfor its specific attributes as well as values of its attributes as a member of the super-\\nclass. We say that an entity that is a member of a subclass inherits all the attributes of \\nthe entity as a member of the superclass. The entity also inherits all the relationships \\nin which the superclass participates. Notice that a subclass, with its own specific (or \\nlocal) attributes and relationships together with all the attributes and relationships it \\ninherits from the superclass, can be considered an entity type in its own right.\\n4\\n4.2 Specialization and Generalization\\n4.2.1 Specialization\\nSpecialization is the process of defining a set of subclasses  of an entity type; this \\nentity type is called the superclass of the specialization. The set of subclasses that \\nforms a specialization is defined on the basis of some distinguishing characteristic \\nof the entities in the superclass. For example, the set of subclasses \\n{SECRETARY, \\nENGINEER, TECHNICIAN}  is a specialization of the superclass EMPLOYEE that dis-\\ntinguishes among employee entities based on the job type  of each employee.  \\nWe may have several specializations of the same entity type based on different \\ndistinguishing characteristics. For example, another specialization of the \\nEMPLOYEE  entity type may yield the set of subclasses {SALARIED_EMPLOYEE,  \\nHOURLY_EMPLOYEE}; this specialization distinguishes among employees based on \\nthe method of pay.\\nFigure 4.1 shows how we represent a specialization diagrammatically in an EER \\ndiagram. The subclasses that define a specialization are attached by lines to a circle \\nthat represents the specialization, which is connected in turn to the superclass. The \\nsubset symbol on each line connecting a subclass to the circle indicates the direction \\nof the superclass/subclass relationship.\\n5 Attributes that apply only to entities of a \\nparticular subclass—such as TypingSpeed of SECRETARY—are attached to the rect-\\nangle representing that subclass. These are called specific (or local) attributes of \\nthe subclass. Similarly, a subclass can participate in specific relationship types , \\nsuch as the HOURLY_EMPLOYEE  subclass participating in the BELONGS_TO  \\n4In some object-oriented programming languages, a common restriction is that an entity (or object) has \\nonly one type. This is generally too restrictive for conceptual database modeling.\\n5There are many alternative notations for specialization; we present the UML notation in Section 4.6 and \\nother proposed notations in Appendix A.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 124, 'page_label': '125'}, page_content='4.2 Specialization and Generalization  111\\nrelationship in Figure 4.1. We will explain the d symbol in the circles in Figure 4.1 \\nand additional EER diagram notation shortly.\\nFigure 4.2 shows a few entity instances that belong to subclasses of the {SECRETARY, \\nENGINEER, TECHNICIAN} specialization. Again, notice that an entity that belongs to \\na subclass represents the same real-world entity  as the entity connected to it in the \\nEMPLOYEE superclass, even though the same entity is shown twice; for example, e1 \\nis shown in both EMPLOYEE and SECRETARY in Figure 4.2. As the figure suggests, \\na superclass/subclass relationship such as EMPLOYEE/SECRETARY  somewhat \\nresembles a 1:1 relationship at the instance level (see Figure 3.12). The main differ-\\nence is that in a 1:1 relationship two distinct entities are related, whereas in a super-\\nclass/subclass relationship the entity in the subclass is the same real-world entity as \\nthe entity in the superclass but is playing a specialized role— for example, an \\nEMPLOYEE specialized in the role of SECRETARY, or an EMPLOYEE specialized in \\nthe role of TECHNICIAN.\\nThere are two main reasons for including class/subclass relationships and special-\\nizations. The first is that certain attributes may apply to some but not all entities of \\nEMPLOYEE\\nSECRETARY\\nENGINEER\\nTECHNICIAN\\ne1\\ne2\\ne3\\ne4\\ne5\\ne6\\ne7\\ne8\\ne1\\ne2\\ne3\\ne4\\ne5\\ne7\\ne8\\nFigure 4.2 \\nInstances of a specialization.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 125, 'page_label': '126'}, page_content='112 Chapter 4 The Enhanced Entity–Relationship (EER) Model\\nthe superclass entity type. A subclass is defined in order to group the entities to \\nwhich these attributes apply. The members of the subclass may still share the \\nmajority of their attributes with the other members of the superclass. For example, \\nin Figure 4.1 the \\nSECRETARY  subclass has the specific attribute Typing_speed , \\nwhereas the ENGINEER  subclass has the specific attribute Eng_type , but  \\nSECRETARY  and ENGINEER  share their other inherited attributes from the \\nEMPLOYEE entity type.\\nThe second reason for using subclasses is that some relationship types may be par-\\nticipated in only by entities that are members of the subclass. For example, if only \\nHOURLY_EMPLOYEES can belong to a trade union, we can represent that fact by \\ncreating the subclass HOURLY_EMPLOYEE of EMPLOYEE and relating the subclass \\nto an entity type TRADE_UNION via the BELONGS_TO relationship type, as illus-\\ntrated in Figure 4.1.\\n4.2.2 Generalization\\nWe can think of a reverse process of abstraction in which we suppress the differences \\namong several entity types, identify their common features, and generalize them \\ninto a single superclass of which the original entity types are special subclasses. For \\nexample, consider the entity types CAR and TRUCK shown in Figure 4.3(a). Because \\nthey have several common attributes, they can be generalized into the entity type \\nVEHICLE, as shown in Figure 4.3(b). Both CAR and TRUCK are now subclasses of the \\n(a)\\n(b)\\nMax_speed\\nVehicle_id\\nNo_of_passengers\\nLicense_plate_no\\nCAR Price Price\\nLicense_plate_no\\nNo_of_axles\\nVehicle_id\\nTonnage\\nTRUCK\\nVehicle_id Price License_plate_no\\nVEHICLE\\nNo_of_passengers\\nMax_speed\\nCAR TRUCK\\nNo_of_axles\\nTonnage\\nd\\nFigure 4.3 \\nGeneralization. (a) Two entity types, CAR and TRUCK.  \\n(b) Generalizing CAR and TRUCK into the superclass VEHICLE.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 126, 'page_label': '127'}, page_content='4.3 Constraints and Characteristics of Specialization and Generalization Hierarchies  113\\ngeneralized superclass VEHICLE. We use the term generalization to refer to the pro-\\ncess of defining a generalized entity type from the given entity types.\\nNotice that the generalization process can be viewed as being functionally the \\ninverse of the specialization process; we can view {CAR, TRUCK} as a specialization \\nof VEHICLE rather than viewing VEHICLE as a generalization of CAR and TRUCK. A \\ndiagrammatic notation to distinguish between generalization and specialization is \\nused in some design methodologies. An arrow pointing to the generalized super-\\nclass represents a generalization process, whereas arrows pointing to the special-\\nized subclasses represent a specialization process. We will not use this notation \\nbecause the decision as to which process was followed in a particular situation is \\noften subjective.\\nSo far we have introduced the concepts of subclasses and superclass/subclass rela-\\ntionships, as well as the specialization and generalization processes. In general, a \\nsuperclass or subclass represents a collection of entities of the same type and hence \\nalso describes an entity type; that is why superclasses and subclasses are all shown in \\nrectangles in EER diagrams, like entity types.\\n4.3  Constraints and Characteristics  \\nof Specialization and Generalization \\nHierarchies\\nFirst, we discuss constraints that apply to a single specialization or a single general-\\nization. For brevity, our discussion refers only to specialization  even though it \\napplies to both specialization and generalization. Then, we discuss differences \\nbetween specialization/generalization lattices (multiple inheritance) and hierarchies \\n(single inheritance), and we elaborate on the differences between the specialization \\nand generalization processes during conceptual database schema design.\\n4.3.1 Constraints on Specialization and Generalization\\nIn general, we may have several specializations defined on the same entity type (or \\nsuperclass), as shown in Figure 4.1. In such a case, entities may belong to subclasses \\nin each of the specializations. A specialization may also consist of a single subclass \\nonly, such as the \\n{MANAGER} specialization in Figure 4.1; in such a case, we do not \\nuse the circle notation.\\nIn some specializations we can determine exactly the entities that will become \\nmembers of each subclass by placing a condition on the value of some attribute of \\nthe superclass. Such subclasses are called predicate-defined (or condition-defined) \\nsubclasses. For example, if the EMPLOYEE entity type has an attribute Job_type, as \\nshown in Figure 4.4, we can specify the condition of membership in the  \\nSECRETARY subclass by the condition ( Job_type = ‘Secretary’), which we call the \\ndefining predicate of the subclass. This condition is a constraint specifying that \\nexactly those entities of the EMPLOYEE entity type whose attribute value for Job_type'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 127, 'page_label': '128'}, page_content='114 Chapter 4 The Enhanced Entity–Relationship (EER) Model\\nis ‘Secretary’ belong to the subclass. We display a predicate-defined subclass by \\nwriting the predicate condition next to the line that connects the subclass to the \\nspecialization circle.\\nIf all subclasses in a specialization have their membership condition on the same \\nattribute of the superclass, the specialization itself is called an attribute-defined \\nspecialization , and the attribute is called the defining attribute  of the special-\\nization.\\n6 In this case, all the entities with the same value for the attribute belong to \\nthe same subclass. We display an attribute-defined specialization by placing the \\ndefining attribute name next to the arc from the circle to the superclass, as shown \\nin Figure 4.4.\\nWhen we do not have a condition for determining membership in a subclass, the \\nsubclass is called user-defined. Membership in such a subclass is determined by the \\ndatabase users when they apply the operation to add an entity to the subclass; hence, \\nmembership is specified individually for each entity by the user , not by any condi-\\ntion that may be evaluated automatically.\\nTwo other constraints may apply to a specialization. The first is the disjointness \\nconstraint, which specifies that the subclasses of the specialization must be disjoint \\nsets. This means that an entity can be a member of at most one of the subclasses of \\nthe specialization. A specialization that is attribute-defined implies the disjointness \\nconstraint (if the attribute used to define the membership predicate is single- \\nvalued). Figure 4.4 illustrates this case, where the d in the circle stands for disjoint. The \\nd notation also applies to user-defined subclasses of a specialization that must be \\ndisjoint, as illustrated by the specialization \\n{HOURLY_EMPLOYEE, SALARIED_EMPLOYEE} \\nin Figure 4.1. If the subclasses are not constrained to be disjoint, their sets of entities \\n6Such an attribute is called a discriminator or discriminating attribute in UML terminology.\\nd\\nMinit Lname\\nName Birth_date Address Job_typeSsn\\nFname\\nEng_typeTgrade ‘Technician’\\nJob_type\\n‘Secretary’ ‘Engineer’\\nTyping_speed\\nSECRETARY TECHNICIAN ENGINEER\\nEMPLOYEE\\nFigure 4.4 \\nEER diagram notation \\nfor an attribute-defined \\nspecialization on  \\nJob_type.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 128, 'page_label': '129'}, page_content='4.3 Constraints and Characteristics of Specialization and Generalization Hierarchies  115\\nmay be overlapping; that is, the same (real-world) entity may be a member of more \\nthan one subclass of the specialization. This case, which is the default, is displayed \\nby placing an o in the circle, as shown in Figure 4.5.\\nThe second constraint on specialization is called the completeness (or totalness) \\nconstraint, which may be total or partial. A total specialization constraint specifies \\nthat every entity in the superclass must be a member of at least one subclass  \\nin the specialization. For example, if every \\nEMPLOYEE  must be either an  \\nHOURLY_EMPLOYEE  or a SALARIED_EMPLOYEE , then the specialization  \\n{HOURLY_EMPLOYEE, SALARIED_EMPLOYEE} in Figure 4.1 is a total specialization \\nof EMPLOYEE. This is shown in EER diagrams by using a double line to connect \\nthe superclass to the circle. A single line is used to display a partial specialization, \\nwhich allows an entity not to belong to any of the subclasses. For example, if some \\nEMPLOYEE entities do not belong to any of the subclasses {SECRETARY, ENGINEER, \\nTECHNICIAN} in Figures 4.1 and 4.4, then that specialization is partial.7\\nNotice that the disjointness and completeness constraints are independent. Hence, \\nwe have the following four possible constraints on a specialization:\\n ■ Disjoint, total\\n ■ Disjoint, partial\\n ■ Overlapping, total\\n ■ Overlapping, partial\\nOf course, the correct constraint is determined from the real-world meaning that \\napplies to each specialization. In general, a superclass that was identified through \\nthe generalization process usually is total, because the superclass is derived from the \\nsubclasses and hence contains only the entities that are in the subclasses.\\nCertain insertion and deletion rules apply to specialization (and generalization) as a \\nconsequence of the constraints specified earlier. Some of these rules are as follows:\\n ■ Deleting an entity from a superclass implies that it is automatically deleted \\nfrom all the subclasses to which it belongs.\\n7The notation of using single or double lines is similar to that for partial or total participation of an entity \\ntype in a relationship type, as described in Chapter 3.\\nPart_no Description\\nPARTManufacture_date\\nDrawing_no\\nPURCHASED_PART\\nSupplier_name\\nBatch_no\\nList_price\\no\\nMANUFACTURED_PART\\nFigure 4.5 \\nEER diagram notation \\nfor an overlapping  \\n(nondisjoint)  \\nspecialization.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 129, 'page_label': '130'}, page_content='116 Chapter 4 The Enhanced Entity–Relationship (EER) Model\\n ■ Inserting an entity in a superclass implies that the entity is mandatorily \\ninserted in all predicate-defined (or attribute-defined) subclasses for which \\nthe entity satisfies the defining predicate.\\n ■ Inserting an entity in a superclass of a total specialization  implies that \\nthe entity is mandatorily inserted in at least one of the subclasses of the \\nspecialization.\\nThe reader is encouraged to make a complete list of rules for insertions and dele-\\ntions for the various types of specializations.\\n4.3.2  Specialization and Generalization Hierarchies  \\nand Lattices\\nA subclass itself may have further subclasses specified on it, forming a hierarchy or \\na lattice of specializations. For example, in Figure 4.6 ENGINEER is a subclass of \\nEMPLOYEE and is also a superclass of ENGINEERING_MANAGER; this represents the \\nreal-world constraint that every engineering manager is required to be an engineer. \\nA specialization hierarchy has the constraint that every subclass participates as a \\nsubclass in only one class/subclass relationship; that is, each subclass has only one \\nparent, which results in a tree structure  or strict hierarchy . In contrast, for a  \\nspecialization lattice, a subclass can be a subclass in more than one class/subclass \\nrelationship. Hence, Figure 4.6 is a lattice.\\nFigure 4.7 shows another specialization lattice of more than one level. This may \\nbe part of a conceptual schema for a \\nUNIVERSITY  database. Notice that this \\narrangement would have been a hierarchy except for the STUDENT_ASSISTANT  \\nsubclass, which is a subclass in two distinct class/subclass relationships.\\nd\\nHOURL Y_EMPLOYEE\\nSALARIED_E MPLOYEE\\nENGINEERING_ MANAGER\\nSECRETARY TECHNICIAN ENGINEER MANAGER\\nEMPLOYEE\\nd\\nFigure 4.6 \\nA specialization lattice with shared subclass \\nENGINEERING_MANAGER.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 130, 'page_label': '131'}, page_content='4.3 Constraints and Characteristics of Specialization and Generalization Hierarchies  117\\nThe requirements for the part of the UNIVERSITY  database shown in Figure 4.7 \\nare the following:\\n  1. The database keeps track of three types of persons: employees, alumni, and \\nstudents. A person can belong to one, two, or all three of these types. Each \\nperson has a name, SSN, sex, address, and birth date.\\n  2. Every employee has a salary, and there are three types of employees: fac-\\nulty, staff, and student assistants. Each employee belongs to exactly one \\nof these types. For each alumnus, a record of the degree or degrees that \\nhe or she earned at the university is kept, including the name of the \\ndegree, the year granted, and the major department. Each student has a \\nmajor department.\\n  3. Each faculty has a rank, whereas each staff member has a staff position. Stu-\\ndent assistants are classified further as either research assistants or teaching \\nassistants, and the percent of time that they work is recorded in the database. \\nResearch assistants have their research project stored, whereas teaching \\nassistants have the current course they work on.\\nSTAFF\\nPercent_time\\nFACULTY\\nName Sex Address\\nPERSON\\nSalary\\nEMPLOYEE\\nMajor_dept\\nBirth_date\\nALUMNUS\\nd\\no\\nSTUDENT_\\nASSISTANT\\nSTUDENT\\nDegrees\\nDegreeYear Major\\nGRADUATE_\\nSTUDENT\\nd\\nUNDERGRADUATE_\\nSTUDENT\\nRESEARCH_ASSISTANT\\nd\\nTEACHING_ASSISTANT\\nPosition Rank Degree_program Class\\nCourseProject\\nSsn\\nFigure 4.7 \\nA specialization lattice  \\nwith multiple inheritance  \\nfor a UNIVERSITY  \\ndatabase.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 131, 'page_label': '132'}, page_content='118 Chapter 4 The Enhanced Entity–Relationship (EER) Model\\n  4. Students are further classified as either graduate or undergraduate, with \\nthe specific attributes degree program (M.S., Ph.D., M.B.A., and so on) \\nfor graduate students and class (freshman, sophomore, and so on) for \\nundergraduates.\\nIn Figure 4.7, all person entities represented in the database are members of \\nthe \\nPERSON  entity type, which is specialized into the subclasses {EMPLOYEE, \\nALUMNUS, STUDENT} . This specialization is overlapping; for example, an alum-\\nnus may also be an employee and a student pursuing an advanced degree. The \\nsubclass \\nSTUDENT  is the superclass for the specialization {GRADUATE_STUDENT, \\nUNDERGRADUATE_STUDENT} , whereas EMPLOYEE is the superclass for the \\nspecialization {STUDENT_ASSISTANT, FACULTY, STAFF} . Notice that  \\nSTUDENT_ASSISTANT is also a subclass of STUDENT. Finally, STUDENT_ASSISTANT \\nis the superclass for the specialization into {RESEARCH_ASSISTANT,  \\nTEACHING_ASSISTANT} .\\nIn such a specialization lattice or hierarchy, a subclass inherits the attributes not \\nonly of its direct superclass, but also of all its predecessor superclasses all the way to \\nthe root  of the hierarchy or lattice if necessary. For example, an entity in  \\nGRADUATE_STUDENT inherits all the attributes of that entity as a STUDENT and as a \\nPERSON. Notice that an entity may exist in several leaf nodes  of the hierarchy, \\nwhere a leaf node is a class that has no subclasses of its own. For example, a member \\nof GRADUATE_STUDENT may also be a member of RESEARCH_ASSISTANT.\\nA subclass with more than one  superclass is called a shared subclass , such as \\nENGINEERING_MANAGER  in Figure 4.6. This leads to the concept known as \\nmultiple inheritance , where the shared subclass ENGINEERING_MANAGER  \\ndirectly inherits attributes and relationships from multiple superclasses. Notice \\nthat the existence of at least one shared subclass leads to a lattice (and hence to \\nmultiple inheritance ); if no shared subclasses existed, we would have a hierarchy \\nrather than a lattice and only single inheritance  would exist. An important rule \\nrelated to multiple inheritance can be illustrated by the example of the shared \\nsubclass \\nSTUDENT_ASSISTANT  in Figure 4.7, which inherits attributes from \\nboth EMPLOYEE  and STUDENT . Here, both EMPLOYEE  and STUDENT  inherit the \\nsame attributes  from PERSON. The rule states that if an attribute (or relation-\\nship) originating in the same superclass  (PERSON) is inherited more than once \\nvia different paths ( EMPLOYEE  and STUDENT ) in the lattice, then it should be \\nincluded only once in the shared subclass ( STUDENT_ASSISTANT ). Hence, the \\nattributes of PERSON are inherited only once  in the STUDENT_ASSISTANT  sub-\\nclass in Figure 4.7.\\nIt is important to note here that some models and languages are limited to single \\ninheritance  and do not allow  multiple inheritance (shared subclasses). It is also \\nimportant to note that some models do not allow an entity to have multiple \\ntypes, and hence an entity can be a member of only one leaf class. 8 In such a \\nmodel, it is necessary to create additional subclasses as leaf nodes to cover all \\n8In some models, the class is further restricted to be a leaf node in the hierarchy or lattice.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 132, 'page_label': '133'}, page_content='4.3 Constraints and Characteristics of Specialization and Generalization Hierarchies  119\\npossible combinations of classes that may have some entity that belongs to all \\nthese classes simultaneously. For example, in the overlapping specialization of \\nPERSON into {EMPLOYEE, ALUMNUS, STUDENT} (or {E, A, S} for short), it would \\nbe necessary to create seven subclasses of PERSON in order to cover all possible \\ntypes of entities: \\nE, A, S, E_A, E_S, A_S,  and E_A_S. Obviously, this can lead to \\nextra complexity.\\nAlthough we have used specialization to illustrate our discussion, similar concepts \\napply equally to generalization, as we mentioned at the beginning of this section. \\nHence, we can also speak of generalization hierarchies and generalization lattices.\\n4.3.3  Utilizing Specialization and Generalization in  \\nRefining Conceptual Schemas\\nNow we elaborate on the differences between the specialization and generalization \\nprocesses and how they are used to refine conceptual schemas during conceptual \\ndatabase design. In the specialization process, the database designers typically start \\nwith an entity type and then define subclasses of the entity type by successive spe-\\ncialization; that is, they repeatedly define more specific groupings of the entity \\ntype. For example, when designing the specialization lattice in Figure 4.7, we may \\nfirst specify an entity type \\nPERSON for a university database. Then we discover \\nthat three types of persons will be represented in the database: university employ-\\nees, alumni, and students and we create the specialization {EMPLOYEE, ALUMNUS, \\nSTUDENT} . The overlapping constraint is chosen because a person may belong  \\nto more than one of the subclasses. We specialize EMPLOYEE  further into  \\n{STAFF, FACULTY, STUDENT_ASSISTANT} , and specialize STUDENT  into  \\n{GRADUATE_ STUDENT, UNDERGRADUATE_STUDENT} . Finally, we specialize \\nSTUDENT_ASSISTANT  into {RESEARCH_ASSISTANT, TEACHING_ASSISTANT} . \\nThis process is called top-down conceptual refinement . So far, we have a hier-\\narchy; then we realize that STUDENT_ASSISTANT  is a shared subclass, since it is \\nalso a subclass of STUDENT , leading to the lattice.\\nIt is possible to arrive at the same hierarchy or lattice from the other direction. In \\nsuch a case, the process involves generalization rather than specialization and cor-\\nresponds to a bottom-up conceptual synthesis. For example, the database design-\\ners may first discover entity types such as \\nSTAFF , FACULTY , ALUMNUS , \\nGRADUATE_STUDENT , UNDERGRADUATE_STUDENT , RESEARCH_ASSISTANT , \\nTEACHING_ASSISTANT , and so on; then they generalize {GRADUATE_STUDENT, \\nUNDERGRADUATE_STUDENT}  into STUDENT ; then {RESEARCH_ASSISTANT, \\nTEACHING_ASSISTANT}  into STUDENT_ASSISTANT ; then {STAFF, FACULTY,  \\nSTUDENT_ASSISTANT} into EMPLOYEE; and finally {EMPLOYEE, ALUMNUS, STUDENT} \\ninto PERSON.\\nThe final design of hierarchies or lattices resulting from either process may be \\nidentical; the only difference relates to the manner or order in which the schema \\nsuperclasses and subclasses were created during the design process. In practice, it \\nis likely that a combination of the two processes is employed. Notice that the'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 133, 'page_label': '134'}, page_content='120 Chapter 4 The Enhanced Entity–Relationship (EER) Model\\nnotion of representing data and knowledge by using superclass/subclass hierar-\\nchies and lattices is quite common in knowledge-based systems and expert sys-\\ntems, which combine database technology with artificial intelligence techniques. \\nFor example, frame-based knowledge representation schemes closely resemble \\nclass hierarchies. Specialization is also common in software engineering design \\nmethodologies that are based on the object-oriented paradigm.\\n4.4  Modeling of UNION Types  \\nUsing Categories\\nIt is sometimes necessary to represent a collection of entities from different entity \\ntypes. In this case, a subclass will represent a collection of entities that is a subset of \\nthe \\nUNION of entities from distinct entity types; we call such a subclass a union type \\nor a category.9\\nFor example, suppose that we have three entity types: PERSON , BANK, and  \\nCOMPANY. In a database for motor vehicle registration, an owner of a vehicle can \\nbe a person, a bank (holding a lien on a vehicle), or a company. We need to create \\na class (collection of entities) that includes entities of all three types to play the \\nrole of vehicle owner.  A category (union type) \\nOWNER that is a subclass of the \\nUNION of the three entity sets of COMPANY, BANK, and PERSON can be created \\nfor this purpose. We display categories in an EER diagram as shown in Figure 4.8. \\nThe superclasses \\nCOMPANY, BANK, and PERSON are connected to the circle with \\nthe ∪ symbol, which stands for the set union operation.  An arc with the subset \\nsymbol connects the circle to the (subclass) OWNER category. In Figure 4.8 we \\nhave two categories: OWNER, which is a subclass (subset) of the union of PERSON, \\nBANK, and COMPANY; and REGISTERED_VEHICLE , which is a subclass (subset) of \\nthe union of CAR and TRUCK.\\nA category has two or more superclasses that may represent collections of enti-\\nties from distinct entity types,  whereas other superclass/subclass relationships \\nalways have a single superclass. To better understand the difference,  \\nwe can compare a category, such as OWNER  in Figure 4.8, with the  \\nENGINEERING_MANAGER  shared subclass in Figure 4.6. The latter is a subclass of \\neach of  the three superclasses ENGINEER, MANAGER, and SALARIED_EMPLOYEE , \\nso an entity that is a member of ENGINEERING_MANAGER  must exist in all \\nthree\\xa0collections. This represents the constraint that an engineering manager must \\nbe an ENGINEER , a MANAGER , and a SALARIED_EMPLOYEE ; that is, the  \\nENGINEERING_MANAGER entity set is a subset of the intersection  of the three \\nentity sets. On the other hand, a category is a subset of the union of its super-\\nclasses. Hence, an entity that is a member of OWNER must exist in only one of the \\nsuperclasses. This represents the constraint that an OWNER may be a COMPANY, \\na BANK, or a PERSON in Figure 4.8.\\n9Our use of the term category is based on the ECR (entity–category–relationship) model (Elmasri et al., \\n1985).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 134, 'page_label': '135'}, page_content='4.4 Modeling of UNION Types Using Categories  121\\nAttribute inheritance works more selectively in the case of categories. For exam-\\nple, in Figure 4.8 each OWNER entity inherits the attributes of a COMPANY , a \\nPERSON, or a BANK, depending on the superclass to which the entity belongs. On \\nthe other hand, a shared subclass such as ENGINEERING_MANAGER  (Figure 4.6) \\ninherits all the attributes of its superclasses SALARIED_EMPLOYEE , ENGINEER , \\nand MANAGER.\\nIt is interesting to note the difference between the category REGISTERED_VEHICLE \\n(Figure 4.8) and the generalized superclass VEHICLE  (Figure 4.3(b)). In Fig- \\nure 4.3(b), every car and every truck is a VEHICLE ; but in Figure 4.8, the  \\nREGISTERED_VEHICLE category includes some cars and some trucks but not necessarily \\nName Address\\nDriver_license_no\\nSsn\\nLicense_plate_no\\nLien_or_regular\\nPurchase_date\\nBname Baddress\\nCname Caddress\\nBANK\\nPERSON\\nOWNER\\nOWNS\\nM\\nN\\nU\\nREGISTERED_VEHICLE\\nCOMPANY\\nU\\nCstyle\\nCyear\\nVehicle_id\\nCmake\\nCmodel\\nCAR\\nTonnage\\nTyear\\nVehicle_id\\nTmake\\nTmodel\\nTRUCK\\nFigure 4.8 \\nTwo categories (union \\ntypes): OWNER and \\nREGISTERED_VEHICLE.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 135, 'page_label': '136'}, page_content='122 Chapter 4 The Enhanced Entity–Relationship (EER) Model\\nall of them (for example, some cars or trucks may not be registered). In general, \\na specialization or generalization such as that in Figure 4.3(b), if it were partial, \\nwould not preclude VEHICLE  from containing other types of entities, such as \\nmotorcycles. However, a category such as REGISTERED_VEHICLE  in Figure 4.8 \\nimplies that only cars and trucks, but not other types of entities, can be members \\nof \\nREGISTERED_VEHICLE .\\nA category can be total or partial. A total category holds the union of all entities in \\nits superclasses, whereas a partial category can hold a subset of the union . A total \\ncategory is represented diagrammatically by a double line connecting the category \\nand the circle, whereas a partial category is indicated by a single line.\\nThe superclasses of a category may have different key attributes, as demonstrated \\nby the \\nOWNER category in Figure 4.8, or they may have the same key attribute, as \\ndemonstrated by the REGISTERED_VEHICLE category. Notice that if a category is \\ntotal (not partial), it may be represented alternatively as a total specialization (or a \\ntotal generalization). In this case, the choice of which representation to use is sub-\\njective. If the two classes represent the same type of entities and share numerous \\nattributes, including the same key attributes, specialization/generalization is pre-\\nferred; otherwise, categorization (union type) is more appropriate.\\nIt is important to note that some modeling methodologies do not have union \\ntypes. In these models, a union type must be represented in a roundabout way \\n(see Section 9.2).\\n4.5  A Sample UNIVERSITY EER Schema,  \\nDesign Choices, and Formal Definitions\\nIn this section, we first give an example of a database schema in the EER model to \\nillustrate the use of the various concepts discussed here and in Chapter 3. Then, we \\ndiscuss design choices for conceptual schemas, and finally we summarize the EER \\nmodel concepts and define them formally in the same manner in which we formally \\ndefined the concepts of the basic ER model in Chapter 3.\\n4.5.1 A Different UNIVERSITY Database Example\\nConsider a UNIVERSITY database that has different requirements from the UNIVERSITY \\ndatabase presented in Section 3.10. This database keeps track of students and their \\nmajors, transcripts, and registration as well as of the university’s course offerings. \\nThe database also keeps track of the sponsored research projects of faculty and \\ngraduate students. This schema is shown in Figure 4.9. A discussion of the require-\\nments that led to this schema follows.\\nFor each person, the database maintains information on the person’s Name \\n[Name], \\nSocial Security number [Ssn], address [Address], sex [Sex], and birth date [Bdate]. \\nTwo subclasses of the PERSON entity type are identified: FACULTY and STUDENT. \\nSpecific attributes of FACULTY are rank [Rank] (assistant, associate, adjunct, research,'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 136, 'page_label': '137'}, page_content='4.5 A Sample UNIVERSITY EER Schema, Design Choices, and Formal Definitions  123\\nFoffice\\nSalary\\nRank\\nFphone\\nFACULTY\\nd\\nCollege Degree Year\\n1 N\\nM N\\nM\\nDegrees\\nClass\\n1\\nM\\n1\\nN\\nN\\nM\\n1\\nN\\nN\\nQtr = Current_qtr and\\nYear = Current_year\\nN\\nN\\n1\\nM\\nN\\nN\\n1\\nCname\\nCdescC#\\n1 N\\n1\\nOffice\\nDphone\\nDname\\nN\\n1\\n1\\nN\\nClass=5\\nFname LnameMinit\\nName\\nBdateSsn Sex No Street Apt_no City State Zip\\nAddress\\nU\\nADVISOR\\nCOMMITTEE\\nCHAIRS\\nBELONGS\\nMINOR\\nMAJOR\\nDCCD\\nAgency\\nSt_date\\nNoTitle\\nStart\\nTime\\nEnd\\nCURRENT_SECTION\\nGrade\\nSec# Year\\nQtr\\nCofficeCname\\nDean\\nPERSON\\nGRAD_STUDENT\\nSTUDENT\\nGRANT\\nSUPPORT\\nREGISTERED\\nTRANSCRIPT\\nSECTION\\nTEACH\\nDEPARTMENT\\nCOURSECOLLEGE\\nCS\\nINSTRUCTOR_RESEARCHER\\nPI\\nFigure 4.9 \\nAn EER conceptual schema \\nfor a different UNIVERSITY \\ndatabase.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 137, 'page_label': '138'}, page_content='124 Chapter 4 The Enhanced Entity–Relationship (EER) Model\\nvisiting, and so on), office [Foffice], office phone [Fphone], and salary [Salary]. All fac-\\nulty members are related to the academic department(s) with which they are affiliated \\n[BELONGS] (a faculty member can be associated with several departments, so the \\nrelationship is M:N). A specific attribute of STUDENT is [Class] (freshman = 1, sopho-\\nmore = 2, … , MS student = 5, PhD student = 6). Each STUDENT is also related to his \\nor her major and minor departments (if known) [MAJOR] and [MINOR], to the course \\nsections he or she is currently attending [REGISTERED], and to the courses completed \\n[TRANSCRIPT]. Each TRANSCRIPT instance includes the grade the student received \\n[Grade] in a section of a course.\\nGRAD_STUDENT is a subclass of STUDENT, with the defining predicate (Class = 5 OR \\nClass = 6). For each graduate student, we keep a list of previous degrees in a compos-\\nite, multivalued attribute [Degrees]. We also relate the graduate student to a faculty \\nadvisor [ADVISOR] and to a thesis committee [COMMITTEE], if one exists.\\nAn academic department has the attributes name [Dname], telephone [Dphone], and \\noffice number [Office] and is related to the faculty member who is its chairperson \\n[CHAIRS] and to the college to which it belongs [CD]. Each college has attributes col-\\nlege name [Cname], office number [Coffice], and the name of its dean [Dean].\\nA course has attributes course number [C#], course name [Cname], and course \\ndescription [Cdesc]. Several sections of each course are offered, with each section \\nhaving the attributes section number [Sec#] and the year and quarter in which the \\nsection was offered ( [Year] and [Qtr]).10 Section numbers uniquely identify each  \\nsection. The sections being offered during the current quarter are in a subclass  \\nCURRENT_SECTION of SECTION, with the defining predicate Qtr = Current_qtr and \\nYear = Current_year. Each section is related to the instructor who taught or is teach-\\ning it ([TEACH]), if that instructor is in the database.\\nThe category INSTRUCTOR_RESEARCHER is a subset of the union of FACULTY and \\nGRAD_STUDENT and includes all faculty, as well as graduate students who are sup-\\nported by teaching or research. Finally, the entity type GRANT keeps track of research \\ngrants and contracts awarded to the university. Each grant has attributes grant title \\n[Title] , grant number [No], the awarding agency [Agency] , and the starting date \\n[St_date]. A grant is related to one principal investigator [PI] and to all researchers it \\nsupports [SUPPORT]. Each instance of support has as attributes the starting date of \\nsupport [Start], the ending date of the support (if known) [End], and the percentage of \\ntime being spent on the project [Time] by the researcher being supported.\\n4.5.2 Design Choices for Specialization/Generalization\\nIt is not always easy to choose the most appropriate conceptual design for a \\ndatabase application. In Section 3.7.3, we presented some of the typical issues \\nthat confront a database designer when choosing among the concepts of entity \\n10We assume that the quarter system rather than the semester system is used in this university.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 138, 'page_label': '139'}, page_content='4.5 A Sample UNIVERSITY EER Schema, Design Choices, and Formal Definitions  125\\ntypes, relationship types, and attributes to represent a particular miniworld sit-\\nuation as an ER schema. In this section, we discuss design guidelines and \\nchoices for the EER concepts of specialization/generalization and categories \\n(union types).\\nAs we mentioned in Section 3.7.3, conceptual database design should be considered \\nas an iterative refinement process until the most suitable design is reached. The fol-\\nlowing guidelines can help to guide the design process for EER concepts:\\n ■ In general, many specializations and subclasses can be defined to make \\nthe conceptual model accurate. However, the drawback is that the \\ndesign becomes quite cluttered. It is important to represent only those \\nsubclasses that are deemed necessary to avoid extreme cluttering of the \\nconceptual schema.\\n ■ If a subclass has few specific (local) attributes and no specific relationships, \\nit can be merged into the superclass. The specific attributes would hold NULL \\nvalues for entities that are not members of the subclass. A type attribute \\ncould specify whether an entity is a member of the subclass.\\n ■ Similarly, if all the subclasses of a specialization/generalization have few spe-\\ncific attributes and no specific relationships, they can be merged into the \\nsuperclass and replaced with one or more type attributes that specify the \\nsubclass or subclasses that each entity belongs to (see Section 9.2 for how \\nthis criterion applies to relational databases).\\n ■ Union types and categories should generally be avoided unless the situation \\ndefinitely warrants this type of construct, which does occur in some practi-\\ncal situations. If possible, we try to model using specialization/generaliza-\\ntion as discussed at the end of Section 4.4.\\n ■ The choice of disjoint/overlapping and total/partial constraints on special-\\nization/generalization is driven by the rules in the miniworld being mod-\\neled. If the requirements do not indicate any particular constraints, the \\ndefault would generally be overlapping and partial, since this does not spec-\\nify any restrictions on subclass membership.\\nAs an example of applying these guidelines, consider Figure 4.6, where no specific \\n(local) attributes are shown. We could merge all the subclasses into the \\nEMPLOYEE \\nentity type and add the following attributes to EMPLOYEE:\\n ■ An attribute Job_type whose value set {‘Secretary’, ‘Engineer’, ‘Technician’} \\nwould indicate which subclass in the first specialization each employee \\nbelongs to.\\n ■ An attribute Pay_method  whose value set {‘Salaried’, ‘Hourly’} would \\nindicate which subclass in the second specialization each employee \\nbelongs to.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 139, 'page_label': '140'}, page_content='126 Chapter 4 The Enhanced Entity–Relationship (EER) Model\\n ■ An attribute Is_a_manager  whose value set {‘Yes’, ‘No’} would indicate \\nwhether an individual employee entity is a manager or not.\\n4.5.3 Formal Definitions for the EER Model Concepts\\nWe now summarize the EER model concepts and give formal definitions. A class11 \\ndefines a type of entity and represents a set or collection of entities of that type; this \\nincludes any of the EER schema constructs that correspond to collections of enti-\\nties, such as entity types, subclasses, superclasses, and categories. A subclass S is a \\nclass whose entities must always be a subset of the entities in another class, called \\nthe superclass  C of the superclass/subclass  (or IS-A) relationship . We denote \\nsuch a relationship by C/S. For such a superclass/subclass relationship, we must \\nalways have\\nS ⊆ C\\nA specialization Z = {S\\n1, S2, … , Sn} is a set of subclasses that have the same super-\\nclass G; that is, G/Si is a superclass/subclass relationship for i = 1, 2, … , n. G is called \\na generalized entity type (or the superclass of the specialization, or a generalization \\nof the subclasses {S1, S2, … , Sn} ). Z is said to be total if we always (at any point in \\ntime) have\\n∪\\nn\\ni=1\\n Si = G\\nOtherwise, Z is said to be partial. Z is said to be disjoint if we always have\\nSi ∩ Sj = ∅ (empty set) for i ≠ j\\nOtherwise, Z is said to be overlapping.\\nA subclass S of C is said to be predicate-defined if a predicate p on the attributes of \\nC is used to specify which entities in C are members of S; that is, S = C[p], where \\nC[p] is the set of entities in C that satisfy p. A subclass that is not defined by a \\npredicate is called user-defined.\\nA specialization Z (or generalization G) is said to be attribute-defined  if a \\npredicate ( A = ci), where A is an attribute of G and ci is a constant value from \\nthe domain of A, is used to specify membership in each subclass Si in Z. Notice \\nthat if ci ≠ cj for i ≠ j, and A is a single-valued attribute, then the specialization \\nwill be disjoint.\\nA category T is a class that is a subset of the union of n defining superclasses D1, D2, \\n… , Dn, n > 1 and is formally specified as follows:\\nT ⊆ (D1 ∪ D2 ...  ∪ Dn)\\n11The use of the word class here refers to a collection (set) of entities, which differs from its more  \\ncommon use in object-oriented programming languages such as C++. In C++, a class is a structured \\ntype definition along with its applicable functions (operations).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 140, 'page_label': '141'}, page_content='4.6 Example of Other Notation: Representing Specialization and Generalization in UML Class Diagrams  127\\nA predicate pi on the attributes of Di can be used to specify the members of each Di \\nthat are members of T. If a predicate is specified on every Di, we get\\nT = (D1[p1] ∪ D2[p2] ... ∪ Dn[pn])\\nWe should now extend the definition of relationship type given in Chapter 3 by \\nallowing any class—not only any entity type—to participate in a relationship. \\nHence, we should replace the words entity type  with class in that definition. The \\ngraphical notation of EER is consistent with ER because all classes are represented \\nby rectangles.\\n4.6  Example of Other Notation: Representing \\nSpecialization and Generalization in UML \\nClass Diagrams\\nWe now discuss the UML notation for generalization/specialization and inheri-\\ntance. We already presented basic UML class diagram notation and terminology \\nin Section 3.8. Figure 4.10 illustrates a possible UML class diagram corresponding \\nto the EER diagram in Figure 4.7. The basic notation for specialization/generaliza-\\ntion (see Figure 4.10) is to connect the subclasses by vertical lines to a horizontal \\nline, which has a triangle connecting the horizontal line through another vertical \\nline to the superclass. A blank triangle indicates a specialization/generalization \\nwith the disjoint  constraint, and a filled triangle indicates an overlapping  con-\\nstraint. The root superclass is called the base class, and the subclasses (leaf nodes) \\nare called leaf classes.\\nThe preceding discussion and the example in Figure 4.10, as well as the presenta-\\ntion in Section 3.8, gave a brief overview of UML class diagrams and terminology. \\nWe focused on the concepts that are relevant to ER and EER database modeling \\nrather than on those concepts that are more relevant to software engineering. In \\nUML, there are many details that we have not discussed because they are outside \\nthe scope of this text and are mainly relevant to software engineering. For example, \\nclasses can be of various types:\\n ■ Abstract classes define attributes and operations but do not have objects \\ncorresponding to those classes. These are mainly used to specify a set of \\nattributes and operations that can be inherited.\\n ■ Concrete classes can have objects (entities) instantiated to belong to the \\nclass.\\n ■ Template classes specify a template that can be further used to define \\nother classes.\\nIn database design, we are mainly concerned with specifying concrete classes whose \\ncollections of objects are permanently (or persistently) stored in the database. The \\nbibliographic notes at the end of this chapter give some references to books that \\ndescribe complete details of UML.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 141, 'page_label': '142'}, page_content='128 Chapter 4 The Enhanced Entity–Relationship (EER) Model\\nProject\\nchange_project\\n. . .\\nRESEARCH_\\nASSISTANT\\nCourse\\nassign_to_course\\n. . .\\nTEACHING_\\nASSISTANT\\nDegree_program\\nchange_degree_program\\n. . .\\nGRADUATE_\\nSTUDENT\\nClass\\nchange_classification\\n. . .\\nUNDERGRADUATE_\\nSTUDENT\\nPosition\\nhire_staff\\n. . .\\nSTAFF\\nRank\\npromote\\n. . .\\nFACULTY\\nPercent_time\\nhire_student\\n. . .\\nSTUDENT_ASSISTANT\\nYear\\nDegree\\nMajor\\nDEGREE\\n. . .\\nSalary\\nhire_emp\\n. . .\\nEMPLOYEE\\nnew_alumnus 1*\\n. . .\\nALUMNUS\\nMajor_dept\\nchange_major\\n. . .\\nSTUDENT\\nName\\nSsn\\nBirth_date\\nSex\\nAddress\\nage\\n. . .\\nPERSON\\nFigure 4.10 \\nA UML class diagram corresponding to the EER diagram in Figure 4.7,  \\nillustrating UML notation for specialization/generalization.\\n4.7  Data Abstraction, Knowledge \\nRepresentation, and Ontology Concepts\\nIn this section, we discuss in general terms some of the modeling concepts that we \\ndescribed quite specifically in our presentation of the ER and EER models in Chap-\\nter 3 and earlier in this chapter. This terminology is not only used in conceptual'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 142, 'page_label': '143'}, page_content='4.7 Data Abstraction, Knowledge Representation, and Ontology Concepts  129\\ndata modeling but also in artificial intelligence literature when discussing  \\nknowledge representation (KR). This section discusses the similarities and differ-\\nences between conceptual modeling and knowledge representation, and introduces \\nsome of the alternative terminology and a few additional concepts.\\nThe goal of KR techniques is to develop concepts for accurately modeling some domain \\nof knowledge by creating an ontology\\n12 that describes the concepts of the domain \\nand how these concepts are interrelated. The ontology is used to store and manipu-\\nlate knowledge for drawing inferences, making decisions, or answering questions. \\nThe goals of KR are similar to those of semantic data models, but there are some \\nimportant similarities and differences between the two disciplines:\\n ■ Both disciplines use an abstraction process to identify common properties and \\nimportant aspects of objects in the miniworld (also known as domain of discourse \\nin KR) while suppressing insignificant differences and unimportant details.\\n ■ Both disciplines provide concepts, relationships, constraints, operations, \\nand languages for defining data and representing knowledge.\\n ■ KR is generally broader in scope than semantic data models. Different forms \\nof knowledge, such as rules (used in inference, deduction, and search), \\nincomplete and default knowledge, and temporal and spatial knowledge, are \\nrepresented in KR schemes. Database models are being expanded to include \\nsome of these concepts (see Chapter 26).\\n ■ KR schemes include reasoning mechanisms  that deduce additional facts \\nfrom the facts stored in a database. Hence, whereas most current database \\nsystems are limited to answering direct queries, knowledge-based systems \\nusing KR schemes can answer queries that involve inferences  over the \\nstored data. Database technology is being extended with inference mecha-\\nnisms (see Section 26.5).\\n ■ Whereas most data models concentrate on the representation of database \\nschemas, or meta-knowledge, KR schemes often mix up the schemas with \\nthe instances themselves in order to provide flexibility in representing \\nexceptions. This often results in inefficiencies when these KR schemes are \\nimplemented, especially when compared with databases and when a large \\namount of structured data (facts) needs to be stored.\\nWe now discuss four abstraction concepts that are used in semantic data models, \\nsuch as the EER model, as well as in KR schemes: (1) classification and instantia-\\ntion, (2) identification, (3) specialization and generalization, and (4) aggregation \\nand association. The paired concepts of classification and instantiation are inverses \\nof one another, as are generalization and specialization. The concepts of aggrega-\\ntion and association are also related. We discuss these abstract concepts and their \\nrelation to the concrete representations used in the EER model to clarify the data \\nabstraction process and to improve our understanding of the related process of \\nconceptual schema design. We close the section with a brief discussion of ontology, \\nwhich is being used widely in recent knowledge representation research.\\n12An ontology is somewhat similar to a conceptual schema, but with more knowledge, rules, and exceptions.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 143, 'page_label': '144'}, page_content='130 Chapter 4 The Enhanced Entity–Relationship (EER) Model\\n4.7.1 Classification and Instantiation\\nThe process of classification involves systematically assigning similar objects/enti-\\nties to object classes/entity types. We can now describe (in DB) or reason about (in \\nKR) the classes rather than the individual objects. Collections of objects that share \\nthe same types of attributes, relationships, and constraints are classified into classes \\nin order to simplify the process of discovering their properties. Instantiation is the \\ninverse of classification and refers to the generation and specific examination of \\ndistinct objects of a class. An object instance is related to its object class by the  \\nIS-AN-INSTANCE-OF  or IS-A-MEMBER-OF relationship. Although EER dia-\\ngrams do not display instances, the UML diagrams allow a form of instantiation by \\npermitting the display of individual objects. We did not describe this feature in our \\nintroduction to UML class diagrams.\\nIn general, the objects of a class should have a similar type structure. However, \\nsome objects may display properties that differ in some respects from the other \\nobjects of the class; these exception objects  also need to be modeled, and KR \\nschemes allow more varied exceptions than do database models. In addition, cer-\\ntain properties apply to the class as a whole and not to the individual objects; KR \\nschemes allow such class properties . UML diagrams also allow specification of \\nclass properties.\\nIn the EER model, entities are classified into entity types according to their basic \\nattributes and relationships. Entities are further classified into subclasses and cat-\\negories based on additional similarities and differences (exceptions) among them. \\nRelationship instances are classified into relationship types. Hence, entity types, \\nsubclasses, categories, and relationship types are the different concepts that are \\nused for classification in the EER model. The EER model does not provide \\nexplicitly for class properties, but it may be extended to do so. In UML, objects \\nare classified into classes, and it is possible to display both class properties and \\nindividual objects.\\nKnowledge representation models allow multiple classification schemes in \\nwhich one class is an instance  of another class (called a meta-class ). Notice that \\nthis cannot  be represented directly in the EER model, because we have only two \\nlevels—classes and instances. The only relationship among classes in the EER \\nmodel is a superclass/subclass relationship, whereas in some KR schemes an \\nadditional class/instance relationship can be represented directly in a class \\nhierarchy. An instance may itself be another class, allowing multiple-level \\nclassification schemes.\\n4.7.2 Identification\\nIdentification is the abstraction process whereby classes and objects are made \\nuniquely identifiable by means of some identifier. For example, a class name uniquely \\nidentifies a whole class within a schema. An additional mechanism is necessary for \\ntelling distinct object instances apart by means of object identifiers. Moreover, it is \\nnecessary to identify multiple manifestations in the database of the same real-world'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 144, 'page_label': '145'}, page_content='4.7 Data Abstraction, Knowledge Representation, and Ontology Concepts  131\\nobject. For example, we may have a tuple <‘Matthew Clarke’, ‘610618’, ‘376-9821’> in \\na PERSON relation and another tuple <‘301-54-0836’, ‘CS’, 3.8> in a STUDENT rela-\\ntion that happen to represent the same real-world entity. There is no way to identify \\nthe fact that these two database objects (tuples) represent the same real-world \\nentity unless we make a provision at design time for appropriate cross-referencing to \\nsupply this identification. Hence, identification is needed at two levels:\\n ■ To distinguish among database objects and classes\\n ■ To identify database objects and to relate them to their real-world counterparts\\nIn the EER model, identification of schema constructs is based on a system of \\nunique names for the constructs in a schema. For example, every class in an EER \\nschema—whether it is an entity type, a subclass, a category, or a relationship type—\\nmust have a distinct name. The names of attributes of a particular class must also be \\ndistinct. Rules for unambiguously identifying attribute name references in a spe-\\ncialization or generalization lattice or hierarchy are needed as well.\\nAt the object level, the values of key attributes are used to distinguish among enti-\\nties of a particular entity type. For weak entity types, entities are identified by a \\ncombination of their own partial key values and the entities they are related to in \\nthe owner entity type(s). Relationship instances are identified by some combination \\nof the entities that they relate to, depending on the cardinality ratio specified.\\n4.7.3 Specialization and Generalization\\nSpecialization is the process of classifying a class of objects into more specialized \\nsubclasses. Generalization is the inverse process of generalizing several classes into \\na higher-level abstract class that includes the objects in all these classes. Specializa-\\ntion is conceptual refinement, whereas generalization is conceptual synthesis. Sub-\\nclasses are used in the EER model to represent specialization and generalization. \\nWe call the relationship between a subclass and its superclass an IS-A-SUBCLASS-OF \\nrelationship, or simply an IS-A relationship. This is the same as the IS-A relation-\\nship discussed earlier in Section 4.5.3.\\n4.7.4 Aggregation and Association\\nAggregation is an abstraction concept for building composite objects from their \\ncomponent objects. There are three cases where this concept can be related to the \\nEER model. The first case is the situation in which we aggregate attribute values of \\nan object to form the whole object. The second case is when we represent an aggre-\\ngation relationship as an ordinary relationship. The third case, which the EER \\nmodel does not provide for explicitly, involves the possibility of combining objects \\nthat are related by a particular relationship instance into a higher-level aggregate \\nobject. This is sometimes useful when the higher-level aggregate object is itself to be \\nrelated to another object. We call the relationship between the primitive objects and \\ntheir aggregate object IS-A-PART-OF; the inverse is called IS-A-COMPONENT-OF. \\nUML provides for all three types of aggregation.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 145, 'page_label': '146'}, page_content='132 Chapter 4 The Enhanced Entity–Relationship (EER) Model\\nThe abstraction of association is used to associate objects from several independent \\nclasses. Hence, it is somewhat similar to the second use of aggregation. It is repre-\\nsented in the EER model by relationship types, and in UML by associations. This \\nabstract relationship is called IS-ASSOCIATED-WITH.\\nIn order to understand the different uses of aggregation better, consider the ER \\nschema shown in Figure 4.11(a), which stores information about interviews by \\njob applicants to various companies. The class \\nCOMPANY  is an aggregation of \\nthe attributes (or component objects) Cname  (company name) and Caddress  \\n(company address), whereas JOB_APPLICANT  is an aggregate of Ssn, Name , \\nAddress, and Phone. The relationship attributes Contact_name  and Contact_phone  \\nrepresent the name and phone number of the person in the company who is \\nresponsible for the interview. Suppose that some interviews result in job offers, \\nwhereas others do not. We would like to treat \\nINTERVIEW as a class to associate it \\nwith JOB_OFFER . The schema shown in Figure 4.11(b) is incorrect  because it \\nrequires each interview relationship instance to have a job offer. The schema \\nshown in Figure 4.11(c) is not allowed  because the ER model does not allow rela-\\ntionships among relationships.\\nOne way to represent this situation is to create a higher-level aggregate class com-\\nposed of \\nCOMPANY, JOB_APPLICANT , and INTERVIEW and to relate this class to \\nJOB_OFFER, as shown in Figure 4.11(d). Although the EER model as described in \\nthis book does not have this facility, some semantic data models do allow it and call \\nthe resulting object a composite or molecular object . Other models treat entity \\ntypes and relationship types uniformly and hence permit relationships among rela-\\ntionships, as illustrated in Figure 4.11(c).\\nTo represent this situation correctly in the ER model as described here, we need to \\ncreate a new weak entity type INTERVIEW, as shown in Figure 4.11(e), and relate it to \\nJOB_OFFER. Hence, we can always represent these situations correctly in the ER \\nmodel by creating additional entity types, although it may be conceptually more \\ndesirable to allow direct representation of aggregation, as in Figure 4.11(d), or to \\nallow relationships among relationships, as in Figure 4.11(c).\\nThe main structural distinction between aggregation and association is that when \\nan association instance is deleted, the participating objects may continue to exist. \\nHowever, if we support the notion of an aggregate object—for example, a CAR that \\nis made up of objects ENGINE, CHASSIS, and TIRES—then deleting the aggregate \\nCAR object amounts to deleting all its component objects.\\n4.7.5 Ontologies and the Semantic Web\\nIn recent years, the amount of computerized data and information available on \\nthe Web has spiraled out of control. Many different models and formats are used. \\nIn addition to the database models that we present in this text, much information \\nis stored in the form of documents, which have considerably less structure than'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 146, 'page_label': '147'}, page_content='4.7 Data Abstraction, Knowledge Representation, and Ontology Concepts  133\\n(a)\\nCOMPANY JOB_APPLICANT\\nAddressName Ssn PhoneCaddressCname\\nContact_phoneContact_name\\nDate\\nINTERVIEW\\n(c)\\nJOB_OFFER\\nCOMPANY JOB_APPLICANTINTERVIEW\\nRESUL TS_IN\\n(b)\\nJOB_OFFER\\nCOMPANY JOB_APPLICANTINTERVIEW\\n(d)\\nJOB_OFFER\\nCOMPANY JOB_APPLICANTINTERVIEW\\nRESUL TS_IN\\n(e)\\nJOB_OFFER\\nCOMPANY JOB_APPLICANT\\nAddressName Ssn PhoneCaddressCname\\nContact_phone\\nContact_name\\nRESUL TS_IN\\nCJI\\nINTERVIEWDate\\nFigure 4.11 \\nAggregation. (a) The  \\nrelationship type INTERVIEW. \\n(b) Including JOB_OFFER in a \\nternary relationship type \\n(incorrect). (c) Having the \\nRESULTS_IN relationship  \\nparticipate in other relationships \\n(not allowed in ER). (d) Using \\naggregation and a composite \\n(molecular) object (generally \\nnot allowed in ER but allowed \\nby some modeling tools).  \\n(e) Correct representation  \\nin ER.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 147, 'page_label': '148'}, page_content='134 Chapter 4 The Enhanced Entity–Relationship (EER) Model\\ndatabase information does. One ongoing project that is attempting to allow \\ninformation exchange among computers on the Web is called the Semantic \\nWeb, which attempts to create knowledge representation models that are quite \\ngeneral in order to allow meaningful information exchange and search among \\nmachines. The concept of ontology  is considered to be the most promising basis \\nfor achieving the goals of the Semantic Web and is closely related to knowledge \\nrepresentation. In this section, we give a brief introduction to what ontology is \\nand how it can be used as a basis to automate information understanding, search, \\nand exchange.\\nThe study of ontologies attempts to describe the concepts and relationships that are \\npossible in reality through some common vocabulary; therefore, it can be consid-\\nered as a way to describe the knowledge of a certain community about reality. \\nOntology originated in the fields of philosophy and metaphysics. One commonly \\nused definition of ontology is a specification of a conceptualization.\\n13\\nIn this definition, a conceptualization is the set of concepts and relationships that \\nare used to represent the part of reality or knowledge that is of interest to a com-\\nmunity of users. Specification refers to the language and vocabulary terms that are \\nused to specify the conceptualization. The ontology includes both specification and \\nconceptualization. For example, the same conceptualization may be specified in two \\ndifferent languages, giving two separate ontologies. Based on this general defini-\\ntion, there is no consensus on what an ontology is exactly. Some possible ways to \\ndescribe ontologies are as follows:\\n ■ A thesaurus (or even a dictionary or a glossary of terms) describes the rela-\\ntionships between words (vocabulary) that represent various concepts.\\n ■ A taxonomy  describes how concepts of a particular area of knowledge \\nare related using structures similar to those used in a specialization or \\ngeneralization.\\n ■ A detailed database schema is considered by some to be an ontology that \\ndescribes the concepts (entities and attributes) and relationships of a mini-\\nworld from reality.\\n ■ A logical theory uses concepts from mathematical logic to try to define con-\\ncepts and their interrelationships.\\nUsually the concepts used to describe ontologies are similar to the concepts we dis-\\ncuss in conceptual modeling, such as entities, attributes, relationships, specializa-\\ntions, and so on. The main difference between an ontology and, say, a database \\nschema, is that the schema is usually limited to describing a small subset of a mini-\\nworld from reality in order to store and manage data. An ontology is usually con-\\nsidered to be more general in that it attempts to describe a part of reality or a \\ndomain of interest (for example, medical terms, electronic-commerce applications, \\nsports, and so on) as completely as possible.\\n13This definition is given in Gruber (1995).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 148, 'page_label': '149'}, page_content='Review Questions 135\\n4.8 Summary\\nIn this chapter we discussed extensions to the ER model that improve its repre-\\nsentational capabilities. We called the resulting model the enhanced ER or EER \\nmodel. We presented the concept of a subclass and its superclass and the related \\nmechanism of attribute/relationship inheritance. We saw how it is sometimes \\nnecessary to create additional classes of entities, either because of additional spe-\\ncific attributes or because of specific relationship types. We discussed two main \\nprocesses for defining superclass/subclass hierarchies and lattices: specialization \\nand generalization.\\nNext, we showed how to display these new constructs in an EER diagram. We also \\ndiscussed the various types of constraints that may apply to specialization or gener-\\nalization. The two main constraints are total/partial and disjoint/overlapping. We \\ndiscussed the concept of a category or union type, which is a subset of the union of \\ntwo or more classes, and we gave formal definitions of all the concepts presented.\\nWe introduced some of the notation and terminology of UML for representing \\nspecialization and generalization. In Section 4.7, we briefly discussed the discipline \\nof knowledge representation and how it is related to semantic data modeling. We \\nalso gave an overview and summary of the types of abstract data representation \\nconcepts: classification and instantiation, identification, specialization and gener-\\nalization, and aggregation and association. We saw how EER and UML concepts \\nare related to each of these.\\nReview Questions\\n 4.1. What is a subclass? When is a subclass needed in data modeling?\\n 4.2. Define the following terms: superclass of a subclass, superclass/subclass rela-\\ntionship, IS-A relationship , specialization, generalization, category, specific \\n(local) attributes, and specific relationships.\\n 4.3. Discuss the mechanism of attribute/relationship inheritance. Why is it use-\\nful?\\n 4.4. Discuss user-defined and predicate-defined subclasses, and identify the dif-\\nferences between the two.\\n 4.5. Discuss user-defined and attribute-defined specializations, and identify the \\ndifferences between the two.\\n 4.6. Discuss the two main types of constraints on specializations and generalizations.\\n 4.7. What is the difference between a specialization hierarchy and a specializa-\\ntion lattice?\\n 4.8. What is the difference between specialization and generalization? Why do \\nwe not display this difference in schema diagrams?'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 149, 'page_label': '150'}, page_content='136 Chapter 4 The Enhanced Entity–Relationship (EER) Model\\n 4.9. How does a category differ from a regular shared subclass? What is a cate-\\ngory used for? Illustrate your answer with examples.\\n 4.10. For each of the following UML terms (see Sections 3.8 and 4.6), discuss the \\ncorresponding term in the EER model, if any: object, class, association, aggre-\\ngation, generalization, multiplicity, attributes, discriminator, link, link attri-\\nbute, reflexive association, and qualified association.\\n 4.11. Discuss the main differences between the notation for EER schema dia-\\ngrams and UML class diagrams by comparing how common concepts are \\nrepresented in each.\\n 4.12. List the various data abstraction concepts and the corresponding modeling \\nconcepts in the EER model.\\n 4.13. What aggregation feature is missing from the EER model? How can the EER \\nmodel be further enhanced to support it?\\n 4.14. What are the main similarities and differences between conceptual database \\nmodeling techniques and knowledge representation techniques?\\n 4.15. Discuss the similarities and differences between an ontology and a database \\nschema.\\nExercises\\n 4.16. Design an EER schema for a database application that you are interested in. \\nSpecify all constraints that should hold on the database. Make sure that the \\nschema has at least five entity types, four relationship types, a weak entity \\ntype, a superclass/subclass relationship, a category, and an n-ary (n > 2) rela-\\ntionship type.\\n 4.17. Consider the BANK ER schema in Figure 3.21, and suppose that it  \\nis necessary to keep track of different types of \\nACCOUNTS   \\n(SAVINGS_ACCTS , CHECKING_ACCTS , … ) and LOANS  ( CAR_LOANS , \\nHOME_LOANS , … ). Suppose that it is also desirable to keep track of \\neach ACCOUNT’s TRANSACTIONS  (deposits, withdrawals, checks, … ) \\nand each LOAN’s PAYMENTS ; both of these include the amount, date, \\nand time. Modify the BANK schema, using ER and EER concepts of \\nspecialization and generalization. State any assumptions you make \\nabout the additional requirements.\\n 4.18. The following narrative describes a simplified version of the organization of \\nOlympic facilities planned for the summer Olympics. Draw an EER diagram \\nthat shows the entity types, attributes, relationships, and specializations for \\nthis application. State any assumptions you make. The Olympic facilities are \\ndivided into sports complexes. Sports complexes are divided into one-sport \\nand multisport types. Multisport complexes have areas of the complex desig-\\nnated for each sport with a location indicator (e.g., center, NE corner, and so'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 150, 'page_label': '151'}, page_content='Exercises 137\\non). A complex has a location, chief organizing individual, total occupied \\narea, and so on. Each complex holds a series of events (e.g., the track sta-\\ndium may hold many different races). For each event there is a planned date, \\nduration, number of participants, number of officials, and so on. A roster of \\nall officials will be maintained together with the list of events each official \\nwill be involved in. Different equipment is needed for the events (e.g., goal \\nposts, poles, parallel bars) as well as for maintenance. The two types of facil-\\nities (one-sport and multisport) will have different types of information. For \\neach type, the number of facilities needed is kept, together with an approxi-\\nmate budget.\\n 4.19. Identify all the important concepts represented in the library database case \\nstudy described below. In particular, identify the abstractions of classifica-\\ntion (entity types and relationship types), aggregation, identification, and \\nspecialization/generalization. Specify (min, max) cardinality constraints \\nwhenever possible. List details that will affect the eventual design but that \\nhave no bearing on the conceptual design. List the semantic constraints sep-\\narately. Draw an EER diagram of the library database.\\nCase Study: The Georgia Tech Library (GTL) has approximately 16,000 \\nmembers, 100,000 titles, and 250,000 volumes (an average of 2.5 copies per \\nbook). About 10% of the volumes are out on loan at any one time. The librar-\\nians ensure that the books that members want to borrow are available when \\nthe members want to borrow them. Also, the librarians must know how \\nmany copies of each book are in the library or out on loan at any given time. \\nA catalog of books is available online that lists books by author, title, and \\nsubject area. For each title in the library, a book description is kept in the \\ncatalog; the description ranges from one sentence to several pages. The refer-\\nence librarians want to be able to access this description when members \\nrequest information about a book. Library staff includes chief librarian, \\ndepartmental associate librarians, reference librarians, check-out staff, and \\nlibrary assistants.\\nBooks can be checked out for 21 days. Members are allowed to have only \\nfive books out at a time. Members usually return books within three to four \\nweeks. Most members know that they have one week of grace before a \\nnotice is sent to them, so they try to return books before the grace period \\nends. About 5% of the members have to be sent reminders to return books. \\nMost overdue books are returned within a month of the due date. Approxi-\\nmately 5% of the overdue books are either kept or never returned. The most \\nactive members of the library are defined as those who borrow books at \\nleast ten times during the year. The top 1% of membership does 15% of the \\nborrowing, and the top 10% of the membership does 40% of the borrowing. \\nAbout 20% of the members are totally inactive in that they are members \\nwho never borrow.\\nTo become a member of the library, applicants fill out a form including their \\nSSN, campus and home mailing addresses, and phone numbers. The librari-'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 151, 'page_label': '152'}, page_content='138 Chapter 4 The Enhanced Entity–Relationship (EER) Model\\nans issue a numbered, machine-readable card with the member’s photo on it. \\nThis card is good for four years. A month before a card expires, a notice is \\nsent to a member for renewal. Professors at the institute are considered auto-\\nmatic members. When a new faculty member joins the institute, his or her \\ninformation is pulled from the employee records and a library card is mailed \\nto his or her campus address. Professors are allowed to check out books for \\nthree-month intervals and have a two-week grace period. Renewal notices to \\nprofessors are sent to their campus address.\\nThe library does not lend some books, such as reference books, rare books, \\nand maps. The librarians must differentiate between books that can be lent \\nand those that cannot be lent. In addition, the librarians have a list of some \\nbooks they are interested in acquiring but cannot obtain, such as rare or out-\\nof-print books and books that were lost or destroyed but have not been \\nreplaced. The librarians must have a system that keeps track of books that \\ncannot be lent as well as books that they are interested in acquiring. Some \\nbooks may have the same title; therefore, the title cannot be used as a means \\nof identification. Every book is identified by its International Standard Book \\nNumber (ISBN), a unique international code assigned to all books. Two \\nbooks with the same title can have different ISBNs if they are in different \\nlanguages or have different bindings (hardcover or softcover). Editions of \\nthe same book have different ISBNs.\\nThe proposed database system must be designed to keep track of the mem-\\nbers, the books, the catalog, and the borrowing activity.\\n 4.20.  Design a database to keep track of information for an art museum. Assume \\nthat the following requirements were collected:\\n ■ The museum has a collection of ART_OBJECTS. Each ART_OBJECT has a \\nunique Id_no, an Artist (if known), a Year (when it was created, if known), \\na Title, and a Description. The art objects are categorized in several ways, as \\ndiscussed below.\\n ■ ART_OBJECTS are categorized based on their type. There are three main \\ntypes—PAINTING, SCULPTURE, and STATUE—plus another type called \\nOTHER to accommodate objects that do not fall into one of the three main \\ntypes.\\n ■ A PAINTING  has a Paint_type  (oil, watercolor, etc.), material on which \\nit is Drawn_on  (paper, canvas, wood, etc.), and Style  (modern, \\nabstract, etc.).\\n ■ A SCULPTURE or a statue has a Material from which it was created (wood, \\nstone, etc.), Height, Weight, and Style.\\n ■ An art object in the OTHER category has a Type (print, photo, etc.) and Style.\\n ■ ART_OBJECTs  are categorized as either PERMANENT_COLLECTION  \\n(objects that are owned by the museum) and BORROWED. Information \\ncaptured about objects in the PERMANENT_COLLECTION  includes  \\nDate_acquired, Status (on display, on loan, or stored), and Cost. Information'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 152, 'page_label': '153'}, page_content='Exercises 139\\ncaptured about BORROWED objects includes the Collection from which it \\nwas borrowed, Date_borrowed, and Date_returned.\\n ■ Information describing the country or culture of Origin (Italian, Egyptian, \\nAmerican, Indian, and so forth) and Epoch (Renaissance, Modern, \\nAncient, and so forth) is captured for each ART_OBJECT.\\n ■ The museum keeps track of ARTIST  information, if known: Name,  \\nDateBorn (if known), Date_died (if not living), Country_of_origin , Epoch, \\nMain_style, and Description. The Name is assumed to be unique.\\n ■ Different EXHIBITIONS occur, each having a Name, Start_date, and End_date. \\nEXHIBITIONS are related to all the art objects that were on display during \\nthe exhibition.\\n ■ Information is kept on other COLLECTIONS  with which the museum \\ninteracts; this information includes Name (unique), Type (museum, per-\\nsonal, etc.), Description, Address, Phone, and current Contact_person.\\nDraw an EER schema diagram for this application. Discuss any assumptions \\nyou make, and then justify your EER design choices.\\n 4.21.  Figure 4.12 shows an example of an EER diagram for a small-private-airport \\ndatabase; the database is used to keep track of airplanes, their owners, air-\\nport employees, and pilots. From the requirements for this database, the fol-\\nlowing information was collected: Each \\nAIRPLANE has a registration number \\n[Reg#], is of a particular plane type [OF_TYPE], and is stored in a particular \\nhangar [STORED_IN] . Each PLANE_TYPE  has a model number [Model], a \\ncapacity [Capacity] , and a weight [Weight] . Each HANGAR has a number  \\n[Number], a capacity [Capacity], and a location [Location]. The database also \\nkeeps track of the OWNERs of each plane [OWNS] and the EMPLOYEEs who \\nhave maintained the plane [MAINTAIN]. Each relationship instance in OWNS \\nrelates an AIRPLANE to an OWNER and includes the purchase date [Pdate]. \\nEach relationship instance in MAINTAIN relates an EMPLOYEE to a service \\nrecord [SERVICE]. Each plane undergoes service many times; hence, it is \\nrelated by [PLANE_SERVICE] to a number of SERVICE records. A SERVICE \\nrecord includes as attributes the date of maintenance [Date], the number of \\nhours spent on the work [Hours], and the type of work done [Work_code]. We \\nuse a weak entity type [SERVICE] to represent airplane service, because the \\nairplane registration number is used to identify a service record. An OWNER \\nis either a person or a corporation. Hence, we use a union type (category) \\n[OWNER] that is a subset of the union of corporation [CORPORATION] and \\nperson [PERSON]  entity types. Both pilots [PILOT]  and employees \\n[EMPLOYEE] are subclasses of PERSON. Each PILOT has specific attributes \\nlicense number [Lic_num] and restrictions [Restr]; each EMPLOYEE has spe-\\ncific attributes salary [Salary] and shift worked [Shift]. All PERSON entities in \\nthe database have data kept on their Social Security number [Ssn], name \\n[Name], address [Address], and telephone number [Phone]. For CORPORATION \\nentities, the data kept includes name [Name] , address [Address] , and  \\ntelephone number [Phone]. The database also keeps track of the types of'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 153, 'page_label': '154'}, page_content='140 Chapter 4 The Enhanced Entity–Relationship (EER) Model\\nplanes each pilot is authorized to fly [FLIES] and the types of planes each \\nemployee can do maintenance work on [WORKS_ON] . Show how the \\nSMALL_AIRPORT EER schema in Figure 4.12 may be represented in UML \\nnotation. (Note: We have not discussed how to represent categories (union \\ntypes) in UML, so you do not have to map the categories in this and the fol-\\nlowing question.)\\n 4.22.  Show how the UNIVERSITY EER schema in Figure 4.9 may be represented in \\nUML notation.\\nNumber Location\\nCapacity\\nName Pho ne\\nAddress\\nName\\nSsn\\nPhone\\nAddress\\nLic_numRestr\\nDate/workcode\\n1\\nN\\nN\\n1\\nN\\n1\\nPLANE_TYPE\\nModel Capacity\\nPdate\\nWeight\\nMAINTAIN\\nM\\nM\\nN\\nOF_TYPE\\nSTORED_IN NM OWNS\\nFLIES\\nWORKS_ON\\nN\\nN\\nM\\nReg#\\nDate\\nHours\\nHANGAR\\nPILOT\\nEMPLOYEE\\nSalary\\nPLANE_SERVICE\\nSERVICE\\nWorkcode\\nAIRPLANE\\nShift\\nU\\nCORPORATION PERSON\\nOWNER\\nFigure 4.12 \\nEER schema for a SMALL_AIRPORT database.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 154, 'page_label': '155'}, page_content='Exercises 141\\n 4.23.  Consider the entity sets and attributes shown in the following table. Place a \\ncheckmark in one column in each row to indicate the relationship between \\nthe far left and far right columns.\\na. The left side has a relationship with the right side.\\nb. The right side is an attribute of the left side.\\nc. The left side is a specialization of the right side.\\nd. The left side is a generalization of the right side.\\nEntity Set\\n(a) Has a\\nRelationship\\nwith\\n(b) Has an\\nAttribute \\nthat is\\n(c) Is a\\nSpecialization\\nof\\n(d) Is a\\nGeneralization\\nof\\nEntity Set \\nor Attribute\\n1. MOTHER PERSON\\n2. DAUGHTER MOTHER\\n3. STUDENT PERSON\\n4. STUDENT Student_id\\n5. SCHOOL STUDENT\\n6. SCHOOL CLASS_ROOM\\n7. ANIMAL HORSE\\n8. HORSE Breed\\n9. HORSE Age\\n10. EMPLOYEE SSN\\n11. FURNITURE CHAIR\\n12. CHAIR Weight\\n13. HUMAN WOMAN\\n14. SOLDIER PERSON\\n15. ENEMY_COMBATANT PERSON\\n 4.24. Draw a UML diagram for storing a played game of chess in a database. \\nYou may look at http://www.chessgames.com for an application similar to \\nwhat you are designing. State clearly any assumptions you make in your \\nUML diagram. A sample of assumptions you can make about the scope is \\nas follows:\\n1. The game of chess is played between two players.\\n2. The game is played on an 8 × 8 board like the one shown below:'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 155, 'page_label': '156'}, page_content='142 Chapter 4 The Enhanced Entity–Relationship (EER) Model\\n3. The players are assigned a color of black or white at the start of the game.\\n4. Each player starts with the following pieces (traditionally called \\nchessmen):\\na. king\\nb. queen\\nc. 2 rooks\\nd. 2 bishops\\ne. 2 knights\\nf. 8 pawns\\n5. Every piece has its own initial position.\\n6. Every piece has its own set of legal moves based on the state of the game. \\nY ou do not need to worry about which moves are or are not legal except \\nfor the following issues:\\na. A piece may move to an empty square or capture an opposing piece.\\nb. If a piece is captured, it is removed from the board.\\nc. If a pawn moves to the last row, it is “promoted” by converting it to \\nanother piece (queen, rook, bishop, or knight).\\nNote: Some of these functions may be spread over multiple classes.\\n 4.25.  Draw an EER diagram for a game of chess as described in Exercise 4. 24. Focus \\non persistent storage aspects of the system. For example, the system would \\nneed to retrieve all the moves of every game played in sequential order.\\n 4.26.  Which of the following EER diagrams is/are incorrect and why? State clearly \\nany assumptions you make.\\na.\\nb.\\nE d\\nE1\\nE2\\nR\\n1\\n1\\nE\\nE1\\nE2\\nR\\n1\\nE3No'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 156, 'page_label': '157'}, page_content='Laboratory Exercises 143\\n 4.27.  Consider the following EER diagram that describes the computer systems at \\na company. Provide your own attributes and key for each entity type. Supply \\nmax cardinality constraints justifying your choice. Write a complete narra-\\ntive description of what this EER diagram represents.\\nc.\\nE1\\nR\\nE3\\nN\\no\\nM\\nMEMORY VIDEO_CARD\\nd\\nLAPTOP DESKTOP\\nINSTALLED\\nd\\nCOMPUTER\\nSOFTWARE\\nOPERATING_\\nSYSTEM\\nINSTALLED_OS\\nSUPPORTS\\nCOMPONENT\\nOPTIONS\\nSOUND_CARD\\nMEM_OPTIONS\\nKEYBOARD MOUSE\\nd\\nACCESSORY\\nMONITOR\\nSOLD_WITH\\nLaboratory Exercises\\n 4.28.  Consider a GRADE_BOOK database in which instructors within an academic \\ndepartment record points earned by individual students in their classes. The \\ndata requirements are summarized as follows:\\n ■ Each student is identified by a unique identifier, first and last name, and \\nan e-mail address.\\n ■ Each instructor teaches certain courses each term. Each course is identified \\nby a course number, a section number, and the term in which it is taught. For'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 157, 'page_label': '158'}, page_content='144 Chapter 4 The Enhanced Entity–Relationship (EER) Model\\neach course he or she teaches, the instructor specifies the minimum number \\nof points required in order to earn letter grades A, B, C, D, and F . For exam-\\nple, 90 points for an A, 80 points for a B, 70 points for a C, and so forth.\\n ■ Students are enrolled in each course taught by the instructor.\\n ■ Each course has a number of grading components (such as midterm \\nexam, final exam, project, and so forth). Each grading component has a \\nmaximum number of points (such as 100 or 50) and a weight (such as \\n20% or 10%). The weights of all the grading components of a course usu-\\nally total 100.\\n ■ Finally, the instructor records the points earned by each student in each of \\nthe grading components in each of the courses. For example, student 1234 \\nearns 84 points for the midterm exam grading component of the section 2 \\ncourse CSc2310 in the fall term of 2009. The midterm exam grading com-\\nponent may have been defined to have a maximum of 100 points and a \\nweight of 20% of the course grade.\\n  Design an enhanced entity–relationship diagram for the grade book data-\\nbase and build the design using a data modeling tool such as ERwin or \\nRational Rose.\\n 4.29.  Consider an ONLINE_AUCTION database system in which members (buyers \\nand sellers) participate in the sale of items. The data requirements for this \\nsystem are summarized as follows:\\n ■ The online site has members, each of whom is identified by a unique \\nmember number and is described by an e-mail address, name, password, \\nhome address, and phone number.\\n ■ A member may be a buyer or a seller. A buyer has a shipping address \\nrecorded in the database. A seller has a bank account number and routing \\nnumber recorded in the database.\\n ■ Items are placed by a seller for sale and are identified by a unique item \\nnumber assigned by the system. Items are also described by an item title, \\na description, starting bid price, bidding increment, the start date of the \\nauction, and the end date of the auction.\\n ■ Items are also categorized based on a fixed classification hierarchy (for \\nexample, a modem may be classified as COMPUTER → HARDWARE → \\nMODEM).\\n ■ Buyers make bids for items they are interested in. Bid price and time of \\nbid are recorded. The bidder at the end of the auction with the highest bid \\nprice is declared the winner, and a transaction between buyer and seller \\nmay then proceed.\\n ■ The buyer and seller may record feedback regarding their completed \\ntransactions. Feedback contains a rating of the other party participating \\nin the transaction (1–10) and a comment.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 158, 'page_label': '159'}, page_content='Laboratory Exercises 145\\n  Design an enhanced entity–relationship diagram for the ONLINE_AUCTION \\ndatabase and build the design using a data modeling tool such as ERwin or \\nRational Rose.\\n 4.30.  Consider a database system for a baseball organization such as the major \\nleagues. The data requirements are summarized as follows:\\n ■ The personnel involved in the league include players, coaches, managers, \\nand umpires. Each is identified by a unique personnel id. They are also \\ndescribed by their first and last names along with the date and place of \\nbirth.\\n ■ Players are further described by other attributes such as their batting ori-\\nentation (left, right, or switch) and have a lifetime batting average (BA).\\n ■ Within the players group is a subset of players called pitchers. Pitchers \\nhave a lifetime ERA (earned run average) associated with them.\\n ■ Teams are uniquely identified by their names. Teams are also described by \\nthe city in which they are located and the division and league in which \\nthey play (such as Central division of the American League).\\n ■ Teams have one manager, a number of coaches, and a number of players.\\n ■ Games are played between two teams, with one designated as the home \\nteam and the other the visiting team on a particular date. The score (runs, \\nhits, and errors) is recorded for each team. The team with the most runs is \\ndeclared the winner of the game.\\n ■ With each finished game, a winning pitcher and a losing pitcher are \\nrecorded. In case there is a save awarded, the save pitcher is also recorded.\\n ■ With each finished game, the number of hits (singles, doubles, triples, and \\nhome runs) obtained by each player is also recorded.\\n  Design an enhanced entity–relationship diagram for the BASEBALL data-\\nbase and enter the design using a data modeling tool such as ERwin or \\nRational Rose.\\n 4.31.  Consider the EER diagram for the UNIVERSITY database shown in Figure 4.9. \\nEnter this design using a data modeling tool such as ERwin or Rational Rose. \\nMake a list of the differences in notation between the diagram in the text \\nand the corresponding equivalent diagrammatic notation you end up using \\nwith the tool.\\n 4.32.  Consider the EER diagram for the small AIRPORT database shown in Fig- \\nure 4.12. Build this design using a data modeling tool such as ERwin or Rational \\nRose. Be careful how you model the category OWNER in this diagram. (Hint: \\nConsider using CORPORATION_IS_OWNER  and PERSON_IS_ OWNER  as \\ntwo distinct relationship types.)\\n 4.33.  Consider the UNIVERSITY database described in Exercise 3.16. You already \\ndeveloped an ER schema for this database using a data modeling tool such as'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 159, 'page_label': '160'}, page_content='146 Chapter 4 The Enhanced Entity–Relationship (EER) Model\\nERwin or Rational Rose in Lab Exercise 3.31. Modify this diagram by clas-\\nsifying COURSES as either UNDERGRAD_COURSES  or GRAD_COURSES  \\nand INSTRUCTORS as either JUNIOR_PROFESSORS or SENIOR_PROFESSORS. \\nInclude appropriate attributes for these new entity types. Then establish \\nrelationships indicating that junior instructors teach undergraduate courses \\nwhereas senior instructors teach graduate courses.\\nSelected Bibliography\\nMany papers have proposed conceptual or semantic data models. We give a repre-\\nsentative list here. One group of papers, including Abrial (1974), Senko’s DIAM \\nmodel (1975), the NIAM method (Verheijen and VanBekkum 1982), and Bracchi \\net al. (1976), presents semantic models that are based on the concept of binary rela-\\ntionships. Another group of early papers discusses methods for extending the rela-\\ntional model to enhance its modeling capabilities. This includes the papers by \\nSchmid and Swenson (1975), Navathe and Schkolnick (1978), Codd’s RM/T model \\n(1979), Furtado (1978), and the structural model of Wiederhold and Elmasri (1979).\\nThe ER model was proposed originally by Chen (1976) and is formalized in Ng \\n(1981). Since then, numerous extensions of its modeling capabilities have been pro-\\nposed, as in Scheuermann et al. (1979), Dos Santos et al. (1979), Teorey et al. (1986), \\nGogolla and Hohenstein (1991), and the entity–category–relationship (ECR) model \\nof Elmasri et al. (1985). Smith and Smith (1977) present the concepts of generaliza-\\ntion and aggregation. The semantic data model of Hammer and McLeod (1981) \\nintroduces the concepts of class/subclass lattices, as well as other advanced model-\\ning concepts.\\nA survey of semantic data modeling appears in Hull and King (1987). Eick (1991) \\ndiscusses design and transformations of conceptual schemas. Analysis of con-\\nstraints for n-ary relationships is given in Soutou (1998). UML is described in detail \\nin Booch, Rumbaugh, and Jacobson (1999). Fowler and Scott (2000) and Stevens \\nand Pooley (2000) give concise introductions to UML concepts.\\nFensel (2000, 2003) discusses the Semantic Web and application of ontologies. \\nUschold and Gruninger (1996) and Gruber (1995) discuss ontologies. The June \\n2002 issue of Communications of the ACM  is devoted to ontology concepts and \\napplications. Fensel (2003) discusses ontologies and e-commerce.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 160, 'page_label': '161'}, page_content='The Relational Data  \\nModel and SQL     \\npart  3'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 161, 'page_label': '162'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 162, 'page_label': '163'}, page_content='149\\n5\\nThe Relational Data Model and \\nRelational Database Constraints\\nT\\nhis chapter opens Part 3 of the book, which covers \\nrelational databases. The relational data model was \\nfirst introduced by Ted Codd of IBM Research in 1970 in a classic paper (Codd, \\n1970), and it attracted immediate attention due to its simplicity and mathematical \\nfoundation. The model uses the concept of a mathematical relation—which looks \\nsomewhat like a table of values—as its basic building block, and has its theoretical \\nbasis in set theory and first-order predicate logic. In this chapter we discuss the \\nbasic characteristics of the model and its constraints.\\nThe first commercial implementations of the relational model became available in \\nthe early 1980s, such as the SQL/DS system on the MVS operating system by IBM \\nand the Oracle DBMS. Since then, the model has been implemented in a large num-\\nber of commercial systems, as well as a number of open source systems. Current \\npopular commercial relational DBMSs (RDBMSs) include DB2 (from IBM), Oracle \\n(from Oracle), Sybase DBMS (now from SAP), and SQLServer and Microsoft \\nAccess (from Microsoft). In addition, several open source systems, such as MySQL \\nand PostgreSQL, are available.\\nBecause of the importance of the relational model, all of Part 2 is devoted to this \\nmodel and some of the languages associated with it. In Chapters 6 and 7, we describe \\nsome aspects of SQL, which is a comprehensive model and language that is the \\nstandard for commercial relational DBMSs. (Additional aspects of SQL will be cov-\\nered in other chapters.) Chapter 8 covers the operations of the relational algebra and \\nintroduces the relational calculus—these are two formal languages associated with \\nthe relational model. The relational calculus is considered to be the basis for the \\nSQL language, and the relational algebra is used in the internals of many database \\nimplementations for query processing and optimization (see Part 8 of the book).\\nchapter 5'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 163, 'page_label': '164'}, page_content='150 Chapter 5 The Relational Data Model and Relational Database Constraints\\nOther features of the relational model are presented in subsequent parts of the \\nbook. Chapter 9 relates the relational model data structures to the constructs of the \\nER and EER models (presented in Chapters 3 and 4), and presents algorithms for \\ndesigning a relational database schema by mapping a conceptual schema in the ER \\nor EER model into a relational representation. These mappings are incorporated \\ninto many database design and CASE\\n1 tools. Chapters 10 and 11 in Part 4 discuss \\nthe programming techniques used to access database systems and the notion of \\nconnecting to relational databases via ODBC and JDBC standard protocols. We \\nalso introduce the topic of Web database programming in Chapter 11. Chapters 14 \\nand 15 in Part 6 present another aspect of the relational model, namely the formal \\nconstraints of functional and multivalued dependencies; these dependencies are \\nused to develop a relational database design theory based on the concept known as \\nnormalization.\\nIn this chapter, we concentrate on describing the basic principles of the relational \\nmodel of data. We begin by defining the modeling concepts and notation of the \\nrelational model in Section 5.1. Section 5.2 is devoted to a discussion of relational \\nconstraints that are considered an important part of the relational model and are \\nautomatically enforced in most relational DBMSs. Section 5.3 defines the update \\noperations of the relational model, discusses how violations of integrity constraints \\nare handled, and introduces the concept of a transaction. Section 5.4 summarizes \\nthe chapter.\\nThis chapter and Chapter 8 focus on the formal foundations of the relational model, \\nwhereas Chapters 6 and 7 focus on the SQL practical relational model, which is the \\nbasis of most commercial and open source relational DBMSs. Many concepts are \\ncommon between the formal and practical models, but a few differences exist that \\nwe shall point out.\\n5.1 Relational Model Concepts\\nThe relational model represents the database as a collection of relations. Informally, \\neach relation resembles a table of values or, to some extent, a flat file of records. It is \\ncalled a flat file because each record has a simple linear or flat structure. For exam-\\nple, the database of files that was shown in Figure 1.2 is similar to the basic rela-\\ntional model representation. However, there are important differences between \\nrelations and files, as we shall soon see.\\nWhen a relation is thought of as a table of values, each row in the table represents a \\ncollection of related data values. A row represents a fact that typically corresponds \\nto a real-world entity or relationship. The table name and column names are used \\nto help to interpret the meaning of the values in each row. For example, the \\nfirst table of Figure 1.2 is called \\nSTUDENT  because each row represents facts \\nabout a particular student entity. The column names— Name, Student_number , \\n1CASE stands for computer-aided software engineering.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 164, 'page_label': '165'}, page_content='5.1 Relational Model Concepts  151\\nClass, and Major—specify how to interpret the data values in each row, based on the \\ncolumn each value is in. All values in a column are of the same data type.\\nIn the formal relational model terminology, a row is called a tuple,  a column \\nheader is called an attribute,  and the table is called a relation.  The data type \\ndescribing the types of values that can appear in each column is represented by a \\ndomain of possible values. We now define these terms— domain, tuple, attribute,  \\nand relation—formally.\\n5.1.1 Domains, Attributes, Tuples, and Relations\\nA domain D is a set of atomic values. By atomic we mean that each value in the \\ndomain is indivisible as far as the formal relational model is concerned. A common \\nmethod of specifying a domain is to specify a data type from which the data values \\nforming the domain are drawn. It is also useful to specify a name for the domain, to \\nhelp in interpreting its values. Some examples of domains follow:\\n ■ Usa_phone_numbers. The set of ten-digit phone numbers valid in the United \\nStates.\\n ■ Local_phone_numbers. The set of seven-digit phone numbers valid within a \\nparticular area code in the United States. The use of local phone numbers is \\nquickly becoming obsolete, being replaced by standard ten-digit numbers.\\n ■ Social_security_numbers. The set of valid nine-digit Social Security numbers. \\n(This is a unique identifier assigned to each person in the United States for \\nemployment, tax, and benefits purposes.)\\n ■ Names: The set of character strings that represent names of persons.\\n ■ Grade_point_averages . Possible values of computed grade point averages; \\neach must be a real (floating-point) number between 0 and 4.\\n ■ Employee_ages. Possible ages of employees in a company; each must be an \\ninteger value between 15 and 80.\\n ■ Academic_department_names . The set of academic department names in a \\nuniversity, such as Computer Science, Economics, and Physics.\\n ■ Academic_department_codes. The set of academic department codes, such as \\n‘CS’, ‘ECON’, and ‘PHYS’.\\nThe preceding are called logical definitions of domains. A data type or format is \\nalso specified for each domain. For example, the data type for the domain  \\nUsa_phone_numbers can be declared as a character string of the form (ddd)ddd-dddd, \\nwhere each d is a numeric (decimal) digit and the first three digits form a valid  \\ntelephone area code. The data type for Employee_ages is an integer number between \\n15 and 80. For Academic_department_names, the data type is the set of all character \\nstrings that represent valid department names. A domain is thus given a name, data \\ntype, and format. Additional information for interpreting the values of a domain \\ncan also be given; for example, a numeric domain such as \\nPerson_weights should \\nhave the units of measurement, such as pounds or kilograms.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 165, 'page_label': '166'}, page_content='152 Chapter 5 The Relational Data Model and Relational Database Constraints\\nA relation schema2 R, denoted by R(A1, A2, … , An), is made up of a relation name \\nR and a list of attributes, A1, A2, … , An. Each attribute Ai is the name of a role \\nplayed by some domain D in the relation schema R. D is called the domain of Ai \\nand is denoted by dom(Ai). A relation schema is used to describe a relation; R is \\ncalled the name of this relation. The degree (or arity) of a relation is the number of \\nattributes n of its relation schema.\\nA relation of degree seven, which stores information about university students, \\nwould contain seven attributes describing each student as follows:\\nSTUDENT(Name, Ssn, Home_phone, Address, Office_phone, Age, Gpa)\\nUsing the data type of each attribute, the definition is sometimes written as:\\nSTUDENT(Name: string, Ssn: string, Home_phone: string, Address: string, \\nOffice_phone: string, Age: integer, Gpa: real)\\nFor this relation schema, STUDENT is the name of the relation, which has seven \\nattributes. In the preceding definition, we showed assignment of generic types such \\nas string or integer to the attributes. More precisely, we can specify the following \\npreviously defined domains for some of the attributes of the STUDENT relation: \\ndom(Name) = Names; dom( Ssn) = Social_security_numbers;  dom( HomePhone ) = \\nUSA_phone_numbers3, dom(Office_phone) = USA_phone_numbers, and dom( Gpa) = \\nGrade_point_averages. It is also possible to refer to attributes of a relation schema by \\ntheir position within the relation; thus, the second attribute of the STUDENT rela-\\ntion is Ssn, whereas the fourth attribute is Address.\\nA relation (or relation state)4 r of the relation schema R(A1, A2, … , An), also denoted \\nby r(R), is a set of n-tuples r = {t1, t2, … , tm}. Each n-tuple t is an ordered list of n \\nvalues t =<v1, v2, … , vn>, where each value vi, 1 ≤ i ≤ n, is an element of dom (Ai) or is \\na special NULL value. (NULL values are discussed further below and in Section 5.1.2.) \\nThe ith value in tuple t, which corresponds to the attribute Ai, is referred to as t[Ai] or \\nt.Ai (or t[i] if we use the positional notation). The terms relation intension for the \\nschema R and relation extension for a relation state r(R) are also commonly used.\\nFigure 5.1 shows an example of a STUDENT relation, which corresponds to the \\nSTUDENT schema just specified. Each tuple in the relation represents a particular \\nstudent entity (or object). We display the relation as a table, where each tuple is \\nshown as a row and each attribute corresponds to a column header indicating a role \\nor interpretation of the values in that column. NULL values  represent attributes \\nwhose values are unknown or do not exist for some individual \\nSTUDENT tuple.\\n2A relation schema is sometimes called a relation scheme.\\n3With the large increase in phone numbers caused by the proliferation of mobile phones, most metropol-\\nitan areas in the United States now have multiple area codes, so seven-digit local dialing has been \\n discontinued in most areas. We changed this domain to Usa_phone_numbers instead of Local_phone_\\nnumbers, which would be a more general choice. This illustrates how database requirements can change \\nover time.\\n4This has also been called a relation instance. We will not use this term because instance is also used \\nto refer to a single tuple or row.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 166, 'page_label': '167'}, page_content='5.1 Relational Model Concepts  153\\nThe earlier definition of a relation can be restated more formally using set theory \\nconcepts as follows. A relation (or relation state) r(R) is a mathematical relation of \\ndegree n on the domains dom(A1), dom(A2), … , dom(An), which is a subset of the \\nCartesian product (denoted by ×) of the domains that define R:\\nr(R) ⊆ (dom(A1) × dom(A2) × . . . × (dom(An))\\nThe Cartesian product specifies all possible combinations of values from the under-\\nlying domains. Hence, if we denote the total number of values, or cardinality, in a \\ndomain D by |D| (assuming that all domains are finite), the total number of tuples \\nin the Cartesian product is\\n|dom(A1)| × |dom(A2)| × . . . × |dom(An)|\\nThis product of cardinalities of all domains represents the total number of possible \\ninstances or tuples that can ever exist in any relation state r(R). Of all these possible \\ncombinations, a relation state at a given time—the current relation state—reflects \\nonly the valid tuples that represent a particular state of the real world. In general, as \\nthe state of the real world changes, so does the relation state, by being transformed \\ninto another relation state. However, the schema R is relatively static and changes \\nvery infrequently—for example, as a result of adding an attribute to represent new \\ninformation that was not originally stored in the relation.\\nIt is possible for several attributes to have the same domain. The attribute names indi-\\ncate different roles, or interpretations, for the domain. For example, in the \\nSTUDENT \\nrelation, the same domain USA_phone_numbers plays the role of Home_phone, referring \\nto the home phone of a student , and the role of Office_phone, referring to the office \\nphone of the student. A third possible attribute (not shown) with the same domain \\ncould be Mobile_phone.\\n5.1.2 Characteristics of Relations\\nThe earlier definition of relations implies certain characteristics that make a rela-\\ntion different from a file or a table. We now discuss some of these characteristics.\\nRelation Name\\nTuples\\nSTUDENT\\nName\\nBenjamin Bayer\\nChung-cha Kim\\nDick Davidson\\nRohan Panchal\\nBarbara Benson\\nSsn\\n305-61-2435\\n381-62-1245\\n422-11-2320\\n489-22-1100\\n533-69-1238\\nHome_phone\\n(817)373-1616\\n(817)375-4409\\nNULL\\n(817)376-9821\\n(817)839-8461\\nAddress\\n2918 Bluebonnet Lane\\n125 Kirby Road\\n3452 Elgin Road\\n265 Lark Lane\\n7384 Fontana Lane\\nOffice_phone\\nNULL\\nNULL\\n(817)749-1253\\n(817)749-6492\\nNULL\\nAge\\n19\\n18\\n25\\n28\\n19\\n3.21\\n2.89\\n3.53\\n3.93\\n3.25\\nGpa\\nAttributes\\nFigure 5.1 \\nThe attributes and tuples of a relation STUDENT.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 167, 'page_label': '168'}, page_content='154 Chapter 5 The Relational Data Model and Relational Database Constraints\\nOrdering of Tuples in a Relation. A relation is defined as a set of tuples. Math-\\nematically, elements of a set have no order among them; hence, tuples in a relation \\ndo not have any particular order. In other words, a relation is not sensitive to the \\nordering of tuples. However, in a file, records are physically stored on disk (or in \\nmemory), so there always is an order among the records. This ordering indicates \\nfirst, second, ith, and last records in the file. Similarly, when we display a relation as \\na table, the rows are displayed in a certain order.\\nTuple ordering is not part of a relation definition because a relation attempts to rep-\\nresent facts at a logical or abstract level. Many tuple orders can be specified on the \\nsame relation. For example, tuples in the \\nSTUDENT relation in Figure 5.1 could be \\nordered by values of Name, Ssn, Age, or some other attribute. The definition of a rela-\\ntion does not specify any order: There is no preference for one ordering over another. \\nHence, the relation displayed in Figure 5.2 is considered identical to the one shown in \\nFigure 5.1. When a relation is implemented as a file or displayed as a table, a particular \\nordering may be specified on the records of the file or the rows of the table.\\nOrdering of Values within a Tuple and an Alternative Definition of a Relation.  \\nAccording to the preceding definition of a relation, an n-tuple is an ordered list of n \\nvalues, so the ordering of values in a tuple—and hence of attributes in a relation \\nschema—is important. However, at a more abstract level, the order of attributes \\nand their values is not that important as long as the correspondence between attri-\\nbutes and values is maintained.\\nAn alternative definition of a relation can be given, making the ordering of values \\nin a tuple unnecessary. In this definition, a relation schema R = {A\\n1, A2, … , An} is a \\nset of attributes (instead of an ordered list of attributes), and a relation state r(R) is \\na finite set of mappings r = {t1, t2, … , tm}, where each tuple ti is a mapping from R \\nto D, and D is the union (denoted by ∪) of the attribute domains; that is, D = \\ndom(A1) ∪ dom(A2) ∪ … ∪ dom(An). In this definition, t[Ai] must be in dom(Ai) \\nfor 1 ≤ i ≤ n for each mapping t in r. Each mapping ti is called a tuple.\\nAccording to this definition of tuple as a mapping, a tuple can be considered as a \\nset of (<attribute>, <value>) pairs, where each pair gives the value of the mapping \\nfrom an attribute Ai to a value vi from dom( Ai). The ordering of attributes is not \\nimportant, because the attribute name appears with its value. By this definition, the \\nDick Davidson\\nBarbara Benson\\nRohan Panchal\\nChung-cha Kim\\n422-11-2320\\n533-69-1238\\n489-22-1100\\n381-62-1245\\nNULL\\n(817)839-8461\\n(817)376-9821\\n(817)375-4409\\n3452 Elgin Road\\n7384 Fontana Lane\\n265 Lark Lane\\n125 Kirby Road\\n(817)749-1253\\nNULL\\n(817)749-6492\\nNULL\\n25\\n19\\n28\\n18\\n3.53\\n3.25\\n3.93\\n2.89\\nBenjamin Bayer 305-61-2435 (817)373-1616 2918 Bluebonnet Lane NUL L 19 3.21\\nSTUDENT\\nName Ssn Home_phone Address Office_phone Age Gpa\\nFigure 5.2 \\nThe relation STUDENT from Figure 5.1 with a different order of tuples.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 168, 'page_label': '169'}, page_content='5.1 Relational Model Concepts  155\\ntwo tuples shown in Figure 5.3 are identical. This makes sense at an abstract level, \\nsince there really is no reason to prefer having one attribute value appear before \\nanother in a tuple. When the attribute name and value are included together in a \\ntuple, it is known as self-describing data , because the description of each value \\n(attribute name) is included in the tuple.\\nWe will mostly use the first definition of relation, where the attributes are ordered \\nin the relation schema and the values within tuples are similarly ordered, because it \\nsimplifies much of the notation. However, the alternative definition given here is \\nmore general.\\n5\\nValues and NULLs in the Tuples. Each value in a tuple is an atomic value; that \\nis, it is not divisible into components within the framework of the basic relational \\nmodel. Hence, composite and multivalued attributes (see Chapter 3) are not \\nallowed. This model is sometimes called the flat relational model . Much of the \\ntheory behind the relational model was developed with this assumption in mind, \\nwhich is called the first normal form  assumption.\\n6 Hence, multivalued attributes \\nmust be represented by separate relations, and composite attributes are represented \\nonly by their simple component attributes in the basic relational model.7\\nAn important concept is that of NULL values, which are used to represent the values of \\nattributes that may be unknown or may not apply to a tuple. A special value, called \\nNULL, is used in these cases. For example, in Figure 5.1, some STUDENT tuples have \\nNULL for their office phones because they do not have an office (that is, office phone \\ndoes not apply to these students). Another student has a NULL for home phone, presum-\\nably because either he does not have a home phone or he has one but we do not know it \\n(value is unknown). In general, we can have several meanings for NULL values, such as \\nvalue unknown, value exists but is not available, or attribute does not apply to this tuple \\n(also known as value undefined). An example of the last type of NULL will occur if we \\nadd an attribute Visa_status to the STUDENT relation that applies only to tuples repre-\\nsenting foreign students. It is possible to devise different codes for different meanings of \\n5We will use the alternative definition of relation when we discuss query processing and optimization in \\nChapter 18.\\n6We discuss this assumption in more detail in Chapter 14.\\n7Extensions of the relational model remove these restrictions. For example, object-relational systems \\n(Chapter 12) allow complex-structured attributes, as do the non-first normal form or nested relational \\nmodels.\\nt = < (Name, Dick Davidson),(Ssn, 422-11-2320),(Home_phone, NULL),(Address, 3452 Elgin Road),\\n   (Office_phone, (817)749-1253),(Age, 25),(Gpa, 3.53)>\\nt = < (Address, 3452 Elgin Road),(Name, Dick Davidson),(Ssn, 422-11-2320),(Age, 25),\\n    (Office_phone, (817)749-1253),(Gpa, 3.53),(Home_phone, NULL)>\\nFigure 5.3 \\nTwo identical tuples when the order of attributes and values is not part of relation definition.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 169, 'page_label': '170'}, page_content='156 Chapter 5 The Relational Data Model and Relational Database Constraints\\nNULL values. Incorporating different types of NULL values into relational model opera-\\ntions has proven difficult and is outside the scope of our presentation.\\nThe exact meaning of a NULL value governs how it fares during arithmetic aggrega-\\ntions or comparisons with other values. For example, a comparison of two NULL \\nvalues leads to ambiguities—if both Customer A and B have NULL addresses, it does \\nnot mean they have the same address. During database design, it is best to avoid \\nNULL values as much as possible. We will discuss this further in Chapters 7 and 8 in \\nthe context of operations and queries, and in Chapter 14 in the context of database \\ndesign and normalization.\\nInterpretation (Meaning) of a Relation. The relation schema can be interpreted \\nas a declaration or a type of assertion. For example, the schema of the \\nSTUDENT \\nrelation of Figure 5.1 asserts that, in general, a student entity has a Name, Ssn, \\nHome_phone, Address, Office_phone, Age, and Gpa. Each tuple in the relation can \\nthen be interpreted as a fact or a particular instance of the assertion. For example, \\nthe first tuple in Figure 5.1 asserts the fact that there is a STUDENT whose Name is \\nBenjamin Bayer, Ssn is 305-61-2435, Age is 19, and so on.\\nNotice that some relations may represent facts about entities, whereas other rela-\\ntions may represent facts about relationships.  For example, a relation schema \\nMAJORS (Student_ssn, Department_code ) asserts that students major in academic \\ndisciplines. A tuple in this relation relates a student to his or her major discipline. \\nHence, the relational model represents facts about both entities and relationships \\nuniformly as relations. This sometimes compromises understandability because \\none has to guess whether a relation represents an entity type or a relationship type. \\nWe introduced the entity–relationship (ER) model in detail in Chapter 3, where the \\nentity and relationship concepts were described in detail. The mapping procedures \\nin Chapter 9 show how different constructs of the ER/EER conceptual data models \\n(see Part 2) get converted to relations.\\nAn alternative interpretation of a relation schema is as a predicate; in this case, the \\nvalues in each tuple are interpreted as values that satisfy the predicate. For example, \\nthe predicate \\nSTUDENT (Name, Ssn, …) is true for the five tuples in relation STUDENT \\nof Figure 5.1. These tuples represent five different propositions or facts in the \\nreal world. This interpretation is quite useful in the context of logical programming \\nlanguages, such as Prolog, because it allows the relational model to be used within \\nthese languages (see Section 26.5). An assumption called the closed world assumption \\nstates that the only true facts in the universe are those present within the extension \\n(state) of the relation(s). Any other combination of values makes the predicate false. \\nThis interpretation is useful when we consider queries on relations based on \\n relational calculus in Section 8.6.\\n5.1.3 Relational Model Notation\\nWe will use the following notation in our presentation:\\n ■ A relation schema R of degree n is denoted by R(A1, A2, … , An).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 170, 'page_label': '171'}, page_content='5.2 Relational Model Constraints and Relational Database Schemas  157\\n ■ The uppercase letters Q, R, S denote relation names.\\n ■ The lowercase letters q, r, s denote relation states.\\n ■ The letters t, u, v denote tuples.\\n ■ In general, the name of a relation schema such as STUDENT also indicates \\nthe current set of tuples in that relation—the current relation state—whereas \\nSTUDENT(Name, Ssn, …) refers only to the relation schema.\\n ■ An attribute A can be qualified with the relation name R to which it belongs \\nby using the dot notation R.A —for example, STUDENT.Name  or  \\nSTUDENT.Age. This is because the same name may be used for two attri-\\nbutes in different relations. However, all attribute names in a particular \\nrelation must be distinct.\\n ■ An n-tuple t in a relation r(R) is denoted by t = <v1, v2, … , vn>, where vi is \\nthe value corresponding to attribute Ai. The following notation refers to \\ncomponent values of tuples:\\n /box4Both t[Ai] and t.Ai (and sometimes t[i]) refer to the value vi in t for attri-\\nbute Ai.\\n /box4Both t[Au, Aw, … , Az] and t.(Au, Aw, … , Az), where Au, Aw, … , Az is a list \\nof attributes from R, refer to the subtuple of values <vu, vw, … , vz> from t \\ncorresponding to the attributes specified in the list.\\nAs an example, consider the tuple t = <’Barbara Benson’, ‘533-69-1238’,  \\n‘(817)839-8461’, ‘7384 Fontana Lane’, NULL, 19, 3.25> from the STUDENT relation in Fig-\\nure 5.1; we have t[Name] = <‘Barbara Benson’>, and t[Ssn, Gpa, Age] = <‘533-69-1238’, \\n3.25, 19>.\\n5.2  Relational Model Constraints  \\nand Relational Database Schemas\\nSo far, we have discussed the characteristics of single relations. In a relational data-\\nbase, there will typically be many relations, and the tuples in those relations are \\nusually related in various ways. The state of the whole database will correspond to \\nthe states of all its relations at a particular point in time. There are generally many \\nrestrictions or constraints on the actual values in a database state. These constraints \\nare derived from the rules in the miniworld that the database represents, as we dis-\\ncussed in Section 1.6.8.\\nIn this section, we discuss the various restrictions on data that can be specified on a \\nrelational database in the form of constraints. Constraints on databases can gener-\\nally be divided into three main categories:\\n  1. Constraints that are inherent in the data model. We call these inherent \\nmodel-based constraints or implicit constraints.\\n  2. Constraints that can be directly expressed in the schemas of the data model, typi-\\ncally by specifying them in the DDL (data definition language, see Section 2.3.1). \\nWe call these schema-based constraints or explicit constraints.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 171, 'page_label': '172'}, page_content='158 Chapter 5 The Relational Data Model and Relational Database Constraints\\n  3. Constraints that cannot be directly expressed in the schemas of the data \\nmodel, and hence must be expressed and enforced by the application pro-\\ngrams or in some other way. We call these application-based or semantic \\nconstraints or business rules.\\nThe characteristics of relations that we discussed in Section 5.1.2 are the inherent \\nconstraints of the relational model and belong to the first category. For example, the \\nconstraint that a relation cannot have duplicate tuples is an inherent constraint. The \\nconstraints we discuss in this section are of the second category, namely, constraints \\nthat can be expressed in the schema of the relational model via the DDL. Constraints \\nin the third category are more general, relate to the meaning as well as behavior of \\nattributes, and are difficult to express and enforce within the data model, so they are \\nusually checked within the application programs that perform database updates. In \\nsome cases, these constraints can be specified as assertions in SQL (see Chapter 7).\\nAnother important category of constraints is data dependencies , which include \\nfunctional dependencies  and multivalued dependencies . They are used mainly for \\ntesting the “goodness” of the design of a relational database and are utilized in a \\nprocess called normalization, which is discussed in Chapters 14 and 15.\\nThe schema-based constraints include domain constraints, key constraints, con-\\nstraints on \\nNULLs, entity integrity constraints, and referential integrity constraints.\\n5.2.1 Domain Constraints\\nDomain constraints specify that within each tuple, the value of each attribute A must \\nbe an atomic value from the domain dom(A). We have already discussed the ways in \\nwhich domains can be specified in Section 5.1.1. The data types associated with \\ndomains typically include standard numeric data types for integers (such as short \\ninteger, integer, and long integer) and real numbers (float and double-precision float). \\nCharacters, Booleans, fixed-length strings, and variable-length strings are also avail-\\nable, as are date, time, timestamp, and other special data types. Domains can also be \\ndescribed by a subrange of values from a data type or as an enumerated data type in \\nwhich all possible values are explicitly listed. Rather than describe these in detail here, \\nwe discuss the data types offered by the SQL relational standard in Section 6.1.\\n5.2.2 Key Constraints and Constraints on NULL Values\\nIn the formal relational model, a relation is defined as a set of tuples. By definition, \\nall elements of a set are distinct; hence, all tuples in a relation must also be distinct. \\nThis means that no two tuples can have the same combination of values for all their \\nattributes. Usually, there are other subsets of attributes of a relation schema R with \\nthe property that no two tuples in any relation state r of R should have the same \\ncombination of values for these attributes. Suppose that we denote one such subset \\nof attributes by SK; then for any two distinct tuples t\\n1 and t2 in a relation state r of R, \\nwe have the constraint that:\\nt1[SK] ≠ t2[SK]'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 172, 'page_label': '173'}, page_content='5.2 Relational Model Constraints and Relational Database Schemas  159\\nAny such set of attributes SK is called a superkey of the relation schema R. A super-\\nkey SK specifies a uniqueness constraint that no two distinct tuples in any state r of \\nR can have the same value for SK. Every relation has at least one default superkey—\\nthe set of all its attributes. A superkey can have redundant attributes, however, so a \\nmore useful concept is that of a key, which has no redundancy. A key k of a relation \\nschema R is a superkey of R with the additional property that removing any attri-\\nbute A from K leaves a set of attributes K′ that is not a superkey of R any more. \\nHence, a key satisfies two properties:\\n  1. Two distinct tuples in any state of the relation cannot have identical values \\nfor (all) the attributes in the key. This uniqueness property also applies to a \\nsuperkey.\\n  2. It is a minimal superkey—that is, a superkey from which we cannot remove \\nany attributes and still have the uniqueness constraint hold. This minimality \\nproperty is required for a key but is optional for a superkey.\\nHence, a key is a superkey but not vice versa. A superkey may be a key (if it is mini-\\nmal) or may not be a key (if it is not minimal). Consider the STUDENT relation of \\nFigure 5.1. The attribute set { Ssn} is a key of STUDENT because no two student \\ntuples can have the same value for Ssn.8 Any set of attributes that includes Ssn—for \\nexample, {Ssn, Name, Age}—is a superkey. However, the superkey {Ssn, Name, Age} \\nis not a key of STUDENT because removing Name or Age or both from the set still \\nleaves us with a superkey. In general, any superkey formed from a single attribute is \\nalso a key. A key with multiple attributes must require all its attributes together to \\nhave the uniqueness property.\\nThe value of a key attribute can be used to identify uniquely each tuple in the rela-\\ntion. For example, the Ssn value 305-61-2435 identifies uniquely the tuple corre-\\nsponding to Benjamin Bayer in the STUDENT relation. Notice that a set of attributes \\nconstituting a key is a property of the relation schema; it is a constraint that should \\nhold on every valid relation state of the schema. A key is determined from the mean-\\ning of the attributes, and the property is time-invariant: It must continue to hold \\nwhen we insert new tuples in the relation. For example, we cannot and should not \\ndesignate the \\nName attribute of the STUDENT relation in Figure 5.1 as a key because \\nit is possible that two students with identical names will exist at some point in a \\nvalid state.9\\nIn general, a relation schema may have more than one key. In this case, each of the \\nkeys is called a candidate key. For example, the CAR relation in Figure 5.4 has two \\ncandidate keys: License_number and Engine_serial_number. It is common to designate \\none of the candidate keys as the primary key of the relation. This is the candidate \\nkey whose values are used to identify tuples in the relation. We use the convention \\nthat the attributes that form the primary key of a relation schema are underlined, as \\nshown in Figure 5.4. Notice that when a relation schema has several candidate keys, \\n8Note that Ssn is also a superkey.\\n9Names are sometimes used as keys, but then some artifact—such as appending an ordinal number—must \\nbe used to distinguish between persons with identical names.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 173, 'page_label': '174'}, page_content='160 Chapter 5 The Relational Data Model and Relational Database Constraints\\nthe choice of one to become the primary key is somewhat arbitrary; however, it is \\nusually better to choose a primary key with a single attribute or a small number \\nof attributes. The other candidate keys are designated as unique keys  and are \\nnot underlined.\\nAnother constraint on attributes specifies whether \\nNULL values are or are not per-\\nmitted. For example, if every STUDENT tuple must have a valid, non-NULL value for \\nthe Name attribute, then Name of STUDENT is constrained to be NOT NULL.\\n5.2.3 Relational Databases and Relational  \\nDatabase Schemas\\nThe definitions and constraints we have discussed so far apply to single relations \\nand their attributes. A relational database usually contains many relations, with \\ntuples in relations that are related in various ways. In this section, we define a rela-\\ntional database and a relational database schema.\\nA relational database schema S is a set of relation schemas S = {R\\n1, R2, … , Rm} and \\na set of integrity constraints  IC. A relational database state 10 DB of S is a set of \\nrelation states DB = {r1, r2, … , rm} such that each ri is a state of Ri and such that the \\nri relation states satisfy the integrity constraints specified in IC. Figure 5.5 shows a \\nrelational database schema that we call COMPANY = { EMPLOYEE, DEPARTMENT, \\nDEPT_LOCATIONS, PROJECT, WORKS_ON, DEPENDENT}. In each relation schema, \\nthe underlined attribute represents the primary key. Figure 5.6 shows a relational \\ndatabase state corresponding to the \\nCOMPANY schema. We will use this schema \\nand database state in this chapter and in Chapters 4 through 6 for developing \\nsample queries in different relational languages. (The data shown here is \\nexpanded and available for loading as a populated database from the Compan-\\nion Website for the text, and can be used for the hands-on project exercises at \\nthe end of the chapters.)\\nWhen we refer to a relational database, we implicitly include both its schema and its \\ncurrent state. A database state that does not obey all the integrity constraints is \\nCAR\\nLicense_number Engine_serial_number Make Model Year\\nTexas ABC-739\\nFlorida TVP-347\\nNew York MPO-22\\nCalifornia 432-TFY\\nCalifornia RSK-629\\nTexas RSK-629\\nA69352\\nB43696\\nX83554\\nC43742\\nY82935\\nU028365\\nFord\\nOldsmobile\\nOldsmobile\\nMercedes\\nToyota\\nJaguar\\nMustang\\nCutlass\\nDelta\\n190-D\\nCamry\\nXJS\\n02\\n05\\n01\\n99\\n04\\n04\\nFigure 5.4 \\nThe CAR relation, with \\ntwo candidate keys: \\nLicense_number and \\nEngine_serial_number.\\n10A relational database state is sometimes called a relational database snapshot or instance. However, \\nas we mentioned earlier, we will not use the term instance since it also applies to single tuples.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 174, 'page_label': '175'}, page_content='5.2 Relational Model Constraints and Relational Database Schemas  161\\ncalled not valid , and a state that satisfies all the constraints in the defined set of \\nintegrity constraints IC is called a valid state.\\nIn Figure 5.5, the Dnumber attribute in both DEPARTMENT and DEPT_LOCATIONS \\nstands for the same real-world concept—the number given to a department. That \\nsame concept is called \\nDno in EMPLOYEE and Dnum in PROJECT. Attributes that \\nrepresent the same real-world concept may or may not have identical names in dif-\\nferent relations. Alternatively, attributes that represent different concepts may have \\nthe same name in different relations. For example, we could have used the attribute \\nname \\nName for both Pname of PROJECT and Dname of DEPARTMENT; in this case, we \\nwould have two attributes that share the same name but represent different real-\\nworld concepts—project names and department names.\\nIn some early versions of the relational model, an assumption was made that the \\nsame real-world concept, when represented by an attribute, would have identical \\nattribute names in all relations. This creates problems when the same real-world \\nconcept is used in different roles (meanings) in the same relation. For example, the \\nconcept of Social Security number appears twice in the \\nEMPLOYEE relation of \\nFigure 5.5: once in the role of the employee’s SSN, and once in the role of the \\nsupervisor’s SSN. We are required to give them distinct attribute names—\\nSsn and \\nSuper_ssn, respectively—because they appear in the same relation and in order to \\ndistinguish their meaning.\\nEach relational DBMS must have a data definition language (DDL) for defining a \\nrelational database schema. Current relational DBMSs are mostly using SQL for \\nthis purpose. We present the SQL DDL in Sections 6.1 and 6.2. \\nDEPARTMENT\\nFname Minit Lname Ssn Bdate Address Sex Salary Super_ssn Dno\\nEMPLOYEE\\nDEPT_LOCATIONS\\nDnumber Dlocation\\nPROJECT\\nPname Pnumber Plocation Dnum\\nWORKS_ON\\nEssn Pno Hours\\nDEPENDENT\\nEssn Dependent_name Sex Bdate Relationship\\nDname Dnumber Mgr_ssn Mgr_start_date\\nFigure 5.5 \\nSchema diagram for the \\nCOMPANY relational \\ndatabase schema.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 175, 'page_label': '176'}, page_content='162 Chapter 5 The Relational Data Model and Relational Database Constraints\\nDEPT_LOCATIONS\\nDnumber\\nHouston\\nStafford\\nBellaire\\nSugarland\\nDlocation\\nDEPARTMENT\\nDname\\nResearch\\nAdministration\\nHeadquarters 1\\n5\\n4\\n888665555\\n333445555\\n987654321\\n1981-06-19\\n1988-05-22\\n1995-01-01\\nDnumber Mgr_ssn Mgr_start_date\\nWORKS_ON\\nEssn\\n123456789\\n123456789\\n666884444\\n453453453\\n453453453\\n333445555\\n333445555\\n333445555\\n333445555\\n999887777\\n999887777\\n987987987\\n987987987\\n987654321\\n987654321\\n888665555\\n3\\n1\\n2\\n2\\n1\\n2\\n30\\n30\\n30\\n10\\n10\\n3\\n10\\n20\\n20\\n20\\n40.0\\n32.5\\n7. 5\\n10.0\\n10.0\\n10.0\\n10.0\\n20.0\\n20.0\\n30.0\\n5.0\\n10.0\\n35.0\\n20.0\\n15.0\\nNULL\\nPno\\nHours\\nPROJECT\\nPname\\nProductX\\nProductY\\nProductZ\\nComputerization\\nReorganization\\nNewbenefits\\n3\\n1\\n2\\n30\\n10\\n20\\n5\\n5\\n5\\n4\\n4\\n1\\nHouston\\nBellaire\\nSugarland\\nStafford\\nStafford\\nHouston\\nPnumber Plocation Dnum\\nDEPENDENT\\n333445555\\n333445555\\n333445555\\n987654321\\n123456789\\n123456789\\n123456789\\nJoy\\nAlice F\\nM\\nF\\nM\\nM\\nF\\nF\\n1986-04-05\\n1983-10-25\\n1958-05-03\\n1942-02-28\\n1988-01-04\\n1988-12-30\\n1967-05-05\\nTheodore\\nAlice\\nElizabeth\\nAbner\\nMichael\\nSpouse\\nDaughter\\nSon\\nDaughter\\nSpouse\\nSpouse\\nSon\\nDependent_name Sex Bdate Relationship\\nEMPLOYEE\\nFname\\nJohn\\nFranklin\\nJennifer\\nAlicia\\nRamesh\\nJoyce\\nJames\\nAhmad\\nNarayan\\nEnglish\\nBorg\\nJabbar\\n666884444\\n453453453\\n888665555\\n987987987\\nF\\nF\\nM\\nM\\nM\\nM\\nM\\nF\\n4\\n4\\n5\\n5\\n4\\n1\\n5\\n5\\n25000\\n43000\\n30000\\n40000\\n25000\\n55000\\n38000\\n25000\\n987654321\\n888665555\\n333445555\\n888665555\\n987654321\\nNULL\\n333445555\\n333445555\\nZelaya\\nWallace\\nSmith\\nWong\\n3321 Castle, Spring, TX\\n291 Berry, Bellaire, TX\\n731 Fondren, Houston, TX\\n638 Voss, Houston, TX\\n1968-01-19\\n1941-06-20\\n1965-01-09\\n1955-12-08\\n1969-03-29\\n1937-11-10\\n1962-09-15\\n1972-07-31\\n980 Dallas, Houston, TX\\n450 Stone, Houston, TX\\n975 Fire Oak, Humble, TX\\n5631 Rice, Houston, TX\\n999887777\\n987654321\\n123456789\\n333445555\\nMinit Lname Ssn  Bdate Address Sex Dno Salary Super_ssn\\nB\\nT\\nJ\\nS\\nK\\nA\\nV\\nE Houston\\n1\\n4\\n5\\n5\\nEssn\\n5\\nFigure 5.6 \\nOne possible database state for the COMPANY relational database schema.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 176, 'page_label': '177'}, page_content='5.2 Relational Model Constraints and Relational Database Schemas  163\\nIntegrity constraints are specified on a database schema and are expected to hold on \\nevery valid database state of that schema. In addition to domain, key, and NOT NULL \\nconstraints, two other types of constraints are considered part of the relational \\nmodel: entity integrity and referential integrity.\\n5.2.4 Entity Integrity, Referential Integrity, and Foreign Keys\\nThe entity integrity constraint states that no primary key value can be NULL. This is \\nbecause the primary key value is used to identify individual tuples in a relation. Hav-\\ning \\nNULL values for the primary key implies that we cannot identify some tuples. For \\nexample, if two or more tuples had NULL for their primary keys, we may not be able \\nto distinguish them if we try to reference them from other relations.\\nKey constraints and entity integrity constraints are specified on individual relations. \\nThe referential integrity constraint is specified between two relations and is used to \\nmaintain the consistency among tuples in the two relations. Informally, the referen-\\ntial integrity constraint states that a tuple in one relation that refers to another rela-\\ntion must refer to an existing tuple in that relation. For example, in Figure 5.6, the \\nattribute \\nDno of EMPLOYEE gives the department number for which each employee \\nworks; hence, its value in every EMPLOYEE tuple must match the Dnumber value of \\nsome tuple in the DEPARTMENT relation.\\nTo define referential integrity more formally, first we define the concept of a foreign \\nkey. The conditions for a foreign key, given below, specify a referential integrity \\nconstraint between the two relation schemas R1 and R2. A set of attributes FK in \\nrelation schema R1 is a foreign key of R1 that references relation R2 if it satisfies the \\nfollowing rules:\\n  1. The attributes in FK have the same domain(s) as the primary key attributes \\nPK of R\\n2; the attributes FK are said to reference or refer to the relation R2.\\n  2. A value of FK in a tuple t1 of the current state r1(R1) either occurs as a value \\nof PK for some tuple t2 in the current state r2(R2) or is NULL. In the former \\ncase, we have t1[FK] = t2[PK], and we say that the tuple t1 references or \\nrefers to the tuple t2.\\nIn this definition, R1 is called the referencing relation  and R2 is the referenced \\nrelation. If these two conditions hold, a referential integrity constraint from R1 to \\nR2 is said to hold. In a database of many relations, there are usually many referential \\nintegrity constraints.\\nTo specify these constraints, first we must have a clear understanding of the mean-\\ning or role that each attribute or set of attributes plays in the various relation sche-\\nmas of the database. Referential integrity constraints typically arise from the \\nrelationships among the entities  represented by the relation schemas. For example, \\nconsider the database shown in Figure 5.6. In the \\nEMPLOYEE relation, the attribute \\nDno refers to the department for which an employee works; hence, we designate Dno \\nto be a foreign key of EMPLOYEE referencing the DEPARTMENT relation. This means \\nthat a value of Dno in any tuple t1 of the EMPLOYEE relation must match a value of'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 177, 'page_label': '178'}, page_content='164 Chapter 5 The Relational Data Model and Relational Database Constraints\\nthe primary key of DEPARTMENT—the Dnumber attribute—in some tuple t2 of the \\nDEPARTMENT relation, or the value of Dno can be NULL  if the employee does not \\nbelong to a department or will be assigned to a department later. For example, in \\nFigure 5.6 the tuple for employee ‘John Smith’ references the tuple for the ‘Research’ \\ndepartment, indicating that ‘John Smith’ works for this department.\\nNotice that a foreign key can refer to its own relation.  For example, the attribute \\nSuper_ssn in EMPLOYEE refers to the supervisor of an employee; this is another \\nemployee, represented by a tuple in the EMPLOYEE relation. Hence, Super_ssn is a \\nforeign key that references the EMPLOYEE relation itself. In Figure 5.6 the tuple for \\nemployee ‘John Smith’ references the tuple for employee ‘Franklin Wong,’ indicat-\\ning that ‘Franklin Wong’ is the supervisor of ‘John Smith’.\\nWe can diagrammatically display referential integrity constraints by drawing a directed \\narc from each foreign key to the relation it references. For clarity, the arrowhead may \\npoint to the primary key of the referenced relation. Figure 5.7 shows the schema in \\nFigure 5.5 with the referential integrity constraints displayed in this manner.\\nAll integrity constraints should be specified on the relational database schema (that is, \\nspecified as part of its definition) if we want the DBMS to enforce these constraints on \\nDEPARTMENT\\nFname Minit Lname Ssn Bdate Address Sex Salary Super_ssn Dno\\nEMPLOYEE\\nDEPT_LOCATIONS\\nDnumber Dlocation\\nPROJECT\\nPname Pnumber Plocation Dnum\\nWORKS_ON\\nEssn Pno Hours\\nDEPENDENT\\nEssn Dependent_name Sex Bdate Relationship\\nDname Dnumber Mgr_ssn Mgr_start_date\\nFigure 5.7 \\nReferential integrity constraints displayed on the COMPANY relational database schema.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 178, 'page_label': '179'}, page_content='5.3 Update Operations, Transactions, and Dealing with Constraint Violations  165\\nthe database states. Hence, the DDL includes provisions for specifying the various \\ntypes of constraints so that the DBMS can automatically enforce them. In SQL, the \\nCREATE TABLE statement of the SQL DDL allows the definition of primary key, \\nunique key, NOT NULL, entity integrity, and referential integrity constraints, among \\nother constraints (see Sections 6.1 and 6.2) .\\n5.2.5 Other Types of Constraints\\nThe preceding integrity constraints are included in the data definition language \\nbecause they occur in most database applications. Another class of general con-\\nstraints, sometimes called semantic integrity constraints,  are not part of the DDL \\nand have to be specified and enforced in a different way. Examples of such con-\\nstraints are the salary of an employee should not exceed the salary of the employee’s \\nsupervisor and the maximum number of hours an employee can work on all projects \\nper week is 56 . Such constraints can be specified and enforced within the applica-\\ntion programs that update the database, or by using a general-purpose constraint \\nspecification language. Mechanisms called triggers and assertions can be used in \\nSQL, through the \\nCREATE ASSERTION and CREATE TRIGGER statements, to specify \\nsome of these constraints (see Chapter 7). It is more common to check for these \\ntypes of constraints within the application programs than to use constraint specifi-\\ncation languages because the latter are sometimes difficult and complex to use, as \\nwe discuss in Section 26.1.\\nThe types of constraints we discussed so far may be called state constraints  \\nbecause they define the constraints that a valid state of the database must satisfy. \\nAnother type of constraint, called transition constraints , can be defined to deal \\nwith state changes in the database.\\n11 An example of a transition constraint is: “the \\nsalary of an employee can only increase.” Such constraints are typically enforced \\nby the application programs or specified using active rules and triggers, as we dis-\\ncuss in Section 26.1.\\n5.3  Update Operations, Transactions,  \\nand Dealing with Constraint Violations\\nThe operations of the relational model can be categorized into retrievals  and \\nupdates. The relational algebra operations, which can be used to specify retrievals, \\nare discussed in detail in Chapter 8. A relational algebra expression forms a new \\nrelation after applying a number of algebraic operators to an existing set of rela-\\ntions; its main use is for querying a database to retrieve information. The user for-\\nmulates a query that specifies the data of interest, and a new relation is formed by \\napplying relational operators to retrieve this data. The result relation becomes the \\nanswer to (or result of ) the user’s query. Chapter 8 also introduces the language \\n11State constraints are sometimes called static constraints, and transition constraints are sometimes \\ncalled dynamic constraints.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 179, 'page_label': '180'}, page_content='166 Chapter 5 The Relational Data Model and Relational Database Constraints\\ncalled relational calculus, which is used to define a query declaratively without giv-\\ning a specific order of operations.\\nIn this section, we concentrate on the database modification or update operations. \\nThere are three basic operations that can change the states of relations in the data-\\nbase: Insert, Delete, and Update (or Modify). They insert new data, delete old data, \\nor modify existing data records, respectively. Insert is used to insert one or more \\nnew tuples in a relation, Delete is used to delete tuples, and Update (or Modify) is \\nused to change the values of some attributes in existing tuples. Whenever these \\noperations are applied, the integrity constraints specified on the relational database \\nschema should not be violated. In this section we discuss the types of constraints \\nthat may be violated by each of these operations and the types of actions that may \\nbe taken if an operation causes a violation. We use the database shown in Figure 5.6 \\nfor examples and discuss only domain constraints, key constraints, entity integrity \\nconstraints, and the referential integrity constraints shown in Figure 5.7. For each \\ntype of operation, we give some examples and discuss any constraints that each \\noperation may violate.\\n5.3.1 The Insert Operation\\nThe Insert operation provides a list of attribute values for a new tuple t that is to be \\ninserted into a relation R. Insert can violate any of the four types of constraints. \\nDomain constraints can be violated if an attribute value is given that does not \\nappear in the corresponding domain or is not of the appropriate data type. Key \\nconstraints can be violated if a key value in the new tuple t already exists in another \\ntuple in the relation r(R). Entity integrity can be violated if any part of the primary \\nkey of the new tuple t is \\nNULL. Referential integrity can be violated if the value of \\nany foreign key in t refers to a tuple that does not exist in the referenced relation. \\nHere are some examples to illustrate this discussion.\\n ■ Operation:\\nInsert <‘Cecilia’ , ‘F’ , ‘Kolonsky’ , NULL, ‘1960-04-05’ , ‘6357 Windy Lane, Katy, \\nTX’ , F , 28000, NULL, 4> into EMPLOYEE.\\nResult: This insertion violates the entity integrity constraint ( NULL for the \\nprimary key Ssn), so it is rejected.\\n ■ Operation:\\nInsert <‘ Alicia’ , ‘J’ , ‘Zelaya’ , ‘999887777’ , ‘1960-04-05’ , ‘6357 Windy Lane, Katy, \\nTX’ , F , 28000, ‘987654321’ , 4> into \\nEMPLOYEE.\\nResult: This insertion violates the key constraint because another tuple with \\nthe same Ssn value already exists in the EMPLOYEE relation, and so it is \\nrejected.\\n ■ Operation:\\nInsert <‘Cecilia’ , ‘F’ , ‘Kolonsky’ , ‘677678989’ , ‘1960-04-05’ , ‘6357 Windswept, \\nKaty, TX’ , F , 28000, ‘987654321’ , 7> into EMPLOYEE.\\nResult: This insertion violates the referential integrity constraint specified on \\nDno in EMPLOYEE because no corresponding referenced tuple exists in \\nDEPARTMENT with Dnumber = 7.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 180, 'page_label': '181'}, page_content='5.3 Update Operations, Transactions, and Dealing with Constraint Violations  167\\n ■ Operation:\\nInsert <‘Cecilia’ , ‘F’ , ‘Kolonsky’ , ‘677678989’ , ‘1960-04-05’ , ‘6357 Windy Lane, \\nKaty, TX’ , F , 28000, \\nNULL, 4> into EMPLOYEE.\\nResult: This insertion satisfies all constraints, so it is acceptable.\\nIf an insertion violates one or more constraints, the default option is to reject the \\ninsertion. In this case, it would be useful if the DBMS could provide a reason to the \\nuser as to why the insertion was rejected. Another option is to attempt to correct the \\nreason for rejecting the insertion, but this is typically not used for violations caused by \\nInsert; rather, it is used more often in correcting violations for Delete and Update. \\nIn the first operation, the DBMS could ask the user to provide a value for Ssn, and \\ncould then accept the insertion if a valid Ssn value is provided. In operation 3, the \\nDBMS could either ask the user to change the value of Dno to some valid value  \\n(or set it to NULL), or it could ask the user to insert a DEPARTMENT  tuple with  \\nDnumber = 7 and could accept the original insertion only after such an operation \\nwas accepted. Notice that in the latter case the insertion violation can cascade back \\nto the EMPLOYEE relation if the user attempts to insert a tuple for department 7 with \\na value for Mgr_ssn that does not exist in the EMPLOYEE relation.\\n5.3.2 The Delete Operation\\nThe Delete operation can violate only referential integrity. This occurs if the tuple \\nbeing deleted is referenced by foreign keys from other tuples in the database. To \\nspecify deletion, a condition on the attributes of the relation selects the tuple (or \\ntuples) to be deleted. Here are some examples.\\n ■ Operation:\\nDelete the WORKS_ON tuple with Essn = ‘999887777’ and Pno = 10.\\nResult: This deletion is acceptable and deletes exactly one tuple.\\n ■ Operation:\\nDelete the EMPLOYEE tuple with Ssn = ‘999887777’ .\\nResult: This deletion is not acceptable, because there are tuples in  \\nWORKS_ON that refer to this tuple. Hence, if the tuple in EMPLOYEE is \\ndeleted, referential integrity violations will result.\\n ■ Operation:\\nDelete the EMPLOYEE tuple with Ssn = ‘333445555’ .\\nResult: This deletion will result in even worse referential integrity violations, \\nbecause the tuple involved is referenced by tuples from the EMPLOYEE, \\nDEPARTMENT, WORKS_ON, and DEPENDENT relations.\\nSeveral options are available if a deletion operation causes a violation. The first \\noption, called restrict, is to reject the deletion. The second option, called cascade, is \\nto attempt to cascade (or propagate) the deletion by deleting tuples that reference the \\ntuple that is being deleted. For example, in operation 2, the DBMS could automati-\\ncally delete the offending tuples from \\nWORKS_ON  with Essn = ‘999887777’. A \\nthird option, called set null  or set default,  is to modify the referencing attribute \\nvalues that cause the violation; each such value is either set to NULL or changed to'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 181, 'page_label': '182'}, page_content='168 Chapter 5 The Relational Data Model and Relational Database Constraints\\nreference another default valid tuple. Notice that if a referencing attribute that \\ncauses a violation is part of the primary key,  it cannot be set to NULL; otherwise, it \\nwould violate entity integrity.\\nCombinations of these three options are also possible. For example, to avoid having \\noperation 3 cause a violation, the DBMS may automatically delete all tuples from \\nWORKS_ON and DEPENDENT with Essn = ‘333445555’. Tuples in EMPLOYEE with \\nSuper_ssn = ‘333445555’ and the tuple in DEPARTMENT with Mgr_ssn = ‘333445555’ \\ncan have their Super_ssn and Mgr_ssn values changed to other valid values or to \\nNULL. Although it may make sense to delete automatically the WORKS_ON and \\nDEPENDENT tuples that refer to an EMPLOYEE tuple, it may not make sense to delete \\nother EMPLOYEE tuples or a DEPARTMENT tuple.\\nIn general, when a referential integrity constraint is specified in the DDL, the DBMS \\nwill allow the database designer to specify which of the options  applies in case of a \\nviolation of the constraint. We discuss how to specify these options in the SQL DDL \\nin Chapter 6.\\n5.3.3 The Update Operation\\nThe Update (or Modify) operation is used to change the values of one or more \\nattributes in a tuple (or tuples) of some relation R. It is necessary to specify a condi-\\ntion on the attributes of the relation to select the tuple (or tuples) to be modified. \\nHere are some examples.\\n ■ Operation:\\nUpdate the salary of the EMPLOYEE tuple with Ssn = ‘999887777’ to 28000.\\nResult: Acceptable.\\n ■ Operation:\\nUpdate the Dno of the EMPLOYEE tuple with Ssn = ‘999887777’ to 1.\\nResult: Acceptable.\\n ■ Operation:\\nUpdate the Dno of the EMPLOYEE tuple with Ssn = ‘999887777’ to 7.\\nResult: Unacceptable, because it violates referential integrity.\\n ■ Operation:\\nUpdate the Ssn of the EMPLOYEE tuple with Ssn = ‘999887777’ to ‘987654321’ .\\nResult: Unacceptable, because it violates primary key constraint by repeating \\na value that already exists as a primary key in another tuple; it violates refer-\\nential integrity constraints because there are other relations that refer to the \\nexisting value of \\nSsn.\\nUpdating an attribute that is neither part of a primary key nor part of a foreign key  \\nusually causes no problems; the DBMS need only check to confirm that the new \\nvalue is of the correct data type and domain. Modifying a primary key value is simi-\\nlar to deleting one tuple and inserting another in its place because we use the pri-\\nmary key to identify tuples. Hence, the issues discussed earlier in both Sections 5.3.1 \\n(Insert) and 5.3.2 (Delete) come into play. If a foreign key attribute is modified, the'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 182, 'page_label': '183'}, page_content='5.4 Summary  169\\nDBMS must make sure that the new value refers to an existing tuple in the refer-\\nenced relation (or is set to NULL). Similar options exist to deal with referential integ-\\nrity violations caused by Update as those options discussed for the Delete operation. \\nIn fact, when a referential integrity constraint is specified in the DDL, the DBMS will \\nallow the user to choose separate options to deal with a violation caused by Delete \\nand a violation caused by Update (see Section 6.2).\\n5.3.4 The Transaction Concept\\nA database application program running against a relational database typically exe-\\ncutes one or more transactions. A transaction is an executing program that includes \\nsome database operations, such as reading from the database, or applying inser-\\ntions, deletions, or updates to the database. At the end of the transaction, it must \\nleave the database in a valid or consistent state that satisfies all the constraints spec-\\nified on the database schema. A single transaction may involve any number of \\nretrieval operations (to be discussed as part of relational algebra and calculus in \\nChapter 8, and as a part of the language SQL in Chapters 6 and 7) and any number \\nof update operations. These retrievals and updates will together form an atomic \\nunit of work against the database. For example, a transaction to apply a bank with-\\ndrawal will typically read the user account record, check if there is a sufficient bal-\\nance, and then update the record by the withdrawal amount.\\nA large number of commercial applications running against relational databases in \\nonline transaction processing (OLTP) systems are executing transactions at rates \\nthat reach several hundred per second. Transaction processing concepts, concur-\\nrent execution of transactions, and recovery from failures will be discussed in \\nChapters 20 to 22.\\n5.4 Summary\\nIn this chapter we presented the modeling concepts, data structures, and constraints \\nprovided by the relational model of data. We started by introducing the concepts of \\ndomains, attributes, and tuples. Then, we defined a relation schema as a list of attri-\\nbutes that describe the structure of a relation. A relation, or relation state, is a set of \\ntuples that conforms to the schema.\\nSeveral characteristics differentiate relations from ordinary tables or files. The first \\nis that a relation is not sensitive to the ordering of tuples. The second involves the \\nordering of attributes in a relation schema and the corresponding ordering of val-\\nues within a tuple. We gave an alternative definition of relation that does not require \\nordering of attributes, but we continued to use the first definition, which requires \\nattributes and tuple values to be ordered, for convenience. Then, we discussed val-\\nues in tuples and introduced \\nNULL values to represent missing or unknown infor-\\nmation. We emphasized that NULL values should be avoided as much as possible.\\nWe classified database constraints into inherent model-based constraints, explicit \\nschema-based constraints, and semantic constraints or business rules. Then, we'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 183, 'page_label': '184'}, page_content='170 Chapter 5 The Relational Data Model and Relational Database Constraints\\ndiscussed the schema constraints pertaining to the relational model, starting with \\ndomain constraints, then key constraints (including the concepts of superkey, \\nkey, and primary key), and the \\nNOT NULL  constraint on attributes. We defined \\nrelational databases and relational database schemas. Additional relational con-\\nstraints include the entity integrity constraint, which prohibits primary key attri-\\nbutes from being \\nNULL. We described the interrelation referential integrity \\nconstraint, which is used to maintain consistency of references among tuples \\nfrom various relations.\\nThe modification operations on the relational model are Insert, Delete, and Update. \\nEach operation may violate certain types of constraints (refer to Section 5.3). When-\\never an operation is applied, the resulting database state must be a valid state. \\nFinally, we introduced the concept of a transaction, which is important in relational \\nDBMSs because it allows the grouping of several database operations into a single \\natomic action on the database.\\nReview Questions\\n 5.1. Define the following terms as they apply to the relational model of data: \\ndomain, attribute, n-tuple, relation schema , relation state , degree of a rela-\\ntion, relational database schema, and relational database state.\\n 5.2. Why are tuples in a relation not ordered?\\n 5.3. Why are duplicate tuples not allowed in a relation?\\n 5.4. What is the difference between a key and a superkey?\\n 5.5. Why do we designate one of the candidate keys of a relation to be the pri-\\nmary key?\\n 5.6. Discuss the characteristics of relations that make them different from ordi-\\nnary tables and files.\\n 5.7. Discuss the various reasons that lead to the occurrence of NULL values in \\nrelations.\\n 5.8. Discuss the entity integrity and referential integrity constraints. Why is each \\nconsidered important?\\n 5.9. Define foreign key. What is this concept used for?\\n 5.10. What is a transaction? How does it differ from an Update operation?\\nExercises\\n 5.11. Suppose that each of the following Update operations is applied directly to \\nthe database state shown in Figure 5.6. Discuss all integrity constraints'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 184, 'page_label': '185'}, page_content='Exercises 171\\nviolated by each operation, if any, and the different ways of enforcing \\nthese constraints.\\na. Insert <‘Robert’, ‘F’, ‘Scott’, ‘943775543’, ‘1972-06-21’, ‘2365 Newcastle \\nRd, Bellaire, TX’, M, 58000, ‘888665555’, 1> into \\nEMPLOYEE.\\nb. Insert <‘ProductA’, 4, ‘Bellaire’, 2> into PROJECT.\\nc. Insert <‘Production’, 4, ‘943775543’, ‘2007-10-01’> into DEPARTMENT.\\nd. Insert <‘677678989’, NULL, ‘40.0’> into WORKS_ON.\\ne. Insert <‘453453453’, ‘John’, ‘M’, ‘1990-12-12’, ‘spouse’> into DEPENDENT.\\nf. Delete the WORKS_ON tuples with Essn = ‘333445555’.\\ng. Delete the EMPLOYEE tuple with Ssn = ‘987654321’.\\nh. Delete the PROJECT tuple with Pname = ‘ProductX’.\\ni. Modify the Mgr_ssn and Mgr_start_date  of the DEPARTMENT tuple with \\nDnumber = 5 to ‘123456789’ and ‘2007-10-01’, respectively.\\nj. Modify the Super_ssn  attribute of the EMPLOYEE  tuple with Ssn = \\n‘999887777’ to ‘943775543’.\\nk. Modify the Hours  attribute of the WORKS_ON  tuple with Essn = \\n‘999887777’ and Pno = 10 to ‘5.0’.\\n 5.12.  Consider the AIRLINE  relational database schema shown in Figure 5.8, \\nwhich describes a database for airline flight information. Each FLIGHT is \\nidentified by a Flight_number , and consists of one or more FLIGHT_LEGs  \\nwith Leg_numbers 1, 2, 3, and so on. Each FLIGHT_LEG  has scheduled \\narrival and departure times, airports, and one or more LEG_INSTANCEs—\\none for each Date on which the flight travels. FAREs are kept for each \\nFLIGHT. For each FLIGHT_LEG instance, SEAT_RESERVATIONs are kept, as \\nare the AIRPLANE used on the leg and the actual arrival and departure times \\nand airports. An AIRPLANE is identified by an Airplane_id and is of a particu-\\nlar AIRPLANE_TYPE. CAN_LAND relates AIRPLANE_TYPEs to the AIRPORTs \\nat which they can land. An AIRPORT is identified by an Airport_code. Con-\\nsider an update for the AIRLINE database to enter a reservation on a particu-\\nlar flight or flight leg on a given date.\\na. Give the operations for this update.\\nb. What types of constraints would you expect to check?\\nc. Which of these constraints are key, entity integrity, and referential integ-\\nrity constraints, and which are not?\\nd. Specify all the referential integrity constraints that hold on the schema \\nshown in Figure 5.8.\\n 5.13.  Consider the relation CLASS (Course# , Univ_Section# , Instructor_name ,  \\nSemester, Building_code, Room#, Time_period, Weekdays, Credit_hours). This rep-\\nresents classes taught in a university, with unique Univ_section#s. Identify what \\nyou think should be various candidate keys, and write in your own words the \\nconditions or assumptions under which each candidate key would be valid.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 185, 'page_label': '186'}, page_content='172 Chapter 5 The Relational Data Model and Relational Database Constraints\\nAIRPORT\\nAirport_code Name City State\\nFlight_number Airline Weekdays\\nFLIGHT\\nFLIGHT_LEG\\nFlight_number Leg_number Departure_airport_code Scheduled_departure_time\\nScheduled_arrival_timeArrival_airport_code\\nLEG_INSTANCE\\nFlight_number Leg_number Date Number_of_available_seats Airplane_id\\nFARE\\nFlight_number Fare_code Amount Restrictions\\nAIRPLANE_TYPE\\nAirplane_type_name Max_seats Company\\nCAN_LAND\\nAirplane_type_name Airport_code\\nAIRPLANE\\nAirplane_id Total_number_of_seats Airplane_type\\nSEAT_RESERVATION\\nLeg_number Date Seat_number Customer_name Customer_phoneFlight_number\\nArrival_timeArrival_airport_codeDeparture_timeDeparture_airport_code\\nFigure 5.8 \\nThe AIRLINE relational database schema.\\n 5.14.  Consider the following six relations for an order-processing database appli-\\ncation in a company:\\nCUSTOMER(Cust#, Cname, City)\\nORDER(Order#, Odate, Cust#, Ord_amt)\\nORDER_ITEM(Order#, Item#, Qty)'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 186, 'page_label': '187'}, page_content='Exercises 173\\nITEM(Item#, Unit_price)\\nSHIPMENT(Order#, Warehouse#, Ship_date)\\nWAREHOUSE(Warehouse#, City)\\n  Here, Ord_amt refers to total dollar amount of an order; Odate is the date the \\norder was placed; and Ship_date is the date an order (or part of an order) is \\nshipped from the warehouse. Assume that an order can be shipped from several \\nwarehouses. Specify the foreign keys for this schema, stating any assumptions \\nyou make. What other constraints can you think of for this database?\\n 5.15.  Consider the following relations for a database that keeps track of business \\ntrips of salespersons in a sales office:\\nSALESPERSON(Ssn, Name, Start_year, Dept_no)\\nTRIP(Ssn, From_city, To_city, Departure_date, Return_date, Trip_id)\\nEXPENSE(Trip_id, Account#, Amount)\\n  A trip can be charged to one or more accounts. Specify the foreign keys for \\nthis schema, stating any assumptions you make.\\n 5.16.  Consider the following relations for a database that keeps track of student \\nenrollment in courses and the books adopted for each course:\\nSTUDENT(Ssn, Name, Major, Bdate)\\nCOURSE(Course#, Cname, Dept)\\nENROLL(Ssn, Course#, Quarter, Grade)\\nBOOK_ADOPTION(Course#, Quarter, Book_isbn)\\nTEXT(Book_isbn, Book_title, Publisher, Author)\\n  Specify the foreign keys for this schema, stating any assumptions you make.\\n 5.17.  Consider the following relations for a database that keeps track of automo-\\nbile sales in a car dealership ( OPTION refers to some optional equipment \\ninstalled on an automobile):\\nCAR(Serial_no, Model, Manufacturer, Price)\\nOPTION(Serial_no, Option_name, Price)\\nSALE(Salesperson_id, Serial_no, Date, Sale_price)\\nSALESPERSON(Salesperson_id, Name, Phone)\\n  First, specify the foreign keys for this schema, stating any assumptions you \\nmake. Next, populate the relations with a few sample tuples, and then give \\nan example of an insertion in the SALE and SALESPERSON relations that \\nviolates the referential integrity constraints and of another insertion that \\ndoes not.\\n 5.18.  Database design often involves decisions about the storage of attributes. For \\nexample, a Social Security number can be stored as one attribute or split into \\nthree attributes (one for each of the three hyphen-delineated groups of'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 187, 'page_label': '188'}, page_content='174 Chapter 5 The Relational Data Model and Relational Database Constraints\\nnumbers in a Social Security number—XXX-XX-XXXX). However, Social \\nSecurity numbers are usually represented as just one attribute. The decision \\nis based on how the database will be used. This exercise asks you to think \\nabout specific situations where dividing the SSN is useful.\\n 5.19.  Consider a STUDENT relation in a UNIVERSITY database with the following \\nattributes (Name, Ssn, Local_phone, Address, Cell_phone, Age, Gpa). Note that \\nthe cell phone may be from a different city and state (or province) from the \\nlocal phone. A possible tuple of the relation is shown below:\\nName Ssn Local_phone Address Cell_phone Age Gpa\\nGeorge Shaw 123-45-6789 555-1234 123 Main St., 555-4321 19 3.75\\nWilliam Edwards Anytown, CA 94539\\na. Identify the critical missing information from the Local_phone  and  \\nCell_phone attributes. (Hint: How do you call someone who lives in a dif-\\nferent state or province?)\\nb. Would you store this additional information in the Local_phone  and  \\nCell_phone attributes or add new attributes to the schema for STUDENT?\\nc. Consider the Name attribute. What are the advantages and disadvantages \\nof splitting this field from one attribute into three attributes (first name, \\nmiddle name, and last name)?\\nd. What general guideline would you recommend for deciding when to \\nstore information in a single attribute and when to split the information?\\ne. Suppose the student can have between 0 and 5 phones. Suggest two dif-\\nferent designs that allow this type of information.\\n 5.20.  Recent changes in privacy laws have disallowed organizations from using \\nSocial Security numbers to identify individuals unless certain restrictions \\nare satisfied. As a result, most U.S. universities cannot use SSNs as primary \\nkeys (except for financial data). In practice, \\nStudent_id, a unique identifier \\nassigned to every student, is likely to be used as the primary key rather than \\nSSN since Student_id can be used throughout the system.\\na. Some database designers are reluctant to use generated keys (also known \\nas surrogate keys) for primary keys (such as Student_id) because they are \\nartificial. Can you propose any natural choices of keys that can be used to \\nidentify the student record in a \\nUNIVERSITY database?\\nb. Suppose that you are able to guarantee uniqueness of a natural key that \\nincludes last name. Are you guaranteed that the last name will not change \\nduring the lifetime of the database? If last name can change, what solu-\\ntions can you propose for creating a primary key that still includes last \\nname but remains unique?\\nc. What are the advantages and disadvantages of using generated (surro-\\ngate) keys?'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 188, 'page_label': '189'}, page_content='Selected Bibliography 175\\nSelected Bibliography\\nThe relational model was introduced by Codd (1970) in a classic paper. Codd also \\nintroduced relational algebra and laid the theoretical foundations for the relational \\nmodel in a series of papers (Codd, 1971, 1972, 1972a, 1974); he was later given the \\nTuring Award, the highest honor of the ACM (Association for Computing Machin-\\nery) for his work on the relational model. In a later paper, Codd (1979) discussed \\nextending the relational model to incorporate more meta-data and semantics about \\nthe relations; he also proposed a three-valued logic to deal with uncertainty in rela-\\ntions and incorporating \\nNULLs in the relational algebra. The resulting model is \\nknown as RM/T. Childs (1968) had earlier used set theory to model databases. \\nLater, Codd (1990) published a book examining over 300 features of the relational \\ndata model and database systems. Date (2001) provides a retrospective review and \\nanalysis of the relational data model.\\nSince Codd’s pioneering work, much research has been conducted on various \\naspects of the relational model. Todd (1976) describes an experimental DBMS \\ncalled PRTV that directly implements the relational algebra operations. Schmidt \\nand Swenson (1975) introduce additional semantics into the relational model by \\nclassifying different types of relations. Chen’s (1976) entity–relationship model, \\nwhich is discussed in Chapter 3, is a means to communicate the real-world seman-\\ntics of a relational database at the conceptual level. Wiederhold and Elmasri (1979) \\nintroduce various types of connections between relations to enhance its constraints. \\nExtensions of the relational model are discussed in Chapters 11 and 26. Additional \\nbibliographic notes for other aspects of the relational model and its languages, sys-\\ntems, extensions, and theory are given in Chapters 6 to 9, 14, 15, 23, and 30. Maier \\n(1983) and Atzeni and De Antonellis (1993) provide an extensive theoretical treat-\\nment of the relational data model.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 189, 'page_label': '190'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 190, 'page_label': '191'}, page_content='177\\n6\\nBasic SQL\\nT\\nhe SQL language may be considered one of the \\nmajor reasons for the commercial success of rela-\\ntional databases. Because it became a standard for relational databases, users were \\nless concerned about migrating their database applications from other types of \\ndatabase systems—for example, older network or hierarchical systems—to rela-\\ntional systems. This is because even if the users became dissatisfied with the partic-\\nular relational DBMS product they were using, converting to another relational \\nDBMS product was not expected to be too expensive and time-consuming because \\nboth systems followed the same language standards. In practice, of course, there \\nare differences among various commercial relational DBMS packages. However, \\nif the user is diligent in using only those features that are part of the standard, \\nand if two relational DBMSs faithfully support the standard, then conversion \\nbetween two systems should be simplified. Another advantage of having such a \\nstandard is that users may write statements in a database application program \\nthat can access data stored in two or more relational DBMSs without having to \\nchange the database sublanguage (SQL), as long as both/all of the relational \\nDBMSs support standard SQL.\\nThis chapter presents the practical relational model, which is based on the SQL \\nstandard for commercial relational DBMSs, whereas Chapter 5 presented the most \\nimportant concepts underlying the formal relational data model. In Chapter 8 (Sec-\\ntions 8.1 through 8.5 ), we shall discuss the relational algebra operations, which are \\nvery important for understanding the types of requests that may be specified on a \\nrelational database. They are also important for query processing and optimization \\nin a relational DBMS, as we shall see in Chapters 18 and 19. However, the relational \\nalgebra operations are too low-level for most commercial DBMS users because a \\nquery in relational algebra is written as a sequence of operations that, when exe-\\ncuted, produces the required result. Hence, the user must specify how—that is, in \\nwhat order—to execute the query operations. On the other hand, the SQL language \\nchapter 6'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 191, 'page_label': '192'}, page_content='178 Chapter 6 Basic SQL\\nprovides a higher-level declarative  language interface, so the user only specifies \\nwhat the result is to be, leaving the actual optimization and decisions on how to \\nexecute the query to the DBMS. Although SQL includes some features from rela-\\ntional algebra, it is based to a greater extent on the tuple relational calculus, which \\nwe describe in Section 8.6. However, the SQL syntax is more user-friendly than \\neither of the two formal languages.\\nThe name SQL is presently expanded as Structured Query Language. Originally, \\nSQL was called SEQUEL (Structured English QUEry Language) and was designed \\nand implemented at IBM Research as the interface for an experimental relational \\ndatabase system called SYSTEM R. SQL is now the standard language for com-\\nmercial relational DBMSs. The standardization of SQL is a joint effort by the \\nAmerican National Standards Institute (ANSI) and the International Standards \\nOrganization (ISO), and the first SQL standard is called SQL-86 or SQL1. A \\nrevised and much expanded standard called SQL-92 (also referred to as SQL2) \\nwas subsequently developed. The next standard that is well-recognized is \\nSQL:1999, which started out as SQL3. Additional updates to the standard are \\nSQL:2003 and SQL:2006, which added XML features (see Chapter 13) among \\nother updates to the language. Another update in 2008 incorporated more object \\ndatabase features into SQL (see Chapter 12), and a further update is SQL:2011. \\nWe will try to cover the latest version of SQL as much as possible, but some of the \\nnewer features are discussed in later chapters. It is also not possible to cover the \\nlanguage in its entirety in this text. It is important to note that when new features \\nare added to SQL, it usually takes a few years for some of these features to make it \\ninto the commercial SQL DBMSs.\\nSQL is a comprehensive database language: It has statements for data definitions, \\nqueries, and updates. Hence, it is both a DDL and a DML. In addition, it has facili-\\nties for defining views on the database, for specifying security and authorization, \\nfor defining integrity constraints, and for specifying transaction controls. It also has \\nrules for embedding SQL statements into a general-purpose programming lan-\\nguage such as Java or C/C++.\\n1\\nThe later SQL standards (starting with SQL:1999) are divided into a core specifica-\\ntion plus specialized extensions. The core is supposed to be implemented by all \\nRDBMS vendors that are SQL compliant. The extensions can be implemented as \\noptional modules to be purchased independently for specific database applications \\nsuch as data mining, spatial data, temporal data, data warehousing, online analyti-\\ncal processing (OLAP), multimedia data, and so on.\\nBecause the subject of SQL is both important and extensive, we devote two chap-\\nters to its basic features. In this chapter, Section 6.1 describes the SQL DDL com-\\nmands for creating schemas and tables, and gives an overview of the basic data \\ntypes in SQL. Section 6.2 presents how basic constraints such as key and referen-\\ntial integrity are specified. Section 6.3 describes the basic SQL constructs for \\n1Originally, SQL had statements for creating and dropping indexes on the files that represent relations, \\nbut these have been dropped from the SQL standard for some time.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 192, 'page_label': '193'}, page_content='6.1 SQL Data Definition and Data Types  179\\nspecifying retrieval queries, and Section 6.4 describes the SQL commands for \\ninsertion, deletion, and update.\\nIn Chapter 7, we will describe more complex SQL retrieval queries, as well as the \\nALTER commands for changing the schema. We will also describe the CREATE \\nASSERTION statement, which allows the specification of more general constraints \\non the database, and the concept of triggers, which is presented in more detail in \\nChapter 26. We discuss the SQL facility for defining views on the database in Chap-\\nter 7. Views are also called virtual or derived tables because they present the user \\nwith what appear to be tables; however, the information in those tables is derived \\nfrom previously defined tables.\\nSection 6.5 lists some SQL features that are presented in other chapters of the book; \\nthese include object-oriented features in Chapter 12, XML in Chapter 13, transac-\\ntion control in Chapter 20, active databases (triggers) in Chapter 26, online analyti-\\ncal processing (OLAP) features in Chapter 29, and security/authorization in \\nChapter 30. Section 6.6 summarizes the chapter. Chapters 10 and 11 discuss the \\nvarious database programming techniques for programming with SQL.\\n6.1 SQL Data Definition and Data Types\\nSQL uses the terms table, row, and column for the formal relational model terms \\nrelation, tuple, and attribute, respectively. We will use the corresponding terms \\ninterchangeably. The main SQL command for data definition is the CREATE state-\\nment, which can be used to create schemas, tables (relations), types, and domains, \\nas well as other constructs such as views, assertions, and triggers. Before we describe \\nthe relevant CREATE statements, we discuss schema and catalog concepts in Sec-\\ntion 6.1.1 to place our discussion in perspective. Section 6.1.2 describes how tables \\nare created, and Section 6.1.3 describes the most important data types available for \\nattribute specification. Because the SQL specification is very large, we give a descrip-\\ntion of the most important features. Further details can be found in the various SQL \\nstandards documents (see end-of-chapter bibliographic notes).\\n6.1.1 Schema and Catalog Concepts in SQL\\nEarly versions of SQL did not include the concept of a relational database schema; \\nall tables (relations) were considered part of the same schema. The concept of an \\nSQL schema was incorporated starting with SQL2 in order to group together tables \\nand other constructs that belong to the same database application (in some systems, \\na schema is called a database). An SQL schema is identified by a schema name and \\nincludes an authorization identifier to indicate the user or account who owns the \\nschema, as well as descriptors for each element  in the schema. Schema elements \\ninclude tables, types, constraints, views, domains, and other constructs (such as \\nauthorization grants) that describe the schema. A schema is created via the \\nCREATE \\nSCHEMA statement, which can include all the schema elements’ definitions. Alter-\\nnatively, the schema can be assigned a name and authorization identifier, and the'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 193, 'page_label': '194'}, page_content='180 Chapter 6 Basic SQL\\nelements can be defined later. For example, the following statement creates a \\nschema called COMPANY owned by the user with authorization identifier ‘Jsmith’. \\nNote that each statement in SQL ends with a semicolon.\\nCREATE SCHEMA COMPANY AUTHORIZATION ‘Jsmith’;\\nIn general, not all users are authorized to create schemas and schema elements. The \\nprivilege to create schemas, tables, and other constructs must be explicitly granted \\nto the relevant user accounts by the system administrator or DBA.\\nIn addition to the concept of a schema, SQL uses the concept of a catalog—a named \\ncollection of schemas.\\n2 Database installations typically have a default environment \\nand schema, so when a user connects and logs in to that database installation, the \\nuser can refer directly to tables and other constructs within that schema without \\nhaving to specify a particular schema name. A catalog always contains a special \\nschema called \\nINFORMATION_SCHEMA , which provides information on all the \\nschemas in the catalog and all the element descriptors in these schemas. Integrity \\nconstraints such as referential integrity can be defined between relations only if \\nthey exist in schemas within the same catalog. Schemas within the same catalog can \\nalso share certain elements, such as type and domain definitions.\\n6.1.2 The CREATE TABLE Command in SQL\\nThe CREATE TABLE command is used to specify a new relation by giving it a name \\nand specifying its attributes and initial constraints. The attributes are specified first, \\nand each attribute is given a name, a data type to specify its domain of values, and \\npossibly attribute constraints, such as NOT NULL. The key, entity integrity, and ref-\\nerential integrity constraints can be specified within the CREATE TABLE statement \\nafter the attributes are declared, or they can be added later using the ALTER TABLE \\ncommand (see Chapter 7). Figure 6.1 shows sample data definition statements in \\nSQL for the \\nCOMPANY relational database schema shown in Figure 3.7.\\nTypically, the SQL schema in which the relations are declared is implicitly specified \\nin the environment in which the CREATE TABLE statements are executed. Alterna-\\ntively, we can explicitly attach the schema name to the relation name, separated by \\na period. For example, by writing\\nCREATE TABLE COMPANY.EMPLOYEE\\nrather than\\nCREATE TABLE EMPLOYEE\\nas in Figure 6.1, we can explicitly (rather than implicitly) make the EMPLOYEE table \\npart of the COMPANY schema.\\nThe relations declared through CREATE TABLE  statements are called base tables  \\n(or base relations); this means that the table and its rows are actually created \\n2SQL also includes the concept of a cluster of catalogs.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 194, 'page_label': '195'}, page_content='6.1 SQL Data Definition and Data Types  181\\nCREATE TABLE EMPLOYEE\\n( Fname\\n  Minit\\n  Lname\\n  Ssn\\n  Bdate\\n  Address\\n  Sex\\n  Salary\\n  Super_ssn\\n  Dno\\nVARCHAR(15)\\nCHAR,\\nVARCHAR(15)\\nCHAR(9)\\nDATE,\\nVARCHAR(30),\\nCHAR,\\nDECIMAL(10,2),\\nCHAR(9),\\nINT\\nNOT NULL,\\nNOT NULL,\\nNOT NULL,\\nNOT NULL,\\nPRIMARY KEY (Ssn),\\nCREATE TABLE DEPARTMENT\\n( Dname\\n  Dnumber\\n  Mgr_ssn\\n  Mgr_start_date\\nVARCHAR(15)\\nINT\\nCHAR(9)\\nDATE,\\nNOT NULL,\\nNOT NULL,\\nNOT NULL,\\nPRIMARY KEY (Dnumber),\\nUNIQUE (Dname),\\nFOREIGN KEY (Mgr_ssn) REFERENCES EMPLOYEE(Ssn) );\\nCREATE TABLE DEPT_LOCATIONS\\n( Dnumber\\n  Dlocation\\nINT\\nVARCHAR(15)\\nNOT NULL,\\nNOT NULL,\\nPRIMARY KEY (Dnumber, Dlocation),\\nFOREIGN KEY (Dnumber) REFERENCES DEPARTMENT(Dnumber) );\\nCREATE TABLE PROJECT\\n( Pname\\n  Pnumber\\n  Plocation\\n  Dnum\\nVARCHAR(15)\\nINT\\nVARCHAR(15),\\nINT\\nNOT NULL,\\nNOT NULL,\\nNOT NULL,\\nPRIMARY KEY (Pnumber),\\nUNIQUE (Pname),\\nFOREIGN KEY (Dnum) REFERENCES DEPARTMENT(Dnumber) ); \\nCREATE TABLE WORKS_ON\\n( Essn\\n  Pno\\n  Hours\\nCHAR(9)\\nINT\\nDECIMAL(3,1)\\nNOT NULL,\\nNOT NULL,\\nNOT NULL,\\nPRIMARY KEY (Essn, Pno),\\nFOREIGN KEY (Essn) REFERENCES EMPLOYEE(Ssn),\\nFOREIGN KEY (Pno) REFERENCES PROJECT(Pnumber) );\\nCREATE TABLE DEPENDENT\\n( Essn\\n  Dependent_name\\n  Sex\\n  Bdate\\n  Relationship\\nCHAR(9)\\nVARCHAR(15)\\nCHAR,\\nDATE,\\nVARCHAR(8),\\nNOT NULL,\\nNOT NULL,\\nPRIMARY KEY (Essn, Dependent_name),\\nFOREIGN KEY (Essn) REFERENCES EMPLOYEE(Ssn) );\\nFigure 6.1 \\nSQL CREATE \\nTABLE data  \\ndefinition statements \\nfor defining the \\nCOMPANY schema \\nfrom Figure 5.7.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 195, 'page_label': '196'}, page_content='182 Chapter 6 Basic SQL\\nand stored as a file by the DBMS. Base relations are distinguished from virtual \\nrelations , created through the CREATE VIEW  statement (see Chapter 7), which \\nmay or may not correspond to an actual physical file. In SQL, the attributes in a \\nbase table are considered to be ordered in the sequence in which they are speci-\\nfied in the \\nCREATE TABLE  statement. However, rows (tuples) are not considered \\nto be ordered within a table (relation).\\nIt is important to note that in Figure 6.1, there are some foreign keys that may cause \\nerrors because they are specified either via circular references or because they refer \\nto a table that has not yet been created. For example, the foreign key Super_ssn in \\nthe EMPLOYEE table is a circular reference because it refers to the EMPLOYEE table \\nitself. The foreign key Dno in the EMPLOYEE table refers to the DEPARTMENT table, \\nwhich has not been created yet. To deal with this type of problem, these constraints \\ncan be left out of the initial \\nCREATE TABLE statement, and then added later using \\nthe ALTER TABLE statement (see Chapter 7). We displayed all the foreign keys in \\nFigure 6.1 to show the complete COMPANY schema in one place.\\n6.1.3 Attribute Data Types and Domains in SQL\\nThe basic data types available for attributes include numeric, character string, bit \\nstring, Boolean, date, and time.\\n ■ Numeric data types include integer numbers of various sizes ( INTEGER or \\nINT, and SMALLINT) and floating-point (real) numbers of various precision \\n(FLOAT or REAL, and DOUBLE PRECISION ). Formatted numbers can be \\ndeclared by using DECIMAL(i, j)—or DEC(i, j) or NUMERIC(i, j)—where i, the \\nprecision, is the total number of decimal digits and j, the scale, is the number \\nof digits after the decimal point. The default for scale is zero, and the default \\nfor precision is implementation-defined.\\n ■ Character-string  data types are either fixed length— CHAR (n) or \\nCHARACTER(n), where n is the number of characters—or varying length—\\nVARCHAR(n) or CHAR VARYING(n) or CHARACTER VARYING(n), where n is \\nthe maximum number of characters. When specifying a literal string value, \\nit is placed between single quotation marks (apostrophes), and it is case sen-\\nsitive (a distinction is made between uppercase and lowercase). 3 For fixed-\\nlength strings, a shorter string is padded with blank characters to the right. \\nFor example, if the value ‘Smith’ is for an attribute of type CHAR(10), it is \\npadded with five blank characters to become ‘Smith’ if needed. Padded \\nblanks are generally ignored when strings are compared. For comparison \\npurposes, strings are considered ordered in alphabetic (or lexicographic) \\norder; if a string str1 appears before another string str2 in alphabetic order, \\nthen str1 is considered to be less than str2.4 There is also a concatenation \\noperator denoted by || (double vertical bar) that can concatenate two strings \\n3This is not the case with SQL keywords, such as CREATE or CHAR. With keywords, SQL is case insen-\\nsitive, meaning that SQL treats uppercase and lowercase letters as equivalent in keywords.\\n4For nonalphabetic characters, there is a defined order.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 196, 'page_label': '197'}, page_content='6.1 SQL Data Definition and Data Types  183\\nin SQL. For example, ‘abc’ || ‘XYZ’ results in a single string ‘abcXYZ’. \\nAnother variable-length string data type called CHARACTER LARGE OBJECT \\nor CLOB is also available to specify columns that have large text values, such \\nas documents. The CLOB maximum length can be specified in kilobytes \\n(K), megabytes (M), or gigabytes (G). For example, \\nCLOB(20M) specifies a \\nmaximum length of 20 megabytes.\\n ■ Bit-string data types are either of fixed length n—BIT(n)—or varying length—\\nBIT VARYING(n), where n is the maximum number of bits. The default for n, \\nthe length of a character string or bit string, is 1. Literal bit strings are placed \\nbetween single quotes but preceded by a \\nB to distinguish them from character \\nstrings; for example, B‘10101’.5 Another variable-length bitstring data type \\ncalled BINARY LARGE OBJECT or BLOB is also available to specify columns \\nthat have large binary values, such as images. As for CLOB, the maximum \\nlength of a BLOB can be specified in kilobits (K), megabits (M), or gigabits (G). \\nFor example, BLOB(30G) specifies a maximum length of 30 gigabits.\\n ■ A Boolean data type has the traditional values of TRUE or FALSE. In SQL, \\nbecause of the presence of NULL values, a three-valued logic is used, so a \\nthird possible value for a Boolean data type is UNKNOWN. We discuss the \\nneed for UNKNOWN and the three-valued logic in Chapter 7.\\n ■ The DATE data type has ten positions, and its components are YEAR, MONTH, \\nand DAY in the form YYYY-MM-DD. The TIME data type has at least eight \\npositions, with the components HOUR, MINUTE, and SECOND in the form \\nHH:MM:SS. Only valid dates and times should be allowed by the SQL imple-\\nmentation. This implies that months should be between 1 and 12 and days \\nmust be between 01 and 31; furthermore, a day should be a valid day for the \\ncorresponding month. The < (less than) comparison can be used with dates \\nor times—an earlier date is considered to be smaller than a later date, and \\nsimilarly with time. Literal values are represented by single-quoted strings \\npreceded by the keyword \\nDATE or TIME; for example, DATE ‘2014-09-27’ or \\nTIME ‘09:12:47’. In addition, a data type TIME(i), where i is called time frac-\\ntional seconds precision , specifies i + 1 additional positions for TIME—one \\nposition for an additional period (.) separator character, and i positions for \\nspecifying decimal fractions of a second. A TIME WITH TIME ZONE data type \\nincludes an additional six positions for specifying the displacement from the \\nstandard universal time zone, which is in the range +13:00 to –12:59 in units \\nof HOURS:MINUTES. If WITH TIME ZONE  is not included, the default is the \\nlocal time zone for the SQL session.\\nSome additional data types are discussed below. The list of types discussed here is \\nnot exhaustive; different implementations have added more data types to SQL.\\n ■ A timestamp data type (TIMESTAMP) includes the DATE and TIME fields, plus \\na minimum of six positions for decimal fractions of seconds and an optional \\nWITH TIME ZONE  qualifier. Literal values are represented by single-quoted \\n5Bit strings whose length is a multiple of 4 can be specified in hexadecimal notation, where the literal \\nstring is preceded by X and each hexadecimal character represents 4 bits.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 197, 'page_label': '198'}, page_content='184 Chapter 6 Basic SQL\\nstrings preceded by the keyword TIMESTAMP, with a blank space between \\ndata and time; for example, TIMESTAMP ‘2014-09-27 09:12:47.648302’.\\n ■ Another data type related to DATE, TIME, and TIMESTAMP is the INTERVAL data \\ntype. This specifies an interval—a relative value that can be used to increment \\nor decrement an absolute value of a date, time, or timestamp. Intervals are \\nqualified to be either \\nYEAR/MONTH intervals or DAY/TIME intervals.\\nThe format of DATE, TIME, and TIMESTAMP can be considered as a special type of \\nstring. Hence, they can generally be used in string comparisons by being cast (or \\ncoerced or converted) into the equivalent strings.\\nIt is possible to specify the data type of each attribute directly, as in Figure 6.1; alter-\\nnatively, a domain can be declared, and the domain name can be used with the \\nattribute specification. This makes it easier to change the data type for a domain \\nthat is used by numerous attributes in a schema, and improves schema readability. \\nFor example, we can create a domain \\nSSN_TYPE by the following statement:\\nCREATE DOMAIN SSN_TYPE AS CHAR(9);\\nWe can use SSN_TYPE in place of CHAR(9) in Figure 6.1 for the attributes Ssn and \\nSuper_ssn of EMPLOYEE, Mgr_ssn of DEPARTMENT, Essn of WORKS_ON, and Essn \\nof DEPENDENT. A domain can also have an optional default specification via a \\nDEFAULT clause, as we discuss later for attributes. Notice that domains may not be \\navailable in some implementations of SQL.\\nIn SQL, there is also a CREATE TYPE command, which can be used to create user \\ndefined types or UDTs. These can then be used either as data types for attributes, or \\nas the basis for creating tables. We shall discuss CREATE TYPE in detail in Chap-\\nter 12, because it is often used in conjunction with specifying object database features \\nthat have been incorporated into more recent versions of SQL.\\n6.2 Specifying Constraints in SQL\\nThis section describes the basic constraints that can be specified in SQL as part of \\ntable creation. These include key and referential integrity constraints, restrictions \\non attribute domains and \\nNULLs, and constraints on individual tuples within a rela-\\ntion using the CHECK clause. We discuss the specification of more general con-\\nstraints, called assertions, in Chapter 7.\\n6.2.1 Specifying Attribute Constraints and Attribute Defaults\\nBecause SQL allows NULLs as attribute values, a constraint NOT NULL may be specified \\nif NULL is not permitted for a particular attribute. This is always implicitly specified for \\nthe attributes that are part of the primary key of each relation, but it can be specified for \\nany other attributes whose values are required not to be NULL, as shown in Figure 6.1.\\nIt is also possible to define a default value for an attribute by appending the clause \\nDEFAULT <value> to an attribute definition. The default value is included in any'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 198, 'page_label': '199'}, page_content='6.2 Specifying Constraints in SQL  185\\nnew tuple if an explicit value is not provided for that attribute. Figure 6.2 illustrates \\nan example of specifying a default manager for a new department and a default \\ndepartment for a new employee. If no default clause is specified, the default default \\nvalue is NULL for attributes that do not have the NOT NULL constraint.\\nAnother type of constraint can restrict attribute or domain values using the CHECK \\nclause following an attribute or domain definition. 6 For example, suppose that \\ndepartment numbers are restricted to integer numbers between 1 and 20; then, we \\ncan change the attribute declaration of \\nDnumber in the DEPARTMENT table (see Fig-\\nure 6.1) to the following:\\nDnumber INT NOT NULL CHECK (Dnumber > 0 AND Dnumber < 21);\\nThe CHECK clause can also be used in conjunction with the CREATE DOMAIN state-\\nment. For example, we can write the following statement:\\nCREATE DOMAIN D_NUM AS INTEGER\\nCHECK (D_NUM > 0 AND D_NUM < 21);\\n6The CHECK clause can also be used for other purposes, as we shall see.\\nCREATE TABLE EMPLOYEE\\n       (  … ,\\n          Dno               INT                  NOT NULL          DEFAULT 1,\\n       CONSTRAINT EMPPK\\n          PRIMARY KEY (Ssn),\\n       CONSTRAINT EMPSUPERFK\\n          FOREIGN KEY (Super_ssn) REFERENCES EMPLOYEE(Ssn)\\n                                    ON DELETE SET NULL              ON UPDATE CASCADE,\\n       CONSTRAINT EMPDEPTFK\\n          FOREIGN KEY(Dno) REFERENCES DEPARTMENT(Dnumber)\\n                                    ON DELETE SET DEFAULT       ON UPDATE CASCADE);\\nCREATE TABLE DEPARTMENT\\n       (  … ,\\n          Mgr_ssn CHAR(9)               NOT NULL           DEFAULT ‘888665555’,\\n          … ,\\n       CONSTRAINT DEPTPK\\n          PRIMARY KEY(Dnumber),\\n       CONSTRAINT DEPTSK\\n          UNIQUE (Dname),\\n       CONSTRAINT DEPTMGRFK\\n          FOREIGN KEY (Mgr_ssn) REFERENCES EMPLOYEE(Ssn)\\n                                    ON DELETE SET DEFAULT       ON UPDATE CASCADE);\\nCREATE TABLE DEPT_LOCATIONS\\n       (  … ,\\n       PRIMARY KEY (Dnumber, Dlocation),\\n       FOREIGN KEY (Dnumber) REFERENCES DEPARTMENT(Dnumber)\\n                                 ON DELETE CASCADE                ON UPDATE CASCADE);\\nFigure 6.2 \\nExample illustrating \\nhow default attribute \\nvalues and referential \\nintegrity triggered \\nactions are specified  \\nin SQL.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 199, 'page_label': '200'}, page_content='186 Chapter 6 Basic SQL\\nWe can then use the created domain D_NUM as the attribute type for all attributes \\nthat refer to department numbers in Figure 6.1, such as Dnumber of DEPARTMENT, \\nDnum of PROJECT, Dno of EMPLOYEE, and so on.\\n6.2.2 Specifying Key and Referential Integrity Constraints\\nBecause keys and referential integrity constraints are very important, there are spe-\\ncial clauses within the \\nCREATE TABLE statement to specify them. Some examples to \\nillustrate the specification of keys and referential integrity are shown in Figure 6.1.7 \\nThe PRIMARY KEY clause specifies one or more attributes that make up the primary \\nkey of a relation. If a primary key has a single attribute, the clause can follow the \\nattribute directly. For example, the primary key of DEPARTMENT can be specified as \\nfollows (instead of the way it is specified in Figure 6.1):\\nDnumber INT PRIMARY KEY,\\nThe UNIQUE clause specifies alternate (unique) keys, also known as candidate keys \\nas illustrated in the DEPARTMENT and PROJECT table declarations in Figure 6.1. \\nThe UNIQUE clause can also be specified directly for a unique key if it is a single \\nattribute, as in the following example:\\nDname VARCHAR(15) UNIQUE,\\nReferential integrity is specified via the FOREIGN KEY  clause, as shown in Fig- \\nure 6.1. As we discussed in Section 5.2.4, a referential integrity constraint can be \\nviolated when tuples are inserted or deleted, or when a foreign key or primary key \\nattribute value is updated. The default action that SQL takes for an integrity viola-\\ntion is to reject the update operation that will cause a violation, which is known as \\nthe \\nRESTRICT option. However, the schema designer can specify an alternative \\naction to be taken by attaching a referential triggered action clause to any foreign \\nkey constraint. The options include SET NULL, CASCADE, and SET DEFAULT. An \\noption must be qualified with either ON DELETE or ON UPDATE. We illustrate this \\nwith the examples shown in Figure 6.2. Here, the database designer chooses ON \\nDELETE SET NULL  and ON UPDATE CASCADE  for the foreign key Super_ssn  of \\nEMPLOYEE. This means that if the tuple for a supervising employee  is deleted, the \\nvalue of Super_ssn is automatically set to NULL for all employee tuples that were \\nreferencing the deleted employee tuple. On the other hand, if the Ssn value for a \\nsupervising employee is updated (say, because it was entered incorrectly), the new \\nvalue is cascaded to Super_ssn  for all employee tuples referencing the updated \\nemployee tuple.8\\nIn general, the action taken by the DBMS for SET NULL  or SET DEFAULT  is the \\nsame for both ON DELETE and ON UPDATE: The value of the affected referencing \\nattributes is changed to NULL for SET NULL and to the specified default value of the \\n7Key and referential integrity constraints were not included in early versions of SQL.\\n8Notice that the foreign key Super_ssn in the EMPLOYEE table is a circular reference and hence may \\nhave to be added later as a named constraint using the AL TER TABLE statement as we discussed at \\nthe end of Section 6.1.2.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 200, 'page_label': '201'}, page_content='6.3 Basic Retrieval Queries in SQL  187\\nreferencing attribute for SET DEFAULT. The action for CASCADE ON DELETE  is to \\ndelete all the referencing tuples, whereas the action for CASCADE ON UPDATE is to \\nchange the value of the referencing foreign key attribute(s) to the updated (new) \\nprimary key value for all the referencing tuples. It is the responsibility of the data-\\nbase designer to choose the appropriate action and to specify it in the database \\nschema. As a general rule, the \\nCASCADE option is suitable for “relationship” rela-\\ntions (see Section 9.1) , such as WORKS_ON; for relations that represent multival-\\nued attributes, such as DEPT_LOCATIONS ; and for relations that represent weak \\nentity types, such as DEPENDENT.\\n6.2.3 Giving Names to Constraints\\nFigure 6.2 also illustrates how a constraint may be given a constraint name, follow-\\ning the keyword CONSTRAINT. The names of all constraints within a particular \\nschema must be unique. A constraint name is used to identify a particular con-\\nstraint in case the constraint must be dropped later and replaced with another con-\\nstraint, as we discuss in Chapter 7. Giving names to constraints is optional. It is also \\npossible to temporarily defer a constraint until the end of a transaction, as we shall \\ndiscuss in Chapter 20 when we present transaction concepts.\\n6.2.4 Specifying Constraints on Tuples Using CHECK\\nIn addition to key and referential integrity constraints, which are specified by spe-\\ncial keywords, other table constraints can be specified through additional \\nCHECK \\nclauses at the end of a CREATE TABLE  statement. These can be called row-based \\nconstraints because they apply to each row individually and are checked whenever \\na row is inserted or modified. For example, suppose that the DEPARTMENT table in \\nFigure 6.1 had an additional attribute Dept_create_date, which stores the date when \\nthe department was created. Then we could add the following CHECK clause at the \\nend of the CREATE TABLE statement for the DEPARTMENT table to make sure that a \\nmanager’s start date is later than the department creation date.\\nCHECK (Dept_create_date <= Mgr_start_date);\\nThe CHECK clause can also be used to specify more general constraints using \\nthe CREATE ASSERTION  statement of SQL. We discuss this in Chapter 7 because \\nit requires the full power of queries, which are discussed in Sections 6.3  \\nand 7.1.\\n6.3 Basic Retrieval Queries in SQL\\nSQL has one basic statement for retrieving information from a database: the \\nSELECT statement. The SELECT statement is not the same as the SELECT operation \\nof relational algebra, which we shall discuss in Chapter 8. There are many options \\nand flavors to the SELECT statement in SQL, so we will introduce its features grad-\\nually. We will use example queries specified on the schema of Figure 5.5 and will'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 201, 'page_label': '202'}, page_content='188 Chapter 6 Basic SQL\\nrefer to the sample database state shown in Figure 5.6 to show the results of some \\nof these queries. In this section, we present the features of SQL for simple retrieval \\nqueries. Features of SQL for specifying more complex retrieval queries are pre-\\nsented in Section 7.1.\\nBefore proceeding, we must point out an important distinction between the practical \\nSQL model and the formal relational model discussed in Chapter 5: SQL allows a \\ntable (relation) to have two or more tuples that are identical in all their attribute \\nvalues. Hence, in general, an SQL table is not a set of tuples, because a set does not \\nallow two identical members; rather, it is a multiset (sometimes called a bag) of \\ntuples. Some SQL relations are constrained to be sets  because a key constraint has \\nbeen declared or because the DISTINCT option has been used with the SELECT state-\\nment (described later in this section). We should be aware of this distinction as we \\ndiscuss the examples.\\n6.3.1  The SELECT-FROM-WHERE Structure  \\nof Basic SQL Queries\\nQueries in SQL can be very complex. We will start with simple queries, and then \\nprogress to more complex ones in a step-by-step manner. The basic form of the \\nSELECT statement, sometimes called a mapping or a select-from-where block, is \\nformed of the three clauses SELECT, FROM, and WHERE and has the following form:9\\nSELECT <attribute list>\\nFROM <table list>\\nWHERE <condition>;\\nwhere\\n ■ <attribute list> is a list of attribute names whose values are to be retrieved by \\nthe query.\\n ■ <table list> is a list of the relation names required to process the query.\\n ■ <condition> is a conditional (Boolean) expression that identifies the tuples \\nto be retrieved by the query.\\nIn SQL, the basic logical comparison operators for comparing attribute values with \\none another and with literal constants are =, <, <=, >, >=, and <>. These correspond \\nto the relational algebra operators =, <, ≤, >, ≥, and ≠, respectively, and to the \\nC/C++ programming language operators =, <, <=, >, >=, and !=. The main syntactic \\ndifference is the not equal operator. SQL has additional comparison operators that \\nwe will present gradually.\\nWe illustrate the basic \\nSELECT statement in SQL with some sample queries. The \\nqueries are labeled here with the same query numbers used in Chapter 8 for easy \\ncross-reference.\\n9The SELECT and FROM clauses are required in all SQL queries. The WHERE is optional (see Sec- \\ntion 6.3.3).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 202, 'page_label': '203'}, page_content='6.3 Basic Retrieval Queries in SQL  189\\nQuery 0. Retrieve the birth date and address of the employee(s) whose name is \\n‘John B. Smith’.\\nQ0: SELECT Bdate, Address\\n FROM EMPLOYEE\\n WHERE Fname = ‘John’ AND Minit = ‘B’ AND Lname = ‘Smith’;\\nThis query involves only the EMPLOYEE relation listed in the FROM clause. The \\nquery selects the individual EMPLOYEE  tuples that satisfy the condition of the \\nWHERE clause, then projects the result on the Bdate and Address attributes listed in \\nthe SELECT clause.\\nThe SELECT clause of SQL specifies the attributes whose values are to be retrieved, \\nwhich are called the projection attributes in relational algebra (see Chapter 8) and \\nthe WHERE clause specifies the Boolean condition that must be true for any \\nretrieved tuple, which is known as the selection condition  in relational algebra . \\nFigure 6.3(a) shows the result of query Q0 on the database of Figure 5.6.\\nWe can think of an implicit tuple variable or iterator in the SQL query ranging or \\nlooping over each individual tuple in the EMPLOYEE table and evaluating the condi-\\ntion in the WHERE clause. Only those tuples that satisfy the condition—that is, \\nthose tuples for which the condition evaluates to TRUE after substituting their cor-\\nresponding attribute values—are selected.\\nQuery 1.  Retrieve the name and address of all employees who work for the \\n‘Research’ department.\\nQ1: SELECT Fname, Lname, Address\\n FROM EMPLOYEE, DEPARTMENT\\n WHERE Dname = ‘Research’ AND Dnumber = Dno;\\nIn the WHERE clause of Q1, the condition Dname = ‘Research’ is a selection condition \\nthat chooses the particular tuple of interest in the DEPARTMENT table, because Dname \\nis an attribute of DEPARTMENT. The condition Dnumber = Dno is called a join condition, \\nbecause it combines two tuples: one from DEPARTMENT and one from EMPLOYEE, \\nwhenever the value of Dnumber in DEPARTMENT is equal to the value of Dno in \\nEMPLOYEE. The result of query Q1 is shown in Figure 6.3(b). In general, any number \\nof selection and join conditions may be specified in a single SQL query.\\nA query that involves only selection and join conditions plus projection attributes is \\nknown as a select-project-join  query. The next example is a select-project-join \\nquery with two join conditions.\\nQuery 2.  For every project located in ‘Stafford’, list the project number, the \\ncontrolling department number, and the department manager’s last name, \\naddress, and birth date.\\nQ2: SELECT Pnumber, Dnum, Lname, Address, Bdate\\n FROM PROJECT, DEPARTMENT, EMPLOYEE\\n WHERE  Dnum = Dnumber AND Mgr_ssn = Ssn AND  \\nPlocation = ‘Stafford’'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 203, 'page_label': '204'}, page_content='190 Chapter 6 Basic SQL\\n(a) Bdate\\n1965-01-09 731Fondren, Houston, TX\\nAddress (b) Fname\\nJohn\\nFranklin\\nRamesh\\nJoyce\\nSmith\\nWong\\nNarayan\\nEnglish\\n731 Fondren, Houston, TX\\n638 Voss, Houston, TX\\n975 Fire Oak, Humble, TX\\n5631 Rice, Houston, TX\\nLname Address\\n(d) E.Fname\\nJohn\\nFranklin\\nAlicia Zelaya\\nJoyce\\nRamesh\\nJennifer Wallace\\nAhmad Jabbar\\nSmith\\nWong\\nNarayan\\nEnglish\\nJennifer\\nJames\\nJennifer\\nFranklin\\nJames\\nFranklin\\nFranklin\\nWallace\\nBorg\\nWallace\\nWong\\nBorg\\nWong\\nWong\\nE.Lname S.Fname S.Lname\\nFname\\nJohn\\nFranklin\\nK\\nJoyce\\nRamesh\\nA\\nB\\nT\\nM\\nF\\nM\\nM\\n5\\n5\\n5\\n5\\n38000\\n25000\\n30000\\n40000\\n333445555\\n333445555\\n333445555\\n888665555\\nNarayan\\nEnglish\\nSmith\\nWong\\n975 Fire Oak, Humble, TX\\n5631 Rice, Houston, TX\\n731 Fondren, Houston, TX\\n638 Voss, Houston, TX\\n1962-09-15\\n1972-07-31\\n1965-09-01\\n1955-12-08\\n666884444\\n453453453\\n123456789\\n333445555\\nMinit Lname Ssn Bdate Address Sex Dno Salary Super_ssn\\n(g) \\n(e) E.Fname\\n123456789\\n333445555\\n999887777\\n453453453\\n666884444\\n987654321\\n987987987\\n888665555\\n(c) Pnumber\\n10\\n30\\n1941-06-20\\n1941-06-20\\n4\\n4\\nWallace 291Berry, Bellaire, TX\\n291Berry, Bellaire, TXWallace\\nDnum Lname Bdate Address (f) Ssn\\n123456789\\n333445555\\n999887777\\n453453453\\n666884444\\n987654321\\n987987987\\n888665555\\n123456789\\n333445555\\n999887777\\n453453453\\n666884444\\n987654321\\n987987987\\n888665555\\n123456789\\n333445555\\n999887777\\n453453453\\n666884444\\n987654321\\n987987987\\n888665555\\nResearch\\nResearch\\nResearch\\nResearch\\nResearch\\nResearch\\nResearch\\nResearch\\nAdministration\\nAdministration\\nAdministration\\nAdministration\\nAdministration\\nAdministration\\nAdministration\\nAdministration\\nHeadquarters\\nHeadquarters\\nHeadquarters\\nHeadquarters\\nHeadquarters\\nHeadquarters\\nHeadquarters\\nHeadquarters\\nDname\\nFigure 6.3 \\nResults of SQL queries when applied to the COMPANY database state shown  \\nin Figure 5.6. (a) Q0. (b) Q1. (c) Q2. (d) Q8. (e) Q9. (f) Q10. (g) Q1C.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 204, 'page_label': '205'}, page_content='6.3 Basic Retrieval Queries in SQL  191\\nThe join condition Dnum = Dnumber relates a project tuple to its controlling depart-\\nment tuple, whereas the join condition Mgr_ssn = Ssn relates the controlling depart-\\nment tuple to the employee tuple who manages that department. Each tuple in the \\nresult will be a combination of one project, one department (that controls the proj-\\nect), and one employee (that manages the department). The projection attributes \\nare used to choose the attributes to be displayed from each combined tuple. The \\nresult of query \\nQ2 is shown in Figure 6.3(c).\\n6.3.2  Ambiguous Attribute Names, Aliasing,  \\nRenaming, and Tuple Variables\\nIn SQL, the same name can be used for two (or more) attributes as long as the \\nattributes are in different tables.  If this is the case, and a multitable query refers to \\ntwo or more attributes with the same name, we must qualify the attribute name \\nwith the relation name to prevent ambiguity. This is done by prefixing the rela-\\ntion name to the attribute name and separating the two by a period. To illustrate \\nthis, suppose that in Figures 5.5 and 5.6 the \\nDno and Lname attributes of the \\nEMPLOYEE  relation were called Dnumber and Name, and the Dname attribute of \\nDEPARTMENT was also called Name; then, to prevent ambiguity, query Q1 would \\nbe rephrased as shown in Q1A. We must prefix the attributes Name and Dnumber \\nin Q1A to specify which ones we are referring to, because the same attribute \\nnames are used in both relations:\\nQ1A: SELECT Fname, EMPLOYEE.Name, Address\\n FROM EMPLOYEE, DEPARTMENT\\n WHERE  DEPARTMENT.Name = ‘Research’ AND  \\nDEPARTMENT.Dnumber = EMPLOYEE.Dnumber;\\nFully qualified attribute names can be used for clarity even if there is no ambi-\\nguity in attribute names. Q1 can be rewritten as Q1′ below with fully qualified \\nattribute names. We can also rename the table names to shorter names by creat-\\ning an alias for each table name to avoid repeated typing of long table names \\n(see Q8 below).\\nQ1′: SELECT  EMPLOYEE.Fname, EMPLOYEE.LName,  \\nEMPLOYEE.Address\\n FROM EMPLOYEE, DEPARTMENT\\n WHERE  DEPARTMENT.DName = ‘Research’ AND  \\nDEPARTMENT.Dnumber = EMPLOYEE.Dno;\\nThe ambiguity of attribute names also arises in the case of queries that refer to the \\nsame relation twice, as in the following example.\\nQuery 8. For each employee, retrieve the employee’s first and last name and the \\nfirst and last name of his or her immediate supervisor.\\nQ8: SELECT E.Fname, E.Lname, S.Fname, S.Lname\\n FROM EMPLOYEE AS E, EMPLOYEE AS S\\n WHERE E.Super_ssn = S.Ssn;'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 205, 'page_label': '206'}, page_content='192 Chapter 6 Basic SQL\\nIn this case, we are required to declare alternative relation names E and S, called \\naliases or tuple variables, for the EMPLOYEE relation. An alias can follow the key-\\nword AS, as shown in Q8, or it can directly follow the relation name—for example, \\nby writing EMPLOYEE E, EMPLOYEE S in the FROM clause of Q8. It is also possible \\nto rename the relation attributes within the query in SQL by giving them aliases. \\nFor example, if we write\\nEMPLOYEE AS E(Fn, Mi, Ln, Ssn, Bd, Addr, Sex, Sal, Sssn, Dno)\\nin the FROM clause, Fn becomes an alias for Fname, Mi for Minit, Ln for Lname, and \\nso on.\\nIn Q8, we can think of E and S as two different copies of the EMPLOYEE relation; the \\nfirst, E, represents employees in the role of supervisees or subordinates; the second, \\nS, represents employees in the role of supervisors. We can now join the two copies. \\nOf course, in reality there is only one EMPLOYEE relation, and the join condition is \\nmeant to join the relation with itself by matching the tuples that satisfy the join \\ncondition \\nE.Super_ssn = S.Ssn. Notice that this is an example of a one-level recur-\\nsive query, as we will discuss in Section 8.4.2. In earlier versions of SQL, it was not \\npossible to specify a general recursive query, with an unknown number of levels, in \\na single SQL statement. A construct for specifying recursive queries has been incor-\\nporated into SQL:1999 (see Chapter 7).\\nThe result of query Q8 is shown in Figure 6.3(d). Whenever one or more aliases \\nare given to a relation, we can use these names to represent different references \\nto that same relation. This permits multiple references to the same relation \\nwithin a query.\\nWe can use this alias-naming or renaming mechanism in any SQL query to specify \\ntuple variables for every table in the WHERE clause, whether or not the same rela-\\ntion needs to be referenced more than once. In fact, this practice is recommended \\nsince it results in queries that are easier to comprehend. For example, we could \\nspecify query Q1 as in Q1B:\\nQ1B: SELECT E.Fname, E.LName, E.Address\\n FROM EMPLOYEE AS E, DEPARTMENT AS D\\n WHERE D.DName = ‘Research’ AND D.Dnumber = E.Dno;\\n6.3.3 Unspecified WHERE Clause and Use of the Asterisk\\nWe discuss two more features of SQL here. A missing  WHERE clause indicates \\nno condition on tuple selection; hence, all tuples  of the relation specified in the \\nFROM clause qualify and are selected for the query result. If more than one rela-\\ntion is specified in the FROM clause and there is no WHERE  clause, then the \\nCROSS PRODUCT —all possible tuple combinations —of these relations is \\nselected. For example, Query 9 selects all EMPLOYEE  Ssns (Figure 6.3(e)), and \\nQuery 10 selects all combinations of an EMPLOYEE  Ssn and a DEPARTMENT  \\nDname , regardless of whether the employee works for the department or not \\n(Figure 6.3(f)).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 206, 'page_label': '207'}, page_content='6.3 Basic Retrieval Queries in SQL  193\\nQueries 9 and 10.  Select all EMPLOYEE Ssn s ( Q9) and all combinations of \\nEMPLOYEE Ssn and DEPARTMENT Dname (Q10) in the database.\\nQ9: SELECT Ssn\\n FROM EMPLOYEE;\\nQ10: SELECT Ssn, Dname\\n FROM EMPLOYEE, DEPARTMENT;\\nIt is extremely important to specify every selection and join condition in the WHERE \\nclause; if any such condition is overlooked, incorrect and very large relations may \\nresult. Notice that \\nQ10 is similar to a CROSS PRODUCT  operation followed by a \\nPROJECT operation in relational algebra (see Chapter 8). If we specify all the attri-\\nbutes of EMPLOYEE and DEPARTMENT in Q10, we get the actual CROSS PRODUCT \\n(except for duplicate elimination, if any).\\nTo retrieve all the attribute values of the selected tuples, we do not have to list the \\nattribute names explicitly in SQL; we just specify an asterisk (*), which stands for all \\nthe attributes. The * can also be prefixed by the relation name or alias; for example, \\nEMPLOYEE.* refers to all attributes of the EMPLOYEE table.\\nQuery Q1C retrieves all the attribute values of any EMPLOYEE  who works in \\nDEPARTMENT number 5 (Figure 6.3(g)), query Q1D retrieves all the attributes of an \\nEMPLOYEE and the attributes of the DEPARTMENT in which he or she works for \\nevery employee of the ‘Research’ department, and Q10A specifies the CROSS \\nPRODUCT of the EMPLOYEE and DEPARTMENT relations.\\nQ1C: SELECT *\\n FROM EMPLOYEE\\n WHERE Dno = 5;\\nQ1D: SELECT *\\n FROM EMPLOYEE, DEPARTMENT\\n WHERE Dname = ‘Research’ AND Dno = Dnumber;\\nQ10A: SELECT *\\n FROM EMPLOYEE, DEPARTMENT;\\n6.3.4 Tables as Sets in SQL\\nAs we mentioned earlier, SQL usually treats a table not as a set but rather as a multiset; \\nduplicate tuples can appear more than once  in a table, and in the result of a query. \\nSQL does not automatically eliminate duplicate tuples in the results of queries, for \\nthe following reasons:\\n ■ Duplicate elimination is an expensive operation. One way to implement it is \\nto sort the tuples first and then eliminate duplicates.\\n ■ The user may want to see duplicate tuples in the result of a query.\\n ■ When an aggregate function (see Section 7.1.7) is applied to tuples, in most \\ncases we do not want to eliminate duplicates.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 207, 'page_label': '208'}, page_content='194 Chapter 6 Basic SQL\\nAn SQL table with a key is restricted to being a set, since the key value must be dis-\\ntinct in each tuple.10 If we do want to eliminate duplicate tuples from the result of \\nan SQL query, we use the keyword DISTINCT in the SELECT clause, meaning that \\nonly distinct tuples should remain in the result. In general, a query with SELECT \\nDISTINCT eliminates duplicates, whereas a query with SELECT ALL does not. Speci-\\nfying SELECT with neither ALL nor DISTINCT—as in our previous examples—is \\nequivalent to SELECT ALL. For example, Q11 retrieves the salary of every employee; \\nif several employees have the same salary, that salary value will appear as many \\ntimes in the result of the query, as shown in Figure 6.4(a). If we are interested only \\nin distinct salary values, we want each value to appear only once, regardless of how \\nmany employees earn that salary. By using the keyword \\nDISTINCT as in Q11A, we \\naccomplish this, as shown in Figure 6.4(b).\\nQuery 11.  Retrieve the salary of every employee ( Q11) and all distinct salary \\nvalues (Q11A).\\nQ11: SELECT ALL Salary\\n FROM EMPLOYEE;\\nQ11A: SELECT DISTINCT Salary\\n FROM EMPLOYEE;\\nSQL has directly incorporated some of the set operations from mathematical set \\ntheory, which are also part of relational algebra (see Chapter 8). There are set union \\n(UNION), set difference ( EXCEPT),11 and set intersection ( INTERSECT) operations. \\nThe relations resulting from these set operations are sets of tuples; that is, duplicate \\ntuples are eliminated from the result.  These set operations apply only to type- \\ncompatible relations, so we must make sure that the two relations on which we apply \\nthe operation have the same attributes and that the attributes appear in the same \\norder in both relations. The next example illustrates the use of \\nUNION.\\n(b)Salary\\n30000\\n40000\\n25000\\n43000\\n38000\\n25000\\n25000\\n55000\\n(c)(a) Salary\\n30000\\n40000\\n25000\\n43000\\n38000\\n55000\\nFname     Lname\\n(d) Fname     Lname\\nJames     Borg\\nFigure 6.4 \\nResults of additional \\nSQL queries when \\napplied to the  \\nCOMPANY database \\nstate shown in  \\nFigure 5.6. (a) Q11.  \\n(b) Q11A. (c) Q16.  \\n(d) Q18.\\n10In general, an SQL table is not required to have a key, although in most cases there will be one.\\n11In some systems, the keyword MINUS is used for the set difference operation instead of EXCEPT.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 208, 'page_label': '209'}, page_content='6.3 Basic Retrieval Queries in SQL  195\\nQuery 4. Make a list of all project numbers for projects that involve an employee \\nwhose last name is ‘Smith’, either as a worker or as a manager of the department \\nthat controls the project.\\nQ4A: ( SELECT DISTINCT Pnumber\\n   FROM PROJECT, DEPARTMENT, EMPLOYEE\\n   WHERE Dnum = Dnumber AND Mgr_ssn = Ssn\\n  AND Lname = ‘Smith’ )\\n   UNION\\n ( SELECT DISTINCT Pnumber\\n   FROM PROJECT, WORKS_ON, EMPLOYEE\\n   WHERE Pnumber = Pno AND Essn = Ssn\\n    AND Lname = ‘Smith’ );\\nThe first SELECT query retrieves the projects that involve a ‘Smith’ as manager of \\nthe department that controls the project, and the second retrieves the projects that \\ninvolve a ‘Smith’ as a worker on the project. Notice that if several employees have \\nthe last name ‘Smith’, the project names involving any of them will be retrieved. \\nApplying the \\nUNION operation to the two SELECT queries gives the desired result.\\nSQL also has corresponding multiset operations, which are followed by the key-\\nword ALL (UNION ALL , EXCEPT ALL , INTERSECT ALL ). Their results are multisets \\n(duplicates are not eliminated). The behavior of these operations is illustrated by \\nthe examples in Figure 6.5. Basically, each tuple—whether it is a duplicate or not—\\nis considered as a different tuple when applying these operations.\\n6.3.5 Substring Pattern Matching and Arithmetic Operators\\nIn this section we discuss several more features of SQL. The first feature allows \\ncomparison conditions on only parts of a character string, using the \\nLIKE compari-\\nson operator. This can be used for string pattern matching. Partial strings are spec-\\nified using two reserved characters: % replaces an arbitrary number of zero or more \\ncharacters, and the underscore (_) replaces a single character. For example, con-\\nsider the following query.\\nT(b)\\nA\\na1\\na1\\na2\\na2\\na2\\na3\\na4\\na5\\nT(c)\\nA\\na2\\na3\\nT(d)\\nA\\na1\\na2\\nR(a)\\nA\\na1\\na2\\na2\\na3\\nS\\nA\\na1\\na2\\na4\\na5\\nFigure 6.5 \\nThe results of SQL multiset \\noperations. (a) Two tables, \\nR(A) and S(A).  \\n(b) R(A)UNION ALL S(A). \\n(c) R(A) EXCEPT ALL S(A). \\n(d) R(A) INTERSECT ALL \\nS(A).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 209, 'page_label': '210'}, page_content='196 Chapter 6 Basic SQL\\nQuery 12. Retrieve all employees whose address is in Houston, Texas.\\nQ12: SELECT Fname, Lname\\n FROM EMPLOYEE\\n WHERE Address LIKE ‘%Houston,TX%’;\\nTo retrieve all employees who were born during the 1970s, we can use Query Q12A. \\nHere, ‘7’ must be the third character of the string (according to our format for date), \\nso we use the value ‘_ _ 5 _ _ _ _ _ _ _’, with each underscore serving as a place-\\nholder for an arbitrary character.\\nQuery 12A. Find all employees who were born during the 1950s.\\nQ12: SELECT Fname, Lname\\n FROM EMPLOYEE\\n WHERE Bdate LIKE ‘_ _ 7 _ _ _ _ _ _ _’;\\nIf an underscore or % is needed as a literal character in the string, the character \\nshould be preceded by an escape character, which is specified after the string using \\nthe keyword ESCAPE. For example, ‘AB\\\\_CD\\\\%EF’ ESCAPE ‘\\\\’ represents the lit-\\neral string ‘AB_CD%EF’ because \\\\ is specified as the escape character. Any charac-\\nter not used in the string can be chosen as the escape character. Also, we need a rule \\nto specify apostrophes or single quotation marks (‘ ’) if they are to be included in a \\nstring because they are used to begin and end strings. If an apostrophe (’) is needed, \\nit is represented as two consecutive apostrophes (”) so that it will not be interpreted \\nas ending the string. Notice that substring comparison implies that attribute values \\nare not atomic (indivisible) values, as we had assumed in the formal relational \\nmodel (see Section 5.1) .\\nAnother feature allows the use of arithmetic in queries. The standard arithmetic \\noperators for addition (+), subtraction (−), multiplication (*), and division (/) can \\nbe applied to numeric values or attributes with numeric domains. For example, \\nsuppose that we want to see the effect of giving all employees who work on the \\n‘ProductX’ project a 10% raise; we can issue Query 13 to see what their salaries \\nwould become. This example also shows how we can rename an attribute in the \\nquery result using \\nAS in the SELECT clause.\\nQuery 13.  Show the resulting salaries if every employee working on the \\n‘ProductX’ project is given a 10% raise.\\nQ13: SELECT E.Fname, E.Lname, 1.1 * E.Salary AS Increased_sal\\n FROM EMPLOYEE AS E, WORKS_ON AS W, PROJECT AS P\\n WHERE  E.Ssn = W.Essn AND W.Pno = P.Pnumber AND  \\nP.Pname = ‘ProductX’;\\nFor string data types, the concatenate operator || can be used in a query to append \\ntwo string values. For date, time, timestamp, and interval data types, operators \\ninclude incrementing (+) or decrementing (−) a date, time, or timestamp by an \\ninterval. In addition, an interval value is the result of the difference between two \\ndate, time, or timestamp values. Another comparison operator, which can be used \\nfor convenience, is \\nBETWEEN, which is illustrated in Query 14.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 210, 'page_label': '211'}, page_content='6.3 Basic Retrieval Queries in SQL  197\\nQuery 14.  Retrieve all employees in department 5 whose salary is between \\n$30,000 and $40,000.\\nQ14: SELECT *\\n FROM EMPLOYEE\\n WHERE (Salary BETWEEN 30000 AND 40000) AND Dno = 5;\\nThe condition (Salary BETWEEN 30000 AND 40000) in Q14 is equivalent to the con-\\ndition ((Salary >= 30000) AND (Salary <= 40000)).\\n6.3.6 Ordering of Query Results\\nSQL allows the user to order the tuples in the result of a query by the values of one \\nor more of the attributes that appear in the query result, by using the \\nORDER BY \\nclause. This is illustrated by Query 15.\\nQuery 15.  Retrieve a list of employees and the projects they are working on, \\nordered by department and, within each department, ordered alphabetically by \\nlast name, then first name.\\nQ15: SELECT D.Dname, E.Lname, E.Fname, P.Pname\\n FROM  DEPARTMENT AS D, EMPLOYEE AS E, WORKS_ON AS W, \\nPROJECT AS P\\n WHERE  D.Dnumber = E.Dno AND E.Ssn = W.Essn AND W.Pno = \\nP.Pnumber\\n ORDER BY D.Dname, E.Lname, E.Fname;\\nThe default order is in ascending order of values. We can specify the keyword DESC \\nif we want to see the result in a descending order of values. The keyword ASC can be \\nused to specify ascending order explicitly. For example, if we want descending \\nalphabetical order on \\nDname and ascending order on Lname, Fname, the ORDER BY \\nclause of Q15 can be written as\\nORDER BY D.Dname DESC, E.Lname ASC, E.Fname ASC\\n6.3.7 Discussion and Summary of  \\nBasic SQL Retrieval Queries\\nA simple retrieval query in SQL can consist of up to four clauses, but only the first \\ntwo—SELECT and FROM—are mandatory. The clauses are specified in the follow-\\ning order, with the clauses between square brackets [ … ] being optional:\\nSELECT <attribute list>\\nFROM <table list>\\n[ WHERE <condition> ]\\n[ ORDER BY <attribute list> ];\\nThe SELECT  clause lists the attributes to be retrieved, and the FROM  clause \\nspecifies all relations (tables) needed in the simple query. The WHERE clause \\nidentifies the conditions for selecting the tuples from these relations, including'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 211, 'page_label': '212'}, page_content='198 Chapter 6 Basic SQL\\njoin conditions if needed. ORDER BY specifies an order for displaying the results \\nof a query. Two additional clauses GROUP BY  and HAVING will be described in \\nSection 7.1.8.\\nIn Chapter 7, we will present more complex features of SQL retrieval queries. These \\ninclude the following: nested queries that allow one query to be included as part of \\nanother query; aggregate functions that are used to provide summaries of the infor-\\nmation in the tables; two additional clauses (\\nGROUP BY and HAVING) that can be \\nused to provide additional power to aggregate functions; and various types of joins \\nthat can combine records from various tables in different ways.\\n6.4  INSERT, DELETE, and UPDATE  \\nStatements in SQL\\nIn SQL, three commands can be used to modify the database: INSERT, DELETE, and \\nUPDATE. We discuss each of these in turn.\\n6.4.1 The INSERT Command\\nIn its simplest form, INSERT is used to add a single tuple (row) to a relation (table). \\nWe must specify the relation name and a list of values for the tuple. The values \\nshould be listed in the same order in which the corresponding attributes were speci-\\nfied in the CREATE TABLE  command. For example, to add a new tuple to the \\nEMPLOYEE  relation shown in Figure 5.5 and specified in the CREATE TABLE \\nEMPLOYEE … command in Figure 6.1, we can use U1:\\nU1: INSERT INTO EMPLOYEE\\n VALUES  ( ‘Richard’, ‘K’, ‘Marini’, ‘653298653’, ‘1962-12-30’, ‘98  \\nOak Forest, Katy, TX’, ‘M’, 37000, ‘653298653’, 4 );\\nA second form of the INSERT statement allows the user to specify explicit attribute \\nnames that correspond to the values provided in the INSERT command. This is use-\\nful if a relation has many attributes but only a few of those attributes are assigned \\nvalues in the new tuple. However, the values must include all attributes with NOT \\nNULL specification and no default value. Attributes with NULL allowed or DEFAULT \\nvalues are the ones that can be left out.  For example, to enter a tuple for a new \\nEMPLOYEE for whom we know only the Fname, Lname, Dno, and Ssn attributes, we \\ncan use U1A:\\nU1A: INSERT INTO EMPLOYEE (Fname, Lname, Dno, Ssn)\\n VALUES (‘Richard’, ‘Marini’, 4, ‘653298653’);\\nAttributes not specified in U1A are set to their DEFAULT or to NULL, and the values \\nare listed in the same order as the attributes are listed in the INSERT command itself. \\nIt is also possible to insert into a relation multiple tuples separated by commas in a \\nsingle INSERT command. The attribute values forming each tuple are enclosed in \\nparentheses.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 212, 'page_label': '213'}, page_content='6.4 INSERT, DELETE, and UPDATE Statements in SQL  199\\nA DBMS that fully implements SQL should support and enforce all the integrity \\nconstraints that can be specified in the DDL. For example, if we issue the command \\nin \\nU2 on the database shown in Figure 5.6, the DBMS should reject the operation \\nbecause no DEPARTMENT tuple exists in the database with Dnumber = 2. Similarly, \\nU2A would be rejected because no Ssn value is provided and it is the primary key, \\nwhich cannot be NULL.\\nU2: INSERT INTO EMPLOYEE (Fname, Lname, Ssn, Dno)\\n VALUES  (‘Robert’, ‘Hatcher’, ‘980760540’, 2);\\n ( U2 is rejected if referential integrity checking is provided by DBMS.)\\nU2A: INSERT INTO EMPLOYEE (Fname, Lname, Dno)\\n VALUES  (‘Robert’, ‘Hatcher’, 5);\\n ( U2A is rejected if NOT NULL checking is provided by DBMS.)\\nA variation of the INSERT command inserts multiple tuples into a relation in con-\\njunction with creating the relation and loading it with the result of a query.  For \\nexample, to create a temporary table that has the employee last name, project name, \\nand hours per week for each employee working on a project, we can write the state-\\nments in \\nU3A and U3B:\\nU3A: CREATE TABLE WORKS_ON_INFO\\n ( Emp_name  VARCHAR (15),\\n   Proj_name  VARCHAR (15),\\n   Hours_per_week DECIMAL (3,1) );\\nU3B: INSERT INTO  WORKS_ON_INFO ( Emp_name, Proj_name, \\nHours_per_week )\\n SELECT  E.Lname, P.Pname, W.Hours\\n FROM  PROJECT P, WORKS_ON W, EMPLOYEE E\\n WHERE  P.Pnumber = W.Pno AND W.Essn = E.Ssn;\\nA table WORKS_ON_INFO is created by U3A and is loaded with the joined informa-\\ntion retrieved from the database by the query in U3B. We can now query  \\nWORKS_ON_INFO as we would any other relation; when we do not need it anymore, \\nwe can remove it by using the DROP TABLE command (see Chapter 7). Notice that \\nthe WORKS_ON_INFO table may not be up to date; that is, if we update any of the \\nPROJECT,WORKS_ON, or EMPLOYEE relations after issuing U3B, the information \\nin WORKS_ON_INFO may become outdated.  We have to create a view (see Chap- \\nter 7) to keep such a table up to date.\\nMost DBMSs have bulk loading tools that allow a user to load formatted data from \\na file into a table without having to write a large number of INSERT commands. \\nThe user can also write a program to read each record in the file, format it as a row \\nin the table, and insert it using the looping constructs of a programming language \\n(see Chapters 10 and 11, where we discuss database programming techniques).\\nAnother variation for loading data is to create a new table TNEW that has the \\nsame attributes as an existing table T, and load some of the data currently in T \\ninto TNEW. The syntax for doing this uses the LIKE clause. For example, if we'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 213, 'page_label': '214'}, page_content='200 Chapter 6 Basic SQL\\nwant to create a table D5EMPS with a similar structure to the EMPLOYEE table \\nand load it with the rows of employees who work in department 5, we can write \\nthe following SQL:\\nCREATE TABLE D5EMPS LIKE EMPLOYEE\\n(SELECT  E.*\\nFROM  EMPLOYEE AS E\\nWHERE  E.Dno = 5) WITH DATA;\\nThe clause WITH DATA specifies that the table will be created and loaded with \\nthe data specified in the query, although in some implementations it may be \\nleft out.\\n6.4.2 The DELETE Command\\nThe DELETE  command removes tuples from a relation. It includes a WHERE \\nclause, similar to that used in an SQL query, to select the tuples to be deleted. \\nTuples are explicitly deleted from only one table at a time. However, the deletion \\nmay propagate to tuples in other relations if referential triggered actions  are spec-\\nified in the referential integrity constraints of the DDL (see Section 6.2.2).\\n12 \\nDepending on the number of tuples selected by the condition in the WHERE \\nclause, zero, one, or several tuples can be deleted by a single DELETE command. A \\nmissing WHERE clause specifies that all tuples in the relation are to be deleted; \\nhowever, the table remains in the database as an empty table. We must use the \\nDROP TABLE  command to remove the table definition (see Chapter 7). The \\nDELETE commands in U4A to U4D, if applied independently to the database state \\nshown in Figure 5.6, will delete zero, one, four, and all tuples, respectively, from \\nthe \\nEMPLOYEE relation:\\nU4A: DELETE FROM EMPLOYEE \\n WHERE  Lname = ‘Brown’;\\nU4B: DELETE FROM EMPLOYEE \\n WHERE  Ssn = ‘123456789’;\\nU4C: DELETE FROM EMPLOYEE\\n WHERE  Dno = 5;\\nU4D: DELETE FROM EMPLOYEE;\\n6.4.3 The UPDATE Command\\nThe UPDATE command is used to modify attribute values of one or more selected \\ntuples. As in the DELETE command, a WHERE clause in the UPDATE command \\nselects the tuples to be modified from a single relation. However, updating a pri-\\nmary key value may propagate to the foreign key values of tuples in other rela-\\ntions if such a referential triggered action  is specified in the referential integrity \\n12Other actions can be automatically applied through triggers (see Section 26.1) and other mechanisms.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 214, 'page_label': '215'}, page_content='6.5 Additional Features of SQL  201\\nconstraints of the DDL (see Section 6.2.2). An additional SET clause in the \\nUPDATE command specifies the attributes to be modified and their new values. \\nFor example, to change the location and controlling department number of proj-\\nect number 10 to ‘Bellaire’ and 5, respectively, we use \\nU5:\\nU5: UPDATE PROJECT\\n SET Plocation = ‘Bellaire’, Dnum = 5\\n WHERE Pnumber = 10;\\nSeveral tuples can be modified with a single UPDATE command. An example is to \\ngive all employees in the ‘Research’ department a 10% raise in salary, as shown in \\nU6. In this request, the modified Salary value depends on the original Salary value \\nin each tuple, so two references to the Salary  attribute are needed. In the SET \\nclause, the reference to the Salary attribute on the right refers to the old Salary \\nvalue before modification , and the one on the left refers to the new Salary value \\nafter modification :\\nU6: UPDATE EMPLOYEE\\n SET Salary = Salary * 1.1\\n WHERE Dno = 5;\\nIt is also possible to specify NULL or DEFAULT as the new attribute value. Notice that \\neach UPDATE command explicitly refers to a single relation only. To modify multi-\\nple relations, we must issue several UPDATE commands.\\n6.5 Additional Features of SQL\\nSQL has a number of additional features that we have not described in this chapter \\nbut that we discuss elsewhere in the book. These are as follows:\\n ■ In Chapter 7, which is a continuation of this chapter, we will present the fol-\\nlowing SQL features: various techniques for specifying complex retrieval \\nqueries, including nested queries, aggregate functions, grouping, joined \\ntables, outer joins, case statements, and recursive queries; SQL views, trig-\\ngers, and assertions; and commands for schema modification.\\n ■ SQL has various techniques for writing programs in various programming \\nlanguages that include SQL statements to access one or more databases. \\nThese include embedded (and dynamic) SQL, SQL/CLI (Call Level Interface) \\nand its predecessor ODBC (Open Data Base Connectivity), and SQL/PSM \\n(Persistent Stored Modules). We discuss these techniques in Chapter 10. We \\nalso describe how to access SQL databases through the Java programming \\nlanguage using JDBC and SQLJ.\\n ■ Each commercial RDBMS will have, in addition to the SQL commands, a set \\nof commands for specifying physical database design parameters, file struc-\\ntures for relations, and access paths such as indexes. We called these com-\\nmands a storage definition language (SDL) in Chapter 2. Earlier versions of \\nSQL had commands for creating indexes, but these were removed from the'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 215, 'page_label': '216'}, page_content='202 Chapter 6 Basic SQL\\nlanguage because they were not at the conceptual schema level. Many sys-\\ntems still have the CREATE INDEX  commands; but they require a special \\nprivilege. We describe this in Chapter 17.\\n ■ SQL has transaction control commands. These are used to specify units of \\ndatabase processing for concurrency control and recovery purposes. We \\ndiscuss these commands in Chapter 20 after we discuss the concept of trans-\\nactions in more detail.\\n ■ SQL has language constructs for specifying the granting and revoking of \\nprivileges to users. Privileges typically correspond to the right to use certain \\nSQL commands to access certain relations. Each relation is assigned an \\nowner, and either the owner or the DBA staff can grant to selected users the \\nprivilege to use an SQL statement—such as \\nSELECT, INSERT, DELETE, or \\nUPDATE—to access the relation. In addition, the DBA staff can grant the \\nprivileges to create schemas, tables, or views to certain users. These SQL \\ncommands—called \\nGRANT and REVOKE—are discussed in Chapter 20, \\nwhere we discuss database security and authorization.\\n ■ SQL has language constructs for creating triggers. These are generally \\nreferred to as active database techniques, since they specify actions that are \\nautomatically triggered by events such as database updates. We discuss these \\nfeatures in Section 26.1, where we discuss active database concepts.\\n ■ SQL has incorporated many features from object-oriented models to have \\nmore powerful capabilities, leading to enhanced relational systems known \\nas object-relational. Capabilities such as creating complex-structured attri-\\nbutes, specifying abstract data types (called UDTs or user-defined types) for \\nattributes and tables, creating object identifiers for referencing tuples, and \\nspecifying operations on types are discussed in Chapter 12.\\n ■ SQL and relational databases can interact with new technologies such as \\nXML (see Chapter 13) and OLAP/data warehouses (Chapter 29).\\n6.6 Summary\\nIn this chapter, we introduced the SQL database language. This language and its \\nvariations have been implemented as interfaces to many commercial relational \\nDBMSs, including Oracle’s Oracle; ibm’s DB2; Microsoft’s SQL Server; and many \\nother systems including Sybase and INGRES. Some open source systems also provide \\nSQL, such as MySQL and PostgreSQL. The original version of SQL was imple-\\nmented in the experimental DBMS called SYSTEM R, which was developed at IBM \\nResearch. SQL is designed to be a comprehensive language that includes statements \\nfor data definition, queries, updates, constraint specification, and view definition. \\nWe discussed the following features of SQL in this chapter: the data definition com-\\nmands for creating tables, SQL basic data types, commands for constraint specifica-\\ntion, simple retrieval queries, and database update commands. In the next chapter, \\nwe will present the following features of SQL: complex retrieval queries; views; trig-\\ngers and assertions; and schema modification commands.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 216, 'page_label': '217'}, page_content='Exercises 203\\nReview Questions\\n 6.1. How do the relations (tables) in SQL differ from the relations defined for-\\nmally in Chapter 3? Discuss the other differences in terminology. Why does \\nSQL allow duplicate tuples in a table or in a query result?\\n 6.2. List the data types that are allowed for SQL attributes.\\n 6.3. How does SQL allow implementation of the entity integrity and referential \\nintegrity constraints described in Chapter 3? What about referential trig-\\ngered actions?\\n 6.4. Describe the four clauses in the syntax of a simple SQL retrieval query. Show \\nwhat type of constructs can be specified in each of the clauses. Which are \\nrequired and which are optional?\\nExercises\\n 6.5. Consider the database shown in Figure 1.2, whose schema is shown in Fig-\\nure 2.1. What are the referential integrity constraints that should hold on the \\nschema? Write appropriate SQL DDL statements to define the database.\\n 6.6. Repeat Exercise 6.5, but use the AIRLINE database schema of Figure 5.8.\\n 6.7. Consider the LIBRARY relational database schema shown in Figure 6.6. \\nChoose the appropriate action (reject, cascade, set to NULL, set to default) for \\neach referential integrity constraint, both for the deletion of a referenced \\ntuple and for the update of a primary key attribute value in a referenced \\ntuple. Justify your choices.\\n 6.8. Write appropriate SQL DDL statements for declaring the LIBRARY relational \\ndatabase schema of Figure 6.6. Specify the keys and referential triggered \\nactions.\\n 6.9. How can the key and foreign key constraints be enforced by the DBMS? Is \\nthe enforcement technique you suggest difficult to implement? Can the con-\\nstraint checks be executed efficiently when updates are applied to the data-\\nbase?\\n 6.10. Specify the following queries in SQL on the COMPANY relational database \\nschema shown in Figure 5.5. Show the result of each query if it is applied to \\nthe \\nCOMPANY database in Figure 5.6.\\na. Retrieve the names of all employees in department 5 who work more \\nthan 10 hours per week on the ProductX project.\\nb. List the names of all employees who have a dependent with the same first \\nname as themselves.\\nc. Find the names of all employees who are directly supervised by ‘Franklin \\nWong’.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 217, 'page_label': '218'}, page_content='204 Chapter 6 Basic SQL\\n 6.11.  Specify the updates of Exercise 3.11 using the SQL update commands.\\n 6.12.  Specify the following queries in SQL on the database schema of Figure 1.2.\\na. Retrieve the names of all senior students majoring in ‘cs’ (computer \\nscience).\\nb. Retrieve the names of all courses taught by Professor King in 2007 and \\n2008.\\nc. For each section taught by Professor King, retrieve the course number, \\nsemester, year, and number of students who took the section.\\nd. Retrieve the name and transcript of each senior student (Class = 4) \\nmajoring in CS. A transcript includes course name, course number, \\ncredit hours, semester, year, and grade for each course completed by \\nthe student.\\nPublisher_nameBook_id Title\\nBOOK\\nBOOK_COPIES\\nBook_id Branch_id No_of_copies\\nBOOK_AUTHORS\\nBook_id Author_name\\nLIBRARY_BRANCH\\nBranch_id Branch_name Address\\nPUBLISHER\\nName Address Phone\\nBOOK_LOANS\\nBook_id Branch_id Card_no Date_out Due_date\\nBORROWER\\nCard_no Name Address Phone\\nFigure 6.6 \\nA relational database \\nschema for a  \\nLIBRARY database.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 218, 'page_label': '219'}, page_content='Selected Bibliography 205\\n 6.13.  Write SQL update statements to do the following on the database schema \\nshown in Figure 1.2.\\na. Insert a new student, <‘Johnson’, 25, 1, ‘Math’>, in the database.\\nb. Change the class of student ‘Smith’ to 2.\\nc. Insert a new course, <‘Knowledge Engineering’, ‘cs4390’, 3, ‘cs’>.\\nd. Delete the record for the student whose name is ‘Smith’ and whose stu-\\ndent number is 17.\\n 6.14.  Design a relational database schema for a database application of your \\nchoice.\\na. Declare your relations using the SQL DDL.\\nb. Specify a number of queries in SQL that are needed by your database \\napplication.\\nc. Based on your expected use of the database, choose some attributes that \\nshould have indexes specified on them.\\nd. Implement your database, if you have a DBMS that supports SQL.\\n 6.15.  Consider that the EMPLOYEE table’s constraint EMPSUPERFK as specified in \\nFigure 6.2 is changed to read as follows:\\nCONSTRAINT EMPSUPERFK\\n   FOREIGN KEY (Super_ssn) REFERENCES EMPLOYEE(Ssn)\\n                             ON DELETE CASCADE ON UPDATE CASCADE,\\nAnswer the following questions:\\na. What happens when the following command is run on the database state \\nshown in Figure 5.6?\\nDELETE EMPLOYEE WHERE Lname = ‘Borg’\\nb. Is it better to CASCADE or SET NULL in case of EMPSUPERFK constraint \\nON DELETE?\\n 6.16.  Write SQL statements to create a table EMPLOYEE_BACKUP to back up the \\nEMPLOYEE table shown in Figure 5.6.\\nSelected Bibliography\\nThe SQL language, originally named SEQUEL, was based on the language SQUARE \\n(Specifying Queries as Relational Expressions) described by Boyce et al. (1975). The \\nsyntax of SQUARE was modified into SEQUEL (Chamberlin & Boyce, 1974) and \\nthen into SEQUEL 2 (Chamberlin et al., 1976), on which SQL is based. The original \\nimplementation of SEQUEL was done at IBM Research, San Jose, California. We \\nwill give additional references to various aspects of SQL at the end of Chapter 7.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 219, 'page_label': '220'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 220, 'page_label': '221'}, page_content='207\\n7\\nMore SQL: Complex Queries, \\nTriggers, Views, and  \\nSchema Modification\\nT\\nhis chapter describes more advanced features of \\nthe SQL language for relational databases. We start \\nin Section 7.1 by presenting more complex features of SQL retrieval queries, such as \\nnested queries, joined tables, outer joins, aggregate functions, and grouping, and \\ncase statements. In Section 7.2, we describe the \\nCREATE ASSERTION  statement, \\nwhich allows the specification of more general constraints on the database. We also \\nintroduce the concept of triggers and the \\nCREATE TRIGGER statement, which will \\nbe presented in more detail in Section 26.1 when we present the principles of active \\ndatabases. Then, in Section 7.3, we describe the SQL facility for defining views on \\nthe database. Views are also called virtual or derived tables because they present the \\nuser with what appear to be tables; however, the information in those tables is \\nderived from previously defined tables. Section 7.4 introduces the SQL \\nALTER \\nTABLE statement, which is used for modifying the database tables and constraints. \\nSection 7.5 is the chapter summary.\\nThis chapter is a continuation of Chapter 6. The instructor may skip parts of this \\nchapter if a less detailed introduction to SQL is intended.\\n7.1 More Complex SQL Retrieval Queries\\nIn Section 6.3, we described some basic types of retrieval queries in SQL. Because of \\nthe generality and expressive power of the language, there are many additional fea-\\ntures that allow users to specify more complex retrievals from the database. We \\ndiscuss several of these features in this section.\\nchapter  7'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 221, 'page_label': '222'}, page_content='208 Chapter 7 More SQL: Complex Queries, Triggers, Views, and Schema Modification\\n7.1.1 Comparisons Involving NULL and Three-Valued Logic\\nSQL has various rules for dealing with NULL values. Recall from Section 5.1.2 that \\nNULL is used to represent a missing value, but that it usually has one of three differ-\\nent interpretations—value unknown (value exists but is not known, or it is not \\nknown whether or not the value exists), value not available (value exists but is pur-\\nposely withheld), or value not applicable (the attribute does not apply to this tuple \\nor is undefined for this tuple). Consider the following examples to illustrate each of \\nthe meanings of \\nNULL.\\n  1. Unknown value. A person’s date of birth is not known, so it is represented \\nby NULL in the database. An example of the other case of unknown would be \\nNULL for a person’s home phone because it is not known whether or not the \\nperson has a home phone.\\n  2. Unavailable or withheld value.  A person has a home phone but does not \\nwant it to be listed, so it is withheld and represented as NULL in the database.\\n  3. Not applicable attribute. An attribute LastCollegeDegree would be NULL for a \\nperson who has no college degrees because it does not apply to that person.\\nIt is often not possible to determine which of the meanings is intended; for exam-\\nple, a NULL for the home phone of a person can have any of the three meanings. \\nHence, SQL does not distinguish among the different meanings of NULL.\\nIn general, each individual NULL value is considered to be different from every other \\nNULL value in the various database records. When a record with NULL in one of its \\nattributes is involved in a comparison operation, the result is considered to be \\nUNKNOWN (it may be TRUE or it may be FALSE). Hence, SQL uses a three-valued \\nlogic with values TRUE, FALSE, and UNKNOWN instead of the standard two-valued \\n(Boolean) logic with values TRUE or FALSE. It is therefore necessary to define the \\nresults (or truth values) of three-valued logical expressions when the logical con-\\nnectives \\nAND, OR, and NOT are used. Table 7.1 shows the resulting values.\\nTable 7.1 Logical Connectives in Three-Valued Logic\\n(a) AND TRUE FALSE UNKNOWN\\nTRUE TRUE FALSE UNKNOWN\\nFALSE FALSE FALSE FALSE\\nUNKNOWN UNKNOWN FALSE UNKNOWN\\n(b) OR TRUE FALSE UNKNOWN\\nTRUE TRUE TRUE TRUE\\nFALSE TRUE FALSE UNKNOWN\\nUNKNOWN TRUE UNKNOWN UNKNOWN\\n(c) NOT\\nTRUE FALSE\\nFALSE TRUE\\nUNKNOWN UNKNOWN'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 222, 'page_label': '223'}, page_content='7.1 More Complex SQL Retrieval Queries  209\\nIn Tables 7.1(a) and 7.1(b), the rows and columns represent the values of the results \\nof comparison conditions, which would typically appear in the WHERE clause of an \\nSQL query. Each expression result would have a value of TRUE, FALSE , or \\nUNKNOWN. The result of combining the two values using the AND logical connec-\\ntive is shown by the entries in Table 7.1(a). Table 7.1(b) shows the result of using \\nthe \\nOR logical connective. For example, the result of ( FALSE AND UNKNOWN ) is \\nFALSE, whereas the result of ( FALSE OR UNKNOWN ) is UNKNOWN. Table 7.1(c) \\nshows the result of the NOT logical operation. Notice that in standard Boolean logic, \\nonly TRUE or FALSE values are permitted; there is no UNKNOWN value.\\nIn select-project-join queries, the general rule is that only those combinations of \\ntuples that evaluate the logical expression in the WHERE clause of the query to TRUE \\nare selected. Tuple combinations that evaluate to FALSE or UNKNOWN are not \\nselected. However, there are exceptions to that rule for certain operations, such as \\nouter joins, as we shall see in Section 7.1.6.\\nSQL allows queries that check whether an attribute value is \\nNULL. Rather than using  \\n= or <> to compare an attribute value to NULL, SQL uses the comparison operators IS or \\nIS NOT. This is because SQL considers each NULL value as being distinct from every \\nother NULL value, so equality comparison is not appropriate. It follows that when a join \\ncondition is specified, tuples with NULL values for the join attributes are not included in \\nthe result (unless it is an OUTER JOIN; see Section 7.1.6). Query 18 illustrates NULL com-\\nparison by retrieving any employees who do not have a supervisor.\\nQuery 18. Retrieve the names of all employees who do not have supervisors.\\nQ18: SELECT Fname, Lname\\n FROM EMPLOYEE\\n WHERE Super_ssn IS NULL;\\n7.1.2  Nested Queries, Tuples,  \\nand Set/Multiset Comparisons\\nSome queries require that existing values in the database be fetched and then used \\nin a comparison condition. Such queries can be conveniently formulated by using \\nnested queries, which are complete select-from-where blocks within another SQL \\nquery. That other query is called the outer query . These nested queries can also \\nappear in the WHERE clause or the FROM clause or the SELECT clause or other \\nSQL clauses as needed. Query 4 is formulated in \\nQ4 without a nested query, but it \\ncan be rephrased to use nested queries as shown in Q4A. Q4A introduces the com-\\nparison operator IN, which compares a value v with a set (or multiset) of values V \\nand evaluates to TRUE if v is one of the elements in V.\\nIn Q4A, the first nested query selects the project numbers of projects that have an \\nemployee with last name ‘Smith’ involved as manager, whereas the second nested query \\nselects the project numbers of projects that have an employee with last name ‘Smith’ \\ninvolved as worker. In the outer query, we use the \\nOR logical connective to retrieve a \\nPROJECT tuple if the PNUMBER value of that tuple is in the result of either nested query.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 223, 'page_label': '224'}, page_content='210 Chapter 7 More SQL: Complex Queries, Triggers, Views, and Schema Modification\\nQ4A: SELECT DISTINCT Pnumber\\n FROM PROJECT\\n WHERE Pnumber IN\\n  ( SELECT Pnumber\\n    FROM PROJECT, DEPARTMENT, EMPLOYEE\\n    WHERE  Dnum = Dnumber AND\\n   Mgr_ssn = Ssn AND Lname = ‘Smith’ )\\n  OR\\n  Pnumber IN\\n  ( SELECT Pno\\n    FROM WORKS_ON, EMPLOYEE\\n    WHERE Essn = Ssn AND Lname = ‘Smith’ );\\nIf a nested query returns a single attribute and a single tuple, the query result will be \\na single (scalar) value. In such cases, it is permissible to use = instead of IN for the \\ncomparison operator. In general, the nested query will return a table (relation), \\nwhich is a set or multiset of tuples.\\nSQL allows the use of tuples of values in comparisons by placing them within \\nparentheses. To illustrate this, consider the following query:\\nSELECT DISTINCT Essn\\nFROM WORKS_ON\\nWHERE ( Pno, Hours) IN ( SELECT Pno, Hours\\n    FROM WORKS_ON\\n    WHERE Essn = ‘123456789’ );\\nThis query will select the Essns of all employees who work the same (project, hours) \\ncombination on some project that employee ‘John Smith’ (whose Ssn = ‘123456789’) \\nworks on. In this example, the IN operator compares the subtuple of values in paren-\\ntheses (Pno, Hours) within each tuple in WORKS_ON with the set of type-compatible \\ntuples produced by the nested query.\\nIn addition to the IN operator, a number of other comparison operators can be used \\nto compare a single value v (typically an attribute name) to a set or multiset v (typi-\\ncally a nested query). The = ANY (or = SOME) operator returns TRUE if the value v \\nis equal to some value in the set V and is hence equivalent to IN. The two keywords \\nANY and SOME have the same effect. Other operators that can be combined with \\nANY (or SOME) include >, >=, <, <=, and <>. The keyword ALL can also be com-\\nbined with each of these operators. For example, the comparison condition (v > ALL V) \\nreturns TRUE if the value v is greater than all the values in the set (or multiset) V.  \\nAn example is the following query, which returns the names of employees whose \\nsalary is greater than the salary of all the employees in department 5:\\nSELECT Lname, Fname\\nFROM EMPLOYEE\\nWHERE Salary > ALL ( SELECT Salary\\n    FROM EMPLOYEE\\n    WHERE Dno = 5 );'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 224, 'page_label': '225'}, page_content='7.1 More Complex SQL Retrieval Queries  211\\nNotice that this query can also be specified using the MAX aggregate function (see \\nSection 7.1.7).\\nIn general, we can have several levels of nested queries. We can once again be faced \\nwith possible ambiguity among attribute names if attributes of the same name \\nexist—one in a relation in the \\nFROM clause of the outer query, and another in a rela-\\ntion in the FROM clause of the nested query.  The rule is that a reference to an \\nunqualified attribute refers to the relation declared in the innermost nested query. \\nFor example, in the SELECT clause and WHERE clause of the first nested query of \\nQ4A, a reference to any unqualified attribute of the PROJECT relation refers to the \\nPROJECT relation specified in the FROM clause of the nested query. To refer to an \\nattribute of the PROJECT relation specified in the outer query, we specify and refer \\nto an alias (tuple variable) for that relation. These rules are similar to scope rules for \\nprogram variables in most programming languages that allow nested procedures \\nand functions. To illustrate the potential ambiguity of attribute names in nested \\nqueries, consider Query 16.\\nQuery 16. Retrieve the name of each employee who has a dependent with the \\nsame first name and is the same sex as the employee.\\nQ16: SELECT E.Fname, E.Lname\\n FROM EMPLOYEE AS E\\n WHERE E.Ssn IN ( SELECT D.Essn\\n     FROM DEPENDENT AS D\\n     WHERE E.Fname = D.Dependent_name\\n    AND E.Sex = D.Sex );\\nIn the nested query of Q16, we must qualify E.Sex because it refers to the Sex attri-\\nbute of EMPLOYEE from the outer query, and DEPENDENT also has an attribute \\ncalled Sex. If there were any unqualified references to Sex in the nested query, they \\nwould refer to the Sex attribute of DEPENDENT. However, we would not have to \\nqualify the attributes Fname and Ssn of EMPLOYEE if they appeared in the nested \\nquery because the DEPENDENT relation does not have attributes called Fname and \\nSsn, so there is no ambiguity.\\nIt is generally advisable to create tuple variables (aliases) for all the tables referenced \\nin an SQL query to avoid potential errors and ambiguities, as illustrated in Q16.\\n7.1.3 Correlated Nested Queries\\nWhenever a condition in the WHERE clause of a nested query references some attri-\\nbute of a relation declared in the outer query, the two queries are said to be correlated. \\nWe can understand a correlated query better by considering that the nested query is \\nevaluated once for each tuple (or combination of tuples) in the outer query.  For \\nexample, we can think of Q16 as follows: For each EMPLOYEE tuple, evaluate the \\nnested query, which retrieves the Essn values for all DEPENDENT tuples with the \\nsame sex and name as that EMPLOYEE tuple; if the Ssn value of the EMPLOYEE tuple \\nis in the result of the nested query, then select that EMPLOYEE tuple.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 225, 'page_label': '226'}, page_content='212 Chapter 7 More SQL: Complex Queries, Triggers, Views, and Schema Modification\\nIn general, a query written with nested select-from-where blocks and using the = or \\nIN comparison operators can always be expressed as a single block query. For exam-\\nple, Q16 may be written as in Q16A:\\nQ16A: SELECT E.Fname, E.Lname\\n FROM EMPLOYEE AS E, DEPENDENT AS D\\n WHERE E.Ssn = D.Essn AND E.Sex = D.Sex\\n  AND E.Fname = D.Dependent_name;\\n7.1.4 The EXISTS and UNIQUE Functions in SQL\\nEXISTS and UNIQUE are Boolean functions that return TRUE or FALSE; hence, \\nthey can be used in a WHERE clause condition. The \\nEXISTS function in SQL is used \\nto check whether the result of a nested query is empty (contains no tuples) or not. \\nThe result of EXISTS is a Boolean value TRUE if the nested query result contains at \\nleast one tuple, or FALSE if the nested query result contains no tuples. We illustrate \\nthe use of EXISTS—and NOT EXISTS —with some examples. First, we formulate \\nQuery 16 in an alternative form that uses EXISTS as in Q16B:\\nQ16B: SELECT E.Fname, E.Lname\\n FROM EMPLOYEE AS E \\n WHERE EXISTS ( SELECT *\\n     FROM DEPENDENT AS D\\n     WHERE E.Ssn = D.Essn AND E.Sex = D.Sex\\n    AND E.Fname = D.Dependent_name);\\nEXISTS and NOT EXISTS are typically used in conjunction with a correlated nested \\nquery. In Q16B, the nested query references the Ssn, Fname, and Sex attributes of \\nthe EMPLOYEE relation from the outer query. We can think of Q16B as follows: For \\neach EMPLOYEE tuple, evaluate the nested query, which retrieves all DEPENDENT \\ntuples with the same Essn, Sex, and Dependent_name as the EMPLOYEE tuple; if at \\nleast one tuple EXISTS in the result of the nested query, then select that EMPLOYEE \\ntuple. EXISTS(Q) returns TRUE if there is at least one tuple in the result of the nested \\nquery Q, and returns FALSE otherwise. On the other hand, NOT EXISTS(Q) returns \\nTRUE if there are no tuples in the result of nested query Q, and returns FALSE other-\\nwise. Next, we illustrate the use of NOT EXISTS.\\nQuery 6. Retrieve the names of employees who have no dependents.\\nQ6: SELECT Fname, Lname\\n FROM EMPLOYEE\\n WHERE  NOT EXISTS ( SELECT *\\n     FROM DEPENDENT\\n     WHERE Ssn = Essn );\\nIn Q6, the correlated nested query retrieves all DEPENDENT  tuples related to a \\nparticular EMPLOYEE tuple. If none exist, the EMPLOYEE tuple is selected because \\nthe WHERE-clause condition will evaluate to TRUE in this case. We can explain \\nQ6 as follows: For each EMPLOYEE tuple, the correlated nested query selects all'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 226, 'page_label': '227'}, page_content='7.1 More Complex SQL Retrieval Queries  213\\nDEPENDENT tuples whose Essn value matches the EMPLOYEE Ssn ; if the result is \\nempty, no dependents are related to the employee, so we select that EMPLOYEE \\ntuple and retrieve its Fname and Lname.\\nQuery 7. List the names of managers who have at least one dependent.\\nQ7: SELECT Fname, Lname\\n FROM EMPLOYEE\\n WHERE EXISTS ( SELECT *\\n     FROM DEPENDENT\\n     WHERE Ssn = Essn )\\n  AND\\n  EXISTS ( SELECT *\\n     FROM DEPARTMENT\\n     WHERE Ssn = Mgr_ssn );\\nOne way to write this query is shown in Q7, where we specify two nested cor-\\nrelated queries; the first selects all DEPENDENT  tuples related to an EMPLOYEE , \\nand the second selects all DEPARTMENT  tuples managed by the EMPLOYEE . If at \\nleast one of the first and at least one of the second exists, we select the EMPLOYEE  \\ntuple. Can you rewrite this query using only a single nested query or no nested \\nqueries?\\nThe query \\nQ3: Retrieve the name of each employee who works on all the projects con-\\ntrolled by department number 5  can be written using EXISTS and NOT EXISTS  in \\nSQL systems. We show two ways of specifying this query Q3 in SQL as Q3A and \\nQ3B. This is an example of certain types of queries that require universal quantifica-\\ntion, as we will discuss in Section 8.6.7. One way to write this query is to use the \\nconstruct ( S2 EXCEPT S1) as explained next, and checking whether the result is \\nempty.1 This option is shown as Q3A.\\nQ3A: SELECT Fname, Lname\\n FROM EMPLOYEE\\n WHERE NOT EXISTS ( ( SELECT   Pnumber\\n        FROM   PROJECT\\n        WHERE   Dnum = 5)\\n        EXCEPT ( SELECT Pno\\n      FROM WORKS_ON\\n      WHERE Ssn = Essn) );\\nIn Q3A, the first subquery (which is not correlated with the outer query) selects all \\nprojects controlled by department 5, and the second subquery (which is corre-\\nlated) selects all projects that the particular employee being considered works on. \\nIf the set difference of the first subquery result \\nMINUS (EXCEPT) the second sub-\\nquery result is empty, it means that the employee works on all the projects and is \\ntherefore selected.\\n1Recall that EXCEPT is the set difference operator. The keyword MINUS is also sometimes used, for \\nexample, in Oracle.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 227, 'page_label': '228'}, page_content='214 Chapter 7 More SQL: Complex Queries, Triggers, Views, and Schema Modification\\nThe second option is shown as Q3B. Notice that we need two-level nesting in Q3B \\nand that this formulation is quite a bit more complex than Q3A.\\nQ3B: SELECT Lname, Fname\\n FROM EMPLOYEE\\n WHERE NOT EXISTS ( SELECT   *\\n     FROM   WORKS_ON B\\n     WHERE ( B.Pno IN ( SELECT  Pnumber\\n       FROM PROJECT\\n       WHERE Dnum = 5 )\\n     AND\\n     NOT EXISTS  ( SELECT *\\n       FROM WORKS_ON C\\n       WHERE C.Essn = Ssn\\n       AND C.Pno = B.Pno )));\\nIn Q3B, the outer nested query selects any WORKS_ON (B) tuples whose Pno is of a \\nproject controlled by department 5, if there is not a WORKS_ON (C) tuple with the \\nsame Pno and the same Ssn as that of the EMPLOYEE tuple under consideration in \\nthe outer query. If no such tuple exists, we select the EMPLOYEE tuple. The form of \\nQ3B matches the following rephrasing of Query 3: Select each employee such that \\nthere does not exist a project controlled by department 5 that the employee does \\nnot work on. It corresponds to the way we will write this query in tuple relation \\ncalculus (see Section 8.6.7).\\nThere is another SQL function, UNIQUE(Q), which returns TRUE if there are no \\nduplicate tuples in the result of query Q; otherwise, it returns FALSE. This can be \\nused to test whether the result of a nested query is a set (no duplicates) or a multiset \\n(duplicates exist).\\n7.1.5 Explicit Sets and Renaming in SQL\\nWe have seen several queries with a nested query in the WHERE clause. It is also \\npossible to use an explicit set of values  in the WHERE clause, rather than a nested \\nquery. Such a set is enclosed in parentheses in SQL.\\nQuery 17. Retrieve the Social Security numbers of all employees who work on \\nproject numbers 1, 2, or 3.\\nQ17: SELECT DISTINCT Essn\\n FROM WORKS_ON\\n WHERE Pno IN (1, 2, 3);\\nIn SQL, it is possible to rename any attribute that appears in the result of a query \\nby adding the qualifier AS followed by the desired new name. Hence, the AS con-\\nstruct can be used to alias both attribute and relation names in general, and it can \\nbe used in appropriate parts of a query. For example, \\nQ8A shows how query Q8 \\nfrom Section 4.3.2 can be slightly changed to retrieve the last name of each \\nemployee and his or her supervisor while renaming the resulting attribute names'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 228, 'page_label': '229'}, page_content='7.1 More Complex SQL Retrieval Queries  215\\nas Employee_name  and Supervisor_name . The new names will appear as column \\nheaders for the query result.\\nQ8A: SELECT E.Lname AS Employee_name, S.Lname AS Supervisor_name\\n FROM EMPLOYEE AS E, EMPLOYEE AS S\\n WHERE E.Super_ssn = S.Ssn;\\n7.1.6 Joined Tables in SQL and Outer Joins\\nThe concept of a joined table (or joined relation) was incorporated into SQL to \\npermit users to specify a table resulting from a join operation in the FROM clause of \\na query. This construct may be easier to comprehend than mixing together all the \\nselect and join conditions in the \\nWHERE clause. For example, consider query Q1, \\nwhich retrieves the name and address of every employee who works for the \\n‘Research’ department. It may be easier to specify the join of the \\nEMPLOYEE and \\nDEPARTMENT relations in the WHERE clause, and then to select the desired tuples \\nand attributes. This can be written in SQL as in Q1A:\\nQ1A: SELECT Fname, Lname, Address\\n FROM (EMPLOYEE JOIN DEPARTMENT ON Dno = Dnumber)\\n WHERE Dname = ‘Research’;\\nThe FROM clause in Q1A contains a single joined table. The attributes of such a table \\nare all the attributes of the first table, EMPLOYEE, followed by all the attributes of \\nthe second table, DEPARTMENT. The concept of a joined table also allows the user to \\nspecify different types of join, such as NATURAL JOIN and various types of OUTER \\nJOIN. In a NATURAL JOIN on two relations R and S, no join condition is specified; an \\nimplicit EQUIJOIN condition for each pair of attributes with the same name  from R \\nand S is created. Each such pair of attributes is included only once in the resulting \\nrelation (see Sections 8.3.2 and 8.4.4 for more details on the various types of join \\noperations in relational algebra).\\nIf the names of the join attributes are not the same in the base relations, it is possible \\nto rename the attributes so that they match, and then to apply NATURAL JOIN. In \\nthis case, the AS construct can be used to rename a relation and all its attributes in \\nthe FROM clause. This is illustrated in Q1B, where the DEPARTMENT relation is \\nrenamed as DEPT and its attributes are renamed as Dname, Dno (to match the name \\nof the desired join attribute Dno in the EMPLOYEE table), Mssn, and Msdate. The \\nimplied join condition for this NATURAL JOIN  is EMPLOYEE.Dno  = DEPT.Dno , \\nbecause this is the only pair of attributes with the same name after renaming:\\nQ1B: SELECT Fname, Lname, Address\\n FROM (EMPLOYEE NATURAL JOIN\\n  (DEPARTMENT AS DEPT (Dname, Dno, Mssn, Msdate)))\\n WHERE Dname = ‘Research’;\\nThe default type of join in a joined table is called an inner join, where a tuple is \\nincluded in the result only if a matching tuple exists in the other relation. For exam-\\nple, in query Q8A, only employees who have a supervisor are included in the result;'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 229, 'page_label': '230'}, page_content='216 Chapter 7 More SQL: Complex Queries, Triggers, Views, and Schema Modification\\nan EMPLOYEE tuple whose value for Super_ssn  is NULL is excluded. If the user \\nrequires that all employees be included, a different type of join called OUTER JOIN \\nmust be used explicitly (see Section 8.4.4 for the definition of OUTER JOIN in rela-\\ntional algebra). There are several variations of OUTER JOIN, as we shall see. In the \\nSQL standard, this is handled by explicitly specifying the keyword OUTER JOIN in a \\njoined table, as illustrated in Q8B:\\nQ8B: SELECT E.Lname AS Employee_name,\\n  S.Lname AS Supervisor_name\\n FROM (EMPLOYEE AS E LEFT OUTER JOIN EMPLOYEE AS S\\n  ON E.Super_ssn = S.Ssn);\\nIn SQL, the options available for specifying joined tables include INNER JOIN (only \\npairs of tuples that match the join condition are retrieved, same as JOIN), LEFT \\nOUTER JOIN (every tuple in the left table must appear in the result; if it does not have \\na matching tuple, it is padded with NULL values for the attributes of the right table), \\nRIGHT OUTER JOIN (every tuple in the right table must appear in the result; if it does \\nnot have a matching tuple, it is padded with NULL values for the attributes of the left \\ntable), and FULL OUTER JOIN. In the latter three options, the keyword OUTER may be \\nomitted. If the join attributes have the same name, one can also specify the natural \\njoin variation of outer joins by using the keyword NATURAL before the operation (for \\nexample, NATURAL LEFT OUTER JOIN). The keyword CROSS JOIN is used to specify \\nthe CARTESIAN PRODUCT  operation (see Section 8.2.2), although this should be \\nused only with the utmost care because it generates all possible tuple combinations.\\nIt is also possible to nest join specifications; that is, one of the tables in a join may \\nitself be a joined table. This allows the specification of the join of three or more tables \\nas a single joined table, which is called a multiway join. For example, \\nQ2A is a differ-\\nent way of specifying query Q2 from Section 6.3.1 using the concept of a joined table:\\nQ2A: SELECT Pnumber, Dnum, Lname, Address, Bdate\\n FROM ( (PROJECT JOIN DEPARTMENT ON Dnum = Dnumber)\\n  JOIN EMPLOYEE ON Mgr_ssn = Ssn)\\n WHERE Plocation = ‘Stafford’;\\nNot all SQL implementations have implemented the new syntax of joined tables. In \\nsome systems, a different syntax was used to specify outer joins by using the compari-\\nson operators + =, = +, and + = + for left, right, and full outer join, respectively, when \\nspecifying the join condition. For example, this syntax is available in Oracle. To specify \\nthe left outer join in \\nQ8B using this syntax, we could write the query Q8C as follows:\\nQ8C: SELECT E.Lname, S.Lname\\n FROM EMPLOYEE E, EMPLOYEE S\\n WHERE E.Super_ssn + = S.Ssn;\\n7.1.7 Aggregate Functions in SQL\\nAggregate functions  are used to summarize information from multiple tuples \\ninto a single-tuple summary. Grouping  is used to create subgroups of tuples \\nbefore summarization. Grouping and aggregation are required in many database'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 230, 'page_label': '231'}, page_content='7.1 More Complex SQL Retrieval Queries  217\\napplications, and we will introduce their use in SQL through examples. A number \\nof built-in aggregate functions exist: COUNT, SUM, MAX, MIN, and AVG.2 The \\nCOUNT function returns the number of tuples or values  as specified in a query. \\nThe functions SUM, MAX, MIN, and AVG can be applied to a set or multiset of \\nnumeric values and return, respectively, the sum, maximum value, minimum \\nvalue, and average (mean) of those values. These functions can be used in the \\nSELECT clause or in a HAVING clause (which we introduce later). The functions \\nMAX and MIN can also be used with attributes that have nonnumeric domains if \\nthe domain values have a total ordering among one another.3 We illustrate the use \\nof these functions with several queries.\\nQuery 19. Find the sum of the salaries of all employees, the maximum salary, \\nthe minimum salary, and the average salary.\\nQ19: SELECT SUM (Salary), MAX (Salary), MIN (Salary), AVG (Salary)\\n FROM EMPLOYEE;\\nThis query returns a single-row summary of all the rows in the EMPLOYEE table. \\nWe could use AS to rename the column names in the resulting single-row table; for \\nexample, as in Q19A.\\nQ19A: SELECT SUM (Salary) AS Total_Sal, MAX (Salary) AS Highest_Sal,\\n  MIN (Salary) AS Lowest_Sal, AVG (Salary) AS Average_Sal\\n FROM EMPLOYEE;\\nIf we want to get the preceding aggregate function values for employees of a specific \\ndepartment—say, the ‘Research’ department—we can write Query 20, where the \\nEMPLOYEE tuples are restricted by the WHERE clause to those employees who work \\nfor the ‘Research’ department.\\nQuery 20. Find the sum of the salaries of all employees of the ‘Research’ depart-\\nment, as well as the maximum salary, the minimum salary, and the average \\nsalary in this department.\\nQ20: SELECT SUM (Salary), MAX (Salary), MIN (Salary), AVG (Salary)\\n FROM (EMPLOYEE JOIN DEPARTMENT ON Dno = Dnumber)\\n WHERE Dname = ‘Research’;\\nQueries 21 and 22.  Retrieve the total number of employees in the company \\n(Q21) and the number of employees in the ‘Research’ department (Q22).\\nQ21: SELECT COUNT (*)\\n FROM EMPLOYEE;\\nQ22: SELECT COUNT (*)\\n FROM EMPLOYEE, DEPARTMENT\\n WHERE DNO = DNUMBER AND DNAME = ‘Research’;\\n2Additional aggregate functions for more advanced statistical calculation were added in SQL-99.\\n3Total order means that for any two values in the domain, it can be determined that one appears before \\nthe other in the defined order; for example, DATE, TIME, and TIMESTAMP domains have total orderings \\non their values, as do alphabetic strings.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 231, 'page_label': '232'}, page_content='218 Chapter 7 More SQL: Complex Queries, Triggers, Views, and Schema Modification\\nHere the asterisk (*) refers to the rows (tuples), so COUNT (*) returns the number of \\nrows in the result of the query. We may also use the COUNT function to count val-\\nues in a column rather than tuples, as in the next example.\\nQuery 23. Count the number of distinct salary values in the database.\\nQ23: SELECT COUNT (DISTINCT Salary)\\n FROM EMPLOYEE;\\nIf we write COUNT(SALARY) instead of COUNT(DISTINCT SALARY ) in Q23, then \\nduplicate values will not be eliminated. However, any tuples with NULL for SALARY \\nwill not be counted. In general, NULL values are discarded when aggregate func-\\ntions are applied to a particular column (attribute); the only exception is for \\nCOUNT(*) because tuples instead of values are counted. In the previous examples, \\nany Salary values that are NULL are not included in the aggregate function calcula-\\ntion. The general rule is as follows: when an aggregate function is applied to a col-\\nlection of values, NULLs are removed from the collection before the calculation; if \\nthe collection becomes empty because all values are NULL, the aggregate function \\nwill return NULL (except in the case of COUNT, where it will return 0 for an empty \\ncollection of values).\\nThe preceding examples summarize a whole relation (\\nQ19, Q21, Q23) or a selected \\nsubset of tuples ( Q20, Q22), and hence all produce a table with a single row or a \\nsingle value. They illustrate how functions are applied to retrieve a summary value \\nor summary tuple from a table. These functions can also be used in selection condi-\\ntions involving nested queries. We can specify a correlated nested query with an \\naggregate function, and then use the nested query in the WHERE clause of an outer \\nquery. For example, to retrieve the names of all employees who have two or more \\ndependents (Query 5), we can write the following:\\nQ5: SELECT Lname, Fname \\n FROM EMPLOYEE\\n WHERE ( SELECT COUNT (*)\\n    FROM  DEPENDENT\\n    WHERE Ssn = Essn ) > =  2;\\nThe correlated nested query counts the number of dependents that each employee \\nhas; if this is greater than or equal to two, the employee tuple is selected.\\nSQL also has aggregate functions SOME and ALL that can be applied to a col-\\nlection of Boolean values; SOME returns TRUE if at least one element in the \\ncollection is TRUE, whereas ALL returns TRUE if all elements in the collection \\nare TRUE.\\n7.1.8 Grouping: The GROUP BY and HAVING Clauses\\nIn many cases we want to apply the aggregate functions to subgroups of tuples in a \\nrelation, where the subgroups are based on some attribute values. For example, we \\nmay want to find the average salary of employees in each department or the number'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 232, 'page_label': '233'}, page_content='7.1 More Complex SQL Retrieval Queries  219\\nof employees who work on each project. In these cases we need to partition the rela-\\ntion into nonoverlapping subsets (or groups) of tuples. Each group (partition) will \\nconsist of the tuples that have the same value of some attribute(s), called the  \\ngrouping attribute(s). We can then apply the function to each such group indepen-\\ndently to produce summary information about each group. SQL has a \\nGROUP BY \\nclause for this purpose. The GROUP BY  clause specifies the grouping attributes, \\nwhich should also appear in the  SELECT clause, so that the value resulting from \\napplying each aggregate function to a group of tuples appears along with the value \\nof the grouping attribute(s).\\nQuery 24. For each department, retrieve the department number, the number \\nof employees in the department, and their average salary.\\nQ24: SELECT Dno, COUNT (*), AVG (Salary)\\n FROM EMPLOYEE\\n GROUP BY Dno;\\nIn Q24, the EMPLOYEE  tuples are partitioned into groups—each group having \\nthe same value for the GROUP BY attribute Dno. Hence, each group contains the \\nemployees who work in the same department. The COUNT and AVG functions \\nare applied to each such group of tuples. Notice that the SELECT clause includes \\nonly the grouping attribute and the aggregate functions to be applied on each \\ngroup of tuples. Figure 7.1(a) illustrates how grouping works and shows the \\nresult of Q24.\\nIf NULLs exist in the grouping attribute, then a separate group  is created for all \\ntuples with a NULL value in the grouping attribute.  For example, if the EMPLOYEE \\ntable had some tuples that had NULL for the grouping attribute Dno, there would be \\na separate group for those tuples in the result of Q24.\\nQuery 25. For each project, retrieve the project number, the project name, and \\nthe number of employees who work on that project.\\nQ25: SELECT Pnumber, Pname, COUNT (*)\\n FROM PROJECT, WORKS_ON\\n WHERE Pnumber = Pno\\n GROUP BY Pnumber, Pname;\\nQ25 shows how we can use a join condition in conjunction with GROUP BY. In this \\ncase, the grouping and functions are applied after the joining of the two relations in \\nthe WHERE clause.\\nSometimes we want to retrieve the values of these functions only for groups that \\nsatisfy certain conditions. For example, suppose that we want to modify Query 25 so \\nthat only projects with more than two employees appear in the result. SQL provides \\na HAVING clause, which can appear in conjunction with a GROUP BY clause, for this \\npurpose. HAVING provides a condition on the summary information regarding the \\ngroup of tuples associated with each value of the grouping attributes. Only the \\ngroups that satisfy the condition are retrieved in the result of the query. This is illus-\\ntrated by Query 26.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 233, 'page_label': '234'}, page_content='220 Chapter 7 More SQL: Complex Queries, Triggers, Views, and Schema Modification\\nDno\\n5\\n4\\n1\\n4\\n3\\n1\\n33250\\n31000\\n55000\\nCount (*) Avg (Salary)\\nResult of Q24\\nPname\\nProductY\\nComputerization\\nReorganization\\nNewbenefits\\n3\\n3\\n3\\n3\\nCount (*)\\nResult of Q26\\nThese groups are not selected by \\nthe HAVING condition of Q26.\\nGrouping EMPLOYEE tuples by the value of Dno\\nAfter applying the WHERE clause but before applying HAVING \\nAfter applying the HAVING clause condition\\nFname\\nJohn\\nFranklin\\nRamesh K\\nJennifer\\nAlicia\\nJoyce A\\nAhmad\\nJames\\nV\\nE\\nT\\nB\\nJ\\nS\\nNarayan\\nEnglish\\nJabbar\\nBong\\nSmith\\nWong\\nZelaya\\nWallace\\n666884444\\n453453453\\n987987987\\n888665555\\n123456789\\n333445555\\n999887777\\n987654321\\nMinit Lname\\n5\\n5\\n4\\n1\\n5\\n5\\n4\\n4\\nDno\\n333445555\\n333445555\\n987654321\\nNULL\\n333445555\\n888665555\\n987654321\\n888665555\\nSuper_ssn\\n38000\\n25000\\n25000\\n55000\\n30000\\n40000\\n25000\\n43000\\nSalary\\n. . .\\nPname\\nProductX\\nProductX\\nProductY\\nProductZ\\nProductY\\nProductY\\nProductZ\\nComputerization\\nComputerization\\nComputerization\\nReorganization\\nNewbenefits\\nReorganization\\nReorganization\\nNewbenefits\\nNewbenefits\\n123456789\\n453453453\\n123456789\\n666884444\\n333445555\\n453453453\\n333445555\\n333445555\\n999887777\\n987987987\\n333445555\\n987987987\\n888665555\\n987654321\\n987654321\\n999887777\\n1\\n1\\n2\\n2\\n2\\n3\\n3\\n10\\n10\\n10\\n20\\n20\\n20\\n30\\n30\\n30\\n1\\n1\\n2\\n2\\n2\\n3\\n3\\n10\\n10\\n10\\n20\\n20\\n20\\n30\\n30\\n30\\n32.5\\n20.0\\n  7 .5\\n20.0\\n10.0\\n40.0\\n10.0\\n10.0\\n10.0\\n35.0\\n10.0\\n15.0\\nNULL\\n5.0\\n20.0\\n30.0\\nPnumber Hours\\n. . .\\nPname\\nProductY\\nProductY\\nProductY\\nComputerization\\nComputerization\\nComputerization\\nReorganization\\nReorganization\\nReorganization\\nNewbenefits\\nNewbenefits\\nNewbenefits\\n123456789\\n453453453\\n333445555\\n987987987\\n999887777\\n333445555\\n333445555\\n987654321\\n888665555\\n987987987\\n987654321\\n999887777\\n2\\n2\\n2\\n10\\n10\\n10\\n20\\n20\\n20\\n30\\n30\\n30\\n2\\n2\\n2\\n10\\n10\\n10\\n20\\n20\\n20\\n30\\n30\\n30\\n7. 5\\n20.0\\n  10.0\\n10.0\\n10.0\\n35.0\\n10.0\\n15.0\\nNULL\\n5.0\\n20.0\\n30.0\\nPnumber Essn Pno Hours\\n. . .\\n(Pnumber not shown)\\nSsn . . .(a)\\n(b) PnoEssn. . .\\n. . .\\nFigure 7.1 \\nResults of GROUP BY and HAVING. (a) Q24. (b) Q26.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 234, 'page_label': '235'}, page_content='7.1 More Complex SQL Retrieval Queries  221\\nQuery 26. For each project on which more than two employees work, retrieve the \\nproject number, the project name, and the number of employees who work on \\nthe project.\\nQ26: SELECT Pnumber, Pname, COUNT (*)\\n FROM PROJECT, WORKS_ON\\n WHERE Pnumber = Pno\\n GROUP BY Pnumber, Pname\\n HAVING COUNT (*) > 2;\\nNotice that although selection conditions in the WHERE clause limit the tuples to \\nwhich functions are applied, the HAVING clause serves to choose whole groups. Fig-\\nure 7.1(b) illustrates the use of HAVING and displays the result of Q26.\\nQuery 27. For each project, retrieve the project number, the project name, and \\nthe number of employees from department 5 who work on the project.\\nQ27: SELECT Pnumber, Pname, COUNT (*)\\n FROM PROJECT, WORKS_ON, EMPLOYEE\\n WHERE Pnumber = Pno AND Ssn = Essn AND Dno = 5\\n GROUP BY Pnumber, Pname;\\nIn Q27, we restrict the tuples in the relation (and hence the tuples in each group) \\nto those that satisfy the condition specified in the \\nWHERE clause—namely, that \\nthey work in department number 5. Notice that we must be extra careful when \\ntwo different conditions apply (one to the aggregate function in the SELECT  \\nclause and another to the function in the HAVING clause). For example, suppose \\nthat we want to count the total  number of employees whose salaries exceed \\n$40,000 in each department, but only for departments where more than five \\nemployees work. Here, the condition ( SALARY  > 40000) applies only to the \\nCOUNT  function in the SELECT  clause. Suppose that we write the following \\nincorrect  query:\\nSELECT Dno, COUNT (*)\\nFROM EMPLOYEE\\nWHERE Salary>40000\\nGROUP BY Dno\\nHAVING COUNT (*) > 5;\\nThis is incorrect because it will select only departments that have more than five \\nemployees who each earn more than $40,000.  The rule is that the WHERE clause is \\nexecuted first, to select individual tuples or joined tuples; the HAVING clause is \\napplied later, to select individual groups of tuples. In the incorrect query, the tuples \\nare already restricted to employees who earn more than $40,000 before the function \\nin the HAVING clause is applied. One way to write this query correctly is to use a \\nnested query, as shown in Query 28.\\nQuery 28. For each department that has more than five employees, retrieve the \\ndepartment number and the number of its employees who are making more \\nthan $40,000.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 235, 'page_label': '236'}, page_content='222 Chapter 7 More SQL: Complex Queries, Triggers, Views, and Schema Modification\\nQ28: SELECT Dno, COUNT (*)\\n FROM EMPLOYEE\\n WHERE Salary>40000 AND Dno IN\\n  ( SELECT Dno\\n    FROM EMPLOYEE\\n GROUP BY Dno\\n    HAVING COUNT (*) > 5)\\n GROUP BY Dno;\\n7.1.9 Other SQL Constructs: WITH and CASE\\nIn this section, we illustrate two additional SQL constructs. The WITH clause \\nallows a user to define a table that will only be used in a particular query; it is some-\\nwhat similar to creating a view (see Section 7.3) that will be used only in one query \\nand then dropped. This construct was introduced as a convenience in SQL:99 and \\nmay not be available in all SQL based DBMSs. Queries using WITH can generally \\nbe written using other SQL constructs. For example, we can rewrite Q28 as Q28′:\\nQ28′: WITH   BIGDEPTS (Dno) AS\\n  ( SELECT   Dno\\n    FROM   EMPLOYEE\\n    GROUP BY   Dno\\n    HAVING   COUNT (*) > 5)\\n SELECT   Dno, COUNT (*)\\n FROM   EMPLOYEE\\n WHERE   Salary>40000 AND Dno IN BIGDEPTS\\n GROUP BY   Dno;\\nIn Q28 ′, we defined in the WITH clause a temporary table BIG_DEPTS whose \\nresult holds the Dno’s of departments with more than five employees, then used \\nthis table in the subsequent query. Once this query is executed, the temporary table \\nBIGDEPTS is discarded.\\nSQL also has a CASE construct, which can be used when a value can be different \\nbased on certain conditions. This can be used in any part of an SQL query where a \\nvalue is expected, including when querying, inserting or updating tuples. We illus-\\ntrate this with an example. Suppose we want to give employees different raise \\namounts depending on which department they work for; for example, employees in \\ndepartment 5 get a $2,000 raise, those in department 4 get $1,500 and those in \\ndepartment 1 get $3,000 (see Figure 5.6 for the employee tuples). Then we could \\nre-write the update operation U6 from Section 6.4.3 as U6′:\\nU6′: UPDATE EMPLOYEE\\n SET Salary  = \\n CASE WHEN Dno = 5 THEN Salary + 2000\\n  WHEN Dno = 4 THEN Salary + 1500\\n  WHEN Dno = 1 THEN Salary + 3000\\n  ELSE Salary + 0 ;'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 236, 'page_label': '237'}, page_content='7.1 More Complex SQL Retrieval Queries  223\\nIn U6′, the salary raise value is determined through the CASE construct based on \\nthe department number for which each employee works. The CASE construct can \\nalso be used when inserting tuples that can have different attributes being NULL \\ndepending on the type of record being inserted into a table, as when a specialization \\n(see Chapter 4) is mapped into a single table (see Chapter 9) or when a union type \\nis mapped into relations.\\n7.1.10 Recursive Queries in SQL\\nIn this section, we illustrate how to write a recursive query in SQL. This syntax was \\nadded in SQL:99 to allow users the capability to specify a recursive query in a \\ndeclarative manner. An example of a recursive relationship between tuples of the \\nsame type is the relationship between an employee and a supervisor. This relation-\\nship is described by the foreign key \\nSuper_ssn of the EMPLOYEE relation in Fig- \\nures 5.5 and 5.6, and it relates each employee tuple (in the role of supervisee) to \\nanother employee tuple (in the role of supervisor). An example of a recursive oper-\\nation is to retrieve all supervisees of a supervisory employee e at all levels—that is, \\nall employees e′ directly supervised by e, all employees e′ directly supervised by each \\nemployee e′, all employees e″′ directly supervised by each employee e″, and so on. \\nIn SQL:99, this query can be written as follows:\\nQ29:   WITH RECURSIVE SUP_EMP (SupSsn, EmpSsn) AS\\n    ( SELECT SupervisorSsn, Ssn\\n      FROM EMPLOYEE\\n      UNION\\n      SELECT E.Ssn, S.SupSsn\\n      FROM EMPLOYEE AS E, SUP_EMP AS S\\n      WHERE E.SupervisorSsn = S.EmpSsn)\\n   SELECT*\\n   FROM SUP_EMP;\\nIn Q29, we are defining a view SUP_EMP that will hold the result of the recursive \\nquery. The view is initially empty. It is first loaded with the first level (supervisor, \\nsupervisee) Ssn combinations via the first part (SELECT SupervisorSss, Ssn FROM \\nEMPLOYEE), which is called the base query. This will be combined via UNION \\nwith each successive level of supervisees through the second part, where the view \\ncontents are joined again with the base values to get the second level combinations, \\nwhich are UNIONed with the first level. This is repeated with successive levels until \\na fixed point is reached, where no more tuples are added to the view. At this point, \\nthe result of the recursive query is in the view SUP_EMP.\\n7.1.11 Discussion and Summary of SQL Queries\\nA retrieval query in SQL can consist of up to six clauses, but only the first two—\\nSELECT  and FROM—are mandatory. The query can span several lines, and is \\nended by a semicolon. Query terms are separated by spaces, and parentheses can \\nbe used to group relevant parts of a query in the standard way. The clauses are'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 237, 'page_label': '238'}, page_content='224 Chapter 7 More SQL: Complex Queries, Triggers, Views, and Schema Modification\\nspecified in the following order, with the clauses between square brackets [ … ] \\nbeing optional:\\nSELECT <attribute and function list>\\nFROM <table list>\\n[ WHERE <condition> ]\\n[ GROUP BY <grouping attribute(s)> ]\\n[ HAVING <group condition> ]\\n[ ORDER BY <attribute list> ];\\nThe SELECT clause lists the attributes or functions to be retrieved. The FROM clause \\nspecifies all relations (tables) needed in the query, including joined relations, but \\nnot those in nested queries. The \\nWHERE clause specifies the conditions for selecting \\nthe tuples from these relations, including join conditions if needed. GROUP BY  \\nspecifies grouping attributes, whereas HAVING specifies a condition on the groups \\nbeing selected rather than on the individual tuples. The built-in aggregate functions \\nCOUNT, SUM, MIN, MAX, and AVG are used in conjunction with grouping, but they \\ncan also be applied to all the selected tuples in a query without a GROUP BY clause. \\nFinally, ORDER BY specifies an order for displaying the result of a query.\\nIn order to formulate queries correctly, it is useful to consider the steps that define \\nthe meaning or semantics of each query. A query is evaluated conceptually4 by first \\napplying the FROM clause (to identify all tables involved in the query or to materialize \\nany joined tables), followed by the WHERE clause to select and join tuples, and then by \\nGROUP BY and HAVING. Conceptually, ORDER BY is applied at the end to sort the query \\nresult. If none of the last three clauses (GROUP BY, HAVING, and ORDER BY) are speci-\\nfied, we can think conceptually of a query as being executed as follows: For each combi-\\nnation of tuples—one from each of the relations specified in the FROM clause—evaluate \\nthe WHERE clause; if it evaluates to TRUE, place the values of the attributes specified in \\nthe SELECT clause from this tuple combination in the result of the query. Of course, this \\nis not an efficient way to implement the query in a real system, and each DBMS has \\nspecial query optimization routines to decide on an execution plan that is efficient to \\nexecute. We discuss query processing and optimization in Chapters 18 and 19.\\nIn general, there are numerous ways to specify the same query in SQL. This flexibility \\nin specifying queries has advantages and disadvantages. The main advantage is that \\nusers can choose the technique with which they are most comfortable when specifying \\na query. For example, many queries may be specified with join conditions in the \\nWHERE clause, or by using joined relations in the FROM clause, or with some form of \\nnested queries and the IN comparison operator. Some users may be more comfortable \\nwith one approach, whereas others may be more comfortable with another. From the \\nprogrammer’s and the system’s point of view regarding query optimization, it is gener-\\nally preferable to write a query with as little nesting and implied ordering as possible.\\nThe disadvantage of having numerous ways of specifying the same query is that \\nthis may confuse the user, who may not know which technique to use to specify \\n4The actual order of query evaluation is implementation dependent; this is just a way to conceptually \\nview a query in order to correctly formulate it.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 238, 'page_label': '239'}, page_content='7.2 Specifying Constraints as Assertions and Actions as Triggers  225\\nparticular types of queries. Another problem is that it may be more efficient to \\nexecute a query specified in one way than the same query specified in an alterna-\\ntive way. Ideally, this should not be the case: The DBMS should process the same \\nquery in the same way regardless of how the query is specified. But this is quite \\ndifficult in practice, since each DBMS has different methods for processing queries \\nspecified in different ways. Thus, an additional burden on the user is to determine \\nwhich of the alternative specifications is the most efficient to execute. Ideally, the \\nuser should worry only about specifying the query correctly, whereas the DBMS \\nwould determine how to execute the query efficiently. In practice, however, it \\nhelps if the user is aware of which types of constructs in a query are more expen-\\nsive to process than others.\\n7.2  Specifying Constraints as Assertions  \\nand Actions as Triggers\\nIn this section, we introduce two additional features of SQL: the CREATE ASSERTION \\nstatement and the CREATE TRIGGER  statement. Section 7.2.1 discusses CREATE \\nASSERTION, which can be used to specify additional types of constraints that are \\noutside the scope of the built-in relational model constraints  (primary and unique \\nkeys, entity integrity, and referential integrity) that we presented in Section 5.2. \\nThese built-in constraints can be specified within the \\nCREATE TABLE statement of \\nSQL (see Sections 6.1 and 6.2).\\nIn Section 7.2.2 we introduce CREATE TRIGGER, which can be used to specify auto-\\nmatic actions that the database system will perform when certain events and condi-\\ntions occur. This type of functionality is generally referred to as active databases. \\nWe only introduce the basics of triggers in this chapter, and present a more com-\\nplete discussion of active databases in Section 26.1.\\n7.2.1 Specifying General Constraints as Assertions in SQL\\nIn SQL, users can specify general constraints—those that do not fall into any of the \\ncategories described in Sections 6.1 and 6.2— via declarative assertions, using the \\nCREATE ASSERTION  statement. Each assertion is given a constraint name and is \\nspecified via a condition similar to the WHERE clause of an SQL query. For exam-\\nple, to specify the constraint that the salary of an employee must not be greater than \\nthe salary of the manager of the department that the employee works for  in SQL, we \\ncan write the following assertion:\\nCREATE ASSERTION SALARY_CONSTRAINT\\nCHECK ( NOT EXISTS ( SELECT *\\n   FROM EMPLOYEE E, EMPLOYEE M,\\n  DEPARTMENT D\\n   WHERE E.Salary>M.Salary\\n  AND E.Dno = D.Dnumber\\n  AND D.Mgr_ssn = M.Ssn ) );'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 239, 'page_label': '240'}, page_content='226 Chapter 7 More SQL: Complex Queries, Triggers, Views, and Schema Modification\\nThe constraint name SALARY_CONSTRAINT is followed by the keyword CHECK , \\nwhich is followed by a condition in parentheses that must hold true on every data-\\nbase state for the assertion to be satisfied. The constraint name can be used later to \\ndisable the constraint or to modify or drop it. The DBMS is responsible for ensur-\\ning that the condition is not violated. Any \\nWHERE clause condition can be used, \\nbut many constraints can be specified using the EXISTS and NOT EXISTS style of \\nSQL conditions. Whenever some tuples in the database cause the condition of an \\nASSERTION statement to evaluate to FALSE, the constraint is violated. The con-\\nstraint is satisfied by a database state if no combination of tuples  in that database \\nstate violates the constraint.\\nThe basic technique for writing such assertions is to specify a query that selects any \\ntuples that violate the desired condition. By including this query inside a NOT EXISTS \\nclause, the assertion will specify that the result of this query must be empty so that \\nthe condition will always be \\nTRUE. Thus, the assertion is violated if the result of the \\nquery is not empty. In the preceding example, the query selects all employees whose \\nsalaries are greater than the salary of the manager of their department. If the result \\nof the query is not empty, the assertion is violated.\\nNote that the \\nCHECK clause and constraint condition can also be used to specify \\nconstraints on individual  attributes and domains (see Section 6.2.1) and on indi-\\nvidual  tuples (see Section 6.2.4). A major difference between CREATE  \\nASSERTION and the individual domain constraints and tuple constraints is that \\nthe CHECK clauses on individual attributes, domains, and tuples are checked in \\nSQL only when tuples are inserted or updated  in a specific table. Hence, con-\\nstraint checking can be implemented more efficiently by the DBMS in these \\ncases. The schema designer should use CHECK on attributes, domains, and tuples \\nonly when he or she is sure that the constraint can only be violated by insertion or \\nupdating of tuples . On the other hand, the schema designer should use CREATE \\nASSERTION  only in cases where it is not possible to use CHECK on attributes, \\ndomains, or tuples, so that simple checks are implemented more efficiently by \\nthe DBMS.\\n7.2.2 Introduction to Triggers in SQL\\nAnother important statement in SQL is CREATE TRIGGER. In many cases it is con-\\nvenient to specify the type of action to be taken when certain events occur and \\nwhen certain conditions are satisfied. For example, it may be useful to specify a \\ncondition that, if violated, causes some user to be informed of the violation. A man-\\nager may want to be informed if an employee’s travel expenses exceed a certain \\nlimit by receiving a message whenever this occurs. The action that the DBMS must \\ntake in this case is to send an appropriate message to that user. The condition is \\nthus used to monitor the database. Other actions may be specified, such as execut-\\ning a specific stored procedure or triggering other updates. The \\nCREATE TRIGGER \\nstatement is used to implement such actions in SQL. We discuss triggers in detail in \\nSection 26.1 when we describe active databases. Here we just give a simple example \\nof how triggers may be used.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 240, 'page_label': '241'}, page_content='7.2 Specifying Constraints as Assertions and Actions as Triggers  227\\nSuppose we want to check whenever an employee’s salary is greater than the salary \\nof his or her direct supervisor in the COMPANY database (see Figures 5.5 and 5.6). \\nSeveral events can trigger this rule: inserting a new employee record, changing an \\nemployee’s salary, or changing an employee’s supervisor. Suppose that the action to \\ntake would be to call an external stored procedure \\nSALARY_VIOLATION,5 which will \\nnotify the supervisor. The trigger could then be written as in R5 below. Here we are \\nusing the syntax of the Oracle database system.\\nR5: CREATE TRIGGER SALARY_VIOLATION\\n BEFORE INSERT OR UPDATE OF SALARY, SUPERVISOR_SSN\\n  ON EMPLOYEE\\n FOR EACH ROW\\n  WHEN ( NEW.SALARY > ( SELECT SALARY FROM EMPLOYEE\\n        WHERE SSN = NEW.SUPERVISOR_SSN ) )\\n        INFORM_SUPERVISOR(NEW.Supervisor_ssn,  \\n        NEW.Ssn );\\nThe trigger is given the name SALARY_VIOLATION, which can be used to remove or \\ndeactivate the trigger later. A typical trigger which is regarded as an ECA (Event, \\nCondition, Action) rule has three components:\\n  1. The event(s): These are usually database update operations that are explic-\\nitly applied to the database. In this example the events are: inserting a new \\nemployee record, changing an employee’s salary, or changing an employee’s \\nsupervisor. The person who writes the trigger must make sure that all pos-\\nsible events are accounted for. In some cases, it may be necessary to write \\nmore than one trigger to cover all possible cases. These events are specified \\nafter the keyword \\nBEFORE in our example, which means that the trigger \\nshould be executed before the triggering operation is executed. An alterna-\\ntive is to use the keyword AFTER, which specifies that the trigger should be \\nexecuted after the operation specified in the event is completed.\\n  2. The condition that determines whether the rule action should be executed: \\nOnce the triggering event has occurred, an optional condition may be evalu-\\nated. If no condition is specified, the action will be executed once the event \\noccurs. If a condition is specified, it is first evaluated, and only if it evaluates \\nto true  will the rule action be executed. The condition is specified in the \\nWHEN clause of the trigger.\\n  3. The action to be taken: The action is usually a sequence of SQL statements, \\nbut it could also be a database transaction or an external program that will \\nbe automatically executed. In this example, the action is to execute the stored \\nprocedure INFORM_SUPERVISOR.\\nTriggers can be used in various applications, such as maintaining database consis-\\ntency, monitoring database updates, and updating derived data automatically. A \\ncomplete discussion is given in Section 26.1.\\n5Assuming that an appropriate external procedure has been declared. We discuss stored procedures in \\nChapter 10.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 241, 'page_label': '242'}, page_content='228 Chapter 7 More SQL: Complex Queries, Triggers, Views, and Schema Modification\\n7.3 Views (Virtual Tables) in SQL\\nIn this section we introduce the concept of a view in SQL. We show how views are \\nspecified, and then we discuss the problem of updating views and how views can be \\nimplemented by the DBMS.\\n7.3.1 Concept of a View in SQL\\nA view in SQL terminology is a single table that is derived from other tables.6  These \\nother tables can be base tables or previously defined views. A view does not neces-\\nsarily exist in physical form; it is considered to be a virtual table, in contrast to base \\ntables, whose tuples are always physically stored in the database. This limits the \\npossible update operations that can be applied to views, but it does not provide any \\nlimitations on querying a view.\\nWe can think of a view as a way of specifying a table that we need to reference \\nfrequently, even though it may not exist physically. For example, referring to the \\nCOMPANY database in Figure 5.5, we may frequently issue queries that retrieve the \\nemployee name and the project names that the employee works on. Rather than \\nhaving to specify the join of the three tables \\nEMPLOYEE, WORKS_ON, and PROJECT \\nevery time we issue this query, we can define a view that is specified as the result of \\nthese joins. Then we can issue queries on the view, which are specified as single-\\ntable retrievals rather than as retrievals involving two joins on three tables. We call \\nthe \\nEMPLOYEE, WORKS_ON, and PROJECT tables the defining tables of the view.\\n7.3.2 Specification of Views in SQL\\nIn SQL, the command to specify a view is CREATE VIEW. The view is given a (vir-\\ntual) table name (or view name), a list of attribute names, and a query to specify the \\ncontents of the view. If none of the view attributes results from applying functions \\nor arithmetic operations, we do not have to specify new attribute names for the \\nview, since they would be the same as the names of the attributes of the defining \\ntables in the default case. The views in \\nV1 and V2 create virtual tables whose sche-\\nmas are illustrated in Figure 7.2 when applied to the database schema of Figure 5.5.\\nV1: CREATE VIEW WORKS_ON1\\n AS SELECT Fname, Lname, Pname, Hours\\n    FROM EMPLOYEE, PROJECT, WORKS_ON\\n    WHERE Ssn = Essn AND Pno = Pnumber;\\nV2: CREATE VIEW DEPT_INFO(Dept_name, No_of_emps, Total_sal)\\n AS SELECT Dname, COUNT (*), SUM (Salary)\\n    FROM DEPARTMENT, EMPLOYEE\\n    WHERE Dnumber = Dno\\n    GROUP BY Dname;\\n6As used in SQL, the term view is more limited than the term user view discussed in Chapters 1 and 2, \\nsince a user view would possibly include many relations.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 242, 'page_label': '243'}, page_content='7.3 Views (Virtual Tables) in SQL  229\\nIn V1, we did not specify any new attribute names for the view WORKS_ON1  \\n(although we could have); in this case, WORKS_ON1  inherits  the names of the \\nview attributes from the defining tables EMPLOYEE , PROJECT , and WORKS_ON . \\nView V2 explicitly specifies new attribute names for the view DEPT_INFO , using \\na one-to-one correspondence between the attributes specified in the CREATE \\nVIEW clause and those specified in the SELECT clause of the query that defines \\nthe view.\\nWe can now specify SQL queries on a view—or virtual table—in the same way we \\nspecify queries involving base tables. For example, to retrieve the last name and first \\nname of all employees who work on the ‘ProductX’ project, we can utilize the \\nWORKS_ON1 view and specify the query as in QV1:\\nQV1: SELECT Fname, Lname\\n FROM WORKS_ON1\\n WHERE Pname = ‘ProductX’;\\nThe same query would require the specification of two joins if specified on the base \\nrelations directly; one of the main advantages of a view is to simplify the specifica-\\ntion of certain queries. Views are also used as a security and authorization mecha-\\nnism (see Section 7.3.4 and Chapter 30).\\nA view is supposed to be always up-to-date ; if we modify the tuples in the base \\ntables on which the view is defined, the view must automatically reflect these \\nchanges. Hence, the view does not have to be realized or materialized at the time of \\nview definition but rather at the time when we specify a query on the view. It is the \\nresponsibility of the DBMS and not the user to make sure that the view is kept up-\\nto-date. We will discuss various ways the DBMS can utilize to keep a view up-to-\\ndate in the next subsection.\\nIf we do not need a view anymore, we can use the \\nDROP VIEW command to dispose \\nof it. For example, to get rid of the view V1, we can use the SQL statement in V1A:\\nV1A: DROP VIEW WORKS_ON1;\\n7.3.3 View Implementation, View Update, and Inline Views\\nThe problem of how a DBMS can efficiently implement a view for efficient querying \\nis complex. Two main approaches have been suggested. One strategy, called query \\nmodification, involves modifying or transforming the view query (submitted by the \\nDEPT_INFO\\nDept_name No_of_emps Total_sal\\nWORKS_ON1\\nFname Lname Pname Hours\\nFigure 7.2 \\nTwo views specified on \\nthe database schema of \\nFigure 5.5.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 243, 'page_label': '244'}, page_content='230 Chapter 7 More SQL: Complex Queries, Triggers, Views, and Schema Modification\\nuser) into a query on the underlying base tables. For example, the query QV1 would \\nbe automatically modified to the following query by the DBMS:\\nSELECT Fname, Lname\\nFROM EMPLOYEE, PROJECT, WORKS_ON\\nWHERE Ssn = Essn AND Pno = Pnumber\\n AND Pname = ‘ProductX’;\\nThe disadvantage of this approach is that it is inefficient for views defined via com-\\nplex queries that are time-consuming to execute, especially if multiple view queries \\nare going to be applied to the same view within a short period of time. The second \\nstrategy, called view materialization, involves physically creating a temporary or \\npermanent view table when the view is first queried or created and keeping that \\ntable on the assumption that other queries on the view will follow. In this case, an \\nefficient strategy for automatically updating the view table when the base tables are \\nupdated must be developed in order to keep the view up-to-date. Techniques using \\nthe concept of incremental update  have been developed for this purpose, where \\nthe DBMS can determine what new tuples must be inserted, deleted, or modified in \\na materialized view table  when a database update is applied to one of the defining \\nbase tables. The view is generally kept as a materialized (physically stored) table as \\nlong as it is being queried. If the view is not queried for a certain period of time, the \\nsystem may then automatically remove the physical table and recompute it from \\nscratch when future queries reference the view.\\nDifferent strategies as to when a materialized view is updated are possible. The \\nimmediate update strategy updates a view as soon as the base tables are changed; \\nthe lazy update strategy updates the view when needed by a view query; and the \\nperiodic update strategy updates the view periodically (in the latter strategy, a view \\nquery may get a result that is not up-to-date).\\nA user can always issue a retrieval query against any view. However, issuing an \\nINSERT, DELETE, or UPDATE command on a view table is in many cases not pos-\\nsible. In general, an update on a view defined on a single table without any aggregate \\nfunctions can be mapped to an update on the underlying base table under certain \\nconditions. For a view involving joins, an update operation may be mapped to \\nupdate operations on the underlying base relations in multiple ways . Hence, it is \\noften not possible for the DBMS to determine which of the updates is intended. To \\nillustrate potential problems with updating a view defined on multiple tables, con-\\nsider the \\nWORKS_ON1 view, and suppose that we issue the command to update the \\nPNAME attribute of ‘John Smith’ from ‘ProductX’ to ‘ProductY’. This view update is \\nshown in UV1:\\nUV1: UPDATE WORKS_ON1\\n SET Pname = ‘ProductY’\\n WHERE Lname = ‘Smith’ AND Fname = ‘John’\\n  AND Pname = ‘ProductX’;\\nThis query can be mapped into several updates on the base relations to give the \\ndesired update effect on the view. In addition, some of these updates will create'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 244, 'page_label': '245'}, page_content='7.3 Views (Virtual Tables) in SQL  231\\nadditional side effects that affect the result of other queries. For example, here are \\ntwo possible updates, (a) and (b), on the base relations corresponding to the view \\nupdate operation in \\nUV1:\\n(a): UPDATE WORKS_ON\\n SET Pno = ( SELECT Pnumber\\n     FROM PROJECT\\n     WHERE Pname = ‘ProductY’ )\\n WHERE Essn IN ( SELECT Ssn\\n     FROM EMPLOYEE\\n     WHERE Lname = ‘Smith’ AND Fname = ‘John’ )\\n  AND\\n  Pno = ( SELECT Pnumber\\n     FROM PROJECT\\n     WHERE Pname = ‘ProductX’ );\\n(b): UPDATE PROJECT   SET  Pname = ‘ProductY’\\n WHERE Pname = ‘ProductX’;\\nUpdate (a) relates ‘John Smith’ to the ‘ProductY’ PROJECT tuple instead of the \\n‘ProductX’ PROJECT tuple and is the most likely desired update. However, (b) would \\nalso give the desired update effect on the view, but it accomplishes this by changing \\nthe name of the ‘ProductX’ tuple in the PROJECT relation to ‘ProductY’. It is quite \\nunlikely that the user who specified the view update UV1 wants the update to be \\ninterpreted as in (b), since it also has the side effect of changing all the view tuples \\nwith Pname = ‘ProductX’.\\nSome view updates may not make much sense; for example, modifying the Total_sal \\nattribute of the DEPT_INFO view does not make sense because Total_sal is defined to be \\nthe sum of the individual employee salaries. This incorrect request is shown as UV2:\\nUV2: UPDATE  DEPT_INFO\\n SET Total_sal = 100000\\n WHERE Dname = ‘Research’;\\nGenerally, a view update is feasible when only one possible update on the base rela-\\ntions can accomplish the desired update operation on the view. Whenever an \\nupdate on the view can be mapped to more than one update on the underlying base \\nrelations, it is usually not permitted. Some researchers have suggested that the \\nDBMS have a certain procedure for choosing one of the possible updates as the \\nmost likely one. Some researchers have developed methods for choosing the most \\nlikely update, whereas other researchers prefer to have the user choose the desired \\nupdate mapping during view definition. But these options are generally not avail-\\nable in most commercial DBMSs.\\nIn summary, we can make the following observations:\\n ■ A view with a single defining table is updatable if the view attributes contain \\nthe primary key of the base relation, as well as all attributes with the NOT \\nNULL constraint that do not have default values specified.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 245, 'page_label': '246'}, page_content='232 Chapter 7 More SQL: Complex Queries, Triggers, Views, and Schema Modification\\n ■ Views defined on multiple tables using joins are generally not updatable.\\n ■ Views defined using grouping and aggregate functions are not updatable.\\nIn SQL, the clause WITH CHECK OPTION  should be added at the end of the view \\ndefinition if a view is to be updated by INSERT, DELETE, or UPDATE statements. \\nThis allows the system to reject operations that violate the SQL rules for view \\nupdates. The full set of SQL rules for when a view may be modified by the user are \\nmore complex than the rules stated earlier.\\nIt is also possible to define a view table in the \\nFROM clause of an SQL query. This is \\nknown as an in-line view. In this case, the view is defined within the query itself.\\n7.3.4 Views as Authorization Mechanisms\\nWe describe SQL query authorization statements (GRANT and REVOKE) in detail \\nin Chapter 30, when we present database security and authorization mechanisms. \\nHere, we will just give a couple of simple examples to illustrate how views can be \\nused to hide certain attributes or tuples from unauthorized users. Suppose a certain \\nuser is only allowed to see employee information for employees who work for \\ndepartment 5; then we can create the following view DEPT5EMP and grant the user \\nthe privilege to query the view but not the base table EMPLOYEE itself. This user \\nwill only be able to retrieve employee information for employee tuples whose  \\nDno = 5, and will not be able to see other employee tuples when the view is queried.\\nCREATE VIEW DEPT5EMP AS\\nSELECT *\\nFROM EMPLOYEE\\nWHERE Dno = 5;\\nIn a similar manner, a view can restrict a user to only see certain columns; for \\nexample, only the first name, last name, and address of an employee may be visible \\nas follows:\\nCREATE VIEW BASIC_EMP_DATA AS\\nSELECT Fname, Lname, Address\\nFROM EMPLOYEE;\\nThus by creating an appropriate view and granting certain users access to the view \\nand not the base tables, they would be restricted to retrieving only the data specified \\nin the view. Chapter 30 discusses security and authorization in detail, including the \\nGRANT and REVOKE statements of SQL.\\n7.4 Schema Change Statements in SQL\\nIn this section, we give an overview of the schema evolution commands available \\nin SQL, which can be used to alter a schema by adding or dropping tables, attri-\\nbutes, constraints, and other schema elements. This can be done while the database \\nis operational and does not require recompilation of the database schema. Certain'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 246, 'page_label': '247'}, page_content='7.4 Schema Change Statements in SQL  233\\nchecks must be done by the DBMS to ensure that the changes do not affect the rest \\nof the database and make it inconsistent.\\n7.4.1 The DROP Command\\nThe DROP command can be used to drop named schema elements, such as tables, \\ndomains, types, or constraints. One can also drop a whole schema if it is no longer \\nneeded by using the \\nDROP SCHEMA  command. There are two drop behavior  \\noptions: CASCADE and RESTRICT. For example, to remove the COMPANY database \\nschema and all its tables, domains, and other elements, the CASCADE option is used \\nas follows:\\nDROP SCHEMA COMPANY CASCADE;\\nIf the RESTRICT option is chosen in place of CASCADE, the schema is dropped only \\nif it has no elements in it; otherwise, the DROP command will not be executed. To \\nuse the RESTRICT option, the user must first individually drop each element in the \\nschema, then drop the schema itself.\\nIf a base relation within a schema is no longer needed, the relation and its definition \\ncan be deleted by using the DROP TABLE command. For example, if we no longer \\nwish to keep track of dependents of employees in the COMPANY database of Fig- \\nure 6.1, we can get rid of the DEPENDENT relation by issuing the following command:\\nDROP TABLE DEPENDENT CASCADE;\\nIf the RESTRICT option is chosen instead of CASCADE, a table is dropped only if it is \\nnot referenced in any constraints (for example, by foreign key definitions in another \\nrelation) or views (see Section 7.3) or by any other elements. With the CASCADE \\noption, all such constraints, views, and other elements that reference the table being \\ndropped are also dropped automatically from the schema, along with the table itself.\\nNotice that the \\nDROP TABLE command not only deletes all the records in the table \\nif successful, but also removes the table definition from the catalog. If it is desired to \\ndelete only the records but to leave the table definition for future use, then the \\nDELETE command (see Section 6.4.2) should be used instead of DROP TABLE.\\nThe DROP command can also be used to drop other types of named schema ele-\\nments, such as constraints or domains.\\n7.4.2 The ALTER Command\\nThe definition of a base table or of other named schema elements can be changed \\nby using the \\nALTER command. For base tables, the possible alter table actions  \\ninclude adding or dropping a column (attribute), changing a column definition, \\nand adding or dropping table constraints. For example, to add an attribute for \\nkeeping track of jobs of employees to the EMPLOYEE base relation in the COMPANY \\nschema (see Figure 6.1), we can use the command\\nALTER TABLE COMPANY.EMPLOYEE ADD COLUMN Job VARCHAR(12);'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 247, 'page_label': '248'}, page_content='234 Chapter 7 More SQL: Complex Queries, Triggers, Views, and Schema Modification\\nWe must still enter a value for the new attribute Job for each individual EMPLOYEE \\ntuple. This can be done either by specifying a default clause or by using the UPDATE \\ncommand individually on each tuple (see Section 6.4.3). If no default clause is speci-\\nfied, the new attribute will have \\nNULLs in all the tuples of the relation immediately after \\nthe command is executed; hence, the NOT NULL constraint is not allowed in this case.\\nTo drop a column, we must choose either CASCADE or RESTRICT for drop behav-\\nior. If CASCADE is chosen, all constraints and views that reference the column are \\ndropped automatically from the schema, along with the column. If RESTRICT is \\nchosen, the command is successful only if no views or constraints (or other schema \\nelements) reference the column. For example, the following command removes the \\nattribute \\nAddress from the EMPLOYEE base table:\\nALTER TABLE COMPANY.EMPLOYEE DROP COLUMN Address CASCADE;\\nIt is also possible to alter a column definition by dropping an existing default clause \\nor by defining a new default clause. The following examples illustrate this clause:\\nALTER TABLE COMPANY.DEPARTMENT ALTER COLUMN Mgr_ssn\\n  DROP DEFAULT;\\nALTER TABLE COMPANY.DEPARTMENT ALTER COLUMN Mgr_ssn\\n  SET DEFAULT ‘333445555’ ;\\nOne can also change the constraints specified on a table by adding or dropping a \\nnamed constraint. To be dropped, a constraint must have been given a name when \\nit was specified. For example, to drop the constraint named \\nEMPSUPERFK in Fig-\\nure 6.2 from the EMPLOYEE relation, we write:\\nALTER TABLE COMPANY.EMPLOYEE\\nDROP CONSTRAINT EMPSUPERFK CASCADE;\\nOnce this is done, we can redefine a replacement constraint by adding a new con-\\nstraint to the relation, if needed. This is specified by using the ADD CONSTRAINT \\nkeyword in the ALTER TABLE statement followed by the new constraint, which can \\nbe named or unnamed and can be of any of the table constraint types discussed.\\nThe preceding subsections gave an overview of the schema evolution commands of \\nSQL. It is also possible to create new tables and views within a database schema \\nusing the appropriate commands. There are many other details and options; we \\nrefer the interested reader to the SQL documents listed in the Selected Bibliography \\nat the end of this chapter.\\n7.5 Summary\\nIn this chapter we presented additional features of the SQL database language. We \\nstarted in Section 7.1 by presenting more complex features of SQL retrieval queries, \\nincluding nested queries, joined tables, outer joins, aggregate functions, and group-\\ning. In Section 7.2, we described the CREATE ASSERTION statement, which allows \\nthe specification of more general constraints on the database, and introduced the'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 248, 'page_label': '249'}, page_content='7.5 Summary  235\\nTable 7.2 Summary of SQL Syntax\\nCREATE TABLE <table name> (  <column name> <column type> [ <attribute constraint> ] \\n{ , <column name> <column type> [ <attribute constraint> ] } \\n[ <table constraint> { , <table constraint> } ] )\\nDROP TABLE <table name>\\nALTER TABLE <table name> ADD <column name> <column type>\\nSELECT [ DISTINCT ] <attribute list>\\nFROM ( <table name> { <alias> } | <joined table> ) { , ( <table name> { <alias> } | <joined table> ) }\\n[ WHERE <condition> ]\\n[ GROUP BY <grouping attributes> [ HAVING <group selection condition> ] ]\\n[ ORDER BY <column name> [ <order> ] { , <column name> [ <order> ] } ]\\n<attribute list> ::= ( * | (  <column name> | <function> ( ( [ DISTINCT ] <column name> | * ) ) ) \\n{ , ( <column name> | <function> ( ( [ DISTINCT] <column name> | * ) ) } ) )\\n<grouping attributes> ::= <column name> { , <column name> }\\n<order> ::= ( ASC | DESC )\\nINSERT INTO <table name> [ ( <column name> { , <column name> } ) ]\\n( VALUES ( <constant value> , { <constant value> } ) { , ( <constant value> { , <constant value> } ) }\\n| <select statement> )\\nDELETE FROM <table name>\\n[ WHERE <selection condition> ]\\nUPDATE <table name>\\nSET <column name> = <value expression> { , <column name> = <value expression> }\\n[ WHERE <selection condition> ]\\nCREATE [ UNIQUE] INDEX <index name>\\nON <table name> ( <column name> [ <order> ] { , <column name> [ <order> ] } )\\n[ CLUSTER ]\\nDROP INDEX <index name>\\nCREATE VIEW <view name> [ ( <column name> { , <column name> } ) ]\\nAS <select statement>\\nDROP VIEW <view name>\\nNOTE: The commands for creating and dropping indexes are not part of standard SQL.\\nconcept of triggers and the CREATE TRIGGER statement. Then, in Section 7.3, we \\ndescribed the SQL facility for defining views on the database. Views are also called \\nvirtual or derived tables because they present the user with what appear to be tables; \\nhowever, the information in those tables is derived from previously defined tables. \\nSection 7.4 introduced the SQL \\nALTER TABLE statement, which is used for modify-\\ning the database tables and constraints.\\nTable 7.2 summarizes the syntax (or structure) of various SQL statements. This \\nsummary is not meant to be comprehensive or to describe every possible SQL \\nconstruct; rather, it is meant to serve as a quick reference to the major types of \\nconstructs available in SQL. We use BNF notation, where nonterminal symbols'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 249, 'page_label': '250'}, page_content='236 Chapter 7 More SQL: Complex Queries, Triggers, Views, and Schema Modification\\nare shown in angled brackets < … >, optional parts are shown in square brac-\\nkets [ … ], repetitions are shown in braces { … }, and alternatives are shown in \\nparentheses ( … | … | … ).\\n7\\nReview Questions\\n 7.1.  Describe the six clauses in the syntax of an SQL retrieval query. Show what \\ntype of constructs can be specified in each of the six clauses. Which of the six \\nclauses are required and which are optional?\\n 7.2.  Describe conceptually how an SQL retrieval query will be executed by speci-\\nfying the conceptual order of executing each of the six clauses.\\n 7.3.  Discuss how NULLs are treated in comparison operators in SQL. How are \\nNULLs treated when aggregate functions are applied in an SQL query? How \\nare NULLs treated if they exist in grouping attributes?\\n 7.4.  Discuss how each of the following constructs is used in SQL, and discuss \\nthe various options for each construct. Specify what each construct is \\nuseful for.\\na. Nested queries\\nb. Joined tables and outer joins\\nc. Aggregate functions and grouping\\nd. Triggers\\ne. Assertions and how they differ from triggers\\nf. The SQL WITH clause\\ng. SQL CASE construct\\nh. Views and their updatability\\ni. Schema change commands\\nExercises\\n 7.5.  Specify the following queries on the database in Figure 5.5 in SQL. Show the \\nquery results if each query is applied to the database state in Figure 5.6.\\na. For each department whose average employee salary is more than \\n$30,000, retrieve the department name and the number of employees \\nworking for that department.\\nb. Suppose that we want the number of male employees in each department \\nmaking more than $30,000, rather than all employees (as in Exer- \\ncise 7.5a). Can we specify this query in SQL? Why or why not?\\n7The full syntax of SQL is described in many voluminous documents of hundreds of pages.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 250, 'page_label': '251'}, page_content='Exercises 237\\n 7.6.  Specify the following queries in SQL on the database schema in Figure 1.2.\\na. Retrieve the names and major departments of all straight-A students \\n(students who have a grade of A in all their courses).\\nb. Retrieve the names and major departments of all students who do not \\nhave a grade of A in any of their courses.\\n 7.7.  In SQL, specify the following queries on the database in Figure 5.5 using the \\nconcept of nested queries and other concepts described in this chapter.\\na. Retrieve the names of all employees who work in the department that has \\nthe employee with the highest salary among all employees.\\nb. Retrieve the names of all employees whose supervisor’s supervisor has \\n‘888665555’ for \\nSsn.\\nc. Retrieve the names of employees who make at least $10,000 more than \\nthe employee who is paid the least in the company.\\n 7.8.  Specify the following views in SQL on the COMPANY  database schema \\nshown in Figure 5.5.\\na. A view that has the department name, manager name, and manager sal-\\nary for every department\\nb. A view that has the employee name, supervisor name, and employee sal-\\nary for each employee who works in the ‘Research’ department\\nc. A view that has the project name, controlling department name, number \\nof employees, and total hours worked per week on the project for each \\nproject\\nd. A view that has the project name, controlling department name, number \\nof employees, and total hours worked per week on the project for each \\nproject with more than one employee working on it\\n 7.9.  Consider the following view, DEPT_SUMMARY, defined on the COMPANY \\ndatabase in Figure 5.6:\\nCREATE VIEW DEPT_SUMMARY (D, C, Total_s, Average_s)\\nAS SELECT Dno, COUNT (*), SUM (Salary), AVG (Salary)\\nFROM EMPLOYEE\\nGROUP BY Dno;\\nState which of the following queries and updates would be allowed on the \\nview. If a query or update would be allowed, show what the correspond-\\ning query or update on the base relations would look like, and give its \\nresult when applied to the database in Figure 5.6.\\na. SELECT *\\nFROM DEPT_SUMMARY;\\nb. SELECT D, C\\nFROM DEPT_SUMMARY\\nWHERE TOTAL_S > 100000;'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 251, 'page_label': '252'}, page_content='238 Chapter 7 More SQL: Complex Queries, Triggers, Views, and Schema Modification\\nc. SELECT D, AVERAGE_S\\nFROM DEPT_SUMMARY\\nWHERE C > ( SELECT C FROM DEPT_SUMMARY WHERE D = 4);\\nd. UPDATE DEPT_SUMMARY\\nSET D = 3\\nWHERE D = 4;\\ne. DELETE FROM DEPT_SUMMARY\\nWHERE C > 4;\\nSelected Bibliography\\nReisner (1977) describes a human factors evaluation of SEQUEL, a precursor of \\nSQL, in which she found that users have some difficulty with specifying join condi-\\ntions and grouping correctly. Date (1984) contains a critique of the SQL language \\nthat points out its strengths and shortcomings. Date and Darwen (1993) describes \\nSQL2. ANSI (1986) outlines the original SQL standard. Various vendor manuals \\ndescribe the characteristics of SQL as implemented on DB2, SQL/DS, Oracle, \\nINGRES, Informix, and other commercial DBMS products. Melton and Simon \\n(1993) give a comprehensive treatment of the ANSI 1992 standard called SQL2. \\nHorowitz (1992) discusses some of the problems related to referential integrity and \\npropagation of updates in SQL2.\\nThe question of view updates is addressed by Dayal and Bernstein (1978), Keller \\n(1982), and Langerak (1990), among others. View implementation is discussed in \\nBlakeley et al. (1989). Negri et al. (1991) describes formal semantics of SQL queries.\\nThere are many books that describe various aspects of SQL. For example, two refer-\\nences that describe SQL-99 are Melton and Simon (2002) and Melton (2003). Fur-\\nther SQL standards—SQL 2006 and SQL 2008—are described in a variety of \\ntechnical reports; but no standard references exist.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 252, 'page_label': '253'}, page_content='239\\n8\\nThe Relational Algebra and \\nRelational Calculus\\nI\\nn this chapter we discuss the two formal languages for \\nthe relational model: the relational algebra and the \\nrelational calculus. In contrast, Chapters 6 and 7 described the practical language \\nfor the relational model, namely the SQL standard. Historically, the relational alge-\\nbra and calculus were developed before the SQL language. SQL is primarily based \\non concepts from relational calculus and has been extended to incorporate some \\nconcepts from relational algebra as well. Because most relational DBMSs use SQL \\nas their language, we presented the SQL language first.\\nRecall from Chapter 2 that a data model must include a set of operations to \\nmanipulate the database, in addition to the data model’s concepts for defining the \\ndatabase’s structure and constraints. We presented the structures and constraints \\nof the formal relational model in Chapter 5. The basic set of operations for the \\nformal relational model is the relational algebra . These operations enable a user \\nto specify basic retrieval requests as relational algebra expressions . The result of a \\nretrieval query is a new relation. The algebra operations thus produce new rela-\\ntions, which can be further manipulated using operations of the same algebra. A \\nsequence of relational algebra operations forms a relational algebra expression , \\nwhose result will also be a relation that represents the result of a database query \\n(or retrieval request).\\nThe relational algebra is very important for several reasons. First, it provides a \\nformal foundation for relational model operations. Second, and perhaps more \\nimportant, it is used as a basis for implementing and optimizing queries in the \\nquery processing and optimization modules that are integral parts of relational \\ndatabase management systems (RDBMSs), as we shall discuss in Chapters 18 \\nand 19. Third, some of its concepts are incorporated into the SQL standard \\nchapter 8'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 253, 'page_label': '254'}, page_content='240 Chapter 8 The Relational Algebra and Relational Calculus\\nquery language for RDBMSs. Although most commercial RDBMSs in use today \\ndo not provide user interfaces for relational algebra queries, the core operations \\nand functions in the internal modules of most relational systems are based on \\nrelational algebra operations. We will define these operations in detail in Sec-\\ntions 8.1 through 8.4 of this chapter.\\nWhereas the algebra defines a set of operations for the relational model, the  \\nrelational calculus provides a higher-level declarative language for specifying rela-\\ntional queries. In a relational calculus expression, there is no order of operations to \\nspecify how to retrieve the query result—only what information the result should \\ncontain. This is the main distinguishing feature between relational algebra and rela-\\ntional calculus. The relational calculus is important because it has a firm basis in \\nmathematical logic and because the standard query language (SQL) for RDBMSs \\nhas some of its foundations in a variation of relational calculus known as the tuple \\nrelational calculus.\\n1\\nThe relational algebra is often considered to be an integral part of the relational data \\nmodel. Its operations can be divided into two groups. One group includes set oper-\\nations from mathematical set theory; these are applicable because each relation is \\ndefined to be a set of tuples in the formal relational model (see Section 5.1). Set \\noperations include \\nUNION, INTERSECTION , SET DIFFERENCE , and CARTESIAN \\nPRODUCT (also known as CROSS PRODUCT). The other group consists of opera-\\ntions developed specifically for relational databases—these include SELECT , \\nPROJECT, and JOIN, among others. First, we describe the SELECT and PROJECT \\noperations in Section 8.1 because they are unary operations that operate on single \\nrelations. Then we discuss set operations in Section 8.2. In Section 8.3, we discuss \\nJOIN and other complex binary operations, which operate on two tables by com-\\nbining related tuples (records) based on join conditions. The COMPANY relational \\ndatabase shown in Figure 5.6 is used for our examples.\\nSome common database requests cannot be performed with the original relational \\nalgebra operations, so additional operations were created to express these requests. \\nThese include aggregate functions, which are operations that can summarize data \\nfrom the tables, as well as additional types of \\nJOIN and UNION operations, known as \\nOUTER JOINs and OUTER UNIONs. These operations, which were added to the origi-\\nnal relational algebra because of their importance to many database applications, \\nare described in Section 8.4. We give examples of specifying queries that use rela-\\ntional operations in Section 8.5. Some of these same queries were used in Chap- \\nters 6 and 7. By using the same query numbers in this chapter, the reader can contrast \\nhow the same queries are written in the various query languages.\\nIn Sections 8.6 and 8.7 we describe the other main formal language for relational \\ndatabases, the relational calculus . There are two variations of relational calculus. \\nThe tuple relational calculus is described in Section 8.6 and the domain relational \\ncalculus is described in Section 8.7. Some of the SQL constructs discussed in \\n1SQL is based on tuple relational calculus, but also incorporates some of the operations from the \\nrelational algebra and its extensions, as illustrated in Chapters 6, 7 , and 9.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 254, 'page_label': '255'}, page_content='8.1 Unary Relational Operations: SELECT and PROJECT  241\\nChapters 6 and 7 are based on the tuple relational calculus. The relational calculus \\nis a formal language, based on the branch of mathematical logic called predicate \\ncalculus.\\n2 In tuple relational calculus, variables range over tuples , whereas in \\ndomain relational calculus, variables range over the domains (values) of attributes. \\nIn Appendix C we give an overview of the Query-By-Example (QBE) language, \\nwhich is a graphical user-friendly relational language based on domain relational \\ncalculus. Section 8.8 summarizes the chapter.\\nFor the reader who is interested in a less detailed introduction to formal relational \\nlanguages, Sections 8.4, 8.6, and 8.7 may be skipped.\\n8.1  Unary Relational Operations:  \\nSELECT and PROJECT\\n8.1.1 The SELECT Operation\\nThe SELECT operation is used to choose a subset of the tuples from a relation that \\nsatisfies a selection condition.3 We can consider the SELECT operation to be a filter \\nthat keeps only those tuples that satisfy a qualifying condition. Alternatively, we can \\nconsider the SELECT operation to restrict the tuples in a relation to only those tuples \\nthat satisfy the condition. The SELECT operation can also be visualized as a horizon-\\ntal partition of the relation into two sets of tuples—those tuples that satisfy the con-\\ndition and are selected, and those tuples that do not satisfy the condition and are \\nfiltered out. For example, to select the EMPLOYEE tuples whose department is 4, or \\nthose whose salary is greater than $30,000, we can individually specify each of these \\ntwo conditions with a SELECT operation as follows:\\nσDno=4(EMPLOYEE) \\nσSalary>30000(EMPLOYEE)\\nIn general, the SELECT operation is denoted by\\nσ<selection condition>(R)\\nwhere the symbol σ (sigma) is used to denote the SELECT operator and the selec-\\ntion condition is a Boolean expression (condition) specified on the attributes of \\nrelation R. Notice that R is generally a relational algebra expression whose result is a \\nrelation—the simplest such expression is just the name of a database relation. The \\nrelation resulting from the SELECT operation has the same attributes as R.\\nThe Boolean expression specified in <selection condition> is made up of a number \\nof clauses of the form\\n<attribute name> <comparison op> <constant value>\\n2In this chapter no familiarity with first-order predicate calculus—which deals with quantified variables \\nand values—is assumed.\\n3The SELECT operation is different from the SELECT clause of SQL. The SELECT operation chooses \\ntuples from a table, and is sometimes called a RESTRICT or FIL TER operation.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 255, 'page_label': '256'}, page_content='242 Chapter 8 The Relational Algebra and Relational Calculus\\nor\\n<attribute name> <comparison op> <attribute name>\\nwhere <attribute name> is the name of an attribute of R, <comparison op> is nor-\\nmally one of the operators {=, <, ≤, >, ≥, ≠}, and <constant value> is a constant \\nvalue from the attribute domain. Clauses can be connected by the standard Boolean \\noperators and, or, and not to form a general selection condition. For example, to \\nselect the tuples for all employees who either work in department 4 and make over \\n$25,000 per year, or work in department 5 and make over $30,000, we can specify \\nthe following \\nSELECT operation:\\nσ(Dno=4 AND Salary>25000) OR (Dno=5 AND Salary>30000)(EMPLOYEE)\\nThe result is shown in Figure 8.1(a).\\nNotice that all the comparison operators in the set {=, <, ≤, >, ≥, ≠} can apply to \\nattributes whose domains are ordered values , such as numeric or date domains. \\nDomains of strings of characters are also considered to be ordered based on the col-\\nlating sequence of the characters. If the domain of an attribute is a set of unordered \\nvalues, then only the comparison operators in the set {=, ≠} can be used. An exam-\\nple of an unordered domain is the domain \\nColor = { ‘red’, ‘blue’, ‘green’, ‘white’, \\n‘yellow’, …}, where no order is specified among the various colors. Some domains \\nallow additional types of comparison operators; for example, a domain of character \\nstrings may allow the comparison operator SUBSTRING_OF.\\nFname Minit Lname Ssn Bdate Address Sex Salary Super_ssn Dno\\nFranklin\\nJennifer\\nRamesh\\nT Wong\\nWallace\\nNarayan\\n333445555\\n987654321\\n666884444\\n1955-12-08\\n1941-06-20\\n1962-09-15\\n638 Voss, Houston, TX\\n291 Berry, Bellaire, TX\\n975 Fire Oak, Humble, TX\\nM\\nF\\nM\\n40000\\n43000\\n38000\\n888665555\\n888665555\\n333445555\\n5\\n4\\n5\\nLname Fname Salary\\nSmith\\nWong\\nZelaya\\nWallace\\nNarayan\\nEnglish\\nJabbar\\nBorg\\nJohn\\nFranklin\\nAlicia\\nJennifer\\nRamesh\\nJoyce\\nAhmad\\nJames\\n30000\\n40000\\n25000\\n43000\\n38000\\n25000\\n25000\\n30000\\n40000\\n25000\\n43000\\n38000\\n25000\\n55000\\n55000\\nSex Salary\\nM\\nM\\nF\\nF\\nM\\nM\\nM\\n(c)(b)\\n(a)\\nS\\nK\\nFigure 8.1 \\nResults of SELECT and PROJECT operations. (a) σ(Dno=4 AND Salary>25000) OR (Dno=5 AND Salary>30000) (EMPLOYEE). \\n(b) πLname, Fname, Salary(EMPLOYEE). (c) πSex, Salary(EMPLOYEE).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 256, 'page_label': '257'}, page_content='8.1 Unary Relational Operations: SELECT and PROJECT  243\\nIn general, the result of a SELECT operation can be determined as follows. The \\n<selection condition> is applied independently to each individual tuple t in R. This \\nis done by substituting each occurrence of an attribute Ai in the selection condition \\nwith its value in the tuple t[Ai]. If the condition evaluates to TRUE, then tuple t is \\nselected. All the selected tuples appear in the result of the SELECT operation. The \\nBoolean conditions AND, OR, and NOT have their normal interpretation, as follows:\\n ■ (cond1 AND cond2) is TRUE if both (cond1) and (cond2) are TRUE; other-\\nwise, it is FALSE.\\n ■ (cond1 OR cond2) is TRUE if either (cond1) or (cond2) or both are TRUE; \\notherwise, it is FALSE.\\n ■ (NOT cond) is TRUE if cond is FALSE; otherwise, it is FALSE.\\nThe SELECT operator is unary; that is, it is applied to a single relation. Moreover, \\nthe selection operation is applied to each tuple individually; hence, selection condi-\\ntions cannot involve more than one tuple. The degree of the relation resulting from \\na SELECT operation—its number of attributes—is the same as the degree of R. The \\nnumber of tuples in the resulting relation is always less than or equal to the number \\nof tuples in R. That is, | σc (R)| ≤ | R| for any condition C. The fraction of tuples \\nselected by a selection condition is referred to as the selectivity of the condition.\\nNotice that the SELECT operation is commutative; that is,\\nσ<cond1>(σ<cond2>(R)) = σ<cond2>(σ<cond1>(R))\\nHence, a sequence of SELECTs can be applied in any order. In addition, we can \\nalways combine a cascade (or sequence) of SELECT operations into a single SELECT \\noperation with a conjunctive (AND) condition; that is,\\nσ<cond1>(σ<cond2>(... (σ<condn>(R)) ...)) = σ<cond1> AND<cond2> AND...AND <condn>(R)\\nIn SQL, the SELECT condition is typically specified in the WHERE clause of a query. \\nFor example, the following operation:\\nσDno=4 AND Salary>25000 (EMPLOYEE)\\nwould correspond to the following SQL query:\\nSELECT *\\nFROM EMPLOYEE\\nWHERE Dno=4 AND Salary>25000;\\n8.1.2 The PROJECT Operation\\nIf we think of a relation as a table, the SELECT operation chooses some of the rows \\nfrom the table while discarding other rows. The PROJECT operation, on the other \\nhand, selects certain columns from the table and discards the other columns. If we \\nare interested in only certain attributes of a relation, we use the PROJECT operation \\nto project the relation over these attributes only. Therefore, the result of the PROJECT \\noperation can be visualized as a vertical partition of the relation into two relations:'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 257, 'page_label': '258'}, page_content='244 Chapter 8 The Relational Algebra and Relational Calculus\\none has the needed columns (attributes) and contains the result of the operation, \\nand the other contains the discarded columns. For example, to list each employee’s \\nfirst and last name and salary, we can use the \\nPROJECT operation as follows:\\nπLname, Fname, Salary(EMPLOYEE)\\nThe resulting relation is shown in Figure 8.1(b). The general form of the PROJECT \\noperation is\\nπ<attribute list>(R)\\nwhere π (pi) is the symbol used to represent the PROJECT operation, and <attribute \\nlist> is the desired sublist of attributes from the attributes of relation R. Again, \\nnotice that R is, in general, a relational algebra expression whose result is a relation, \\nwhich in the simplest case is just the name of a database relation. The result of the \\nPROJECT operation has only the attributes specified in <attribute list> in the same \\norder as they appear in the list. Hence, its degree is equal to the number of attributes \\nin <attribute list>.\\nIf the attribute list includes only nonkey attributes of R, duplicate tuples are \\nlikely to occur. The PROJECT  operation removes any duplicate tuples , so the \\nresult of the PROJECT  operation is a set of distinct tuples, and hence a valid \\nrelation. This is known as duplicate elimination . For example, consider the \\nfollowing PROJECT  operation:\\nπSex, Salary(EMPLOYEE)\\nThe result is shown in Figure 8.1(c). Notice that the tuple <‘F’, 25000> appears only \\nonce in Figure 8.1(c), even though this combination of values appears twice in the \\nEMPLOYEE relation. Duplicate elimination involves sorting or some other technique to \\ndetect duplicates and thus adds more processing. If duplicates are not eliminated, the \\nresult would be a multiset or bag of tuples rather than a set. This was not permitted in \\nthe formal relational model but is allowed in SQL (see Section 6.3).\\nThe number of tuples in a relation resulting from a \\nPROJECT operation is always \\nless than or equal to the number of tuples in R. If the projection list is a superkey of \\nR—that is, it includes some key of R—the resulting relation has the same number of \\ntuples as R. Moreover,\\nπ<list1> (π<list2>(R)) = π<list1>(R)\\nas long as <list2> contains the attributes in <list1>; otherwise, the left-hand side is \\nan incorrect expression. It is also noteworthy that commutativity does not  hold \\non PROJECT.\\nIn SQL, the PROJECT attribute list is specified in the SELECT clause of a query. For \\nexample, the following operation:\\nπSex, Salary(EMPLOYEE)\\nwould correspond to the following SQL query:\\nSELECT DISTINCT Sex, Salary\\nFROM EMPLOYEE'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 258, 'page_label': '259'}, page_content='8.1 Unary Relational Operations: SELECT and PROJECT  245\\nNotice that if we remove the keyword DISTINCT from this SQL query, then dupli-\\ncates will not be eliminated. This option is not available in the formal relational \\nalgebra, but the algebra can be extended to include this operation and allow rela-\\ntions to be multisets; we do not discuss these extensions here.\\n8.1.3 Sequences of Operations and the RENAME Operation\\nThe relations shown in Figure 8.1 that depict operation results do not have any \\nnames. In general, for most queries, we need to apply several relational algebra \\noperations one after the other. Either we can write the operations as a single  \\nrelational algebra expression by nesting the operations, or we can apply one operation \\nat a time and create intermediate result relations. In the latter case, we must give \\nnames to the relations that hold the intermediate results. For example, to retrieve \\nthe first name, last name, and salary of all employees who work in department \\nnumber 5, we must apply a \\nSELECT and a PROJECT operation. We can write a sin-\\ngle relational algebra expression, also known as an in-line expression, as follows:\\nπFname, Lname, Salary(σDno=5(EMPLOYEE))\\nFigure 8.2(a) shows the result of this in-line relational algebra expression. Alterna-\\ntively, we can explicitly show the sequence of operations, giving a name to each \\nintermediate relation, and using the assignment operation,  denoted by ← (left \\narrow), as follows:\\nDEP5_EMPS ← σDno=5(EMPLOYEE)\\nRESULT ← πFname, Lname, Salary(DEP5_EMPS)\\nIt is sometimes simpler to break down a complex sequence of operations by specify-\\ning intermediate result relations than to write a single relational algebra expression. \\nWe can also use this technique to rename the attributes in the intermediate and \\nresult relations. This can be useful in connection with more complex operations \\nsuch as \\nUNION and JOIN, as we shall see. To rename the attributes in a relation, we \\nsimply list the new attribute names in parentheses, as in the following example:\\nTEMP ← σDno=5(EMPLOYEE)\\nR(First_name, Last_name, Salary) ← πFname, Lname, Salary(TEMP)\\nThese two operations are illustrated in Figure 8.2(b).\\nIf no renaming is applied, the names of the attributes in the resulting relation of a \\nSELECT operation are the same as those in the original relation and in the same \\norder. For a PROJECT operation with no renaming, the resulting relation has the \\nsame attribute names as those in the projection list and in the same order in which \\nthey appear in the list.\\nWe can also define a formal \\nRENAME operation—which can rename either the rela-\\ntion name or the attribute names, or both—as a unary operator. The general \\nRENAME operation when applied to a relation R of degree n is denoted by any of the \\nfollowing three forms:\\nρS(B1, B2, ... , Bn)(R)   or   ρS(R)   or   ρ(B1, B2, ... , Bn)(R)'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 259, 'page_label': '260'}, page_content='246 Chapter 8 The Relational Algebra and Relational Calculus\\nwhere the symbol ρ (rho) is used to denote the RENAME operator, S is the new rela-\\ntion name, and B1, B2, … , Bn are the new attribute names. The first expression \\nrenames both the relation and its attributes, the second renames the relation only, \\nand the third renames the attributes only. If the attributes of R are (A\\n1, A2, … , An) \\nin that order, then each Ai is renamed as Bi.\\nIn SQL, a single query typically represents a complex relational algebra expression. \\nRenaming in SQL is accomplished by aliasing using AS, as in the following example:\\nSELECT E.Fname AS First_name, E.Lname AS Last_name, E.Salary AS Salary\\nFROM EMPLOYEE AS E\\nWHERE E.Dno =5,\\n8.2  Relational Algebra Operations  \\nfrom Set Theory\\n8.2.1 The UNION, INTERSECTION, and MINUS Operations\\nThe next group of relational algebra operations are the standard mathematical \\noperations on sets. For example, to retrieve the Social Security numbers of all \\n(b)\\n(a)\\nTEMP\\nFname\\nJohn\\nFranklin\\nRamesh\\nJoyce\\nMinit\\nB\\nT\\nK\\nA\\nLname\\nSmith\\nWong\\nNarayan\\nEnglish\\nSsn\\n123456789\\n333445555\\n666884444\\n453453453\\nBdate\\n1965-01-09\\n1955-12-08\\n1962-09-15\\n1972-07-31\\nAddress\\n731 Fondren, Houston,TX\\n638 Voss, Houston,TX\\n975 Fire Oak, Humble,TX\\n5631 Rice, Houston,  TX\\nSex\\nM\\nM\\nM\\nF\\nSalary\\n30000\\n40000\\n38000\\n25000\\nDno\\n5\\n5\\n5\\n5\\nSuper_ssn\\n333445555\\n888665555\\n333445555\\n333445555\\nSmith\\nWong\\nNarayan\\nEnglish\\n30000\\n40000\\n38000\\n25000\\nFname Lname Salary\\nJohn\\nFranklin\\nRamesh\\nJoyce\\nSmith\\nWong\\nNarayan\\nEnglish\\n30000\\n40000\\n38000\\n25000\\nFirst_name Last_name Salary\\nJohn\\nFranklin\\nRamesh\\nJoyce\\nR\\nFigure 8.2 \\nResults of a sequence of operations. (a) πFname, Lname, Salary (σDno=5(EMPLOYEE)).  \\n(b) Using intermediate relations and renaming of attributes.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 260, 'page_label': '261'}, page_content='8.2 Relational Algebra Operations from Set Theory  247\\nemployees who either work in department 5 or directly supervise an employee who \\nworks in department 5, we can use the UNION operation as follows:4\\nDEP5_EMPS ← σDno=5(EMPLOYEE) \\nRESULT1 ← πSsn(DEP5_EMPS) \\nRESULT2(Ssn) ← πSuper_ssn(DEP5_EMPS) \\nRESULT ← RESULT1 ∪ RESULT2\\nThe relation RESULT1 has the Ssn of all employees who work in department 5, \\nwhereas RESULT2 has the Ssn of all employees who directly supervise an employee \\nwho works in department 5. The UNION operation produces the tuples that are in \\neither RESULT1 or RESULT2 or both (see Figure 8.3) while eliminating any dupli-\\ncates. Thus, the Ssn value ‘333445555’ appears only once in the result.\\nSeveral set theoretic operations are used to merge the elements of two sets in vari-\\nous ways, including UNION, INTERSECTION , and SET DIFFERENCE  (also called \\nMINUS or EXCEPT). These are binary operations; that is, each is applied to two sets \\n(of tuples). When these operations are adapted to relational databases, the two rela-\\ntions on which any of these three operations are applied must have the same type of \\ntuples; this condition has been called union compatibility  or type compatibility . \\nTwo relations R(A1, A2, … , An) and S(B1, B2, … , Bn) are said to be union  \\ncompatible (or type compatible) if they have the same degree n and if dom( Ai) = \\ndom(Bi) for 1 ≤ i ≤ n. This means that the two relations have the same number of \\nattributes and each corresponding pair of attributes has the same domain.\\nWe can define the three operations UNION, INTERSECTION, and SET DIFFERENCE \\non two union-compatible relations R and S as follows:\\n ■ UNION: The result of this operation, denoted by R ∪ S, is a relation that \\nincludes all tuples that are either in R or in S or in both R and S. Duplicate \\ntuples are eliminated.\\n ■ INTERSECTION: The result of this operation, denoted by R ∩ S, is a relation \\nthat includes all tuples that are in both R and S.\\n ■ SET DIFFERENCE (or MINUS): The result of this operation, denoted by R – S, \\nis a relation that includes all tuples that are in R but not in S.\\n4As a single relational algebra expression, this becomes Result ← πSsn (σDno=5 (EMPLOYEE) ) ∪ \\nπSuper_ssn (σDno=5 (EMPLOYEE)).\\nRESUL T1\\nSsn\\n123456789\\n333445555\\n666884444\\n453453453\\nRESUL T\\nSsn\\n123456789\\n333445555\\n666884444\\n453453453\\n888665555\\nRESUL T2\\nSsn\\n333445555\\n888665555\\nFigure 8.3 \\nResult of the UNION operation \\nRESULT ← RESULT1 ∪ RESULT2.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 261, 'page_label': '262'}, page_content='248 Chapter 8 The Relational Algebra and Relational Calculus\\nWe will adopt the convention that the resulting relation has the same attribute \\nnames as the first relation R. It is always possible to rename the attributes in the \\nresult using the rename operator.\\nFigure 8.4 illustrates the three operations. The relations STUDENT and INSTRUCTOR \\nin Figure 8.4(a) are union compatible and their tuples represent the names of stu-\\ndents and the names of instructors, respectively. The result of the \\nUNION operation \\nin Figure 8.4(b) shows the names of all students and instructors. Note that duplicate \\ntuples appear only once in the result. The result of the \\nINTERSECTION operation \\n(Figure 8.4(c)) includes only those who are both students and instructors.\\nNotice that both UNION and INTERSECTION are commutative operations; that is,\\nR ∪ S = S ∪ R and R ∩ S = S ∩ R\\nBoth UNION and INTERSECTION can be treated as n-ary operations applicable to \\nany number of relations because both are also associative operations; that is,\\nR ∪ (S ∪ T ) = (R ∪ S) ∪ T and (R ∩ S) ∩ T = R ∩ (S ∩ T )\\nSTUDENT(a)\\nFn\\nSusan\\nRamesh\\nJohnny\\nBarbara\\nAmy\\nJimmy\\nErnest\\nLn\\nYao\\nShah\\nKohler\\nJones\\nFord\\nWang\\nGilbert\\n(b) Fn\\nSusan\\nRamesh\\nJohnny\\nBarbara\\nAmy\\nJimmy\\nErnest\\nLn\\nYao\\nShah\\nKohler\\nJones\\nFord\\nWang\\nGilbert\\nJohn Smith\\nRicardo Browne\\nFrancis Johnson\\n(d) Fn\\nJohnny\\nBarbara\\nAmy\\nJimmy\\nErnest\\nLn\\nKohler\\nJones\\nFord\\nWang\\nGilbert\\n(c)\\nFn\\nSusan\\nRamesh\\nLn\\nYao\\nShah\\nINSTRUCTOR\\nFname\\nJohn\\nRicardo\\nSusan\\nFrancis\\nRamesh\\nLname\\nSmith\\nBrowne\\nYao\\nJohnson\\nShah\\n(e) Fname\\nJohn\\nRicardo\\nFrancis\\nLname\\nSmith\\nBrowne\\nJohnson\\nFigure 8.4 \\nThe set operations UNION, INTERSECTION, and MINUS. (a) Two union-compatible relations.  \\n(b) STUDENT ∪ INSTRUCTOR. (c) STUDENT ∩ INSTRUCTOR. (d) STUDENT – INSTRUCTOR.  \\n(e) INSTRUCTOR – STUDENT.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 262, 'page_label': '263'}, page_content='8.2 Relational Algebra Operations from Set Theory  249\\nThe MINUS operation is not commutative; that is, in general,\\nR − S ≠ S − R\\nFigure 8.4(d) shows the names of students who are not instructors, and Fig- \\nure 8.4(e) shows the names of instructors who are not students.\\nNote that INTERSECTION can be expressed in terms of union and set difference as \\nfollows:\\nR ∩ S = ((R ∪ S) − (R − S)) − (S − R)\\nIn SQL, there are three operations— UNION, INTERSECT, and EXCEPT—that corre-\\nspond to the set operations described here. In addition, there are multiset opera-\\ntions (\\nUNION ALL , INTERSECT ALL , and EXCEPT ALL ) that do not eliminate \\nduplicates (see Section 6.3.4).\\n8.2.2  The CARTESIAN PRODUCT (CROSS PRODUCT) \\nOperation\\nNext, we discuss the CARTESIAN PRODUCT  operation—also known as CROSS \\nPRODUCT or CROSS JOIN—which is denoted by ×. This is also a binary set opera-\\ntion, but the relations on which it is applied do not have to be union compatible. In \\nits binary form, this set operation produces a new element by combining every \\nmember (tuple) from one relation (set) with every member (tuple) from the other \\nrelation (set). In general, the result of R(A1, A2, … , An) × S(B1, B2, … , Bm) is a rela-\\ntion Q with degree n + m attributes Q(A1, A2, … , An, B1, B2, … , Bm), in that order. \\nThe resulting relation Q has one tuple for each combination of tuples—one from R \\nand one from S. Hence, if R has nR tuples (denoted as |R| = nR), and S has nS tuples, \\nthen R × S will have nR * nS tuples.\\nThe n-ary CARTESIAN PRODUCT operation is an extension of the above concept, \\nwhich produces new tuples by concatenating all possible combinations of tuples \\nfrom n underlying relations. The CARTESIAN PRODUCT operation applied by itself \\nis generally meaningless. It is mostly useful when followed by a selection that \\nmatches values of attributes coming from the component relations. For example, \\nsuppose that we want to retrieve a list of names of each female employee’s depen-\\ndents. We can do this as follows:\\nFEMALE_EMPS ← σSex=‘F’(EMPLOYEE) \\nEMPNAMES ← πFname, Lname, Ssn(FEMALE_EMPS) \\nEMP_DEPENDENTS ← EMPNAMES × DEPENDENT \\nACTUAL_DEPENDENTS ← σSsn=Essn(EMP_DEPENDENTS) \\nRESULT ← πFname, Lname, Dependent_name(ACTUAL_DEPENDENTS)\\nThe resulting relations from this sequence of operations are shown in Figure 8.5. \\nThe EMP_DEPENDENTS relation is the result of applying the CARTESIAN PRODUCT \\noperation to EMPNAMES from Figure 8.5 with DEPENDENT from Figure 5.6. In \\nEMP_DEPENDENTS , every tuple from EMPNAMES is combined with every tuple \\nfrom DEPENDENT, giving a result that is not very meaningful (every dependent is'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 263, 'page_label': '264'}, page_content='250 Chapter 8 The Relational Algebra and Relational Calculus\\nFname\\nFEMALE_EMPS\\nAlicia\\nJennifer\\nJoyce A\\nJ\\nS\\nMinit\\nEnglish\\nZelaya\\nWallace\\nLname\\n453453453\\n999887777 3321Castle, Spring, TX\\n987654321\\nSsn\\n1972-07-31\\n1968-07-19\\n1941-06-20\\nBdate\\n5631 Rice, Houston, TX\\n291Berry, Bellaire, TX\\nF\\nF\\nF\\nAddress Sex Dno\\n25000\\n25000\\n43000\\n4\\n5\\n4\\nSalary\\n987654321\\n333445555\\n888665555\\nSuper_ssn\\nFname\\nEMPNAMES\\nAlicia\\nJennifer\\nJoyce English\\nZelaya\\nWallace\\nLname\\n453453453\\n999887777\\n987654321\\nSsn \\nFname\\nEMP_DEPENDENTS\\nAlicia\\nAlicia\\nAlicia\\nAlicia\\nAlicia\\nAlicia\\nAlicia\\nJennifer\\nJennifer\\nJennifer\\nJennifer\\nJennifer\\nJoyce\\nJennifer\\nJennifer\\nJoyce\\nJoyce\\nZelaya\\nZelaya\\nZelaya\\nZelaya\\nZelaya\\nZelaya\\nWallace\\nWallace\\nWallace\\nWallace\\nWallace\\nWallace\\nEnglish\\nZelaya\\nEnglish\\nWallace\\nEnglish\\nLname\\n999887777\\n999887777 Alice\\n999887777\\nSsn\\n333445555\\n333445555\\n333445555\\nEssn\\nAbner\\nTheodore\\nJoy\\nF\\nF\\nM\\nDependent_name Sex . . .\\n. . .\\n. . .\\n. . .\\n1986-04-05\\n1958-05-03\\n1983-10-25\\n999887777\\n999887777\\nMichael999887777\\n123456789\\n987654321\\n123456789\\nElizabeth\\nAlice\\nM\\nF\\nM\\n. . .\\n. . .\\n. . .\\n1942-02-28\\n1988-12-30\\n1988-01-04\\n987654321\\n999887777\\nAlice987654321\\n333445555\\n123456789\\n333445555\\nJoy\\nTheodore\\nF\\nM\\nF\\n. . .\\n. . .\\n. . .\\n1967-05-05\\n1983-10-25\\n1986-04-05\\n987654321\\n987654321\\nAbner987654321\\n123456789\\n333445555\\n987654321\\nAlice\\nMichael\\nF\\nM\\nM\\n. . .\\n. . .\\n. . .\\n1958-05-03\\n1988-01-04\\n1942-02-28\\n453453453\\n987654321\\nElizabeth987654321\\n333445555\\n123456789\\n123456789\\nTheodore\\nAlice\\nF\\nF\\nF\\n. . .\\n. . .\\n. . .\\n1988-12-30\\n1986-04-05\\n1967-05-05\\n453453453\\nJoy453453453\\n333445555\\n333445555\\nM\\nF\\n. . .\\n. . .\\n1983-10-25\\n1958-05-03\\nBdate\\nJoyce\\nJoyce\\nJoyce\\nJoyce\\nEnglish\\nEnglish\\nEnglish\\nEnglish\\n453453453\\nAbner453453453\\n123456789\\n987654321\\nAlice\\nMichael M\\nM\\n. . .\\n. . .\\n1988-01-04\\n1942-02-28\\n453453453\\nElizabeth453453453\\n123456789\\n123456789\\nF\\nF\\n. . .\\n. . .\\n1988-12-30\\n1967-05-05\\nFname\\nACTUAL_DEPENDENTS\\nLname Ssn Essn Dependent_name Sex . . .Bdate\\nJennifer Wallace Abner987654321 987654321 M . . .1942-02-28\\nFname\\nRESUL T\\nLname Dependent_name\\nJennifer Wallace Abner\\nFigure 8.5 \\nThe CARTESIAN PRODUCT (CROSS PRODUCT) operation.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 264, 'page_label': '265'}, page_content='8.3 Binary Relational Operations: JOIN and DIVISION  251\\ncombined with every female employee). We want to combine a female employee \\ntuple only with her particular dependents—namely, the DEPENDENT tuples whose \\nEssn value match the Ssn value of the EMPLOYEE tuple. The ACTUAL_DEPENDENTS \\nrelation accomplishes this. The EMP_DEPENDENTS relation is a good example of \\nthe case where relational algebra can be correctly applied to yield results that make \\nno sense at all. It is the responsibility of the user to make sure to apply only mean-\\ningful operations to relations.\\nThe \\nCARTESIAN PRODUCT creates tuples with the combined attributes of two rela-\\ntions. We can SELECT related tuples only  from the two relations by specifying an \\nappropriate selection condition after the Cartesian product, as we did in the pre-\\nceding example. Because this sequence of \\nCARTESIAN PRODUCT  followed by \\nSELECT is quite commonly used to combine related tuples  from two relations, a \\nspecial operation, called JOIN, was created to specify this sequence as a single opera-\\ntion. We discuss the JOIN operation next.\\nIn SQL, CARTESIAN PRODUCT can be realized by using the CROSS JOIN option in \\njoined tables (see Section 7.1.6). Alternatively, if there are two tables in the FROM \\nclause and there is no corresponding join condition in the WHERE clause of the \\nSQL query, the result will also be the CARTESIAN PRODUCT of the two tables (see \\nQ10 in Section 6.3.3).\\n8.3  Binary Relational Operations:  \\nJOIN and DIVISION\\n8.3.1 The JOIN Operation\\nThe JOIN operation, denoted by , is used to combine related tuples from two rela-\\ntions into single “longer” tuples. This operation is very important for any relational \\ndatabase with more than a single relation because it allows us to process relation-\\nships among relations. To illustrate JOIN, suppose that we want to retrieve the name \\nof the manager of each department. To get the manager’s name, we need to com-\\nbine each department tuple with the employee tuple whose Ssn value matches the \\nMgr_ssn value in the department tuple. We do this by using the JOIN operation and \\nthen projecting the result over the necessary attributes, as follows:\\nDEPT_MGR ← DEPARTMENT  Mgr_ssn=Ssn EMPLOYEE \\nRESULT ← πDname, Lname, Fname(DEPT_MGR)\\nThe first operation is illustrated in Figure 8.6. Note that Mgr_ssn is a foreign key of \\nthe DEPARTMENT relation that references Ssn, the primary key of the EMPLOYEE \\nrelation. This referential integrity constraint plays a role in having matching tuples \\nin the referenced relation \\nEMPLOYEE.\\nThe JOIN operation can be specified as a CARTESIAN PRODUCT  operation fol-\\nlowed by a SELECT  operation. However, JOIN is very important because it is \\nused frequently when specifying database queries. Consider the earlier example'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 265, 'page_label': '266'}, page_content='252 Chapter 8 The Relational Algebra and Relational Calculus\\nillustrating CARTESIAN PRODUCT , which included the following sequence of \\noperations:\\nEMP_DEPENDENTS ← EMPNAMES × DEPENDENT \\nACTUAL_DEPENDENTS ← σSsn=Essn(EMP_DEPENDENTS)\\nThese two operations can be replaced with a single JOIN operation as follows:\\nACTUAL_DEPENDENTS ← EMPNAMES  Ssn=EssnDEPENDENT\\nThe general form of a JOIN operation on two relations 5 R(A1, A2, … , An) and \\nS(B1, B2, … , Bm) is\\nR  <join condition>S\\nThe result of the JOIN is a relation Q with n + m attributes Q(A1, A2, … , An, B1, B2, \\n… , Bm) in that order; Q has one tuple for each combination of tuples—one from \\nR and one from S—whenever the combination satisfies the join condition . This is \\nthe main difference between CARTESIAN PRODUCT and JOIN. In JOIN, only combi-\\nnations of tuples satisfying the join condition  appear in the result, whereas in the \\nCARTESIAN PRODUCT  all combinations of tuples are included in the result. The \\njoin condition is specified on attributes from the two relations R and S and is \\nevaluated for each combination of tuples. Each tuple combination for which the \\njoin condition evaluates to TRUE is included in the resulting relation Q as a single \\ncombined tuple .\\nA general join condition is of the form\\n<condition> AND <condition> AND … AND <condition>\\nwhere each <condition> is of the form Ai θ Bj, Ai is an attribute of R, Bj is an attri-\\nbute of S, Ai and Bj have the same domain, and θ (theta) is one of the comparison \\noperators {=, <, ≤, >, ≥, ≠}. A JOIN operation with such a general join condition is \\ncalled a THETA JOIN. Tuples whose join attributes are NULL or for which the join \\ncondition is FALSE do not appear in the result. In that sense, the JOIN operation \\ndoes not necessarily preserve all of the information in the participating relations, \\nbecause tuples that do not get combined with matching ones in the other relation \\ndo not appear in the result.\\nDEPT_MGR\\nDname Dnumber Mgr_ssn Fname Minit Lname Ssn\\nResearch 5 333445555 Franklin T Wong 333445555\\nAdministration 4 987654321 Jennifer S Wallace 987654321\\nHeadquarters 1 888665555 James E Borg 888665555\\n. . . . . .\\n. . .\\n. . .\\n. . .\\n. . .\\n. . .\\n. . .\\nFigure 8.6 \\nResult of the JOIN operation DEPT_MGR ← DEPARTMENT  Mgr_ssn=SsnEMPLOYEE.\\n5Again, notice that R and S can be any relations that result from general relational algebra expressions.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 266, 'page_label': '267'}, page_content='8.3 Binary Relational Operations: JOIN and DIVISION  253\\n8.3.2 Variations of JOIN: The EQUIJOIN and NATURAL JOIN\\nThe most common use of JOIN involves join conditions with equality comparisons \\nonly. Such a JOIN, where the only comparison operator used is =, is called an \\nEQUIJOIN. Both previous examples were EQUIJOINs. Notice that in the result of an \\nEQUIJOIN we always have one or more pairs of attributes that have identical values \\nin every tuple. For example, in Figure 8.6, the values of the attributes Mgr_ssn and \\nSsn are identical in every tuple of DEPT_MGR (the EQUIJOIN result) because the \\nequality join condition specified on these two attributes requires the values to be \\nidentical in every tuple in the result. Because one of each pair of attributes with \\nidentical values is superfluous, a new operation called NATURAL JOIN —denoted  \\nby *—was created to get rid of the second (superfluous) attribute in an EQUIJOIN \\ncondition. 6 The standard definition of NATURAL JOIN  requires that the two join \\nattributes (or each pair of join attributes) have the same name in both relations. If \\nthis is not the case, a renaming operation is applied first.\\nSuppose we want to combine each \\nPROJECT tuple with the DEPARTMENT tuple that \\ncontrols the project. In the following example, first we rename the Dnumber attribute \\nof DEPARTMENT to Dnum—so that it has the same name as the Dnum attribute in \\nPROJECT—and then we apply NATURAL JOIN:\\nPROJ_DEPT ← PROJECT * ρ(Dname, Dnum, Mgr_ssn, Mgr_start_date)(DEPARTMENT)\\nThe same query can be done in two steps by creating an intermediate table DEPT \\nas follows:\\nDEPT ← ρ(Dname, Dnum, Mgr_ssn, Mgr_start_date)(DEPARTMENT) \\nPROJ_DEPT ← PROJECT * DEPT\\nThe attribute Dnum is called the join attribute  for the NATURAL JOIN  operation, \\nbecause it is the only attribute with the same name in both relations. The resulting \\nrelation is illustrated in Figure 8.7(a). In the \\nPROJ_DEPT relation, each tuple combines \\na PROJECT tuple with the DEPARTMENT tuple for the department that controls the \\nproject, but only one join attribute value is kept.\\nIf the attributes on which the natural join is specified already have the same names \\nin both relations , renaming is unnecessary. For example, to apply a natural join \\non the Dnumber attributes of DEPARTMENT and DEPT_LOCATIONS , it is sufficient \\nto write\\nDEPT_LOCS ← DEPARTMENT * DEPT_LOCATIONS\\nThe resulting relation is shown in Figure 8.7(b), which combines each department \\nwith its locations and has one tuple for each location. In general, the join condition \\nfor \\nNATURAL JOIN is constructed by equating each pair of join attributes  that have \\nthe same name in the two relations and combining these conditions with AND. \\nThere can be a list of join attributes from each relation, and each corresponding \\npair must have the same name.\\n6NATURAL JOIN is basically an EQUIJOIN followed by the removal of the superfluous attributes.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 267, 'page_label': '268'}, page_content='254 Chapter 8 The Relational Algebra and Relational Calculus\\nNotice that if no combination of tuples satisfies the join condition, the result of a \\nJOIN is an empty relation with zero tuples. In general, if R has nR tuples and S has \\nnS tuples, the result of a JOIN operation R  <join condition> S will have between zero \\nand nR * nS tuples. The expected size of the join result divided by the maximum \\nsize nR * nS leads to a ratio called join selectivity, which is a property of each join \\ncondition. If there is no join condition, all combinations of tuples qualify and the \\nJOIN degenerates into a CARTESIAN PRODUCT , also called CROSS PRODUCT  or \\nCROSS JOIN.\\nAs we can see, a single JOIN operation is used to combine data from two relations so \\nthat related information can be presented in a single table. These operations are \\nalso known as inner joins, to distinguish them from a different join variation called \\nouter joins  (see Section 8.4.4). Informally, an inner join  is a type of match-and-\\ncombine operation defined formally as a combination of \\nCARTESIAN PRODUCT  \\nand SELECTION. Note that sometimes a join may be specified between a relation \\nand itself, as we will illustrate in Section 8.4.3. The NATURAL JOIN  or EQUIJOIN \\noperation can also be specified among multiple tables, leading to an n-way join. For \\nexample, consider the following three-way join:\\n((PROJECT  Dnum=DnumberDEPARTMENT)  Mgr_ssn=SsnEMPLOYEE)\\nPname\\nPROJ_DEPT\\n(a)\\nProductX\\nProductY\\nProductZ\\nComputerization\\nReorganization\\nNewbenefits\\n3\\n1\\n2\\n30\\n10\\n20\\nPnumber\\nHouston\\nBellaire\\nSugarland\\nStafford\\nStafford\\nHouston\\nPlocation\\n5\\n5 333445555\\n5\\n4\\n4\\n1\\nDnum\\nResearch\\nResearch\\nResearch\\nAdministration\\nAdministration\\nHeadquarters\\nDname\\n333445555\\n333445555\\n987654321\\n987654321\\n888665555\\n1988-05-22\\n1988-05-22\\n1988-05-22\\n1995-01-01\\n1995-01-01\\n1981-06-19\\nMgr_ssn Mgr_start_date\\nDname\\nDEPT_LOCS\\n(b)\\n5\\n1\\n4\\n5\\n5\\nDnumber\\n333445555\\n888665555\\n987654321\\n333445555\\n333445555\\nMgr_ssn\\n1988-05-22\\n1981-06-19\\n1995-01-01\\nResearch\\nResearch\\nResearch\\nAdministration\\n1988-05-22\\n1988-05-22\\nHeadquarters Houston\\nBellaire\\nStafford\\nSugarland\\nHouston\\nLocationMgr_start_date\\nFigure 8.7 \\nResults of two natural join operations. (a) proj_dept ← project * dept.  \\n(b) dept_locs ← department * dept_locations.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 268, 'page_label': '269'}, page_content='8.3 Binary Relational Operations: JOIN and DIVISION  255\\nThis combines each project tuple with its controlling department tuple into a single \\ntuple, and then combines that tuple with an employee tuple that is the department \\nmanager. The net result is a consolidated relation in which each tuple contains this \\nproject-department-manager combined information.\\nIn SQL, \\nJOIN can be realized in several different ways. The first method is to specify \\nthe <join conditions> in the WHERE clause, along with any other selection condi-\\ntions. This is very common and is illustrated by queries Q1, Q1A, Q1B, Q2, and Q8 \\nin Sections 6.3.1 and 6.3.2, as well as by many other query examples in Chapters 6 \\nand 7. The second way is to use a nested relation, as illustrated by queries \\nQ4A \\nand Q16 in Section 7.1.2. Another way is to use the concept of joined tables, as \\nillustrated by the queries Q1A, Q1B, Q8B, and Q2A in Section 7.1.6. The construct \\nof joined tables was added to SQL2 to allow the user to specify explicitly all the \\nvarious types of joins, because the other methods were more limited. It also allows \\nthe user to clearly distinguish join conditions from the selection conditions in the \\nWHERE clause.\\n8.3.3 A Complete Set of Relational Algebra Operations\\nIt has been shown that the set of relational algebra operations { σ, π, ∪, ρ, –, ×} is a \\ncomplete set; that is, any of the other original relational algebra operations can be \\nexpressed as a sequence of operations from this set. For example, the INTERSECTION \\noperation can be expressed by using UNION and MINUS as follows:\\nR ∩ S ≡ (R ∪ S) – ((R – S) ∪ (S – R))\\nAlthough, strictly speaking, INTERSECTION is not required, it is inconvenient to \\nspecify this complex expression every time we wish to specify an intersection. As \\nanother example, a \\nJOIN operation can be specified as a CARTESIAN PRODUCT fol-\\nlowed by a SELECT operation, as we discussed:\\nR  <condition>S ≡ σ<condition>(R × S)\\nSimilarly, a NATURAL JOIN can be specified as a CARTESIAN PRODUCT preceded by \\nRENAME and followed by SELECT and PROJECT operations. Hence, the various \\nJOIN operations are also not strictly necessary for the expressive power of the rela-\\ntional algebra. However, they are important to include as separate operations \\nbecause they are convenient to use and are very commonly applied in database \\napplications. Other operations have been included in the basic relational algebra \\nfor convenience rather than necessity. We discuss one of these—the \\nDIVISION  \\noperation—in the next section.\\n8.3.4 The DIVISION Operation\\nThe DIVISION  operation, denoted by ÷, is useful for a special kind of query that \\nsometimes occurs in database applications. An example is Retrieve the names of \\nemployees who work on  all the projects that ‘John Smith’ works on . To express \\nthis query using the DIVISION  operation, proceed as follows. First, retrieve the'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 269, 'page_label': '270'}, page_content='256 Chapter 8 The Relational Algebra and Relational Calculus\\nlist of project numbers that ‘John Smith’ works on in the intermediate relation \\nSMITH_PNOS :\\nSMITH ← σFname=‘John’ AND Lname=‘Smith’(EMPLOYEE) \\nSMITH_PNOS ← πPno(WORKS_ON  Essn=SsnSMITH)\\nNext, create a relation that includes a tuple < Pno, Essn> whenever the employee \\nwhose Ssn is Essn works on the project whose number is Pno in the intermediate \\nrelation SSN_PNOS:\\nSSN_PNOS ← πEssn, Pno(WORKS_ON)\\nFinally, apply the DIVISION operation to the two relations, which gives the desired \\nemployees’ Social Security numbers:\\nSSNS(Ssn) ← SSN_PNOS ÷ SMITH_PNOS \\nRESULT ← πFname, Lname(SSNS * EMPLOYEE)\\nThe preceding operations are shown in Figure 8.8(a).\\nIn general, the \\nDIVISION operation is applied to two relations R(Z) ÷ S(X), where the \\nattributes of S are a subset of the attributes of R; that is, X ⊆ Z. Let Y be the set of \\nattributes of R that are not attributes of S; that is, Y = Z – X (and hence Z = X ∪ Y). \\nEssn\\nSSN_PNOS\\n(a)\\n123456789\\n123456789\\n666884444\\n453453453\\n453453453\\n333445555\\n333445555\\n333445555\\n333445555\\n999887777\\n999887777\\n987987987\\n987987987\\n987654321\\n987654321\\n888665555\\n3\\n1\\n2\\n2\\n1\\n2\\n30\\n30\\n30\\n10\\n10\\n3\\n10\\n20\\n20\\n20\\nPno\\nA\\nR\\n(b)\\na1\\na2\\na3\\na4\\na1\\na3\\na2\\na3\\na4\\na1\\na2\\na3\\nb1\\nb1\\nb1\\nb2\\nb1\\nb2\\nb4\\nb4\\nb4\\nb3\\nb3\\nb3\\nB\\nSMITH_PNOS\\n1\\n2\\nPno\\nS\\na1\\na2\\na3\\nA\\nT\\nb1\\nb4\\nB\\nSSNS\\n123456789\\n453453453\\nSsn\\nFigure 8.8 \\nThe DIVISION operation. (a) Dividing SSN_PNOS by SMITH_PNOS. (b) T ← R ÷ S.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 270, 'page_label': '271'}, page_content='8.3 Binary Relational Operations: JOIN and DIVISION  257\\nThe result of DIVISION is a relation T(Y) that includes a tuple t if tuples tR appear in \\nR with tR [Y] = t, and with tR [X] = tS for every tuple tS in S. This means that, for a \\ntuple t to appear in the result T of the DIVISION, the values in t must appear in R in \\ncombination with every tuple  in S. Note that in the formulation of the DIVISION \\noperation, the tuples in the denominator relation S restrict the numerator rela-\\ntion R by selecting those tuples in the result that match all values present in the \\ndenominator. It is not necessary to know what those values are as they can be \\ncomputed by another operation, as illustrated in the \\nSMITH_PNOS  relation in \\nthe previous example.\\nFigure 8.8(b) illustrates a DIVISION operation where X = {A}, Y = {B}, and Z = {A, B}. \\nNotice that the tuples (values) b1 and b4 appear in R in combination with all three \\ntuples in S; that is why they appear in the resulting relation T. All other values of B \\nin R do not appear with all the tuples in S and are not selected: b2 does not appear \\nwith a2, and b3 does not appear with a1.\\nThe DIVISION operation can be expressed as a sequence of π, ×, and – operations as \\nfollows:\\nT1 ← πY(R) \\nT2 ← πY((S × T1) – R) \\nT ← T1 – T2\\nThe DIVISION operation is defined for convenience for dealing with queries that \\ninvolve universal quantification  (see Section 8.6.7) or the all condition. Most \\nRDBMS implementations with SQL as the primary query language do not directly \\nimplement division. SQL has a roundabout way of dealing with the type of query \\njust illustrated (see Section 7.1.4, queries Q3A and Q3B). Table 8.1 lists the various \\nbasic relational algebra operations we have discussed.\\n8.3.5 Notation for Query Trees\\nIn this section we describe a notation typically used in relational DBMSs (RDBMSs) \\nto represent queries internally. The notation is called a query tree or sometimes it is \\nknown as a query evaluation tree or query execution tree. It includes the relational \\nalgebra operations being executed and is used as a possible data structure for the \\ninternal representation of the query in an RDBMS.\\nA query tree is a tree data structure that corresponds to a relational algebra expres-\\nsion. It represents the input relations of the query as leaf nodes of the tree, and rep-\\nresents the relational algebra operations as internal nodes. An execution of the \\nquery tree consists of executing an internal node operation whenever its operands \\n(represented by its child nodes) are available, and then replacing that internal node \\nby the relation that results from executing the operation. The execution terminates \\nwhen the root node is executed and produces the result relation for the query.\\nFigure 8.9 shows a query tree for Query 2 (see Section 6.3.1): For every project \\nlocated in ‘Stafford’, list the project number, the controlling department number, and \\nthe department manager’s last name, address, and birth date. This query is specified'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 271, 'page_label': '272'}, page_content='258 Chapter 8 The Relational Algebra and Relational Calculus\\nTable 8.1  Operations of Relational Algebra\\nOPERATION PURPOSE NOTATION\\nSELECT Selects all tuples that satisfy the selection  \\ncondition from a relation R.\\nσ<selection condition>(R)\\nPROJECT Produces a new relation with only some of the \\nattributes of R, and removes duplicate tuples.\\nπ<attribute list>(R)\\nTHETA JOIN Produces all combinations of tuples from R1  \\nand R2 that satisfy the join condition.\\nR1  <join condition> R2\\nEQUIJOIN Produces all the combinations of tuples from  \\nR1 and R2 that satisfy a join condition with  \\nonly equality comparisons.\\nR1  <join condition> R2, OR \\nR1  (<join attributes 1>),  \\n(<join attributes 2>) R2\\nNATURAL JOIN Same as EQUIJOIN except that the join attributes \\nof R2 are not included in the resulting relation;  \\nif the join attributes have the same names, they \\ndo not have to be specified at all.\\nR\\n1*<join condition> R2,  \\nOR R1* (<join attributes 1>),  \\n(<join attributes 2>)  \\nR2 OR R1 * R2\\nUNION Produces a relation that includes all the tuples  \\nin R1 or R2 or both R1 and R2; R1 and R2 must  \\nbe union compatible.\\nR1 ∪ R2\\nINTERSECTION Produces a relation that includes all the tuples  \\nin both R1 and R2; R1 and R2 must be union \\ncompatible.\\nR1 ∩ R2\\nDIFFERENCE Produces a relation that includes all the tuples  \\nin R1 that are not in R2; R1 and R2 must be  \\nunion compatible.\\nR1 – R2\\nCARTESIAN PRODUCT Produces a relation that has the attributes of  \\nR1 and R2 and includes as tuples all possible \\ncombinations of tuples from R1 and R2.\\nR1 × R2\\nDIVISION Produces a relation R(X) that includes all tuples \\nt[X] in R1(Z) that appear in R1 in combination \\nwith every tuple from R2(Y), where Z = X ∪ Y.\\nR1(Z) ÷ R2(Y)\\non the relational schema of Figure 5.5 and corresponds to the following relational \\nalgebra expression:\\nπPnumber, Dnum, Lname, Address, Bdate(((σPlocation=‘Stafford’(PROJECT))  \\n Dnum=Dnumber(DEPARTMENT))  Mgr_ssn=Ssn(EMPLOYEE))\\nIn Figure 8.9, the three leaf nodes P, D, and E represent the three relations PROJECT, \\nDEPARTMENT, and EMPLOYEE. The relational algebra operations in the expression are \\nrepresented by internal tree nodes. The query tree signifies an explicit order of execu-\\ntion in the following sense. In order to execute \\nQ2, the node marked (1) in Figure 8.9 \\nmust begin execution before node (2) because some resulting tuples of opera- \\ntion (1) must be available before we can begin to execute operation (2). Similarly,'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 272, 'page_label': '273'}, page_content='8.4 Additional Relational Operations  259\\nnode (2) must begin to execute and produce results before node (3) can start execution, \\nand so on. In general, a query tree gives a good visual representation and understand-\\ning of the query in terms of the relational operations it uses and is recommended as \\nan additional means for expressing queries in relational algebra. We will revisit query \\ntrees when we discuss query processing and optimization in Chapters 18 and 19.\\n8.4 Additional Relational Operations\\nSome common database requests—which are needed in commercial applications \\nfor RDBMSs—cannot be performed with the original relational algebra operations \\ndescribed in Sections 8.1 through 8.3. In this section we define additional opera-\\ntions to express these requests. These operations enhance the expressive power of \\nthe original relational algebra.\\n8.4.1 Generalized Projection\\nThe generalized projection operation extends the projection operation by allowing \\nfunctions of attributes to be included in the projection list. The generalized form \\ncan be expressed as:\\nπ\\nF1, F2, ..., Fn (R)\\nwhere F1, F2, … , Fn are functions over the attributes in relation R and may involve \\narithmetic operations and constant values. This operation is helpful when devel-\\noping reports where computed values have to be produced in the columns of a \\nquery result.\\nFigure 8.9 \\nQuery tree corresponding \\nto the relational algebra \\nexpression for Q2.\\n(1)\\n(2)\\n(3)\\nP.Pnumber,P.Dnum,E.Lname,E.Address,E.Bdateπ\\nD.Mgr_ssn=E.Ssn\\nP.Dnum=D.Dnumber\\nσ P.Plocation= ‘Stafford’\\nE\\nD\\nP\\nEMPLOYEE\\nDEPARTMENT\\nPROJECT'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 273, 'page_label': '274'}, page_content='260 Chapter 8 The Relational Algebra and Relational Calculus\\nAs an example, consider the relation\\nEMPLOYEE (Ssn, Salary, Deduction, Years_service)\\nA report may be required to show\\nNet Salary = Salary – Deduction, \\nBonus = 2000 * Years_service, and \\nTax = 0.25 * Salary\\nThen a generalized projection combined with renaming may be used as follows:\\nREPORT ← ρ(Ssn, Net_salary, Bonus, Tax)(πSsn, Salary – Deduction, 2000 * Years_service,  \\n0.25 * Salary(EMPLOYEE))\\n8.4.2 Aggregate Functions and Grouping\\nAnother type of request that cannot be expressed in the basic relational algebra is \\nto specify mathematical aggregate functions  on collections of values from the \\ndatabase. Examples of such functions include retrieving the average or total salary \\nof all employees or the total number of employee tuples. These functions are used \\nin simple statistical queries that summarize information from the database \\ntuples. Common functions applied to collections of numeric values include \\nSUM, \\nAVERAGE, MAXIMUM, and MINIMUM. The COUNT function is used for counting \\ntuples or values.\\nAnother common type of request involves grouping the tuples in a relation by the \\nvalue of some of their attributes and then applying an aggregate function indepen-\\ndently to each group . An example would be to group EMPLOYEE tuples by Dno, so \\nthat each group includes the tuples for employees working in the same department. \\nWe can then list each \\nDno value along with, say, the average salary of employees \\nwithin the department, or the number of employees who work in the department.\\nWe can define an AGGREGATE FUNCTION  operation, using the symbol I (pro-\\nnounced script F)7, to specify these types of requests as follows:\\n<grouping attributes> ℑ <function list> (R)\\nwhere <grouping attributes> is a list of attributes of the relation specified in R, and \\n<function list> is a list of (<function> <attribute>) pairs. In each such pair, <function> \\nis one of the allowed functions—such as \\nSUM, AVERAGE, MAXIMUM, MINIMUM, \\nCOUNT—and <attribute> is an attribute of the relation specified by R. The resulting \\nrelation has the grouping attributes plus one attribute for each element in the function \\nlist. For example, to retrieve each department number, the number of employees in \\nthe department, and their average salary, while renaming the resulting attributes as \\nindicated below, we write:\\nρ\\nR(Dno, No_of_employees, Average_sal) (Dno ℑ COUNT Ssn, AVERAGE Salary (EMPLOYEE))\\n7There is no single agreed-upon notation for specifying aggregate functions. In some cases a “script A” \\nis used.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 274, 'page_label': '275'}, page_content='8.4 Additional Relational Operations  261\\nThe result of this operation on the EMPLOYEE relation of Figure 5.6 is shown in \\nFigure 8.10(a).\\nIn the preceding example, we specified a list of attribute names—between parenthe-\\nses in the RENAME operation—for the resulting relation R. If no renaming is applied, \\nthen the attributes of the resulting relation that correspond to the function list will \\neach be the concatenation of the function name with the attribute name in the form \\n<function>_<attribute>.8 For example, Figure 8.10(b) shows the result of the fol-\\nlowing operation:\\nDno ℑ COUNT Ssn, AVERAGE Salary(EMPLOYEE)\\nIf no grouping attributes are specified, the functions are applied to all the tuples   \\nin the relation, so the resulting relation has a single tuple only . For example, Fig- \\nure 8.10(c) shows the result of the following operation:\\nℑ COUNT Ssn, AVERAGE Salary(EMPLOYEE)\\nIt is important to note that, in general, duplicates are not eliminated  when an \\naggregate function is applied; this way, the normal interpretation of functions such \\nas \\nSUM and AVERAGE is computed.9 However, NULL values are not considered in \\nthe aggregation, as we discussed in Section 7.1.7. It is worth emphasizing that the \\nresult of applying an aggregate function is a relation, not a scalar number—even \\nif it has a single value. This makes the relational algebra a closed mathematical \\nsystem.\\n8Note that this is an arbitrary notation, consistent with what SQL would do.\\n9In SQL, the option of eliminating duplicates before applying the aggregate function is available by \\nincluding the keyword DISTINCT (see Section Section 4.4.4).\\nCount_ssn\\n8 35125\\nDno Count_ssn\\n5\\n4\\n1\\n4\\n3\\n1\\n33250\\n31000\\n55000\\nAverage_salary\\nAverage_salary\\n(b)\\n(c)\\n4\\n3\\n1\\n33250\\n31000\\n55000\\n(a) Dno\\n5\\n4\\n1\\nNo_of_employees Average_sal\\nR\\nFigure 8.10 \\nThe aggregate function operation.\\na. ρR(Dno, No_of_employees, Average_sal)(Dno ℑ COUNT Ssn, AVERAGE Salary (EMPLOYEE)).\\nb. Dno ℑ COUNT Ssn, AVERAGE Salary(EMPLOYEE).\\nc. ℑ COUNT Ssn, AVERAGE Salary(EMPLOYEE).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 275, 'page_label': '276'}, page_content='262 Chapter 8 The Relational Algebra and Relational Calculus\\n8.4.3 Recursive Closure Operations\\nAnother type of operation that, in general, cannot be specified in the basic original \\nrelational algebra is recursive closure.  This operation is applied to a recursive  \\nrelationship between tuples of the same type, such as the relationship between an \\nemployee and a supervisor. This relationship is described by the foreign key  \\nSuper_ssn  of the EMPLOYEE relation in Figures 5.5 and 5.6, and it relates each \\nemployee tuple (in the role of supervisee) to another employee tuple (in the role of \\nsupervisor). An example of a recursive operation is to retrieve all supervisees of an \\nemployee e at all levels—that is, all employees e′ directly supervised by e, all employ-\\nees e′ℑ directly supervised by each employee e′, all employees e″′ directly super-\\nvised by each employee e″, and so on.\\nIt is relatively straightforward in the relational algebra to specify all employees \\nsupervised by e at a specific level  by joining the table with itself one or more \\ntimes. However, it is difficult to specify all supervisees at all levels. For example, \\nto specify the \\nSsns of all employees e′ directly supervised— at level one— by the \\nemployee e whose name is ‘James Borg’ (see Figure 5.6), we can apply the follow-\\ning operation:\\nBORG_SSN ← πSsn(σFname=‘James’ AND Lname=‘Borg’(EMPLOYEE)) \\nSUPERVISION(Ssn1, Ssn2) ← πSsn,Super_ssn(EMPLOYEE) \\nRESULT1(Ssn) ← πSsn1(SUPERVISION  Ssn2=SsnBORG_SSN)\\nTo retrieve all employees supervised by Borg at level 2—that is, all employees e″ \\nsupervised by some employee e′ who is directly supervised by Borg—we can apply \\nanother JOIN to the result of the first query, as follows:\\nRESULT2(Ssn) ← πSsn1(SUPERVISION  Ssn2=SsnRESULT1)\\nTo get both sets of employees supervised at levels 1 and 2 by ‘James Borg’, we can \\napply the UNION operation to the two results, as follows:\\nRESULT ← RESULT2 ∪ RESULT1\\nThe results of these queries are illustrated in Figure 8.11. Although it is possible to \\nretrieve employees at each level and then take their UNION, we cannot, in general, \\nspecify a query such as “retrieve the supervisees of ‘James Borg’ at all levels” without \\nutilizing a looping mechanism unless we know the maximum number of levels.\\n10 \\nAn operation called the transitive closure of relations has been proposed to com-\\npute the recursive relationship as far as the recursion proceeds.\\n8.4.4 OUTER JOIN Operations\\nNext, we discuss some additional extensions to the JOIN operation that are nec-\\nessary to specify certain types of queries. The JOIN operations described earlier \\nmatch tuples that satisfy the join condition. For example, for a NATURAL JOIN  \\n10The SQL3 standard includes syntax for recursive closure.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 276, 'page_label': '277'}, page_content='8.4 Additional Relational Operations  263\\noperation R * S, only tuples from R that have matching tuples in S—and vice \\nversa—appear in the result. Hence, tuples without a matching  (or related) tuple \\nare eliminated from the JOIN result. Tuples with NULL values in the join attri-\\nbutes are also eliminated. This type of join, where tuples with no match are elim-\\ninated, is known as an inner join . The join operations we described earlier in \\nSection 8.3 are all inner joins. This amounts to the loss of information if the user \\nwants the result of the \\nJOIN to include all the tuples in one or more of the com-\\nponent relations.\\nA set of operations, called outer joins, were developed for the case where the user \\nwants to keep all the tuples in R, or all those in S, or all those in both relations in \\nthe result of the JOIN, regardless of whether or not they have matching tuples in \\nthe other relation. This satisfies the need of queries in which tuples from two \\ntables are to be combined by matching corresponding rows, but without losing \\nany tuples for lack of matching values. For example, suppose that we want a list of \\nall employee names as well as the name of the departments they manage if they \\nhappen to manage a department ; if they do not manage one, we can indicate it \\nSUPERVISION\\nSsn1 Ssn2\\n123456789\\n333445555\\n999887777\\n987654321\\n666884444\\n453453453\\n987987987\\n888665555\\n333445555\\n888665555\\n987654321\\n888665555\\n333445555\\n333445555\\n987654321\\nnull\\n(Borg’s Ssn is 888665555)\\n(Ssn) (Super_ssn)\\nRESULT1\\nSsn\\n333445555\\n987654321\\n(Supervised by Borg)\\nRESULT\\nSsn\\n123456789\\n999887777\\n666884444\\n453453453\\n987987987\\n333445555\\n987654321\\n(RESULT1 ∪ RESULT2)\\nRESULT2\\nSsn\\n123456789\\n999887777\\n666884444\\n453453453\\n987987987\\n(Supervised by\\nBorg’s subordinates) Figure 8.11 \\nA two-level recursive \\nquery.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 277, 'page_label': '278'}, page_content='264 Chapter 8 The Relational Algebra and Relational Calculus\\nwith a NULL value. We can apply an operation LEFT OUTER JOIN, denoted by , to \\nretrieve the result as follows:\\nTEMP ← (EMPLOYEE  Ssn=Mgr_ssnDEPARTMENT) \\nRESULT ← πFname, Minit, Lname, Dname(TEMP)\\nThe LEFT OUTER JOIN operation keeps every tuple in the first, or left, relation R in R  S; \\nif no matching tuple is found in S, then the attributes of S in the join result are filled or \\npadded with NULL values. The result of these operations is shown in Figure 8.12.\\nA similar operation, RIGHT OUTER JOIN , denoted by , keeps every tuple in the \\nsecond, or right, relation S in the result of R  S. A third operation, FULL OUTER \\nJOIN, denoted by , keeps all tuples in both the left and the right relations when no \\nmatching tuples are found, padding them with NULL values as needed. The three \\nouter join operations are part of the SQL2 standard (see Section 7.1.6). These oper-\\nations were provided later as an extension of relational algebra in response to the \\ntypical need in business applications to show related information from multiple \\ntables exhaustively. Sometimes a complete reporting of data from multiple tables is \\nrequired whether or not there are matching values.\\n8.4.5 The OUTER UNION Operation\\nThe OUTER UNION operation was developed to take the union of tuples from two \\nrelations that have some common attributes, but are not union (type) compatible . \\nThis operation will take the UNION of tuples in two relations R(X, Y) and S(X, Z) \\nthat are partially compatible, meaning that only some of their attributes, say X, are \\nunion compatible. The attributes that are union compatible are represented only \\nonce in the result, and those attributes that are not union compatible from either \\nrelation are also kept in the result relation T(X, Y, Z). It is therefore the same as a \\nFULL OUTER JOIN on the common attributes.\\nTwo tuples t1 in R and t2 in S are said to match if t1[X] = t2[X]. These will be com-\\nbined (unioned) into a single tuple in t. Tuples in either relation that have no \\nmatching tuple in the other relation are padded with NULL values. For example, an \\nRESULT\\nFname Minit Lname Dname\\nJohn\\nFranklin\\nAlicia\\nJennifer\\nRamesh\\nJoyce\\nAhmad\\nJames\\nB\\nT\\nJ\\nS\\nK\\nA\\nV\\nE\\nSmith\\nWong\\nZelaya\\nWallace\\nNarayan\\nEnglish\\nJabbar\\nBorg\\nNULL\\nResearch\\nNULL\\nAdministration\\nNULL\\nNULL\\nNULL\\nHeadquarters\\nFigure 8.12 \\nThe result of a LEFT \\nOUTER JOIN operation.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 278, 'page_label': '279'}, page_content='8.5 Examples of Queries in Relational Algebra  265\\nOUTER UNION can be applied to two relations whose schemas are STUDENT(Name, \\nSsn, Department, Advisor) and INSTRUCTOR(Name, Ssn, Department, Rank). Tuples \\nfrom the two relations are matched based on having the same combination of \\nvalues of the shared attributes—\\nName, Ssn, Department . The resulting relation, \\nSTUDENT_OR_INSTRUCTOR , will have the following attributes:\\nSTUDENT_OR_INSTRUCTOR(Name, Ssn, Department, Advisor, Rank)\\nAll the tuples from both relations are included in the result, but tuples with the \\nsame ( Name, Ssn, Department ) combination will appear only once in the result. \\nTuples appearing only in STUDENT will have a NULL for the Rank attribute, whereas \\ntuples appearing only in INSTRUCTOR will have a NULL for the Advisor attribute. A \\ntuple that exists in both relations, which represent a student who is also an instruc-\\ntor, will have values for all its attributes.\\n11\\nNotice that the same person may still appear twice in the result. For example, we \\ncould have a graduate student in the Mathematics department who is an instructor \\nin the Computer Science department. Although the two tuples representing that \\nperson in \\nSTUDENT and INSTRUCTOR will have the same ( Name, Ssn) values, they \\nwill not agree on the Department value, and so will not be matched. This is because \\nDepartment has two different meanings in STUDENT (the department where the per-\\nson studies) and INSTRUCTOR (the department where the person is employed as an \\ninstructor). If we wanted to apply the OUTER UNION based on the same (Name, Ssn) \\ncombination only, we should rename the Department attribute in each table to reflect \\nthat they have different meanings and designate them as not being part of the \\nunion-compatible attributes. For example, we could rename the attributes as \\nMajorDept in STUDENT and WorkDept in INSTRUCTOR.\\n8.5 Examples of Queries in Relational Algebra\\nThe following are additional examples to illustrate the use of the relational alge-\\nbra operations. All examples refer to the database in Figure 5.6. In general, the \\nsame query can be stated in numerous ways using the various operations. We will \\nstate each query in one way and leave it to the reader to come up with equivalent \\nformulations.\\nQuery 1.  Retrieve the name and address of all employees who work for the \\n‘Research’ department.\\nRESEARCH_DEPT ← σDname=‘Research’(DEPARTMENT) \\nRESEARCH_EMPS ← (RESEARCH_DEPT  Dnumber=DnoEMPLOYEE) \\nRESULT ← πFname, Lname, Address(RESEARCH_EMPS)\\nAs a single in-line expression, this query becomes:\\nπFname, Lname, Address (σDname=‘Research’(DEPARTMENT  Dnumber=Dno(EMPLOYEE))\\n11Note that OUTER UNION is equivalent to a FULL OUTER JOIN if the join attributes are all the com-\\nmon attributes of the two relations.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 279, 'page_label': '280'}, page_content='266 Chapter 8 The Relational Algebra and Relational Calculus\\nThis query could be specified in other ways; for example, the order of the JOIN \\nand SELECT  operations could be reversed, or the JOIN could be replaced by a \\nNATURAL JOIN  after renaming one of the join attributes to match the other join \\nattribute name.\\nQuery 2. For every project located in ‘Stafford’ , list the project number, the con-\\ntrolling department number, and the department manager’s last name, address, \\nand birth date.\\nSTAFFORD_PROJS ← σPlocation=‘Stafford’(PROJECT) \\nCONTR_DEPTS ← (STAFFORD_PROJS  Dnum=DnumberDEPARTMENT) \\nPROJ_DEPT_MGRS ← (CONTR_DEPTS  Mgr_ssn=SsnEMPLOYEE) \\nRESULT ← πPnumber, Dnum, Lname, Address, Bdate(PROJ_DEPT_MGRS)\\nIn this example, we first select the projects located in Stafford, then join them with \\ntheir controlling departments, and then join the result with the department manag-\\ners. Finally, we apply a project operation on the desired attributes.\\nQuery 3. Find the names of employees who work on all the projects controlled \\nby department number 5.\\nDEPT5_PROJS ← ρ(Pno)(πPnumber(σDnum=5(PROJECT))) \\nEMP_PROJ ← ρ(Ssn, Pno)(πEssn, Pno(WORKS_ON)) \\nRESULT_EMP_SSNS ← EMP_PROJ ÷ DEPT5_PROJS \\nRESULT ← πLname, Fname(RESULT_EMP_SSNS * EMPLOYEE)\\nIn this query, we first create a table DEPT5_PROJS  that contains the project \\nnumbers of all projects controlled by department 5. Then we create a table \\nEMP_PROJ  that holds ( Ssn, Pno) tuples, and apply the division operation. Notice \\nthat we renamed the attributes so that they will be correctly used in the division \\noperation. Finally, we join the result of the division, which holds only \\nSsn val-\\nues, with the EMPLOYEE table to retrieve the Fname, Lname attributes from \\nEMPLOYEE.\\nQuery 4. Make a list of project numbers for projects that involve an employee \\nwhose last name is ‘Smith’ , either as a worker or as a manager of the department \\nthat controls the project.\\nSMITHS(Essn) ← πSsn (σLname=‘Smith’(EMPLOYEE)) \\nSMITH_WORKER_PROJS ← πPno(WORKS_ON * SMITHS) \\nMGRS ← πLname, Dnumber(EMPLOYEE  Ssn=Mgr_ssnDEPARTMENT) \\nSMITH_MANAGED_DEPTS(Dnum) ← πDnumber (σLname=‘Smith’(MGRS)) \\nSMITH_MGR_PROJS(Pno) ← πPnumber(SMITH_MANAGED_DEPTS * PROJECT) \\nRESULT ← (SMITH_WORKER_PROJS ∪ SMITH_MGR_PROJS)\\nIn this query, we retrieved the project numbers for projects that involve an employee \\nnamed Smith as a worker in SMITH_WORKER_PROJS. Then we retrieved the proj-\\nect numbers for projects that involve an employee named Smith as manager of the \\ndepartment that controls the project in SMITH_MGR_PROJS. Finally, we applied the'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 280, 'page_label': '281'}, page_content='8.5 Examples of Queries in Relational Algebra  267\\nUNION operation on SMITH_WORKER_PROJS and SMITH_MGR_PROJS. As a single \\nin-line expression, this query becomes:\\nπPno (WORKS_ON  Essn=Ssn (πSsn (σLname=‘Smith’(EMPLOYEE))) ∪ πPno  \\n((πDnumber (σLname=‘Smith’(πLname, Dnumber(EMPLOYEE)))   \\nSsn=Mgr_ssnDEPARTMENT))  Dnum-ber=DnumPROJECT)\\nQuery 5. List the names of all employees with two or more dependents.\\nStrictly speaking, this query cannot be done in the basic ( original) relational \\nalgebra. We have to use the AGGREGATE FUNCTION operation with the COUNT \\naggregate function. We assume that dependents of the same employee have \\ndistinct Dependent_name values.\\nT1(Ssn, No_of_dependents)← Essn ℑ COUNT Dependent_name(DEPENDENT) \\nT2 ← σNo_of_dependents>2(T1) \\nRESULT ← πLname, Fname(T2 * EMPLOYEE)\\nQuery 6. Retrieve the names of employees who have no dependents.\\nThis is an example of the type of query that uses the MINUS (SET DIFFERENCE) \\noperation.\\nALL_EMPS ← πSsn(EMPLOYEE) \\nEMPS_WITH_DEPS(Ssn) ← πEssn(DEPENDENT) \\nEMPS_WITHOUT_DEPS ← (ALL_EMPS – EMPS_WITH_DEPS) \\nRESULT ← πLname, Fname(EMPS_WITHOUT_DEPS * EMPLOYEE)\\nWe first retrieve a relation with all employee Ssns in ALL_EMPS. Then we create  \\na table with the Ssns of employees who have at least one dependent in  \\nEMPS_WITH_DEPS . Then we apply the SET DIFFERENCE  operation to retrieve \\nemployees Ssns with no dependents in EMPS_WITHOUT_DEPS , and finally join \\nthis with EMPLOYEE to retrieve the desired attributes. As a single in-line expres-\\nsion, this query becomes:\\nπLname, Fname((πSsn(EMPLOYEE) – ρSsn(πEssn(DEPENDENT))) * EMPLOYEE)\\nQuery 7. List the names of managers who have at least one dependent.\\nMGRS(Ssn) ← πMgr_ssn(DEPARTMENT) \\nEMPS_WITH_DEPS(Ssn) ← πEssn(DEPENDENT) \\nMGRS_WITH_DEPS ← (MGRS ∩ EMPS_WITH_DEPS) \\nRESULT ← πLname, Fname(MGRS_WITH_DEPS * EMPLOYEE)\\nIn this query, we retrieve the Ssns of managers in MGRS, and the Ssns of employ-\\nees with at least one dependent in EMPS_WITH_DEPS , then we apply the SET \\nINTERSECTION  operation to get the Ssns of managers who have at least one \\ndependent.\\nAs we mentioned earlier, the same query can be specified in many different ways in \\nrelational algebra. In particular, the operations can often be applied in various \\norders. In addition, some operations can be used to replace others; for example, the'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 281, 'page_label': '282'}, page_content='268 Chapter 8 The Relational Algebra and Relational Calculus\\nINTERSECTION operation in Q7 can be replaced by a NATURAL JOIN. As an exercise, \\ntry to do each of these sample queries using different operations.12 We showed how to \\nwrite queries as single relational algebra expressions for queries Q1, Q4, and Q6. Try \\nto write the remaining queries as single expressions. In Chapters 6 and 7 and in Sec-\\ntions 8.6 and 8.7, we show how these queries are written in other relational languages.\\n8.6 The Tuple Relational Calculus\\nIn this and the next section, we introduce another formal query language for the \\nrelational model called relational calculus . This section introduces the language \\nknown as tuple relational calculus , and Section 8.7 introduces a variation called \\ndomain relational calculus. In both variations of relational calculus, we write one \\ndeclarative expression to specify a retrieval request; hence, there is no description \\nof how, or in what order, to evaluate a query. A calculus expression specifies what is \\nto be retrieved rather than how to retrieve it. Therefore, the relational calculus is \\nconsidered to be a nonprocedural language. This differs from relational algebra, \\nwhere we must write a sequence of operations to specify a retrieval request in a par-\\nticular order of applying the operations; thus, it can be considered as a procedural \\nway of stating a query. It is possible to nest algebra operations to form a single \\nexpression; however, a certain order among the operations is always explicitly spec-\\nified in a relational algebra expression. This order also influences the strategy for \\nevaluating the query. A calculus expression may be written in different ways, but \\nthe way it is written has no bearing on how a query should be evaluated.\\nIt has been shown that any retrieval that can be specified in the basic relational alge-\\nbra can also be specified in relational calculus, and vice versa; in other words, the \\nexpressive power of the languages is identical. This led to the definition of the con-\\ncept of a relationally complete language. A relational query language L is considered \\nrelationally complete  if we can express in L any query that can be expressed in \\nrelational calculus. Relational completeness has become an important basis for \\ncomparing the expressive power of high-level query languages. However, as we saw \\nin Section 8.4, certain frequently required queries in database applications cannot \\nbe expressed in basic relational algebra or calculus. Most relational query languages \\nare relationally complete but have more expressive power than relational algebra or \\nrelational calculus because of additional operations such as aggregate functions, \\ngrouping, and ordering. As we mentioned in the introduction to this chapter, the \\nrelational calculus is important for two reasons. First, it has a firm basis in mathe-\\nmatical logic. Second, the standard query language (SQL) for RDBMSs has its basic \\nfoundation in the tuple relational calculus.\\nOur examples refer to the database shown in Figures 5.6 and 5.7. We will use the \\nsame queries that were used in Section 8.5. Sections 8.6.6, 8.6.7, and 8.6.8 discuss \\ndealing with universal quantifiers and safety of expression issues. Students inter-\\nested in a basic introduction to tuple relational calculus may skip these sections.\\n12When queries are optimized (see Chapters 18 and 19), the system will choose a particular sequence \\nof operations that corresponds to an execution strategy that can be executed efficiently.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 282, 'page_label': '283'}, page_content='8.6 The Tuple Relational Calculus  269\\n8.6.1 Tuple Variables and Range Relations\\nThe tuple relational calculus is based on specifying a number of tuple variables . \\nEach tuple variable usually ranges over a particular database relation, meaning that \\nthe variable may take as its value any individual tuple from that relation. A simple \\ntuple relational calculus query is of the form:\\n{t | \\nCOND(t)}\\nwhere t is a tuple variable and COND(t) is a conditional (Boolean) expression \\ninvolving t that evaluates to either TRUE or FALSE for different assignments of \\ntuples to the variable t. The result of such a query is the set of all tuples t that evalu-\\nate COND(t) to TRUE. These tuples are said to satisfy COND(t). For example, to find \\nall employees whose salary is above $50,000, we can write the following tuple calcu-\\nlus expression:\\n{t | \\nEMPLOYEE(t) AND t.Salary>50000}\\nThe condition EMPLOYEE(t) specifies that the range relation of tuple variable t is \\nEMPLOYEE. Each EMPLOYEE tuple t that satisfies the condition t.Salary>50000 will \\nbe retrieved. Notice that t.Salary references attribute Salary of tuple variable t; this \\nnotation resembles how attribute names are qualified with relation names or aliases \\nin SQL, as we saw in Chapter 6. In the notation of Chapter 5, t.\\nSalary is the same as \\nwriting t[Salary].\\nThe previous query retrieves all attribute values for each selected EMPLOYEE tuple \\nt. To retrieve only some of the attributes—say, the first and last names—we write\\nt.Fname, t.Lname | EMPLOYEE(t) AND t.Salary>50000}\\nInformally, we need to specify the following information in a tuple relational calcu-\\nlus expression:\\n ■ For each tuple variable t, the range relation R of t. This value is specified by \\na condition of the form R(t). If we do not specify a range relation, then the \\nvariable t will range over all possible tuples “in the universe” as it is not \\nrestricted to any one relation.\\n ■ A condition to select particular combinations of tuples. As tuple variables \\nrange over their respective range relations, the condition is evaluated for \\nevery possible combination of tuples to identify the selected combinations \\nfor which the condition evaluates to \\nTRUE.\\n ■ A set of attributes to be retrieved, the requested attributes . The values of \\nthese attributes are retrieved for each selected combination of tuples.\\nBefore we discuss the formal syntax of tuple relational calculus, consider another query.\\nQuery 0. Retrieve the birth date and address of the employee (or employees) \\nwhose name is John B. Smith.\\nQ0: {t.Bdate, t.Address | EMPLOYEE(t) AND t.Fname=‘John’ AND t.Minit=‘B’  \\n  AND t.Lname=‘Smith’}'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 283, 'page_label': '284'}, page_content='270 Chapter 8 The Relational Algebra and Relational Calculus\\nIn tuple relational calculus, we first specify the requested attributes t.Bdate and \\nt.Address for each selected tuple t. Then we specify the condition for selecting a tuple \\nfollowing the bar (|)—namely, that t be a tuple of the EMPLOYEE relation whose \\nFname, Minit, and Lname attribute values are ‘John’, ‘B’, and ‘Smith’, respectively.\\n8.6.2 Expressions and Formulas in Tuple Relational Calculus\\nA general expression of the tuple relational calculus is of the form\\n{t1.Aj, t2.Ak, ... , tn.Am | COND(t1, t2, ..., tn, tn+1, tn+2, ..., tn+m)}\\nwhere t1, t2, … , tn, tn+1, … , tn+m are tuple variables, each Ai is an attribute of the \\nrelation on which ti ranges, and COND is a condition or formula13 of the tuple rela-\\ntional calculus. A formula is made up of predicate calculus atoms, which can be one \\nof the following:\\n  1. An atom of the form R(ti), where R is a relation name and ti is a tuple vari-\\nable. This atom identifies the range of the tuple variable ti as the relation \\nwhose name is R. It evaluates to TRUE if ti is a tuple in the relation R, and \\nevaluates to FALSE otherwise.\\n  2. An atom of the form ti.A op tj.B, where op is one of the comparison opera-\\ntors in the set {=, <, ≤, >, ≥, ≠}, ti and tj are tuple variables, A is an attribute \\nof the relation on which ti ranges, and B is an attribute of the relation on \\nwhich tj ranges.\\n  3. An atom of the form ti.A op c or c op tj.B, where op is one of the comparison \\noperators in the set {=, <, ≤, >, ≥, ≠}, ti and tj are tuple variables, A is an attri-\\nbute of the relation on which ti ranges, B is an attribute of the relation on \\nwhich tj ranges, and c is a constant value.\\nEach of the preceding atoms evaluates to either TRUE or FALSE for a specific combi-\\nnation of tuples; this is called the truth value of an atom. In general, a tuple variable \\nt ranges over all possible tuples in the universe . For atoms of the form R(t), if t is \\nassigned to a tuple that is a member of the specified relation R , the atom is TRUE; \\notherwise, it is FALSE. In atoms of types 2 and 3, if the tuple variables are assigned \\nto tuples such that the values of the specified attributes of the tuples satisfy the con-\\ndition, then the atom is \\nTRUE.\\nA formula (Boolean condition) is made up of one or more atoms connected via \\nthe logical operators AND, OR, and NOT and is defined recursively by Rules 1 and 2 \\nas follows:\\n ■ Rule 1: Every atom is a formula.\\n ■ Rule 2: If F1 and F2 are formulas, then so are ( F1 AND F2), (F1 OR F2), NOT \\n(F1), and NOT (F2). The truth values of these formulas are derived from their \\ncomponent formulas F1 and F2 as follows:\\n13Also called a well-formed formula, or WFF, in mathematical logic.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 284, 'page_label': '285'}, page_content='8.6 The Tuple Relational Calculus  271\\na. (F1 AND F2) is TRUE if both F1 and F2 are TRUE; otherwise, it is FALSE.\\nb. (F1 OR F2) is FALSE if both F1 and F2 are FALSE; otherwise, it is TRUE.\\nc. NOT (F1) is TRUE if F1 is FALSE; it is FALSE if F1 is TRUE.\\nd. NOT (F2) is TRUE if F2 is FALSE; it is FALSE if F2 is TRUE.\\n8.6.3 The Existential and Universal Quantifiers\\nIn addition, two special symbols called quantifiers can appear in formulas; these \\nare the universal quantifier (∀) and the existential quantifier (∃). Truth values for \\nformulas with quantifiers are described in Rules 3 and 4 below; first, however, we \\nneed to define the concepts of free and bound tuple variables in a formula. Infor-\\nmally, a tuple variable t is bound if it is quantified, meaning that it appears in an \\n(∃t) or ( ∀t) clause; otherwise, it is free. Formally, we define a tuple variable in a \\nformula as free or bound according to the following rules:\\n ■ An occurrence of a tuple variable in a formula F that is an atom is free in F.\\n ■ An occurrence of a tuple variable t is free or bound in a formula made up of \\nlogical connectives—( F1 AND F2), ( F1 OR F2), NOT(F1), and NOT(F2)—\\ndepending on whether it is free or bound in F1 or F2 (if it occurs in either). \\nNotice that in a formula of the form F = ( F1 AND F2) or F = ( F1 OR F2), a \\ntuple variable may be free in F1 and bound in F2, or vice versa; in this case, \\none occurrence of the tuple variable is bound and the other is free in F.\\n ■ All free occurrences of a tuple variable t in F are bound in a formula F′ of the \\nform F′= (∃t)(F) or F′ = (∀t)(F). The tuple variable is bound to the quanti-\\nfier specified in F′. For example, consider the following formulas:\\nF1: d.Dname = ‘Research’ \\nF2: (∃t)(d.Dnumber = t.Dno) \\nF3: (∀d)(d.Mgr_ssn = ‘333445555’)\\nThe tuple variable d is free in both F1 and F2, whereas it is bound to the (∀) quanti-\\nfier in F3. Variable t is bound to the (∃) quantifier in F2.\\nWe can now give Rules 3 and 4 for the definition of a formula we started earlier:\\n ■ Rule 3: If F is a formula, then so is ( ∃t)(F), where t is a tuple variable. The \\nformula (∃t)(F) is TRUE if the formula F evaluates to TRUE for some (at least \\none) tuple assigned to free occurrences of t in F; otherwise, (∃t)(F) is FALSE.\\n ■ Rule 4: If F is a formula, then so is (∀t)(F), where t is a tuple variable. The for-\\nmula (∀t)(F) is TRUE if the formula F evaluates to TRUE for every tuple (in the \\nuniverse) assigned to free occurrences of t in F; otherwise, (∀t)(F) is FALSE.\\nThe (∃) quantifier is called an existential quantifier because a formula ( ∃t)(F) is \\nTRUE if there exists  some tuple that makes F TRUE. For the universal quantifier,  \\n(∀t)(F) is TRUE if every possible tuple that can be assigned to free occurrences of  \\nt in F is substituted for t, and F is TRUE for every such substitution. It is called the \\nuniversal or for all  quantifier because every tuple in the universe of  tuples must \\nmake F TRUE to make the quantified formula TRUE.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 285, 'page_label': '286'}, page_content='272 Chapter 8 The Relational Algebra and Relational Calculus\\n8.6.4 Sample Queries in Tuple Relational Calculus\\nWe will use some of the same queries from Section 8.5 to give a flavor of how the \\nsame queries are specified in relational algebra and in relational calculus. Notice \\nthat some queries are easier to specify in the relational algebra than in the relational \\ncalculus, and vice versa.\\nQuery 1. List the name and address of all employees who work for the ‘Research’ \\ndepartment.\\nQ1:  {t.Fname, t.Lname, t.Address | EMPLOYEE(t) AND (∃d)(DEPARTMENT(d)  \\nAND d.Dname=‘Research’ AND d.Dnumber=t.Dno)}\\nThe only free tuple variables in a tuple relational calculus expression should be those \\nthat appear to the left of the bar (|). In Q1, t is the only free variable; it is then bound \\nsuccessively to each tuple. If a tuple satisfies the conditions specified after the bar in \\nQ1, the attributes Fname, Lname, and Address are retrieved for each such tuple. The \\nconditions EMPLOYEE(t) and DEPARTMENT (d) specify the range relations for t  \\nand d. The condition d.Dname = ‘Research’ is a selection condition  and corre-\\nsponds to a SELECT operation in the relational algebra, whereas the condition \\nd.Dnumber = t.Dno is a join condition and is similar in purpose to the (INNER) JOIN \\noperation (see Section 8.3).\\nQuery 2. For every project located in ‘Stafford’, list the project number, the con-\\ntrolling department number, and the department manager’s last name, birth \\ndate, and address.\\nQ2:  {p.Pnumber, p.Dnum, m.Lname, m.Bdate, m.Address | PROJECT(p) AND \\nEMPLOYEE(m) AND p.Plocation=‘Stafford’ AND ((∃d)(DEPARTMENT(d) \\nAND p.Dnum=d.Dnumber AND d.Mgr_ssn=m.Ssn))}\\nIn Q2 there are two free tuple variables, p and m. Tuple variable d is bound to the \\nexistential quantifier. The query condition is evaluated for every combination of \\ntuples assigned to p and m, and out of all possible combinations of tuples to which \\np and m are bound, only the combinations that satisfy the condition are selected.\\nSeveral tuple variables in a query can range over the same relation. For example, to \\nspecify \\nQ8—for each employee, retrieve the employee’s first and last name and the \\nfirst and last name of his or her immediate supervisor—we specify two tuple vari-\\nables e and s that both range over the \\nEMPLOYEE relation:\\nQ8:  {e.Fname, e.Lname, s.Fname, s.Lname | EMPLOYEE(e) AND EMPLOYEE(s)  \\nAND e.Super_ssn=s.Ssn}\\nQuery 3′. List the name of each employee who works on some project controlled \\nby department number 5. This is a variation of Q3 in which all is changed to \\nsome. In this case we need two join conditions and two existential quantifiers.\\nQ0′:  {e.Lname, e.Fname | EMPLOYEE(e) AND ((∃x)(∃w)(PROJECT(x) AND  \\nWORKS_ON(w) AND x.Dnum=5 AND w.Essn=e.Ssn AND  \\nx.Pnumber=w.Pno))}'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 286, 'page_label': '287'}, page_content='8.6 The Tuple Relational Calculus  273\\nQuery 4. Make a list of project numbers for projects that involve an employee \\nwhose last name is ‘Smith’, either as a worker or as manager of the controlling \\ndepartment for the project.\\nQ4:  { p.Pnumber | PROJECT(p) AND (((∃e)(∃w)(EMPLOYEE(e) \\nAND WORKS_ON(w) AND w.Pno=p.Pnumber \\nAND e.Lname=‘Smith’ AND e.Ssn=w.Essn) ) \\nOR \\n((∃m)(∃d)(EMPLOYEE(m) AND DEPARTMENT(d) \\nAND p.Dnum=d.Dnumber AND d.Mgr_ssn=m.Ssn \\nAND m.Lname=‘Smith’)))}\\nCompare this with the relational algebra version of this query in Section 8.5. The \\nUNION operation in relational algebra can usually be substituted with an OR con-\\nnective in relational calculus.\\n8.6.5 Notation for Query Graphs\\nIn this section, we describe a notation that has been proposed to represent relational \\ncalculus queries that do not involve complex quantification in a graphical form. \\nThese types of queries are known as select-project-join queries because they only \\ninvolve these three relational algebra operations. The notation may be expanded to \\nmore general queries, but we do not discuss these extensions here. This graphical \\nrepresentation of a query is called a query graph. Figure 8.13 shows the query graph \\nfor \\nQ2. Relations in the query are represented by relation nodes, which are displayed \\nas single circles. Constant values, typically from the query selection conditions, are \\nrepresented by constant nodes, which are displayed as double circles or ovals. Selec-\\ntion and join conditions are represented by the graph edges (the lines that connect \\nthe nodes), as shown in Figure 8.13. Finally, the attributes to be retrieved from each \\nrelation are displayed in square brackets above each relation.\\nThe query graph representation does not indicate a particular order to specify which \\noperations to perform first, and is hence a more neutral representation of a select-\\nproject-join query than the query tree representation (see Section 8.3.5), where the \\norder of execution is implicitly specified. There is only a single query graph corre-\\nsponding to each query. Although some query optimization techniques were based \\non query graphs, it is now generally accepted that query trees are preferable because, \\n[P.Pnumber,P.Dnum] [E.Lname,E.address,E.Bdate]\\nP.Dnum=D.Dnumber\\nP.Plocation=‘Stafford’\\nPDE\\n‘Stafford’\\nD.Mgr_ssn=E.Ssn\\nFigure 8.13 \\nQuery graph for Q2.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 287, 'page_label': '288'}, page_content='274 Chapter 8 The Relational Algebra and Relational Calculus\\nin practice, the query optimizer needs to show the order of operations for query \\nexecution, which is not possible in query graphs.\\nIn the next section we discuss the relationship between the universal and existential \\nquantifiers and show how one can be transformed into the other.\\n8.6.6 Transforming the Universal and Existential Quantifiers\\nWe now introduce some well-known transformations from mathematical logic that \\nrelate the universal and existential quantifiers. It is possible to transform a universal \\nquantifier into an existential quantifier, and vice versa, to get an equivalent expres-\\nsion. One general transformation can be described informally as follows: Trans-\\nform one type of quantifier into the other with negation (preceded by \\nNOT); AND \\nand OR replace one another; a negated formula becomes unnegated; and an un-\\nnegated formula becomes negated. Some special cases of this transformation can be \\nstated as follows, where the ≡ symbol stands for equivalent to:\\n(∀x) (P(x)) ≡ \\nNOT (∃x) (NOT (P(x))) \\n(∃x) (P(x)) ≡ NOT (∀x) (NOT (P(x))) \\n(∀x) (P(x) AND Q(x)) ≡ NOT (∃x) (NOT (P(x)) OR NOT (Q(x))) \\n(∀x) (P(x) OR Q(x)) ≡ NOT (∃x) (NOT (P(x)) AND NOT (Q(x))) \\n(∃x) (P(x)) OR Q(x)) ≡ NOT (∀x) (NOT (P(x)) AND NOT (Q(x))) \\n(∃x) (P(x) AND Q(x)) ≡ NOT (∀x) (NOT (P(x)) OR NOT (Q(x)))\\nNotice also that the following is TRUE, where the ⇒ symbol stands for implies:\\n(∀x)(P(x)) ⇒ (∃x)(P(x)) \\nNOT (∃x)(P(x)) ⇒ NOT (∀x)(P(x))\\n8.6.7 Using the Universal Quantifier in Queries\\nWhenever we use a universal quantifier, it is quite judicious to follow a few rules to \\nensure that our expression makes sense. We discuss these rules with respect to the \\nquery \\nQ3.\\nQuery 3. List the names of employees who work on all the projects controlled \\nby department number 5. One way to specify this query is to use the universal \\nquantifier as shown:\\nQ3:  {e.Lname, e.Fname | EMPLOYEE(e) AND ((∀x)(NOT(PROJECT(x)) OR NOT \\n(x.Dnum=5) OR ((∃w)(WORKS_ON(w) AND w.Essn=e.Ssn AND  \\nx.Pnumber=w.Pno))))}\\nWe can break up Q3 into its basic components as follows:\\nQ3:  {e.Lname, e.Fname | EMPLOYEE(e) AND F′} \\nF′ = ((∀x)(NOT(PROJECT(x)) OR F1)) \\nF1 = NOT(x.Dnum=5) OR F2 \\nF2 = ((∃w)(WORKS_ON(w) AND w.Essn=e.Ssn \\nAND x.Pnumber=w.Pno))'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 288, 'page_label': '289'}, page_content='8.6 The Tuple Relational Calculus  275\\nWe want to make sure that a selected employee e works on all the projects  con-\\ntrolled by department 5, but the definition of universal quantifier  says that to \\nmake the quantified formula TRUE, the inner formula  must be TRUE for all tuples \\nin the universe . The trick is to exclude from the universal quantification all tuples \\nthat we are not interested in by making the condition TRUE for all such tuples . \\nThis is necessary because a universally quantified tuple variable, such as x in Q3, \\nmust evaluate to TRUE for every possible tuple  assigned to it to make the quantified \\nformula TRUE.\\nThe first tuples to exclude (by making them evaluate automatically to TRUE) are \\nthose that are not in the relation R of interest. In Q3, using the expression \\nNOT(PROJECT(x)) inside the universally quantified formula evaluates to TRUE all \\ntuples x that are not in the PROJECT relation. Then we exclude the tuples we are not \\ninterested in from R itself. In Q3, using the expression NOT(x.Dnum=5) evaluates to \\nTRUE all tuples x that are in the PROJECT relation but are not controlled by depart-\\nment 5. Finally, we specify a condition F2 that must hold on all the remaining tuples \\nin R. Hence, we can explain Q3 as follows:\\n  1. For the formula F′ = ( ∀x)(F) to be TRUE, we must have the formula F be \\nTRUE for all tuples in the universe that can be assigned to x . However, in Q3 \\nwe are only interested in F being TRUE for all tuples of the PROJECT relation \\nthat are controlled by department 5. Hence, the formula F is of the form \\n(NOT(PROJECT(x)) OR F1). The ‘ NOT ( PROJECT(x)) OR …’ condition is \\nTRUE for all tuples not in the PROJECT relation and has the effect of elimi-\\nnating these tuples from consideration in the truth value of F1. For every \\ntuple in the PROJECT relation, F1 must be TRUE if F′ is to be TRUE.\\n  2. Using the same line of reasoning, we do not want to consider tuples in the \\nPROJECT relation that are not controlled by department number 5, since we \\nare only interested in PROJECT tuples whose Dnum=5. Therefore, we can \\nwrite:\\nIF (x.Dnum=5) THEN F2\\nwhich is equivalent to\\n(NOT (x.Dnum=5) OR F2)\\n  3. Formula F1, hence, is of the form NOT(x.Dnum=5) OR F2. In the context of \\nQ3, this means that, for a tuple x in the PROJECT relation, either its Dnum≠5 \\nor it must satisfy F2.\\n  4. Finally, F2 gives the condition that we want to hold for a selected EMPLOYEE \\ntuple: that the employee works on every PROJECT tuple that has not been \\nexcluded yet. Such employee tuples are selected by the query.\\nIn English, Q3 gives the following condition for selecting an EMPLOYEE tuple e: \\nFor every tuple x in the PROJECT relation with x.Dnum=5, there must exist a tuple \\nw in WORKS_ON such that w.Essn=e.Ssn and w.Pno=x.Pnumber. This is equivalent \\nto saying that EMPLOYEE e works on every PROJECT x in DEPARTMENT number 5. \\n(Whew!)'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 289, 'page_label': '290'}, page_content='276 Chapter 8 The Relational Algebra and Relational Calculus\\nUsing the general transformation from universal to existential quantifiers given in \\nSection 8.6.6, we can rephrase the query in Q3 as shown in Q3A, which uses a \\nnegated existential quantifier instead of the universal quantifier:\\nQ3A:  {e.Lname, e.Fname | EMPLOYEE(e) AND (NOT (∃x) (PROJECT(x) AND  \\n(x.Dnum=5) and (NOT (∃w)(WORKS_ON(w) AND w.Essn=e.Ssn  \\nAND x.Pnumber=w.Pno))))}\\nWe now give some additional examples of queries that use quantifiers.\\nQuery 6. List the names of employees who have no dependents.\\nQ6:  {e.Fname, e.Lname | EMPLOYEE(e) AND (NOT (∃d)(DEPENDENT(d)  \\nAND e.Ssn=d.Essn))}\\nUsing the general transformation rule, we can rephrase Q6 as follows:\\nQ6A:  {e.Fname, e.Lname | EMPLOYEE(e) AND ((∀d)(NOT(DEPENDENT(d))  \\nOR NOT(e.Ssn=d.Essn)))}\\nQuery 7. List the names of managers who have at least one dependent.\\nQ7:  {e.Fname, e.Lname | EMPLOYEE(e) AND ((∃d)(∃ρ)(DEPARTMENT(d)  \\nAND DEPENDENT(ρ) AND e.Ssn=d.Mgr_ssn AND ρ.Essn=e.Ssn))}\\nThis query is handled by interpreting managers who have at least one dependent as \\nmanagers for whom there exists some dependent.\\n8.6.8 Safe Expressions\\nWhenever we use universal quantifiers, existential quantifiers, or negation of predi-\\ncates in a calculus expression, we must make sure that the resulting expression \\nmakes sense. A safe expression in relational calculus is one that is guaranteed to \\nyield a finite number of tuples as its result; otherwise, the expression is called unsafe. \\nFor example, the expression\\n{t | \\nNOT (EMPLOYEE(t))}\\nis unsafe because it yields all tuples in the universe that are not EMPLOYEE tuples, \\nwhich are infinitely numerous. If we follow the rules for Q3 discussed earlier, we \\nwill get a safe expression when using universal quantifiers. We can define safe \\nexpressions more precisely by introducing the concept of the domain of a tuple \\nrelational calculus expression:  This is the set of all values that either appear as \\nconstant values in the expression or exist in any tuple in the relations referenced \\nin the expression. For example, the domain of { t | \\nNOT(EMPLOYEE(t))} is the set \\nof all attribute values appearing in some tuple of the EMPLOYEE relation (for any \\nattribute). The domain of the expression Q3A would include all values appearing \\nin EMPLOYEE, PROJECT, and WORKS_ON (unioned with the value 5 appearing in \\nthe query itself).\\nAn expression is said to be safe if all values in its result are from the domain of the \\nexpression. Notice that the result of {t | NOT(EMPLOYEE(t))} is unsafe, since it will,'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 290, 'page_label': '291'}, page_content='8.7 The Domain Relational Calculus  277\\nin general, include tuples (and hence values) from outside the EMPLOYEE relation; \\nsuch values are not in the domain of the expression. All of our other examples are \\nsafe expressions.\\n8.7 The Domain Relational Calculus\\nThere is another type of relational calculus called the domain relational calculus, or \\nsimply domain calculus. Historically, while SQL (see Chapters 6 and 7), which was \\nbased on tuple relational calculus, was being developed by IBM Research at San \\nJose, California, another language called QBE (Query-By-Example), which is \\nrelated to domain calculus, was being developed almost concurrently at the IBM  \\nT. J. Watson Research Center in Yorktown Heights, New York. The formal specifi-\\ncation of the domain calculus was proposed after the development of the QBE lan-\\nguage and system.\\nDomain calculus differs from tuple calculus in the type of variables used in formu-\\nlas: Rather than having variables range over tuples, the variables range over single \\nvalues from domains of attributes. To form a relation of degree n for a query result, \\nwe must have n of these domain variables—one for each attribute. An expression \\nof the domain calculus is of the form\\n{x\\n1, x2, ..., xn | COND(x1, x2, ..., xn, xn+1, xn+2, ..., xn+m)}\\nwhere x1, x2, … , xn, xn+1, xn+2, … , xn+m are domain variables that range over \\ndomains (of attributes), and COND is a condition  or formula  of the domain \\nrelational calculus.\\nA formula is made up of atoms. The atoms of a formula are slightly different from \\nthose for the tuple calculus and can be one of the following:\\n  1. An atom of the form R( x1, x2, … , xj), where R is the name of a relation of \\ndegree j and each xi, 1 ≤ i ≤ j, is a domain variable. This atom states that a list \\nof values of <x1, x2, … , xj> must be a tuple in the relation whose name is R, \\nwhere xi is the value of the ith attribute value of the tuple. To make a domain \\ncalculus expression more concise, we can drop the commas in a list of vari-\\nables; thus, we can write:\\n{x1, x2, ..., xn | R(x1 x2 x3) AND ...}\\ninstead of:\\n{x1, x2, ... , xn | R(x1, x2, x3) AND ...}\\n  2. An atom of the form xi op xj, where op is one of the comparison operators in \\nthe set {=, <, ≤, >, ≥, ≠}, and xi and xj are domain variables.\\n  3. An atom of the form xi op c or c op xj, where op is one of the comparison \\noperators in the set {=, <, ≤, >, ≥, ≠}, xi and xj are domain variables, and c is \\na constant value.\\nAs in tuple calculus, atoms evaluate to either TRUE or FALSE for a specific set of \\nvalues, called the truth values of the atoms. In case 1, if the domain variables are'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 291, 'page_label': '292'}, page_content='278 Chapter 8 The Relational Algebra and Relational Calculus\\nassigned values corresponding to a tuple of the specified relation R, then the atom is \\nTRUE. In cases 2 and 3, if the domain variables are assigned values that satisfy the \\ncondition, then the atom is TRUE.\\nIn a similar way to the tuple relational calculus, formulas are made up of atoms, \\nvariables, and quantifiers, so we will not repeat the specifications for formulas here. \\nSome examples of queries specified in the domain calculus follow. We will use low-\\nercase letters l, m, n, … , x, y, z for domain variables.\\nQuery 0. List the birth date and address of the employee whose name is ‘John \\nB. Smith’.\\nQ0:  {u, v | (∃q) (∃r) (∃s) (∃t) (∃w) (∃x) (∃y) (∃z)  \\n(EMPLOYEE(qrstuvwxyz) AND q=‘John’ AND r=‘B’ AND s=‘Smith’)}\\nWe need ten variables for the EMPLOYEE relation, one to range over each of the \\ndomains of attributes of EMPLOYEE in order. Of the ten variables q, r, s, … , z, \\nonly u and v are free, because they appear to the left of the bar and hence should \\nnot be bound to a quantifier. We first specify the requested attributes , Bdate and \\nAddress, by the free domain variables u for BDATE and v for ADDRESS. Then we \\nspecify the condition for selecting a tuple following the bar (|)—namely, that the \\nsequence of values assigned to the variables qrstuvwxyz be a tuple of the EMPLOYEE \\nrelation and that the values for q ( Fname), r ( Minit), and s ( Lname) be equal to \\n‘John’, ‘B’, and ‘Smith’, respectively. For convenience, we will quantify only those \\nvariables actually appearing in a condition  (these would be q, r, and s in Q0) in the \\nrest of our examples. 14\\nAn alternative shorthand notation, used in QBE, for writing this query is to assign \\nthe constants ‘John’, ‘B’, and ‘Smith’ directly as shown in \\nQ0A. Here, all variables \\nnot appearing to the left of the bar are implicitly existentially quantified:15\\nQ0A: {u, v | EMPLOYEE(‘John’, ‘B’, ‘Smith’, t, u, v, w, x, y, z)}\\nQuery 1.  Retrieve the name and address of all employees who work for the \\n‘Research’ department.\\nQ1:  {q, s, v | (∃z) (∃l) (∃m) (EMPLOYEE(qrstuvwxyz) AND  \\nDEPARTMENT(lmno) AND l=‘Research’ AND m=z)}\\nA condition relating two domain variables that range over attributes from two rela-\\ntions, such as m = z in Q1, is a join condition, whereas a condition that relates a \\ndomain variable to a constant, such as l = ‘Research’, is a selection condition.\\nQuery 2. For every project located in ‘Stafford’, list the project number, the con-\\ntrolling department number, and the department manager’s last name, birth \\ndate, and address.\\n14Quantifying only the domain variables actually used in conditions and specifying a predicate such as \\nEMPLOYEE(qrstuvwxyz) without separating domain variables with commas is an abbreviated notation \\nused for convenience; it is not the correct formal notation.\\n15Again, this is not a formally accurate notation.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 292, 'page_label': '293'}, page_content='8.8 Summary  279\\nQ2:  {i, k, s, u, v | (∃j)(∃m)(∃n)(∃t)(PROJECT(hijk) AND \\nEMPLOYEE(qrstuvwxyz) AND DEPARTMENT(lmno) AND k=m AND  \\nn=t AND j=‘Stafford’)}\\nQuery 6. List the names of employees who have no dependents.\\nQ6:  {q, s | (∃t)(EMPLOYEE(qrstuvwxyz) AND  \\n(NOT(∃l)(DEPENDENT(lmnop) AND t=l)))}\\nQ6 can be restated using universal quantifiers instead of the existential quantifiers, \\nas shown in Q6A:\\nQ6A:  {q, s | (∃t)(EMPLOYEE(qrstuvwxyz) AND  \\n((∀l)(NOT(DEPENDENT(lmnop)) OR NOT(t=l))))}\\nQuery 7. List the names of managers who have at least one dependent.\\nQ7:  {s, q | (∃t)(∃j)(∃l)(EMPLOYEE(qrstuvwxyz) AND DEPARTMENT(hijk)  \\nAND DEPENDENT(lmnop) AND t=j AND l=t)}\\nAs we mentioned earlier, it can be shown that any query that can be expressed in \\nthe basic relational algebra can also be expressed in the domain or tuple relational \\ncalculus. Also, any safe expression in the domain or tuple relational calculus can be \\nexpressed in the basic relational algebra.\\nThe QBE language was based on the domain relational calculus, although this was \\nrealized later, after the domain calculus was formalized. QBE was one of the first \\ngraphical query languages with minimum syntax developed for database systems. It \\nwas developed at IBM Research and is available as an IBM commercial product as \\npart of the Query Management Facility (QMF) interface option to DB2. The basic \\nideas used in QBE have been applied in several other commercial products. Because \\nof its important place in the history of relational languages, we have included an \\noverview of QBE in Appendix C.\\n8.8 Summary\\nIn this chapter we presented two formal languages for the relational model of data. \\nThey are used to manipulate relations and produce new relations as answers to que-\\nries. We discussed the relational algebra and its operations, which are used to spec-\\nify a sequence of operations to specify a query. Then we introduced two types of \\nrelational calculi called tuple calculus and domain calculus.\\nIn Sections 8.1 through 8.3, we introduced the basic relational algebra operations \\nand illustrated the types of queries for which each is used. First, we discussed the \\nunary relational operators \\nSELECT and PROJECT, as well as the RENAME operation. \\nThen, we discussed binary set theoretic operations requiring that relations on  \\nwhich they are applied be union (or type) compatible; these include \\nUNION,  \\nINTERSECTION, and SET DIFFERENCE . The CARTESIAN PRODUCT  operation is a  \\nset operation that can be used to combine tuples from two relations, producing  \\nall possible combinations. It is rarely used in practice; however, we showed how'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 293, 'page_label': '294'}, page_content='280 Chapter 8 The Relational Algebra and Relational Calculus\\nCARTESIAN PRODUCT followed by SELECT can be used to define matching tuples \\nfrom two relations and leads to the JOIN operation. Different JOIN operations called \\nTHETA JOIN, EQUIJOIN, and NATURAL JOIN were introduced. Query trees were intro-\\nduced as a graphical representation of relational algebra queries, which can also be used \\nas the basis for internal data structures that the DBMS can use to represent a query.\\nWe discussed some important types of queries that cannot be stated with the basic \\nrelational algebra operations but are important for practical situations. We intro-\\nduced \\nGENERALIZED PROJECTION to use functions of attributes in the projection \\nlist and the AGGREGATE FUNCTION operation to deal with aggregate types of statis-\\ntical requests that summarize the information in the tables. We discussed recursive \\nqueries, for which there is no direct support in the algebra but which can be han-\\ndled in a step-by-step approach, as we demonstrated. Then we presented the \\nOUTER \\nJOIN and OUTER UNION  operations, which extend JOIN and UNION and allow all \\ninformation in source relations to be preserved in the result.\\nThe last two sections described the basic concepts behind relational calculus, which \\nis based on the branch of mathematical logic called predicate calculus. There are \\ntwo types of relational calculi: (1) the tuple relational calculus, which uses tuple \\nvariables that range over tuples (rows) of relations, and (2) the domain relational \\ncalculus, which uses domain variables that range over domains (columns of rela-\\ntions). In relational calculus, a query is specified in a single declarative statement, \\nwithout specifying any order or method for retrieving the query result. Hence, rela-\\ntional calculus is often considered to be a higher-level declarative language than the \\nrelational algebra, because a relational calculus expression states what we want to \\nretrieve regardless of how the query may be executed.\\nWe introduced query graphs as an internal representation for queries in relational \\ncalculus. We also discussed the existential quantifier ( ∃) and the universal quanti-\\nfier ( ∀). We discussed the problem of specifying safe queries whose results are \\nfinite. We also discussed rules for transforming universal into existential quantifi-\\ners, and vice versa. It is the quantifiers that give expressive power to the relational \\ncalculus, making it equivalent to the basic relational algebra. There is no analog to \\ngrouping and aggregation functions in basic relational calculus, although some \\nextensions have been suggested.\\nReview Questions\\n 8.1.  List the operations of relational algebra and the purpose of each.\\n 8.2.  What is union compatibility? Why do the UNION , INTERSECTION , and \\nDIFFERENCE  operations require that the relations on which they are \\napplied be union compatible?\\n 8.3.  Discuss some types of queries for which renaming of attributes is necessary \\nin order to specify the query unambiguously.\\n 8.4.  Discuss the various types of inner join operations. Why is theta join required?'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 294, 'page_label': '295'}, page_content='Exercises 281\\n 8.5.  What role does the concept of foreign key  play when specifying the most \\ncommon types of meaningful join operations?\\n 8.6.  What is the FUNCTION operation? For what is it used?\\n 8.7.  How are the OUTER JOIN operations different from the INNER JOIN opera-\\ntions? How is the OUTER UNION operation different from UNION?\\n 8.8.  In what sense does relational calculus differ from relational algebra, and in \\nwhat sense are they similar?\\n 8.9.  How does tuple relational calculus differ from domain relational calculus?\\n 8.10.  Discuss the meanings of the existential quantifier ( ∃) and the universal \\nquantifier (∀).\\n 8.11.  Define the following terms with respect to the tuple calculus: tuple variable, \\nrange relation, atom, formula, and expression.\\n 8.12.  Define the following terms with respect to the domain calculus: domain \\nvariable, range relation, atom, formula, and expression.\\n 8.13.  What is meant by a safe expression in relational calculus?\\n 8.14.  When is a query language called relationally complete?\\nExercises\\n 8.15.  Show the result of each of the sample queries in Section 8.5 as it would apply \\nto the database state in Figure 5.6.\\n 8.16.  Specify the following queries on the COMPANY relational database schema \\nshown in Figure 5.5 using the relational operators discussed in this chapter. \\nAlso show the result of each query as it would apply to the database state in \\nFigure 5.6.\\na. Retrieve the names of all employees in department 5 who work more \\nthan 10 hours per week on the ProductX project.\\nb. List the names of all employees who have a dependent with the same first \\nname as themselves.\\nc. Find the names of all employees who are directly supervised by ‘Franklin \\nWong’.\\nd. For each project, list the project name and the total hours per week (by all \\nemployees) spent on that project.\\ne. Retrieve the names of all employees who work on every project.\\nf. Retrieve the names of all employees who do not work on any project.\\ng. For each department, retrieve the department name and the average sal-\\nary of all employees working in that department.\\nh. Retrieve the average salary of all female employees.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 295, 'page_label': '296'}, page_content='282 Chapter 8 The Relational Algebra and Relational Calculus\\ni. Find the names and addresses of all employees who work on at least one \\nproject located in Houston but whose department has no location in \\nHouston.\\nj. List the last names of all department managers who have no dependents.\\n 8.17.  Consider the AIRLINE relational database schema shown in Figure 5.8, which \\nwas described in Exercise 5.12. Specify the following queries in relational \\nalgebra:\\na. For each flight, list the flight number, the departure airport for the first \\nleg of the flight, and the arrival airport for the last leg of the flight.\\nb. List the flight numbers and weekdays of all flights or flight legs that depart \\nfrom Houston Intercontinental Airport (airport code ‘iah’) and arrive in \\nLos Angeles International Airport (airport code ‘lax’).\\nc. List the flight number, departure airport code, scheduled departure time, \\narrival airport code, scheduled arrival time, and weekdays of all flights or \\nflight legs that depart from some airport in the city of Houston and arrive \\nat some airport in the city of Los Angeles.\\nd. List all fare information for flight number ‘co197’.\\ne. Retrieve the number of available seats for flight number ‘co197’ on  \\n‘2009-10-09’.\\n 8.18.  Consider the LIBRARY relational database schema shown in Figure 8.14, which \\nis used to keep track of books, borrowers, and book loans. Referential integrity \\nconstraints are shown as directed arcs in Figure 8.14, as in the notation of Fig-\\nure 5.7. Write down relational expressions for the following queries:\\na. How many copies of the book titled The Lost Tribe  are owned by the \\nlibrary branch whose name is ‘Sharpstown’?\\nb. How many copies of the book titled The Lost Tribe  are owned by each \\nlibrary branch?\\nc. Retrieve the names of all borrowers who do not have any books \\nchecked out.\\nd. For each book that is loaned out from the Sharpstown branch and whose \\nDue_date is today, retrieve the book title, the borrower’s name, and the \\nborrower’s address.\\ne. For each library branch, retrieve the branch name and the total number \\nof books loaned out from that branch.\\nf. Retrieve the names, addresses, and number of books checked out for all \\nborrowers who have more than five books checked out.\\ng. For each book authored (or coauthored) by Stephen King, retrieve the \\ntitle and the number of copies owned by the library branch whose name \\nis Central.\\n 8.19.  Specify the following queries in relational algebra on the database schema \\ngiven in Exercise 5.14:'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 296, 'page_label': '297'}, page_content='Exercises 283\\na. List the Order# and Ship_date for all orders shipped from Warehouse# W2.\\nb. List the WAREHOUSE  information from which the CUSTOMER  \\nnamed Jose Lopez was supplied his orders. Produce a listing: Order# , \\nWarehouse# .\\nc. Produce a listing Cname, No_of_orders, Avg_order_amt, where the middle \\ncolumn is the total number of orders by the customer and the last column \\nis the average order amount for that customer.\\nd. List the orders that were not shipped within 30 days of ordering.\\ne. List the Order# for orders that were shipped from all warehouses that the \\ncompany has in New York.\\n 8.20.  Specify the following queries in relational algebra on the database schema \\ngiven in Exercise 5.15:\\na. Give the details (all attributes of trip relation) for trips that exceeded \\n$2,000 in expenses.\\nPublisher_nameBook_id Title\\nBOOK\\nBOOK_COPIES\\nBook_id Branch_id No_of_copies\\nBOOK_AUTHORS\\nBook_id Author_name\\nLIBRARY_BRANCH\\nBranch_id Branch_name Address\\nPUBLISHER\\nName Address Phone\\nBOOK_LOANS\\nBook_id Branch_id Card_no Date_out Due_date\\nBORROWER\\nCard_no Name Address Phone\\nFigure 8.14 \\nA relational database \\nschema for a LIBRARY \\ndatabase.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 297, 'page_label': '298'}, page_content='284 Chapter 8 The Relational Algebra and Relational Calculus\\nb. Print the Ssns of salespeople who took trips to Honolulu.\\nc. Print the total trip expenses incurred by the salesperson with SSN = \\n‘234-56-7890’.\\n 8.21.  Specify the following queries in relational algebra on the database schema \\ngiven in Exercise 5.16:\\na. List the number of courses taken by all students named John Smith in \\nWinter 2009 (i.e., \\nQuarter=W09).\\nb. Produce a list of textbooks (include Course#, Book_isbn, Book_title) for \\ncourses offered by the ‘CS’ department that have used more than two books.\\nc. List any department that has all its adopted books published by ‘Pearson \\nPublishing’.\\n 8.22.  Consider the two tables T1 and T2 shown in Figure 8.15. Show the results of \\nthe following operations:\\na. T1  T1.P = T2.A T2\\nb. T1  T1.Q = T2.B T2\\nc. T1  T1.P = T2.A T2\\nd. T1  T1.Q = T2.B T2\\ne. T1 ∪ T2\\nf. T1  (T1.P = T2.A AND T1.R = T2.C) T2\\n 8.23.  Specify the following queries in relational algebra on the database schema in \\nExercise 5.17:\\na. For the salesperson named ‘Jane Doe’, list the following information for \\nall the cars she sold: \\nSerial#, Manufacturer, Sale_price.\\nb. List the Serial# and Model of cars that have no options.\\nc. Consider the NATURAL JOIN  operation between SALESPERSON  and \\nSALE. What is the meaning of a left outer join for these tables (do not \\nchange the order of relations)? Explain with an example.\\nd. Write a query in relational algebra involving selection and one set opera-\\ntion and say in words what the query does.\\n 8.24.  Specify queries a, b, c, e, f, i, and j of Exercise 8.16 in both tuple and domain \\nrelational calculus.\\n 8.25.  Specify queries a, b, c, and d of Exercise 8.17 in both tuple and domain rela-\\ntional calculus.\\nPQR ABC\\n10\\n15\\n25\\na\\nb\\na\\n5\\n8\\n6\\n10\\n25\\n10\\nb\\nc\\nb\\n6\\n3\\n5\\nTABLE T1 TABLE T2 Figure 8.15 \\nA database state for the \\nrelations T1 and T2.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 298, 'page_label': '299'}, page_content='Exercises 285\\n 8.26.  Specify queries c, d, and f of Exercise 8.18 in both tuple and domain rela-\\ntional calculus.\\n 8.27.  In a tuple relational calculus query with n tuple variables, what would be the \\ntypical minimum number of join conditions? Why? What is the effect of \\nhaving a smaller number of join conditions?\\n 8.28.  Rewrite the domain relational calculus queries that followed Q0 in Sec- \\ntion 8.7 in the style of the abbreviated notation of Q0A, where the objective \\nis to minimize the number of domain variables by writing constants in place \\nof variables wherever possible.\\n 8.29.  Consider this query: Retrieve the Ssns of employees who work on at least \\nthose projects on which the employee with Ssn=123456789 works. This may \\nbe stated as (FORALL x) (IF P THEN Q), where\\n ■ x is a tuple variable that ranges over the PROJECT relation.\\n ■ P ≡ employee with Ssn=123456789 works on project x.\\n ■ Q ≡ employee e works on project x.\\nExpress the query in tuple relational calculus, using the rules\\n ■ (∀ x)(P(x)) ≡ NOT(∃x)(NOT(P(x))).\\n ■ (IF P THEN Q) ≡ (NOT(P) OR Q).\\n 8.30.  Show how you can specify the following relational algebra operations in \\nboth tuple and domain relational calculus.\\na. σA=C(R(A, B, C))\\nb. π<A, B>(R(A, B, C))\\nc. R(A, B, C) * S(C, D, E)\\nd. R(A, B, C) ∪ S(A, B, C)\\ne. R(A, B, C) ∩ S(A, B, C)\\nf. R(A, B, C) = S(A, B, C)\\ng. R(A, B, C) × S(D, E, F)\\nh. R(A, B) ÷ S(A)\\n 8.31.  Suggest extensions to the relational calculus so that it may express the fol-\\nlowing types of operations that were discussed in Section 8.4: (a) aggre-\\ngate functions and grouping; (b) \\nOUTER JOIN  operations; (c) recursive \\nclosure queries.\\n 8.32.  A nested query is a query within a query. More specifically, a nested query is \\na parenthesized query whose result can be used as a value in a number of \\nplaces, such as instead of a relation. Specify the following queries on the \\ndatabase specified in Figure 5.5 using the concept of nested queries and the \\nrelational operators discussed in this chapter. Also show the result of each \\nquery as it would apply to the database state in Figure 5.6.\\na. List the names of all employees who work in the department that has the \\nemployee with the highest salary among all employees.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 299, 'page_label': '300'}, page_content='286 Chapter 8 The Relational Algebra and Relational Calculus\\nb. List the names of all employees whose supervisor’s supervisor has \\n‘888665555’ for Ssn.\\nc. List the names of employees who make at least $10,000 more than the \\nemployee who is paid the least in the company.\\n 8.33.  State whether the following conclusions are true or false:\\na. NOT (P(x) OR Q(x)) → (NOT (P(x)) AND (NOT (Q(x)))\\nb. NOT (∃x) (P(x)) → ∀ x (NOT (P(x))\\nc. (∃x) (P(x)) → ∀ x ((P(x))\\nLaboratory Exercises\\n 8.34.  Specify and execute the following queries in relational algebra (RA) using \\nthe RA interpreter on the COMPANY database schema in Figure 5.5.\\na. List the names of all employees in department 5 who work more than 10 \\nhours per week on the ProductX project.\\nb. List the names of all employees who have a dependent with the same first \\nname as themselves.\\nc. List the names of employees who are directly supervised by Franklin Wong.\\nd. List the names of employees who work on every project.\\ne. List the names of employees who do not work on any project.\\nf. List the names and addresses of employees who work on at least one \\nproject located in Houston but whose department has no location in \\nHouston.\\ng. List the names of department managers who have no dependents.\\n 8.35.  Consider the following MAILORDER relational schema describing the data \\nfor a mail order company.\\nPARTS(Pno, Pname, Qoh, Price, Olevel)\\nCUSTOMERS(Cno, Cname, Street, Zip, Phone)\\nEMPLOYEES(Eno, Ename, Zip, Hdate)\\nZIP_CODE S(Zip, City)\\nORDERS(Ono, Cno, Eno, Received, Shipped)\\nODETAILS(Ono, Pno, Qty)\\n  Qoh stands for quantity on hand : the other attribute names are self-\\nexplanatory. Specify and execute the following queries using the RA \\ninterpreter on the MAILORDER  database schema.\\na. Retrieve the names of parts that cost less than $20.00.\\nb. Retrieve the names and cities of employees who have taken orders for \\nparts costing more than $50.00.\\nc. Retrieve the pairs of customer number values of customers who live in \\nthe same ZIP Code.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 300, 'page_label': '301'}, page_content='Laboratory Exercises 287\\nd. Retrieve the names of customers who have ordered parts from employees \\nliving in Wichita.\\ne. Retrieve the names of customers who have ordered parts costing less than \\n$20.00.\\nf. Retrieve the names of customers who have not placed an order.\\ng. Retrieve the names of customers who have placed exactly two orders.\\n 8.36.  Consider the following GRADEBOOK relational schema describing the data \\nfor a grade book of a particular instructor. ( Note: The attributes A, B, C,  \\nand D of COURSES store grade cutoffs.)\\nCATALOG(Cno, Ctitle)\\nSTUDENTS(Sid, Fname, Lname, Minit)\\nCOURSES(Term, Sec_no, Cno, A, B, C, D)\\nENROLLS(Sid, Term, Sec_no)\\n  Specify and execute the following queries using the RA interpreter on the \\nGRADEBOOK database schema.\\na. Retrieve the names of students enrolled in the Automata class during the \\nfall 2009 term.\\nb. Retrieve the Sid values of students who have enrolled in CSc226 and \\nCSc227.\\nc. Retrieve the Sid values of students who have enrolled in CSc226 or \\nCSc227.\\nd. Retrieve the names of students who have not enrolled in any class.\\ne. Retrieve the names of students who have enrolled in all courses in the \\nCATALOG table.\\n 8.37.  Consider a database that consists of the following relations.\\nSUPPLIER(Sno, Sname)\\nPART(Pno, Pname)\\nPROJECT(Jno, Jname)\\nSUPPLY(Sno, Pno, Jno)\\n  The database records information about suppliers, parts, and projects and \\nincludes a ternary relationship between suppliers, parts, and projects. This \\nrelationship is a many-many-many relationship. Specify and execute the fol-\\nlowing queries using the RA interpreter.\\na. Retrieve the part numbers that are supplied to exactly two projects.\\nb. Retrieve the names of suppliers who supply more than two parts to \\nproject ‘J1’.\\nc. Retrieve the part numbers that are supplied by every supplier.\\nd. Retrieve the project names that are supplied by supplier ‘S1’ only.\\ne. Retrieve the names of suppliers who supply at least two different parts \\neach to at least two different projects.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 301, 'page_label': '302'}, page_content='288 Chapter 8 The Relational Algebra and Relational Calculus\\n 8.38.  Specify and execute the following queries for the database in Exercise 5.16 \\nusing the RA interpreter.\\na. Retrieve the names of students who have enrolled in a course that uses a \\ntextbook published by Addison-Wesley-Longman.\\nb. Retrieve the names of courses in which the textbook has been changed at \\nleast once.\\nc. Retrieve the names of departments that adopt textbooks published by \\nAddison-Wesley only.\\nd. Retrieve the names of departments that adopt textbooks written by \\nNavathe and published by Addison-Wesley.\\ne. Retrieve the names of students who have never used a book (in a course) \\nwritten by Navathe and published by Addison-Wesley.\\n 8.39.  Repeat Laboratory Exercises 8.34 through 8.38 in domain relational calculus \\n(DRC) by using the DRC interpreter.\\nSelected Bibliography\\nCodd (1970) defined the basic relational algebra. Date (1983a) discusses outer joins. \\nWork on extending relational operations is discussed by Carlis (1986) and Ozsoyo-\\nglu et al. (1985). Cammarata et al. (1989) extends the relational model integrity \\nconstraints and joins.\\nCodd (1971) introduced the language Alpha, which is based on concepts of tuple \\nrelational calculus. Alpha also includes the notion of aggregate functions, which \\ngoes beyond relational calculus. The original formal definition of relational calculus \\nwas given by Codd (1972), which also provided an algorithm that transforms any \\ntuple relational calculus expression to relational algebra. The QUEL (Stonebraker et \\nal., 1976) is based on tuple relational calculus, with implicit existential quantifiers, \\nbut no universal quantifiers, and was implemented in the INGRES system as a com-\\nmercially available language. Codd defined relational completeness of a query lan-\\nguage to mean at least as powerful as relational calculus. Ullman (1988) describes a \\nformal proof of the equivalence of relational algebra with the safe expressions of \\ntuple and domain relational calculus. Abiteboul et al. (1995) and Atzeni and deAn-\\ntonellis (1993) give a detailed treatment of formal relational languages.\\nAlthough ideas of domain relational calculus were initially proposed in the QBE \\nlanguage (Zloof, 1975), the concept was formally defined by Lacroix and Pirotte \\n(1977a). The experimental version of the Query-By-Example system is described in \\nZloof (1975). The ILL (Lacroix & Pirotte, 1977b) is based on domain relational cal-\\nculus. Whang et al. (1990) extends QBE with universal quantifiers. Visual query \\nlanguages, of which QBE is an example, are being proposed as a means of querying \\ndatabases; conferences such as the Visual Database Systems Working Conference \\n(e.g., Arisawa & Catarci (2000) or Zhou & Pu (2002)) present a number of propos-\\nals for such languages.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 302, 'page_label': '303'}, page_content='289\\n9\\nRelational Database  \\nDesign by ER- and  \\nEER-to-Relational Mapping\\nT\\nhis chapter discusses how to design a relational \\ndatabase schema  based on a conceptual schema \\ndesign. Figure 3.1 presented a high-level view of the database design process. In this \\nchapter we focus on the logical database design step of database design, which is \\nalso known as data model mapping . We present the procedures to create a rela-\\ntional schema from an entity–relationship (ER) or an enhanced ER (EER) schema. \\nOur discussion relates the constructs of the ER and EER models, presented in \\nChapters 3 and 4, to the constructs of the relational model, presented in Chapters 5 \\nthrough 8. Many computer-aided software engineering (CASE) tools are based on \\nthe ER or EER models, or other similar models, as we have discussed in Chapters 3 \\nand 4. Many tools use ER or EER diagrams or variations to develop the schema \\ngraphically and collect information about the data types and constraints, then con-\\nvert the ER/EER schema automatically into a relational database schema in the \\nDDL of a specific relational DBMS. The design tools employ algorithms similar to \\nthe ones presented in this chapter.\\nWe outline a seven-step algorithm in Section 9.1 to convert the basic ER model \\nconstructs—entity types (strong and weak), binary relationships (with various \\nstructural constraints), n-ary relationships, and attributes (simple, composite, \\nand multivalued)—into relations. Then, in Section 9.2, we continue the mapping \\nalgorithm by describing how to map EER model constructs—specializa- \\ntion/generalization and union types (categories)—into relations. Section 9.3 sum-\\nmarizes the chapter.\\nchapter 9'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 303, 'page_label': '304'}, page_content='290 Chapter 9 Relational Database Design by ER- and EER-to-Relational Mapping\\n9.1  Relational Database Design Using  \\nER-to-Relational Mapping\\n9.1.1 ER-to-Relational Mapping Algorithm\\nIn this section we describe the steps of an algorithm for ER-to-relational mapping. \\nWe use the COMPANY  database example to illustrate the mapping procedure. \\nThe COMPANY ER schema is shown again in Figure 9.1, and the corresponding \\nCOMPANY  relational database schema is shown in Figure 9.2 to illustrate the \\nEMPLOYEE\\nFname Minit Lname\\nName Address\\nSex\\nSalary\\nSsn\\nBdate\\nSupervisor Supervisee\\nSUPERVISION\\n1\\nN\\nHours\\nWORKS_ON\\nCONTROLS\\nM N\\n1\\nDEPENDENTS_OF\\nName\\nLocation\\nN\\n1\\n1 1\\nPROJECT\\nDEPARTMENT\\nLocations\\nName Number\\nNumber\\nNumber_of_employees\\nMANAGES\\nStart_date\\nWORKS_FOR 1N\\nN\\nDEPENDENT\\nSex Birth_date RelationshipName\\nFigure 9.1 \\nThe ER conceptual schema diagram for the COMPANY database.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 304, 'page_label': '305'}, page_content='9.1 Relational Database Design Using ER-to-Relational Mapping  291\\nmapping steps. We assume that the mapping will create tables with simple single-\\nvalued attributes. The relational model constraints defined in Chapter 5, which \\ninclude primary keys, unique keys (if any), and referential integrity constraints on \\nthe relations, will also be specified in the mapping results.\\nStep 1: Mapping of Regular Entity Types. For each regular (strong) entity type \\nE in the ER schema, create a relation R that includes all the simple attributes of E. \\nInclude only the simple component attributes of a composite attribute. Choose one \\nof the key attributes of E as the primary key for R. If the chosen key of E is a com-\\nposite, then the set of simple attributes that form it will together form the primary \\nkey of R.\\nIf multiple keys were identified for E during the conceptual design, the information \\ndescribing the attributes that form each additional key is kept in order to specify \\nadditional (unique) keys of relation R. Knowledge about keys is also kept for index-\\ning purposes and other types of analyses.\\nIn our example, we create the relations \\nEMPLOYEE, DEPARTMENT, and PROJECT in \\nFigure 9.2 to correspond to the regular entity types EMPLOYEE, DEPARTMENT, and \\nPROJECT from Figure 9.1. The foreign key and relationship attributes, if any,  \\nare not included yet; they will be added during subsequent steps. These include  \\nDEPARTMENT\\nFname Minit Lname Ssn Bdate Address Sex Salary Super_ssn Dno\\nEMPLOYEE\\nDEPT_LOCATIONS\\nDnumber Dlocation\\nPROJECT\\nPname Pnumber Plocation Dnum\\nWORKS_ON\\nEssn Pno Hours\\nDEPENDENT\\nEssn Dependent_name Sex Bdate Relationship\\nDname Dnumber Mgr_ssn Mgr_start_date\\nFigure 9.2 \\nResult of mapping the \\nCOMPANY ER schema \\ninto a relational database \\nschema.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 305, 'page_label': '306'}, page_content='292 Chapter 9 Relational Database Design by ER- and EER-to-Relational Mapping\\nthe attributes Super_ssn  and Dno of EMPLOYEE , Mgr_ssn and Mgr_start_date  of \\nDEPARTMENT, and Dnum of PROJECT. In our example, we choose Ssn, Dnumber, and \\nPnumber as primary keys for the relations EMPLOYEE, DEPARTMENT, and PROJECT, \\nrespectively. Knowledge that Dname of DEPARTMENT and Pname of PROJECT are \\nunique keys is kept for possible use later in the design.\\nThe relations that are created from the mapping of entity types are sometimes called \\nentity relations because each tuple represents an entity instance. The result after \\nthis mapping step is shown in Figure 9.3(a).\\nStep 2: Mapping of Weak Entity Types. For each weak entity type W in the \\nER schema with owner entity type E, create a relation R and include all simple \\nattributes (or simple components of composite attributes) of W as attributes of \\nR. In addition, include as foreign key attributes of R, the primary key attribute(s) \\nof the relation(s) that correspond to the owner entity type(s); this takes care of \\nmapping the identifying relationship type of W. The primary key of R is the \\ncombination of the primary key(s) of the owner(s) and the partial key of the \\nweak entity type W, if any. If there is a weak entity type E\\n2 whose owner is also \\na weak entity type E1, then E1 should be mapped before E2 to determine its \\nprimary key first.\\nIn our example, we create the relation DEPENDENT in this step to correspond to  \\nthe weak entity type DEPENDENT (see Figure 9.3(b)). We include the primary key \\nSsn of the EMPLOYEE relation—which corresponds to the owner entity type— \\nas a foreign key attribute of DEPENDENT; we rename it Essn, although this is not  \\nDEPARTMENT\\nFname Minit Lname Ssn Bdate Address Sex Salary\\nEMPLOYEE\\nWORKS_ON\\nEssn Pno Hours\\nDname Dnumber\\nDEPT_LOCATIONS\\nDnumber Dlocation\\nPROJECT\\nPname Pnumber Plocation\\nDEPENDENT\\n(a)\\n(c)\\n(d)\\n(b)\\nEssn Dependent_name Sex Bdate Relationship\\nFigure 9.3 \\nIllustration of some  \\nmapping steps.\\n(a) Entity relations  \\nafter step 1.\\n(b) Additional weak entity \\nrelation after step 2.\\n(c) Relationship relations \\nafter step 5.\\n(d) Relation representing \\nmultivalued attribute  \\nafter step 6.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 306, 'page_label': '307'}, page_content='9.1 Relational Database Design Using ER-to-Relational Mapping  293\\nnecessary. The primary key of the DEPENDENT relation is the combination { Essn, \\nDependent_name}, because Dependent_name (also renamed from Name in Figure 9.1) \\nis the partial key of DEPENDENT.\\nIt is common to choose the propagate ( CASCADE) option for the referential trig-\\ngered action (see Section 6.2) on the foreign key in the relation corresponding to \\nthe weak entity type, since a weak entity has an existence dependency on its owner \\nentity. This can be used for both \\nON UPDATE and ON DELETE.\\nStep 3: Mapping of Binary 1:1 Relationship Types. For each binary 1:1 rela-\\ntionship type R in the ER schema, identify the relations S and T that correspond  \\nto the entity types participating in R. There are three possible approaches: (1) the \\nforeign key approach, (2) the merged relationship approach, and (3) the cross- \\nreference or relationship relation approach. The first approach is the most useful \\nand should be followed unless special conditions exist, as we discuss below.\\n  1. Foreign key approach: Choose one of the relations—S, say—and include as \\na foreign key in S the primary key of T. It is better to choose an entity type \\nwith total participation in R in the role of S. Include all the simple attributes \\n(or simple components of composite attributes) of the 1:1 relationship type \\nR as attributes of S.\\nIn our example, we map the 1:1 relationship type \\nMANAGES from Figure 9.1 \\nby choosing the participating entity type DEPARTMENT to serve in the role \\nof S because its participation in the MANAGES relationship type is total \\n(every department has a manager). We include the primary key of the \\nEMPLOYEE relation as foreign key in the DEPARTMENT relation and rename \\nit to Mgr_ssn. We also include the simple attribute Start_date of the MANAGES \\nrelationship type in the DEPARTMENT relation and rename it Mgr_start_date \\n(see Figure 9.2 ).\\nNote that it is possible to include the primary key of S as a foreign key in T \\ninstead. In our example, this amounts to having a foreign key attribute, say \\nDepartment_managed in the EMPLOYEE relation, but it will have a NULL value \\nfor employee tuples who do not manage a department. This would be a bad \\nchoice, because if only 2% of employees manage a department, then 98% of \\nthe foreign keys would be NULL in this case. Another possibility is to have \\nforeign keys in both relations S and T redundantly, but this creates redun-\\ndancy and incurs a penalty for consistency maintenance.\\n  2. Merged relation approach:  An alternative mapping of a 1:1 relationship \\ntype is to merge the two entity types and the relationship into a single rela-\\ntion. This is possible when both participations are total,  as this would indi-\\ncate that the two tables will have the exact same number of tuples at all times.\\n  3. Cross-reference or relationship relation approach:  The third option is to \\nset up a third relation R for the purpose of cross-referencing the primary \\nkeys of the two relations S and T representing the entity types. As we will see, \\nthis approach is required for binary M:N relationships. The relation R is \\ncalled a relationship relation (or sometimes a lookup table), because each'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 307, 'page_label': '308'}, page_content='294 Chapter 9 Relational Database Design by ER- and EER-to-Relational Mapping\\ntuple in R represents a relationship instance that relates one tuple from S \\nwith one tuple from T. The relation R will include the primary key attributes \\nof S and T as foreign keys to S and T. The primary key of R will be one of the \\ntwo foreign keys, and the other foreign key will be a unique key of R. The \\ndrawback is having an extra relation, and requiring extra join operations \\nwhen combining related tuples from the tables.\\nStep 4: Mapping of Binary 1:N Relationship Types. There are two possible \\napproaches: (1) the foreign key approach and (2) the cross-reference or relationship \\nrelation approach. The first approach is generally preferred as it reduces the num-\\nber of tables.\\n  1. The foreign key approach: For each regular binary 1:N relationship type R, \\nidentify the relation S that represents the participating entity type at the \\nN-side of the relationship type. Include as foreign key in S the primary key of \\nthe relation T that represents the other entity type participating in R; we do \\nthis because each entity instance on the N-side is related to at most one \\nentity instance on the 1-side of the relationship type. Include any simple \\nattributes (or simple components of composite attributes) of the 1:N rela-\\ntionship type as attributes of S.\\nTo apply this approach to our example, we map the 1:N relationship types \\nWORKS_FOR, CONTROLS, and SUPERVISION from Figure 9.1. For  \\nWORKS_FOR we include the primary key Dnumber of the DEPARTMENT relation \\nas foreign key in the EMPLOYEE relation and call it Dno. For SUPERVISION we \\ninclude the primary key of the EMPLOYEE relation as foreign key in the \\nEMPLOYEE relation itself—because the relationship is recursive—and call it \\nSuper_ssn. The CONTROLS relationship is mapped to the foreign key attri-\\nbute Dnum of PROJECT, which references the primary key Dnumber of the \\nDEPARTMENT relation. These foreign keys are shown in Figure 9.2.\\n  2. The relationship relation approach:  An alternative approach is to use the \\nrelationship relation  (cross-reference) option as in the third option for \\nbinary 1:1 relationships. We create a separate relation R whose attributes are \\nthe primary keys of S and T, which will also be foreign keys to S and T. The \\nprimary key of R is the same as the primary key of S. This option can be used \\nif few tuples in S participate in the relationship to avoid excessive NULL val-\\nues in the foreign key.\\nStep 5: Mapping of Binary M:N Relationship Types. In the traditional rela-\\ntional model with no multivalued attributes, the only option for M:N relationships \\nis the relationship relation (cross-reference) option . For each binary M:N rela-\\ntionship type R, create a new relation S to represent R. Include as foreign key attri-\\nbutes in S the primary keys of the relations that represent the participating entity \\ntypes; their combination will form the primary key of S. Also include any simple \\nattributes of the M:N relationship type (or simple components of composite attri-\\nbutes) as attributes of S. Notice that we cannot represent an M:N relationship type \\nby a single foreign key attribute in one of the participating relations (as we did for'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 308, 'page_label': '309'}, page_content='9.1 Relational Database Design Using ER-to-Relational Mapping  295\\n1:1 or 1:N relationship types) because of the M:N cardinality ratio; we must create a \\nseparate relationship relation S.\\nIn our example, we map the M:N relationship type WORKS_ON from Figure 9.1 by \\ncreating the relation WORKS_ON in Figure 9.2. We include the primary keys of the \\nPROJECT and EMPLOYEE  relations as foreign keys in WORKS_ON  and rename \\nthem Pno and Essn, respectively (renaming is not required;  it is a design choice). \\nWe also include an attribute Hours in WORKS_ON to represent the Hours attribute \\nof the relationship type. The primary key of the WORKS_ON relation is the combi-\\nnation of the foreign key attributes { Essn, Pno}. This relationship relation  is \\nshown in Figure 9.3(c).\\nThe propagate ( CASCADE) option for the referential triggered action (see Sec- \\ntion 4.2) should be specified on the foreign keys in the relation corresponding to the \\nrelationship R, since each relationship instance has an existence dependency on \\neach of the entities it relates. This can be used for both \\nON UPDATE and ON DELETE.\\nAlthough we can map 1:1 or 1:N relationships in a manner similar to M:N relation-\\nships by using the cross-reference (relationship relation) approach, as we discussed \\nearlier, this is only recommended when few relationship instances exist, in order to \\navoid \\nNULL values in foreign keys. In this case, the primary key of the relationship \\nrelation will be only one of the foreign keys that reference the participating entity \\nrelations. For a 1:N relationship, the primary key of the relationship relation will be \\nthe foreign key that references the entity relation on the N-side. For a 1:1 relation-\\nship, either foreign key can be used as the primary key of the relationship relation.\\nStep 6: Mapping of Multivalued Attributes. For each multivalued attribute A, \\ncreate a new relation R. This relation R will include an attribute corresponding to A, \\nplus the primary key attribute K—as a foreign key in R—of the relation that repre-\\nsents the entity type or relationship type that has A as a multivalued attribute. The \\nprimary key of R is the combination of A and K. If the multivalued attribute is com-\\nposite, we include its simple components.\\nIn our example, we create a relation DEPT_LOCATIONS  (see Figure 9.3(d)).  \\nThe attribute Dlocation  represents the multivalued attribute LOCATIONS  of  \\nDEPARTMENT, whereas Dnumber—as foreign key—represents the primary key of the \\nDEPARTMENT relation. The primary key of DEPT_LOCATIONS is the combination of \\n{Dnumber, Dlocation}. A separate tuple will exist in DEPT_LOCATIONS for each loca-\\ntion that a department has. It is important to note that in more recent versions of \\nthe relational model that allow array data types, the multivalued attribute can be \\nmapped to an array attribute rather than requiring a separate table.\\nThe propagate ( CASCADE) option for the referential triggered action (see Sec- \\ntion 6.2) should be specified on the foreign key in the relation R corresponding to the \\nmultivalued attribute for both ON UPDATE and ON DELETE. We should also note \\nthat the key of R when mapping a composite, multivalued attribute requires some \\nanalysis of the meaning of the component attributes. In some cases, when a multi-\\nvalued attribute is composite, only some of the component attributes are required'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 309, 'page_label': '310'}, page_content='296 Chapter 9 Relational Database Design by ER- and EER-to-Relational Mapping\\nto be part of the key of R; these attributes are similar to a partial key of a weak entity \\ntype that corresponds to the multivalued attribute (see Section 3.5).\\nFigure 9.2 shows the COMPANY relational database schema obtained with steps 1 \\nthrough 6, and Figure 5.6 shows a sample database state. Notice that we did not yet \\ndiscuss the mapping of n-ary relationship types ( n > 2) because none exist in Fig-\\nure 9.1 ; these are mapped in a similar way to M:N relationship types by including \\nthe following additional step in the mapping algorithm.\\nStep 7: Mapping of N-ary Relationship Types. We use the relationship  \\nrelation option. For each n-ary relationship type R, where n > 2, create a new relation-\\nship relation S to represent R. Include as foreign key attributes in S the primary keys \\nof the relations that represent the participating entity types. Also include any simple \\nattributes of the n-ary relationship type (or simple components of composite attri-\\nbutes) as attributes of S. The primary key of S is usually a combination of all the \\nforeign keys that reference the relations representing the participating entity types. \\nHowever, if the cardinality constraints on any of the entity types E participating in \\nR is 1, then the primary key of S should not include the foreign key attribute that \\nreferences the relation E′ corresponding to E (see the discussion in Section 3.9.2 \\nconcerning constraints on n-ary relationships).\\nConsider the ternary relationship type \\nSUPPLY in Figure 3.17, which relates a \\nSUPPLIER s, PART p, and PROJECT j whenever s is currently supplying p to j; this \\ncan be mapped to the relation SUPPLY shown in Figure 9.4, whose primary key is the \\ncombination of the three foreign keys {Sname, Part_no, Proj_name}.\\n9.1.2  Discussion and Summary of Mapping  \\nfor ER Model Constructs\\nTable 9.1 summarizes the correspondences between ER and relational model con-\\nstructs and constraints.\\nSUPPLIER\\nSname\\nPROJECT\\nProj_name\\nSUPPLY\\nSname Proj_name Part_no Quantity\\nPART\\nPart_no\\n. . .\\n. . .\\n. . .\\nFigure 9.4 \\nMapping the n-ary  \\nrelationship type  \\nSUPPLY from  \\nFigure 3.17(a).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 310, 'page_label': '311'}, page_content='9.1 Relational Database Design Using ER-to-Relational Mapping  297\\nTable 9.1   Correspondence between ER and Relational Models\\nER MODEL RELATIONAL MODEL\\nEntity type Entity relation\\n1:1 or 1:N relationship type Foreign key (or relationship relation)\\nM:N relationship type Relationship relation and two foreign keys\\nn-ary relationship type Relationship relation and n foreign keys\\nSimple attribute Attribute\\nComposite attribute Set of simple component attributes\\nMultivalued attribute Relation and foreign key\\nValue set Domain\\nKey attribute Primary (or secondary) key\\nOne of the main points to note in a relational schema, in contrast to an ER \\nschema, is that relationship types are not represented explicitly; instead, they \\nare represented by having two attributes A and B, one a primary key and the \\nother a foreign key (over the same domain) included in two relations S and T. \\nTwo tuples in S and T are related when they have the same value for A and B. By \\nusing the \\nEQUIJOIN  operation (or NATURAL JOIN  if the two join attributes have \\nthe same name) over S.A and T.B, we can combine all pairs of related tuples \\nfrom S and T and materialize the relationship. When a binary 1:1 or 1:N rela-\\ntionship type is involved and the foreign key mapping is used, a single join \\noperation is usually needed. When the relationship relation approach is used, \\nsuch as for a binary M:N relationship type, two join operations are needed, \\nwhereas for n-ary relationship types, n joins are needed to fully materialize the \\nrelationship instances.\\nFor example, to form a relation that includes the employee name, project name, \\nand hours that the employee works on each project, we need to connect  \\neach \\nEMPLOYEE  tuple to the related PROJECT  tuples via the WORKS_ON   \\nrelation in Figure 9.2. Hence, we must apply the EQUIJOIN  operation to  \\nthe EMPLOYEE  and WORKS_ON  relations with the join condition  \\nEMPLOYEE. Ssn = WORKS_ON. Essn, and then apply another EQUIJOIN  opera-\\ntion to the resulting relation and the PROJECT  relation with join condition \\nWORKS_ON. Pno = PROJECT. Pnumber . In general, when multiple relationships \\nneed to be traversed, numerous join operations must be specified. The user \\nmust always be aware of the foreign key attributes in order to use them cor-\\nrectly in combining related tuples from two or more relations. This is some-\\ntimes considered to be a drawback of the relational data model, because the \\nforeign key/primary key correspondences are not always obvious upon inspec-\\ntion of relational schemas. If an \\nEQUIJOIN  is performed among attributes of two \\nrelations that do not represent a foreign key/primary key relationship, the result \\ncan often be meaningless and may lead to spurious data. For example, the \\nreader can try joining the \\nPROJECT  and DEPT_LOCATIONS  relations on the con-\\ndition Dlocation  = Plocation  and examine the result.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 311, 'page_label': '312'}, page_content='298 Chapter 9 Relational Database Design by ER- and EER-to-Relational Mapping\\nIn the relational schema we create a separate relation for each multivalued attribute. \\nFor a particular entity with a set of values for the multivalued attribute, the key \\nattribute value of the entity is repeated once for each value of the multivalued attri-\\nbute in a separate tuple because the basic relational model does not allow multiple \\nvalues (a list, or a set of values) for an attribute in a single tuple. For example, \\nbecause department 5 has three locations, three tuples exist in the \\nDEPT_LOCATIONS \\nrelation in Figure 3.6; each tuple specifies one of the locations. In our example, we \\napply \\nEQUIJOIN to DEPT_LOCATIONS and DEPARTMENT on the Dnumber attribute to \\nget the values of all locations along with other DEPARTMENT attributes. In the result-\\ning relation, the values of the other DEPARTMENT attributes are repeated in separate \\ntuples for every location that a department has.\\nThe basic relational algebra does not have a NEST or COMPRESS operation that \\nwould produce a set of tuples of the form {<‘1’, ‘Houston’>, <‘4’, ‘Stafford’>, <‘5’, \\n{‘Bellaire’, ‘Sugarland’, ‘Houston’}>} from the \\nDEPT_LOCATIONS relation in Figure 3.6. \\nThis is a serious drawback of the basic normalized or flat version of the relational \\nmodel. The object data model and object-relational systems (see Chapter 12) do \\nallow multivalued attributes by using the array type for the attribute.\\n9.2  Mapping EER Model Constructs  \\nto Relations\\nIn this section, we discuss the mapping of EER model constructs to relations by \\nextending the ER-to-relational mapping algorithm that was presented in Sec-\\ntion 9.1.1.\\n9.2.1 Mapping of Specialization or Generalization\\nThere are several options for mapping a number of subclasses that together form a \\nspecialization (or alternatively, that are generalized into a superclass), such as the \\n{\\nSECRETARY, TECHNICIAN, ENGINEER} subclasses of EMPLOYEE in Figure 4.4. The \\ntwo main options are to map the whole specialization into a single table, or to map \\nit into multiple tables. Within each option are variations that depend on the con-\\nstraints on the specialization/generalization.\\nWe can add a further step to our ER-to-relational mapping algorithm from Sec- \\ntion 9.1.1, which has seven steps, to handle the mapping of specialization. Step 8, \\nwhich follows, gives the most common options; other mappings are also possible. \\nWe discuss the conditions under which each option should be used. We use Attrs(R) \\nto denote the attributes of a relation R , and PK(R) to denote the primary key of R . \\nFirst we describe the mapping formally, then we illustrate it with examples.\\nStep 8: Options for Mapping Specialization or Generalization. Convert \\neach specialization with m subclasses { S\\n1, S2, … , Sm} and (generalized) super- \\nclass C, where the attributes of C are {k, a1, … , an} and k is the (primary) key, into \\nrelation schemas using one of the following options:'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 312, 'page_label': '313'}, page_content='9.2 Mapping EER Model Constructs to Relations  299\\n ■ Option 8A: Multiple relations—superclass and subclasses.  Create a  \\nrelation L for C with attributes Attrs( L) = { k, a1, … , an} and PK( L) = k.  \\nCreate a relation Li for each subclass Si, 1 ≤ i ≤ m, with the attributes  \\nAttrs(Li) = {k} ∪ {attributes of Si} and PK(Li) = k. This option works for any \\nspecialization (total or partial, disjoint or overlapping).\\n ■ Option 8B: Multiple relations—subclass relations only.  Create a  \\nrelation Li for each subclass Si, 1 ≤ i ≤ m, with the attributes  \\nAttrs(Li) = {attributes of Si} ∪ {k, a1, … , an} and PK(Li) = k. This option only \\nworks for a specialization whose subclasses are total (every entity in the \\nsuperclass must belong to (at least) one of the subclasses). Additionally, it is \\nonly recommended if the specialization has the disjointedness constraint (see \\nSection 4.3.1). If the specialization is overlapping, the same entity may be \\nduplicated in several relations.\\n ■ Option 8C: Single relation with one type attribute. Create a single relation \\nL with attributes Attrs(L) = {k, a1, …, an} ∪ {attributes of S1} ∪ … ∪ {attri-\\nbutes of Sm} ∪ { t} and PK( L) = k. The attribute t is called a type (or  \\ndiscriminating) attribute whose value indicates the subclass to which each \\ntuple belongs, if any. This option works only for a specialization whose sub-\\nclasses are disjoint, and has the potential for generating many NULL values if \\nmany specific (local) attributes exist in the subclasses.\\n ■ Option 8D: Single relation with multiple type attributes.  Create a single \\nrelation schema L with attributes Attrs( L) = { k, a1, …, an} ∪ {attributes \\nof S1} ∪ … ∪ {attributes of Sm} ∪ {t1, t2, …, tm} and PK( L) = k. Each ti,  \\n1 ≤ i ≤ m, is a Boolean type attribute  indicating whether or not a tuple \\nbelongs to subclass Si. This option is used for a specialization whose sub-\\nclasses are overlapping (but will also work for a disjoint specialization).\\nOptions 8A and 8B are the multiple-relation options, whereas options 8C and 8D are \\nthe single-relation options. Option 8A creates a relation L for the superclass C and its \\nattributes, plus a relation Li for each subclass Si; each Li includes the specific (local) \\nattributes of Si, plus the primary key of the superclass C, which is propagated to Li and \\nbecomes its primary key. It also becomes a foreign key to the superclass relation. An \\nEQUIJOIN operation on the primary key between any Li and L produces all the specific \\nand inherited attributes of the entities in Si. This option is illustrated in Figure 9.5(a) \\nfor the EER schema in Figure 4.4. Option 8A works for any constraints on the special-\\nization: disjoint or overlapping, total or partial. Notice that the constraint\\nπ\\n<k>(Li) ⊆ π<k>(L)\\nmust hold for each Li. This specifies a foreign key from each Li to L.\\nIn option 8B, the EQUIJOIN operation between each subclass and the superclass is \\nbuilt into the schema and the superclass relation L is done away with, as illustrated \\nin Figure 9.5(b) for the EER specialization in Figure 4.3(b). This option works well \\nonly when both the disjoint and total constraints hold. If the specialization is not \\ntotal, an entity that does not belong to any of the subclasses S\\ni is lost. If the special-\\nization is not disjoint, an entity belonging to more than one subclass will have its'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 313, 'page_label': '314'}, page_content='300 Chapter 9 Relational Database Design by ER- and EER-to-Relational Mapping\\ninherited attributes from the superclass C stored redundantly in more than one table Li. \\nWith option 8B, no relation holds all the entities in the superclass C; consequently, we \\nmust apply an OUTER UNION (or FULL OUTER JOIN) operation (see Section 6.4) to the Li \\nrelations to retrieve all the entities in C. The result of the outer union will be similar to \\nthe relations under options 8C and 8D except that the type fields will be missing. When-\\never we search for an arbitrary entity in C, we must search all the m relations L\\ni.\\nOptions 8C and 8D create a single relation to represent the superclass C and all its \\nsubclasses. An entity that does not belong to some of the subclasses will have NULL \\nvalues for the specific (local) attributes of these subclasses. These options are not \\nrecommended if many specific attributes are defined for the subclasses. If few local \\nsubclass attributes exist, however, these mappings are preferable to options 8A  \\nand 8B because they do away with the need to specify \\nJOIN operations; therefore, \\nthey can yield a more efficient implementation for queries.\\nOption 8C is used to handle disjoint subclasses by including a single type (or image \\nor discriminating) attribute t to indicate to which of the m subclasses each tuple \\nbelongs; hence, the domain of t could be {1, 2, … , m}. If the specialization is partial, t \\ncan have NULL values in tuples that do not belong to any subclass. If the specialization \\nis attribute-defined, that attribute itself serves the purpose of t and t is not needed; this \\noption is illustrated in Figure 9.5(c) for the EER specialization in Figure 4.4.\\nOption 8D is designed to handle overlapping subclasses by including m Boolean \\ntype (or flag) fields, one for each subclass. It can also be used for disjoint subclasses. \\nSECRETARY\\nTyping_speed\\nTECHNICIAN\\nTgrade\\nENGINEER\\nEng_type\\nCAR\\nLicense_plate_no Price Max_speed No_of_passengers\\nTRUCK\\nLicense_plate_no Price No_of_axles Tonnage\\nEMPLOYEE\\nSsn Fname Minit Lname Birth_date Address Typing_speed Tgrade Eng_typeJob_type\\nPART\\nDescription Mflag Drawing_no Batch_no Pflag List_priceSupplier_nameManufacture_date\\nFname Minit Lname Birth_date Address Job_type\\nEMPLOYEE(a)\\n(b)\\n(c)\\n(d)\\nSsn\\nSsn Ssn Ssn\\nVehicle_id\\nVehicle_id\\nPart_no\\nFigure 9.5 \\nOptions for mapping specialization or generalization. (a) Mapping the EER schema in Figure 4.4 using option 8A.  \\n(b) Mapping the EER schema in Figure 4.3(b) using option 8B. (c) Mapping the EER schema in Figure 4.4 using \\noption 8C. (d) Mapping Figure 4.5 using option 8D with Boolean type fields Mflag and Pflag.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 314, 'page_label': '315'}, page_content='9.2 Mapping EER Model Constructs to Relations  301\\nEach type field ti can have a domain {yes, no}, where a value of yes indicates that the \\ntuple is a member of subclass Si. If we use this option for the EER specialization in \\nFigure 4.4, we would include three type attributes—Is_a_secretary, Is_a_engineer, and \\nIs_a_technician —instead of the Job_type attribute in Figure 9.5(c). Figure 9.5(d) \\nshows the mapping of the specialization from Figure 4.5 using option 8D.\\nFor a multilevel specialization (or generalization) hierarchy or lattice, we do not have \\nto follow the same mapping option for all the specializations. Instead, we can use one \\nmapping option for part of the hierarchy or lattice and other options for other parts. \\nFigure 9.6 shows one possible mapping into relations for the EER lattice in Figure 4.6. \\nHere we used option 8A for \\nPERSON/{EMPLOYEE, ALUMNUS, STUDENT}, and option \\n8C for EMPLOYEE /{STAFF, FACULTY, STUDENT_ASSISTANT } by including the  \\ntype attribute Employee_type . We then used the single-table option 8D for  \\nSTUDENT_ASSISTANT/{RESEARCH_ASSISTANT, TEACHING_ASSISTANT} by including \\nthe type attributes Ta_flag and Ra_flag in EMPLOYEE. We also used option 8D for  \\nSTUDENT/STUDENT_ASSISTANT by including the type attributes Student_assist_flag \\nin STUDENT, and for STUDENT/{GRADUATE_STUDENT, UNDERGRADUATE_STUDENT} \\nby including the type attributes Grad_flag and Undergrad_flag in STUDENT. In Figure 9.6, \\nall attributes whose names end with type or flag are type fields.\\n9.2.2 Mapping of Shared Subclasses (Multiple Inheritance)\\nA shared subclass, such as ENGINEERING_MANAGER in Figure 4.6, is a subclass of \\nseveral superclasses, indicating multiple inheritance. These classes must all have the \\nsame key attribute; otherwise, the shared subclass would be modeled as a category \\n(union type) as we discussed in Section 4.4. We can apply any of the options dis-\\ncussed in step 8 to a shared subclass, subject to the restrictions discussed in step 8 of \\nthe mapping algorithm. In Figure 9.6, options 8C and 8D are used for the shared \\nsubclass \\nSTUDENT_ASSISTANT . Option 8C is used in the EMPLOYEE  relation \\n(Employee_type  attribute) and option 8D is used in the STUDENT  relation  \\n(Student_assist_flag attribute).\\nEMPLOYEE\\nSalary Employee_type Position Rank Percent_time Ra_flag Ta_flag Project Course\\nSTUDENT\\nMajor_dept Grad_flag Undergrad_flag Degree_program Class Student_assist_flag\\nName Birth_date Sex Address\\nPERSON\\nSsn\\nALUMNUS ALUMNUS_DEGREES\\nYear MajorSsn\\nSsn\\nSsn\\nSsn Degree\\nFigure 9.6 \\nMapping the EER specialization \\nlattice in Figure 4.8 using  \\nmultiple options.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 315, 'page_label': '316'}, page_content='302 Chapter 9 Relational Database Design by ER- and EER-to-Relational Mapping\\n9.2.3 Mapping of Categories (Union Types)\\nWe add another step to the mapping procedure—step 9—to handle categories. A \\ncategory (or union type) is a subclass of the union of two or more superclasses \\nthat can have different keys because they can be of different entity types (see Sec-\\ntion 4.4). An example is the \\nOWNER category shown in Figure 4.8, which is a \\nsubset of the union of three entity types PERSON, BANK, and COMPANY . The \\nother category in that figure, REGISTERED_VEHICLE , has two superclasses that \\nhave the same key attribute.\\nStep 9: Mapping of Union Types (Categories). For mapping a category whose \\ndefining superclasses have different keys, it is customary to specify a new key attri-\\nbute, called a surrogate key, when creating a relation to correspond to the union \\ntype. The keys of the defining classes are different, so we cannot use any one of \\nthem exclusively to identify all entities in the relation. In our example in Figure 4.8, \\nwe create a relation \\nOWNER to correspond to the OWNER category, as illustrated in \\nFigure 9.7, and include any attributes of the category in this relation. The primary \\nkey of the \\nOWNER relation is the surrogate key, which we called Owner_id. We also \\nDriver_license_no Name Address Owner_id\\nPERSON\\nSsn\\nBANK\\nBaddress Owner_idBname\\nCOMPANY\\nCaddress Owner_idCname\\nOWNER\\nOwner_id\\nREGISTERED_VEHICLE\\nLicense_plate_number Vehicle_id\\nCAR\\nCstyle Cmake Cmodel CyearVehicle_id\\nTRUCK\\nTmake Tmodel Tonnage TyearVehicle_id\\nOWNS\\nPurchase_date Lien_or_regularOwner_id Vehicle_id\\nFigure 9.7 \\nMapping the EER categories \\n(union types) in Figure 4.8 to \\nrelations.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 316, 'page_label': '317'}, page_content='Exercises 303\\ninclude the surrogate key attribute Owner_id as foreign key in each relation corre-\\nsponding to a superclass of the category, to specify the correspondence in values \\nbetween the surrogate key and the original key of each superclass. Notice that if a \\nparticular \\nPERSON (or BANK or COMPANY) entity is not a member of OWNER, it \\nwould have a NULL value for its Owner_id attribute in its corresponding tuple in the \\nPERSON (or BANK or COMPANY) relation, and it would not have a tuple in the \\nOWNER relation. It is also recommended to add a type attribute (not shown in Fig-\\nure 9.7) to the OWNER relation to indicate the particular entity type to which each \\ntuple belongs (PERSON or BANK or COMPANY).\\nFor a category whose superclasses have the same key, such as VEHICLE in Figure 4.8, \\nthere is no need for a surrogate key. The mapping of the REGISTERED_VEHICLE  \\ncategory, which illustrates this case, is also shown in Figure 9.7.\\n9.3 Summary\\nIn Section 9.1, we showed how a conceptual schema design in the ER model can \\nbe mapped to a relational database schema. An algorithm for ER-to-relational \\nmapping was given and illustrated by examples from the \\nCOMPANY  database. \\nTable 9.1 summarized the correspondences between the ER and relational \\nmodel constructs and constraints. Next, we added additional steps to the algo-\\nrithm in Section 9.2 for mapping the constructs from the EER model into the \\nrelational model. Similar algorithms are incorporated into graphical database \\ndesign tools to create a relational schema from a conceptual schema design \\nautomatically.\\nReview Questions\\n 9.1. (a) Discuss the correspondences between the ER model constructs and the \\nrelational model constructs. Show how each ER model construct can be \\nmapped to the relational model and discuss any alternative mappings.  \\n(b) Discuss the options for mapping EER model constructs to relations, and \\nthe conditions under which each option could be used.\\nExercises\\n 9.2. Map the UNIVERSITY database schema shown in Figure 3.20 into a rela-\\ntional database schema.\\n 9.3. Try to map the relational schema in Figure 6.14 into an ER schema. This is \\npart of a process known as reverse engineering , where a conceptual schema \\nis created for an existing implemented database. State any assumptions \\nyou make.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 317, 'page_label': '318'}, page_content='304 Chapter 9 Relational Database Design by ER- and EER-to-Relational Mapping\\n 9.4. Figure 9.8 shows an ER schema for a database that can be used to keep track of \\ntransport ships and their locations for maritime authorities. Map this schema \\ninto a relational schema and specify all primary keys and foreign keys.\\n 9.5. Map the BANK ER schema of Exercise 3.23 (shown in Figure 3.21) into a \\nrelational schema. Specify all primary keys and foreign keys. Repeat for the \\nAIRLINE schema (Figure 3.20) of Exercise 3.19 and for the other schemas for \\nExercises 3.16 through 3.24.\\n 9.6. Map the EER diagrams in Figures 4.9 and 4.12 into relational schemas.  \\nJustify your choice of mapping options.\\n 9.7. Is it possible to successfully map a binary M:N relationship type without \\nrequiring a new relation? Why or why not?\\nTime_stamp\\nLongitude\\nLatitude\\nTime\\nSname\\nOwner\\nDate\\nTonnage\\nName\\nName\\nStart_date End_date\\nHullType1\\nN\\n1\\nN\\nN1\\nN 1\\n(0, *)\\n(0, *)\\n1\\n(1,1)\\nN\\nSHIP_MOVEMENT\\nHISTORY\\nSHIP TYPE SHIP_TYPE\\nHOME_PORT\\nPORT\\nPORT_VISIT\\nSTATE/COUNTRY\\nSEA/OCEAN/LAKE\\nSHIP_AT\\n_PORT\\nPname\\nContinent\\nIN\\nON\\nFigure 9.8 \\nAn ER schema for a SHIP_TRACKING database.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 318, 'page_label': '319'}, page_content='Laboratory Exercises 305\\n 9.8. Consider the EER diagram in Figure 9.9 for a car dealer.\\n  Map the EER schema into a set of relations. For the VEHICLE to CAR/TRUCK/SUV \\ngeneralization, consider the four options presented in Section 9.2.1 and show \\nthe relational schema design under each of those options.\\n 9.9. Using the attributes you provided for the EER diagram in Exercise 4.27, map \\nthe complete schema into a set of relations. Choose an appropriate option \\nout of 8A thru 8D from Section 9.2.1 in doing the mapping of generaliza-\\ntions and defend your choice.\\nLaboratory Exercises\\n 9.10. Consider the ER design for the UNIVERSITY database that was modeled using \\na tool like ERwin or Rational Rose in Laboratory Exercise 3.31. Using the \\nSQL schema generation feature of the modeling tool, generate the SQL \\nschema for an Oracle database.\\n 9.11. Consider the ER design for the MAIL_ORDER database that was modeled \\nusing a tool like ERwin or Rational Rose in Laboratory Exercise 3.32. Using \\nthe SQL schema generation feature of the modeling tool, generate the SQL \\nschema for an Oracle database.\\n 9.12. Consider the ER design for the CONFERENCE_REVIEW  database that was \\nmodeled using a tool like ERwin or Rational Rose in Laboratory Exer- \\ncise 3.34. Using the SQL schema generation feature of the modeling tool, \\ngenerate the SQL schema for an Oracle database.\\nName Name\\nModel\\nVEHICLE\\nPrice\\nDate\\nEngine_size\\nT onnage\\nNo_seats\\nCAR\\nTRUCK\\nSUV\\nd\\nSALESPERSON CUSTOMER\\nVin\\nSid Ssn State\\nAddress City\\nStreet\\nSALE\\n11\\nN\\nFigure 9.9 \\nEER diagram for \\na car dealer.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 319, 'page_label': '320'}, page_content='306 Chapter 9 Relational Database Design by ER- and EER-to-Relational Mapping\\n 9.13. Consider the EER design for the GRADE_BOOK database that was modeled \\nusing a tool like ERwin or Rational Rose in Laboratory Exercise 4.28. Using \\nthe SQL schema generation feature of the modeling tool, generate the SQL \\nschema for an Oracle database.\\n 9.14. Consider the EER design for the ONLINE_AUCTION database that was mod-\\neled using a tool like ERwin or Rational Rose in Laboratory Exercise 4.29. \\nUsing the SQL schema generation feature of the modeling tool, generate the \\nSQL schema for an Oracle database.\\nSelected Bibliography\\nThe original ER-to-relational mapping algorithm was described in Chen’s classic \\npaper (Chen, 1976). Batini et al. (1992) discuss a variety of mapping algorithms \\nfrom ER and EER models to legacy models and vice versa.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 320, 'page_label': '321'}, page_content='Database Programming \\nTechniques  \\npart 4'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 321, 'page_label': '322'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 322, 'page_label': '323'}, page_content='309\\n10\\nIntroduction to SQL  \\nProgramming Techniques\\nI\\nn Chapters 6 and 7, we described several aspects of the \\nSQL language, which is the standard for relational \\ndatabases. We described the SQL statements for data definition, schema modifica-\\ntion, queries, views, and updates. We also described how various constraints on the \\ndatabase contents, such as key and referential integrity constraints, are specified.\\nIn this chapter and the next, we discuss some of the methods that have been devel-\\noped for accessing databases from programs. Most database access in practical \\napplications is accomplished through software programs that implement database \\napplications. This software is usually developed in a general-purpose program-\\nming language such as Java, C/C++/C#, COBOL (historically), or some other pro-\\ngramming language. In addition, many scripting languages, such as PHP, Python, \\nand JavaScript, are also being used for programming of database access within Web \\napplications. In this chapter, we focus on how databases can be accessed from the \\ntraditional programming languages C/C++ and Java, whereas in the next chapter \\nwe introduce how databases are accessed from scripting languages such as PHP. \\nRecall from Section 2.3.1 that when database statements are included in a program, \\nthe general-purpose programming language is called the host language, whereas the \\ndatabase language—SQL, in our case—is called the data sublanguage . In some \\ncases, special database programming languages are developed specifically for writ-\\ning database applications. Although many of these were developed as research pro-\\ntotypes, some notable database programming languages have widespread use, such \\nas Oracle’s PL/SQL (Programming Language/SQL).\\nIt is important to note that database programming is a very broad topic. There are \\nwhole textbooks devoted to each database programming technique and how that \\ntechnique is realized in a specific system. New techniques are developed all the \\nchapter 10'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 323, 'page_label': '324'}, page_content='310 Chapter 10 Introduction to SQL Programming Techniques\\ntime, and changes to existing techniques are incorporated into newer system ver-\\nsions and languages. An additional difficulty in presenting this topic is that although \\nthere are SQL standards, these standards themselves are continually evolving, and \\neach DBMS vendor may have some variations from the standard. Because of this, \\nwe have chosen to give an introduction to some of the main types of database pro-\\ngramming techniques and to compare these techniques, rather than study one par-\\nticular method or system in detail. The examples we give serve to illustrate the main \\ndifferences that a programmer would face when using each of these database pro-\\ngramming techniques. We will try to use the SQL standards in our examples rather \\nthan describe a specific system. When using a specific system, the materials in this \\nchapter can serve as an introduction, but should be augmented with the system \\nmanuals or with books describing the specific system.\\nWe start our presentation of database programming in Section 10.1 with an over-\\nview of the different techniques developed for accessing a database from programs. \\nThen, in Section 10.2, we discuss the rules for embedding SQL statements into a \\ngeneral-purpose programming language, generally known as embedded SQL. This \\nsection also briefly discusses dynamic SQL , in which queries can be dynamically \\nconstructed at runtime, and presents the basics of the SQLJ variation of embedded \\nSQL that was developed specifically for the programming language Java. In Sec-\\ntion 10.3, we discuss the technique known as SQL/CLI (Call Level Interface), in which \\na library of procedures and functions is provided for accessing the database. Various \\nsets of library functions have been proposed. The SQL/CLI set of functions is the \\none given in the SQL standard. Another widely used library of functions is ODBC \\n(Open Data Base Connectivity), which has many similarities to SQL/CLI; in fact, \\nSQL/CLI can be thought of as the standardized version of ODBC. A third library of \\nclasses—which we do describe—is JDBC; this was developed specifically for access-\\ning databases from the Java object-oriented programming language (OOPL). In \\nOOPL, a library of classes is used instead of a library of functions and procedures, \\nand each class has its own operations and functions. In Section 10.4 we discuss \\nSQL/PSM (Persistent Stored Modules), which is a part of the SQL standard that \\nallows program modules—procedures and functions—to be stored by the DBMS \\nand accessed through SQL; this also specifies a procedural database programming \\nlanguage for writing the persistent stored modules. We briefly compare the three \\napproaches to database programming in Section 10.5, and provide a chapter sum-\\nmary in Section 10.6.\\n10.1  Overview of Database Programming \\nTechniques and Issues\\nWe now turn our attention to the techniques that have been developed for access-\\ning databases from programs and, in particular, to the issue of how to access SQL \\ndatabases from application programs. Our presentation of SQL in Chapters 6 and 7 \\nfocused on the language constructs for various database operations—from schema \\ndefinition and constraint specification to querying, updating, and specifying views.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 324, 'page_label': '325'}, page_content='10.1 Overview of Database Programming Techniques and Issues  311\\nMost database systems have an interactive interface where these SQL commands \\ncan be typed directly into a monitor for execution by the database system.  \\nFor example, in a computer system where the Oracle RDBMS is installed, the com-\\nmand \\nSQLPLUS starts the interactive interface. The user can type SQL commands \\nor queries directly over several lines, ended by a semicolon and the Enter key (that \\nis, \\n\";<cr>\"). Alternatively, a file of commands  can be created and executed \\nthrough the interactive interface by typing @<filename>. The system will execute \\nthe commands written in the file and display the results, if any.\\nThe interactive interface is quite convenient for schema and constraint creation or \\nfor occasional ad hoc queries. However, in practice, the majority of database inter-\\nactions are executed through programs that have been carefully designed and \\ntested. These programs are generally known as application programs or database \\napplications, and are used as canned transactions by the end users, as discussed in \\nSection 1.4.3. Another common use of database programming is to access a data-\\nbase through an application program that implements a Web interface, for exam-\\nple, when making airline reservations or online purchases. In fact, the vast majority \\nof Web electronic commerce applications include some database access commands. \\nChapter 11 gives an overview of Web database programming using PHP, a script-\\ning language that has recently become widely used.\\nIn this section, first we give an overview of the main approaches to database pro-\\ngramming. Then we discuss some of the problems that occur when trying to access \\na database from a general-purpose programming language, and the typical sequence \\nof commands for interacting with a database from a software program.\\n10.1.1 Approaches to Database Programming\\nSeveral techniques exist for including database interactions in application pro-\\ngrams. The main approaches for database programming are the following:\\n  1. Embedding database commands in a general-purpose programming  \\nlanguage. In this approach, database statements are embedded into the host \\nprogramming language, but they are identified by a special prefix. For \\nexample, the prefix for embedded SQL is the string \\nEXEC SQL, which pre-\\ncedes all SQL commands in a host language program. 1 A precompiler or \\npreproccessor  scans the source program code to identify database state-\\nments and extract them for processing by the DBMS. They are replaced in \\nthe program by function calls to the DBMS-generated code. This technique \\nis generally referred to as embedded SQL.\\n  2. Using a library of database functions or classes.  A library of functions is \\nmade available to the host programming language for database calls. For \\nexample, there could be functions to connect to a database, prepare a query, \\nexecute a query, execute an update, loop over the query result on record at a \\ntime, and so on. The actual database query and update commands and any \\n1Other prefixes are sometimes used, but this is the most common.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 325, 'page_label': '326'}, page_content='312 Chapter 10 Introduction to SQL Programming Techniques\\nother necessary information are included as parameters in the function calls. \\nThis approach provides what is known as an application programming \\ninterface (API) for accessing a database from application programs. For \\nobject-oriented programming languages (OOPLs), a class library  is used. \\nFor example, Java has the JDBC class library, which can generate various \\ntypes of objects such as: connection objects to a particular database, query \\nobjects, and query result objects. Each type of object has a set of operations \\nassociated with the class corresponding to the object.\\n  3. Designing a brand-new language.  A database programming language  is \\ndesigned from scratch to be compatible with the database model and query \\nlanguage. Additional programming structures such as loops and conditional \\nstatements are added to the database language to convert it into a full-fledged \\nprogramming language. An example of this approach is Oracle’s PL/SQL. The \\nSQL standard has the SQL/PSM language for specifying stored procedures.\\nIn practice, the first two approaches are more common, since many applications \\nare already written in general-purpose programming languages but require some \\ndatabase access. The third approach is more appropriate for applications that have \\nintensive database interaction. One of the main problems with the first two \\napproaches is impedance mismatch, which does not occur in the third approach.\\n10.1.2 Impedance Mismatch\\nImpedance mismatch is the term used to refer to the problems that occur because \\nof differences between the database model and the programming language model. \\nFor example, the practical relational model has three main constructs: columns \\n(attributes) and their data types, rows (also referred to as tuples or records), and \\ntables (sets or multisets of records). The first problem that may occur is that the \\ndata types of the programming language differ from the attribute data types that are \\navailable in the data model. Hence, it is necessary to have a binding for each host \\nprogramming language that specifies for each attribute type the compatible pro-\\ngramming language types. A different binding is needed for each programming lan-\\nguage because different languages have different data types. For example, the data \\ntypes available in C/C++ and Java are different, and both differ from the SQL data \\ntypes, which are the standard data types for relational databases.\\nAnother problem occurs because the results of most queries are sets or multisets of \\ntuples (rows), and each tuple is formed of a sequence of attribute values. In the pro-\\ngram, it is often necessary to access the individual data values within individual \\ntuples for printing or processing. Hence, a binding is needed to map the query result \\ndata structure , which is a table, to an appropriate data structure in the program-\\nming language. A mechanism is needed to loop over the tuples in a query result in \\norder to access a single tuple at a time and to extract individual values from the \\ntuple. The extracted attribute values are typically copied to appropriate program \\nvariables for further processing by the program. A cursor or iterator variable  is \\ntypically used to loop over the tuples in a query result. Individual values within each \\ntuple are then extracted into distinct program variables of the appropriate type.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 326, 'page_label': '327'}, page_content='10.1 Overview of Database Programming Techniques and Issues  313\\nImpedance mismatch is less of a problem when a special database programming \\nlanguage is designed that uses the same data model and data types as the database \\nmodel. One example of such a language is Oracle’s PL/SQL. The SQL standard also \\nhas a proposal for such a database programming language, known as SQL/PSM. For \\nobject databases, the object data model (see Chapter 12) is quite similar to the data \\nmodel of the Java programming language, so the impedance mismatch is greatly \\nreduced when Java is used as the host language for accessing a Java-compatible \\nobject database. Several database programming languages have been implemented \\nas research prototypes (see the Selected Bibliography).\\n10.1.3  Typical Sequence of Interaction  \\nin Database Programming\\nWhen a programmer or software engineer writes a program that requires access to \\na database, it is quite common for the program to be running on one computer \\nsystem while the database is installed on another. Recall from Section 2.5 that a \\ncommon architecture for database access is the three-tier client/server model, \\nwhere a top-tier client program  handles display of information on a laptop or \\nmobile device usually as a Web client or mobile app, a middle-tier application  \\nprogram implements the logic of a business software application but includes some \\ncalls to one or more database servers  at the bottom tier to access or update the \\ndata.\\n2 When writing such an application program, a common sequence of interac-\\ntion is the following:\\n  1. When the application program requires access to a particular database, the \\nprogram must first establish or open a connection to the database server. \\nTypically, this involves specifying the Internet address (URL) of the machine \\nwhere the database server is located, plus providing a login account name \\nand password for database access.\\n  2. Once the connection is established, the program can interact with the database \\nby submitting queries, updates, and other database commands. In general, \\nmost types of SQL statements can be included in an application program.\\n  3. When the program no longer needs access to a particular database, it should \\nterminate or close the connection to the database.\\nA program can access multiple databases if needed. In some database programming \\napproaches, only one connection can be active at a time, whereas in other \\napproaches multiple connections can be established simultaneously.\\nIn the next three sections, we discuss examples of each of the three main approaches \\nto database programming. Section 10.2 describes how SQL is embedded into a pro-\\ngramming language. Section 10.3 discusses how function calls and class libraries are \\nused to access the database using SQL/CLI (similar to ODBC) and JDBC, and Sec-\\ntion 10.4 discusses an extension to SQL called SQL/PSM that allows general-purpose \\n2As we discussed in Section 2.5, there are two-tier and three-tier architectures; to keep our discussion \\nsimple, we will assume a two-tier client/server architecture here.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 327, 'page_label': '328'}, page_content='314 Chapter 10 Introduction to SQL Programming Techniques\\nprogramming constructs for defining modules (procedures and functions) that are \\nstored within the database system.3 Section 10.5 compares these approaches.\\n10.2 Embedded SQL, Dynamic SQL, and SQL J\\nIn this section, we give an overview of the techniques for embedding SQL state-\\nments in a general-purpose programming language. We focus on two languages: C \\nand Java. The examples used with the C language, known as embedded SQL, are \\npresented in Sections 10.2.1 through 10.2.3, and can be adapted to other similar \\nprogramming languages. The examples using Java, known as SQLJ, are presented \\nin Sections 10.2.4 and 10.2.5. In this embedded approach, the programming lan-\\nguage is called the host language. Most SQL statements—including data or con-\\nstraint definitions, queries, updates, or view definitions—can be embedded in a \\nhost language program.\\n10.2.1 Retrieving Single Tuples with Embedded SQL\\nTo illustrate the concepts of embedded SQL, we will use C as the host programming \\nlanguage.\\n4 In a C program, an embedded SQL statement is distinguished from pro-\\ngramming language statements by prefixing it with the keywords EXEC SQL so that \\na preprocessor (or precompiler) can separate embedded SQL statements from the \\nhost language source code. The SQL statements within a program are terminated \\nby a matching \\nEND-EXEC or by a semicolon (;). Similar rules apply to embedding \\nSQL in other programming languages.\\nWithin an embedded SQL command, the programmer can refer to specially \\ndeclared C program variables; these are called shared variables  because they are \\nused in both the C program and the embedded SQL statements. Shared variables \\nare prefixed by a colon (:) when they appear in an SQL statement . This distin-\\nguishes program variable names from the names of database schema constructs \\nsuch as attributes (column names) and relations (table names). It also allows pro-\\ngram variables to have the same names as attribute names, since they are distin-\\nguishable by the colon (:) prefix in the SQL statement. Names of database schema \\nconstructs—such as attributes and relations—can only be used within the SQL \\ncommands, but shared program variables can be used elsewhere in the C program \\nwithout the colon (:) prefix.\\nSuppose that we want to write C programs to process the \\nCOMPANY database in \\nFigure 5.5. We need to declare program variables to match the types of the database \\nattributes that the program will process. The programmer can choose the names of \\nthe program variables; they may or may not have names that are identical to their \\n3SQL/PSM illustrates how typical general-purpose programming language constructs—such as loops \\nand conditional structures—can be incorporated into SQL.\\n4Our discussion here also applies to the C++ or C# programming languages, since we do not use any \\nof the object-oriented features, but focus on the database programming mechanism.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 328, 'page_label': '329'}, page_content='10.2 Embedded SQL, Dynamic SQL, and SQL J  315\\ncorresponding database attributes. We will use the C program variables declared \\nin Figure 10.1 for all our examples and show C program segments without vari-\\nable declarations . Shared variables are declared within a declare section  in the \\nprogram, as shown in Figure 10.1 (lines 1 through 7). 5 A few of the common \\nbindings of C types to SQL types are as follows. The SQL types INTEGER, SMALLINT, \\nREAL, and DOUBLE are mapped to the C data types long, short, float, and \\ndouble , respectively. Fixed-length and varying-length strings ( CHAR [ i],  \\nVARCHAR [ i]) in SQL can be mapped to arrays of characters ( char [i+1],  \\nvarchar [i+1]) in C that are one character longer than the SQL type because \\nstrings in C are terminated by a NULL character ( \\\\0), which is not part of the \\ncharacter string itself. 6 Although varchar is not a standard C data type, it is per-\\nmitted when C is used for SQL database programming.\\nNotice that the only embedded SQL commands in Figure 10.1 are lines 1 and 7, \\nwhich tell the precompiler to take note of the C variable names between BEGIN \\nDECLARE and END DECLARE because they can be included in embedded SQL state-\\nments—as long as they are preceded by a colon (:). Lines 2 through 5 are regular C \\nprogram declarations. The C program variables declared in lines 2 through 5 cor-\\nrespond to the attributes of the \\nEMPLOYEE  and DEPARTMENT  tables from the \\nCOMPANY database in Figure 5.5 that was declared by the SQL DDL in Figure 6.1. \\nThe variables declared in line 6— SQLCODE  and SQLSTATE —are called SQL \\ncommunication variables;  they are used to communicate errors and exception \\nconditions between the database system and the executing program. Line 0 shows a \\nprogram variable loop that will not be used in any embedded SQL statement, so it is \\ndeclared outside the SQL declare section.\\nConnecting to the Database. The SQL command for establishing a connection \\nto a database has the following form:\\nCONNECT TO <server name>AS <connection name>\\nAUTHORIZATION <user account name and password> ;\\nIn general, since a user or program can access several database servers, several con-\\nnections can be established, but only one connection can be active at any point in \\n5We use line numbers in our code segments for easy reference; these numbers are not part of the \\nactual code.\\n6SQL strings can also be mapped to char* types in C.\\n0) int loop ;\\n1) EXEC SQL BEGIN DECLARE SECTION ;\\n2) varchar dname [16], fname [16], lname [16], address [31] ;\\n3) char ssn [10], bdate [11], sex [2], minit [2] ;\\n4) float salary, raise ;\\n5) int dno, dnumber ;\\n6) int SQLCODE ; char SQLSTATE [6] ;\\n7) EXEC SQL END DECLARE SECTION ;\\nFigure 10.1 \\nC program variables used in the  \\nembedded SQL examples E1 and E2.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 329, 'page_label': '330'}, page_content='316 Chapter 10 Introduction to SQL Programming Techniques\\ntime. The programmer or user can use the <connection name> to change from the \\ncurrently active connection to a different one by using the following command:\\nSET CONNECTION <connection name> ;\\nOnce a connection is no longer needed, it can be terminated by the following \\ncommand:\\nDISCONNECT <connection name> ;\\nIn the examples in this chapter, we assume that the appropriate connection has \\nalready been established to the COMPANY database, and that it is the currently \\nactive connection.\\nCommunication variables SQLCODE and SQLSTATE. The two special  \\ncommunication variables that are used by the DBMS to communicate exception \\nor error conditions to the program are SQLCODE and SQLSTATE. The SQLCODE \\nvariable shown in Figure 10.1 is an integer variable. After each database command \\nis executed, the DBMS returns a value in \\nSQLCODE. A value of 0 indicates that the \\nstatement was executed successfully by the DBMS. If SQLCODE > 0 (or, more spe-\\ncifically, if SQLCODE = 100), this indicates that no more data (records) are available \\nin a query result. If SQLCODE < 0, this indicates some error has occurred. In some \\nsystems—for example, in the Oracle RDBMS— SQLCODE is a field in a record \\nstructure called SQLCA  (SQL communication area), so it is referenced as  \\nSQLCA.SQLCODE. In this case, the definition of SQLCA must be included in the C \\nprogram by including the following line:\\nEXEC SQL include SQLCA ;\\nIn later versions of the SQL standard, a communication variable called SQLSTATE \\nwas added, which is a string of five characters. A value of ‘00000’ in SQLSTATE indi-\\ncates no error or exception; other values indicate various errors or exceptions. For \\nexample, ‘02000’ indicates ‘no more data’ when using SQLSTATE. Currently, both \\nSQLSTATE and SQLCODE are available in the SQL standard. Many of the error and \\nexception codes returned in SQLSTATE are supposed to be standardized for all SQL \\nvendors and platforms, 7 whereas the codes returned in SQLCODE are not stan-\\ndardized but are defined by the DBMS vendor. Hence, it is generally better to use \\nSQLSTATE because this makes error handling in the application programs indepen-\\ndent of a particular DBMS. As an exercise, the reader should rewrite the examples \\ngiven later in this chapter using \\nSQLSTATE instead of SQLCODE.\\nExample of Embedded SQL Programming. Our first example to illustrate \\nembedded SQL programming is a repeating program segment (loop) that takes as \\ninput a Social Security number of an employee and prints some information from \\nthe corresponding \\nEMPLOYEE record in the database. The C program code is shown \\nas program segment E1 in Figure 10.2. The program reads (inputs) an Ssn value \\n7In particular, SQLSTATE codes starting with the characters 0 through 4 or A through H are supposed to \\nbe standardized, whereas other values can be implementation-defined.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 330, 'page_label': '331'}, page_content='10.2 Embedded SQL, Dynamic SQL, and SQL J  317\\nand then retrieves the EMPLOYEE tuple with that Ssn from the database via the \\nembedded SQL command. The INTO clause (line 5) specifies the program vari-\\nables into which attribute values from the database record are retrieved. C program \\nvariables in the \\nINTO clause are prefixed with a colon ( :), as we discussed earlier. \\nThe INTO clause can be used in this manner only when the query result is a single \\nrecord; if multiple records are retrieved, an error will be generated. We will see how \\nmultiple records are handled in Section 10.2.2.\\nLine 7 in E1 illustrates the communication between the database and the program \\nthrough the special variable SQLCODE . If the value returned by the DBMS in \\nSQLCODE is 0, the previous statement was executed without errors or exception \\nconditions. Line 7 checks this and assumes that if an error occurred, it was because \\nno \\nEMPLOYEE tuple existed with the given Ssn; therefore it outputs a message to \\nthat effect (line 8).\\nWhen a single record is retrieved as in example E1, the programmer can assign its \\nattribute values directly to C program variables in the INTO clause, as in line 5. In \\ngeneral, an SQL query can retrieve many tuples. In that case, the C program will \\ntypically loop through the retrieved tuples and process them one at a time. The con-\\ncept of a cursor is used to allow tuple-at-a-time processing of a query result by the \\nhost language program. We describe cursors next.\\n10.2.2 Processing Query Results Using Cursors\\nA cursor is a variable that refers to a single tuple  (row) from a query result  that \\nretrieves a collection of tuples. It is used to loop over the query result, one record at \\na time. The cursor is declared when the SQL query is declared. Later in the pro-\\ngram, an OPEN CURSOR command fetches the query result from the database and \\nsets the cursor to a position before the first row  in the result of the query. This \\nbecomes the current row  for the cursor. Subsequently, FETCH commands are \\nissued in the program; each FETCH moves the cursor to the next row in the result of \\nthe query, making it the current row and copying its attribute values into the C \\n(host language) program variables specified in the FETCH command by an INTO \\n   //Program Segment E1:\\n0) loop = 1 ;\\n1) while (loop) {\\n2)   prompt(\"Enter a Social Security Number: \", ssn) ;\\n3)   EXEC SQL\\n4)     SELECT Fname, Minit, Lname, Address, Salary\\n5)     INTO :fname, :minit, :lname, :address, :salary\\n6)     FROM EMPLOYEE WHERE Ssn = :ssn ;\\n7)   if (SQLCODE = = 0) printf(fname, minit, lname, address, salary)\\n8)     else printf(\"Social Security Number does not exist: \", ssn) ;\\n9)   prompt(\"More Social Security Numbers (enter 1 for Yes, 0 for No): \", loop) ;\\n10)  }\\nFigure 10.2 \\nProgram segment E1, \\na C program segment \\nwith embedded SQL.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 331, 'page_label': '332'}, page_content='318 Chapter 10 Introduction to SQL Programming Techniques\\nclause. The cursor variable is basically an iterator that iterates (loops) over the \\ntuples in the query result—one tuple at a time.\\nTo determine when all the tuples in the result of the query have been processed, the \\ncommunication variable SQLCODE (or, alternatively, SQLSTATE) is checked. If a \\nFETCH command is issued that results in moving the cursor past the last tuple in the \\nresult of the query, a positive value ( SQLCODE  > 0) is returned in SQLCODE , \\nindicating that no data (tuple) was found (or the string ‘02000’ is returned in \\nSQLSTATE). The programmer uses this to terminate the loop over the tuples in the \\nquery result. In general, numerous cursors can be opened at the same time. A \\nCLOSE CURSOR command is issued to indicate that we are done with processing \\nthe result of the query associated with that cursor.\\nAn example of using cursors to process a query result with multiple records is shown \\nin Figure 10.3, where a cursor called EMP is declared in line 4. The EMP cursor  \\nis associated with the SQL query declared in lines 5 through 6, but the query  \\nis not executed until the \\nOPEN EMP  command (line 8) is processed. The  \\nOPEN <cursor name> command executes the query and fetches its result as a table \\ninto the program workspace, where the program can loop through the individual \\nrows (tuples) by subsequent FETCH <cursor name> commands (line 9). We assume \\n    //Program Segment E2:\\n  0) prompt(\"Enter the Department Name: \", dname) ;\\n  1) EXEC SQL\\n  2)   SELECT Dnumber INTO :dnumber\\n  3)   FROM DEPARTMENT WHERE Dname = :dname ;\\n  4) EXEC SQL DECLARE EMP CURSOR FOR\\n  5)   SELECT Ssn, Fname, Minit, Lname, Salary\\n  6)   FROM EMPLOYEE WHERE Dno = :dnumber\\n  7)   FOR UPDATE OF Salary ;\\n  8) EXEC SQL OPEN EMP ;\\n  9) EXEC SQL FETCH FROM EMP INTO :ssn, :fname, :minit, :lname, :salary ;\\n10) while (SQLCODE = = 0) {\\n11)   printf(\"Employee name is:\", Fname, Minit, Lname) ;\\n12)   prompt(\"Enter the raise amount: \", raise) ;\\n13)   EXEC SQL\\n14)     UPDATE EMPLOYEE\\n15)     SET Salary = Salary + :raise\\n16)     WHERE CURRENT OF EMP ;\\n17)   EXEC SQL FETCH FROM EMP INTO :ssn, :fname, :minit, :lname, :salary ;\\n18)   }\\n19) EXEC SQL CLOSE EMP ;\\nFigure 10.3 \\nProgram segment E2, a C program segment that uses \\ncursors with embedded SQL for update purposes.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 332, 'page_label': '333'}, page_content='10.2 Embedded SQL, Dynamic SQL, and SQL J  319\\nthat appropriate C program variables have been declared as in Figure 10.1. The pro-\\ngram segment in E2 reads (inputs) a department name (line 0), retrieves the \\nmatching department number from the database (lines 1 to 3), and then retrieves \\nthe employees who work in that department via the declared \\nEMP cursor. A loop \\n(lines 10 to 18) iterates over each record in the query result, one at a time, and \\nprints the employee name, then reads (inputs) a raise amount for that employee \\n(line 12) and updates the employee’s salary in the database by the raise amount \\n(lines 14 to 16).\\nThis example also illustrates how the programmer can update database records. \\nWhen a cursor is defined for rows that are to be modified ( updated), we must add \\nthe clause \\nFOR UPDATE OF in the cursor declaration and list the names of any attri-\\nbutes that will be updated by the program. This is illustrated in line 7 of code seg-\\nment E2. If rows are to be deleted, the keywords \\nFOR UPDATE  must be added \\nwithout specifying any attributes. In the embedded UPDATE (or DELETE) command, \\nthe condition WHERE CURRENT OF <cursor name> specifies that the current tuple \\nreferenced by the cursor is the one to be updated (or deleted), as in line 16 of E2.\\nThere is no need to include the FOR UPDATE OF clause in line 7 of E2 if the results \\nof the query are to be used for retrieval purposes only (no update or delete).\\nGeneral Options for a Cursor Declaration. Several options can be specified \\nwhen declaring a cursor. The general form of a cursor declaration is as follows:\\nDECLARE <cursor name> [ INSENSITIVE ] [ SCROLL ] CURSOR\\n[ WITH HOLD ] FOR <query specification>\\n[ ORDER BY <ordering specification> ]\\n[ FOR READ ONLY | FOR UPDATE [ OF <attribute list> ] ] ;\\nWe already briefly discussed the options listed in the last line. The default is that the \\nquery is for retrieval purposes (FOR READ ONLY). If some of the tuples in the query \\nresult are to be updated, we need to specify FOR UPDATE OF <attribute list> and list \\nthe attributes that may be updated. If some tuples are to be deleted, we need to \\nspecify \\nFOR UPDATE without any attributes listed.\\nWhen the optional keyword SCROLL is specified in a cursor declaration, it is pos-\\nsible to position the cursor in other ways than for purely sequential access. A fetch \\norientation can be added to the FETCH command, whose value can be one of NEXT, \\nPRIOR, FIRST, LAST, ABSOLUTE i, and RELATIVE i. In the latter two commands, i \\nmust evaluate to an integer value that specifies an absolute tuple position within the \\nquery result (for ABSOLUTE i), or a tuple position relative to the current cursor \\nposition (for RELATIVE i). The default fetch orientation, which we used in our \\nexamples, is NEXT. The fetch orientation allows the programmer to move the cursor \\naround the tuples in the query result with greater flexibility, providing random \\naccess by position or access in reverse order. When SCROLL is specified on the cur-\\nsor, the general form of a FETCH command is as follows, with the parts in square \\nbrackets being optional:\\nFETCH [ [ <fetch orientation> ] FROM ] <cursor name> INTO <fetch target list>;'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 333, 'page_label': '334'}, page_content='320 Chapter 10 Introduction to SQL Programming Techniques\\nThe ORDER BY clause orders the tuples so that the FETCH command will fetch them \\nin the specified order. It is specified in a similar manner to the corresponding clause \\nfor SQL queries (see Section 6.3.6). The last two options when declaring a cursor \\n(\\nINSENSITIVE and WITH HOLD) refer to transaction characteristics of database pro-\\ngrams, which we will discuss in Chapter 20.\\n10.2.3 Specifying Queries at Runtime Using Dynamic SQL\\nIn the previous examples, the embedded SQL queries were written as part of the \\nhost program source code. Hence, anytime we want to write a different query, we \\nmust modify the program code and go through all the steps involved (compiling, \\ndebugging, testing, and so on). In some cases, it is convenient to write a program \\nthat can execute different SQL queries or updates (or other operations) dynamically \\nat runtime . For example, we may want to write a program that accepts an SQL \\nquery typed from the monitor, executes it, and displays its result, such as the inter-\\nactive interfaces available for most relational DBMSs. Another example is when a \\nuser-friendly interface generates SQL queries dynamically for the user based on \\nuser input through a Web interface or mobile App. In this section, we give a brief \\noverview of dynamic SQL, which is one technique for writing this type of database \\nprogram, by giving a simple example to illustrate how dynamic SQL can work. In \\nSection 10.3, we will describe another approach for dealing with dynamic queries \\nusing function libraries or class libraries.\\nProgram segment E3 in Figure 10.4 reads a string that is input by the user (that \\nstring should be an SQL update command in this example) into the string program \\nvariable \\nsqlupdatestring  in line 3. It then prepares  this as an SQL command in \\nline 4 by associating it with the SQL variable sqlcommand . Line 5 then executes \\nthe command. Notice that in this case no syntax check or other types of checks \\non the command are possible at compile time , since the SQL command is not \\navailable until runtime. This contrasts with our previous examples of embedded \\nSQL, where the query could be checked at compile time because its text was in \\nthe program source code.\\nIn E3, the reason for separating \\nPREPARE and EXECUTE is that if the command is to \\nbe executed multiple times in a program, it can be prepared only once. Preparing \\nthe command generally involves syntax and other types of checks by the system, as \\n        //Program Segment E3:\\n0) EXEC SQL BEGIN DECLARE SECTION ;\\n1) varchar sqlupdatestring [256] ;\\n2) EXEC SQL END DECLARE SECTION ;\\n ...\\n3) prompt(\"Enter the Update Command: \", sqlupdatestring) ;\\n4) EXEC SQL PREPARE sqlcommand FROM :sqlupdatestring ;\\n5) EXEC SQL EXECUTE sqlcommand ;\\n ...\\nFigure 10.4 \\nProgram segment E3, a C program segment \\nthat uses dynamic SQL for updating a table.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 334, 'page_label': '335'}, page_content='10.2 Embedded SQL, Dynamic SQL, and SQL J  321\\nwell as generating the code for executing it. It is possible to combine the PREPARE \\nand EXECUTE commands (lines 4 and 5 in E3) into a single statement by writing\\nEXEC SQL EXECUTE IMMEDIATE :sqlupdatestring ;\\nThis is useful if the command is to be executed only once. Alternatively, the pro-\\ngrammer can separate the two statements to catch any errors after the \\nPREPARE \\nstatement as in E3.\\nAlthough including a dynamic update command  is relatively straightforward in \\ndynamic SQL, a dynamic retrieval query is much more complicated. This is because \\nthe programmer does not know the types or the number of attributes to be retrieved \\nby the SQL query when writing the program. A complex data structure is needed to \\nallow for different numbers and types of attributes in the query result if no prior \\ninformation is known about the dynamic query. Techniques similar to those that \\nwe shall discuss in Section 10.3 can be used to assign retrieval query results (and \\nquery parameters) to host program variables.\\n10.2.4 SQLJ: Embedding SQL Commands in Java\\nIn the previous subsections, we gave an overview of how SQL commands can be \\nembedded in a traditional programming language, using the C language in our \\nexamples. We now turn our attention to how SQL can be embedded in an object-\\noriented programming language,\\n8 in particular, the Java language. SQLJ is a stan-\\ndard that has been adopted by several vendors for embedding SQL in Java. \\nHistorically, SQLJ was developed after JDBC, which is used for accessing SQL data-\\nbases from Java using class libraries and function calls. We discuss JDBC in Sec-\\ntion 10.3.2. In this section, we focus on SQLJ as it is used in the Oracle RDBMS. An \\nSQLJ translator will generally convert SQL statements into Java, which can then be \\nexecuted through the JDBC interface. Hence, it is necessary to install a JDBC driver \\nwhen using SQLJ.\\n9 In this section, we focus on how to use SQLJ concepts to write \\nembedded SQL in a Java program.\\nBefore being able to process SQLJ with Java in Oracle, it is necessary to import several \\nclass libraries, shown in Figure 10.5. These include the JDBC and IO classes (lines 1 \\nand 2), plus the additional classes listed in lines 3, 4, and 5. In addition, the program \\nmust first connect to the desired database using the function call \\ngetConnection, \\nwhich is one of the methods of the oracle class in line 5 of Figure 10.5. The format of \\nthis function call, which returns an object of type default context,10 is as follows:\\npublic static DefaultContext\\ngetConnection(String url, String user, String password,\\n         Boolean autoCommit)\\nthrows SQLException ;\\n8This section assumes familiarity with object-oriented concepts (see Chapter 12) and basic Java concepts.\\n9We discuss JDBC drivers in Section 10.3.2.\\n10A default context, when set, applies to subsequent commands in the program until it is changed.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 335, 'page_label': '336'}, page_content='322 Chapter 10 Introduction to SQL Programming Techniques\\nFor example, we can write the statements in lines 6 through 8 in Figure 10.5 to  \\nconnect to an Oracle database located at the url <url name> using the login of \\n<user name> and <password> with automatic commitment of each command, 11 \\nand then set this connection as the default context for subsequent commands.\\nIn the following examples, we will not show complete Java classes or programs \\nsince it is not our intention to teach Java. Rather, we will show program segments \\nthat illustrate the use of SQLJ. Figure 10.6 shows the Java program variables used in \\nour examples. Program segment J1 in Figure 10.7 reads an employee’s \\nSsn and \\nprints some of the employee’s information from the database.\\nNotice that because Java already uses the concept of exceptions  for error han-\\ndling, a special exception called SQLException  is used to return errors or \\nexception conditions after executing an SQL database command. This plays a \\nsimilar role to \\nSQLCODE  and SQLSTATE  in embedded SQL. Java has many types \\nof predefined exceptions. Each Java operation (function) must specify the \\nexceptions that can be thrown —that is, the exception conditions that may \\noccur while executing the Java code of that operation. If a defined exception \\noccurs, the system transfers control to the Java code specified for exception \\nhandling. In J1, exception handling for an \\nSQLException is specified in lines 7 \\nand 8. In Java, the following structure\\ntry {<operation>} catch (<exception>) {<exception handling \\n  code>} <continuation code>\\n1) import java.sql.* ;\\n2) import java.io.* ;\\n3) import sqlj.runtime.* ;\\n4) import sqlj.runtime.ref.* ;\\n5) import oracle.sqlj.runtime.* ;\\n ...\\n6) DefaultContext cntxt = \\n7) oracle.getConnection(\"<url name>\", \"<user name>\", \"<password>\", true) ;\\n8) DefaultContext.setDefaultContext(cntxt) ;\\n ...\\nFigure 10.5 \\nImporting classes needed for including \\nSQLJ in Java programs in Oracle, and \\nestablishing a connection  \\nand default context.\\n11Automatic commitment roughly means that each command is applied to the database after it is  \\nexecuted. The alternative is that the programmer wants to execute several related database commands \\nand then commit them together. We discuss commit concepts in Chapter 20 when we describe database \\ntransactions.\\n1) string dname, ssn , fname, fn, lname, ln,  \\nbdate, address ;\\n2) char sex, minit, mi ;\\n3) double salary, sal ;\\n4) integer dno, dnumber ;\\nFigure 10.6 \\nJava program variables  \\nused in SQLJ examples  \\nJ1 and J2.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 336, 'page_label': '337'}, page_content='10.2 Embedded SQL, Dynamic SQL, and SQL J  323\\nis used to deal with exceptions that occur during the execution of <operation>. If \\nno exception occurs, the <continuation code> is processed directly. Exceptions \\nthat can be thrown by the code in a particular operation should be specified as part \\nof the operation declaration or interface—for example, in the following format:\\n<operation return type> <operation name> (<parameters>)\\nthrows SQLException, IOException ;\\nIn SQLJ, the embedded SQL commands within a Java program are preceded by \\n#sql, as illustrated in J1 line 3, so that they can be identified by the preprocessor. \\nThe #sql is used instead of the keywords EXEC SQL that are used in embedded SQL \\nwith the C programming language (see Section 10.2.1). SQLJ uses an INTO clause—\\nsimilar to that used in embedded SQL—to return the attribute values retrieved from \\nthe database by an SQL query into Java program variables. The program variables \\nare preceded by colons (:) in the SQL statement, as in embedded SQL.\\nIn J1 a single tuple is retrieved by the embedded SQLJ query; that is why we are able \\nto assign its attribute values directly to Java program variables in the \\nINTO clause in \\nline 4 in Figure 10.7. For queries that retrieve many tuples, SQLJ uses the concept of \\nan iterator, which is similar to a cursor in embedded SQL.\\n10.2.5 Processing Query Results in SQLJ Using Iterators\\nIn SQLJ, an iterator is a type of object associated with a collection (set or multiset) \\nof records in a query result.12 The iterator is associated with the tuples and attri-\\nbutes that appear in a query result. There are two types of iterators:\\n  1. A named iterator is associated with a query result by listing the attribute names \\nand types that appear in the query result. The attribute names must correspond \\nto appropriately declared Java program variables, as shown in Figure 10.6.\\n  2. A positional iterator lists only the attribute types that appear in the query \\nresult.\\n         //Program Segment J1:\\n  1) ssn = readEntry(\"Enter a Social Security Number: \") ;\\n  2) try {\\n  3)   #sql { SELECT Fname, Minit, Lname, Address, Salary\\n  4)     INTO :fname, :minit, :lname, :address, :salary\\n  5)     FROM EMPLOYEE WHERE Ssn = :ssn} ;\\n  6) } catch (SQLException se) {\\n  7)     System.out.println(\"Social Security Number does not exist: \" + ssn) ;\\n  8)     Return ;\\n  9)   }\\n10) System.out.println(fname + \" \" + minit + \" \" + lname + \" \" + address  \\n  + \" \" + salary)\\nFigure 10.7 \\nProgram segment J1, \\na Java program  \\nsegment with SQLJ.\\n12We shall discuss iterators in more detail in Chapter 12 when we present object database concepts.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 337, 'page_label': '338'}, page_content='324 Chapter 10 Introduction to SQL Programming Techniques\\nIn both cases, the list should be in the same order as the attributes that are listed in \\nthe SELECT clause of the query. However, looping over a query result is different for \\nthe two types of iterators. First, we show an example of using a named iterator in \\nFigure 10.8, program segment J2A. Line 9 in Figure 10.8 shows how a named itera-\\ntor type Emp is declared. Notice that the names of the attributes in a named iterator \\ntype must match the names of the attributes in the SQL query result. Line 10 shows \\nhow an iterator object \\ne of type Emp is created in the program and then associated \\nwith a query (lines 11 and 12).\\nWhen the iterator object is associated with a query (lines 11 and 12 in Figure 10.8), \\nthe program fetches the query result from the database and sets the iterator to a \\nposition before the first row in the result of the query. This becomes the current row \\nfor the iterator. Subsequently, next operations are issued on the iterator object; \\neach \\nnext moves the iterator to the next row in the result of the query, making it the \\ncurrent row. If the row exists, the operation retrieves the attribute values for that \\nrow into the corresponding program variables. If no more rows exist, the \\nnext \\noperation returns NULL, and can thus be used to control the looping. Notice that the \\nnamed iterator does not need an INTO clause, because the program variables corre-\\nsponding to the retrieved attributes are already specified when the iterator type is \\ndeclared (line 9 in Figure 10.8).\\nIn Figure 10.8, the command (e.next()) in line 13 performs two functions: It \\ngets the next tuple in the query result and controls the WHILE loop. Once the \\nFigure 10.8 \\nProgram segment J2A, a Java program segment that uses a named iterator to print employee information in a \\nparticular department.\\n    //Program Segment J2A:\\n 0) dname = readEntry(\"Enter the Department Name: \") ;\\n 1) try {\\n 2)   #sql { SELECT Dnumber INTO :dnumber\\n 3)     FROM DEPARTMENT WHERE Dname = :dname} ;\\n 4) } catch (SQLException se) {\\n 5)   System.out.println(\"Department does not exist: \" + dname) ;\\n 6)   Return ;\\n 7)   }\\n 8) System.out.printline(\"Employee information for Department: \" + dname) ;\\n 9) #sql iterator Emp(String ssn, String fname, String minit, String lname,\\n      double salary) ;\\n10) Emp e = null ;\\n11) #sql e = { SELECT ssn, fname, minit, lname, salary\\n12)   FROM EMPLOYEE WHERE Dno = :dnumber} ;\\n13) while (e.next()) {\\n14)   System.out.printline(e.ssn + \" \" + e.fname + \" \" + e.minit + \" \" +  \\n    e.lname  + \" \" + e.salary) ;\\n15) } ;\\n16) e.close() ;'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 338, 'page_label': '339'}, page_content='10.2 Embedded SQL, Dynamic SQL, and SQL J  325\\nprogram is done with processing the query result, the command e.close()  \\n(line 16) closes the iterator.\\nNext, consider the same example using positional iterators as shown in Figure 10.9 \\n(program segment J2B). Line 9 in Figure 10.9 shows how a positional iterator type \\nEmppos is declared. The main difference between this and the named iterator is that \\nthere are no attribute names (corresponding to program variable names) in the \\npositional iterator—only attribute types. This can provide more flexibility, but it \\nmakes the processing of the query result slightly more complex. The attribute types \\nmust still be compatible with the attribute types in the SQL query result and in the \\nsame order. Line 10 shows how a positional iterator object \\ne of type Emppos is cre-\\nated in the program and then associated with a query (lines 11 and 12).\\nThe positional iterator behaves in a manner that is more similar to embedded SQL \\n(see Section 10.2.2). A FETCH <iterator variable> INTO <program variables> com-\\nmand is needed to get the next tuple in a query result. The first time fetch is exe-\\ncuted, it gets the first tuple (line 13 in Figure 10.9). Line 16 gets the next tuple until \\nno more tuples exist in the query result. To control the loop, a positional iterator \\nfunction \\ne.endFetch() is used. This function is automatically set to a value of \\nTRUE when the iterator is initially associated with an SQL query (line 11), and is set \\nto FALSE each time a fetch command returns a valid tuple from the query result. It \\nis set to TRUE again when a fetch command does not find any more tuples. Line 14 \\nshows how the looping is controlled by negation.\\nFigure 10.9 \\nProgram segment J2B, a Java program segment that uses a positional iterator to print employee information in a \\nparticular department.\\n    //Program Segment J2B:\\n 0) dname = readEntry(\"Enter the Department Name: \") ;\\n 1) try {\\n 2)   #sql { SELECT Dnumber INTO :dnumber\\n 3)     FROM DEPARTMENT WHERE Dname = :dname} ;\\n 4) } catch (SQLException se) {\\n 5)   System.out.println(\"Department does not exist: \" + dname) ;\\n 6)   Return ;\\n 7)   }\\n 8) System.out.printline(\"Employee information for Department: \" + dname) ;\\n 9) #sql iterator Emppos(String, String, String, String, double) ;\\n10) Emppos e = null ;\\n11) #sql e = { SELECT ssn, fname, minit, lname, salary\\n12)   FROM EMPLOYEE WHERE Dno = :dnumber} ;\\n13) #sql { FETCH :e INTO :ssn, :fn, :mi, :ln, :sal} ;\\n14) while (!e.endFetch()) {\\n15)   System.out.printline(ssn + \" \" + fn + \" \" + mi + \" \" + ln + \" \" + sal) ;\\n16)   #sql { FETCH :e INTO :ssn, :fn, :mi, :ln, :sal} ;\\n17) } ;\\n18) e.close() ;'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 339, 'page_label': '340'}, page_content='326 Chapter 10 Introduction to SQL Programming Techniques\\n10.3  Database Programming with Function \\nCalls and Class Libraries: SQL/CLI  \\nand JDBC\\nEmbedded SQL (see Section 10.2) is sometimes referred to as a static database pro-\\ngramming approach because the query text is written within the program source \\ncode and cannot be changed without recompiling or reprocessing the source code. \\nThe use of function calls is a more dynamic approach for database programming \\nthan embedded SQL. We already saw one dynamic database programming technique—\\ndynamic SQL—in Section 10.2.3. The techniques discussed here provide another \\napproach to dynamic database programming. A library of functions , also known \\nas an application programming interface  (API), is used to access the database. \\nAlthough this provides more flexibility because no preprocessor is needed, one \\ndrawback is that syntax and other checks on SQL commands have to be done at \\nruntime. Another drawback is that it sometimes requires more complex program-\\nming to access query results because the types and numbers of attributes in a query \\nresult may not be known in advance.\\nIn this section, we give an overview of two function call interfaces. We first discuss \\nthe SQL Call Level Interface (SQL/CLI ), which is part of the SQL standard. This \\nwas developed as a standardization of the popular library of functions known as \\nODBC (Open Database Connectivity) . We use C as the host language in our  \\nSQL/CLI examples. Then we give an overview of JDBC, which is the call function \\ninterface for accessing databases from Java. Although it is commonly assumed that \\nJDBC stands for Java Database Connectivity, JDBC is just a registered trademark of \\nSun Microsystems (now Oracle), not an acronym.\\nThe main advantage of using a function call interface is that it makes it easier \\nto access multiple databases within the same application program, even if they \\nare stored under different DBMS packages. We discuss this further in Sec- \\ntion 10.3.2 when we discuss Java database programming with JDBC, although \\nthis advantage also applies to database programming with SQL/CLI and ODBC \\n(see Section 10.3.1).\\n10.3.1  Database Programming with SQL/CLI Using C  \\nas the Host Language\\nBefore using the function calls in SQL/CLI, it is necessary to install the appropriate \\nlibrary packages on the database server. These packages are obtained from the ven-\\ndor of the DBMS being used. We now give an overview of how SQL/CLI can be \\nused in a C program.\\n13 We will illustrate our presentation with the sample program \\nsegment CLI1 shown in Figure 10.10.\\n13Our discussion here also applies to the C++ and C# programming languages, since we do not use \\nany of the object-oriented features but focus on the database programming mechanism.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 340, 'page_label': '341'}, page_content='10.3 Database Programming with Function Calls and Class Libraries: SQL/CLI and JDBC  327\\nHandles to environment, connection, statement, and description \\nrecords. When using SQL/CLI, the SQL statements are dynamically created and \\npassed as string parameters in the function calls. Hence, it is necessary to keep track \\nof the information about host program interactions with the database in runtime \\ndata structures because the database commands are processed at runtime. The \\ninformation is kept in four types of records, represented as structs in C data types. \\nAn environment record is used as a container to keep track of one or more data-\\nbase connections and to set environment information. A connection record keeps \\ntrack of the information needed for a particular database connection. A statement \\nrecord  keeps track of the information needed for one SQL statement. A  \\ndescription record keeps track of the information about tuples or parameters—for \\nexample, the number of attributes and their types in a tuple, or the number and \\ntypes of parameters in a function call. This is needed when the programmer does \\nnot know this information about the query when writing the program. In our \\nexamples, we assume that the programmer knows the exact query, so we do not \\nshow any description records.\\n    //Program CLI1:\\n 0) #include sqlcli.h ;\\n 1) void printSal() {\\n 2) SQLHSTMT stmt1 ;\\n 3) SQLHDBC con1 ;\\n 4) SQLHENV env1 ;\\n 5) SQLRETURN ret1, ret2, ret3, ret4 ;\\n 6) ret1 = SQLAllocHandle(SQL_HANDLE_ENV, SQL_NULL_HANDLE, &env1) ;\\n 7) if (!ret1) ret2 = SQLAllocHandle(SQL_HANDLE_DBC, env1, &con1) else exit ;\\n 8) if (!ret2) ret3 = SQLConnect(con1, \"dbs\", SQL_NTS, \"js\", SQL_NTS, \"xyz\",\\n      SQL_NTS) else exit ;\\n 9) if (!ret3) ret4 = SQLAllocHandle(SQL_HANDLE_STMT, con1, &stmt1) else exit ;\\n10) SQLPrepare(stmt1, \"select Lname, Salary from EMPLOYEE where Ssn = ?\",\\n      SQL_NTS) ;\\n11) prompt(\"Enter a Social Security Number: \", ssn) ;\\n12) SQLBindParameter(stmt1, 1, SQL_CHAR, &ssn, 9, &fetchlen1) ;\\n13) ret1 = SQLExecute(stmt1) ;\\n14) if (!ret1) {\\n15)   SQLBindCol(stmt1, 1, SQL_CHAR, &lname, 15, &fetchlen1) ;\\n16)   SQLBindCol(stmt1, 2, SQL_FLOAT, &salary, 4, &fetchlen2) ;\\n17)   ret2 = SQLFetch(stmt1) ;\\n18)   if (!ret2) printf(ssn, lname, salary)\\n19)     else printf(\"Social Security Number does not exist: \", ssn) ;\\n20)   }\\n21) }\\nFigure 10.10 \\nProgram segment CLI1, a C program segment with SQL/CLI.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 341, 'page_label': '342'}, page_content='328 Chapter 10 Introduction to SQL Programming Techniques\\nEach record is accessible to the program through a C pointer variable—called a \\nhandle to the record. The handle is returned when a record is first created. To cre-\\nate a record and return its handle, the following SQL/CLI function is used:\\nSQLAllocHandle(<handle_type>, <handle_1>, <handle_2>)\\nIn this function, the parameters are as follows:\\n ■ <handle_type> indicates the type of record being created. The possible val-\\nues for this parameter are the keywords SQL_HANDLE_ENV, SQL_HANDLE_DBC, \\nSQL_HANDLE_STMT , or SQL_HANDLE_DESC , for an environment, connec-\\ntion, statement, or description record, respectively.\\n ■ <handle_1> indicates the container within which the new handle is being \\ncreated. For example, for a connection record this would be the environ-\\nment within which the connection is being created, and for a statement \\nrecord this would be the connection for that statement.\\n ■ <handle_2> is the pointer (handle) to the newly created record of type \\n<handle_type>.\\nSteps in a database program. When writing a C program that will include \\ndatabase calls through SQL/CLI, the following are the typical steps that are taken. \\nWe illustrate the steps by referring to the example CLI1 in Figure 10.10, which \\nreads a Social Security number of an employee and prints the employee’s last name \\nand salary.\\n  1. Including the library of functions.  The library of functions  comprising \\nSQL/CLI must be included in the C program. This is called sqlcli.h, and is \\nincluded using line 0 in Figure 10.10.\\n  2. Declaring handle variables.  Declare handle variables  of types SQLHSTMT, \\nSQLHDBC, SQLHENV, and SQLHDESC for the statements, connections, envi-\\nronments, and descriptions needed in the program, respectively (lines 2 \\nto 4). 14 Also declare variables of type SQLRETURN  (line 5) to hold the \\nreturn codes from the SQL/CLI function calls. A return code of 0 (zero) \\nindicates successful execution  of the function call.\\n  3. Environment record. An environment record must be set up in the program \\nusing SQLAllocHandle. The function to do this is shown in line 6. Because \\nan environment record is not contained in any other record, the parameter \\n<\\nhandle_1> is the NULL handle SQL_NULL_HANDLE (NULL pointer) when \\ncreating an environment. The handle (pointer) to the newly created envi-\\nronment record is returned in variable env1 in line 6.\\n  4. Connecting to the database.  A connection record is set up in the program \\nusing SQLAllocHandle. In line 7, the connection record created has the han-\\ndle con1 and is contained in the environment env1. A connection is then \\nestablished in con1 to a particular server database using the SQLConnect \\n14To keep our presentation simple, we will not show description records here.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 342, 'page_label': '343'}, page_content='10.3 Database Programming with Function Calls and Class Libraries: SQL/CLI and JDBC  329\\nfunction of SQL/CLI (line 8). In our example, the database server name we \\nare connecting to is dbs and the account name and password for login are js \\nand xyz, respectively.\\n  5. Statement record.  A statement record  is set up in the program using \\nSQLAllocHandle. In line 9, the statement record created has the handle \\nstmt1 and uses the connection con1.\\n  6. Preparing an SQL statement and statement parameters.  The SQL state-\\nment is prepared  using the SQL/CLI function SQLPrepare. In line 10, \\nthis assigns the SQL statement string  (the query in our example) to the \\nstatement handle stmt1. The question mark ( ?) symbol in line 10 repre-\\nsents a statement parameter , which is a value to be determined at run-\\ntime—typically by binding it to a C program variable. In general, there \\ncould be several parameters in a statement string. They are distinguished \\nby the order of appearance of the question marks in the statement string \\n(the first \\n? represents parameter 1, the second ? represents parameter 2, \\nand so on). The last parameter in SQLPrepare should give the length of \\nthe SQL statement string in bytes, but if we enter the keyword SQL_NTS, \\nthis indicates that the string holding the query is a NULL-terminated \\nstring so that SQL can calculate the string length automatically. This use \\nof SQL_NTS also applies to other string parameters  in the function calls in \\nour examples.\\n  7. Binding the statement parameters. Before executing the query, any param-\\neters in the query string should be bound to program variables using the \\nSQL/CLI function SQLBindParameter . In Figure 10.10, the parameter \\n(indicated by ?) to the prepared query referenced by stmt1 is bound to the \\nC program variable ssn in line 12. If there are n parameters in the SQL state-\\nment, we should have n SQLBindParameter function calls, each with a dif-\\nferent parameter position (1, 2, … , n).\\n  8. Executing the statement.  Following these preparations, we can now exe-\\ncute the SQL statement referenced by the handle stmt1 using the func-\\ntion SQLExecute  (line 13). Notice that although the query will be \\nexecuted in line 13, the query results have not yet been assigned to any C \\nprogram variables.\\n  9. Processing the query result.  In order to determine where the result of the \\nquery is returned, one common technique is the bound columns approach. \\nHere, each column in a query result is bound to a C program variable using \\nthe \\nSQLBindCol function. The columns are distinguished by their order of \\nappearance in the SQL query. In Figure 10.10 lines 15 and 16, the two col-\\numns in the query ( Lname and Salary) are bound to the C program vari-\\nables lname and salary, respectively.15\\n15An alternative technique known as unbound columns uses different SQL/CLI functions, namely \\nSQLGetCol or SQLGetData, to retrieve columns from the query result without previously binding them; \\nthese are applied after the SQLFetch command in line 17 .'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 343, 'page_label': '344'}, page_content='330 Chapter 10 Introduction to SQL Programming Techniques\\n 10. Retrieving column values. Finally, in order to retrieve the column values into \\nthe C program variables, the function SQLFetch is used (line 17). This func-\\ntion is similar to the FETCH command of embedded SQL. If a query result has \\na collection of tuples, each SQLFetch call gets the next tuple and returns its \\ncolumn values into the bound program variables. SQLFetch returns an excep-\\ntion (nonzero) code if there are no more tuples in the query result.16\\nAs we can see, using dynamic function calls requires a lot of preparation to set up \\nthe SQL statements and to bind statement parameters and query results to the \\nappropriate program variables.\\nIn CLI1 a single tuple is selected by the SQL query. Figure 10.11 shows an example \\nof retrieving multiple tuples. We assume that appropriate C program variables have \\nbeen declared as in Figure 10.1. The program segment in CLI2 reads (inputs) a \\n16If unbound program variables are used, SQLFetch returns the tuple into a temporary program area. \\nEach subsequent SQLGetCol (or SQLGetData) returns one attribute value in order. Basically, for each \\nrow in the query result, the program should iterate over the attribute values (columns) in that row. This is \\nuseful if the number of columns in the query result is variable.\\n    //Program Segment CLI2:\\n 0) #include sqlcli.h ;\\n 1) void printDepartmentEmps() {\\n 2) SQLHSTMT stmt1 ;\\n 3) SQLHDBC con1 ;\\n 4) SQLHENV env1 ;\\n 5) SQLRETURN ret1, ret2, ret3, ret4 ;\\n 6) ret1 = SQLAllocHandle(SQL_HANDLE_ENV, SQL_NULL_HANDLE, &env1) ;\\n 7) if (!ret1) ret2 = SQLAllocHandle(SQL_HANDLE_DBC, env1, &con1) else exit ;\\n 8) if (!ret2) ret3 = SQLConnect(con1, \"dbs\", SQL_NTS, \"js\", SQL_NTS, \"xyz\",\\n      SQL_NTS) else exit ;\\n 9) if (!ret3) ret4 = SQLAllocHandle(SQL_HANDLE_STMT, con1, &stmt1) else exit ;\\n10) SQLPrepare(stmt1, \"select Lname, Salary from EMPLOYEE where Dno = ?\",\\n      SQL_NTS) ;\\n11) prompt(\"Enter the Department Number: \", dno) ;\\n12) SQLBindParameter(stmt1, 1, SQL_INTEGER, &dno, 4, &fetchlen1) ;\\n13) ret1 = SQLExecute(stmt1) ;\\n14) if (!ret1) {\\n15)   SQLBindCol(stmt1, 1, SQL_CHAR, &lname, 15, &fetchlen1) ;\\n16)   SQLBindCol(stmt1, 2, SQL_FLOAT, &salary, 4, &fetchlen2) ;\\n17)   ret2 = SQLFetch(stmt1) ;\\n18)   while (!ret2) {\\n19)     printf(lname, salary) ;\\n20)     ret2 = SQLFetch(stmt1) ;\\n21)     }\\n22)   }\\n23) }\\nFigure 10.11 \\nProgram segment CLI2, a C program segment \\nthat uses SQL/CLI for a query with a collection \\nof tuples in its result.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 344, 'page_label': '345'}, page_content='10.3 Database Programming with Function Calls and Class Libraries: SQL/CLI and JDBC  331\\ndepartment number and then retrieves the employees who work in that depart-\\nment. A loop then iterates over each employee record, one at a time, and prints the \\nemployee’s last name and salary.\\n10.3.2 JDBC: SQL Class Library for Java Programming\\nWe now turn our attention to how SQL can be called from the Java object-oriented \\nprogramming language.\\n17 The class libraries and associated function calls for this \\naccess are known as JDBC.18 The Java programming language was designed to be \\nplatform independent—that is, a program should be able to run on any type of \\ncomputer system that has a Java interpreter installed. Because of this portability, \\nmany RDBMS vendors provide JDBC drivers so that it is possible to access their \\nsystems via Java programs.\\nJDBC drivers. A JDBC driver is basically an implementation of the classes and \\nassociated objects and function calls specified in JDBC for a particular vendor’s \\nRDBMS. Hence, a Java program with JDBC objects and function calls can access \\nany RDBMS that has a JDBC driver available.\\nBecause Java is object-oriented, its function libraries are implemented as classes. \\nBefore being able to process JDBC function calls with Java, it is necessary to import \\nthe JDBC class libraries, which are called \\njava.sql.*. These can be downloaded \\nand installed via the Web.19\\nJDBC is designed to allow a single Java program to connect to several different \\ndatabases. These are sometimes called the data sources accessed by the Java pro-\\ngram, and could be stored using RDBMSs from different vendors residing on dif-\\nferent machines. Hence, different data source accesses within the same Java \\nprogram may require JDBC drivers from different vendors. To achieve this flexibil-\\nity, a special JDBC class called the driver manager class is employed, which keeps \\ntrack of the installed drivers. A driver should be registered with the driver manager \\nbefore it is used. The operations (methods) of the driver manager class include \\ngetDriver, registerDriver, and deregisterDriver. These can be used to add \\nand remove drivers for different systems dynamically. Other functions set up and \\nclose connections to data sources.\\nTo load a JDBC driver explicitly, the generic Java function for loading a class can be \\nused. For example, to load the JDBC driver for the Oracle RDBMS, the following \\ncommand can be used:\\nClass.forName(\"oracle.jdbc.driver.OracleDriver\")\\n17This section assumes familiarity with object-oriented concepts (see Chapter 11) and basic Java concepts.\\n18As we mentioned earlier, JDBC is a registered trademark of Sun Microsystems, although it is commonly \\nthought to be an acronym for Java Database Connectivity.\\n19These are available from several Web sites—for example, at http://industry.java.sun.com/products/\\njdbc/drivers.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 345, 'page_label': '346'}, page_content='332 Chapter 10 Introduction to SQL Programming Techniques\\nThis will register the driver with the driver manager and make it available to the \\nprogram. It is also possible to load and register the driver(s) needed in the com-\\nmand line that runs the program, for example, by including the following in the \\ncommand line:\\n-Djdbc.drivers = oracle.jdbc.driver\\nJDBC programming steps. The following are typical steps that are taken when \\nwriting a Java application program with database access through JDBC function \\ncalls. We illustrate the steps by referring to the example JDBC1 in Figure 10.12, \\nwhich reads a Social Security number of an employee and prints the employee’s last \\nname and salary.\\n  1. Import the JDBC class library.  The JDBC library of classes  must be \\nimported into the Java program. These classes are called java.sql.*, and \\ncan be imported using line 1 in Figure 10.12. Any additional Java class \\nlibraries needed by the program must also be imported.\\n    //Program JDBC1:\\n 0) import java.io.* ;\\n 1) import java.sql.*\\n    ...\\n 2) class getEmpInfo {\\n 3)   public static void main (String args []) throws SQLException, IOException {\\n 4)     try { Class.forName(\"oracle.jdbc.driver.OracleDriver\")\\n 5)     } catch (ClassNotFoundException x) {\\n 6)       System.out.println (\"Driver could not be loaded\") ;\\n 7)     }\\n 8)     String dbacct, passwrd, ssn, lname ;\\n 9)     Double salary ;\\n10)     dbacct = readentry(\"Enter database account:\") ;\\n11)     passwrd = readentry(\"Enter password:\") ;\\n12)     Connection conn = DriverManager.getConnection\\n13)       (\"jdbc:oracle:oci8:\" + dbacct + \"/\" + passwrd) ;\\n14)     String stmt1 = \"select Lname, Salary from EMPLOYEE where Ssn = ?\" ;\\n15)     PreparedStatement p = conn.prepareStatement(stmt1) ;\\n16)     ssn = readentry(\"Enter a Social Security Number: \") ;\\n17)     p.clearParameters() ;\\n18)     p.setString(1, ssn) ;\\n19)     ResultSet r = p.executeQuery() ;\\n20)     while (r.next()) {\\n21)       lname = r.getString(1) ;\\n22)       salary = r.getDouble(2) ;\\n23)       system.out.printline(lname + salary) ;\\n24)   } }\\n25) }\\nFigure 10.12 \\nProgram segment JDBC1, \\na Java program segment \\nwith JDBC.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 346, 'page_label': '347'}, page_content='10.3 Database Programming with Function Calls and Class Libraries: SQL/CLI and JDBC  333\\n  2. Load the JDBC driver. This is shown in lines 4 to 7. The Java exception in \\nline 5 occurs if the driver is not loaded successfully.\\n  3. Create appropriate variables.  These are the variables needed in the Java \\nprogram (lines 8 and 9).\\n  4. The Connection  object.  A connection object  is created using the  \\ngetConnection function of the DriverManager class of JDBC. In lines 12 \\nand 13, the Connection  object is created by using the function call \\ngetConnection(urlstring), where urlstring has the form\\njdbc:oracle:<driverType>:<dbaccount>/<password>\\nAn alternative form is\\ngetConnection(url, dbaccount, password)\\nVarious properties can be set for a connection object, but they are mainly \\nrelated to transactional properties, which we discuss in Chapter 21.\\n  5. The Prepared Statement object. A statement object is created in the pro-\\ngram. In JDBC, there is a basic statement class, Statement, with two spe-\\ncialized subclasses: PreparedStatement and CallableStatement. The \\nexample in Figure 10.12 illustrates how PreparedStatement objects are \\ncreated and used. The next example (Figure 10.13) illustrates the other type \\nof \\nStatement objects. In line 14 in Figure 10.12, a query string with a sin-\\ngle parameter—indicated by the ? symbol—is created in the string variable \\nstmt1. In line 15, an object p of type PreparedStatement is created based \\non the query string in stmt1 and using the connection object conn. In gen-\\neral, the programmer should use PreparedStatement objects if a query is \\nto be executed multiple times , since it would be prepared, checked, and \\ncompiled only once, thus saving this cost for the additional executions of \\nthe query.\\n  6. Setting the statement parameters. The question mark (?) symbol in line 14 \\nrepresents a statement parameter, which is a value to be determined at run-\\ntime, typically by binding it to a Java program variable. In general, there \\ncould be several parameters, distinguished by the order of appearance of the \\nquestion marks within the statement string (first \\n? represents parameter 1, \\nsecond ? represents parameter 2, and so on), as we discussed previously.\\n  7. Binding the statement parameters. Before executing a PreparedStatement \\nquery, any parameters should be bound to program variables. Depending \\non the type of the parameter, different functions such as setString , \\nsetInteger, setDouble, and so on are applied to the PreparedStatement \\nobject to set its parameters. The appropriate function should be used to cor-\\nrespond to the data type of the parameter being set. In Figure 10.12, the \\nparameter (indicated by \\n?) in object p is bound to the Java program variable \\nssn in line 18. The function setString is used because ssn is a string vari-\\nable. If there are n parameters in the SQL statement, we should have n set ... \\nfunctions, each with a different parameter position (1, 2, … , n). Generally, it \\nis advisable to clear all parameters before setting any new values (line 17).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 347, 'page_label': '348'}, page_content='334 Chapter 10 Introduction to SQL Programming Techniques\\n  8. Executing the SQL statement.  Following these preparations, we can now \\nexecute the SQL statement referenced by the object p using the function \\nexecuteQuery  (line 19). There is a generic function execute in JDBC,  \\nplus two specialized functions: executeUpdate  and executeQuery .  \\nexecuteUpdate is used for SQL insert, delete, or update statements, and \\nreturns an integer value indicating the number of tuples that were affected. \\nexecuteQuery is used for SQL retrieval statements, and returns an object of \\ntype ResultSet, which we discuss next.\\n  9. Processing the ResultSet  object.  In line 19, the result of the query is \\nreturned in an object r of type ResultSet. This resembles a two-dimensional \\narray or a table, where the tuples are the rows and the attributes returned are \\nthe columns. A \\nResultSet object is similar to a cursor in embedded SQL \\nand an iterator in SQLJ. In our example, when the query is executed, r refers \\nto a tuple before the first tuple in the query result. The r.next() function \\n(line 20) moves to the next tuple (row) in the ResultSet object and returns \\nNULL if there are no more objects. This is used to control the looping. The \\n    //Program Segment JDBC2:\\n 0) import java.io.* ;\\n 1) import java.sql.*\\n    ...\\n 2) class printDepartmentEmps {\\n 3)   public static void main (String args [])\\n          throws SQLException, IOException {\\n 4)     try { Class.forName(\"oracle.jdbc.driver.OracleDriver\")\\n 5)     } catch (ClassNotFoundException x) {\\n 6)       System.out.println (\"Driver could not be loaded\") ;\\n 7)     }\\n 8)     String dbacct, passwrd, lname ;\\n 9)     Double salary ;\\n10)     Integer dno ;\\n11)     dbacct = readentry(\"Enter database account:\") ;\\n12)     passwrd = readentry(\"Enter password:\") ;\\n13)     Connection conn = DriverManager.getConnection\\n14)       (\"jdbc:oracle:oci8:\" + dbacct + \"/\" + passwrd) ;\\n15)     dno = readentry(\"Enter a Department Number: \") ;\\n16)     String q = \"select Lname, Salary from EMPLOYEE where Dno = \" +\\n        dno.tostring() ;\\n17)     Statement s = conn.createStatement() ;\\n18)     ResultSet r = s.executeQuery(q) ;\\n19)     while (r.next()) {\\n20)       lname = r.getString(1) ;\\n21)       salary = r.getDouble(2) ;\\n22)       system.out.printline(lname + salary) ;\\n23)   } }\\n24) }\\nFigure 10.13 \\nProgram segment JDBC2, a Java program \\nsegment that uses JDBC for a query with a \\ncollection of tuples in its result.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 348, 'page_label': '349'}, page_content='10.4 Database Stored Procedures and SQL/PSM  335\\nprogrammer can refer to the attributes in the current tuple using various \\nget ... functions that depend on the type of each attribute (for example, \\ngetString, getInteger, getDouble, and so on). The programmer can \\neither use the attribute positions (1, 2) or the actual attribute names \\n(\\n\"Lname\", \"Salary\") with the get … functions. In our examples, we used \\nthe positional notation in lines 21 and 22.\\nIn general, the programmer can check for SQL exceptions after each JDBC function \\ncall. We did not do this to simplify the examples.\\nNotice that JDBC does not distinguish between queries that return single tuples and \\nthose that return multiple tuples, unlike some of the other techniques. This is justi-\\nfiable because a single tuple result set is just a special case.\\nIn example JDBC1, a single tuple is selected by the SQL query, so the loop in lines 20 \\nto 24 is executed at most once. The example shown in Figure 10.13 illustrates the \\nretrieval of multiple tuples. The program segment in JDBC2 reads (inputs) a depart-\\nment number and then retrieves the employees who work in that department. A \\nloop then iterates over each employee record, one at a time, and prints the employee’s \\nlast name and salary. This example also illustrates how we can execute a query \\ndirectly, without having to prepare it as in the previous example. This technique is \\npreferred for queries that will be executed only once, since it is simpler to program. \\nIn line 17 of Figure 10.13, the programmer creates a Statement object (instead of \\nPreparedStatement , as in the previous example) without associating it with a \\nparticular query string. The query string q is passed to the statement object s when \\nit is executed in line 18.\\nThis concludes our brief introduction to JDBC. The interested reader is referred to \\nthe Web site http://java.sun.com/docs/books/tutorial/jdbc/, which contains many \\nfurther details about JDBC.\\n10.4  Database Stored Procedures  \\nand SQL/PSM\\nThis section introduces two additional topics related to database programming. In \\nSection 10.4.1, we discuss the concept of stored procedures, which are program \\nmodules that are stored by the DBMS at the database server. Then in Section 10.4.2 \\nwe discuss the extensions to SQL that are specified in the standard to include  \\ngeneral-purpose programming constructs in SQL. These extensions are known as \\nSQL/PSM (SQL/Persistent Stored Modules) and can be used to write stored proce-\\ndures. SQL/PSM also serves as an example of a database programming language \\nthat extends a database model and language—namely, SQL—with programming \\nlanguage constructs, such as conditional statements and loops.\\n10.4.1 Database Stored Procedures and Functions\\nIn our presentation of database programming techniques so far, there was an \\nimplicit assumption that the database application program was running on a client'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 349, 'page_label': '350'}, page_content='336 Chapter 10 Introduction to SQL Programming Techniques\\nmachine, or more likely at the application server computer  in the middle-tier of a \\nthree-tier client-server architecture (see Section 2.5.4 and Figure 2.7). In either case, \\nthe machine where the program is executing is different from the machine on which \\nthe database server—and the main part of the DBMS software package—is located. \\nAlthough this is suitable for many applications, it is sometimes useful to create \\ndatabase program modules—procedures or functions—that are stored and exe-\\ncuted by the DBMS at the database server. These are historically known as database \\nstored procedures, although they can be functions or procedures. The term used in \\nthe SQL standard for stored procedures is persistent stored modules because these \\nprograms are stored persistently by the DBMS, similarly to the persistent data \\nstored by the DBMS.\\nStored procedures are useful in the following circumstances:\\n ■ If a database program is needed by several applications, it can be stored at \\nthe server and invoked by any of the application programs. This reduces \\nduplication of effort and improves software modularity.\\n ■ Executing a program at the server can reduce data transfer and communica-\\ntion cost between the client and server in certain situations.\\n ■ These procedures can enhance the modeling power provided by views by \\nallowing more complex types of derived data to be made available to the \\ndatabase users via the stored procedures. Additionally, they can be used to \\ncheck for complex constraints that are beyond the specification power of \\nassertions and triggers.\\nIn general, many commercial DBMSs allow stored procedures and functions to be \\nwritten in a general-purpose programming language. Alternatively, a stored proce-\\ndure can be made of simple SQL commands such as retrievals and updates. The \\ngeneral form of declaring stored procedures is as follows:\\nCREATE PROCEDURE <procedure name> (<parameters>)\\n<local declarations>\\n<procedure body> ;\\nThe parameters and local declarations are optional, and are specified only if needed. \\nFor declaring a function, a return type is necessary, so the declaration form is:\\nCREATE FUNCTION <function name> (<parameters>)\\nRETURNS <return type>\\n<local declarations>\\n<function body> ;\\nIf the procedure (or function) is written in a general-purpose programming language, \\nit is typical to specify the language as well as a file name where the program code is \\nstored. For example, the following format can be used:\\nCREATE PROCEDURE <procedure name> (<parameters>)\\nLANGUAGE <programming language name>\\nEXTERNAL NAME <file path name> ;'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 350, 'page_label': '351'}, page_content='10.4 Database Stored Procedures and SQL/PSM  337\\nIn general, each parameter should have a parameter type  that is one of the SQL \\ndata types. Each parameter should also have a parameter mode, which is one of IN, \\nOUT, or INOUT. These correspond to parameters whose values are input only, out-\\nput (returned) only, or both input and output, respectively.\\nBecause the procedures and functions are stored persistently by the DBMS, it \\nshould be possible to call them from the various SQL interfaces and programming \\ntechniques. The \\nCALL statement in the SQL standard can be used to invoke a stored \\nprocedure—either from an interactive interface or from embedded SQL or SQLJ. \\nThe format of the statement is as follows:\\nCALL <procedure or function name> (<argument list>) ;\\nIf this statement is called from JDBC, it should be assigned to a statement object of \\ntype CallableStatement (see Section 10.3.2).\\n10.4.2  SQL/PSM: Extending SQL for Specifying Persistent \\nStored Modules\\nSQL/PSM is the part of the SQL standard that specifies how to write persistent \\nstored modules. It includes the statements to create functions and procedures that \\nwe described in the previous section. It also includes additional programming con-\\nstructs to enhance the power of SQL for the purpose of writing the code (or body) \\nof stored procedures and functions.\\nIn this section, we discuss the SQL/PSM constructs for conditional (branching) \\nstatements and for looping statements. These will give a flavor of the type of con-\\nstructs that SQL/PSM has incorporated;\\n20 then we give an example to illustrate how \\nthese constructs can be used.\\nThe conditional branching statement in SQL/PSM has the following form:\\nIF <condition> THEN <statement list>\\nELSEIF <condition> THEN <statement list>\\n…\\nELSEIF <condition> THEN <statement list>\\nELSE <statement list>\\nEND IF ;\\nConsider the example in Figure 10.14, which illustrates how the conditional branch \\nstructure can be used in an SQL/PSM function. The function returns a string value \\n(line 1) describing the size of a department within a company based on the number \\nof employees. There is one IN integer parameter, \\ndeptno, which gives a depart-\\nment number. A local variable NoOfEmps is declared in line 2. The query in lines 3 \\nand 4 returns the number of employees in the department, and the conditional \\n20We only give a brief introduction to SQL/PSM here. There are many other features in the SQL/PSM \\nstandard.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 351, 'page_label': '352'}, page_content='338 Chapter 10 Introduction to SQL Programming Techniques\\nbranch in lines 5 to 8 then returns one of the values {‘HUGE’, ‘LARGE’, ‘MEDIUM’, \\n‘SMALL’} based on the number of employees.\\nSQL/PSM has several constructs for looping. There are standard while and repeat \\nlooping structures, which have the following forms:\\nWHILE <condition> DO\\n          <statement list>\\nEND WHILE ;\\nREPEAT\\n          <statement list>\\nUNTIL <condition>\\nEND REPEAT ;\\nThere is also a cursor-based looping structure. The statement list in such a loop is \\nexecuted once for each tuple in the query result. This has the following form:\\nFOR <loop name> AS <cursor name> CURSOR FOR <query> DO\\n          <statement list>\\nEND FOR ;\\nLoops can have names, and there is a LEAVE <loop name> statement to break a loop \\nwhen a condition is satisfied. SQL/PSM has many other features, but they are out-\\nside the scope of our presentation.\\n10.5 Comparing the Three Approaches\\nIn this section, we briefly compare the three approaches for database programming \\nand discuss the advantages and disadvantages of each approach.\\n  4. Embedded SQL Approach. The main advantage of this approach is that the \\nquery text is part of the program source code itself, and hence can be checked \\nfor syntax errors and validated against the database schema at compile time. \\nThis also makes the program quite readable, as the queries are readily visible \\n//Function PSM1:\\n0) CREATE FUNCTION Dept_size(IN deptno INTEGER)\\n1) RETURNS VARCHAR [7]\\n2) DECLARE No_of_emps INTEGER ;\\n3) SELECT COUNT(*) INTO No_of_emps\\n4) FROM EMPLOYEE WHERE Dno = deptno ;\\n5) IF No_of_emps > 100 THEN RETURN \"HUGE\"\\n6) ELSEIF No_of_emps > 25 THEN RETURN \"LARGE\"\\n7) ELSEIF No_of_emps > 10 THEN RETURN \"MEDIUM\"\\n8) ELSE RETURN \"SMALL\"\\n9) END IF ;\\nFigure 10.14 \\nDeclaring a function in \\nSQL/PSM.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 352, 'page_label': '353'}, page_content='10.6 Summary  339\\nin the source code. The main disadvantages are the loss of flexibility in \\nchanging the query at runtime, and the fact that all changes to queries must \\ngo through the whole recompilation process. In addition, because the que-\\nries are known beforehand, the choice of program variables to hold the \\nquery results is a simple task, and so the programming of the application is \\ngenerally easier. However, for complex applications where queries have to \\nbe generated at runtime, the function call approach will be more suitable.\\n  5. Library of Classes and Function Calls Approach.  This approach provides \\nmore flexibility in that queries can be generated at runtime if needed. How-\\never, this leads to more complex programming, as program variables that \\nmatch the columns in the query result may not be known in advance. \\nBecause queries are passed as statement strings within the function calls, no \\nchecking can be done at compile time. All syntax checking and query valida-\\ntion has to be done at runtime by preparing the query, and the programmer \\nmust check and account for possible additional runtime errors within the \\nprogram code.\\n  6. Database Programming Language Approach. This approach does not suf-\\nfer from the impedance mismatch problem, as the programming language \\ndata types are the same as the database data types. However, programmers \\nmust learn a new programming language rather than use a language they are \\nalready familiar with. In addition, some database programming languages \\nare vendor-specific, whereas general-purpose programming languages can \\neasily work with systems from multiple vendors.\\n10.6 Summary\\nIn this chapter we presented additional features of the SQL database language. In \\nparticular, we presented an overview of the most important techniques for database \\nprogramming in Section 10.1. Then we discussed the various approaches to data-\\nbase application programming in Sections 10.2 to 10.4.\\nIn Section 10.2, we discussed the general technique known as embedded SQL, \\nwhere the queries are part of the program source code. A precompiler is typically \\nused to extract SQL commands from the program for processing by the DBMS, and \\nreplacing them with function calls to the DBMS compiled code. We presented an \\noverview of embedded SQL, using the C programming language as host language in \\nour examples. We also discussed the SQLJ technique for embedding SQL in Java \\nprograms. The concepts of cursor (for embedded SQL) and iterator (for SQLJ) were \\npresented and illustrated by examples to show how they are used for looping over \\nthe tuples in a query result, and extracting the attribute value into program vari-\\nables for further processing.\\nIn Section 10.3, we discussed how function call libraries can be used to access SQL \\ndatabases. This technique is more dynamic than embedding SQL, but requires \\nmore complex programming because the attribute types and number in a query \\nresult may be determined at runtime. An overview of the SQL/CLI standard was'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 353, 'page_label': '354'}, page_content='340 Chapter 10 Introduction to SQL Programming Techniques\\npresented, with examples using C as the host language. We discussed some of the \\nfunctions in the SQL/CLI library, how queries are passed as strings, how query \\nparameters are assigned at runtime, and how results are returned to program vari-\\nables. We then gave an overview of the JDBC class library, which is used with Java, \\nand discussed some of its classes and operations. In particular, the \\nResultSet class \\nis used to create objects that hold the query results, which can then be iterated over \\nby the \\nnext() operation. The get and set functions for retrieving attribute values \\nand setting parameter values were also discussed.\\nIn Section 10.4, we gave a brief overview of stored procedures, and discussed  \\nSQL/PSM as an example of a database programming language. Finally, we briefly \\ncompared the three approaches in Section 10.5. It is important to note that we chose \\nto give a comparative overview of the three main approaches to database program-\\nming, since studying a particular approach in depth is a topic that is worthy of its \\nown textbook.\\nReview Questions\\n 10.1. What is ODBC? How is it related to SQL/CLI?\\n 10.2. What is JDBC? Is it an example of embedded SQL or of using function calls?\\n 10.3. List the three main approaches to database programming. What are the \\nadvantages and disadvantages of each approach?\\n 10.4. What is the impedance mismatch problem? Which of the three program-\\nming approaches minimizes this problem?\\n 10.5. Describe the concept of a cursor and how it is used in embedded SQL.\\n 10.6. What is SQLJ used for? Describe the two types of iterators available in SQLJ.\\nExercises\\n 10.7. Consider the database shown in Figure 1.2, whose schema is shown in Fig-\\nure 2.1. Write a program segment to read a student’s name and print his or \\nher grade point average, assuming that A = 4, B = 3, C = 2, and D = 1 points. \\nUse embedded SQL with C as the host language.\\n 10.8. Repeat Exercise 10.7, but use SQLJ with Java as the host language.\\n 10.9. Consider the library relational database schema in Figure 6.6. Write a pro-\\ngram segment that retrieves the list of books that became overdue yesterday \\nand that prints the book title and borrower name for each. Use embedded \\nSQL with C as the host language.\\n 10.10. Repeat Exercise 10.9, but use SQLJ with Java as the host language.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 354, 'page_label': '355'}, page_content='Selected Bibliography 341\\n 10.11. Repeat Exercises 10.7 and 10.9, but use SQL/CLI with C as the host lan-\\nguage.\\n 10.12. Repeat Exercises 10.7 and 10.9, but use JDBC with Java as the host language.\\n 10.13. Repeat Exercise 10.7, but write a function in SQL/PSM.\\n 10.14. Create a function in PSM that computes the median salary for the EMPLOYEE \\ntable shown in Figure 5.5.\\nSelected Bibliography\\nThere are many books that describe various aspects of SQL database programming. \\nFor example, Sunderraman (2007) describes programming on the Oracle 10g \\nDBMS and Reese (1997) focuses on JDBC and Java programming. Many Web \\nresources are also available.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 355, 'page_label': '356'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 356, 'page_label': '357'}, page_content='343\\n11\\nWeb Database  \\nProgramming Using PHP\\nI\\nn the previous chapter, we gave an overview of data-\\nbase programming techniques using traditional pro-\\ngramming languages, and we used the Java and C programming languages in our \\nexamples. We now turn our attention to how databases are accessed from scripting \\nlanguages. Many Internet applications that provide Web interfaces to access infor-\\nmation stored in one or more databases use scripting languages. These languages \\nare often used to generate HTML documents, which are then displayed by the Web \\nbrowser for interaction with the user. In our presentation, we assume that the \\nreader is familiar with basic HTML concepts.\\nBasic HTML is useful for generating static Web pages with fixed text and other \\nobjects, but most Internet applications require Web pages that provide interactive \\nfeatures with the user. For example, consider the case of an airline customer who \\nwants to check the arrival time and gate information of a particular flight. The user \\nmay enter information such as a date and flight number in certain fields of the Web \\npage. The Web interface will send this information to the application program, \\nwhich formulates and submits a query to the airline database server to retrieve the \\ninformation that the user needs. The database information is sent back to the Web \\npage for display. Such Web pages, where part of the information is extracted from \\ndatabases or other data sources, are called dynamic Web pages. The data extracted \\nand displayed each time will be for different flights and dates.\\nThere are various techniques for programming dynamic features into Web pages. \\nWe will focus on one technique here, which is based on using the PHP open source \\nserver side scripting language. PHP originally stood for Personal Home Page, but \\nnow stands for PHP Hypertext Processor. PHP has experienced widespread use. The \\ninterpreters for PHP are provided free of charge and are written in the C language so \\nchapter 11'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 357, 'page_label': '358'}, page_content='344 Chapter 11 Web Database Programming Using PHP\\nthey are available on most computer platforms. A PHP interpreter provides a Hyper-\\ntext Preprocessor, which will execute PHP commands in a text file and create the \\ndesired HTML file. To access databases, a library of PHP functions needs to be \\nincluded in the PHP interpreter, as we will discuss in Section 11.3. PHP programs \\nare executed on the Web server computer. This is in contrast to some scripting lan-\\nguages, such as JavaScript, that are executed on the client computer. There are many \\nother popular scripting languages that can be used to access databases and create \\ndynamic Web pages, such as JavaScript, Ruby, Python, and PERL, to name a few.\\nThis chapter is organized as follows. Section 11.1 gives a simple example to illustrate \\nhow PHP can be used. Section 11.2 gives a general overview of the PHP language \\nand how it is used to program some basic functions for interactive Web pages. Sec-\\ntion 11.3 focuses on using PHP to interact with SQL databases through a library of \\nfunctions known as PEAR DB. Section 11.4 lists some of the additional technologies \\nassociated with Java for Web and database programming (we already discussed \\nJDBC and SQLJ in Chapter 10). Finally, Section 11.5 contains a chapter summary.\\n11.1 A Simple PHP Example\\nPHP is an open source general-purpose scripting language. The interpreter engine \\nfor PHP is written in the C programming language so it can be used on nearly all \\ntypes of computers and operating systems. PHP usually comes installed with the \\nUNIX operating system. For computer platforms with other operating systems \\nsuch as Windows, Linux, or Mac OS, the PHP interpreter can be downloaded from: \\nhttp://www.php.net. As with other scripting languages, PHP is particularly suited \\nfor manipulation of text pages, and in particular for manipulating dynamic HTML \\npages at the Web server computer. This is in contrast to JavaScript, which is down-\\nloaded with the Web pages to execute on the client computer.\\nPHP has libraries of functions for accessing databases stored under various types of \\nrelational database systems such as Oracle, MySQL, SQLServer, and any system \\nthat supports the ODBC standard (see Chapter 10). Under the three-tier architec-\\nture (see Chapter 2), the DBMS would reside at the bottom-tier database server . \\nPHP would run at the middle-tier Web server, where the PHP program commands \\nwould manipulate the HTML files to create the customized dynamic Web pages. \\nThe HTML is then sent to the client tier for display and interaction with the user.\\nConsider the PHP example shown in Figure 11.1(a), which prompts a user to enter \\nthe first and last name and then prints a welcome message to that user. The line \\nnumbers are not part of the program code; they are used below for explanation \\npurposes only:\\n  1. Suppose that the file containing PHP script in program segment P1 is stored in \\nthe following Internet location: http://www.myserver.com/example/greeting.php. \\nThen if a user types this address in the browser, the PHP interpreter would start \\ninterpreting the code and produce the form shown in Figure 11.1(b). We will \\nexplain how that happens as we go over the lines in code segment P1.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 358, 'page_label': '359'}, page_content='11.1 A Simple PHP Example  345\\n  2. Line 0 shows the PHP start tag <?php, which indicates to the PHP inter-\\npreter engine that it should process all subsequent text lines until it encoun-\\nters the PHP end tag \\n?>, shown on line 16. Text outside of these tags is \\nprinted as is. This allows PHP code segments to be included within a larger \\nHTML file. Only the sections in the file between \\n<?php and ?> are processed \\nby the PHP preprocessor.\\n  3. Line 1 shows one way of posting comments in a PHP program on a single \\nline started by \\n//. Single-line comments can also be started with #, and end \\nat the end of the line in which they are entered. Multiple-line comments \\nstart with \\n/* and end with */.\\n  4. The auto-global predefined PHP variable $_POST (line 2) is an array that \\nholds all the values entered through form parameters. Arrays in PHP are \\nEnter your name:\\nSUBMIT NAME SUBMIT NAME\\nEnter your name:\\n(b) (c)\\n(d)\\nJohn Smith\\nWelcome, John Smith\\n(a)\\n    //Program Segment P1:\\n 0) <?php\\n 1) // Printing a welcome message if the user submitted their name\\n    // through the HTML form\\n 2) if ($_POST[\\'user_name\\']) {\\n 3)   print(\"Welcome, \") ;\\n 4)   print($_POST[\\'user_name\\']);\\n 5) }\\n 6) else {\\n 7)   // Printing the form to enter the user name since no name has\\n      // been entered yet\\n 8)   print <<<_HTML_\\n 9)   <FORM method=\"post\" action=\"$_SERVER[\\'PHP_SELF\\']\">\\n10)   Enter your name: <input type=\"text\" name=\"user_name\">\\n11)   <BR/>\\n12)   <INPUT type=\"submit\" value=\"SUBMIT NAME\">\\n13)   </FORM>\\n14)   _HTML_;\\n15) }\\n16) ?>\\nFigure 11.1 \\n(a) PHP program segment for entering a greeting. \\n(b) Initial form displayed by PHP program segment. \\n(c) User enters name John Smith. (d) Form prints \\nwelcome message for John Smith.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 359, 'page_label': '360'}, page_content='346 Chapter 11 Web Database Programming Using PHP\\ndynamic arrays, with no fixed number of elements. They can be numerically \\nindexed arrays whose indexes (positions) are numbered (0, 1, 2, … ), or they \\ncan be associative arrays whose indexes can be any string values. For exam-\\nple, an associative array indexed based on color can have the indexes {“red”, \\n“blue”, “green”}. In this example, \\n$_POST is associatively indexed by the \\nname of the posted value user_name that is specified in the name attribute of \\nthe input tag on line 10. Thus $_POST[\\'user_name\\'] will contain the value \\ntyped in by the user. We will discuss PHP arrays further in Section 11.2.2.\\n  5. When the Web page at http://www.myserver.com/example/greeting.php is \\nfirst opened, the \\nif condition in line 2 will evaluate to false because there is \\nno value yet in $_POST[\\'user_name\\'] . Hence, the PHP interpreter will \\nprocess lines 6 through 15, which create the text for an HTML file that dis-\\nplays the form shown in Figure 11.1(b). This is then displayed at the client \\nside by the Web browser.\\n  6. Line 8 shows one way of creating long text strings in an HTML file. We will \\ndiscuss other ways to specify strings later in this section. All text between an \\nopening <<<_HTML_ and a closing _HTML_; is printed into the HTML file as \\nis. The closing _HTML_; must be alone on a separate line. Thus, the text \\nadded to the HTML file sent to the client will be the text between lines 9  \\nand 13. This includes HTML tags to create the form shown in Figure 11.1(b).\\n  7. PHP variable names start with a $ sign and can include characters, num-\\nbers, and the underscore character _. The PHP auto-global (predefined) \\nvariable $_SERVER (line 9) is an array that includes information about the \\nlocal server. The element $_SERVER[\\'PHP_SELF\\'] in the array is the path \\nname of the PHP file currently being executed on the server. Thus, the action \\nattribute of the form tag (line 9) instructs the PHP interpreter to reprocess \\nthe same file, once the form parameters are entered by the user.\\n  8. Once the user types the name John Smith in the text box and clicks on the \\nSUBMIT NAME  button (Figure 11.1(c)), program segment P1 is repro-\\ncessed. This time, $_POST[\\'user_name\\']  will include the string  \\n\"John Smith\", so lines 3 and 4 will now be placed in the HTML file sent to \\nthe client, which displays the message in Figure 11.1(d).\\nAs we can see from this example, a PHP program can create two different HTML \\ncommands depending on whether the user just started or whether they had already \\nsubmitted their name through the form. In general, a PHP program can create \\nnumerous variations of HTML text in an HTML file at the server depending on the \\nparticular conditional paths taken in the program. Hence, the HTML sent to the \\nclient will be different depending on the interaction with the user. This is one way \\nin which PHP is used to create dynamic Web pages.\\n11.2 Overview of Basic Features of PHP\\nIn this section we give an overview of a few of the features of PHP that are useful in \\ncreating interactive HTML pages. Section 11.3 will focus on how PHP programs \\ncan access databases for querying and updating. We cannot give a comprehensive'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 360, 'page_label': '361'}, page_content='11.2 Overview of Basic Features of PHP  347\\ndiscussion of PHP; there are many books that focus solely on PHP. Rather, we focus \\non illustrating certain features of PHP that are particularly suited for creating \\ndynamic Web pages that contain database access commands. This section covers \\nsome PHP concepts and features that will be needed when we discuss database \\naccess in Section 11.3.\\n11.2.1 PHP Variables, Data Types, and Programming Constructs\\nPHP variable names start with the $ symbol and can include characters, letters, and \\nthe underscore character ( _). No other special characters are permitted. Variable \\nnames are case sensitive, and the first character cannot be a number. Variables are \\nnot typed. The values assigned to the variables determine their type. In fact, the \\nsame variable can change its type once a new value is assigned to it. Assignment is \\nvia the \\n= operator.\\nSince PHP is directed toward text processing, there are several different types of \\nstring values. There are also many functions available for processing strings. We \\nonly discuss some basic properties of string values and variables here. Figure 11.2 \\nillustrates some string values. There are three main ways to express strings and text:\\n  1. Single-quoted strings. Enclose the string between single quotes, as in lines \\n0, 1, and 2. If a single quote is needed within the string, use the escape char-\\nacter (\\n\\\\) (see line 2).\\n  2. Double-quoted strings.  Enclose strings between double quotes as in  \\nline 7. In this case, variable names appearing within the string  are replaced \\nby the values that are currently stored in these variables. The interpreter \\nidentifies variable names within double-quoted strings by their initial \\ncharacter \\n$ and replaces them with the value in the variable. This is known \\nas interpolating variables  within strings. Interpolation does not occur in \\nsingle-quoted strings.\\n  3. Here documents.  Enclose a part of a document between a <<<DOCNAME  \\nand end it with a single line containing the document name DOCNAME.  \\n 0) print \\'Welcome to my Web site.\\';\\n 1) print \\'I said to him, \"Welcome Home\"\\';\\n 2) print \\'We\\\\\\'ll now visit the next Web site\\';\\n 3) printf(\\'The cost is $%.2f and the tax is $%.2f\\',  \\n$cost, $tax) ;\\n 4) print strtolower(\\'AbCdE\\');\\n 5) print ucwords(strtolower(\\'JOHN smith\\'));\\n 6) print \\'abc\\' . \\'efg\\'\\n 7) print \"send your email reply to: $email_address\"\\n 8) print <<<FORM_HTML\\n 9) <FORM method=\"post\" action=\"$_SERVER[\\'PHP_SELF\\']\">\\n10) Enter your name: <input type=\"text\" name=\"user_name\">\\n11) FORM_HTML\\nFigure 11.2 \\nIllustrating basic PHP \\nstring and text values.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 361, 'page_label': '362'}, page_content='348 Chapter 11 Web Database Programming Using PHP\\nDOCNAME can be any string as long as it used both to start and end the here \\ndocument. This is illustrated in lines 8 through 11 in Figure 11.2. Variables \\nare also interpolated by replacing them with their string values if they appear \\ninside here documents. This feature is used in a similar way to double-\\nquoted strings, but it is more convenient for multiple-line text.\\n  4. Single and double quotes. Single and double quotes used by PHP to enclose \\nstrings should be straight quotes ( \"\") on both sides of the string. The text \\neditor that creates these quotes should not produce curly opening and clos-\\ning quotes (“ ”) around the string.\\nThere is also a string concatenate operator specified by the period ( .) symbol, as \\nillustrated in line 6 of Figure 11.2. There are many string functions. We only illus-\\ntrate a couple of them here. The function \\nstrtolower changes the alphabetic char-\\nacters in the string to all lowercase, whereas the function ucwords capitalizes all the \\nwords in a string. These are illustrated in lines 4 and 5 in Figure 11.2.\\nThe general rule is to use single-quoted strings for literal strings that contain no \\nPHP program variables and the other two types (double-quoted strings and here \\ndocuments) when the values from variables need to be interpolated into the string. \\nFor large blocks of multiline text, the program should use the here documents style \\nfor strings.\\nPHP also has numeric data types for integers and floating points and generally fol-\\nlows the rules of the C programming language for processing these types. Numbers \\ncan be formatted for printing into strings by specifying the number of digits that \\nfollow the decimal point. A variation of the print function called printf (print \\nformatted) allows formatting of numbers within a string, as illustrated in line 3 of \\nFigure 11.2.\\nThere are the standard programming language constructs of for-loops, while-loops, \\nand conditional if-statements. They are generally similar to their C language coun-\\nterparts. We will not discuss them here. Similarly, any value evaluates to true if used \\nas a Boolean expression except for numeric zero (\\n0) and blank string, which evalu-\\nate to false. There are also literal true and false values that can be assigned. The \\ncomparison operators also generally follow C language rules. They are \\n== (equal), \\n!= (not equal), > (greater than), >= (greater than or equal), < (less than),  \\nand <= (less than or equal).\\n11.2.2 PHP Arrays\\nArrays are very important in PHP, since they allow lists of elements. They are used \\nfrequently in forms that employ pull-down menus. A single-dimensional array is \\nused to hold the list of choices in the pull-down menu. For database query results, \\ntwo-dimensional arrays are used, with the first dimension representing rows of a \\ntable and the second dimension representing columns (attributes) within a row. \\nThere are two main types of arrays: numeric and associative. We discuss each of \\nthese in the context of single-dimensional arrays next.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 362, 'page_label': '363'}, page_content='11.2 Overview of Basic Features of PHP  349\\nA numeric array associates a numeric index (or position or sequence number) with \\neach element in the array. Indexes are integer numbers that start at zero and grow \\nincrementally. An element in the array is referenced through its index. An  \\nassociative array provides pairs of (key \\n=> value) elements. The value of an element \\nis referenced through its key, and all key values in a particular array must be unique. \\nThe element values can be strings or integers, or they can be arrays themselves, thus \\nleading to higher dimensional arrays.\\nFigure 11.3 gives two examples of array variables: \\n$teaching and $courses. The \\nfirst array $teaching is associative (see line 0 in Figure 11.3), and each element \\nassociates a course name (as key) with the name of the course instructor (as value). \\nThere are three elements in this array. Line 1 shows how the array may be updated. \\nThe first command in line 1 assigns a new instructor to the course ‘Graphics’ by \\nupdating its value. Since the key value ‘Graphics’ already exists in the array, no new \\nelement is created but the existing value is updated. The second command creates a \\nnew element since the key value ‘Data Mining’ did not exist in the array before. \\nNew elements are added at the end of the array.\\nIf we only provide values (no keys) as array elements, the keys are automatically \\nnumeric and numbered 0, 1, 2, … . This is illustrated in line 5 of Figure 11.3, by \\nthe \\n$courses array. Both associative and numeric arrays have no size limits. If \\nsome value of another data type, say an integer, is assigned to a PHP variable that \\nwas holding an array, the variable now holds the integer value and the array con-\\ntents are lost. Basically, most variables can be assigned to values of any data type \\nat any time.\\nThere are several different techniques for looping through arrays in PHP. We illus-\\ntrate two of these techniques in Figure 11.3. Lines 3 and 4 show one method of \\nlooping through all the elements in an array using the \\nforeach construct, and \\nprinting the key and value of each element on a separate line. Lines 7 through 10 \\nshow how a traditional for-loop construct can be used. A built-in function count \\nFigure 11.3 \\nIllustrating basic PHP array processing.\\n 0) $teaching = array(\\'Database\\' => \\'Smith\\', \\'OS\\' => \\'Carrick\\',\\n                      \\'Graphics\\' => \\'Kam\\');\\n 1) $teaching[\\'Graphics\\'] = \\'Benson\\'; $teaching[\\'Data Mining\\'] = \\'Li\\';\\n 2) sort($teaching);\\n 3) foreach ($teaching as $key => $value) {\\n 4)   print \" $key : $value\\\\n\";}\\n 5) $courses = array(\\'Database\\', \\'OS\\', \\'Graphics\\', \\'Data Mining\\');\\n 6) $alt_row_color = array(\\'blue\\', \\'yellow\\');\\n 7) for ($i = 0, $num = count($courses); i < $num; $i++) {\\n 8)   print \\'<TR bgcolor=\"\\' . $alt_row_color[$i % 2] . \\'\">\\';\\n 9)   print \"<TD>Course $i is</TD><TD>$course[$i]</TD></TR>\\\\n\";\\n10) }'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 363, 'page_label': '364'}, page_content='350 Chapter 11 Web Database Programming Using PHP\\n(line 7) returns the current number of elements in the array, which is assigned to \\nthe variable $num and used to control ending the loop.\\nThe example in lines 7 through 10 also illustrates how an HTML table can be  \\ndisplayed with alternating row colors, by setting the two colors in an array  \\n$alt_row_color  (line 8). Each time through the loop, the remainder function  \\n$i % 2 switches from one row (index 0) to the next (index 1) (see line 8). The color \\nis assigned to the HTML bgcolor attribute of the <TR> (table row) tag.\\nThe count function (line 7) returns the current number of elements in the array. \\nThe sort function (line 2) sorts the array based on the element values in it (not the \\nkeys). For associative arrays, each key remains associated with the same element \\nvalue after sorting. This does not occur when sorting numeric arrays. There are \\nmany other functions that can be applied to PHP arrays, but a full discussion is \\noutside the scope of our presentation.\\n11.2.3 PHP Functions\\nAs with other programming languages, functions  can be defined in PHP to bet-\\nter structure a complex program and to share common sections of code that can \\nbe reused by multiple applications. The newer version of PHP, PHP5, also has \\nobject-oriented features, but we will not discuss these here because we are focus-\\ning on the basics of PHP. Basic PHP functions can have arguments that are \\npassed by value . Global variables can be accessed within functions. Standard \\nscope rules apply to variables that appear within a function and within the code \\nthat calls the function.\\nWe now give two simple examples to illustrate basic PHP functions. In Figure 11.4, \\nwe show how we could rewrite the code segment P1 from Figure 11.1(a) using func-\\ntions. The code segment P1′ in Figure 11.4 has two functions: \\ndisplay_welcome() \\n(lines 0 to 3) and display_empty_form() (lines 5 to 13). Neither of these func-\\ntions has arguments; nor do they have return values. Lines 14 through 19 show how \\nwe can call these functions to produce the same effect as the segment of code P1 in \\nFigure 11.1(a). As we can see in this example, functions can be used just to make the \\nPHP code better structured and easier to follow.\\nA second example is shown in Figure 11.5. Here we are using the \\n$teaching array \\nintroduced in Figure 11.3. The function course_instructor() in lines 0 to 8 in \\nFigure 11.5 has two arguments: $course (a string holding a course name) and \\n$teaching_assignments (an associative array holding course assignments, simi-\\nlar to the $teaching array shown in Figure 11.3). The function finds the name of \\nthe instructor who teaches a particular course. Lines 9 to 14 in Figure 11.5 show \\nhow this function may be used.\\nThe function call in line 11 would return the string: Smith is teaching Database , \\nbecause the array entry with the key ‘Database’ has the value ‘Smith’ for instructor. \\nOn the other hand, the function call on line 13 would return the string: there is no \\nComputer Architecture course  because there is no entry in the array with the key'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 364, 'page_label': '365'}, page_content='11.2 Overview of Basic Features of PHP  351\\nFigure 11.4 \\nRewriting program segment P1 as P1′ using functions.\\n    //Program Segment P1′:\\n 0) function display_welcome() {\\n 1)     print(\"Welcome, \") ;\\n 2)     print($_POST[\\'user_name\\']);\\n 3) }\\n 4) \\n 5) function display_empty_form(); {\\n 6) print <<<_HTML_\\n 7) <FORM method=\"post\" action=\"$_SERVER[\\'PHP_SELF\\']\">\\n 8) Enter your name: <INPUT type=\"text\" name=\"user_name\">\\n 9) <BR/>\\n10) <INPUT type=\"submit\" value=\"Submit name\">\\n11) </FORM>\\n12) _HTML_;\\n13) }\\n14) if ($_POST[\\'user_name\\']) {\\n15)   display_welcome();\\n16) }\\n17) else {\\n18)   display_empty_form();\\n19) }\\nFigure 11.5 \\nIllustrating a function with arguments and return value.\\n 0) function course_instructor ($course, $teaching_assignments) {\\n 1)   if (array_key_exists($course, $teaching_assignments)) {\\n 2)   $instructor = $teaching_assignments[$course];\\n 3)   RETURN \"$instructor is teaching $course\";\\n 4)   }\\n 5)   else {\\n 6)   RETURN \"there is no $course course\";\\n 7)   }\\n 8) }\\n 9) $teaching = array(\\'Database\\' => \\'Smith\\', \\'OS\\' => \\'Carrick\\',\\n                      \\'Graphics\\' => \\'Kam\\');\\n10) $teaching[\\'Graphics\\'] = \\'Benson\\'; $teaching[\\'Data Mining\\'] = \\'Li\\';\\n11) $x = course_instructor(\\'Database\\', $teaching);\\n12) print($x);\\n13) $x = course_instructor(\\'Computer Architecture\\', $teaching);\\n14) print($x);'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 365, 'page_label': '366'}, page_content=\"352 Chapter 11 Web Database Programming Using PHP\\n‘Computer Architecture’. A few comments about this example and about PHP \\nfunctions in general:\\n ■ The built-in PHP array function array_key_exists($k, $a) returns true \\nif the value in variable $k exists as a key in the associative array in the vari-\\nable $a. In our example, it checks whether the $course value provided \\nexists as a key in the array $teaching_assignments (line 1 in Figure 11.5).\\n ■ Function arguments are passed by value. Hence, in this example, the calls in \\nlines 11 and 13 could not change the array $teaching provided as argu-\\nment for the call. The values provided in the arguments are passed (copied) \\nto the function arguments when the function is called.\\n ■ Return values of a function are placed after the RETURN keyword. A function \\ncan return any type. In this example, it returns a string type. Two different \\nstrings can be returned in our example, depending on whether the \\n$course \\nkey value provided exists in the array or not.\\n ■ Scope rules for variable names apply as in other programming languages. \\nGlobal variables outside of the function cannot be used unless they are referred \\nto using the built-in PHP array $GLOBALS. Basically, $GLOBALS['abc'] will \\naccess the value in a global variable $abc defined outside the function. Other-\\nwise, variables appearing inside a function are local even if there is a global \\nvariable with the same name.\\nThe previous discussion gives a brief overview of PHP functions. Many details are \\nnot discussed since it is not our goal to present PHP in detail.\\n11.2.4 PHP Server Variables and Forms\\nThere are a number of built-in entries in a PHP auto-global built-in array variable \\ncalled \\n$_SERVER that can provide the programmer with useful information about \\nthe server where the PHP interpreter is running, as well as other information. These \\nmay be needed when constructing the text in an HTML document (for example, see \\nline 7 in Figure 11.4). Here are some of these entries:\\n  1. $_SERVER['SERVER_NAME']. This provides the Web site name or the Uni-\\nform Resource Locator (URL) of the server computer where the PHP inter-\\npreter is running. For example, if the PHP interpreter is running on the  \\nWeb site http://www.uta.edu, then this string would be the value in  \\n$_SERVER['SERVER_NAME'].\\n  2. $_SERVER['REMOTE_ADDRESS']. This is the IP (Internet Protocol) address \\nof the client user computer that is accessing the server; for example, \\n129.107.61.8.\\n  3. $_SERVER['REMOTE_HOST']. This is the Web site name (URL) of the client \\nuser computer; for example, abc.uta.edu. In this case, the server will need to \\ntranslate the name into an IP address to access the client.\\n  4. $_SERVER['PATH_INFO']. This is the part of the URL address that comes \\nafter a backslash (/) at the end of the URL.\"),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 366, 'page_label': '367'}, page_content=\"11.3 Overview of PHP Database Programming  353\\n  5. $_SERVER['QUERY_STRING']. This provides the string that holds parame-\\nters in a URL after a question mark (?) at the end of the URL. This can hold \\nsearch parameters, for example.\\n  6. $_SERVER['DOCUMENT_ROOT'] . This is the root directory that holds the \\nfiles on the Web server that are accessible to client users.\\nThese and other entries in the $_SERVER array are usually needed when creating \\nthe HTML file to be sent to the client for display.\\nAnother important PHP auto-global built-in array variable is called $_POST. This \\nprovides the programmer with input values submitted by the user through HTML \\nforms specified in the HTML \\n<INPUT> tag and other similar tags. For example, in \\nFigure 11.4, line 14, the variable $_POST['user_name'] provides the programmer \\nwith the value typed in by the user in the HTML form specified via the <INPUT> tag \\non line 8 in Figure 11.4. The keys to this array are the names of the various input \\nparameters provided via the form, for example by using the \\nname attribute of the \\nHTML <INPUT> tag as on line 8. When users enter data through forms, the data \\nvalues are stored in this array.\\n11.3 Overview of PHP Database Programming\\nThere are various techniques for accessing a database through a programming lan-\\nguage. We discussed some of the techniques in Chapter 10, in the overviews of how \\nto access an SQL database using the C and Java programming languages. In particu-\\nlar, we discussed embedded SQL, JDBC, SQL/CLI (similar to ODBC), and SQLJ. In \\nthis section we give an overview of how to access the database using the script lan-\\nguage PHP, which is suitable for creating Web interfaces for searching and updat-\\ning databases, as well as dynamic Web pages.\\nThere is a PHP database access function library that is part of PHP Extension and \\nApplication Repository (PEAR), which is a collection of several libraries of func-\\ntions for enhancing PHP. The PEAR DB library provides functions for database \\naccess. Many database systems can be accessed from this library, including Oracle, \\nMySQL, SQLite, and Microsoft SQLServer, among others.\\nWe will discuss several functions that are part of PEAR DB in the context of some \\nexamples. Section 11.3.1 shows how to connect to a database using PHP. Sec- \\ntion 11.3.2 discusses how data collected from HTML forms can be used to insert a \\nnew record in a database table. Section 11.3.3 shows how retrieval queries can be \\nexecuted and have their results displayed within a dynamic Web page.\\n11.3.1 Connecting to a Database\\nTo use the database functions in a PHP program, the PEAR DB library module \\ncalled \\nDB.php must be loaded. In Figure 11.6, this is done in line 0 of the example. \\nThe DB library functions can now be accessed using DB::<function_name> . \\nThe function for connecting to a database is called DB::connect('string'),\"),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 367, 'page_label': '368'}, page_content='354 Chapter 11 Web Database Programming Using PHP\\nwhere the string argument specifies the database information. The format for \\n\\'string\\' is:\\n<DBMS software>://<user account>:<password>@<database server>\\nIn Figure 11.6, line 1 connects to the database that is stored using Oracle (specified \\nvia the string oci8). The <DBMS software> portion of the \\'string\\' specifies the \\nparticular DBMS software package being connected to. Some of the DBMS software \\npackages that are accessible through PEAR DB are:\\n ■ MySQL. Specified as mysql for earlier versions and mysqli for later ver-\\nsions starting with version 4.1.2.\\n ■ Oracle. Specified as oc8i for versions 7, 8, and 9. This is used in line 1 of \\nFigure 11.6.\\n ■ SQLite. Specified as sqlite.\\n ■ Microsoft SQL Server. Specified as mssql.\\n ■ Mini SQL. Specified as msql.\\n ■ Informix. Specified as ifx.\\n ■ Sybase. Specified as sybase.\\n ■ Any ODBC-compliant system. Specified as odbc.\\nThe above is not a comprehensive list.\\n 0) require \\'DB.php\\';\\n 1) $d = DB::connect(\\'oci8://acct1:pass12@www.host.com/db1\\');\\n 2) if (DB::isError($d)) { die(\"cannot connect − \" . $d->getMessage());}\\n    ...\\n 3) $q = $d->query(\"CREATE TABLE EMPLOYEE\\n 4)   (Emp_id INT,\\n 5)   Name VARCHAR(15),\\n 6)   Job VARCHAR(10),\\n 7)   Dno INT);\" );\\n 8) if (DB::isError($q)) { die(\"table creation not successful − \" .\\n                           $q->getMessage()); }\\n      ...\\n 9) $d->setErrorHandling(PEAR_ERROR_DIE);\\n    ...\\n10) $eid = $d->nextID(\\'EMPLOYEE\\');\\n11) $q = $d->query(\"INSERT INTO EMPLOYEE VALUES\\n12)   ($eid, $_POST[\\'emp_name\\'], $_POST[\\'emp_job\\'], $_POST[\\'emp_dno\\'])\" );\\n    ...\\n13) $eid = $d->nextID(\\'EMPLOYEE\\');\\n14) $q = $d->query(\\'INSERT INTO EMPLOYEE VALUES (?, ?, ?, ?)\\',\\n15) array($eid, $_POST[\\'emp_name\\'], $_POST[\\'emp_job\\'], $_POST[\\'emp_dno\\']) );\\nFigure 11.6 \\nConnecting to a database, creating a table, and inserting a record.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 368, 'page_label': '369'}, page_content='11.3 Overview of PHP Database Programming  355\\nFollowing the <DB software> in the string argument passed to DB::connect is \\nthe separator :// followed by the user account name <user account> followed by \\nthe separator : and the account password <password>. These are followed by the \\nseparator @ and the server name and directory <database server>  where the \\ndatabase is stored.\\nIn line 1 of Figure 11.6, the user is connecting to the server at www.host.com/db1 \\nusing the account name acct1 and password pass12 stored under the Oracle \\nDBMS oci8. The whole string is passed using DB::connect . The connection \\ninformation is kept in the database connection variable $d, which is used whenever \\nan operation to this particular database is applied.\\nChecking for errors. Line 2 in Figure 11.6 shows how to check whether the \\nconnection to the database was established successfully or not. PEAR DB has a \\nfunction DB::isError, which can determine whether any database access oper-\\nation was successful or not. The argument to this function is the database con-\\nnection variable (\\n$d in this example). In general, the PHP programmer can \\ncheck after every database call to determine whether the last database operation \\nwas successful or not, and terminate the program (using the die function) if it \\nwas not successful. An error message is also returned from the database via the \\noperation \\n$d->get_message(). This can also be displayed as shown in line 2 of \\nFigure 11.6.\\nSubmitting queries and other SQL statements. In general, most SQL com-\\nmands can be sent to the database once a connection is established by using the \\nquery function. The function $d->query takes an SQL command as its string argu-\\nment and sends it to the database server for execution. In Figure 11.6, lines 3 to 7 \\nsend a \\nCREATE TABLE command to create a table called EMPLOYEE with four attri-\\nbutes. Whenever a query or SQL statement is executed, the result of the query is \\nassigned to a query variable, which is called \\n$q in our example. Line 8 checks \\nwhether the query was executed successfully or not.\\nThe PHP PEAR DB library offers an alternative to having to check for errors after \\nevery database command. The function\\n$d–>setErrorHandling(PEAR_ERROR_DIE)\\nwill terminate the program and print the default error messages if any subsequent \\nerrors occur when accessing the database through connection $d (see line 9 in \\nFigure 11.6).\\n11.3.2  Collecting Data from Forms  \\nand Inserting Records\\nIt is common in database applications to collect information through HTML or \\nother types of Web forms. For example, when purchasing an airline ticket or apply-\\ning for a credit card, the user has to enter personal information such as name, \\naddress, and phone number. This information is typically collected and stored in a \\ndatabase record on a database server.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 369, 'page_label': '370'}, page_content=\"356 Chapter 11 Web Database Programming Using PHP\\nLines 10 through 12 in Figure 11.6 illustrate how this may be done. In this exam-\\nple, we omitted the code for creating the form and collecting the data, which can \\nbe a variation of the example in Figure 11.1. We assume that the user entered valid \\nvalues in the input parameters called \\nemp_name, emp_job, and emp_dno. These \\nwould be accessible via the PHP auto-global array $_POST as discussed at the end \\nof Section 11.2.4.\\nIn the SQL INSERT command shown on lines 11 and 12 in Figure 11.6, the array \\nentries $POST['emp_name'], $POST['emp_job'], and $POST['emp_dno'] will \\nhold the values collected from the user through the input form of HTML. These are \\nthen inserted as a new employee record in the \\nEMPLOYEE table.\\nThis example also illustrates another feature of PEAR DB. It is common in some \\napplications to create a unique record identifier for each new record inserted into \\nthe database.\\n1\\nPHP has a function $d–>nextID to create a sequence of unique values for a partic-\\nular table. In our example, the field Emp_id of the EMPLOYEE table (see Figure 11.6, \\nline 4) is created for this purpose. Line 10 shows how to retrieve the next unique \\nvalue in the sequence for the EMPLOYEE table and insert it as part of the new record \\nin lines 11 and 12.\\nThe code for insert in lines 10 to 12 in Figure 11.6 may allow malicious strings to be \\nentered that can alter the INSERT command. A safer way to do inserts and other \\nqueries is through the use of placeholders (specified by the ? symbol). An example \\nis illustrated in lines 13 to 15, where another record is to be inserted. In this form of \\nthe \\n$d->query() function, there are two arguments. The first argument is the SQL \\nstatement, with one or more ? symbols (placeholders). The second argument is an \\narray, whose element values will be used to replace the placeholders in the order \\nthey are specified (see lines 13 to 15 in Figure 11.6).\\n11.3.3 Retrieval Queries from Database Tables\\nWe now give three examples of retrieval queries through PHP, shown in Fig- \\nure 11.7. The first few lines 0 to 3 establish a database connection \\n$d and set the \\nerror handling to the default, as we discussed in the previous section. The first \\nquery (lines 4 to 7) retrieves the name and department number of all employee \\nrecords. The query variable \\n$q is used to refer to the query result. A while-loop to \\ngo over each row in the result is shown in lines 5 to 7. The function $q->fetchRow() \\nin line 5 serves to retrieve the next record in the query result and to control the \\nloop. The looping starts at the first record.\\nThe second query example is shown in lines 8 to 13 and illustrates a dynamic \\nquery. In this query, the conditions for selection of rows are based on values \\ninput by the user. Here we want to retrieve the names of employees who have a \\n1This would be similar to the system-generated OID discussed in Chapter 12 for object and object-rela-\\ntional database systems.\"),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 370, 'page_label': '371'}, page_content='11.3 Overview of PHP Database Programming  357\\nspecific job and work for a particular department. The particular job and \\ndepartment number are entered through a form in the array variables \\n$POST[\\'emp_job\\']  and $POST[\\'emp_dno\\'] . If the user had entered  \\n‘Engineer’ for the job and 5 for the department number, the query would select \\nthe names of all engineers who worked in department 5. As we can see, this is a \\ndynamic query whose results differ depending on the choices that the user \\nenters as input. We used two \\n? placeholders in this example, as discussed at the \\nend of Section 11.3.2.\\nThe last query (lines 14 to 17) shows an alternative way of specifying a query and \\nlooping over its rows. In this example, the function $d=>getAll  holds all the \\nrecords in a query result in a single variable, called $allresult. To loop over the \\nindividual records, a foreach loop can be used, with the row variable $r iterating \\nover each row in $allresult.2\\nAs we can see, PHP is suited for both database access and creating dynamic \\nWeb pages.\\n 0) require \\'DB.php\\';\\n 1) $d = DB::connect(\\'oci8://acct1:pass12@www.host.com/dbname\\');\\n 2) if (DB::isError($d)) { die(\"cannot connect − \" . $d->getMessage()); }\\n 3) $d->setErrorHandling(PEAR_ERROR_DIE);\\n    ...\\n 4) $q = $d->query(\\'SELECT Name, Dno FROM EMPLOYEE\\');\\n 5) while ($r = $q->fetchRow()) {\\n 6)   print \"employee $r[0] works for department $r[1] \\\\n\" ;\\n 7) }\\n    ...\\n 8) $q = $d->query(\\'SELECT Name FROM EMPLOYEE WHERE Job = ? AND Dno = ?\\',\\n 9)   array($_POST[\\'emp_job\\'], $_POST[\\'emp_dno\\']) );\\n10) print \"employees in dept $_POST[\\'emp_dno\\'] whose job is\\n      $_POST[\\'emp_job\\']: \\\\n\"\\n11) while ($r = $q->fetchRow()) {\\n12)   print \"employee $r[0] \\\\n\" ;\\n13) }\\n    ...\\n14) $allresult = $d->getAll(\\'SELECT Name, Job, Dno FROM EMPLOYEE\\');\\n15) foreach ($allresult as $r) {\\n16)   print \"employee $r[0] has job $r[1] and works for department $r[2] \\\\n\" ;\\n17) }\\n    ...\\nFigure 11.7 \\nIllustrating database retrieval queries.\\n2The $r variable is similar to the cursors and iterator variables discussed in Chapters 10 and 12.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 371, 'page_label': '372'}, page_content='358 Chapter 11 Web Database Programming Using PHP\\n11.4  Brief Overview of Java Technologies  \\nfor Database Web Programming\\nThe parts of the PHP scripting language that we discussed run on the application \\nserver and serve as a conduit that collects client user input through forms, formu-\\nlates database queries and submits them to the database server, and then creates \\ndynamic HTML Web pages to display query results. The Java environment has \\ncomponents that run on the server and other components that can run on the client \\nmachine. It also has standards for exchanging data objects. We briefly discuss some \\nof these components here that are related to Web and database access. We already \\ndiscussed JDBC and SQLJ in some detail in Chapter 10.\\nJava Servlets.  Servlets are Java objects that can reside on the Web server \\nmachine and manage interactions with the client. They can store information \\nthat was submitted by the client during a session, so that this information can \\nbe used to generate database queries. Servlet objects can also store query results \\nso that parts of these results can be formatted as HTML and sent to the client \\nfor display. The servlet object can maintain all the information produced dur-\\ning a particular client interaction until the client session is terminated.\\nJava Server Pages (JSP). This allows scripting at the server to produce dynamic Web \\npages to be sent at the client in a manner somewhat similar to PHP. However, it is \\nassociated with the Java language and the scripting can be combined with Java code.\\nJavaScript. JavaScript is a scripting language that is different from the Java \\nprogramming language and was developed separately. It is widely used in Web \\napplications, and it can run on the client computer or on the server.\\nJava Script Object Notation (JSON).  This is a text-based representation of \\ndata objects, so that data can be formatted in JSON and exchanged between \\nclients and servers over the Web in text format. It can be considered as an alter-\\nnative to XML (see Chapter 13) and represents objects using attribute-value \\npairs. JSON has also been adopted as the data model by some newer database \\nsystems known as NOSQL systems, such as MongoDB (see Chapter 24).\\n11.5 Summary\\nIn this chapter, we gave an overview of how to convert some structured data from \\ndatabases into elements to be entered or displayed on a Web page. We focused on \\nthe PHP scripting language, which is becoming very popular for Web database pro-\\ngramming. Section 11.1 presented some PHP basics for Web programming through \\na simple example. Section 11.2 gave some of the basics of the PHP language, includ-\\ning its array and string data types that are used extensively. Section 11.3 presented \\nan overview of how PHP can be used to specify various types of database com-\\nmands, including creating tables, inserting new records, and retrieving database \\nrecords. PHP runs at the server computer in comparison to some other scripting \\nlanguages that run on the client computer. Section 11.4 introduced some of the \\ntechnologies associated with Java that can be used in similar contexts.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 372, 'page_label': '373'}, page_content='Selected Bibliography 359\\nWe gave only a very basic introduction to PHP. There are many books as well as \\nmany Web sites devoted to introductory and advanced PHP programming. Many \\nlibraries of functions also exist for PHP, as it is an open source product.\\nReview Questions\\n 11.1. Why are scripting languages popular for programming Web applications? \\nWhere in the three-tier architecture does a PHP program execute? Where \\ndoes a JavaScript program execute?\\n 11.2. What type of programming language is PHP?\\n 11.3. Discuss the different ways of specifying strings in PHP.\\n 11.4. Discuss the different types of arrays in PHP.\\n 11.5. What are PHP auto-global variables? Give some examples of PHP auto-\\nglobal arrays, and discuss how each is typically used.\\n 11.6. What is PEAR? What is PEAR DB?\\n 11.7. Discuss the main functions for accessing a database in PEAR DB, and how \\neach is used.\\n 11.8. Discuss the different ways for looping over a query result in PHP.\\n 11.9. What are placeholders? How are they used in PHP database programming?\\nExercises\\n 11.10. Consider the LIBRARY database schema shown in Figure 4.6. Write PHP \\ncode to create the tables of this schema.\\n 11.11. Write a PHP program that creates Web forms for entering the information \\nabout a new BORROWER entity. Repeat for a new BOOK entity.\\n 11.12. Write PHP Web interfaces for the queries specified in Exercise 6.18.\\nSelected Bibliography\\nThere are many sources for PHP programming, both in print and on the Web. We \\ngive two books as examples. A very good introduction to PHP is given in Sklar \\n(2005). For advanced Web site development, the book by Schlossnagle (2005) pro-\\nvides many detailed examples. Nixon (2014) has a popular book on web program-\\nming that covers PHP, Javascript, Jquery, CSS and HTML5.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 373, 'page_label': '374'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 374, 'page_label': '375'}, page_content='Object, Object-Relational, and \\nXML: Concepts, Models, \\nLanguages, and Standards  \\npart 5'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 375, 'page_label': '376'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 376, 'page_label': '377'}, page_content='363\\n12\\nObject and Object-Relational \\nDatabases\\nI\\nn this chapter, we discuss the features of object- \\noriented data models and show how some of these \\nfeatures have been incorporated in relational database systems and the SQL standard. \\nSome features of object data models have also been incorporated into the data mod-\\nels of newer types of database systems, known as NOSQL systems (see Chapter 24). \\nIn addition, the XML model (see Chapter 13) has similarities to the object model. \\nSo an introduction to the object model will give a good perspective on many of the \\nrecent advances in database technology. Database systems that were based on the \\nobject data model were known originally as object-oriented databases (OODBs) but \\nare now referred to as object databases (ODBs).Traditional data models and sys-\\ntems, such as network, hierarchical, and relational have been quite successful in \\ndeveloping the database technologies required for many traditional business data-\\nbase applications. However, they have certain shortcomings when more complex \\ndatabase applications must be designed and implemented—for example, databases \\nfor engineering design and manufacturing (CAD/CAM and CIM\\n1), biological and \\nother sciences, telecommunications, geographic information systems, and multi-\\nmedia.\\n2 These ODBs were developed for applications that have requirements \\nrequiring more complex structures for stored objects. A key feature of object data-\\nbases is the power they give the designer to specify both the structure of complex \\nobjects and the operations that can be applied to these objects.\\nchapter 12\\n1Computer-aided design/computer-aided manufacturing and computer-integrated manufacturing.\\n2Multimedia databases must store various types of multimedia objects, such as video, audio, images, \\ngraphics, and documents (see Chapter 26).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 377, 'page_label': '378'}, page_content='364 Chapter 12 Object and Object-Relational Databases\\nAnother reason for the creation of object-oriented databases is the vast increase in \\nthe use of object-oriented programming languages for developing software applica-\\ntions. Databases are fundamental components in many software systems, and tradi-\\ntional databases are sometimes difficult to use with software applications that are \\ndeveloped in an object-oriented programming language such as C++ or Java. Object \\ndatabases are designed so they can be directly—or seamlessly—integrated with soft-\\nware that is developed using object-oriented programming languages.\\nRelational DBMS (RDBMS) vendors have also recognized the need for incorporat-\\ning features that were proposed for object databases, and newer versions of rela-\\ntional systems have incorporated many of these features. This has led to database \\nsystems that are characterized as object-relational or ORDBMSs. A recent version \\nof the SQL standard (2008) for RDBMSs, known as SQL/Foundation, includes \\nmany of these features, which were originally known as SQL/Object and have now \\nbeen merged into the main SQL specification.\\nAlthough many experimental prototypes and commercial object-oriented database \\nsystems have been created, they have not found widespread use because of the pop-\\nularity of relational and object-relational systems. The experimental prototypes \\nincluded the Orion system developed at MCC, OpenOODB at Texas Instruments, \\nthe Iris system at Hewlett-Packard laboratories, the Ode system at AT&T Bell Labs, \\nand the ENCORE/ObServer project at Brown University. Commercially available \\nsystems included GemStone Object Server of GemStone Systems, ONTOS DB  \\nof Ontos, Objectivity/DB of Objectivity Inc., Versant Object Database and  \\nFastObjects by Versant Corporation (and Poet), ObjectStore of Object Design, and \\nArdent Database of Ardent.\\nAs commercial object DBMSs became available, the need for a standard model and \\nlanguage was recognized. Because the formal procedure for approval of standards \\nnormally takes a number of years, a consortium of object DBMS vendors and users, \\ncalled ODMG, proposed a standard whose current specification is known as the \\nODMG 3.0 standard.\\nObject-oriented databases have adopted many of the concepts that were developed \\noriginally for object-oriented programming languages.\\n3 In Section 12.1, we describe \\nthe key concepts utilized in many object database systems and that were later incor-\\nporated into object-relational systems and the SQL standard. These include object \\nidentity, object structure and type constructors, encapsulation of operations, and the \\ndefinition of methods as part of class declarations, mechanisms for storing objects \\nin a database by making them persistent, and type and class hierarchies and inheri-\\ntance. Then, in Section 12.2 we see how these concepts have been incorporated into \\nthe latest SQL standards, leading to object-relational databases. Object features \\nwere originally introduced in SQL:1999, and then updated in SQL:2008. In Sec- \\ntion 12.3, we turn our attention to “pure” object database standards by presenting \\nfeatures of the object database standard ODMG 3.0 and the object definition  \\n3Similar concepts were also developed in the fields of semantic data modeling and knowledge  \\nrepresentation.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 378, 'page_label': '379'}, page_content='12.1 Overview of Object Database Concepts  365\\nlanguage ODL. Section 12.4 presents an overview of the database design process for \\nobject databases. Section 12.5 discusses the object query language (OQL), which is \\npart of the ODMG 3.0 standard. In Section 12.6, we discuss programming language \\nbindings, which specify how to extend object-oriented programming languages to \\ninclude the features of the object database standard. Section 12.7 summarizes the \\nchapter. Sections 12.3 through 12.6 may be left out if a less thorough introduction \\nto object databases is desired.\\n12.1 Overview of Object Database Concepts\\n12.1.1 Introduction to Object-Oriented Concepts and Features\\nThe term object-oriented —abbreviated OO or O-O—has its origins in OO pro-\\ngramming languages, or OOPLs. Today OO concepts are applied in the areas of \\ndatabases, software engineering, knowledge bases, artificial intelligence, and \\ncomputer systems in general. OOPLs have their roots in the SIMULA language, \\nwhich was proposed in the late 1960s. The programming language Smalltalk, \\ndeveloped at Xerox PARC\\n4 in the 1970s, was one of the first languages to explic-\\nitly incorporate additional OO concepts, such as message passing and inheri-\\ntance. It is known as a pure OO programming language, meaning that it was \\nexplicitly designed to be object-oriented. This contrasts with hybrid  OO pro-\\ngramming languages, which incorporate OO concepts into an already existing \\nlanguage. An example of the latter is C++, which incorporates OO concepts into \\nthe popular C programming language.\\nAn object typically has two components: state (value) and behavior (operations). It \\ncan have a complex data structure as well as specific operations defined by the pro-\\ngrammer.\\n5 Objects in an OOPL exist only during program execution; therefore, \\nthey are called transient objects. An OO database can extend the existence of objects \\nso that they are stored permanently in a database, and hence the objects become \\npersistent objects that exist beyond program termination and can be retrieved later \\nand shared by other programs. In other words, OO databases store persistent \\nobjects permanently in secondary storage and allow the sharing of these objects \\namong multiple programs and applications. This requires the incorporation of \\nother well-known features of database management systems, such as indexing \\nmechanisms to efficiently locate the objects, concurrency control to allow object \\nsharing among concurrent programs, and recovery from failures. An OO database \\nsystem will typically interface with one or more OO programming languages to \\nprovide persistent and shared object capabilities.\\nThe internal structure of an object in OOPLs includes the specification of instance \\nvariables, which hold the values that define the internal state of the object. An \\ninstance variable is similar to the concept of an attribute in the relational model , \\n4Palo Alto Research Center, Palo Alto, California.\\n5Objects have many other characteristics, as we discuss in the rest of this chapter.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 379, 'page_label': '380'}, page_content='366 Chapter 12 Object and Object-Relational Databases\\nexcept that instance variables may be encapsulated within the object and thus are \\nnot necessarily visible to external users. Instance variables may also be of arbitrarily \\ncomplex data types. Object-oriented systems allow definition of the operations or \\nfunctions (behavior) that can be applied to objects of a particular type. In fact, some \\nOO models insist that all operations a user can apply to an object must be pre-\\ndefined. This forces a complete encapsulation  of objects. This rigid approach has \\nbeen relaxed in most OO data models for two reasons. First, database users often \\nneed to know the attribute names so they can specify selection conditions on the \\nattributes to retrieve specific objects. Second, complete encapsulation implies that \\nany simple retrieval requires a predefined operation, thus making ad hoc queries \\ndifficult to specify on the fly.\\nTo encourage encapsulation, an operation is defined in two parts. The first part, \\ncalled the signature or interface of the operation, specifies the operation name and \\narguments (or parameters). The second part, called the method or body, specifies \\nthe implementation of the operation, usually written in some general-purpose pro-\\ngramming language. Operations can be invoked by passing a message to an object, \\nwhich includes the operation name and the parameters. The object then executes \\nthe method for that operation. This encapsulation permits modification of the \\ninternal structure of an object, as well as the implementation of its operations, with-\\nout the need to disturb the external programs that invoke these operations. Hence, \\nencapsulation provides a form of data and operation independence (see Chapter 2).\\nAnother key concept in OO systems is that of type and class hierarchies and inheri-\\ntance. This permits specification of new types or classes that inherit much of their \\nstructure and/or operations from previously defined types or classes. This makes it \\neasier to develop the data types of a system incrementally and to reuse existing type \\ndefinitions when creating new types of objects.\\nOne problem in early OO database systems involved representing relationships  \\namong objects. The insistence on complete encapsulation in early OO data models \\nled to the argument that relationships should not be explicitly represented, but \\nshould instead be described by defining appropriate methods that locate related \\nobjects. However, this approach does not work very well for complex databases \\nwith many relationships because it is useful to identify these relationships and make \\nthem visible to users. The ODMG object database standard has recognized this \\nneed and it explicitly represents binary relationships via a pair of inverse references, \\nas we will describe in Section 12.3.\\nAnother OO concept is operator overloading, which refers to an operation’s ability \\nto be applied to different types of objects; in such a situation, an operation name \\nmay refer to several distinct implementations, depending on the type of object it is \\napplied to. This feature is also called operator polymorphism. For example, an oper-\\nation to calculate the area of a geometric object may differ in its method (imple-\\nmentation), depending on whether the object is of type triangle, circle, or rectangle. \\nThis may require the use of late binding of the operation name to the appropriate \\nmethod at runtime, when the type of object to which the operation is applied \\nbecomes known.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 380, 'page_label': '381'}, page_content='12.1 Overview of Object Database Concepts  367\\nIn the next several sections, we discuss in some detail the main characteristics of \\nobject databases. Section 12.1.2 discusses object identity; Section 12.1.3 shows \\nhow the types for complex-structured objects are specified via type constructors; \\nSection 12.1.4 discusses encapsulation and persistence; and Section 12.1.5 pres-\\nents inheritance concepts. Section 12.1.6 discusses some additional OO con-\\ncepts, and Section 12.1.7 gives a summary of all the OO concepts that we \\nintroduced. In Section 12.2, we show how some of these concepts have been \\nincorporated into the SQL:2008 standard for relational databases. Then in Sec-\\ntion 12.3, we show how these concepts are realized in the ODMG 3.0 object data-\\nbase standard.\\n12.1.2 Object Identity, and Objects versus Literals\\nOne goal of an ODB is to maintain a direct correspondence between real-world \\nand database objects so that objects do not lose their integrity and identity and \\ncan easily be identified and operated upon. Hence, a unique identity  is assigned \\nto each independent object stored in the database. This unique identity is typi-\\ncally implemented via a unique, system-generated object identifier (OID) . The \\nvalue of an OID may not be visible to the external user but is used internally by \\nthe system to identify each object uniquely and to create and manage interobject \\nreferences. The OID can be assigned to program variables of the appropriate type \\nwhen needed.\\nThe main property required of an OID is that it be immutable; that is, the OID \\nvalue of a particular object should not change. This preserves the identity of the \\nreal-world object being represented. Hence, an ODMS must have some mechanism \\nfor generating OIDs and preserving the immutability property. It is also desirable \\nthat each OID be used only once; that is, even if an object is removed from the data-\\nbase, its OID should not be assigned to another object. These two properties imply \\nthat the OID should not depend on any attribute values of the object, since the \\nvalue of an attribute may be changed or corrected. We can compare this with the \\nrelational model, where each relation must have a primary key attribute whose \\nvalue identifies each tuple uniquely. If the value of the primary key is changed, the \\ntuple will have a new identity, even though it may still represent the same real-\\nworld object. Alternatively, a real-world object may have different names for key \\nattributes in different relations, making it difficult to ascertain that the keys repre-\\nsent the same real-world object (for example, using the \\nEmp_id of an EMPLOYEE in \\none relation and the Ssn in another).\\nIt is also inappropriate to base the OID on the physical address of the object in stor-\\nage, since the physical address can change after a physical reorganization of the \\ndatabase. However, some early ODMSs have used the physical address as the OID \\nto increase the efficiency of object retrieval. If the physical address of the object \\nchanges, an indirect pointer  can be placed at the former address, which gives the \\nnew physical location of the object. It is more common to use long integers as OIDs \\nand then to use some form of hash table to map the OID value to the current physi-\\ncal address of the object in storage.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 381, 'page_label': '382'}, page_content='368 Chapter 12 Object and Object-Relational Databases\\nSome early OO data models required that everything—from a simple value to a \\ncomplex object—was represented as an object; hence, every basic value, such as an \\ninteger, string, or Boolean value, has an OID. This allows two identical basic values \\nto have different OIDs, which can be useful in some cases. For example, the integer \\nvalue 50 can sometimes be used to mean a weight in kilograms and at other times to \\nmean the age of a person. Then, two basic objects with distinct OIDs could be cre-\\nated, but both objects would have the integer 50 as their value. Although useful as a \\ntheoretical model, this is not very practical, since it leads to the generation of too \\nmany OIDs. Hence, most ODBs allow for the representation of both objects and \\nliterals (or values). Every object must have an immutable OID, whereas a literal \\nvalue has no OID and its value just stands for itself. Thus, a literal value is typically \\nstored within an object and cannot be referenced from other objects. In many sys-\\ntems, complex structured literal values can also be created without having a corre-\\nsponding OID if needed.\\n12.1.3 Complex Type Structures for Objects and Literals\\nAnother feature of ODBs is that objects and literals may have a type structure  of \\narbitrary complexity  in order to contain all of the necessary information that \\ndescribes the object or literal. In contrast, in traditional database systems, informa-\\ntion about a complex object is often scattered over many relations or records, lead-\\ning to loss of direct correspondence between a real-world object and its database \\nrepresentation. In ODBs, a complex type may be constructed from other types by \\nnesting of type constructors. The three most basic constructors are atom, struct (or \\ntuple), and collection.\\n  1. One type constructor has been called the atom constructor, although this \\nterm is not used in the latest object standard. This includes the basic built-in \\ndata types of the object model, which are similar to the basic types in many \\nprogramming languages: integers, strings, floating-point numbers, enumer-\\nated types, Booleans, and so on. These basic data types are called single-\\nvalued or atomic types, since each value of the type is considered an atomic \\n(indivisible) single value.\\n  2. A second type constructor is referred to as the struct (or tuple) constructor. \\nThis can create standard structured types, such as the tuples (record types) \\nin the basic relational model. A structured type is made up of several com-\\nponents and is also sometimes referred to as a compound or composite type. \\nMore accurately, the struct constructor is not considered to be a type, but \\nrather a type generator, because many different structured types can be cre-\\nated. For example, two different structured types that can be created are: \\nstruct Name<FirstName: string, MiddleInitial: char, LastName: string>, and \\nstruct CollegeDegree<Major: string, Degree: string, Year: date>. To create \\ncomplex nested type structures in the object model, the collection type con-\\nstructors are needed, which we discuss next. Notice that the type construc-\\ntors atom and struct are the only ones available in the original (basic) \\nrelational model.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 382, 'page_label': '383'}, page_content='12.1 Overview of Object Database Concepts  369\\n  3. Collection (or multivalued) type constructors include the set(T), list(T), \\nbag(T), array(T), and dictionary(K,T) type constructors. These allow part \\nof an object or literal value to include a collection of other objects or values \\nwhen needed. These constructors are also considered to be type generators \\nbecause many different types can be created. For example, set( string), \\nset(integer), and set(Employee) are three different types that can be created \\nfrom the set type constructor. All the elements in a particular collection \\nvalue must be of the same type. For example, all values in a collection of type \\nset(string) must be string values.\\nThe atom constructor is used to represent all basic atomic values, such as integers, \\nreal numbers, character strings, Booleans, and any other basic data types that the \\nsystem supports directly. The tuple constructor  can create structured values and \\nobjects of the form <a\\n1:i1, a2:i2, … , an:in>, where each aj is an attribute name6 and \\neach ij is a value or an OID.\\nThe other commonly used constructors are collectively referred to as collection \\ntypes but have individual differences among them. The set constructor will create \\nobjects or literals that are a set of distinct elements { i1, i2, … , in}, all of the same \\ntype. The bag constructor (also called a multiset) is similar to a set except that the \\nelements in a bag need not be distinct. The list constructor will create an ordered list \\n[i1, i2, … , in] of OIDs or values of the same type. A list is similar to a bag except that \\nthe elements in a list are ordered, and hence we can refer to the first, second, or jth \\nelement. The array constructor creates a single-dimensional array of elements of \\nthe same type. The main difference between array and list is that a list can have an \\narbitrary number of elements whereas an array typically has a maximum size. \\nFinally, the dictionary constructor  creates a collection of key-value pairs ( K, V), \\nwhere the value of a key K can be used to retrieve the corresponding value V.\\nThe main characteristic of a collection type is that its objects or values will be a col-\\nlection of objects or values of the same type that may be unordered (such as a set or a \\nbag) or ordered (such as a list or an array). The tuple type constructor is often \\ncalled a structured type, since it corresponds to the struct construct in the C and \\nC++ programming languages.\\nAn object definition language  (ODL)\\n7 that incorporates the preceding type con-\\nstructors can be used to define the object types for a particular database application. \\nIn Section 12.3 we will describe the standard ODL of ODMG, but first we introduce \\nthe concepts gradually in this section using a simpler notation. The type construc-\\ntors can be used to define the data structures  for an OO database schema.  Fig- \\nure 12.1 shows how we may declare \\nEMPLOYEE and DEPARTMENT types.\\nIn Figure 12.1, the attributes that refer to other objects—such as Dept of EMPLOYEE \\nor Projects of DEPARTMENT—are basically OIDs that serve as references to other \\nobjects to represent relationships among the objects. For example, the attribute Dept \\n6Also called an instance variable name in OO terminology.\\n7This corresponds to the DDL (data definition language) of the database system (see Chapter 2).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 383, 'page_label': '384'}, page_content='370 Chapter 12 Object and Object-Relational Databases\\nof EMPLOYEE  is of type DEPARTMENT  and hence is used to refer to a specific \\nDEPARTMENT object (the DEPARTMENT object where the employee works). The \\nvalue of such an attribute would be an OID for a specific DEPARTMENT object. A \\nbinary relationship can be represented in one direction, or it can have an inverse \\nreference. The latter representation makes it easy to traverse the relationship in both \\ndirections. For example, in Figure 12.1 the attribute Employees of DEPARTMENT has \\nas its value a set of references (that is, a set of OIDs) to objects of type EMPLOYEE; \\nthese are the employees who work for the DEPARTMENT. The inverse is the refer-\\nence attribute Dept of EMPLOYEE. We will see in Section 12.3 how the ODMG stan-\\ndard allows inverses to be explicitly declared as relationship attributes to ensure \\nthat inverse references are consistent.\\n12.1.4  Encapsulation of Operations  \\nand Persistence of Objects\\nEncapsulation of Operations. The concept of encapsulation is one of the main \\ncharacteristics of OO languages and systems. It is also related to the concepts of \\nabstract data types  and information hiding  in programming languages. In tradi-\\ntional database models and systems this concept was not applied, since it is cus-\\ntomary to make the structure of database objects visible to users and external \\nprograms. In these traditional models, a number of generic database operations \\ndefine type EMPLOYEE\\n tuple  ( Fname: string;\\n  Minit : char;\\n  Lname: string;\\n  Ssn: string;\\n  Birth_date: DATE;\\n  Address: string;\\n  Sex: char;\\n  Salary: float;\\n  Supervisor: EMPLOYEE;\\n  Dept: DEPARTMENT;\\ndefine type DATE\\n tuple ( Year: integer;\\n  Month: integer;\\n  Day: integer; );\\ndefine type DEPARTMENT\\n tuple ( Dname: string;\\n  Dnumber: integer;\\n  Mgr: tuple ( Manager: EMPLOYEE;\\n    Start_date: DATE; );\\n  Locations: set(string);\\n  Employees: set(EMPLOYEE);\\n  Projects: set(PROJECT); );\\nFigure 12.1 \\nSpecifying the object \\ntypes EMPLOYEE, \\nDATE, and  \\nDEPARTMENT using \\ntype constructors.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 384, 'page_label': '385'}, page_content='12.1 Overview of Object Database Concepts  371\\nare applicable to objects of all types. For example, in the relational model, the oper-\\nations for selecting, inserting, deleting, and modifying tuples are generic and may \\nbe applied to any relation in the database. The relation and its attributes are visible \\nto users and to external programs that access the relation by using these opera-\\ntions. The concept of encapsulation is applied to database objects in ODBs by \\ndefining the behavior of a type of object based on the operations that can be exter-\\nnally applied to objects of that type. Some operations may be used to create (insert) \\nor destroy (delete) objects; other operations may update the object state; and oth-\\ners may be used to retrieve parts of the object state or to apply some calculations. \\nStill other operations may perform a combination of retrieval, calculation, and \\nupdate. In general, the implementation  of an operation can be specified in a \\n general-purpose programming language  that provides flexibility and power in \\ndefining the operations.\\nThe external users of the object are only made aware of the interface of the oper-\\nations, which defines the name and arguments (parameters) of each operation. \\nThe implementation is hidden from the external users; it includes the definition \\nof any hidden internal data structures of the object and the implementation of the \\noperations that access these structures. The interface part of an operation is \\nsometimes called the signature, and the operation implementation is sometimes \\ncalled the method.\\nFor database applications, the requirement that all objects be completely encapsu-\\nlated is too stringent. One way to relax this requirement is to divide the structure of \\nan object into visible and hidden attributes (instance variables). Visible attributes \\ncan be seen by and are directly accessible to the database users and programmers \\nvia the query language. The hidden attributes of an object are completely encapsu-\\nlated and can be accessed only through predefined operations. Most ODMSs \\nemploy high-level query languages for accessing visible attributes. In Section 12.5 \\nwe will describe the OQL query language that is proposed as a standard query lan-\\nguage for ODBs.\\nThe term class is often used to refer to a type definition, along with the definitions \\nof the operations for that type.\\n8 Figure 12.2 shows how the type definitions in Fig-\\nure 12.1 can be extended with operations to define classes. A number of operations \\nare declared for each class, and the signature (interface) of each operation is \\nincluded in the class definition. A method (implementation) for each operation \\nmust be defined elsewhere using a programming language. Typical operations \\ninclude the object constructor operation (often called new), which is used to create \\na new object, and the destructor operation, which is used to destroy (delete) an \\nobject. A number of object modifier operations can also be declared to modify the \\nstates (values) of various attributes of an object. Additional operations can retrieve \\ninformation about the object.\\n8This definition of class is similar to how it is used in the popular C++ programming language. The \\nODMG standard uses the word interface in addition to class (see Section 12.3). In the EER model, the \\nterm class was used to refer to an object type, along with the set of all objects of that type (see  \\nChapter 8).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 385, 'page_label': '386'}, page_content='372 Chapter 12 Object and Object-Relational Databases\\nAn operation is typically applied to an object by using the dot notation. For exam-\\nple, if d is a reference to a DEPARTMENT object, we can invoke an operation such as \\nno_of_emps by writing d.no_of_emps. Similarly, by writing d.destroy_dept, the object \\nreferenced by d is destroyed (deleted). The only exception is the constructor opera-\\ntion, which returns a reference to a new DEPARTMENT object. Hence, it is custom-\\nary in some OO models to have a default name for the constructor operation that is \\nthe name of the class itself, although this was not used in Figure 12.2.\\n9 The dot notation \\nis also used to refer to attributes of an object—for example, by writing d.Dnumber or \\nd.Mgr_Start_date.\\ndefine class EMPLOYEE\\n type tuple ( Fname: string;\\n   Minit: char;\\n   Lname: string;\\n   Ssn: string;\\n   Birth_date: DATE;\\n   Address: string;\\n   Sex: char;\\n   Salary: float;\\n   Supervisor: EMPLOYEE;\\n   Dept: DEPARTMENT; );\\n operations age: integer;\\n   create_emp: EMPLOYEE;\\n   destroy_emp: boolean;\\nend EMPLOYEE;\\ndefine class DEPARTMENT \\n type tuple ( Dname: string;\\n   Dnumber: integer;\\n   Mgr: tuple ( Manager: EMPLOYEE;\\n               Start_date: DATE; );\\n   Locations: set (string);\\n   Employees: set (EMPLOYEE);\\n   Projects set(PROJECT); );\\n operations no_of_emps: integer;\\n   create_dept: DEPARTMENT;\\n   destroy_dept: boolean;\\n   assign_emp(e: EMPLOYEE): boolean;\\n   (* adds an employee to the department *)\\n   remove_emp(e: EMPLOYEE): boolean;\\n   (* removes an employee from the department *)\\nend DEPARTMENT;\\nFigure 12.2 \\nAdding operations to \\nthe definitions of \\nEMPLOYEE and \\nDEPARTMENT.\\n9Default names for the constructor and destructor operations exist in the C++ programming language. \\nFor example, for class EMPLOYEE, the default constructor name is EMPLOYEE and the default  \\ndestructor name is ~EMPLOYEE. It is also common to use the new operation to create new objects.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 386, 'page_label': '387'}, page_content='12.1 Overview of Object Database Concepts  373\\nSpecifying Object Persistence via Naming and Reachability. An ODBS is \\noften closely coupled with an object-oriented programming language (OOPL). The \\nOOPL is used to specify the method (operation) implementations as well as other \\napplication code. Not all objects are meant to be stored permanently in the data-\\nbase. Transient objects exist in the executing program and disappear once the pro-\\ngram terminates. Persistent objects  are stored in the database and persist after \\nprogram termination. The typical mechanisms for making an object persistent are \\nnaming and reachability.\\nThe naming mechanism involves giving an object a unique persistent name within \\na particular database. This persistent object name can be given via a specific state-\\nment or operation in the program, as shown in Figure 12.3. The named persistent \\nobjects are used as entry points to the database through which users and applica-\\ntions can start their database access. Obviously, it is not practical to give names to \\nall objects in a large database that includes thousands of objects, so most objects are \\nmade persistent by using the second mechanism, called reachability. The reach-\\nability mechanism works by making the object reachable from some other persis-\\ntent object. An object B is said to be reachable from an object A if a sequence of \\nreferences in the database lead from object A to object B.\\nIf we first create a named persistent object N, whose state is a set of objects of some \\nclass C, we can make objects of C persistent by adding them to the set, thus making \\nthem reachable from N. Hence, N is a named object that defines a persistent  \\ncollection of objects of class C. In the object model standard, N is called the extent \\nof C (see Section 12.3).\\nFor example, we can define a class \\nDEPARTMENT_SET  (see Figure 12.3) whose \\nobjects are of type set (DEPARTMENT ).10 We can create an object of type  \\nDEPARTMENT_SET, and give it a persistent name ALL_DEPARTMENTS, as shown in \\nFigure 12.3. Any DEPARTMENT object that is added to the set of ALL_DEPARTMENTS \\nby using the add_dept  operation becomes persistent by virtue of its being reach-\\nable from ALL_DEPARTMENTS . As we will see in Section 12.3, the ODMG ODL \\nstandard gives the schema designer the option of naming an extent as part of \\nclass definition.\\nNotice the difference between traditional database models and ODBs in this respect. \\nIn traditional database models, such as the relational model, all objects are assumed \\nto be persistent. Hence, when a table such as \\nEMPLOYEE is created in a relational \\ndatabase, it represents both the type declaration for EMPLOYEE and a persistent set \\nof all EMPLOYEE  records (tuples). In the OO approach, a class declaration of \\nEMPLOYEE specifies only the type and operations for a class of objects. The user \\nmust separately define a persistent object of type set(EMPLOYEE) whose value is the \\ncollection of references (OIDs) to all persistent EMPLOYEE objects, if this is desired, \\nas shown in Figure 12.3.11 This allows transient and persistent objects to follow the \\n10As we will see in Section 12.3, the ODMG ODL syntax uses set<DEPARTMENT> instead of \\nset(DEPARTMENT).\\n11Some systems, such as POET, automatically create the extent for a class.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 387, 'page_label': '388'}, page_content='374 Chapter 12 Object and Object-Relational Databases\\nsame type and class declarations of the ODL and the OOPL. In general, it is possible \\nto define several persistent collections for the same class definition, if desired.\\n12.1.5 Type Hierarchies and Inheritance\\nSimplified Model for Inheritance. Another main characteristic of ODBs is that \\nthey allow type hierarchies and inheritance. We use a simple OO model in this \\nsection—a model in which attributes and operations are treated uniformly—since \\nboth attributes and operations can be inherited. In Section 12.3, we will discuss the \\ninheritance model of the ODMG standard, which differs from the model discussed \\nhere because it distinguishes between two types of inheritance . Inheritance allows \\nthe definition of new types based on other predefined types, leading to a type (or \\nclass) hierarchy.\\nA type is defined by assigning it a type name and then defining a number of attri-\\nbutes (instance variables) and operations (methods) for the type.\\n12 In the simplified \\nmodel we use in this section, the attributes and operations are together called func-\\ntions, since attributes resemble functions with zero arguments. A function name \\ncan be used to refer to the value of an attribute or to refer to the resulting value of an \\noperation (method). We use the term function to refer to both attributes and oper-\\nations, since they are treated similarly in a basic introduction to inheritance.13\\ndefine class DEPARTMENT_SET\\n type set (DEPARTMENT);\\n operations add_dept(d: DEPARTMENT): boolean;\\n  (* adds a department to the DEPARTMENT_SET object *)\\n   remove_dept(d: DEPARTMENT): boolean;\\n  (* removes a department from the DEPARTMENT_SET object *)\\n   create_dept_set: DEPARTMENT_SET;\\n   destroy_dept_set: boolean;\\nend Department_Set;\\n…\\npersistent name ALL_DEPARTMENTS: DEPARTMENT_SET;\\n(* ALL_DEPARTMENTS is a persistent named object of type DEPARTMENT_SET *)\\n…\\nd:= create_dept;\\n(* create a new DEPARTMENT object in the variable d *)\\n…\\nb:= ALL_DEPARTMENTS.add_dept(d);\\n(* make d persistent by adding it to the persistent set ALL_DEPARTMENTS *)\\nFigure 12.3 \\nCreating persistent \\nobjects by naming \\nand reachability.\\n12In this section we will use the terms type and class as meaning the same thing—namely, the attributes \\nand operations of some type of object.\\n13We will see in Section 12.3 that types with functions are similar to the concept of interfaces as used in \\nODMG ODL.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 388, 'page_label': '389'}, page_content='12.1 Overview of Object Database Concepts  375\\nA type in its simplest form has a type name and a list of visible ( public) functions. \\nWhen specifying a type in this section, we use the following format, which does not \\nspecify arguments of functions, to simplify the discussion:\\nTYPE_NAME: function, function, … , function\\nFor example, a type that describes characteristics of a PERSON may be defined as \\nfollows:\\nPERSON: Name, Address, Birth_date, Age, Ssn\\nIn the PERSON type, the Name, Address, Ssn, and Birth_date functions can be imple-\\nmented as stored attributes, whereas the Age function can be implemented as an \\noperation that calculates the Age from the value of the Birth_date attribute and the \\ncurrent date.\\nThe concept of subtype is useful when the designer or user must create a new type that \\nis similar but not identical to an already defined type. The subtype then inherits all the \\nfunctions of the predefined type, which is referred to as the supertype. For example, \\nsuppose that we want to define two new types \\nEMPLOYEE and STUDENT as follows:\\nEMPLOYEE: Name, Address, Birth_date, Age, Ssn, Salary, Hire_date, Seniority\\nSTUDENT: Name, Address, Birth_date, Age, Ssn, Major, Gpa\\nSince both STUDENT and EMPLOYEE include all the functions defined for PERSON \\nplus some additional functions of their own, we can declare them to be subtypes of \\nPERSON. Each will inherit the previously defined functions of PERSON—namely, \\nName, Address, Birth_date, Age, and Ssn. For STUDENT, it is only necessary to define \\nthe new (local) functions Major and Gpa, which are not inherited. Presumably, Major \\ncan be defined as a stored attribute, whereas Gpa may be implemented as an opera-\\ntion that calculates the student’s grade point average by accessing the Grade values \\nthat are internally stored (hidden) within each STUDENT object as hidden attributes. \\nFor EMPLOYEE, the Salary and Hire_date functions may be stored attributes, whereas \\nSeniority may be an operation that calculates Seniority from the value of Hire_date.\\nTherefore, we can declare EMPLOYEE and STUDENT as follows:\\nEMPLOYEE subtype-of PERSON: Salary, Hire_date, Seniority\\nSTUDENT subtype-of PERSON: Major, Gpa\\nIn general, a subtype includes all of the functions that are defined for its supertype \\nplus some additional functions that are specific only to the subtype. Hence, it is pos-\\nsible to generate a type hierarchy  to show the supertype/subtype relationships \\namong all the types declared in the system.\\nAs another example, consider a type that describes objects in plane geometry, which \\nmay be defined as follows:\\nGEOMETRY_OBJECT: Shape, Area, Reference_point\\nFor the GEOMETRY_OBJECT type, Shape is implemented as an attribute (its domain \\ncan be an enumerated type with values ‘triangle’, ‘rectangle’, ‘circle’, and so on), and'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 389, 'page_label': '390'}, page_content='376 Chapter 12 Object and Object-Relational Databases\\nArea is a method that is applied to calculate the area. Reference_point specifies the \\ncoordinates of a point that determines the object location. Now suppose that we \\nwant to define a number of subtypes for the \\nGEOMETRY_OBJECT type, as follows:\\nRECTANGLE subtype-of GEOMETRY_OBJECT: Width, Height\\nTRIANGLE S subtype-of GEOMETRY_OBJECT: Side1, Side2, Angle\\nCIRCLE subtype-of GEOMETRY_OBJECT: Radius\\nNotice that the Area operation may be implemented by a different method for each \\nsubtype, since the procedure for area calculation is different for rectangles, trian-\\ngles, and circles. Similarly, the attribute \\nReference_point may have a different mean-\\ning for each subtype; it might be the center point for RECTANGLE and CIRCLE \\nobjects, and the vertex point between the two given sides for a TRIANGLE object.\\nNotice that type definitions describe objects but do not generate objects on their \\nown. When an object is created, typically it belongs to one or more of these types \\nthat have been declared. For example, a circle object is of type \\nCIRCLE  and  \\nGEOMETRY_OBJECT (by inheritance). Each object also becomes a member of one \\nor more persistent collections of objects (or extents), which are used to group \\ntogether collections of objects that are persistently stored in the database.\\nConstraints on Extents Corresponding to a Type Hierarchy. In most ODBs, \\nan extent is defined to store the collection of persistent objects for each type or sub-\\ntype. In this case, the constraint is that every object in an extent that corresponds to \\na subtype must also be a member of the extent that corresponds to its supertype. \\nSome OO database systems have a predefined system type (called the ROOT class or \\nthe OBJECT class) whose extent contains all the objects in the system.14\\nClassification then proceeds by assigning objects into additional subtypes that are \\nmeaningful to the application, creating a type hierarchy (or class hierarchy) for the \\nsystem. All extents for system- and user-defined classes are subsets of the extent \\ncorresponding to the class \\nOBJECT, directly or indirectly. In the ODMG model (see \\nSection 12.3), the user may or may not specify an extent for each class (type), \\ndepending on the application.\\nAn extent is a named persistent object whose value is a persistent collection that \\nholds a collection of objects of the same type that are stored permanently in the \\ndatabase. The objects can be accessed and shared by multiple programs. It is also \\npossible to create a transient collection, which exists temporarily during the execu-\\ntion of a program but is not kept when the program terminates. For example, a \\ntransient collection may be created in a program to hold the result of a query that \\nselects some objects from a persistent collection and copies those objects into the \\ntransient collection. The program can then manipulate the objects in the transient \\ncollection, and once the program terminates, the transient collection ceases to exist. \\nIn general, numerous collections—transient or persistent—may contain objects of \\nthe same type.\\n14This is called OBJECT in the ODMG model (see Section 12.3).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 390, 'page_label': '391'}, page_content='12.1 Overview of Object Database Concepts  377\\nThe inheritance model discussed in this section is very simple. As we will see in Sec-\\ntion 12.3, the ODMG model distinguishes between type inheritance—called inter-\\nface inheritance  and denoted by a colon (:)—and the extent inheritance  \\nconstraint—denoted by the keyword EXTEND.\\n12.1.6 Other Object-Oriented Concepts\\nPolymorphism of Operations (Operator Overloading). Another characteris-\\ntic of OO systems in general is that they provide for polymorphism of operations, \\nwhich is also known as operator overloading. This concept allows the same opera-\\ntor name or symbol to be bound to two or more different implementations of the \\noperator, depending on the type of objects to which the operator is applied. A sim-\\nple example from programming languages can illustrate this concept. In some lan-\\nguages, the operator symbol “+” can mean different things when applied to \\noperands (objects) of different types. If the operands of “+” are of type integer, the \\noperation invoked is integer addition. If the operands of “+” are of type floating \\npoint, the operation invoked is floating-point addition. If the operands of “+” are of \\ntype set, the operation invoked is set union. The compiler can determine which \\noperation to execute based on the types of operands supplied.\\nIn OO databases, a similar situation may occur. We can use the \\nGEOMETRY_OBJECT \\nexample presented in Section 12.1.5 to illustrate operation polymorphism 15  \\nin ODB. In this example, the function Area is declared for all objects of type  \\nGEOMETRY_OBJECT. However, the implementation of the method for Area may \\ndiffer for each subtype of GEOMETRY_OBJECT. One possibility is to have a general \\nimplementation for calculating the area of a generalized GEOMETRY_OBJECT (for \\nexample, by writing a general algorithm to calculate the area of a polygon) and then \\nto rewrite more efficient algorithms to calculate the areas of specific types of geo-\\nmetric objects, such as a circle, a rectangle, a triangle, and so on. In this case, the \\nArea function is overloaded by different implementations.\\nThe ODMS must now select the appropriate method for the Area function based on \\nthe type of geometric object to which it is applied. In strongly typed systems, this \\ncan be done at compile time, since the object types must be known. This is termed \\nearly (or static) binding. However, in systems with weak typing or no typing (such \\nas Smalltalk, LISP, PHP, and most scripting languages), the type of the object to \\nwhich a function is applied may not be known until runtime. In this case, the func-\\ntion must check the type of object at runtime and then invoke the appropriate \\nmethod. This is often referred to as late (or dynamic) binding.\\nMultiple Inheritance and Selective Inheritance.  Multiple inheritance occurs \\nwhen a certain subtype T is a subtype of two (or more) types and hence inherits the \\nfunctions (attributes and methods) of both supertypes. For example, we may create \\n15In programming languages, there are several kinds of polymorphism. The interested reader is referred to \\nthe Selected Bibliography at the end of this chapter for works that include a more thorough discussion.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 391, 'page_label': '392'}, page_content='378 Chapter 12 Object and Object-Relational Databases\\na subtype ENGINEERING_MANAGER  that is a subtype of both MANAGER  and  \\nENGINEER. This leads to the creation of a type lattice rather than a type hierarchy. \\nOne problem that can occur with multiple inheritance is that the supertypes from \\nwhich the subtype inherits may have distinct functions of the same name, creating an \\nambiguity. For example, both \\nMANAGER and ENGINEER may have a function called \\nSalary. If the Salary function is implemented by different methods in the MANAGER \\nand ENGINEER supertypes, an ambiguity exists as to which of the two is inherited by \\nthe subtype ENGINEERING_MANAGER. It is possible, however, that both ENGINEER \\nand MANAGER inherit Salary from the same supertype (such as EMPLOYEE) higher \\nup in the lattice. The general rule is that if a function is inherited from some com-\\nmon supertype, then it is inherited only once. In such a case, there is no ambiguity; \\nthe problem only arises if the functions are distinct in the two supertypes.\\nThere are several techniques for dealing with ambiguity in multiple inheritance. \\nOne solution is to have the system check for ambiguity when the subtype is created, \\nand to let the user explicitly choose which function is to be inherited at this time. A \\nsecond solution is to use some system default. A third solution is to disallow mul-\\ntiple inheritance altogether if name ambiguity occurs, instead forcing the user to \\nchange the name of one of the functions in one of the supertypes. Indeed, some OO \\nsystems do not permit multiple inheritance at all. In the object database standard \\n(see Section 12.3), multiple inheritance is allowed for operation inheritance of \\ninterfaces, but is not allowed for \\nEXTENDS inheritance of classes.\\nSelective inheritance occurs when a subtype inherits only some of the functions of \\na supertype. Other functions are not inherited. In this case, an EXCEPT clause may \\nbe used to list the functions in a supertype that are not to be inherited by the sub-\\ntype. The mechanism of selective inheritance is not typically provided in ODBs, but \\nit is used more frequently in artificial intelligence applications.16\\n12.1.7 Summary of Object Database Concepts\\nTo conclude this section, we give a summary of the main concepts used in ODBs \\nand object-relational systems:\\n ■ Object identity. Objects have unique identities that are independent of their \\nattribute values and are generated by the ODB system.\\n ■ Type constructors. Complex object structures can be constructed by apply-\\ning in a nested manner a set of basic type generators/constructors, such as \\ntuple, set, list, array, and bag.\\n ■ Encapsulation of operations. Both the object structure and the operations that \\ncan be applied to individual objects are included in the class/type definitions.\\n ■ Programming language compatibility. Both persistent and transient objects \\nare handled seamlessly. Objects are made persistent by being reachable from \\n16In the ODMG model, type inheritance refers to inheritance of operations only, not attributes (see \\nSection 12.3).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 392, 'page_label': '393'}, page_content='12.2 Object Database Extensions to SQL  379\\na persistent collection (extent) or by explicit naming (assigning a unique \\nname by which the object can be referenced/retrieved).\\n ■ Type hierarchies and inheritance. Object types can be specified by using a \\ntype hierarchy, which allows the inheritance of both attributes and methods \\n(operations) of previously defined types. Multiple inheritance is allowed in \\nsome models.\\n ■ Extents. All persistent objects of a particular class/type C can be stored in an \\nextent, which is a named persistent object of type set(C). Extents corre-\\nsponding to a type hierarchy have set/subset constraints enforced on their \\ncollections of persistent objects.\\n ■ Polymorphism and operator overloading. Operations and method names \\ncan be overloaded to apply to different object types with different imple-\\nmentations.\\nIn the following sections we show how these concepts are realized, first in the SQL \\nstandard (Section 12.2) and then in the ODMG standard (Section 12.3).\\n12.2 Object Database Extensions to SQL\\nWe introduced SQL as the standard language for RDBMSs in Chapters 6 and 7. As \\nwe discussed, SQL was first specified by Chamberlin and Boyce (1974) and under-\\nwent enhancements and standardization in 1989 and 1992. The language continued \\nits evolution with a new standard, initially called SQL3 while being developed and \\nlater known as SQL:99 for the parts of SQL3 that were approved into the standard. \\nStarting with the version of SQL known as SQL3, features from object databases \\nwere incorporated into the SQL standard. At first, these extensions were known as \\nSQL/Object, but later they were incorporated in the main part of SQL, known as \\nSQL/Foundation in SQL:2008.\\nThe relational model with object database enhancements is sometimes referred to \\nas the object-relational model. Additional revisions were made to SQL in 2003 and \\n2006 to add features related to XML (see Chapter 13).\\nThe following are some of the object database features that have been included in SQL:\\n ■ Some type constructors have been added to specify complex objects. These \\ninclude the row type, which corresponds to the tuple (or struct) constructor. \\nAn array type  for specifying collections is also provided. Other collection \\ntype constructors, such as set, list, and bag constructors, were not part of the \\noriginal SQL/Object specifications in SQL:99 but were later included in the \\nstandard in SQL:2008.\\n ■ A mechanism for specifying object identity  through the use of reference \\ntype is included.\\n ■ Encapsulation of operations  is provided through the mechanism of \\nuser-defined types (UDTs) that may include operations as part of their \\ndeclaration. These are somewhat similar to the concept of abstract data'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 393, 'page_label': '394'}, page_content='380 Chapter 12 Object and Object-Relational Databases\\ntypes  that were developed in programming languages. In addition, the \\nconcept of user-defined routines (UDRs) allows the definition of general \\nmethods (operations).\\n ■ Inheritance mechanisms are provided using the keyword UNDER.\\nWe now discuss each of these concepts in more detail. In our discussion, we will \\nrefer to the example in Figure 12.4.\\n12.2.1  User-Defined Types Using CREATE TYPE  \\nand Complex Objects\\nTo allow the creation of complex-structured objects and to separate the declaration \\nof a class/type from the creation of a table (which is the collection of objects/rows \\nand hence corresponds to the extent discussed in Section 12.1), SQL now provides \\nuser-defined types (UDTs). In addition, four collection types have been included \\nto allow for collections (multivalued types and attributes) in order to specify com-\\nplex-structured objects rather than just simple (flat) records. The user will create \\nthe UDTs for a particular application as part of the database schema. A UDT may \\nbe specified in its simplest form using the following syntax:\\nCREATE TYPE TYPE_NAME AS (<component declarations>);\\nFigure 12.4 illustrates some of the object concepts in SQL. We will explain the \\nexamples in this figure gradually as we explain the concepts. First, a UDT can be \\nused as either the type for an attribute or as the type for a table. By using a UDT as \\nthe type for an attribute within another UDT, a complex structure for objects \\n(tuples) in a table can be created, much like that achieved by nesting type construc-\\ntors/generators as discussed in Section 12.1. This is similar to using the struct  \\ntype constructor of Section 12.1.3. For example, in Figure 12.4(a), the UDT \\nSTREET_ADDR_TYPE is used as the type for the STREET_ADDR attribute in the UDT \\nUSA_ADDR_TYPE. Similarly, the UDT USA_ADDR_TYPE is in turn used as the type \\nfor the ADDR attribute in the UDT PERSON_TYPE in Figure 12.4(b). If a UDT does \\nnot have any operations, as in the examples in Figure 12.4(a), it is possible to use  \\nthe concept of \\nROW TYPE  to directly create a structured attribute by using the  \\nkeyword ROW. For example, we could use the following instead of declaring \\nSTREET_ADDR_TYPE as a separate type as in Figure 12.4(a):\\nCREATE TYPE USA_ADDR_TYPE AS (\\n STREET_ADDR ROW ( NUMBER VARCHAR (5),\\n   STREET_NAME VARCHAR (25),\\n   APT_NO VARCHAR (5),\\n   SUITE_NO VARCHAR (5) ),\\n CITY VARCHAR (25),\\n ZIP VARCHAR (10)\\n );\\nTo allow for collection types in order to create complex-structured objects, four \\nconstructors are now included in SQL: ARRAY, MULTISET, LIST, and SET. These are'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 394, 'page_label': '395'}, page_content='12.2 Object Database Extensions to SQL  381\\n(a) CREATE TYPE STREET_ADDR_TYPE AS (\\n  NUMBER VARCHAR (5),\\n  STREET NAME VARCHAR (25),\\n  APT_NO VARCHAR (5),\\n  SUITE_NO VARCHAR (5)\\n );\\n CREATE TYPE USA_ADDR_TYPE AS (\\n  STREET_ADDR STREET_ADDR_TYPE,\\n  CITY VARCHAR (25),\\n  ZIP VARCHAR (10)\\n );\\n CREATE TYPE USA_PHONE_TYPE AS (\\n  PHONE_TYPE VARCHAR (5),\\n  AREA_CODE CHAR (3),\\n  PHONE_NUM CHAR (7)\\n );\\n(b) CREATE TYPE PERSON_TYPE AS (\\n  NAME VARCHAR (35),\\n  SEX CHAR,\\n  BIRTH_DATE DATE,\\n  PHONES USA_PHONE_TYPE ARRAY [4],\\n  ADDR USA_ADDR_TYPE\\n INSTANTIABLE\\n NOT FINAL\\n REF IS SYSTEM GENERATED\\n INSTANCE METHOD AGE() RETURNS INTEGER;\\n CREATE INSTANCE METHOD AGE() RETURNS INTEGER\\n  FOR PERSON_TYPE\\n  BEGIN\\n    RETURN /*  CODE TO CALCULATE A PERSON’S AGE FROM \\nTODAY’S DATE AND SELF.BIRTH_DATE */\\n  END;\\n );\\n(c) CREATE TYPE GRADE_TYPE AS (\\n  COURSENO CHAR (8),\\n  SEMESTER VARCHAR (8),\\n  YEAR CHAR (4),\\n  GRADE CHAR\\n );\\n CREATE TYPE STUDENT_TYPE UNDER PERSON_TYPE AS (\\n  MAJOR_CODE CHAR (4),\\n  STUDENT_ID CHAR (12),\\n  DEGREE VARCHAR (5),\\n  TRANSCRIPT GRADE_TYPE ARRAY [100]\\nFigure 12.4 \\nIllustrating some of the object  \\nfeatures of SQL. (a) Using UDTs  \\nas types for attributes such as  \\nAddress and Phone, (b) specifying  \\nUDT for PERSON_TYPE,  \\n(c) specifying UDTs for  \\nSTUDENT_TYPE and EMPLOYEE_TYPE \\nas two subtypes of PERSON_TYPE.\\n(continues)'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 395, 'page_label': '396'}, page_content='382 Chapter 12 Object and Object-Relational Databases\\n INSTANTIABLE\\n NOT FINAL\\n INSTANCE METHOD GPA( ) RETURNS FLOAT;\\n CREATE INSTANCE METHOD GPA( ) RETURNS FLOAT\\n  FOR STUDENT_TYPE\\n  BEGIN\\n    RETURN /*  CODE TO CALCULATE A STUDENT’S GPA FROM  \\nSELF.TRANSCRIPT */\\n  END;\\n );\\n CREATE TYPE EMPLOYEE_TYPE UNDER PERSON_TYPE AS (\\n  JOB_CODE CHAR (4),\\n  SALARY FLOAT,\\n  SSN CHAR (11)\\n INSTANTIABLE\\n NOT FINAL\\n );\\n CREATE TYPE MANAGER_TYPE UNDER EMPLOYEE_TYPE AS (\\n   DEPT_MANAGED CHAR (20)\\n INSTANTIABLE\\n );\\n(d) CREATE TABLE PERSON OF PERSON_TYPE\\n  REF IS PERSON_ID SYSTEM GENERATED;\\n CREATE TABLE EMPLOYEE OF EMPLOYEE_TYPE\\n  UNDER PERSON;\\n CREATE TABLE MANAGER OF MANAGER_TYPE\\n  UNDER EMPLOYEE;\\n CREATE TABLE STUDENT OF STUDENT_TYPE\\n  UNDER PERSON;\\n(e) CREATE TYPE COMPANY_TYPE AS (\\n  COMP_NAME VARCHAR (20),\\n  LOCATION VARCHAR (20));\\n CREATE TYPE EMPLOYMENT_TYPE AS (\\n  Employee REF (EMPLOYEE_TYPE) SCOPE (EMPLOYEE),\\n  Company REF (COMPANY_TYPE) SCOPE (COMPANY) );\\n CREATE TABLE COMPANY OF COMPANY_TYPE (\\n  REF IS COMP_ID SYSTEM GENERATED,\\n  PRIMARY KEY (COMP_NAME) );\\n CREATE TABLE EMPLOYMENT OF EMPLOYMENT_TYPE;\\nFigure 12.4 \\n(continued)\\nllustrating some of  \\nthe object features of  \\nSQL. (c) (continued)  \\nSpecifying UDTs for  \\nSTUDENT_TYPE and  \\nEMPLOYEE_TYPE as  \\ntwo subtypes of  \\nPERSON_TYPE,  \\n(d) Creating tables based  \\non some of the UDTs,  \\nand illustrating table  \\ninheritance,  \\n(e) Specifying  \\nrelationships using REF \\nand SCOPE.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 396, 'page_label': '397'}, page_content='12.2 Object Database Extensions to SQL  383\\nsimilar to the type constructors discussed in Section 12.1.3. In the initial specifica-\\ntion of SQL/Object, only the ARRAY type was specified, since it can be used to simu-\\nlate the other types, but the three additional collection types were included in a  \\nlater version of the SQL standard. In Figure 12.4(b), the \\nPHONES attribute of  \\nPERSON_TYPE has as its type an array whose elements are of the previously defined \\nUDT USA_PHONE_TYPE . This array has a maximum of four elements, meaning \\nthat we can store up to four phone numbers per person. An array can also have no \\nmaximum number of elements if desired.\\nAn array type can have its elements referenced using the common notation of \\nsquare brackets. For example, \\nPHONES[1] refers to the first location value in a \\nPHONES attribute (see Figure 12.4(b)). A built-in function CARDINALITY can return \\nthe current number of elements in an array (or any other collection type). For \\nexample, \\nPHONES[CARDINALITY (PHONES)] refers to the last element in the array.\\nThe commonly used dot notation is used to refer to components of a ROW TYPE or \\na UDT. For example, ADDR.CITY refers to the CITY component of an ADDR attribute \\n(see Figure 12.4(b)).\\n12.2.2 Object Identifiers Using Reference Types\\nUnique system-generated object identifiers can be created via the reference type \\nusing the keyword REF. For example, in Figure 12.4(b), the phrase:\\nREF IS SYSTEM GENERATED\\nindicates that whenever a new PERSON_TYPE  object is created, the system will \\nassign it a unique system-generated identifier. It is also possible not to have a system-\\ngenerated object identifier and use the traditional keys of the basic relational model \\nif desired.\\nIn general, the user can specify that system-generated object identifiers for the indi-\\nvidual rows in a table should be created. By using the syntax:\\nREF IS <OID_ATTRIBUTE> <VALUE_GENERATION_METHOD> ;\\nthe user declares that the attribute named <OID_ATTRIBUTE> will be used to identify \\nindividual tuples in the table. The options for < VALUE_GENERATION_ METHOD> \\nare SYSTEM GENERATED  or DERIVED . In the former case, the system will  \\nautomatically generate a unique identifier for each tuple. In the latter case, the \\ntraditional method of using the user-provided primary key value to identify \\ntuples is applied.\\n12.2.3 Creating Tables Based on the UDTs\\nFor each UDT that is specified to be instantiable via the phrase INSTANTIABLE (see \\nFigure 12.4(b)), one or more tables may be created. This is illustrated in Fig- \\nure 12.4(d), where we create a table \\nPERSON based on the PERSON_TYPE UDT. Notice \\nthat the UDTs in Figure 12.4(a) are noninstantiable and hence can only be used as'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 397, 'page_label': '398'}, page_content='384 Chapter 12 Object and Object-Relational Databases\\ntypes for attributes, but not as a basis for table creation. In Figure 12.4(b), the attri-\\nbute PERSON_ID will hold the system-generated object identifier whenever a new \\nPERSON record (object) is created and inserted in the table.\\n12.2.4 Encapsulation of Operations\\nIn SQL, a user-defined type can have its own behavioral specification by specifying \\nmethods (or operations) in addition to the attributes. The general form of a UDT \\nspecification with methods is as follows:\\nCREATE TYPE <TYPE-NAME> (\\n  <LIST OF COMPONENT ATTRIBUTES AND THEIR TYPES>\\n  <DECLARATION OF FUNCTIONS (METHODS)>\\n);\\nFor example, in Figure 12.4(b), we declared a method Age() that calculates the age of \\nan individual object of type PERSON_TYPE.\\nThe code for implementing the method still has to be written. We can refer to the \\nmethod implementation by specifying the file that contains the code for the method, \\nor we can write the actual code within the type declaration itself (see Figure 12.4(b)).\\nSQL provides certain built-in functions for user-defined types. For a UDT called \\nTYPE_T, the constructor function TYPE_T( ) returns a new object of that type. In \\nthe new UDT object, every attribute is initialized to its default value. An observer \\nfunction A is implicitly created for each attribute A to read its value. Hence, A(X) \\nor X.A returns the value of attribute A of TYPE_T if X is a variable that refers to an \\nobject/row of type TYPE_T. A mutator function for updating an attribute sets the \\nvalue of the attribute to a new value. SQL allows these functions to be blocked from \\npublic use; an \\nEXECUTE privilege is needed to have access to these functions.\\nIn general, a UDT can have a number of user-defined functions associated with it. \\nThe syntax is\\nINSTANCE METHOD <NAME> (<ARGUMENT_LIST>) RETURNS  \\n<RETURN_TYPE>;\\nTwo types of functions can be defined: internal SQL and external. Internal functions \\nare written in the extended PSM language of SQL (see Chapter 10). External func-\\ntions are written in a host language, with only their signature (interface) appearing \\nin the UDT definition. An external function definition can be declared as follows:\\nDECLARE EXTERNAL <FUNCTION_NAME> <SIGNATURE>\\nLANGUAGE <LANGUAGE_NAME>;\\nAttributes and functions in UDTs are divided into three categories:\\n ■ PUBLIC (visible at the UDT interface)\\n ■ PRIVATE (not visible at the UDT interface)\\n ■ PROTECTED (visible only to subtypes)'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 398, 'page_label': '399'}, page_content='12.2 Object Database Extensions to SQL  385\\nIt is also possible to define virtual attributes as part of UDTs, which are computed \\nand updated using functions.\\n12.2.5 Specifying Inheritance and Overloading of Functions\\nIn SQL, inheritance can be applied to types or to tables; we will discuss the meaning \\nof each in this section. Recall that we already discussed many of the principles of \\ninheritance in Section 12.1.5. SQL has rules for dealing with type inheritance  \\n(specified via the \\nUNDER keyword). In general, both attributes and instance meth-\\nods (operations) are inherited. The phrase NOT FINAL must be included in a UDT if \\nsubtypes are allowed to be created under that UDT (see Figures 12.4(a) and (b), \\nwhere \\nPERSON_TYPE, STUDENT_TYPE , and EMPLOYEE_TYPE  are declared to be \\nNOT FINAL). Associated with type inheritance are the rules for overloading of func-\\ntion implementations and for resolution of function names. These inheritance rules \\ncan be summarized as follows:\\n ■ All attributes are inherited.\\n ■ The order of supertypes in the UNDER clause determines the inheritance \\nhierarchy.\\n ■ An instance of a subtype can be used in every context in which a supertype \\ninstance is used.\\n ■ A subtype can redefine any function that is defined in its supertype, with the \\nrestriction that the signature be the same.\\n ■ When a function is called, the best match is selected based on the types of all \\narguments.\\n ■ For dynamic linking, the types of the parameters are considered at runtime.\\nConsider the following examples to illustrate type inheritance, which are illustrated \\nin Figure 12.4(c). Suppose that we want to create two subtypes of PERSON_TYPE: \\nEMPLOYEE_TYPE  and STUDENT_TYPE . In addition, we also create a subtype \\nMANAGER_TYPE that inherits all the attributes (and methods) of EMPLOYEE_TYPE \\nbut has an additional attribute DEPT_MANAGED . These subtypes are shown in \\nFigure 12.4(c).\\nIn general, we specify the local (specific) attributes and any additional specific \\nmethods for the subtype, which inherits the attributes and operations (methods) of \\nits supertype.\\nAnother facility in SQL is table inheritance  via the supertable/subtable facility. \\nThis is also specified using the keyword \\nUNDER (see Figure 12.4(d)). Here, a new \\nrecord that is inserted into a subtable, say the MANAGER table, is also inserted into \\nits supertables EMPLOYEE and PERSON. Notice that when a record is inserted in \\nMANAGER, we must provide values for all its inherited attributes. INSERT, DELETE, \\nand UPDATE operations are appropriately propagated. Basically, table inheritance \\ncorresponds to the extent inheritance discussed in Section 12.1.5. The rule is that a \\ntuple in a sub-table must also exist in its super-table to enforce the set/subset con-\\nstraint on the objects.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 399, 'page_label': '400'}, page_content='386 Chapter 12 Object and Object-Relational Databases\\n12.2.6 Specifying Relationships via Reference\\nA component attribute of one tuple may be a reference (specified using the key-\\nword REF) to a tuple of another (or possibly the same) table. An example is shown \\nin Figure 12.4(e).\\nThe keyword SCOPE specifies the name of the table whose tuples can be referenced \\nby the reference attribute. Notice that this is similar to a foreign key, except that the \\nsystem-generated OID value is used rather than the primary key value.\\nSQL uses a dot notation  to build path expressions  that refer to the component \\nattributes of tuples and row types. However, for an attribute whose type is \\nREF, the \\ndereferencing symbol –> is used. For example, the query below retrieves employees \\nworking in the company named ‘ABCXYZ’ by querying the EMPLOYMENT table:\\nSELECT E.Employee–>NAME\\nFROM EMPLOYMENT AS E\\nWHERE E.Company–>COMP_NAME = ‘ABCXYZ’;\\nIn SQL, –> is used for dereferencing and has the same meaning assigned to it in the \\nC programming language. Thus, if r is a reference to a tuple (object) and a is a com-\\nponent attribute in that tuple, then r –> a is the value of attribute a in that tuple.\\nIf several relations of the same type exist, SQL provides the SCOPE keyword by \\nwhich a reference attribute may be made to point to a tuple within a specific table of \\nthat type.\\n12.3  The ODMG Object Model and the Object \\nDefinition Language ODL\\nAs we discussed in the introduction to Chapter 6, one of the reasons for the success \\nof commercial relational DBMSs is the SQL standard. The lack of a standard for \\nODBs for several years may have caused some potential users to shy away from con-\\nverting to this new technology. Subsequently, a consortium of ODB vendors and \\nusers, called ODMG (Object Data Management Group), proposed a standard that is \\nknown as the ODMG-93 or ODMG 1.0 standard. This was revised into ODMG 2.0, \\nand later to ODMG 3.0. The standard is made up of several parts, including the \\nobject model, the object definition language  (ODL), the object query language  \\n(OQL), and the bindings to object-oriented programming languages.\\nIn this section, we describe the ODMG object model and the ODL. In Section 12.4, \\nwe discuss how to design an ODB from an EER conceptual schema. We will give an \\noverview of OQL in Section 12.5, and the C++ language binding in Section 12.6. \\nExamples of how to use ODL, OQL, and the C++ language binding will use the \\nUNIVERSITY database example introduced in Chapter 4. In our description, we will \\nfollow the ODMG 3.0 object model as described in Cattell et al. (2000). 17 It is \\n17The earlier versions of the object model were published in 1993 and 1997 .'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 400, 'page_label': '401'}, page_content='12.3 The ODMG Object Model and the Object Definition Language ODL  387\\nimportant to note that many of the ideas embodied in the ODMG object model are \\nbased on two decades of research into conceptual modeling and object databases by \\nmany researchers.\\nThe incorporation of object concepts into the SQL relational database standard, \\nleading to object-relational technology, was presented in Section 12.2.\\n12.3.1 Overview of the Object Model of ODMG\\nThe ODMG object model is the data model upon which the object definition lan-\\nguage (ODL) and object query language (OQL) are based. It is meant to provide a \\nstandard data model for object databases, just as SQL describes a standard data \\nmodel for relational databases. It also provides a standard terminology in a field \\nwhere the same terms were sometimes used to describe different concepts. We will \\ntry to adhere to the ODMG terminology in this chapter. Many of the concepts in \\nthe ODMG model have already been discussed in Section 12.1, and we assume the \\nreader has read this section. We will point out whenever the ODMG terminology \\ndiffers from that used in Section 12.1.\\nObjects and Literals. Objects and literals are the basic building blocks of the \\nobject model. The main difference between the two is that an object has both an \\nobject identifier and a state  (or current value), whereas a literal has a value \\n(state) but no object identifier.\\n18 In either case, the value can have a complex \\nstructure. The object state can change over time by modifying the object value. A \\nliteral is basically a constant value, possibly having a complex structure, but it \\ndoes not change.\\nAn object has five aspects: identifier, name, lifetime, structure, and creation.\\n  1. The object identifier  is a unique system-wide identifier (or Object_id).19 \\nEvery object must have an object identifier.\\n  2. Some objects may optionally be given a unique name within a particular \\nODMS—this name can be used to locate the object, and the system should \\nreturn the object given that name.\\n20 Obviously, not all individual objects \\nwill have unique names. Typically, a few objects, mainly those that hold \\ncollections of objects of a particular object class/type—such as extents—will \\nhave a name. These names are used as entry points to the database; that is, \\nby locating these objects by their unique name, the user can then locate \\nother objects that are referenced from these objects. Other important \\nobjects in the application may also have unique names, and it is possible to \\ngive more than one  name to an object. All names within a particular ODB \\nmust be unique.\\n18We will use the terms value and state interchangeably here.\\n19This corresponds to the OID of Section 12.1.2.\\n20This corresponds to the naming mechanism for persistence, described in Section 12.1.4.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 401, 'page_label': '402'}, page_content='388 Chapter 12 Object and Object-Relational Databases\\n  3. The lifetime of an object specifies whether it is a persistent object (that is, a \\ndatabase object) or transient object (that is, an object in an executing pro-\\ngram that disappears after the program terminates). Lifetimes are indepen-\\ndent of classes/types—that is, some objects of a particular class may be \\ntransient whereas others may be persistent.\\n  4. The structure of an object specifies how the object is constructed by using \\nthe type constructors. The structure specifies whether an object is atomic or \\nnot. An atomic object refers to a single object that follows a user-defined \\ntype, such as Employee or Department. If an object is not atomic, then it will be \\ncomposed of other objects. For example, a collection object is not an atomic \\nobject, since its state will be a collection of other objects. 21 The term atomic \\nobject  is different from how we defined the atom constructor  in Sec- \\ntion 12.1.3, which referred to all values of built-in data types. In the ODMG \\nmodel, an atomic object is any individual user-defined object . All values of \\nthe basic built-in data types are considered to be literals.\\n  5. Object creation refers to the manner in which an object can be created. This \\nis typically accomplished via an operation new for a special Object_Factory \\ninterface. We shall describe this in more detail later in this section.\\nIn the object model, a literal is a value that does not have an object identifier. How-\\never, the value may have a simple or complex structure. There are three types of \\nliterals: atomic, structured, and collection.\\n  1. Atomic literals22 correspond to the values of basic data types and are pre-\\ndefined. The basic data types of the object model include long, short, and \\nunsigned integer numbers (these are specified by the keywords long, short, \\nunsigned long , and unsigned short  in ODL), regular and double precision \\nfloating-point numbers ( float, double), Boolean values ( boolean), single \\ncharacters (char), character strings (string), and enumeration types (enum), \\namong others.\\n  2. Structured literals correspond roughly to values that are constructed using \\nthe tuple constructor described in Section 12.1.3. The built-in structured lit-\\nerals include Date, Interval, Time, and Timestamp (see Figure 12.5(b)). Addi-\\ntional user-defined structured literals can be defined as needed by each \\napplication.23 User-defined structures are created using the STRUCT key-\\nword in ODL, as in the C and C++ programming languages.\\n21In the ODMG model, atomic objects do not correspond to objects whose values are basic data types. \\nAll basic values (integers, reals, and so on) are considered literals.\\n22The use of the word atomic in atomic literal  corresponds to the way we used atom constructor in \\nSection 12.1.3.\\n23The structures for Date, Interval, Time, and Timestamp can be used to create either literal values or \\nobjects with identifiers.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 402, 'page_label': '403'}, page_content='12.3 The ODMG Object Model and the Object Definition Language ODL  389\\n(continues)\\n(a)  nterface Object {\\n  …\\n  boolean same_as(in object other_object);\\n  object copy();\\n  void delete();\\n };\\n(b) Class Date : Object {\\n  enum Weekday\\n    { Sunday, Monday, Tuesday, Wednesday,  \\n      Thursday, Friday, Saturday };\\n  enum Month\\n    { January, February, March, April, May, June,  \\n      July, August, September, October, November,  \\n      December };\\n  unsigned short year();\\n  unsigned short month();\\n  unsigned short day();\\n  …\\n  boolean is_equal(in Date other_date);\\n  boolean is_greater(in Date other_date);\\n  … };\\n Class Time : Object {\\n  …\\n  unsigned short hour();\\n  unsigned short minute();\\n  unsigned short second();\\n  unsigned short millisecond();\\n  …\\n  boolean is_equal(in Time a_time);\\n  boolean is_greater(in Time a_time);\\n  …\\n  Time add_interval(in Interval an_interval);\\n  Time subtract_interval(in Interval an_interval);\\n  Interval subtract_time(in Time other_time); };\\n class Timestamp : Object {\\n  …\\n  unsigned short year();\\n  unsigned short month();\\n  unsigned short day();\\n  unsigned short hour();\\n  unsigned short minute();\\n  unsigned short second();\\n  unsigned short millisecond();\\n  …\\n  Timestamp plus(in Interval an_interval);\\nFigure 12.5 \\nOverview of the interface definitions  \\nfor part of the ODMG object model.  \\n(a) The basic Object interface, inherited \\nby all objects, (b) Some standard  \\ninterfaces for structured literals.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 403, 'page_label': '404'}, page_content='390 Chapter 12 Object and Object-Relational Databases\\n  Timestamp minus(in Interval an_interval);\\n  boolean is_equal(in Timestamp a_timestamp);\\n  boolean is_greater(in Timestamp a_timestamp);\\n  …  };\\n  class Interval : Object {\\n  unsigned short day();\\n  unsigned short hour();\\n  unsigned short minute();\\n  unsigned short second();\\n  unsigned short millisecond();\\n  …\\n  Interval plus(in Interval an_interval);\\n  Interval minus(in Interval an_interval);\\n  Interval product(in long a_value);\\n  Interval quotient(in long a_value);\\n  boolean is_equal(in interval an_interval);\\n  boolean is_greater(in interval an_interval);\\n  …  };\\n(c) interface Collection : Object {\\n  …\\n  exception ElementNotFound{ Object element; };\\n  unsigned long cardinality();\\n  boolean is_empty();\\n  …\\n  boolean contains_element(in Object element);\\n  void insert_element(in Object element);\\n  void remove_element(in Object element)\\n    raises(ElementNotFound);\\n  iterator create_iterator(in boolean stable);\\n  …  };\\n interface Iterator {\\n  exception NoMoreElements();\\n  …\\n  boolean at_end();\\n  void reset();\\n  Object get_element() raises(NoMoreElements);\\n  void next_position() raises(NoMoreElements);\\n  …  };\\n interface set : Collection {\\n  set create_union(in set other_set);\\n  …\\n  boolean is_subset_of(in set other_set);\\n  …  };\\n interface bag : Collection {\\n  unsigned long occurrences_of(in Object element);\\nFigure 12.5  \\n(continued)\\nOverview of the \\ninterface  \\ndefinitions for  \\npart of the ODMG  \\nobject model.\\n(b) (continued) Some  \\nstandard interfaces  \\nfor structured literals,  \\n(c) Interfaces for  \\ncollections and  \\niterators.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 404, 'page_label': '405'}, page_content='12.3 The ODMG Object Model and the Object Definition Language ODL  391\\n  bag create_union(in Bag other_bag);\\n  …  };\\n interface list : Collection {\\n  exception lnvalid_lndex{unsigned_long index; );\\n  void remove_element_at(in unsigned long index)\\n    raises(lnvalidlndex);\\n  Object retrieve_element_at(in unsigned long index)\\n    raises(lnvalidlndex);\\n  void replace_element_at(in Object element, in unsigned long index)\\n    raises(lnvalidlndex);\\n  void insert_element_after(in Object element, in unsigned long index)\\n    raises(lnvalidlndex);\\n  …\\n  void insert_element_first(in Object element);\\n  …\\n  void remove_first_element() raises(ElementNotFound);\\n  …\\n  Object retrieve_first_element() raises(ElementNotFound);\\n  …\\n  list concat(in list other_list);\\n  void append(in list other_list);\\n };\\n interface array : Collection {\\n  exception lnvalid_lndex{unsigned_long index; };\\n  exception lnvalid_Size{unsigned_long size; };\\n  void remove_element_at(in unsigned long index)\\n    raises(InvalidIndex);\\n  Object retrieve_element_at(in unsigned long index)\\n    raises(InvalidIndex);\\n  void replace_element_at(in unsigned long index, in Object element)\\n    raises(InvalidIndex);\\n  void resize(in unsigned long new_size)\\n    raises(InvalidSize);\\n };\\n struct association { Object key; Object value; };\\n interface dictionary : Collection {\\n  exception DuplicateName{string key; };\\n  exception KeyNotFound{Object key; };\\n  void bind(in Object key, in Object value)\\n    raises(DuplicateName);\\n  void unbind(in Object key) raises(KeyNotFound);\\n  Object lookup(in Object key) raises(KeyNotFound);\\n  boolean contains_key(in Object key);\\n };\\nFigure 12.5  \\n(continued)\\nOverview of the\\ninterface  \\ndefinitions for  \\npart of the  \\nODMG object  \\nmodel.  \\n(c) (continued)  \\nInterfaces for  \\ncollections and  \\niterators.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 405, 'page_label': '406'}, page_content='392 Chapter 12 Object and Object-Relational Databases\\n  3. Collection literals  specify a literal value that is a collection of objects or \\nvalues but the collection itself does not have an Object_id. The collections \\nin the object model can be defined by the type generators  set<T>, bag<T>, \\nlist<T>, and array<T>, where T is the type of objects or values in the collec-\\ntion.24 Another collection type is dictionary<K, V>, which is a collection of \\nassociations < K, V>, where each K is a key (a unique search value) associ-\\nated with a value V; this can be used to create an index on a collection of \\nvalues V.\\nFigure 12.5 gives a simplified view of the basic types and type generators of the \\nobject model. The notation of ODMG uses three concepts: interface , literal, and \\nclass. Following the ODMG terminology, we use the word behavior  to refer to \\noperations  and state  to refer to properties  (attributes and relationships). An  \\ninterface specifies only behavior of an object type and is typically noninstantiable \\n(that is, no objects are created corresponding to an interface). Although an inter-\\nface may have state properties (attributes and relationships) as part of its specifi-\\ncations, these cannot be inherited from the interface. Hence, an interface serves \\nto define operations that can be inherited  by other interfaces, as well as by classes \\nthat define the user-defined objects for a particular application. A class specifies \\nboth state (attributes) and behavior (operations) of an object type and is \\ninstantiable . Hence, database and application objects are typically created based \\non the user-specified class declarations that form a database schema. Finally, a \\nliteral declaration specifies state but no behavior. Thus, a literal instance holds a \\nsimple or complex structured value but has neither an object identifier nor \\nencapsulated operations.\\nFigure 12.5 is a simplified version of the object model. For the full specifications, \\nsee Cattell et al. (2000). We will describe some of the constructs shown in Fig- \\nure 12.5 as we describe the object model. In the object model, all objects inherit the \\nbasic interface operations of \\nObject, shown in Figure 12.5(a); these include opera-\\ntions such as copy (creates a new copy of the object), delete (deletes the object), and \\nsame_as (compares the object’s identity to another object).25 In general, operations \\nare applied to objects using the dot notation. For example, given an object O, to \\ncompare it with another object P, we write\\nO.same_as(P)\\nThe result returned by this operation is Boolean and would be true if the identity of \\nP is the same as that of O, and false otherwise. Similarly, to create a copy P of object \\nO, we write\\nP = O.copy()\\nAn alternative to the dot notation is the arrow notation:  O–>same_as (P) or \\nO–>copy().\\n24These are similar to the corresponding type constructors described in Section 12.1.3.\\n25Additional operations are defined on objects for locking purposes, which are not shown in Figure 12.5. \\nWe discuss locking concepts for databases in Chapter 22.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 406, 'page_label': '407'}, page_content='12.3 The ODMG Object Model and the Object Definition Language ODL  393\\n12.3.2 Inheritance in the Object Model of ODMG\\nIn the ODMG object model, two types of inheritance relationships exist: behavior-\\nonly inheritance and state plus behavior inheritance. Behavior inheritance   \\nis also known as ISA or interface inheritance  and is specified by the colon (:) \\nnotation. 26 Hence, in the ODMG object model, behavior inheritance requires \\nthe supertype to be an interface, whereas the subtype could be either a class or \\nanother interface.\\nThe other inheritance relationship, called EXTENDS inheritance, is specified by the \\nkeyword extends. It is used to inherit both state and behavior strictly among classes, \\nso both the supertype and the subtype must be classes. Multiple inheritance via \\nextends is not permitted. However, multiple inheritance is allowed for behavior \\ninheritance via the colon (:) notation. Hence, an interface may inherit behavior \\nfrom several other interfaces. A class may also inherit behavior from several inter-\\nfaces via colon (:) notation, in addition to inheriting behavior and state from at \\nmost one other class via \\nextends. In Section 12.3.4 we will give examples of how these \\ntwo inheritance relationships—“:” and extends—may be used.\\n12.3.3 Built-in Interfaces and Classes in the Object Model\\nFigure 12.5 shows the built-in interfaces of the object model. All interfaces, such as \\nCollection, Date, and Time, inherit the basic Object interface. In the object model, \\nthere is a distinction between collections, whose state contains multiple objects or \\nliterals, versus atomic (and structured) objects, whose state is an individual object \\nor literal. Collection objects  inherit the basic \\nCollection interface shown in Fig- \\nure 12.5(c), which shows the operations for all collection objects. Given a collection \\nobject O, the O\\n.cardinality() operation returns the number of elements in the collec-\\ntion. The operation O.is_empty () returns true if the collection O is empty, and \\nreturns false otherwise. The operations O.insert_element(E) and O.remove_element(E) \\ninsert or remove an element E from the collection O. Finally, the operation  \\nO.contains_element (E) returns true if the collection O includes element E, and \\nreturns false otherwise. The operation I = O.create_iterator () creates an iterator \\nobject I for the collection object O, which can iterate over each element in the  \\ncollection. The interface for iterator objects is also shown in Figure 12.5(c). The  \\nI\\n.reset() operation sets the iterator at the first element in a collection (for an unor-\\ndered collection, this would be some arbitrary element), and I.next_position() sets the \\niterator to the next element. The I.get_element () retrieves the current element , \\nwhich is the element at which the iterator is currently positioned.\\nThe ODMG object model uses exceptions for reporting errors or particular condi-\\ntions. For example, the ElementNotFound exception in the Collection interface would be \\nraised by the O.remove_element(E) operation if E is not an element in the collection O. \\n26The ODMG report also calls interface inheritance as type/subtype, is-a, and generalization/specializa-\\ntion relationships, although in the literature these terms have been used to describe inheritance of both \\nstate and operations (see Chapter 8 and Section 12.1).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 407, 'page_label': '408'}, page_content='394 Chapter 12 Object and Object-Relational Databases\\nThe NoMoreElements  exception in the iterator interface would be raised by the  \\nI.next_position() operation if the iterator is currently positioned at the last element in \\nthe collection, and hence no more elements exist for the iterator to point to.\\nCollection objects are further specialized into set, list, bag, array, and dictionary, which \\ninherit the operations of the Collection interface. A set<T> type generator  can be \\nused to create objects such that the value of object O is a set whose elements are of \\ntype T.  The Set interface includes the additional operation P = O.create_union(S) \\n(see Figure 12.5(c)), which returns a new object P of type set<T> that is the union of \\nthe two sets O and S. Other operations similar to create_union (not shown in Fig- \\nure 12.5(c)) are create_intersection(S) and create_difference(S). Operations for set com-\\nparison include the O.is_subset_of(S) operation, which returns true if the set object \\nO is a subset of some other set object S, and returns false otherwise. Similar opera-\\ntions (not shown in Figure 12.5(c)) are is_proper_subset_of(S), is_superset_of(S), and \\nis_proper_superset_of(S). The bag<T> type generator  allows duplicate elements in \\nthe collection and also inherits the Collection interface. It has three operations—\\ncreate_union(b), create_intersection(b), and create_difference(b)—that all return a new \\nobject of type bag<T>.\\nA list<T> type generator inherits the Collection operations and can be used to create \\ncollections of objects of type T where the order of the elements is important. The \\nvalue of each such object O is an ordered list whose elements are of type T. Hence, we \\ncan refer to the first, last, and ith element in the list. Also, when we add an element to \\nthe list, we must specify the position in the list where the element is inserted. Some of \\nthe \\nlist operations are shown in Figure 12.5(c). If O is an object of type list<T>, the \\noperation O.insert_element_first(E) inserts the element E before the first element in the \\nlist O, so that E becomes the first element in the list. A similar operation (not shown) \\nis O.insert_element_last(E). The operation O.insert_element_after(E, I) in Figure 12.5(c) \\ninserts the element E after the ith element in the list O and will raise the exception \\nInvalidIndex  if no ith element exists in O. A similar operation (not shown) is \\nO.insert_element_before(E, I). To remove elements from the list, the operations are  \\nE = O.remove_first_element(), E = O.remove_last_element(), and E = O.remove_element _at(I); \\nthese operations remove the indicated element from the list and return the element as \\nthe operation’s result. Other operations retrieve an element without removing it from \\nthe list. These are E = O.retrieve_first_element (), E = O.retrieve _last_element (), and  \\nE = O.retrieve_element_at(I). Also, two operations to manipulate lists are defined. They \\nare P = O.concat(I), which creates a new list P that is the concatenation of lists O and I \\n(the elements in list O followed by those in list I), and O.append(I), which appends \\nthe elements of list I to the end of list O (without creating a new list object).\\nThe array<T> type generator also inherits the Collection operations and is similar to \\nlist. Specific operations for an array object O are O.replace_element_at(I, E), which \\nreplaces the array element at position I with element E; E = O.remove_element_at(I), \\nwhich retrieves the ith element and replaces it with a NULL  value; and  \\nE = O.retrieve_element_at(I), which simply retrieves the ith element of the array. Any \\nof these operations can raise the exception InvalidIndex if I is greater than the array’s \\nsize. The operation O.resize(N) changes the number of array elements to N.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 408, 'page_label': '409'}, page_content='12.3 The ODMG Object Model and the Object Definition Language ODL  395\\nThe last type of collection objects are of type dictionary<K,V>. This allows the cre-\\nation of a collection of association pairs <K,V>, where all K (key) values are unique. \\nMaking the key values unique allows for associative retrieval of a particular pair \\ngiven its key value (similar to an index). If O is a collection object of type \\ndictionary <K,V>, then O.bind(K,V) binds value V to the key K as an association \\n<K,V> in the collection, whereas O.unbind(K) removes the association with key K \\nfrom O, and V = O.lookup(K) returns the value V associated with key K in O. The \\nlatter two operations can raise the exception KeyNotFound. Finally, O.contains_key(K) \\nreturns true if key K exists in O, and returns false otherwise.\\nFigure 12.6 is a diagram that illustrates the inheritance hierarchy of the built-in \\nconstructs of the object model. Operations are inherited from the supertype to the \\nsubtype. The collection interfaces described above are not directly instantiable; that \\nis, one cannot directly create objects based on these interfaces. Rather, the inter-\\nfaces can be used to generate user-defined collection types—of type \\nset, bag, list, \\narray, or dictionary—for a particular database application. If an attribute or class has \\na collection type, say a set, then it will inherit the operations of the set interface. For \\nexample, in a UNIVERSITY  database application, the user can specify a type for \\nset<STUDENT>, whose state would be sets of STUDENT objects. The programmer \\ncan then use the operations for set<T> to manipulate an object of type \\nset<STUDENT>. Creating application classes is typically done by utilizing the object \\ndefinition language ODL (see Section 12.3.6).\\nIt is important to note that all objects in a particular collection must be of the same \\ntype. Hence, although the keyword any appears in the specifications of collection \\ninterfaces in Figure 12.5(c), this does not mean that objects of any type can be inter-\\nmixed within the same collection. Rather, it means that any type can be used when \\nspecifying the type of elements for a particular collection (including other collec-\\ntion types!).\\n12.3.4 Atomic (User-Defined) Objects\\nThe previous section described the built-in collection types of the object model. \\nNow we discuss how object types for atomic objects can be constructed. These are \\nCollection\\nObject\\nIterator Date Interval Time\\nset list bag dictionary\\nTimestamp\\narray\\nFigure 12.6 \\nInheritance hierarchy for the built-in \\ninterfaces of the object model.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 409, 'page_label': '410'}, page_content='396 Chapter 12 Object and Object-Relational Databases\\nspecified using the keyword class in ODL. In the object model, any user-defined \\nobject that is not a collection object is called an atomic object.27\\nFor example, in a UNIVERSITY database application, the user can specify an object \\ntype (class) for STUDENT objects. Most such objects will be structured objects; for \\nexample, a STUDENT object will have a complex structure, with many attributes, \\nrelationships, and operations, but it is still considered atomic because it is not a \\ncollection. Such a user-defined atomic object type is defined as a class by specify-\\ning its properties and operations. The properties define the state of the object and \\nare further distinguished into attributes and relationships. In this subsection, we \\nelaborate on the three types of components—attributes, relationships, and \\n operations—that a user-defined object type for atomic (structured) objects can \\ninclude. We illustrate our discussion with the two classes \\nEMPLOYEE and DEPARTMENT \\nshown in Figure 12.7.\\nAn attribute is a property that describes some aspect of an object. Attributes have \\nvalues (which are typically literals having a simple or complex structure) that are \\nstored within the object. However, attribute values can also be \\nObject_ids of other \\nobjects. Attribute values can even be specified via methods that are used to calculate \\nthe attribute value. In Figure 12.7 28 the attributes for EMPLOYEE are Name, Ssn, \\nBirth_date , Sex, and Age, and those for DEPARTMENT  are Dname, Dnumber, Mgr,  \\nLocations, and Projs. The Mgr and Projs attributes of DEPARTMENT have complex \\nstructure and are defined via struct, which corresponds to the tuple constructor of \\nSection 12.1.3. Hence, the value of Mgr in each DEPARTMENT object will have two \\ncomponents: Manager, whose value is an Object_id that references the EMPLOYEE \\nobject that manages the DEPARTMENT, and Start_date, whose value is a date. The \\nlocations attribute of DEPARTMENT is defined via the set constructor, since each \\nDEPARTMENT object can have a set of locations.\\nA relationship is a property that specifies that two objects in the database are related. \\nIn the object model of ODMG, only binary relationships (see Section 3.4) are \\nexplicitly represented, and each binary relationship is represented by a pair of \\ninverse references specified via the keyword relationship. In Figure 12.7, one rela-\\ntionship exists that relates each EMPLOYEE to the DEPARTMENT in which he or she \\nworks—the Works_for relationship of EMPLOYEE. In the inverse direction, each \\nDEPARTMENT is related to the set of EMPLOYEES that work in the DEPARTMENT—\\nthe Has_emps relationship of DEPARTMENT. The keyword inverse specifies that \\nthese two properties define a single conceptual relationship in inverse directions.29\\nBy specifying inverses, the database system can maintain the referential integrity of \\nthe relationship automatically. That is, if the value of \\nWorks_for for a particular \\n27As mentioned earlier, this definition of atomic object in the ODMG object model is different from the \\ndefinition of atom constructor given in Section 12.1.3, which is the definition used in much of the object-\\noriented database literature.\\n28We are using the Object Definition Language (ODL) notation in Figure 12.7 , which will be discussed in \\nmore detail in Section 12.3.6.\\n29Section 7 .4 discusses how a relationship can be represented by two attributes in inverse directions.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 410, 'page_label': '411'}, page_content='12.3 The ODMG Object Model and the Object Definition Language ODL  397\\nEMPLOYEE E refers to DEPARTMENT D, then the value of Has_emps for DEPARTMENT \\nD must include a reference to E in its set of EMPLOYEE references. If the database \\ndesigner desires to have a relationship to be represented in only one direction, then \\nit has to be modeled as an attribute (or operation). An example is the Manager com-\\nponent of the Mgr attribute in DEPARTMENT.\\nIn addition to attributes and relationships, the designer can include operations in \\nobject type (class) specifications. Each object type can have a number of operation \\nsignatures, which specify the operation name, its argument types, and its returned \\nvalue, if applicable. Operation names are unique within each object type, but they \\ncan be overloaded by having the same operation name appear in distinct object \\ntypes. The operation signature can also specify the names of exceptions  that  \\ncan occur during operation execution. The implementation of the operation  \\nwill include the code to raise these exceptions. In Figure 12.7 the \\nEMPLOYEE class \\nclass EMPLOYEE\\n( extent ALL_EMPLOYEES\\n key Ssn )\\n{\\n attribute string Name;\\n attribute string Ssn;\\n attribute date Birth_date;\\n attribute enum Gender{M, F} Sex;\\n attribute short Age;\\n relationship DEPARTMENT Works_for\\n   inverse DEPARTMENT::Has_emps;\\n void reassign_emp(in string New_dname)\\n   raises(dname_not_valid);\\n};\\nclass DEPARTMENT\\n( extent ALL_DEPARTMENTS\\n key Dname, Dnumber )\\n{\\n attribute string Dname;\\n attribute short Dnumber;\\n attribute struct Dept_mgr {EMPLOYEE Manager, date Start_date}\\n   Mgr;\\n attribute set<string> Locations;\\n attribute struct Projs {string Proj_name, time Weekly_hours)\\n   Projs;\\n relationship set<EMPLOYEE> Has_emps inverse EMPLOYEE::Works_for;\\n void add_emp(in string New_ename) raises(ename_not_valid);\\n void change_manager(in string New_mgr_name; in date\\n   Start_date);\\n};\\nFigure 12.7 \\nThe attributes, relationships, \\nand operations in a class \\ndefinition.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 411, 'page_label': '412'}, page_content='398 Chapter 12 Object and Object-Relational Databases\\nhas one operation: reassign_emp, and the DEPARTMENT class has two operations: \\nadd_emp and change_manager .\\n12.3.5 Extents, Keys, and Factory Objects\\nIn the ODMG object model, the database designer can declare an extent (using the \\nkeyword extent) for any object type that is defined via a class declaration. The extent \\nis given a name, and it will contain all persistent objects of that class. Hence, the \\nextent behaves as a set object  that holds all persistent objects of the class. In Fig- \\nure 12.7 the EMPLOYEE and DEPARTMENT classes have extents called ALL_EMPLOYEES \\nand ALL_DEPARTMENTS, respectively. This is similar to creating two objects—one \\nof type set<EMPLOYEE> and the second of type set<DEPARTMENT>—and making \\nthem persistent by naming them ALL_EMPLOYEES and ALL_DEPARTMENTS. Extents \\nare also used to automatically enforce the set/subset relationship between the \\nextents of a supertype and its subtype. If two classes \\nA and B have extents ALL_A and \\nALL_B, and class B is a subtype of class A (that is, class B extends class A), then the \\ncollection of objects in ALL_B must be a subset of those in ALL_A at any point. This \\nconstraint is automatically enforced by the database system.\\nA class with an extent can have one or more keys. A key consists of one or more \\nproperties (attributes or relationships) whose values are constrained to be unique \\nfor each object in the extent. For example, in Figure 12.7 the \\nEMPLOYEE class has \\nthe Ssn attribute as key (each EMPLOYEE object in the extent must have a unique \\nSsn value), and the DEPARTMENT class has two distinct keys: Dname and Dnumber \\n(each DEPARTMENT  must have a unique Dname and a unique Dnumber ). For a \\ncomposite key 30 that is made of several properties, the properties that form the \\nkey are contained in parentheses. For example, if a class VEHICLE with an extent \\nALL_VEHICLES  has a key made up of a combination of two attributes State and \\nLicense_number , they would be placed in parentheses as ( State, License_number ) in \\nthe key declaration.\\nNext, we present the concept of factory object—an object that can be used to gen-\\nerate or create individual objects via its operations. Some of the interfaces of factory \\nobjects that are part of the ODMG object model are shown in Figure 12.8. The \\ninterface \\nObjectFactory has a single operation, new(), which returns a new object \\nwith an Object_id. By inheriting this interface, users can create their own factory \\ninterfaces for each user-defined (atomic) object type, and the programmer can \\nimplement the operation new differently for each type of object. Figure 12.8 also \\nshows a \\nDateFactory interface, which has additional operations for creating a new \\ncalendar_date and for creating an object whose value is the current_date, among other \\noperations (not shown in Figure 12.8). As we can see, a factory object basically pro-\\nvides the constructor operations for new objects.\\nFinally, we discuss the concept of a database. Because an ODB system can create \\nmany different databases, each with its own schema, the ODMG object model has \\n30A composite key is called a compound key in the ODMG report.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 412, 'page_label': '413'}, page_content='12.3 The ODMG Object Model and the Object Definition Language ODL  399\\ninterface ObjectFactory {\\n Object new();\\n};\\ninterface SetFactory : ObjectFactory {\\n Set new_of_size(in long size);\\n};\\ninterface ListFactory : ObjectFactory {\\n List new_of_size(in long size);\\n};\\ninterface ArrayFactory : ObjectFactory {\\n Array new_of_size(in long size);\\n};\\ninterface DictionaryFactory : ObjectFactory {\\n Dictionary new_of_size(in long size);\\n};\\ninterface DateFactory : ObjectFactory {\\n exception InvalidDate{};\\n …\\n Date calendar_date( in unsigned short year,\\n    in unsigned short month,\\n    in unsigned short day )\\n  raises(InvalidDate);\\n …\\n Date current();\\n};\\ninterface DatabaseFactory {\\n Database new();\\n};\\ninterface Database {\\n …\\n void open(in string database_name)\\n   raises(DatabaseNotFound, DatabaseOpen);\\n void close() raises(DatabaseClosed, …);\\n void bind(in Object an_object, in string name)\\n   raises(DatabaseClosed, ObjectNameNotUnique, …);\\n Object unbind(in string name)\\n   raises(DatabaseClosed, ObjectNameNotFound, …);\\n Object Iookup(in string object_name)\\n   raises(DatabaseClosed, ObjectNameNotFound, …);\\n … };\\nFigure 12.8 \\nInterfaces to illustrate factory \\nobjects and database objects.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 413, 'page_label': '414'}, page_content='400 Chapter 12 Object and Object-Relational Databases\\ninterfaces for DatabaseFactory and Database objects, as shown in Figure 12.8. Each \\ndatabase has its own database name, and the bind operation can be used to assign \\nindividual unique names to persistent objects in a particular database. The lookup \\noperation returns an object from the database that has the specified persistent \\nobject_name, and the unbind operation removes the name of a persistent named \\nobject from the database.\\n12.3.6 The Object Definition Language ODL\\nAfter our overview of the ODMG object model in the previous section, we now \\nshow how these concepts can be utilized to create an object database schema using \\nthe object definition language ODL.\\n31\\nThe ODL is designed to support the semantic constructs of the ODMG object \\nmodel and is independent of any particular programming language. Its main use is \\nto create object specifications—that is, classes and interfaces. Hence, ODL is not a \\nprogramming language. A user can specify a database schema in ODL indepen-\\ndently of any programming language, and then use the specific language bindings \\nto specify how ODL constructs can be mapped to constructs in specific program-\\nming languages, such as C++, Smalltalk, and Java. We will give an overview of the \\nC++ binding in Section 12.6.\\nFigure 12.9(b) shows a possible object schema for part of the \\nUNIVERSITY data-\\nbase, which was presented in Chapter 4. We will describe the concepts of ODL \\nusing this example, and the one in Figure 12.11. The graphical notation for Fig-\\nure 12.9(b) is shown in Figure 12.9(a) and can be considered as a variation of EER \\ndiagrams (see Chapter 4) with the added concept of interface inheritance but \\nwithout several EER concepts, such as categories (union types) and attributes of \\nrelationships.\\nFigure 12.10 shows one possible set of ODL class definitions for the \\nUNIVERSITY \\ndatabase. In general, there may be several possible mappings from an object schema \\ndiagram (or EER schema diagram) into ODL classes. We will discuss these options \\nfurther in Section 12.4.\\nFigure 12.10 shows the straightforward way of mapping part of the \\nUNIVERSITY  \\ndatabase from Chapter 4. Entity types are mapped into ODL classes, and inher-\\nitance is done using \\nextends. However, there is no direct way to map categories \\n(union types) or to do multiple inheritance. In Figure 12.10 the classes  \\nPERSON, FACULTY , STUDENT , and GRAD_STUDENT  have the extents PERSONS , \\nFACULTY , STUDENTS , and GRAD_STUDENTS , respectively. Both FACULTY  and \\nSTUDENT  extends PERSON and GRAD_STUDENT  extends STUDENT . Hence, the \\ncollection of STUDENTS  (and the collection of FACULTY ) will be constrained to \\nbe a subset of the collection of PERSONs at any time. Similarly, the collection of \\n31The ODL syntax and data types are meant to be compatible with the Interface Definition language \\n(IDL) of CORBA (Common Object Request Broker Architecture), with extensions for relationships and \\nother database concepts.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 414, 'page_label': '415'}, page_content='12.3 The ODMG Object Model and the Object Definition Language ODL  401\\n(a)\\n(b)\\nPerson-IFInterface\\nSTUDENTClass\\nPERSON\\nWorks_in\\nHas_faculty\\nHas_majors\\nDEPARTMENT\\nGRAD_STUDENT\\nRegistered_in\\nFACUL TY STUDENT\\nAdvisor\\nCommittee\\nAdvises\\nCOURSE\\nOffered_by\\nMajors_in\\nCompleted_sections\\nHas_sections\\nStudents\\nOf_course\\nOffers\\nSECTION\\nRegistered_students\\nOn_committee_of\\nCURR_SECTION\\nRelationships\\n1:1\\n1:N\\nM:N\\nInheritance\\nInterface(is-a)\\ninheritance\\nusing “:”\\nClass inheritance\\nusing extends\\nFigure 12.9 \\nAn example of a database schema.  \\n(a) Graphical notation for representing ODL \\nschemas. (b) A graphical object database \\nschema for part of the UNIVERSITY  \\ndatabase (GRADE and DEGREE classes \\nare not shown).\\nGRAD_STUDENT s will be a subset of STUDENT s. At the same time, individual \\nSTUDENT  and FACULTY  objects will inherit the properties (attributes and rela-\\ntionships) and operations of PERSON, and individual GRAD_STUDENT  objects \\nwill inherit those of STUDENT .\\nThe classes DEPARTMENT, COURSE, SECTION, and CURR_SECTION in Figure 12.10 \\nare straightforward mappings of the corresponding entity types in Figure 12.9(b).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 415, 'page_label': '416'}, page_content='402 Chapter 12 Object and Object-Relational Databases\\nclass PERSON\\n( extent PERSONS\\n key Ssn )\\n{ attribute struct Pname { string Fname,\\n    string Mname,\\n    string Lname } Name;\\n attribute string   Ssn;\\n attribute date    Birth_date;\\n attribute enum Gender{M, F}   Sex;\\n attribute struct Address { short No,\\n    string Street,\\n    short Apt_no,\\n    string City,\\n    string State,\\n    short Zip } Address;\\n short Age(); };\\nclass FACULTY extends PERSON\\n( extent FACULTY )\\n{ attribute string Rank;\\n attribute float  Salary;\\n attribute string Office;\\n attribute string Phone;\\n relationship DEPARTMENT Works_in inverse DEPARTMENT::Has faculty;\\n relationship set<GRAD_STUDENT> Advises inverse GRAD_STUDENT::Advisor;\\n relationship set<GRAD_STUDENT> On_committee_of inverse GRAD_STUDENT::Committee;\\n void give_raise(in float raise);\\n void promote(in string new rank); };\\nclass GRADE\\n( extent GRADES )\\n{\\n attribute enum GradeValues{A,B,C,D,F,l, P} Grade;\\n relationship SECTION Section inverse SECTION::Students;\\n relationship STUDENT Student inverse STUDENT::Completed_sections; };\\nclass STUDENT extends PERSON\\n( extent STUDENTS )\\n{ attribute string Class;\\n attribute Department Minors_in;\\n relationship Department Majors_in inverse DEPARTMENT::Has_majors;\\n relationship set<GRADE> Completed_sections inverse GRADE::Student;\\n relationship set<CURR_SECTION> Registered_in INVERSE CURR_SECTION::Registered_students;\\n void change_major(in string dname) raises(dname_not_valid);\\n float gpa();\\n void register(in short secno) raises(section_not_valid);\\n void assign_grade(in short secno; IN GradeValue grade)\\n   raises(section_not_valid,grade_not_valid); };\\nFigure 12.10 \\nPossible ODL schema for the UNIVERSITY database in Figure 12.8(b).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 416, 'page_label': '417'}, page_content='12.3 The ODMG Object Model and the Object Definition Language ODL  403\\nclass DEGREE\\n{ attribute string College;\\n attribute string Degree; \\n attribute string Year; };\\nclass GRAD_STUDENT extends STUDENT\\n( extent GRAD_STUDENTS )\\n{ attribute set<Degree> Degrees;\\n relationship Faculty advisor inverse FACULTY::Advises;\\n relationship set<FACULTY> Committee inverse FACULTY::On_committee_of;\\n void assign_advisor(in string Lname; in string Fname)\\n   raises(facuIty_not_valid);\\n void assign_committee_member(in string Lname; in string Fname)\\n   raises(facuIty_not_valid); };\\nclass DEPARTMENT\\n( extent DEPARTMENTS\\n key Dname )\\n{ attribute string Dname;\\n attribute string Dphone;\\n attribute string Doffice;\\n attribute string College;\\n attribute FACULTY Chair;\\n relationship set<FACULTY> Has_faculty inverse FACULTY::Works_in;\\n relationship set<STUDENT> Has_majors inverse STUDENT::Majors_in;\\n relationship set<COURSE> Offers inverse COURSE::Offered_by; };\\nclass COURSE\\n( extent COURSES\\n key Cno )\\n{ attribute string Cname;\\n attribute string Cno;\\n attribute string Description;\\n relationship set<SECTION> Has_sections inverse SECTION::Of_course;\\n relationship <DEPARTMENT> Offered_by inverse DEPARTMENT::Offers; };\\nclass SECTION\\n( extent SECTIONS )\\n{ attribute short Sec_no; \\n attribute string  Year;\\n attribute enum Quarter{Fall, Winter, Spring, Summer}\\n   Qtr;\\n relationship set<Grade> Students inverse Grade::Section;\\n relationship COURSE Of_course inverse COURSE::Has_sections; };\\nclass CURR_SECTION extends SECTION\\n( extent CURRENT_SECTIONS )\\n{ relationship set<STUDENT> Registered_students\\n   inverse STUDENT::Registered_in\\n void register_student(in string Ssn)\\n   raises(student_not_valid, section_full); };\\nFigure 12.10 (continued)\\nPossible ODL schema for the UNIVERSITY database in Figure 12.8(b).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 417, 'page_label': '418'}, page_content='404 Chapter 12 Object and Object-Relational Databases\\nHowever, the class GRADE requires some explanation. The GRADE class corre-\\nsponds to the M:N relationship between STUDENT and SECTION in Figure 12.9(b). \\nThe reason it was made into a separate class (rather than as a pair of inverse rela-\\ntionships) is because it includes the relationship attribute \\nGrade.32\\nHence, the M:N relationship is mapped to the class GRADE, and a pair of 1:N rela-\\ntionships, one between STUDENT and GRADE and the other between SECTION and \\n32We will discuss alternative mappings for attributes of relationships in Section 12.4.\\nTRIANGLE\\nGeometryObject\\nCIRCLERECT ANGLE . . . \\nFigure 12.11 \\nAn illustration of  \\ninterface inheritance \\nvia “:”. (a) Graphical \\nschema representation,  \\n(b) Corresponding \\ninterface and class \\ndefinitions in ODL.\\n(b) interface GeometryObject\\n { attribute enum Shape{RECTANGLE, TRIANGLE, CIRCLE, … } \\n     Shape;\\n  attribute struct Point {short x, short y} Reference_point;\\n  float perimeter();\\n  float area();\\n  void translate(in short x_translation; in short y_translation);\\n  void rotate(in float angle_of_rotation); };\\n class RECTANGLE : GeometryObject\\n ( extent RECTANGLES )\\n { attribute struct Point {short x, short y} Reference_point;\\n  attribute short Length;\\n  attribute short Height;\\n  attribute float Orientation_angle; };\\n class TRIANGLE : GeometryObject\\n ( extent TRIANGLES )\\n { attribute struct Point {short x, short y} Reference_point;\\n  attribute short Side_1;\\n  attribute short Side_2;\\n  attribute float Side1_side2_angle;\\n  attribute float Side1_orientation_angle; };\\n class CIRCLE : GeometryObject\\n ( extent CIRCLES )\\n { attribute struct Point {short x, short y} Reference_point;\\n  attribute short Radius; };\\n …\\n(a)'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 418, 'page_label': '419'}, page_content='12.4 Object Database Conceptual Design  405\\nGRADE.33 These relationships are represented by the following relationship proper-\\nties: Completed_sections of STUDENT; Section and Student of GRADE; and Students of \\nSECTION (see Figure 12.10). Finally, the class DEGREE is used to represent the com-\\nposite, multivalued attribute degrees of GRAD_STUDENT (see Figure 8.10).\\nBecause the previous example does not include any interfaces, only classes, we now \\nutilize a different example to illustrate interfaces and interface (behavior) inheri-\\ntance. Figure 12.11(a) is part of a database schema for storing geometric objects. An \\ninterface \\nGeometryObject is specified, with operations to calculate the perimeter and \\narea of a geometric object, plus operations to translate (move) and rotate an object. \\nSeveral classes ( RECTANGLE, TRIANGLE, CIRCLE, …) inherit the GeometryObject  \\ninterface. Since GeometryObject  is an interface, it is noninstantiable —that is, no \\nobjects can be created based on this interface directly. However, objects of type \\nRECTANGLE, TRIANGLE, CIRCLE, … can be created, and these objects inherit all the \\noperations of the GeometryObject  interface. Note that with interface inheritance, \\nonly operations are inherited, not properties (attributes, relationships). Hence, if a \\nproperty is needed in the inheriting class, it must be repeated in the class defini-\\ntion, as with the \\nReference_point attribute in Figure 12.11(b). Notice that the inher-\\nited operations can have different implementations in each class. For example, the \\nimplementations of the area and perimeter  operations may be different for \\nRECTANGLE, TRIANGLE, and CIRCLE.\\nMultiple inheritance of interfaces by a class is allowed, as is multiple inheritance of \\ninterfaces by another interface. However, with extends (class) inheritance, multiple \\ninheritance is not permitted. Hence, a class can inherit via extends from at most one \\nclass (in addition to inheriting from zero or more interfaces).\\n12.4 Object Database Conceptual Design\\nSection 12.4.1 discusses how object database (ODB) design differs from relational \\ndatabase (RDB) design. Section 12.4.2 outlines a mapping algorithm that can be \\nused to create an ODB schema, made of ODMG ODL class definitions, from a con-\\nceptual EER schema.\\n12.4.1 Differences between Conceptual Design  \\nof ODB and RDB\\nOne of the main differences between ODB and RDB design is how relationships are \\nhandled. In ODB, relationships are typically handled by having relationship prop-\\nerties or reference attributes that include OID(s) of the related objects. These can be \\nconsidered as OID references to the related objects. Both single references and col-\\nlections of references are allowed. References for a binary relationship can be \\n33This is similar to how an M:N relationship is mapped in the relational model (see Section 9.1) and in \\nthe legacy network model (see Appendix E).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 419, 'page_label': '420'}, page_content='406 Chapter 12 Object and Object-Relational Databases\\ndeclared in a single direction, or in both directions, depending on the types of \\naccess expected. If declared in both directions, they may be specified as inverses of \\none another, thus enforcing the ODB equivalent of the relational referential integ-\\nrity constraint.\\nIn RDB, relationships among tuples (records) are specified by attributes with \\nmatching values. These can be considered as value references and are specified via \\nforeign keys,  which are values of primary key attributes repeated in tuples of the \\nreferencing relation. These are limited to being single-valued in each record because \\nmultivalued attributes are not permitted in the basic relational model. Thus, M:N \\nrelationships must be represented not directly, but as a separate relation (table), as \\ndiscussed in Section 9.1.\\nMapping binary relationships that contain attributes is not straightforward in \\nODBs, since the designer must choose in which direction the attributes should be \\nincluded. If the attributes are included in both directions, then redundancy in stor-\\nage will exist and may lead to inconsistent data. Hence, it is sometimes preferable to \\nuse the relational approach of creating a separate table by creating a separate class \\nto represent the relationship. This approach can also be used for n-ary relation-\\nships, with degree n > 2.\\nAnother major area of difference between ODB and RDB design is how inheritance \\nis handled. In ODB, these structures are built into the model, so the mapping is \\nachieved by using the inheritance constructs, such as derived (:) and \\nextends. In \\nrelational design, as we discussed in Section 9.2, there are several options to choose \\nfrom since no built-in construct exists for inheritance in the basic relational model. \\nIt is important to note, though, that object-relational and extended-relational sys-\\ntems are adding features to model these constructs directly as well as to include \\noperation specifications in abstract data types (see Section 12.2).\\nThe third major difference is that in ODB design, it is necessary to specify the oper-\\nations early on in the design since they are part of the class specifications. Although \\nit is important to specify operations during the design phase for all types of data-\\nbases, the design of operations may be delayed in RDB design as it is not strictly \\nrequired until the implementation phase.\\nThere is a philosophical difference between the relational model and the object \\nmodel of data in terms of behavioral specification. The relational model does not \\nmandate the database designers to predefine a set of valid behaviors or operations, \\nwhereas this is a tacit requirement in the object model. One of the claimed advan-\\ntages of the relational model is the support of ad hoc queries and transactions, \\nwhereas these are against the principle of encapsulation.\\nIn practice, it is becoming commonplace to have database design teams apply \\nobject-based methodologies at early stages of conceptual design so that both the \\nstructure and the use or operations of the data are considered, and a complete spec-\\nification is developed during conceptual design. These specifications are then \\nmapped into relational schemas, constraints, and behavioral artifacts such as trig-\\ngers or stored procedures (see Sections 5.2 and 13.4).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 420, 'page_label': '421'}, page_content='12.4 Object Database Conceptual Design  407\\n12.4.2 Mapping an EER Schema to an ODB Schema\\nIt is relatively straightforward to design the type declarations of object classes \\nfor an ODBMS from an EER schema that contains neither  categories nor n -ary \\nrelationships with n > 2. However, the operations of classes are not specified in \\nthe EER diagram and must be added to the class declarations after the struc-\\ntural mapping is completed. The outline of the mapping from EER to ODL is \\nas follows:\\nStep 1. Create an ODL class for each EER entity type or subclass. The type of the \\nODL class should include all the attributes of the EER class.\\n34 Multivalued attributes \\nare typically declared by using the set, bag, or list constructors.35 If the values of the \\nmultivalued attribute for an object should be ordered, the list constructor is chosen; \\nif duplicates are allowed, the bag constructor should be chosen; otherwise, the set \\nconstructor is chosen. Composite attributes are mapped into a tuple constructor (by \\nusing a struct declaration in ODL).\\nDeclare an extent for each class, and specify any key attributes as keys of the extent.\\nStep 2. Add relationship properties or reference attributes for each binary relation-\\nship into the ODL classes that participate in the relationship. These may be created \\nin one or both directions. If a binary relationship is represented by references in both \\ndirections, declare the references to be relationship properties that are inverses of \\none another, if such a facility exists.\\n36 If a binary relationship is represented by a \\nreference in only one direction, declare the reference to be an attribute in the refer-\\nencing class whose type is the referenced class name.\\nDepending on the cardinality ratio of the binary relationship, the relationship \\nproperties or reference attributes may be single-valued or collection types. They \\nwill be single-valued  for binary relationships in the 1:1 or N:1 directions; they will \\nbe collection types  (set-valued or list-valued\\n37) for relationships in the 1:N or \\nM:N direction. An alternative way to map binary M:N relationships is discussed in \\nstep 7.\\nIf relationship attributes exist, a tuple constructor (\\nstruct) can be used to create a \\nstructure of the form < reference, relationship attributes >, which may be included \\ninstead of the reference attribute. However, this does not allow the use of the inverse \\nconstraint. Additionally, if this choice is represented in both directions, the attribute \\nvalues will be represented twice, creating redundancy.\\n34This implicitly uses a tuple constructor at the top level of the type declaration, but in general, the tuple \\nconstructor is not explicitly shown in the ODL class declarations.\\n35Further analysis of the application domain is needed to decide which constructor to use because this \\ninformation is not available from the EER schema.\\n36The ODL standard provides for the explicit definition of inverse relationships. Some ODBMS products \\nmay not provide this support; in such cases, programmers must maintain every relationship explicitly by \\ncoding the methods that update the objects appropriately.\\n37The decision whether to use set or list is not available from the EER schema and must be determined \\nfrom the requirements.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 421, 'page_label': '422'}, page_content='408 Chapter 12 Object and Object-Relational Databases\\nStep 3. Include appropriate operations for each class. These are not available from \\nthe EER schema and must be added to the database design by referring to the origi-\\nnal requirements. A constructor method should include program code that checks \\nany constraints that must hold when a new object is created. A destructor method \\nshould check any constraints that may be violated when an object is deleted. Other \\nmethods should include any further constraint checks that are relevant.\\nStep 4. An ODL class that corresponds to a subclass in the EER schema inherits (via \\nextends) the attributes, relationships, and methods of its superclass in the ODL \\nschema. Its specific (local) attributes, relationship references, and operations are \\nspecified, as discussed in steps 1, 2, and 3.\\nStep 5. Weak entity types can be mapped in the same way as regular entity types. \\nAn alternative mapping is possible for weak entity types that do not participate in \\nany relationships except their identifying relationship; these can be mapped as \\nthough they were composite multivalued attributes of the owner entity type, by using \\nthe \\nset<struct<…>> or list<struct<…>> constructors. The attributes of the weak entity \\nare included in the struct<…> construct, which corresponds to a tuple constructor. \\nAttributes are mapped as discussed in steps 1 and 2.\\nStep 6. Categories (union types) in an EER schema are difficult to map to ODL. It is \\npossible to create a mapping similar to the EER-to-relational mapping (see Sec- \\ntion 9.2) by declaring a class to represent the category and defining 1:1 relationships \\nbetween the category and each of its superclasses.\\nStep 7. An n-ary relationship with degree n > 2 can be mapped into a separate class, \\nwith appropriate references to each participating class. These references are based on \\nmapping a 1:N relationship from each class that represents a participating entity \\ntype to the class that represents the n-ary relationship. An M:N binary relationship, \\nespecially if it contains relationship attributes, may also use this mapping option, \\nif desired.\\nThe mapping has been applied to a subset of the \\nUNIVERSITY database schema in \\nFigure 4.10 in the context of the ODMG object database standard. The mapped \\nobject schema using the ODL notation is shown in Figure 12.10.\\n12.5 The Object Query Language OQL\\nThe object query language OQL is the query language proposed for the ODMG \\nobject model. It is designed to work closely with the programming languages for \\nwhich an ODMG binding is defined, such as C++, Smalltalk, and Java. Hence, an \\nOQL query embedded into one of these programming languages can return objects \\nthat match the type system of that language. Additionally, the implementations of \\nclass operations in an ODMG schema can have their code written in these pro-\\ngramming languages. The OQL syntax for queries is similar to the syntax of the \\nrelational standard query language SQL, with additional features for ODMG con-\\ncepts, such as object identity, complex objects, operations, inheritance, polymor-\\nphism, and relationships.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 422, 'page_label': '423'}, page_content='12.5 The Object Query Language OQL  409\\nIn Section 12.5.1 we will discuss the syntax of simple OQL queries and the concept \\nof using named objects or extents as database entry points. Then, in Section 12.5.2 \\nwe will discuss the structure of query results and the use of path expressions to tra-\\nverse relationships among objects. Other OQL features for handling object identity, \\ninheritance, polymorphism, and other object-oriented concepts are discussed in \\nSection 12.5.3. The examples to illustrate OQL queries are based on the \\nUNIVERSITY \\ndatabase schema given in Figure 12.10.\\n12.5.1  Simple OQL Queries, Database Entry Points,  \\nand Iterator Variables\\nThe basic OQL syntax is a select … from … where … structure, as it is for SQL. For \\nexample, the query to retrieve the names of all departments in the college of  \\n‘Engineering’ can be written as follows:\\nQ0: select D.Dname\\n from D in DEPARTMENTS\\n where D.College = ‘Engineering’;\\nIn general, an entry point to the database is needed for each query, which can be \\nany named persistent object.  For many queries, the entry point is the name of the \\nextent of a class. Recall that the extent name is considered to be the name of a persis-\\ntent object whose type is a collection (in most cases, a set) of objects from the class. \\nLooking at the extent names in Figure 12.10, the named object DEPARTMENTS is of \\ntype set<DEPARTMENT>; PERSONS is of type set<PERSON>; FACULTY is of type \\nset<FACULTY>; and so on.\\nThe use of an extent name— DEPARTMENTS in Q0—as an entry point refers to a \\npersistent collection of objects. Whenever a collection is referenced in an OQL \\nquery, we should define an iterator variable\\n38—D in Q0—that ranges over each \\nobject in the collection. In many cases, as in Q0, the query will select certain objects \\nfrom the collection, based on the conditions specified in the where clause. In Q0, \\nonly persistent objects D in the collection of DEPARTMENTS that satisfy the condi-\\ntion D.College = ‘Engineering’ are selected for the query result. For each selected \\nobject D, the value of D.Dname is retrieved in the query result. Hence, the type of the \\nresult for Q0 is bag<string> because the type of each Dname value is string (even \\nthough the actual result is a set because Dname is a key attribute). In general, the \\nresult of a query would be of type bag for select … from … and of type set for select \\ndistinct … from … , as in SQL (adding the keyword distinct eliminates duplicates).\\nUsing the example in Q0, there are three syntactic options for specifying iterator \\nvariables:\\nD in DEPARTMENTS\\nDEPARTMENTS D\\nDEPARTMENTS AS D\\n38This is similar to the tuple variables that range over tuples in SQL queries.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 423, 'page_label': '424'}, page_content='410 Chapter 12 Object and Object-Relational Databases\\nWe will use the first construct in our examples.39\\nThe named objects used as database entry points for OQL queries are not limited to \\nthe names of extents. Any named persistent object, whether it refers to an atomic \\n(single) object or to a collection object, can be used as a database entry point.\\n12.5.2 Query Results and Path Expressions\\nIn general, the result of a query can be of any type that can be expressed in the \\nODMG object model. A query does not have to follow the \\nselect … from … where … \\nstructure; in the simplest case, any persistent name on its own is a query, whose \\nresult is a reference to that persistent object. For example, the query\\nQ1: DEPARTMENTS;\\nreturns a reference to the collection of all persistent DEPARTMENT objects, whose \\ntype is set<DEPARTMENT>. Similarly, suppose we had given (via the database bind \\noperation, see Figure 12.8) a persistent name CS_DEPARTMENT  to a single \\nDEPARTMENT object (the Computer Science department); then, the query\\nQ1A: CS_DEPARTMENT;\\nreturns a reference to that individual object of type DEPARTMENT. Once an entry point \\nis specified, the concept of a path expression can be used to specify a path to related \\nattributes and objects. A path expression typically starts at a persistent object name, or at \\nthe iterator variable that ranges over individual objects in a collection. This name will \\nbe followed by zero or more relationship names or attribute names connected using \\nthe dot notation. For example, referring to the \\nUNIVERSITY database in Figure 12.10, \\nthe following are examples of path expressions, which are also valid queries in OQL:\\nQ2: CS_DEPARTMENT.Chair;\\nQ2A: CS_DEPARTMENT.Chair.Rank;\\nQ2B: CS_DEPARTMENT.Has_faculty;\\nThe first expression Q2 returns an object of type FACULTY, because that is the type \\nof the attribute Chair of the DEPARTMENT  class. This will be a reference to the  \\nFACULTY object that is related to the DEPARTMENT object whose persistent name is \\nCS_DEPARTMENT via the attribute Chair; that is, a reference to the FACULTY object \\nwho is chairperson of the Computer Science department. The second expression \\nQ2A is similar, except that it returns the Rank of this FACULTY object (the Computer \\nScience chair) rather than the object reference; hence, the type returned by Q2A is \\nstring, which is the data type for the Rank attribute of the FACULTY class.\\nPath expressions Q2 and Q2A return single values, because the attributes Chair (of \\nDEPARTMENT) and Rank (of FACULTY) are both single-valued and they are applied to \\na single object. The third expression, Q2B, is different; it returns an object of type \\nset<FACULTY> even when applied to a single object, because that is the type of the \\nrelationship Has_faculty of the DEPARTMENT class. The collection returned will include \\n39Note that the latter two options are similar to the syntax for specifying tuple variables in SQL queries.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 424, 'page_label': '425'}, page_content='12.5 The Object Query Language OQL  411\\na set of references to all FACULTY objects that are related to the DEPARTMENT object \\nwhose persistent name is CS_DEPARTMENT via the relationship Has_faculty; that is, a \\nset of references to all FACULTY objects who are working in the Computer Science \\ndepartment. Now, to return the ranks of Computer Science faculty, we cannot write\\nQ3′: CS_DEPARTMENT.Has_faculty.Rank;\\nbecause it is not clear whether the object returned would be of type set<string> or \\nbag<string> (the latter being more likely, since multiple faculty may share the same \\nrank). Because of this type of ambiguity problem, OQL does not allow expressions \\nsuch as \\nQ3′. Rather, one must use an iterator variable over any collections, as in \\nQ3A or Q3B below:\\nQ3A: select F.Rank\\n from F in CS_DEPARTMENT.Has_faculty;\\nQ3B: select distinct F.Rank\\n from F in CS_DEPARTMENT.Has_faculty;\\nHere, Q3A returns bag<string> (duplicate rank values appear in the result), whereas \\nQ3B returns set<string> (duplicates are eliminated via the distinct keyword). Both \\nQ3A and Q3B illustrate how an iterator variable can be defined in the from clause to \\nrange over a restricted collection specified in the query. The variable F in Q3A and \\nQ3B ranges over the elements of the collection CS_DEPARTMENT.Has_faculty, which \\nis of type set<FACULTY>, and includes only those faculty who are members of the \\nComputer Science department.\\nIn general, an OQL query can return a result with a complex structure specified in \\nthe query itself by utilizing the struct keyword. Consider the following examples:\\nQ4: CS_DEPARTMENT.Chair.Advises;\\nQ4A: select struct ( name: struct ( last_name: S.name.Lname, first_name: \\nS.name.Fname),\\n     degrees:( select struct ( deg: D.Degree, \\nyr: D.Year, \\ncollege: D.College)\\n        from D in S.Degrees ))\\n from S in CS_DEPARTMENT.Chair.Advises;\\nHere, Q4 is straightforward, returning an object of type set<GRAD_STUDENT> as its \\nresult; this is the collection of graduate students who are advised by the chair of the \\nComputer Science department. Now, suppose that a query is needed to retrieve the \\nlast and first names of these graduate students, plus the list of previous degrees of \\neach. This can be written as in Q4A, where the variable S ranges over the collection \\nof graduate students advised by the chairperson, and the variable D ranges over the \\ndegrees of each such student S. The type of the result of Q4A is a collection of (first-\\nlevel) structs where each struct has two components: name and degrees.40\\n40As mentioned earlier, struct corresponds to the tuple constructor discussed in Section 12.1.3.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 425, 'page_label': '426'}, page_content='412 Chapter 12 Object and Object-Relational Databases\\nThe name component is a further struct made up of last_name and first_name, each \\nbeing a single string. The degrees component is defined by an embedded query and \\nis itself a collection of further (second level) structs, each with three string compo-\\nnents: \\ndeg, yr, and college.\\nNote that OQL is orthogonal with respect to specifying path expressions. That is, \\nattributes, relationships, and operation names (methods) can be used interchange-\\nably within the path expressions, as long as the type system of OQL is not compro-\\nmised. For example, one can write the following queries to retrieve the grade point \\naverage of all senior students majoring in Computer Science, with the result ordered \\nby GPA, and within that by last and first name:\\nQ5A: select struct (  last_name: S.name.Lname, first_name: S.name.Fname, \\ngpa: S.gpa )\\n from S in CS_DEPARTMENT.Has_majors\\n where S.Class = ‘senior’\\n order by gpa desc, last_name asc, first_name asc;\\nQ5B: select struct (  last_name: S.name.Lname, first_name: S.name.Fname,  \\ngpa: S.gpa )\\n from  S in STUDENTS\\n where S.Majors_in.Dname = ‘Computer Science’ and\\n  S.Class = ‘senior’\\n order by gpa desc, last_name asc, first_name asc;\\nQ5A used the named entry point CS_DEPARTMENT to directly locate the reference \\nto the Computer Science department and then locate the students via the relation-\\nship Has_majors, whereas Q5B searches the STUDENTS extent to locate all students \\nmajoring in that department. Notice how attribute names, relationship names, and \\noperation (method) names are all used interchangeably (in an orthogonal manner) \\nin the path expressions: gpa is an operation; Majors_in and Has_majors are relation-\\nships; and Class, Name, Dname, Lname, and Fname are attributes. The implementa-\\ntion of the gpa operation computes the grade point average and returns its value as \\na float type for each selected STUDENT.\\nThe order by clause is similar to the corresponding SQL construct, and specifies in \\nwhich order the query result is to be displayed. Hence, the collection returned by a \\nquery with an \\norder by clause is of type list.\\n12.5.3 Other Features of OQL\\nSpecifying Views as Named Queries. The view mechanism in OQL uses the \\nconcept of a named query. The define keyword is used to specify an identifier of the \\nnamed query, which must be a unique name among all named objects, class names, \\nmethod names, and function names in the schema. If the identifier has the same \\nname as an existing named query, then the new definition replaces the previous \\ndefinition. Once defined, a query definition is persistent until it is redefined or \\ndeleted. A view can also have parameters (arguments) in its definition.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 426, 'page_label': '427'}, page_content='12.5 The Object Query Language OQL  413\\nFor example, the following view V1 defines a named query Has_minors to retrieve \\nthe set of objects for students minoring in a given department:\\nV1: define Has_minors(Dept_name) as\\n select S\\n from S in STUDENTS\\n where S.Minors_in.Dname = Dept_name;\\nBecause the ODL schema in Figure 12.10 only provided a unidirectional Minors_in \\nattribute for a STUDENT, we can use the above view to represent its inverse without \\nhaving to explicitly define a relationship. This type of view can be used to represent \\ninverse relationships that are not expected to be used frequently. The user can now \\nutilize the above view to write queries such as\\nHas_minors(‘Computer Science’);\\nwhich would return a bag of students minoring in the Computer Science depart-\\nment. Note that in Figure 12.10, we defined Has_majors as an explicit relationship, \\npresumably because it is expected to be used more often.\\nExtracting Single Elements from Singleton Collections. An OQL query will, \\nin general, return a collection as its result, such as a bag, set (if distinct is specified), or \\nlist (if the order by clause is used). If the user requires that a query only return a sin-\\ngle element, there is an element operator in OQL that is guaranteed to return a  \\nsingle element E from a singleton collection C that contains only one element. If C \\ncontains more than one element or if C is empty, then the element operator raises \\nan exception. For example, Q6 returns the single object reference to the Computer \\nScience department:\\nQ6: element ( select D\\n    from D in DEPARTMENTS\\n    where D.Dname = ‘Computer Science’ );\\nSince a department name is unique across all departments, the result should be one \\ndepartment. The type of the result is D:DEPARTMENT.\\nCollection Operators (Aggregate Functions, Quantifiers). Because many \\nquery expressions specify collections as their result, a number of operators have been \\ndefined that are applied to such collections. These include aggregate operators as \\nwell as membership and quantification (universal and existential) over a collection.\\nThe aggregate operators (\\nmin, max, count, sum, avg) operate over a collection. 41 The \\noperator count returns an integer type. The remaining aggregate operators ( min, \\nmax, sum, avg) return the same type as the type of the operand collection. Two \\nexamples follow. The query Q7 returns the number of students minoring in Com-\\nputer Science and Q8 returns the average GPA of all seniors majoring in Computer \\nScience.\\n41These correspond to aggregate functions in SQL.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 427, 'page_label': '428'}, page_content='414 Chapter 12 Object and Object-Relational Databases\\nQ7: count ( S in Has_minors(‘Computer Science’));\\nQ8: avg ( select S.Gpa\\n  from S in STUDENTS\\n  where S.Majors_in.Dname = ‘Computer Science’ and \\n   S.Class = ‘Senior’);\\nNotice that aggregate operations can be applied to any collection of the appropriate \\ntype and can be used in any part of a query. For example, the query to retrieve all \\ndepartment names that have more than 100 majors can be written as in \\nQ9:\\nQ9: select  D.Dname\\n from D in DEPARTMENTS\\n where count (D.Has_majors) > 100;\\nThe membership and quantification expressions return a Boolean type—that is, true or \\nfalse. Let V be a variable, C a collection expression, B an expression of type Boolean (that \\nis, a Boolean condition), and E an element of the type of elements in collection C. Then:\\n(E in C) returns true if element E is a member of collection C.\\n(for all V in C : B) returns true if all the elements of collection C satisfy B.\\n(exists V in C : B) returns true if there is at least one element in C satisfying B.\\nTo illustrate the membership condition, suppose we want to retrieve the names of \\nall students who completed the course called ‘Database Systems I’. This can be writ-\\nten as in \\nQ10, where the nested query returns the collection of course names that \\neach STUDENT S has completed, and the membership condition returns true if \\n‘Database Systems I’ is in the collection for a particular STUDENT S:\\nQ10: select S.name.Lname, S.name.Fname\\n from S in STUDENTS\\n where ‘Database Systems I’ in\\n  ( select C.Section.Of_course.Cname\\n    from C in S.Completed_sections);\\nQ10 also illustrates a simpler way to specify the select clause of queries that return a \\ncollection of structs; the type returned by Q10 is bag<struct(string, string)>.\\nOne can also write queries that return true/false results. As an example, let us \\nassume that there is a named object called JEREMY of type STUDENT. Then, query \\nQ11 answers the following question: Is Jeremy a Computer Science minor? Similarly, \\nQ12 answers the question Are all Computer Science graduate students advised by \\nComputer Science faculty? Both Q11 and Q12 return true or false, which are inter-\\npreted as yes or no answers to the above questions:\\nQ11: JEREMY in Has_minors(‘Computer Science’);\\nQ12: for all G in\\n  ( select S\\n    from S in GRAD_STUDENTS\\n    where S.Majors_in.Dname = ‘Computer Science’ )\\n  : G.Advisor in CS_DEPARTMENT.Has_faculty;'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 428, 'page_label': '429'}, page_content='12.5 The Object Query Language OQL  415\\nNote that query Q12 also illustrates how attribute, relationship, and operation \\ninheritance applies to queries. Although S is an iterator that ranges over the extent \\nGRAD_STUDENTS , we can write S.Majors_in because the Majors_in relationship is \\ninherited by GRAD_STUDENT from STUDENT via extends (see Figure 12.10). Finally, \\nto illustrate the exists quantifier, query Q13 answers the following question: Does \\nany graduate Computer Science major have a 4.0 GPA?  Here, again, the operation \\ngpa is inherited by GRAD_STUDENT from STUDENT via extends.\\nQ13: exists G in\\n ( select S\\n   from S in GRAD_STUDENTS\\n   where S.Majors_in.Dname = ‘Computer Science’ )\\n : G.Gpa = 4;\\nOrdered (Indexed) Collection Expressions. As we discussed in Section 12.3.3, \\ncollections that are lists and arrays have additional operations, such as retrieving \\nthe ith, first, and last elements. Additionally, operations exist for extracting a sub-\\ncollection and concatenating two lists. Hence, query expressions that involve lists \\nor arrays can invoke these operations. We will illustrate a few of these operations \\nusing sample queries. \\nQ14 retrieves the last name of the faculty member who earns \\nthe highest salary:\\nQ14: first ( select struct(facname: F.name.Lname, salary: F.Salary)\\n  from F in FACULTY\\n  order by salary desc );\\nQ14 illustrates the use of the first operator on a list collection that contains the sala-\\nries of faculty members sorted in descending order by salary. Thus, the first element \\nin this sorted list contains the faculty member with the highest salary. This query \\nassumes that only one faculty member earns the maximum salary. The next query, \\nQ15, retrieves the top three Computer Science majors based on GPA.\\nQ15: ( select struct(  last_name: S.name.Lname, first_name: S.name.Fname,  \\ngpa: S.Gpa )\\n   from S in CS_DEPARTMENT.Has_majors\\n   order by gpa desc ) [0:2];\\nThe select-from-order-by query returns a list of Computer Science students ordered \\nby GPA in descending order. The first element of an ordered collection has an \\nindex position of 0, so the expression \\n[0:2] returns a list containing the first, second, \\nand third elements of the select … from … order by … result.\\nThe Grouping Operator. The group by clause in OQL, although similar to the \\ncorresponding clause in SQL, provides explicit reference to the collection of objects \\nwithin each group or partition. First we give an example, and then we describe the \\ngeneral form of these queries.\\nQ16 retrieves the number of majors in each department. In this query, the students \\nare grouped into the same partition (group) if they have the same major; that is, the \\nsame value for S.Majors_in.Dname:'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 429, 'page_label': '430'}, page_content='416 Chapter 12 Object and Object-Relational Databases\\nQ16: ( select struct( dept_name, number_of_majors: count (partition) )\\n   from S in STUDENTS\\n   group by dept_name: S.Majors_in.Dname;\\nThe result of the grouping specification is of type set<struct(dept_name: string, partition: \\nbag<struct(S:STUDENT>)>), which contains a struct for each group ( partition) that \\nhas two components: the grouping attribute value ( dept_name) and the bag of the \\nSTUDENT objects in the group ( partition). The select clause returns the grouping \\nattribute (name of the department), and a count of the number of elements in each \\npartition (that is, the number of students in each department), where \\npartition is the \\nkeyword used to refer to each partition. The result type of the select clause is \\nset<struct(dept_name: string , number_of_majors: integer )>. In general, the syntax for \\nthe group by clause is\\ngroup by F1: E1, F2: E2, … , Fk: Ek\\nwhere F1: E1, F2: E2, … , Fk: Ek is a list of partitioning (grouping) attributes and each \\npartitioning attribute specification Fi: Ei defines an attribute (field) name Fi and an \\nexpression Ei. The result of applying the grouping (specified in the group by clause) \\nis a set of structures:\\nset<struct(F1: T1, F2: T2, … , Fk: Tk, partition: bag)>\\nwhere Ti is the type returned by the expression Ei, partition is a distinguished field \\nname (a keyword), and B is a structure whose fields are the iterator variables ( S in \\nQ16) declared in the from clause having the appropriate type.\\nJust as in SQL, a having clause can be used to filter the partitioned sets (that is, select \\nonly some of the groups based on group conditions). In Q17, the previous query is \\nmodified to illustrate the having clause (and also shows the simplified syntax for the \\nselect clause). Q17 retrieves for each department having more than 100 majors, the \\naverage GPA of its majors. The having clause in Q17 selects only those partitions \\n(groups) that have more than 100 elements (that is, departments with more than \\n100 students).\\nQ17: select dept_name, avg_gpa: avg ( select P.gpa from P in partition)\\n from S in STUDENTS\\n group by dept_name:  S.Majors_in.Dname\\n having count (partition) > 100;\\nNote that the select clause of Q17 returns the average GPA of the students in the \\npartition. The expression\\nselect P.Gpa from P in partition\\nreturns a bag of student GPAs for that partition. The from clause declares an iterator \\nvariable P over the partition collection, which is of type bag<struct(S: STUDENT)>. \\nThen the path expression P.gpa is used to access the GPA of each student in the \\npartition.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 430, 'page_label': '431'}, page_content='12.6 Overview of the C++ Language Binding in the ODMG Standard  417\\n12.6  Overview of the C++ Language Binding  \\nin the ODMG Standard\\nThe C++ language binding specifies how ODL constructs are mapped to C++ con-\\nstructs. This is done via a C++ class library that provides classes and operations \\nthat implement the ODL constructs. An object manipulation language (OML) is \\nneeded to specify how database objects are retrieved and manipulated within a \\nC++ program, and this is based on the C++ programming language syntax and \\nsemantics. In addition to the ODL/OML bindings, a set of constructs called physi-\\ncal pragmas are defined to allow the programmer some control over physical stor-\\nage issues, such as clustering of objects, utilizing indexes, and memory \\nmanagement.\\nThe class library added to C++ for the ODMG standard uses the prefix \\nd_ for \\nclass declarations that deal with database concepts. 42 The goal is that the pro-\\ngrammer should think that only one language is being used, not two separate \\nlanguages. For the programmer to refer to database objects in a program, a class \\nD_Ref<T> is defined for each database class T in the schema. Hence, program \\nvariables of type D_Ref<T> can refer to both persistent and transient objects of \\nclass T.\\nIn order to utilize the various built-in types in the ODMG object model such as \\ncollection types, various template classes are specified in the library. For example, \\nan abstract class \\nD_Object<T> specifies the operations to be inherited by all objects. \\nSimilarly, an abstract class D_Collection<T> specifies the operations of collections. \\nThese classes are not instantiable, but only specify the operations that can be \\ninherited by all objects and by collection objects, respectively. A template class is \\nspecified for each type of collection; these include \\nD_Set <T>, D_List <T>,  \\nD_Bag<T>, D_Varray<T>, and D_Dictionary<T>, and they correspond to the collection \\ntypes in the object model (see Section 12.3.1). Hence, the programmer can create \\nclasses of types such as \\nD_Set<D_Ref<STUDENT>> whose instances would be sets \\nof references to STUDENT objects, or D_Set<string> whose instances would be sets \\nof strings. Additionally, a class d_Iterator  corresponds to the Iterator class of the \\nobject model.\\nThe C++ ODL allows a user to specify the classes of a database schema using  \\nthe constructs of C++ as well as the constructs provided by the object database  \\nlibrary. For specifying the data types of attributes, 43 basic types such as d_Short \\n(short integer), d_Ushort  (unsigned short integer), d_Long  (long integer), and  \\nd_Float (floating-point number) are provided. In addition to the basic data types, \\nseveral structured literal types are provided to correspond to the structured literal \\ntypes of the ODMG object model. These include \\nd_String, d_Interval, d_Date, d_Time, \\nand d_Timestamp (see Figure 12.5(b)).\\n42Presumably, d_ stands for database classes.\\n43That is, member variables in object-oriented programming terminology.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 431, 'page_label': '432'}, page_content='418 Chapter 12 Object and Object-Relational Databases\\nTo specify relationships, the keyword rel_ is used within the prefix of type names; \\nfor example, by writing\\nd_Rel_Ref<DEPARTMENT, Has_majors> Majors_in;\\nin the STUDENT class, and\\nd_Rel_Set<STUDENT, Majors_in> Has_majors;\\nin the DEPARTMENT class, we are declaring that Majors_in and Has_majors are rela-\\ntionship properties that are inverses of one another and hence represent a 1:N \\nbinary relationship between \\nDEPARTMENT and STUDENT.\\nFor the OML, the binding overloads the operation new so that it can be used to \\ncreate either persistent or transient objects. To create persistent objects, one \\nmust provide the database name and the persistent name of the object. For \\nexample, by writing\\nD_Ref<STUDENT> S = new(DB1, ‘John_Smith’) STUDENT;\\nthe programmer creates a named persistent object of type STUDENT in database \\nDB1 with persistent name John_Smith. Another operation, delete_object () can be \\nused to delete objects. Object modification is done by the operations (methods) \\ndefined in each class by the programmer.\\nThe C++ binding also allows the creation of extents by using the library class  \\nd_Extent. For example, by writing\\nD_Extent<PERSON> ALL_PERSONS(DB1);\\nthe programmer would create a named collection object ALL_PERSONS—whose \\ntype would be D_Set<PERSON>—in the database DB1 that would hold persistent \\nobjects of type PERSON. However, key constraints are not supported in the C++ \\nbinding, and any key checks must be programmed in the class methods. 44 Also, \\nthe C++ binding does not support persistence via reachability; the object must be \\nstatically declared to be persistent at the time it is created.\\n12.7 Summary\\nIn this chapter, we started in Section 12.1 with an overview of the concepts utilized \\nin object databases, and we discussed how these concepts were derived from gen-\\neral object-oriented principles. The main concepts we discussed were: object iden-\\ntity and identifiers; encapsulation of operations; inheritance; complex structure of \\nobjects through nesting of type constructors; and how objects are made persistent. \\n44We have only provided a brief overview of the C++ binding. For full details, see Cattell et al. (2000), \\nChapter 5.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 432, 'page_label': '433'}, page_content='12.7 Summary  419\\nThen, in Section 12.2, we showed how many of these concepts were incorporated \\ninto the relational model and the SQL standard; we showed that this incorporation \\nleads to expanded relational database functionality. These systems have been called \\nobject-relational databases.\\nWe then discussed the ODMG 3.0 standard for object databases. We started by \\ndescribing the various constructs of the object model in Sction 12.3. The various \\nbuilt-in types, such as \\nObject, Collection, Iterator, set, list, and so on, were described by \\ntheir interfaces, which specify the built-in operations of each type. These built-in \\ntypes are the foundation upon which the object definition language (ODL) and \\nobject query language (OQL) are based. We also described the difference between \\nobjects, which have an ObjectId, and literals, which are values with no OID. Users \\ncan declare classes for their application that inherit operations from the appropriate \\nbuilt-in interfaces. Two types of properties can be specified in a user-defined class—\\nattributes and relationships—in addition to the operations that can be applied to \\nobjects of the class. The ODL allows users to specify both interfaces and classes, and \\npermits two different types of inheritance—interface inheritance via “:” and class \\ninheritance via \\nextends. A class can have an extent and keys. A description of ODL \\nfollowed, and an example database schema for the UNIVERSITY database was used to \\nillustrate the ODL constructs.\\nFollowing the description of the ODMG object model, we described a general tech-\\nnique for designing object database schemas in Section 12.4. We discussed how \\nobject databases differ from relational databases in three main areas: references to \\nrepresent relationships, inclusion of operations, and inheritance. Finally, we \\nshowed how to map a conceptual database design in the EER model to the con-\\nstructs of object databases.\\nIn Section 12.5, we presented an overview of the object query language (OQL). The \\nOQL follows the concept of orthogonality in constructing queries, meaning that an \\noperation can be applied to the result of another operation as long as the type of the \\nresult is of the correct input type for the operation. The OQL syntax follows many \\nof the constructs of SQL but includes additional concepts such as path expressions, \\ninheritance, methods, relationships, and collections. Examples of how to use OQL \\nover the \\nUNIVERSITY database were given.\\nNext we gave an overview of the C++ language binding in Section 12.6, which \\nextends C++ class declarations with the ODL type constructors but permits seam-\\nless integration of C++ with the ODBMS.\\nIn 1997 Sun endorsed the ODMG API (Application Program Interface). O2 tech-\\nnologies was the first corporation to deliver an ODMG-compliant DBMS. Many \\nODBMS vendors, including Object Design (now eXcelon), Gemstone Systems, POET \\nSoftware, and Versant Corporation\\n45, have endorsed the ODMG standard.\\n45The Versant Object Technology product now belongs to Actian Corporation.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 433, 'page_label': '434'}, page_content='420 Chapter 12 Object and Object-Relational Databases\\nReview Questions\\n 12.1. What are the origins of the object-oriented approach?\\n 12.2. What primary characteristics should an OID possess?\\n 12.3. Discuss the various type constructors. How are they used to create complex \\nobject structures?\\n 12.4. Discuss the concept of encapsulation, and tell how it is used to create abstract \\ndata types.\\n 12.5. Explain what the following terms mean in object-oriented database termi-\\nnology: method, signature, message, collection, extent.\\n 12.6. What is the relationship between a type and its subtype in a type hierarchy? \\nWhat is the constraint that is enforced on extents corresponding to types in \\nthe type hierarchy?\\n 12.7. What is the difference between persistent and transient objects? How is \\npersistence handled in typical OO database systems?\\n 12.8. How do regular inheritance, multiple inheritance, and selective inheritance \\ndiffer?\\n 12.9. Discuss the concept of polymorphism/operator overloading.\\n 12.10. Discuss how each of the following features is realized in SQL 2008: object identi-\\nfier, type inheritance, encapsulation of operations, and complex object structures.\\n 12.11. In the traditional relational model, creating a table defined both the table \\ntype (schema or attributes) and the table itself (extension or set of current \\ntuples). How can these two concepts be separated in SQL 2008?\\n 12.12. Describe the rules of inheritance in SQL 2008.\\n 12.13. What are the differences and similarities between objects and literals in the \\nODMG object model?\\n 12.14. List the basic operations of the following built-in interfaces of the \\nODMG object model: Object , Collection , Iterator , Set, List, Bag, Array, and \\nDictionary .\\n 12.15. Describe the built-in structured literals of the ODMG object model and the \\noperations of each.\\n 12.16. What are the differences and similarities of attribute and relationship prop-\\nerties of a user-defined (atomic) class?\\n 12.17. What are the differences and similarities of class inhertance via extends and \\ninterface inheritance via “:” in the ODMG object model?\\n 12.18. Discuss how persistence is specified in the ODMG object model in the C++ \\nbinding.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 434, 'page_label': '435'}, page_content='Exercises 421\\n 12.19. Why are the concepts of extents and keys important in database applica-\\ntions?\\n 12.20. Describe the following OQL concepts: database entry points, path expressions, \\niterator variables, named queries (views) , aggregate functions , grouping , \\nand quantifiers.\\n 12.21. What is meant by the type orthogonality of OQL?\\n 12.22. Discuss the general principles behind the C++ binding of the ODMG \\nstandard.\\n 12.23. What are the main differences between designing a relational database and \\nan object database?\\n 12.24. Describe the steps of the algorithm for object database design by EER-to-\\nOO mapping.\\nExercises\\n 12.25. Convert the example of GEOMETRY_OBJECTs given in Section 12.1.5 from \\nthe functional notation to the notation given in Figure 12.2 that distin-\\nguishes between attributes and operations. Use the keyword \\nINHERIT to \\nshow that one class inherits from another class.\\n 12.26. Compare inheritance in the EER model (see Chapter 4) to inheritance in the \\nOO model described in Section 12.1.5.\\n 12.27. Consider the UNIVERSITY EER schema in Figure 4.10. Think of what opera-\\ntions are needed for the entity types/classes in the schema. Do not consider \\nconstructor and destructor operations.\\n 12.28. Consider the COMPANY ER schema in Figure 3.2. Think of what operations \\nare needed for the entity types/classes in the schema. Do not consider con-\\nstructor and destructor operations.\\n 12.29. Design an OO schema for a database application that you are interested in. \\nConstruct an EER schema for the application, and then create the corre-\\nsponding classes in ODL. Specify a number of methods for each class, and \\nthen specify queries in OQL for your database application.\\n 12.30. Consider the AIRPORT database described in Exercise 4.21. Specify a num-\\nber of operations/methods that you think should be applicable to that appli-\\ncation. Specify the ODL classes and methods for the database.\\n 12.31. Map the COMPANY ER schema in Figure 3.2 into ODL classes. Include \\nappropriate methods for each class.\\n 12.32. Specify in OQL the queries in the exercises of Chapters 6 and 7 that apply to \\nthe COMPANY database.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 435, 'page_label': '436'}, page_content='422 Chapter 12 Object and Object-Relational Databases\\nSelected Bibliography\\nObject-oriented database concepts are an amalgam of concepts from OO pro-\\ngramming languages and from database systems and conceptual data models. A \\nnumber of textbooks describe OO programming languages—for example, \\nStroustrup (1997) for C++, and Goldberg and Robson (1989) for Smalltalk. \\nBooks by Cattell (1994) and Lausen and Vossen (1997) describe OO database \\nconcepts. Other books on OO models include a detailed description of the \\nexperimental OODBMS developed at Microelectronic Computer Corporation \\ncalled ORION and related OO topics by Kim and Lochovsky (1989). Bancilhon \\net al. (1992) describes the story of building the O2 OODBMS with a detailed \\ndiscussion of design decisions and language implementation. Dogac et al. \\n(1994) provides a thorough discussion on OO database topics by experts at a \\nNATO workshop.\\nThere is a vast bibliography on OO databases, so we can only provide a repre-\\nsentative sample here. The October 1991 issue of CACM  and the December \\n1990 issue of ieee Computer  describe OO database concepts and systems. Dit-\\ntrich (1986) and Zaniolo et al. (1986) survey the basic concepts of OO data \\nmodels. An early paper on OO database system implementation is Baroody and \\nDeWitt (1981). Su et al. (1988) presents an OO data model that was used in \\nCAD/CAM applications. Gupta and Horowitz (1992) discusses OO applica-\\ntions to CAD, Network Management, and other areas. Mitschang (1989) \\nextends the relational algebra to cover complex objects. Query languages and \\ngraphical user interfaces for OO are described in Gyssens et al. (1990), Kim \\n(1989), Alashqur et al. (1989), Bertino et al. (1992), Agrawal et al. (1990), and \\nCruz (1992).\\nThe Object-Oriented Manifesto by Atkinson et al. (1990) is an interesting arti-\\ncle that reports on the position by a panel of experts regarding the mandatory \\nand optional features of OO database management. Polymorphism in databases \\nand OO programming languages is discussed in Osborn (1989), Atkinson and \\nBuneman (1987), and Danforth and Tomlinson (1988). Object identity is dis-\\ncussed in Abiteboul and Kanellakis (1989). OO programming languages for \\ndatabases are discussed in Kent (1991). Object constraints are discussed in Del-\\ncambre et al. (1991) and Elmasri, James, and Kouramajian (1993). Authoriza-\\ntion and security in OO databases are examined in Rabitti et al. (1991) and \\nBertino (1992).\\nCattell et al. (2000) describe the ODMG 3.0 standard, which is described in this \\nchapter, and Cattell et al. (1993) and Cattell et al. (1997) describe the earlier \\nversions of the standard. Bancilhon and Ferrari (1995) give a tutorial presenta-\\ntion of the important aspects of the ODMG standard. Several books describe \\nthe CORBA architecture—for example, Baker (1996).\\nThe O2 system is described in Deux et al. (1991), and Bancilhon et al. (1992) \\nincludes a list of references to other publications describing various aspects of \\nO2. The O2 model was formalized in Velez et al. (1989). The ObjectStore system'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 436, 'page_label': '437'}, page_content='Selected Bibliography 423\\nis described in Lamb et al. (1991). Fishman et al. (1987) and Wilkinson et al. \\n(1990) discuss IRIS, an object-oriented DBMS developed at Hewlett-Packard \\nLaboratories. Maier et al. (1986) and Butterworth et al. (1991) describe the design \\nof GEMSTONE. The ODE system developed at AT&T Bell Labs is described in \\nAgrawal and Gehani (1989). The ORION system developed at MCC is described \\nin Kim et al. (1990). Morsi et al. (1992) describes an OO testbed.\\nCattell (1991) surveys concepts from both relational and object databases and \\ndiscusses several prototypes of object-based and extended relational database sys-\\ntems. Alagic (1997) points out discrepancies between the ODMG data model and \\nits language bindings and proposes some solutions. Bertino and Guerrini (1998) \\npropose an extension of the ODMG model for supporting composite objects. \\nAlagic (1999) presents several data models belonging to the ODMG family.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 437, 'page_label': '438'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 438, 'page_label': '439'}, page_content='425\\n13\\nXML: Extensible  \\nMarkup Language\\nM\\nany Internet applications provide Web inter-\\nfaces to access information stored in one or \\nmore databases. These databases are often referred to as data sources. It is common \\nto use the three-tier client/server architectures for Internet applications (see Sec-\\ntion 2.5). Internet database applications are designed to interact with the user through \\nWeb interfaces that display Web pages on desktops, laptops, and mobile devices. \\nThe common method of specifying the contents and formatting of Web pages is \\nthrough the use of hypertext documents. There are various languages for writing \\nthese documents, the most common being HTML (HyperText Markup Language). \\nAlthough HTML is widely used for formatting and structuring Web documents, it \\nis not suitable for specifying structured data that is extracted from databases. A new \\nlanguage—namely, XML (Extensible Markup Language)—has emerged as the stan-\\ndard for structuring and exchanging data over the Web in text files. Another lan-\\nguage that can be used for the same purpose is JSON (JavaScript Object Notation; \\nsee Section 11.4). XML can be used to provide information about the structure and \\nmeaning of the data in the Web pages rather than just specifying how the Web \\npages are formatted for display on the screen. Both XML and JSON documents \\nprovide descriptive information, such as attribute names, as well as the values of \\nthese attributes, in a text file; hence, they are known as self-describing documents. \\nThe formatting aspects of Web pages are specified separately—for example, by \\nusing a formatting language such as XSL (Extensible Stylesheet Language) or a \\ntransformation language such as XSLT (Extensible Stylesheet Language for Trans-\\nformations or simply XSL Transformations). Recently, XML has also been pro-\\nposed as a possible model for data storage and retrieval, although only a few \\nexperimental database systems based on XML have been developed so far.\\nchapter 13'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 439, 'page_label': '440'}, page_content='426 Chapter 13 XML: Extensible Markup Language\\nBasic HTML is useful for generating static Web pages with fixed text and other \\nobjects, but most e-commerce applications require Web pages that provide interac-\\ntive features with the user and use the information provided by the user for select-\\ning specific data from a database for display. Such Web pages are called dynamic \\nWeb pages, because the data extracted and displayed each time will be different \\ndepending on user input. For example, a banking app would get the user’s account \\nnumber, then extract the balance for that user’s account from the database for dis-\\nplay. We discussed how scripting languages, such as PHP, can be used to generate \\ndynamic Web pages for applications such as those presented in Chapter 11. XML \\ncan be used to transfer information in self-describing textual files among various \\nprograms on different computers when needed by the applications.\\nIn this chapter, we will focus on describing the XML data model and its associated \\nlanguages, and how data extracted from relational databases can be formatted as \\nXML documents to be exchanged over the Web. Section 13.1 discusses the differ-\\nence among structured, semistructured, and unstructured data. Section 13.2 pres-\\nents the XML data model, which is based on tree (hierarchical) structures as \\ncompared to the flat relational data model structures. In Section 13.3, we focus on \\nthe structure of XML documents and the languages for specifying the structure of \\nthese documents, such as DTD (Document Type Definition) and XML Schema. \\nSection 13.4 shows the relationship between XML and relational databases. Sec-\\ntion 13.5 describes some of the languages associated with XML, such as XPath and \\nXQuery. Section 13.6 discusses how data extracted from relational databases can be \\nformatted as XML documents. In Section 13.7, we discuss the new functions that \\nhave been incorporated into XML for the purpose of generating XML documents \\nfrom relational databases. Finally, Section 13.8 is the chapter summary.\\n13.1  Structured, Semistructured,  \\nand Unstructured Data\\nThe information stored in relational databases is known as structured data because \\nit is represented in a strict format. For example, each record in a relational database \\ntable—such as each of the tables in the \\nCOMPANY database in Figure 5.6—follows \\nthe same format as the other records. For structured data, it is common to carefully \\ndesign the database schema using techniques such as those described in Chapters 3 \\nand 4 in order to define the database structure. The DBMS then checks to ensure \\nthat all data follows the structures and constraints specified in the schema.\\nHowever, not all data is collected and inserted into carefully designed structured \\ndatabases. In some applications, data is collected in an ad hoc manner before it is \\nknown how it will be stored and managed. This data may have a certain structure, \\nbut not all the information collected will have the identical structure. Some attri-\\nbutes may be shared among the various entities, but other attributes may exist only \\nin a few entities. Moreover, additional attributes can be introduced in some of the \\nnewer data items at any time, and there is no predefined schema. This type of data \\nis known as semistructured data. A number of data models have been introduced'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 440, 'page_label': '441'}, page_content='13.1 Structured, Semistructured, and Unstructured Data  427\\nfor representing semistructured data, often based on using tree or graph data struc-\\ntures rather than the flat relational model structures.\\nA key difference between structured and semistructured data concerns how the \\nschema constructs (such as the names of attributes, relationships, and entity types) \\nare handled. In semistructured data, the schema information is mixed in with the \\ndata values, since each data object can have different attributes that are not known \\nin advance. Hence, this type of data is sometimes referred to as self-describing \\ndata. Many of the newer NOSQL systems adopt self-describing storage schemes \\n(see Chapter 24). Consider the following example. We want to collect a list of bib-\\nliographic references related to a certain research project. Some of these may be \\nbooks or technical reports, others may be research articles in journals or conference \\nproceedings, and still others may refer to complete journal issues or conference \\nproceedings. Clearly, each of these may have different attributes and different types \\nof information. Even for the same type of reference—say, conference articles—we \\nmay have different information. For example, one article citation may be com-\\nplete, with full information about author names, title, proceedings, page numbers, \\nand so on, whereas another citation may not have all the information available. \\nNew types of bibliographic sources may appear in the future—for instance, references \\nto Web pages or to conference tutorials—and these may have new attributes that \\ndescribe them.\\nOne model for displaying semistructured data is a directed graph, as shown in \\nFigure 13.1. The information shown in Figure 13.1 corresponds to some of the \\nstructured data shown in Figure 5.6. As we can see, this model somewhat resem-\\nbles the object model (see Section 12.1.3) in its ability to represent complex objects \\nand nested structures. In Figure 13.1, the labels  or tags on the directed edges \\nrepresent the schema names: the names of attributes, object types ( or entity types  \\nLocationNumber\\nProject Project\\nCompany projects\\nName\\n‘Bellaire’1‘Product X’\\nWorker Worker\\nHoursLast_\\nname\\nSsn HoursFirst_\\nname\\nSsn\\n32.5‘Smith’‘123456789’ 20.0‘Joyce’‘435435435’\\nFigure 13.1 \\nRepresenting  \\nsemistructured data  \\nas a graph.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 441, 'page_label': '442'}, page_content='428 Chapter 13 XML: Extensible Markup Language\\nor classes), and relationships . The internal nodes represent individual objects or \\ncomposite attributes. The leaf nodes represent actual data values of simple \\n(atomic) attributes.\\nThere are two main differences between the semistructured model and the object \\nmodel that we discussed in Chapter 12:\\n  1. The schema information—names of attributes, relationships, and classes \\n(object types) in the semistructured model—is intermixed with the objects \\nand their data values in the same data structure.\\n  2. In the semistructured model, there is no requirement for a predefined \\nschema to which the data objects must conform, although it is possible \\nto define a schema if necessary. The object model of Chapter 12 requires \\na schema.\\nIn addition to structured and semistructured data, a third category exists, known as \\nunstructured data  because there is very limited indication of the type of data. A \\ntypical example is a text document that contains information embedded within it. \\nWeb pages in HTML that contain some data are considered to be unstructured \\ndata. Consider part of an HTML file, shown in Figure 13.2. Text that appears \\nbetween angled brackets, <…>, is an HTML tag. A tag with a slash, </…>, indicates \\nan end tag, which represents the ending of the effect of a matching start tag. The \\ntags mark up the document\\n1 in order to instruct an HTML processor how to dis-\\nplay the text between a start tag and a matching end tag. Hence, the tags specify \\ndocument formatting rather than the meaning of the various data elements in the \\ndocument. HTML tags specify information, such as font size and style (boldface, \\nitalics, and so on), color, heading levels in documents, and so on. Some tags provide \\ntext structuring in documents, such as specifying a numbered or unnumbered list \\nor a table. Even these structuring tags specify that the embedded textual data is to be \\ndisplayed in a certain manner rather than indicating the type of data represented in \\nthe table.\\nHTML uses a large number of predefined tags, which are used to specify a variety of \\ncommands for formatting Web documents for display. The start and end tags spec-\\nify the range of text to be formatted by each command. A few examples of the tags \\nshown in Figure 13.2 follow:\\n ■ The <HTML> … </HTML> tags specify the boundaries of the document.\\n ■ The document header  information—within the < HEAD> … < /HEAD> \\ntags—specifies various commands that will be used elsewhere in the docu-\\nment. For example, it may specify various script functions  in a language \\nsuch as JavaScript or PERL, or certain formatting styles (fonts, paragraph \\nstyles, header styles, and so on) that can be used in the document. It can also \\nspecify a title to indicate what the HTML file is for, and other similar infor-\\nmation that will not be displayed as part of the document.\\n1That is why it is known as HyperText Markup Language.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 442, 'page_label': '443'}, page_content='13.1 Structured, Semistructured, and Unstructured Data  429\\n<HTML>\\n <HEAD>\\n …\\n </HEAD>\\n <BODY>\\n  <H1>List of company projects and the employees in each project</H1>\\n  <H2>The ProductX project:</H2>\\n  <TABLE width=“100%” border=0 cellpadding=0 cellspacing=0>\\n   <TR>\\n    <TD width=“50%”><FONT size=“2” face=“Arial”>John Smith:</FONT></TD>\\n    <TD>32.5 hours per week</TD>\\n   </TR>\\n   <TR>\\n    <TD width=“50%”><FONT size=“2” face=“Arial”>Joyce English:</FONT></TD>\\n    <TD>20.0 hours per week</TD>\\n   </TR>\\n  </TABLE>\\n  <H2>The ProductY project:</H2>\\n  <TABLE width=“100%” border=0 cellpadding=0 cellspacing=0>\\n   <TR>\\n    <TD width=“50%”><FONT size=“2” face=“Arial”>John Smith:</FONT></TD>\\n    <TD>7.5 hours per week</TD>\\n   </TR>\\n   <TR>\\n    <TD width=“50%”><FONT size=“2” face=“Arial”>Joyce English:</FONT></TD>\\n    <TD>20.0 hours per week</TD>\\n   </TR>\\n   <TR>\\n    <TD width=“50%”><FONT size=“2” face=“Arial”>Franklin Wong:</FONT></TD>\\n    <TD>10.0 hours per week</TD>\\n   </TR>\\n  </TABLE>\\n …\\n </BODY>\\n</HTML>\\nFigure 13.2 \\nPart of an HTML document  \\nrepresenting unstructured data.\\n ■ The body of the document—specified within the < BODY> … < /BODY> \\ntags—includes the document text and the markup tags that specify how the \\ntext is to be formatted and displayed. It can also include references to other \\nobjects, such as images, videos, voice messages, and other documents.\\n ■ The <H1> … </H1> tags specify that the text is to be displayed as a level 1 \\nheading. There are many heading levels (< H2>, < H3>, and so on), each \\ndisplaying text in a less prominent heading format.\\n ■ The <TABLE> … < /TABLE> tags specify that the following text is to be dis-\\nplayed as a table. Each table row in the table is enclosed within <TR> … </TR>'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 443, 'page_label': '444'}, page_content='430 Chapter 13 XML: Extensible Markup Language\\ntags, and the individual table data elements in a row are displayed within \\n<TD> … </TD> tags.2\\n ■ Some tags may have attributes , which appear within the start tag and \\ndescribe additional properties of the tag.3\\nIn Figure 13.2, the <TABLE> start tag has four attributes describing various charac-\\nteristics of the table. The following < TD> and <FONT> start tags have one and two \\nattributes, respectively.\\nHTML has a very large number of predefined tags, and whole books are devoted to \\ndescribing how to use these tags. If designed properly, HTML documents can be \\nformatted so that humans are able to easily understand the document contents and \\nare able to navigate through the resulting Web documents. However, the source \\nHTML text documents are very difficult to interpret automatically by computer pro-\\ngrams because they do not include schema information about the type of data in the \\ndocuments. As e-commerce and other Internet applications become increasingly \\nautomated, it is becoming crucial to be able to exchange Web documents among \\nvarious computer sites and to interpret their contents automatically. This need was \\none of the reasons that led to the development of XML. In addition, an extendible \\nversion of HTML called XHTML was developed that allows users to extend the tags \\nof HTML for different applications and allows an XHTML file to be interpreted by \\nstandard XML processing programs. Our discussion will focus on XML only.\\nThe example in Figure 13.2 illustrates a static HTML page, since all the information \\nto be displayed is explicitly spelled out as fixed text in the HTML file. In many cases, \\nsome of the information to be displayed may be extracted from a database. For \\nexample, the project names and the employees working on each project may be \\nextracted from the database in Figure 5.6 through the appropriate SQL query. We \\nmay want to use the same HTML formatting tags for displaying each project and the \\nemployees who work on it, but we may want to change the particular projects (and \\nemployees) being displayed. For example, we may want to see a Web page displaying \\nthe information for ProjectX, and then later a page displaying the information for \\nProjectY. Although both pages are displayed using the same HTML formatting tags, \\nthe actual data items displayed will be different. Such Web pages are called dynamic, \\nsince the data parts of the page may be different each time it is displayed, even though \\nthe display appearance is the same. We discussed in Chapter 11 how scripting lan-\\nguages, such as PHP, can be used to generate dynamic Web pages.\\n13.2 X ML Hierarchical (Tree) Data Model\\nWe now introduce the data model used in XML. The basic object in XML is the XML \\ndocument. Two main structuring concepts are used to construct an XML document: \\nelements and attributes. It is important to note that the term attribute in XML is not \\n2<TR> stands for table row and <TD> stands for table data.\\n3This is how the term attribute is used in document markup languages, which differs from how it is used \\nin database models.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 444, 'page_label': '445'}, page_content='13.2 XML Hierarchical (Tree) Data Model  431\\nused in the same manner as is customary in database terminology, but rather as it is used \\nin document description languages such as HTML and SGML. 4 Attributes in XML \\nprovide additional information that describes elements, as we will see. There are addi-\\ntional concepts in XML, such as entities, identifiers, and references, but first we concen-\\ntrate on describing elements and attributes to show the essence of the XML model.\\nFigure 13.3 shows an example of an XML element called \\n<Projects>. As in HTML, \\nelements are identified in a document by their start tag and end tag. The tag names \\nare enclosed between angled brackets < … >, and end tags are further identified by \\na slash, </ … >.\\n5\\nComplex elements  are constructed from other elements hierarchically, whereas \\nsimple elements contain data values. A major difference between XML and HTML \\nis that XML tag names are defined to describe the meaning of the data elements in \\nthe document rather than to describe how the text is to be displayed. This makes it \\npossible to process the data elements in the XML document automatically by com-\\nputer programs. Also, the XML tag (element) names can be defined in another doc-\\nument, known as the schema document , to give a semantic meaning to the tag \\nnames that can be exchanged among multiple programs and users. In HTML, all \\ntag names are predefined and fixed; that is why they are not extendible.\\nIt is straightforward to see the correspondence between the XML textual representa-\\ntion shown in Figure 13.3 and the tree structure shown in Figure 13.1. In the tree \\nrepresentation, internal nodes represent complex elements, whereas leaf nodes rep-\\nresent simple elements. That is why the XML model is called a tree model  or a  \\nhierarchical model. In Figure 13.3, the simple elements are the ones with the tag \\nnames \\n<Name>, <Number>, <Location>, <Dept_no>, <Ssn>, <Last_name>, <First_name>, \\nand <Hours>. The complex elements are the ones with the tag names <Projects>,  \\n<Project>, and <Worker>. In general, there is no limit on the levels of nesting of elements.\\nIt is possible to characterize three main types of XML documents:\\n ■ Data-centric XML documents.  These documents have many small data \\nitems that follow a specific structure and hence may be extracted from a \\nstructured database. They are formatted as XML documents in order to \\nexchange them over the Web. These usually follow a predefined schema that \\ndefines the tag names.\\n ■ Document-centric XML documents.  These are documents with large \\namounts of text, such as news articles or books. There are few or no struc-\\ntured data elements in these documents.\\n ■ Hybrid XML documents.  These documents may have parts that contain \\nstructured data and other parts that are predominantly textual or unstruc-\\ntured. They may or may not have a predefined schema.\\n4SGML (Standard Generalized Markup Language) is a more general language for describing documents \\nand provides capabilities for specifying new tags. However, it is more complex than HTML and XML.\\n5The left and right angled bracket characters (< and >) are reserved characters, as are the ampersand \\n(&), apostrophe (’), and single quotation mark (‘). To include them within the text of a document, they \\nmust be encoded with escapes as &lt;, &gt;, &amp;, &apos;, and &quot;, respectively.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 445, 'page_label': '446'}, page_content='432 Chapter 13 XML: Extensible Markup Language\\n<?xml version=“1.0” standalone=“yes”?>\\n <Projects>\\n  <Project>\\n   <Name>ProductX</Name>\\n   <Number>1</Number>\\n   <Location>Bellaire</Location>\\n   <Dept_no>5</Dept_no>\\n   <Worker>\\n    <Ssn>123456789</Ssn>\\n    <Last_name>Smith</Last_name>\\n    <Hours>32.5</Hours>\\n   </Worker>\\n   <Worker>\\n    <Ssn>453453453</Ssn>\\n    <First_name>Joyce</First_name>\\n    <Hours>20.0</Hours>\\n   </Worker>\\n  </Project>\\n  <Project>\\n   <Name>ProductY</Name>\\n   <Number>2</Number>\\n   <Location>Sugarland</Location>\\n   <Dept_no>5</Dept_no>\\n   <Worker>\\n    <Ssn>123456789</Ssn>\\n    <Hours>7.5</Hours>\\n   </Worker>\\n   <Worker>\\n    <Ssn>453453453</Ssn>\\n    <Hours>20.0</Hours>\\n   </Worker>\\n   <Worker>\\n    <Ssn>333445555</Ssn>\\n    <Hours>10.0</Hours>\\n   </Worker>\\n  </Project>\\n …\\n </Projects>\\nFigure 13.3 \\nA complex XML  \\nelement called  \\n<Projects>.\\nXML documents that do not follow a predefined schema of element names and cor-\\nresponding tree structure are known as schemaless XML documents. It is impor-\\ntant to note that data-centric XML documents can be considered either as \\nsemistructured data or as structured data as defined in Section 13.1. If an XML \\ndocument conforms to a predefined XML schema or DTD (see Section 13.3), then \\nthe document can be considered as structured data. On the other hand, XML allows'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 446, 'page_label': '447'}, page_content='13.3 XML Documents, DTD, and XML Schema  433\\ndocuments that do not conform to any schema; these would be considered as  \\nsemistructured data  and are schemaless XML documents . When the value of the \\nstandalone attribute in an XML document is yes, as in the first line in Figure 13.3, \\nthe document is standalone and schemaless.\\nXML attributes are generally used in a manner similar to how they are used in \\nHTML (see Figure 13.2), namely, to describe properties and characteristics of the \\nelements (tags) within which they appear. It is also possible to use XML attributes \\nto hold the values of simple data elements; however, this is generally not recom-\\nmended. An exception to this rule is in cases that need to reference another ele-\\nment in another part of the XML document. To do this, it is common to use \\nattribute values in one element as the references. This resembles the concept of for-\\neign keys in relational databases, and it is a way to get around the strict hierarchical \\nmodel that the XML tree model implies. We discuss XML attributes further in Sec-\\ntion 13.3 when we discuss XML schema and DTD.\\n13.3 X ML Documents, DTD, and XML Schema\\n13.3.1  Well-Formed and Valid XML Documents and XML DTD\\nIn Figure 13.3, we saw what a simple XML document may look like. An XML docu-\\nment is well formed if it follows a few conditions. In particular, it must start with an \\nXML declaration to indicate the version of XML being used as well as any other \\nrelevant attributes, as shown in the first line in Figure 13.3. It must also follow the \\nsyntactic guidelines of the tree data model. This means that there should be a single \\nroot element, and every element must include a matching pair of start and end tags \\nwithin the start and end tags of the parent element. This ensures that the nested ele-\\nments specify a well-formed tree structure.\\nA well-formed XML document is syntactically correct. This allows it to be pro-\\ncessed by generic processors that traverse the document and create an internal tree \\nrepresentation. A standard model with an associated set of API (application pro-\\ngramming interface) functions called DOM (Document Object Model) allows pro-\\ngrams to manipulate the resulting tree representation corresponding to a \\nwell-formed XML document. However, the whole document must be parsed \\nbeforehand when using DOM in order to convert the document to that standard \\nDOM internal data structure representation. Another API called SAX (Simple API \\nfor XML) allows processing of XML documents on the fly by notifying the process-\\ning program through callbacks whenever a start or end tag is encountered. This \\nmakes it easier to process large documents and allows for processing of so-called \\nstreaming XML documents, where the processing program can process the tags as \\nthey are encountered. This is also known as event-based processing. There are also \\nother specialized processors that work with various programming and scripting \\nlanguages for parsing XML documents.\\nA well-formed XML document can be schemaless; that is, it can have any tag \\nnames for the elements within the document. In this case, there is no predefined'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 447, 'page_label': '448'}, page_content='434 Chapter 13 XML: Extensible Markup Language\\nset of elements (tag names) that a program processing the document knows to \\nexpect. This gives the document creator the freedom to specify new elements but \\nlimits the possibilities for automatically interpreting the meaning or semantics of \\nthe elements within the document.\\nA stronger criterion is for an XML document to be valid. In this case, the document \\nmust be well formed, and it must follow a particular schema. That is, the element \\nnames used in the start and end tag pairs must follow the structure specified in a \\nseparate XML DTD (Document Type Definition ) file or XML schema file . We \\nfirst discuss XML DTD here, and then we give an overview of XML schema in Sec-\\ntion 13.3.2. Figure 13.4 shows a simple XML DTD file, which specifies the elements \\n(tag names) and their nested structures. Any valid documents conforming to this \\nDTD should follow the specified structure. A special syntax exists for specifying \\nDTD files, as illustrated in Figure 13.4(a). First, a name is given to the root tag of \\nthe document, which is called \\nProjects in the first line in Figure 13.4. Then the ele-\\nments and their nested structure are specified.\\nWhen specifying elements, the following notation is used:\\n ■ A * following the element name means that the element can be repeated zero \\nor more times in the document. This kind of element is known as an optional \\nmultivalued (repeating) element.\\n ■ A + following the element name means that the element can be repeated one \\nor more times in the document. This kind of element is a required multival-\\nued (repeating) element.\\n ■ A ? following the element name means that the element can be repeated zero \\nor one times. This kind is an optional single-valued (nonrepeating) element.\\n ■ An element appearing without any of the preceding three symbols must \\nappear exactly once in the document. This kind is a required single-valued \\n(nonrepeating) element.\\n ■ The type of the element is specified via parentheses following the element. If \\nthe parentheses include names of other elements, these latter elements are \\nthe children of the element in the tree structure. If the parentheses include \\nthe keyword #PCDATA or one of the other data types available in XML DTD, \\nthe element is a leaf node. PCDATA stands for parsed character data, which is \\nroughly similar to a string data type.\\n ■ The list of attributes that can appear within an element can also be specified \\nvia the keyword !ATTLIST. In Figure 13.3, the Project element has an attribute \\nProjId. If the type of an attribute is ID, then it can be referenced from another \\nattribute whose type is IDREF within another element. Notice that attributes \\ncan also be used to hold the values of simple data elements of type #PCDATA.\\n ■ Parentheses can be nested when specifying elements.\\n ■ A bar symbol ( e1 | e2 ) specifies that either e1 or e2 can appear in the document.\\nWe can see that the tree structure in Figure 13.1 and the XML document in Fig-\\nure 13.3 conform to the XML DTD in Figure 13.4. To require that an XML \\ndocument be checked for conformance to a DTD, we must specify this in the'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 448, 'page_label': '449'}, page_content='13.3 XML Documents, DTD, and XML Schema  435\\ndeclaration of the document. For example, we could change the first line in Fig-\\nure 13.3 to the following:\\n<?xml version = “1.0” standalone = “no”?>\\n<!DOCTYPE Projects SYSTEM “proj.dtd”>\\nWhen the value of the standalone attribute in an XML document is “no”, the docu-\\nment needs to be checked against a separate DTD document or XML schema docu-\\nment (see Section 13.2.2). The DTD file shown in Figure 13.4 should be stored in \\nFigure 13.4 \\n(a) An XML DTD  \\nfile called Projects. \\n(b) An XML  \\nDTD file called \\nCompany.\\n(a)\\n <!DOCTYPE Projects [\\n  <!ELEMENT Projects (Project+)>\\n  <!ELEMENT Project (Name, Number, Location, Dept_no?, Workers)>\\n   <!ATTLIST Project\\n    ProjId ID #REQUIRED>\\n  <!ELEMENT Name (#PCDATA)>\\n  <!ELEMENT Number (#PCDATA)\\n  <!ELEMENT Location (#PCDATA)>\\n  <!ELEMENT Dept_no (#PCDATA)>\\n  <!ELEMENT Workers (Worker*)>\\n  <!ELEMENT Worker (Ssn, Last_name?, First_name?, Hours)>\\n  <!ELEMENT Ssn (#PCDATA)>\\n  <!ELEMENT Last_name (#PCDATA)>\\n  <!ELEMENT First_name (#PCDATA)>\\n  <!ELEMENT Hours (#PCDATA)>\\n ] >\\n(b) <!DOCTYPE Company [\\n  <!ELEMENT Company( (Employee|Department|Project)*)>\\n  <!ELEMENT Department (DName, Location+)>\\n   <!ATTLIST Department\\n    DeptId ID #REQUIRED>\\n  <!ELEMENT Employee (EName, Job, Salary)>\\n   <!ATTLIST Project\\n    EmpId ID #REQUIRED\\n    DeptId IDREF #REQUIRED>\\n  <!ELEMENT Project (PName, Location)\\n   <!ATTLIST Project\\n    ProjId ID #REQUIRED\\n    Workers IDREFS #IMPLIED>\\n  <!ELEMENT DName (#PCDATA)>\\n  <!ELEMENT EName (#PCDATA)>\\n  <!ELEMENT PName (#PCDATA)>\\n  <!ELEMENT Job (#PCDATA)\\n  <!ELEMENT Location (#PCDATA)>\\n  <!ELEMENT Salary (#PCDATA)>\\n ] >'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 449, 'page_label': '450'}, page_content='436 Chapter 13 XML: Extensible Markup Language\\nthe same file system as the XML document and should be given the file name  \\nproj.dtd. Alternatively, we could include the DTD document text at the beginning of \\nthe XML document itself to allow the checking.\\nFigure 13.4(b) shows another DTD document called Company to illustrate the use \\nof IDREF. A Company document can have any number of Department, Employee, \\nand Project elements, with IDs DeptID, EmpId, and ProjID, respectively. The \\nEmployee element has an attribute DeptId of type IDREF, which is a reference to \\nthe Department element where the employee works; this is similar to a foreign key. \\nThe Project element has an attribute Workers of type IDREFS, which will hold a list \\nof Employee EmpIDs that work on that project; this is similar to a collection or list \\nof foreign keys. The #IMPLIED keyword means that this attribute is optional. It is \\nalso possible to provide a default value for any attribute.\\nAlthough XML DTD is adequate for specifying tree structures with required, \\noptional, and repeating elements, and with various types of attributes, it has several \\nlimitations. First, the data types in DTD are not very general. Second, DTD has its \\nown special syntax and thus requires specialized processors. It would be advanta-\\ngeous to specify XML schema documents using the syntax rules of XML itself so \\nthat the same processors used for XML documents could process XML schema \\ndescriptions. Third, all DTD elements are always forced to follow the specified \\nordering of the document, so unordered elements are not permitted. These draw-\\nbacks led to the development of XML schema, a more general but also more com-\\nplex language for specifying the structure and elements of XML documents.\\n13.3.2 XML Schema\\nThe XML schema language is a standard for specifying the structure of XML docu-\\nments. It uses the same syntax rules as regular XML documents, so that the same pro-\\ncessors can be used on both. To distinguish the two types of documents, we will use the \\nterm XML instance document or XML document for a regular XML document that con-\\ntains both tag names and data values, and XML schema document for a document that \\nspecifies an XML schema. An XML schema document would contain only tag names, \\ntree structure information, constraints, and other descriptions but no data values. Fig-\\nure 13.5 shows an XML schema document corresponding to the \\nCOMPANY database \\nshown in Figure 5.5. Although it is unlikely that we would want to display the whole \\ndatabase as a single document, there have been proposals to store data in native XML \\nformat as an alternative to storing the data in relational databases. The schema in Fig-\\nure 13.5 would serve the purpose of specifying the structure of the \\nCOMPANY database \\nif it were stored in a native XML system. We discuss this topic further in Section 13.4.\\nAs with XML DTD, XML schema is based on the tree data model, with elements and \\nattributes as the main structuring concepts. However, it borrows additional concepts \\nfrom database and object models, such as keys, references, and identifiers. Here we \\ndescribe the features of XML schema in a step-by-step manner, referring to the sam-\\nple XML schema document in Figure 13.5 for illustration. We introduce and describe \\nsome of the schema concepts in the order in which they are used in Figure 13.5.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 450, 'page_label': '451'}, page_content='13.3 XML Documents, DTD, and XML Schema  437\\nFigure 13.5 \\nAn XML schema file called company.\\n<?xml version=“1.0” encoding=“UTF-8” ?>\\n<xsd:schema xmlns:xsd=“http://www.w3.org/2001/XMLSchema”>\\n <xsd:annotation>\\n  <xsd:documentation xml:lang=“en”>Company Schema (Element Approach) - Prepared by Babak\\n   Hojabri</xsd:documentation>\\n </xsd:annotation>\\n<xsd:element name=“company”>\\n <xsd:complexType>\\n  <xsd:sequence>\\n   <xsd:element name=“department” type=“Department” minOccurs=“0” maxOccurs=“unbounded” />\\n   <xsd:element name=“employee” type=“Employee” minOccurs=“0” maxOccurs=“unbounded”>\\n    <xsd:unique name=“dependentNameUnique”>\\n     <xsd:selector xpath=“employeeDependent” />\\n     <xsd:field xpath=“dependentName” />\\n    </xsd:unique>\\n   </xsd:element>\\n   <xsd:element name=“project” type=“Project” minOccurs=“0” maxOccurs=“unbounded” />\\n  </xsd:sequence>\\n </xsd:complexType>\\n <xsd:unique name=“departmentNameUnique”>\\n  <xsd:selector xpath=“department” />\\n  <xsd:field xpath=“departmentName” />\\n </xsd:unique>\\n <xsd:unique name=“projectNameUnique”>\\n  <xsd:selector xpath=“project” />\\n  <xsd:field xpath=“projectName” />\\n </xsd:unique>\\n <xsd:key name=“projectNumberKey”>\\n  <xsd:selector xpath=“project” />\\n  <xsd:field xpath=“projectNumber” />\\n </xsd:key>\\n <xsd:key name=“departmentNumberKey”>\\n  <xsd:selector xpath=“department” />\\n  <xsd:field xpath=“departmentNumber” />\\n </xsd:key>\\n <xsd:key name=“employeeSSNKey”>\\n  <xsd:selector xpath=“employee” />\\n  <xsd:field xpath=“employeeSSN” />\\n </xsd:key>\\n <xsd:keyref name=“departmentManagerSSNKeyRef” refer=“employeeSSNKey”>\\n  <xsd:selector xpath=“department” />\\n  <xsd:field xpath=“departmentManagerSSN” />\\n </xsd:keyref>\\n(continues)'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 451, 'page_label': '452'}, page_content='438 Chapter 13 XML: Extensible Markup Language\\n <xsd:keyref name=“employeeDepartmentNumberKeyRef”\\n  refer=“departmentNumberKey”>\\n  <xsd:selector xpath=“employee” />\\n  <xsd:field xpath=“employeeDepartmentNumber” />\\n </xsd:keyref>\\n <xsd:keyref name=“employeeSupervisorSSNKeyRef” refer=“employeeSSNKey”>\\n  <xsd:selector xpath=“employee” />\\n  <xsd:field xpath=“employeeSupervisorSSN” />\\n </xsd:keyref>\\n <xsd:keyref name=“projectDepartmentNumberKeyRef” refer=“departmentNumberKey”>\\n  <xsd:selector xpath=“project” />\\n  <xsd:field xpath=“projectDepartmentNumber” />\\n </xsd:keyref>\\n <xsd:keyref name=“projectWorkerSSNKeyRef” refer=“employeeSSNKey”>\\n  <xsd:selector xpath=“project/projectWorker” />\\n  <xsd:field xpath=“SSN” />\\n </xsd:keyref>\\n <xsd:keyref name=“employeeWorksOnProjectNumberKeyRef”\\n  refer=“projectNumberKey”>\\n  <xsd:selector xpath=“employee/employeeWorksOn” />\\n  <xsd:field xpath=“projectNumber” />\\n </xsd:keyref>\\n</xsd:element>\\n<xsd:complexType name=“Department”>\\n <xsd:sequence>\\n  <xsd:element name=“departmentName” type=“xsd:string” />\\n  <xsd:element name=“departmentNumber” type=“xsd:string” />\\n  <xsd:element name=“departmentManagerSSN” type=“xsd:string” />\\n  <xsd:element name=“departmentManagerStartDate” type=“xsd:date” />\\n  <xsd:element name=“departmentLocation” type=“xsd:string” minOccurs=“0” maxOccurs=“unbounded” />\\n </xsd:sequence>\\n</xsd:complexType>\\n<xsd:complexType name=“Employee”>\\n <xsd:sequence>\\n  <xsd:element name=“employeeName” type=“Name” />\\n  <xsd:element name=“employeeSSN” type=“xsd:string” />\\n  <xsd:element name=“employeeSex” type=“xsd:string” />\\n  <xsd:element name=“employeeSalary” type=“xsd:unsignedInt” />\\n  <xsd:element name=“employeeBirthDate” type=“xsd:date” />\\n  <xsd:element name=“employeeDepartmentNumber” type=“xsd:string” />\\n  <xsd:element name=“employeeSupervisorSSN” type=“xsd:string” />\\n  <xsd:element name=“employeeAddress” type=“Address” />\\n  <xsd:element name=“employeeWorksOn” type=“WorksOn” minOccurs=“1” maxOccurs=“unbounded” />\\n  <xsd:element name=“employeeDependent” type=“Dependent” minOccurs=“0” maxOccurs=“unbounded” />\\n </xsd:sequence>\\n</xsd:complexType>\\nFigure 13.5 (continued) \\nAn XML schema file called company.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 452, 'page_label': '453'}, page_content='13.3 XML Documents, DTD, and XML Schema  439\\n<xsd:complexType name=“Project”>\\n <xsd:sequence>\\n  <xsd:element name=“projectName” type=“xsd:string” />\\n  <xsd:element name=“projectNumber” type=“xsd:string” />\\n  <xsd:element name=“projectLocation” type=“xsd:string” />\\n  <xsd:element name=“projectDepartmentNumber” type=“xsd:string” />\\n  <xsd:element name=“projectWorker” type=“Worker” minOccurs=“1” maxOccurs=“unbounded” />\\n </xsd:sequence>\\n</xsd:complexType>\\n<xsd:complexType name=“Dependent”>\\n <xsd:sequence>\\n  <xsd:element name=“dependentName” type=“xsd:string” />\\n  <xsd:element name=“dependentSex” type=“xsd:string” />\\n  <xsd:element name=“dependentBirthDate” type=“xsd:date” />\\n  <xsd:element name=“dependentRelationship” type=“xsd:string” />\\n </xsd:sequence>\\n</xsd:complexType>\\n<xsd:complexType name=“Address”>\\n <xsd:sequence>\\n  <xsd:element name=“number” type=“xsd:string” />\\n  <xsd:element name=“street” type=“xsd:string” />\\n  <xsd:element name=“city” type=“xsd:string” />\\n  <xsd:element name=“state” type=“xsd:string” />\\n </xsd:sequence>\\n</xsd:complexType>\\n<xsd:complexType name=“Name”>\\n <xsd:sequence>\\n  <xsd:element name=“firstName” type=“xsd:string” />\\n  <xsd:element name=“middleName” type=“xsd:string” />\\n  <xsd:element name=“lastName” type=“xsd:string” />\\n </xsd:sequence>\\n</xsd:complexType>\\n<xsd:complexType name=“Worker”>\\n <xsd:sequence>\\n  <xsd:element name=“SSN” type=“xsd:string” />\\n  <xsd:element name=“hours” type=“xsd:float” />\\n </xsd:sequence>\\n</xsd:complexType>\\n<xsd:complexType name=“WorksOn”>\\n <xsd:sequence>\\n  <xsd:element name=“projectNumber” type=“xsd:string” />\\n  <xsd:element name=“hours” type=“xsd:float” />\\n </xsd:sequence>\\n</xsd:complexType>\\n</xsd:schema>\\nFigure 13.5 (continued) \\nAn XML schema file called company.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 453, 'page_label': '454'}, page_content='440 Chapter 13 XML: Extensible Markup Language\\n  1. Schema descriptions and XML namespaces.  It is necessary to identify the \\nspecific set of XML schema language elements (tags) being used by specify-\\ning a file stored at a Web site location. The second line in Figure 13.5 speci-\\nfies the file used in this example, which is \\nhttp://www.w3.org/2001/XMLSchema. \\nThis is a commonly used standard for XML schema commands. Each such \\ndefinition is called an XML namespace  because it defines the set of com-\\nmands (names) that can be used. The file name is assigned to the variable \\nxsd \\n(XML schema description) using the attribute xmlns (XML namespace), and \\nthis variable is used as a prefix to all XML schema commands (tag names). \\nFor example, in Figure 13.5, when we write \\nxsd:element or xsd:sequence, we \\nare referring to the definitions of the element and sequence tags as defined in \\nthe file http://www.w3.org/2001/XMLSchema.\\n  2. Annotations, documentation, and language used. The next couple of lines \\nin Figure 13.5 illustrate the XML schema elements (tags) xsd:annotation and \\nxsd:documentation , which are used for providing comments and other \\ndescriptions in the XML document. The attribute xml:lang  of the \\nxsd:documentation element specifies the language being used, where en stands \\nfor the English language.\\n  3. Elements and types. Next, we specify the root element of our XML schema. \\nIn XML schema, the name attribute of the xsd:element tag specifies the ele-\\nment name, which is called company for the root element in our example (see \\nFigure 13.5). The structure of the company root element can then be speci-\\nfied, which in our example is xsd:complexType. This is further specified to be \\na sequence of departments, employees, and projects using the xsd:sequence \\nstructure of XML schema. It is important to note here that this is not the \\nonly way to specify an XML schema for the COMPANY database. We will \\ndiscuss other options in Section 13.6.\\n  4. First-level elements in the COMPANY database. Next, we specify the three \\nfirst-level elements under the company root element in Figure 13.5. These \\nelements are named employee, department, and project, and each is specified \\nin an xsd:element tag. Notice that if a tag has only attributes and no further \\nsubelements or data within it, it can be ended with the backslash symbol (/>) \\ndirectly instead of having a separate matching end tag. These are called \\nempty elements ; examples are the xsd:element elements named department \\nand project in Figure 13.5.\\n  5. Specifying element type and minimum and maximum occurrences.  In \\nXML schema, the attributes type, minOccurs, and maxOccurs in the xsd:element \\ntag specify the type and multiplicity of each element in any document that \\nconforms to the schema specifications. If we specify a type attribute in an \\nxsd:element, the structure of the element must be described separately, typi-\\ncally using the xsd:complexType element of XML schema. This is illustrated \\nby the employee, department, and project elements in Figure 13.5. On the other \\nhand, if no type attribute is specified, the element structure can be defined \\ndirectly following the tag, as illustrated by the company root element in Fig-\\nure 13.5. The minOccurs and maxOccurs tags are used for specifying lower'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 454, 'page_label': '455'}, page_content='13.3 XML Documents, DTD, and XML Schema  441\\nand upper bounds on the number of occurrences of an element in any XML \\ndocument that conforms to the schema specifications. If they are not speci-\\nfied, the default is exactly one occurrence. These serve a similar role to the \\n*, \\n+, and ? symbols of XML DTD.\\n  6. Specifying keys.  In XML schema, it is possible to specify constraints that \\ncorrespond to unique and primary key constraints in a relational database \\n(see Section 5.2.2), as well as foreign keys (or referential integrity) con-\\nstraints (see Section 5.2.4). The \\nxsd:unique tag specifies elements that cor-\\nrespond to unique attributes in a relational database. We can give each \\nsuch uniqueness constraint a name, and we must specify \\nxsd:selector and \\nxsd:field tags for it to identify the element type that contains the unique ele-\\nment and the element name within it that is unique via the xpath attribute. \\nThis is illustrated by the departmentNameUnique  and projectNameUnique  ele-\\nments in Figure 13.5. For specifying primary keys , the tag xsd:key is used \\ninstead of xsd:unique , as illustrated by the projectNumberKey , department-\\nNumberKey , and employeeSSNKey  elements in Figure 13.5. For specifying \\nforeign keys , the tag xsd:keyref  is used, as illustrated by the six xsd:keyref \\nelements in Figure 13.5. When specifying a foreign key, the attribute refer \\nof the xsd:keyref tag specifies the referenced primary key, whereas the tags \\nxsd:selector  and xsd:field specify the referencing element type and foreign \\nkey (see Figure 13.5).\\n  7. Specifying the structures of complex elements via complex types.  The \\nnext part of our example specifies the structures of the complex elements \\nDepartment, Employee, Project, and Dependent, using the tag xsd:complexType \\n(see Figure 13.5). We specify each of these as a sequence of subelements cor-\\nresponding to the database attributes of each entity type (see Figure 7.7)by \\nusing the \\nxsd:sequence and xsd:element tags of XML schema. Each element is \\ngiven a name and type via the attributes name and type of xsd:element. We can \\nalso specify minOccurs and maxOccurs attributes if we need to change the \\ndefault of exactly one occurrence. For (optional) database attributes where \\nnull is allowed, we need to specify \\nminOccurs = 0 , whereas for multivalued \\ndatabase attributes we need to specify maxOccurs = “unbounded” on the cor-\\nresponding element. Notice that if we were not going to specify any key con-\\nstraints, we could have embedded the subelements within the parent element \\ndefinitions directly without having to specify complex types. However, when \\nunique, primary key and foreign key constraints need to be specified; we \\nmust define complex types to specify the element structures.\\n  8. Composite (compound) attributes.  Composite attributes from Figure 9.2 \\nare also specified as complex types in Figure 13.7, as illustrated by the \\nAddress, Name, Worker, and WorksOn complex types. These could have been \\ndirectly embedded within their parent elements.\\nThis example illustrates some of the main features of XML schema. There are other \\nfeatures, but they are beyond the scope of our presentation. In the next section, we \\ndiscuss the different approaches to creating XML documents from relational data-\\nbases and storing XML documents.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 455, 'page_label': '456'}, page_content='442 Chapter 13 XML: Extensible Markup Language\\n13.4  Storing and Extracting XML Documents \\nfrom Databases\\nSeveral approaches to organizing the contents of XML documents to facilitate their \\nsubsequent querying and retrieval have been proposed. The following are the most \\ncommon approaches:\\n  1. Using a file system or a DBMS to store the documents as text.  An XML \\ndocument can be stored as a text file within a traditional file system. Alter-\\nnatively, a relational DBMS can be used to store whole XML documents as \\ntext fields within the DBMS recordss. This approach can be used if the \\nDBMS has a special module for document processing, and it would work for \\nstoring schemaless and document-centric XML documents.\\n  2. Using a DBMS to store the document contents as data elements.  This \\napproach would work for storing a collection of documents that follow a \\nspecific XML DTD or XML schema. Because all the documents have the \\nsame structure, one can design a relational database to store the leaf-level \\ndata elements within the XML documents. This approach would require \\nmapping algorithms to design a database schema that is compatible with the \\nXML document structure as specified in the XML schema or DTD and to \\nre-create the XML documents from the stored data. These algorithms can be \\nimplemented either as an internal DBMS module or as separate middleware \\nthat is not part of the DBMS. If all elements in an XML document have IDs, \\na simple representation would be to have a table with attributes XDOC(CId, \\nPId, Etag, Val) where CID and PId are the parent and child element IDs, \\nEtag is the name of the element of the Cid, and Val is the value if it is a leaf \\nnode, assuming all values are the same type.\\n  3. Designing a specialized system for storing native XML data.  A new type \\nof database system based on the hierarchical (tree) model could be designed \\nand implemented. Such systems are referred to as native XML DBMSs. The \\nsystem would include specialized indexing and querying techniques and \\nwould work for all types of XML documents. It could also include data com-\\npression techniques to reduce the size of the documents for storage. Tamino \\nby Software AG and the Dynamic Application Platform of eXcelon are two \\npopular products that offer native XML DBMS capability. Oracle also offers \\na native XML storage option.\\n  4. Creating or publishing customized XML documents from preexisting \\nrelational databases. Because there are enormous amounts of data already \\nstored in relational databases, parts of this data may need to be formatted as \\ndocuments for exchanging or displaying over the Web. This approach would \\nuse a separate middleware software layer to handle the conversions needed \\nbetween the relational data and the extracted XML documents. Section 13.6 \\ndiscusses this approach, in which data-centric XML documents are extracted \\nfrom existing databases, in more detail. In particular, we show how tree \\nstructured documents can be created from flat relational databases that have'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 456, 'page_label': '457'}, page_content='13.5 XML Languages  443\\nbeen designed using the ER graph-structured data model. Section 13.6.2 \\ndiscusses the problem of cycles and how to deal with it.\\nAll of these approaches have received considerable attention. We focus on the \\nfourth approach in Section 13.6, because it gives a good conceptual understanding \\nof the differences between the XML tree data model and the traditional database \\nmodels based on flat files (relational model) and graph representations (ER model). \\nBut first we give an overview of XML query languages in Section 13.5.\\n13.5 X ML Languages\\nThere have been several proposals for XML query languages, and two query language \\nstandards have emerged. The first is XPath, which provides language constructs for \\nspecifying path expressions to identify certain nodes (elements) or attributes within \\nan XML document that match specific patterns. The second is XQuery, which is a \\nmore general query language. XQuery uses XPath expressions but has additional con-\\nstructs. We give an overview of each of these languages in this section. Then we dis-\\ncuss some additional languages related to HTML in Section 13.5.3.\\n13.5.1 XPath: Specifying Path Expressions in XML\\nAn XPath expression generally returns a sequence of items that satisfy a certain pat-\\ntern as specified by the expression. These items are either values (from leaf nodes) \\nor elements or attributes. The most common type of XPath expression returns a col-\\nlection of element or attribute nodes that satisfy certain patterns specified in the \\nexpression. The names in the XPath expression are node names in the XML docu-\\nment tree that are either tag (element) names or attribute names, possibly with \\nadditional qualifier conditions to further restrict the nodes that satisfy the pattern. \\nTwo main separators are used when specifying a path: single slash (/) and double \\nslash (//). A single slash before a tag specifies that the tag must appear as a direct \\nchild of the previous (parent) tag, whereas a double slash specifies that the tag can \\nappear as a descendant of the previous tag at any level. To refer to an attribute name \\ninstead of an element (tag) name, the prefix @ is used before the attribute name. Let \\nus look at some examples of XPath as shown in Figure 13.6.\\nThe first XPath expression in Figure 13.6 returns the \\ncompany root node and all its \\ndescendant nodes, which means that it returns the whole XML document. We \\nshould note that it is customary to include the file name in the \\nXPath query. This \\nallows us to specify any local file name or even any path name that specifies a file on \\nthe Web. For example, if the COMPANY XML document is stored at the location\\nwww.company.com/info.XML\\nthen the first XPath expression in Figure 13.6 can be written as\\ndoc(www.company.com/info.XML)/company\\nThis prefix would also be included in the other examples of XPath expressions.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 457, 'page_label': '458'}, page_content='444 Chapter 13 XML: Extensible Markup Language\\nThe second example in Figure 13.6 returns all department nodes (elements) and \\ntheir descendant subtrees. Note that the nodes (elements) in an XML document are \\nordered, so the XPath result that returns multiple nodes will do so in the same order \\nin which the nodes are ordered in the document tree.\\nThe third XPath expression in Figure 13.6 illustrates the use of //, which is conve-\\nnient to use if we do not know the full path name we are searching for, but we do \\nknow the name of some tags of interest within the XML document. This is particu-\\nlarly useful for schemaless XML documents or for documents with many nested \\nlevels of nodes.\\n6\\nThe expression returns all employeeName  nodes that are direct children of an \\nemployee node, such that the employee node has another child element employeeSalary \\nwhose value is greater than 70000. This illustrates the use of qualifier conditions, \\nwhich restrict the nodes selected by the XPath expression to those that satisfy the \\ncondition. XPath has a number of comparison operations for use in qualifier condi-\\ntions, including standard arithmetic, string, and set comparison operations.\\nThe fourth XPath expression in Figure 13.6 should return the same result as the pre-\\nvious one, except that we specified the full path name in this example. The fifth \\nexpression in Figure 13.6 returns all \\nprojectWorker  nodes and their descendant \\nnodes that are children under a path /company/project and have a child node, hours, \\nwith a value greater than 20.0 hours.\\nWhen we need to include attributes in an XPath expression, the attribute name is \\nprefixed by the @ symbol to distinguish it from element (tag) names. It is also pos-\\nsible to use the wildcard symbol *, which stands for any element, as in the following \\nexample, which retrieves all elements that are child elements of the root, regardless \\nof their element type. When wildcards are used, the result can be a sequence of dif-\\nferent types of elements.\\n/company/*\\nThe examples above illustrate simple XPath expressions, where we can only move \\ndown in the tree structure from a given node. A more general model for path \\nexpressions has been proposed. In this model, it is possible to move in multiple \\ndirections from the current node in the path expression. These are known as the \\n1. /company\\n2. /company/department\\n3. //employee [employeeSalary gt 70000]/employeeName\\n4. /company/employee [employeeSalary gt 70000]/employeeName\\n5. /company/project/projectWorker [hours ge 20.0]\\nFigure 13.6 \\nSome examples of \\nXPath expressions \\non XML documents \\nthat follow the XML \\nschema file company \\nin Figure 13.5.\\n6We use the terms node, tag, and element interchangeably here.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 458, 'page_label': '459'}, page_content='13.5 XML Languages  445\\naxes of an XPath expression. Our examples above used only three of these axes: child \\nof the current node (/), descendent or self at any level of the current node (//), and \\nattribute of the current node (@). Other axes include parent, ancestor (at any level), \\nprevious sibling (a node at same level to the left), and next sibling (a node at the \\nsame level to the right). These axes allow for more complex path expressions.\\nThe main restriction of \\nXPath path expressions is that the path that specifies the pat-\\ntern also specifies the items to be retrieved. Hence, it is difficult to specify certain \\nconditions on the pattern while separately specifying which result items should be \\nretrieved. The \\nXQuery language separates these two concerns and provides more \\npowerful constructs for specifying queries.\\n13.5.2 XQuery: Specifying Queries in XML\\nXPath allows us to write expressions that select items from a tree-structured XML \\ndocument. XQuery permits the specification of more general queries on one or \\nmore XML documents. The typical form of a query in XQuery  is known as a \\nFLWOR expression, which stands for the five main clauses of XQuery and has the \\nfollowing form:\\nFOR <variable bindings to individual nodes (elements)>\\nLET <variable bindings to collections of nodes (elements)>\\nWHERE <qualifier conditions>\\nORDER BY <ordering specifications>\\nRETURN <query result specification>\\nThere can be zero or more instances of the FOR clause, as well as of the LET clause \\nin a single XQuery. The WHERE and ORDER BY clauses are optional but can appear \\nat most once, and the RETURN clause must appear exactly once. Let us illustrate \\nthese clauses with the following simple example of an XQuery.\\nLET $d : = doc(www.company.com/info.xml)\\nFOR  $x IN $d/company/project[projectNumber = 5]/projectWorker, \\n$y IN $d/company/employee\\nWHERE $x/hours gt 20.0 AND $y.ssn = $x.ssn\\nORDER BY $x/hours\\nRETURN <res>  $y/employeeName/firstName, $y/employeeName/lastName,  \\n$x/hours </res>\\n  1. Variables are prefixed with the $ sign. In the above example, $d, $x, and $y \\nare variables. The LET clause assigns a variable to a particular expression for \\nthe rest of the query. In this example, $d is assigned to the document file \\nname. It is possible to have a query that refers to multiple documents by \\nassigning multiple variables in this way.\\n  2. The FOR clause assigns a variable to range over each of the individual ele-\\nments in a sequence. In our example, the sequences are specified by path \\nexpressions. The $x variable ranges over elements that satisfy the path expres-\\nsion $d/company/project[projectNumber = 5]/projectWorker.  The $y variable'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 459, 'page_label': '460'}, page_content='446 Chapter 13 XML: Extensible Markup Language\\nranges over elements that satisfy the path expression $d/company/employee. \\nHence, $x ranges over projectWorker elements for workers who work in proj-\\nect\\xa05, whereas $y ranges over employee elements.\\n  3. The WHERE clause specifies additional conditions on the selection of items. \\nIn this example, the first condition selects only those projectWorker elements \\nthat satisfy the condition (hours gt 20.0) . The second condition specifies a \\njoin condition that combines an employee with a projectWorker only if they \\nhave the same ssn value.\\n  4. The ORDER BY clause specifies that the result elements will be ordered by the \\nvalue of the hours per week they work on the project in ascending value of hours.\\n  5. Finally, the RETURN clause specifies which elements or attributes should be \\nretrieved from the items that satisfy the query conditions. In this example, it \\nwill return a sequence of elements each containing \\n<firstName, lastName, hours> \\nfor employees who work more that 20 hours per week on project number 5.\\nFigure 13.7 includes some additional examples of queries in XQuery that can be \\nspecified on an XML instance documents that follow the XML schema document \\nin Figure 13.5. The first query retrieves the first and last names of employees who \\nearn more than $70,000. The variable $x is bound to each employeeName element \\nthat is a child of an employee element, but only for employee elements that satisfy \\nthe qualifier that their employeeSalary  value is greater than $70,000. The result \\nretrieves the firstName and lastName child elements of the selected employeeName \\nelements. The second query is an alternative way of retrieving the same elements \\nretrieved by the first query.\\nThe third query illustrates how a join operation can be performed by using more \\nthan one variable. Here, the $x variable is bound to each projectWorker element that \\nis a child of project number 5, whereas the $y variable is bound to each employee \\nelement. The join condition matches ssn values in order to retrieve the employee \\nnames. Notice that this is an alternative way of specifying the same query in our \\nearlier example, but without the LET clause.\\nXQuery has very powerful constructs to specify complex queries. In particular, it can \\nspecify universal and existential quantifiers in the conditions of a query, aggregate \\nfunctions, ordering of query results, selection based on position in a sequence, and \\neven conditional branching. Hence, in some ways, it qualifies as a full-fledged pro-\\ngramming language.\\nThis concludes our brief introduction to XQuery. The interested reader is referred to \\nwww.w3.org, which contains documents describing the latest standards related to \\nXML and XQuery. The next section briefly discusses some additional languages and \\nprotocols related to XML.\\n13.5.3 Other Languages and Protocols Related to XML\\nThere are several other languages and protocols related to XML technology. \\nThe long-term goal of these and other languages and protocols is to provide the'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 460, 'page_label': '461'}, page_content='13.6 Extracting XML Documents from Relational Databases  447\\ntechnology for realization of the Semantic Web, where all information in the \\nWeb can be intelligently located and processed.\\n ■ The Extensible Stylesheet Language (XSL) can be used to define how a docu-\\nment should be rendered for display by a Web browser.\\n ■ The Extensible Stylesheet Language for Transformations (XSLT) can be \\nused to transform one structure into a different structure. Hence, it can con-\\nvert documents from one form to another.\\n ■ The Web Services Description Language (WSDL) allows for the description \\nof Web Services in XML. This makes the Web Service available to users and \\nprograms over the Web.\\n ■ The Simple Object Access Protocol (SOAP) is a platform-independent and \\nprogramming language-independent protocol for messaging and remote \\nprocedure calls.\\n ■ The Resource Description Framework (RDF) provides languages and tools \\nfor exchanging and processing of meta-data (schema) descriptions and \\nspecifications over the Web.\\n13.6  Extracting XML Documents from  \\nRelational Databases\\n13.6.1  Creating Hierarchical XML Views over  \\nFlat or Graph-Based Data\\nThis section discusses the representational issues that arise when converting data \\nfrom a database system into XML documents. As we have discussed, XML uses a \\nhierarchical (tree) model to represent documents. The database systems with the \\nmost widespread use follow the flat relational data model. When we add referential \\n1. FOR $x IN \\ndoc(www.company.com/info.xml) \\n//employee [employeeSalary gt 70000]/employeeName \\nRETURN <res> $x/firstName, $x/lastName </res>\\n2. FOR $x IN \\ndoc(www.company.com/info.xml)/company/employee \\nWHERE $x/employeeSalary gt 70000 \\nRETURN <res> $x/employeeName/firstName, $x/employeeName/lastName </res>\\n3. FOR $x IN \\ndoc(www.company.com/info.xml)/company/project[projectNumber=5]/projectWorker, \\n$y IN doc(www.company.com/info.xml)/company/employee\\n \\nWHERE $x/hours gt 20.0 AND $y.ssn=$x.ssn \\nRETURN <res> $y/employeeName/firstName, $y/employeeName/lastName, $x/hours </res>\\nFigure 13.7 \\nSome examples of XQuery \\nqueries on XML documents \\nthat follow the XML schema \\nfile company in Figure 13.5.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 461, 'page_label': '462'}, page_content='448 Chapter 13 XML: Extensible Markup Language\\nintegrity constraints, a relational schema can be considered to be a graph structure \\n(for example, see Figure 3.7). Similarly, the ER model represents data using graph-\\nlike structures (for example, see Figure 7.2). We saw in Chapter 9 that there are \\nstraightforward mappings between the ER and relational models, so we can con-\\nceptually represent a relational database schema using the corresponding ER \\nschema. Although we will use the ER model in our discussion and examples to clar-\\nify the conceptual differences between tree and graph models, the same issues apply \\nto converting relational data to XML.\\nWe will use the simplified \\nUNIVERSITY  ER schema shown in Figure 13.8 to illus-\\ntrate our discussion. Suppose that an application needs to extract XML docu-\\nments for student, course, and grade information from the \\nUNIVERSITY  database. \\nThe data needed for these documents is contained in the database attributes of \\nthe entity types \\nCOURSE , SECTION , and STUDENT  from Figure 13.8, and the \\nrelationships S-S and C-S between them. In general, most documents extracted \\nName\\nS-D\\nStudents\\nCourses\\nInstructors\\nMajor dept Department\\n1 1\\n1\\n1\\nN\\nN\\nS-S C-S S-1\\nD-1\\nD-C\\nDEPARTMENT\\nCOURSE\\nSECTION\\nName\\nSsn\\nN N\\nM 1\\nClass\\nYearNumber Qtr\\nGrade\\nSTUDENT\\nSections \\ncompleted Sections taught\\nN N\\nStudents attended Instructors\\nNameSsnName\\nNumber\\nRank\\nSalaryINSTRUCTOR\\nDepartment\\nCourse\\nSections\\nFigure 13.8 \\nAn ER schema diagram for a simplified UNIVERSITY database.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 462, 'page_label': '463'}, page_content='13.6 Extracting XML Documents from Relational Databases  449\\nfrom a database will only use a subset of the attributes, entity types, and relation-\\nships in the database. In this example, the subset of the database that is needed is \\nshown in Figure 13.9.\\nAt least three possible document hierarchies can be extracted from the database \\nsubset in Figure 13.9. First, we can choose \\nCOURSE as the root, as illustrated in \\nFigure 13.10. Here, each course entity has the set of its sections as subelements, and \\neach section has its students as subelements. We can see one consequence of mod-\\neling the information in a hierarchical tree structure. If a student has taken multiple \\nsections, that student’s information will appear multiple times in the document—\\nonce under each section. A possible simplified XML schema for this view is shown \\nin Figure 13.11. The Grade database attribute in the \\nS-S relationship is migrated to \\nthe STUDENT element. This is because STUDENT becomes a child of SECTION in this \\nhierarchy, so each STUDENT element under a specific SECTION element can have a \\n1\\nNumber\\nSections\\nName\\nCOURSE\\n1\\nNumber\\nStudents\\nattended\\nQtr\\nYearSECTION\\nN\\nN\\nName\\nSsn\\nGrade\\nClass\\nSTUDENT\\nFigure 13.10 \\nHierarchical (tree) view with \\nCOURSE as the root.\\nS-D\\nSsn\\nName\\nClass\\nSTUDENT\\nSections \\ncompleted\\nMN N1\\nNumber\\nYear Qtr\\nSECTION\\nNumber\\nName\\nCOURSES-D\\nStudents \\nattended\\nCourse Sections\\nGrade\\nFigure 13.9 \\nSubset of the UNIVERSITY database schema  \\nneeded for XML document extraction.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 463, 'page_label': '464'}, page_content='450 Chapter 13 XML: Extensible Markup Language\\n<xsd:element name=“root”>\\n <xsd:sequence>\\n <xsd:element name=“course” minOccurs=“0” maxOccurs=“unbounded”>\\n  <xsd:sequence>\\n   <xsd:element name=“cname” type=“xsd:string” />\\n   <xsd:element name=“cnumber” type=“xsd:unsignedInt” />\\n   <xsd:element name=“section” minOccurs=“0” maxOccurs=“unbounded”>\\n    <xsd:sequence>\\n     <xsd:element name=“secnumber” type=“xsd:unsignedInt” />\\n     <xsd:element name=“year” type=“xsd:string” />\\n     <xsd:element name=“quarter” type=“xsd:string” />\\n     <xsd:element name=“student” minOccurs=“0” maxOccurs=“unbounded”>\\n      <xsd:sequence>\\n       <xsd:element name=“ssn” type=“xsd:string” />\\n       <xsd:element name=“sname” type=“xsd:string” />\\n       <xsd:element name=“class” type=“xsd:string” />\\n       <xsd:element name=“grade” type=“xsd:string” />\\n      </xsd:sequence>\\n     </xsd:element>\\n    </xsd:sequence>\\n   </xsd:element>\\n  </xsd:sequence>\\n </xsd:element>\\n </xsd:sequence>\\n </xsd:element>\\nFigure 13.11 \\nXML schema document with course as the root.\\nspecific grade in that section. In this document hierarchy, a student taking more \\nthan one section will have several replicas, one under each section, and each replica \\nwill have the specific grade given in that particular section.\\nIn the second hierarchical document view, we can choose \\nSTUDENT as root (Fig-\\nure 13.12). In this hierarchical view, each student has a set of sections as its child \\nelements, and each section is related to one course as its child, because the rela-\\ntionship between \\nSECTION and COURSE is N:1. Thus, we can merge the COURSE \\nand SECTION elements in this view, as shown in Figure 13.12. In addition, the \\nGRADE database attribute can be migrated to the SECTION element. In this hier-\\narchy, the combined COURSE/SECTION  information is replicated under each stu-\\ndent who completed the section. A possible simplified XML schema for this view \\nis shown in Figure 13.13.\\nThe third possible way is to choose \\nSECTION as the root, as shown in Figure 13.14. \\nSimilar to the second hierarchical view, the COURSE information can be merged \\ninto the SECTION element. The GRADE database attribute can be migrated to the'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 464, 'page_label': '465'}, page_content='13.6 Extracting XML Documents from Relational Databases  451\\n1\\nSsn\\nSections\\ncompleted\\nNameSTUDENT\\n1\\nNumber\\nQtr\\nYear\\nSECTION\\n1\\nN\\nGrade\\nClass\\nCOURSE\\nCourse_number\\nCourse_name\\nFigure 13.12 \\nHierarchical (tree) view with \\nSTUDENT as the root.\\nFigure 13.13 \\nXML schema document \\nwith student as the root.\\n<xsd:element name=“root”>\\n<xsd:sequence>\\n<xsd:element name=“student” minOccurs=“0” maxOccurs=“unbounded”>\\n <xsd:sequence>\\n  <xsd:element name=“ssn” type=“xsd:string” />\\n  <xsd:element name=“sname” type=“xsd:string” />\\n  <xsd:element name=“class” type=“xsd:string” />\\n  <xsd:element name=“section” minOccurs=“0” maxOccurs=“unbounded”>\\n   <xsd:sequence>\\n    <xsd:element name=“secnumber” type=“xsd:unsignedInt” />\\n    <xsd:element name=“year” type=“xsd:string” />\\n    <xsd:element name=“quarter” type=“xsd:string” />\\n    <xsd:element name=“cnumber” type=“xsd:unsignedInt” />\\n    <xsd:element name=“cname” type=“xsd:string” />\\n    <xsd:element name=“grade” type=“xsd:string” />\\n   </xsd:sequence>\\n  </xsd:element>\\n </xsd:sequence>\\n</xsd:element>\\n</xsd:sequence>\\n</xsd:element>'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 465, 'page_label': '466'}, page_content='452 Chapter 13 XML: Extensible Markup Language\\nSTUDENT element. As we can see, even in this simple example, there can be numer-\\nous hierarchical document views, each corresponding to a different root and a dif-\\nferent XML document structure.\\n13.6.2 Breaking Cycles to Convert Graphs into Trees\\nIn the previous examples, the subset of the database of interest had no cycles. It is \\npossible to have a more complex subset with one or more cycles, indicating multi-\\nple relationships among the entities. In this case, it is more difficult to decide how \\nto create the document hierarchies. Additional duplication of entities may be \\nneeded to represent the multiple relationships. We will illustrate this with an exam-\\nple using the ER schema in Figure 13.8.\\nSuppose that we need the information in all the entity types and relationships in \\nFigure 13.8 for a particular XML document, with \\nSTUDENT as the root element. \\nFigure 13.15 illustrates how a possible hierarchical tree structure can be created for \\nthis document. First, we get a lattice with \\nSTUDENT as the root, as shown in Fig- \\nure 13.15(a). This is not a tree structure because of the cycles. One way to break the \\ncycles is to replicate the entity types involved in the cycles. First, we replicate \\nINSTRUCTOR  as shown in Figure 13.15(b), calling the replica to the right  \\nINSTRUCTOR1 . The INSTRUCTOR replica on the left represents the relationship \\nbetween instructors and the sections they teach, whereas the INSTRUCTOR1 replica \\non the right represents the relationship between instructors and the department \\neach works in. After this, we still have the cycle involving \\nCOURSE, so we can repli-\\ncate COURSE  in a similar manner, leading to the hierarchy shown in Fig- \\nure 13.15(c). The COURSE1 replica to the left represents the relationship between \\ncourses and their sections, whereas the COURSE replica to the right represents the \\nrelationship between courses and the department that offers each course.\\nIn Figure 13.15(c), we have converted the initial graph to a hierarchy. We can do \\nfurther merging if desired (as in our previous example) before creating the final \\nhierarchy and the corresponding XML schema structure.\\n1\\nSsn Students\\nattended\\nName\\nSTUDENT\\n1\\nNumber\\nQtr\\nYear\\nSECTION\\n1\\nN\\nGrade\\nClass\\nCOURSE\\nCourse_number\\nCourse_nameFigure 13.14 \\nHierarchical (tree) \\nview with SECTION as \\nthe root.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 466, 'page_label': '467'}, page_content='13.7 XML/SQL: SQL Functions for Creating XML Data  453\\n13.6.3  Other Steps for Extracting XML Documents  \\nfrom Databases\\nIn addition to creating the appropriate XML hierarchy and corresponding XML \\nschema document, several other steps are needed to extract a particular XML docu-\\nment from a database:\\n  1. It is necessary to create the correct query in SQL to extract the desired infor-\\nmation for the XML document.\\n  2. Once the query is executed, its result must be restructured from the flat rela-\\ntional form to the XML tree structure.\\n  3. The query can be customized to select either a single object or multiple \\nobjects into the document. For example, in the view in Figure 13.13, the \\nquery can select a single student entity and create a document corresponding \\nto that single student, or it may select several—or even all—of the students and \\ncreate a document with multiple students.\\n13.7  XML/SQL: SQL Functions for Creating \\nXML Data\\nIn this section, we discuss some of the functions that have been added to the recent \\nversions of the SQL standard for the purpose of generating XML data from relational \\ndatabases. These functions can be used to format the results of queries into XML ele-\\nments and documents, and to specify the roots of an XML hierarchy so that nested \\nhierarchical data can be created from flat relational data. First we list and briefly \\ndescribe some of the functions that were added to SQL; then we show a few examples.\\nCOURSE\\nINSTRUCTOR\\n11 NN\\n11NN\\n(a) (b)\\nSTUDENT\\nDEPARTMENTSECTION COURSE\\nINSTRUCTOR INSTRUCTOR1\\nSTUDENT\\nDEPARTMENTSECTION\\n(c)\\nSTUDENT\\nDEPARTMENTSECTION\\nINSTRUCTOR COURSE1 INSTRUCTOR1 COURSE\\n1\\nM\\nN\\nN\\nFigure 13.15 \\nConverting a graph with cycles into a hierarchical (tree) structure.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 467, 'page_label': '468'}, page_content='454 Chapter 13 XML: Extensible Markup Language\\nWe discuss the following functions:\\n  1. XMLELEMENT: This is used to specify a tag (element) name that will \\nappear in the XML result. It can specify a tag name for a complex element or \\nfor an individual column.\\n  2. XMLFOREST: If several tags (elements) are needed in the XML result, this \\nfunction can create multiple element names in a simpler manner than \\nXMLELEMENT. The column names can be listed directly, separated by \\ncommas, with or without renaming. If a column name is not renamed, it will \\nbe used as the element (tag) name.\\n  3. XMLAGG: This can group together (or aggregate) several elements so they \\ncan be placed under a parent element as a collection of subelements.\\n  4. XMLROOT: This allows the selected elements to be formatted as an XML \\ndocument with a single root element.\\n  5. XMLATTRIBUTES: This allows the creation of attributes for the elements \\nof the XML result.\\nWe now illustrate these functions with a few SQL/XML examples that refer to the \\nEMPLOYEE table from Figures 5.5 and 5.6. The first example X1 shows how to cre-\\nate an XML element that contains the EMPLOYEE lastname for the employee \\nwhose ssn is “123456789”:\\nX1: SELECT XMLELEMENT (NAME “lastname”, E.LName)\\n FROM EMPLOYEE E\\n WHERE E.Ssn = “123456789” ;\\nThe SQL keyword NAME specifies the XML element (tag) name. The result on the \\ndata shown in Figure 5.6 would be:\\n<lastname>Smith</lastname>\\nIf we want to retrieve multiple columns for a single row, we can use multiple list-\\nings of XMLELEMENT within the parent element, but a simpler way would be \\nto use XMLFOREST, which allows the specification of multiple columns without \\nrepeating the keyword XMLELEMENT multiple times. This is shown as X2:\\nX2: SELECT XMLELEMENT (NAME “employee”,\\n   XMLFOREST (\\n    E.Lname AS “ln”,\\n    E.Fname AS “fn”,\\n    E.Salary AS “sal” ) )\\n FROM EMPLOYEE AS E\\n WHERE E.Ssn = “123456789” ;\\nThe result of X2 on the data shown in Figure 5.6 would be:\\n<employee><ln>Smith</ln><fn>John</fn><sal>30000</sal></employee>\\nSuppose we want to create XML data that has the last name, first name, and \\nsalary of the employees who work in department 4, and format it as an XML'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 468, 'page_label': '469'}, page_content='13.8 Summary  455\\ndocument with the root tag “dept4emps”. Then we can write the SQL/XML \\nquery X3:\\nX3: SELECT XMLROOT (\\n  XMLELEMENT (NAME “dept4emps”,\\n  XMLAGG (\\n   XMLELEMENT (NAME “emp”\\n   XMLFOREST (Lname, Fname, Salary)\\n   ORDER BY Lname ) ) )\\n FROM EMPLOYEE\\n WHERE Dno = 4 ;\\nThe XMLROOT function creates a single root element, so the XML data would be a \\nwell-formed document (a tree with a single root). The result of X3 on the data \\nshown in Figure 5.6 would be:\\n<dept4emps>\\n<emp><Lname>Jabbar</Lname><Fname>Ahmad</Fname><Salary>25000 \\n </Salary></emp>\\n<emp><Lname>Wallace</Lname><Fname>Jennifer \\n </Fname><Salary>43000</Salary></emp>\\n<emp><Lname>Zelaya</Lname><Fname>Alicia</Fname><Salary>25000 \\n </Salary></emp>\\n</dept4emps>\\nThese examples give a flavor of how the SQL standard has been extended to allow \\nusers to format query results as XML data.\\n13.8 Summary\\nThis chapter provided an overview of the XML standard for representing and \\nexchanging data over the Internet. First we discussed some of the differences between \\nvarious types of data, classifying three main types: structured, semistructured, and \\nunstructured. Structured data is stored in traditional databases. Semistructured data \\nmixes data types names and data values, but the data does not all have to follow a \\nfixed predefined structure. Unstructured data refers to information displayed on the \\nWeb, specified via HTML, where information on the types of data items is missing. \\nWe described the XML standard and its tree-structured (hierarchical) data model, \\nand we discussed XML documents and the languages for specifying the structure of \\nthese documents, namely, XML DTD (Document Type Definition) and XML \\nschema. We gave an overview of the various approaches for storing XML docu-\\nments, whether in their native (text) format, in a compressed form, or in relational \\nand other types of databases. We gave an overview of the XPath and XQuery lan-\\nguages proposed for querying XML data, and we discussed the mapping issues that \\narise when it is necessary to convert data stored in traditional relational databases \\ninto XML documents. Finally, we discussed SQL/XML, which provides SQL with \\nadditional functionality to format SQL query results as XML data.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 469, 'page_label': '470'}, page_content='456 Chapter 13 XML: Extensible Markup Language\\nReview Questions\\n 13.1. What are the differences between structured, semistructured, and unstruc-\\ntured data?\\n 13.2. Under which of the categories mentioned in Question 13.1 do XML docu-\\nments fall? What about self-describing data?\\n 13.3. What are the differences between the use of tags in XML versus HTML?\\n 13.4. What is the difference between data-centric and document-centric XML \\ndocuments?\\n 13.5. What is the difference between attributes and elements in XML? List some \\nof the important attributes used to specify elements in XML schema.\\n 13.6. What is the difference between XML schema and XML DTD?\\nExercises\\n 13.7. Create part of an XML instance document to correspond to the data stored \\nin the relational database shown in Figure 5.6 such that the XML document \\nconforms to the XML schema document in Figure 13.5.\\n 13.8. Create XML schema documents and XML DTDs to correspond to the hier-\\narchies shown in Figures 13.14 and 13.15(c).\\n 13.9. Consider the LIBRARY relational database schema in Figure 6.6. Create an \\nXML schema document that corresponds to this database schema.\\n 13.10. Specify the following views as queries in XQuery on the company XML \\nschema shown in Figure 13.5.\\na. A view that has the department name, manager name, and manager salary \\nfor every department\\nb. A view that has the employee name, supervisor name, and employee salary \\nfor each employee who works in the Research department\\nc. A view that has the project name, controlling department name, number of \\nemployees, and total hours worked per week on the project for each project\\nd. A view that has the project name, controlling department name, number \\nof employees, and total hours worked per week on the project for each \\nproject with more than one employee working on it\\nSelected Bibliography\\nThere are so many articles and books on various aspects of XML that it would be \\nimpossible to make even a modest list. We will mention one book: Chaudhri, \\nRashid, and Zicari, editors (2003). This book discusses various aspects of XML and \\ncontains a list of references to XML research and practice.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 470, 'page_label': '471'}, page_content='Database Design Theory  \\nand Normalization  \\npart 6'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 471, 'page_label': '472'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 472, 'page_label': '473'}, page_content='459\\n14\\nBasics of Functional \\nDependencies and Normalization \\nfor Relational Databases\\nI\\nn Chapters 5 through 8, we presented various aspects \\nof the relational model and the languages associated \\nwith it. Each relation schema consists of a number of attributes, and the relational \\ndatabase schema consists of a number of relation schemas. So far, we have assumed \\nthat attributes are grouped to form a relation schema by using the common sense of \\nthe database designer or by mapping a database schema design from a conceptual \\ndata model such as the ER or enhanced-ER (EER) data model. These models make \\nthe designer identify entity types and relationship types and their respective attri-\\nbutes, which leads to a natural and logical grouping of the attributes into relations \\nwhen the mapping procedures discussed in Chapter 9 are followed. However, we \\nstill need some formal way of analyzing why one grouping of attributes into a rela-\\ntion schema may be better than another. While discussing database design in \\n Chapters 3, 4, and 9, we did not develop any measure of appropriateness or  goodness \\nto measure the quality of the design, other than the intuition of the designer. In this \\nchapter we discuss some of the theory that has been developed with the goal of \\nevaluating relational schemas for design quality—that is, to measure formally why \\none set of groupings of attributes into relation schemas is better than another.\\nThere are two levels at which we can discuss the goodness of relation schemas. The \\nfirst is the logical (or conceptual) level—how users interpret the relation schemas \\nand the meaning of their attributes. Having good relation schemas at this level \\nenables users to understand clearly the meaning of the data in the relations, and \\nhence to formulate their queries correctly. The second is the implementation (or \\nphysical storage) level—how the tuples in a base relation are stored and updated. \\nchapter 14'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 473, 'page_label': '474'}, page_content='460 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\nThis level applies only to schemas of base relations—which will be physically stored \\nas files—whereas at the logical level we are interested in schemas of both base rela-\\ntions and views (virtual relations). The relational database design theory developed \\nin this chapter applies mainly to base relations, although some criteria of appropri-\\nateness also apply to views, as shown in Section 14.1.\\nAs with many design problems, database design may be performed using two \\napproaches: bottom-up or top-down. A bottom-up design methodology (also called \\ndesign by synthesis) considers the basic relationships among individual attributes as \\nthe starting point and uses those to construct relation schemas. This approach is not \\nvery popular in practice\\n1 because it suffers from the problem of having to collect a \\nlarge number of binary relationships among attributes as the starting point. For prac-\\ntical situations, it is next to impossible to capture binary relationships among all such \\npairs of attributes. In contrast, a top-down design methodology (also called design by \\nanalysis) starts with a number of groupings of attributes into relations that exist \\ntogether naturally, for example, on an invoice, a form, or a report. The relations are \\nthen analyzed individually and collectively, leading to further decomposition until all \\ndesirable properties are met. The theory described in this chapter is applicable pri-\\nmarily to the top-down design approach, and as such is more appropriate when per-\\nforming design of databases by analysis and decomposition of sets of attributes that \\nappear together in files, in reports, and on forms in real-life situations.\\nRelational database design ultimately produces a set of relations. The implicit goals \\nof the design activity are information preservation  and minimum redundancy . \\nInformation is very hard to quantify—hence we consider information preservation \\nin terms of maintaining all concepts, including attribute types, entity types, and \\nrelationship types as well as generalization/specialization relationships, which are \\ndescribed using a model such as the EER model. Thus, the relational design must \\npreserve all of these concepts, which are originally captured in the conceptual \\ndesign after the conceptual to logical design mapping. Minimizing redundancy \\nimplies minimizing redundant storage of the same information and reducing the \\nneed for multiple updates to maintain consistency across multiple copies of the \\nsame information in response to real-world events that require making an update.\\nWe start this chapter by informally discussing some criteria for good and bad rela-\\ntion schemas in Section 14.1. In Section 14.2, we define the concept of functional \\ndependency, a formal constraint among attributes that is the main tool for formally \\nmeasuring the appropriateness of attribute groupings into relation schemas. In Sec-\\ntion 14.3, we discuss normal forms and the process of normalization using func-\\ntional dependencies. Successive normal forms are defined to meet a set of desirable \\nconstraints expressed using primary keys and functional dependencies. The normal-\\nization procedure consists of applying a series of tests to relations to meet these \\nincreasingly stringent requirements and decompose the relations when necessary. In \\nSection 14.4, we discuss more general definitions of normal forms that can be directly \\n1An exception in which this approach is used in practice is based on a model called the binary relational \\nmodel. An example is the NIAM methodology (Verheijen and VanBekkum, 1982).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 474, 'page_label': '475'}, page_content='14.1 Informal Design Guidelines for Relation Schemas  461\\napplied to any given design and do not require step-by-step analysis and normaliza-\\ntion. Sections 14.5 to 14.7 discuss further normal forms up to the fifth normal form. \\nIn Section 14.6 we introduce the multivalued dependency (MVD), followed by the \\njoin dependency (JD) in Section 14.7. Section 14.8 summarizes the chapter.\\nChapter 15 continues the development of the theory related to the design of good \\nrelational schemas. We discuss desirable properties of relational decomposition—\\nnonadditive join property and functional dependency preservation property. A \\ngeneral algorithm that tests whether or not a decomposition has the nonadditive \\n(or lossless) join property (Algorithm 15.3 is also presented). We then discuss prop-\\nerties of functional dependencies and the concept of a minimal cover of dependen-\\ncies. We consider the bottom-up approach to database design consisting of a set of \\nalgorithms to design relations in a desired normal form. These algorithms assume \\nas input a given set of functional dependencies and achieve a relational design in a \\ntarget normal form while adhering to the above desirable properties. In Chapter 15 \\nwe also define additional types of dependencies that further enhance the evaluation \\nof the goodness of relation schemas.\\nIf Chapter 15 is not covered in a course, we recommend a quick introduction to the \\ndesirable properties of decomposition from Section 15.2. and the importance of the \\nnon-additive join property during decomposition.\\n14.1  Informal Design Guidelines  \\nfor Relation Schemas\\nBefore discussing the formal theory of relational database design, we discuss four \\ninformal guidelines that may be used as measures to determine the quality of relation \\nschema design:\\n ■ Making sure that the semantics of the attributes is clear in the schema\\n ■ Reducing the redundant information in tuples\\n ■ Reducing the NULL values in tuples\\n ■ Disallowing the possibility of generating spurious tuples\\nThese measures are not always independent of one another, as we will see.\\n14.1.1 Imparting Clear Semantics to Attributes in Relations\\nWhenever we group attributes to form a relation schema, we assume that attri-\\nbutes belonging to one relation have certain real-world meaning and a proper \\ninterpretation associated with them. The semantics of a relation refers to its mean-\\ning resulting from the interpretation of attribute values in a tuple. In Chapter 5 we \\ndiscussed how a relation can be interpreted as a set of facts. If the conceptual \\ndesign described in Chapters 3 and 4 is done carefully and the mapping procedure \\nin Chapter 9 is followed systematically, the relational schema design should have a \\nclear meaning.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 475, 'page_label': '476'}, page_content='462 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\nIn general, the easier it is to explain the semantics of the relation—or in other words, \\nwhat a relation exactly means and stands for—the better the relation schema design \\nwill be. To illustrate this, consider Figure 14.1, a simplified version of the \\nCOMPANY \\nrelational database schema in Figure 5.5, and Figure 14.2, which presents an example \\nof populated relation states of this schema. The meaning of the \\nEMPLOYEE relation \\nschema is simple: Each tuple represents an employee, with values for the employee’s \\nname (\\nEname), Social Security number ( Ssn), birth date ( Bdate), and address \\n(Address), and the number of the department that the employee works for (Dnumber). \\nThe Dnumber attribute is a foreign key that represents an implicit relationship between \\nEMPLOYEE and DEPARTMENT. The semantics of the DEPARTMENT and PROJECT \\nschemas are also straightforward: Each DEPARTMENT tuple represents a department \\nentity, and each PROJECT tuple represents a project entity. The attribute Dmgr_ssn of \\nDEPARTMENT relates a department to the employee who is its manager, whereas \\nDnum of PROJECT relates a project to its controlling department; both are foreign key \\nattributes. The ease with which the meaning of a relation’s attributes can be explained \\nis an informal measure of how well the relation is designed.\\nDEPARTMENT\\nDnumberDname\\nEname Bdate Address Dnumber\\nEMPLOYEE\\nP.K.\\nP.K.\\nF.K.\\nPname Pnumber Plocation Dnum\\nPROJECT F.K.\\nF.K.\\nDEPT_LOCATIONS\\nDnumber Dlocation\\nP.K.\\nP.K.\\nPnumber Hours\\nWORKS_ON\\nF.K. F.K.\\nP.K.\\nF.K.\\nSsn\\nDmgr_ssn\\nSsn\\nFigure 14.1 \\nA simplified COMPANY relational \\ndatabase schema.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 476, 'page_label': '477'}, page_content='14.1 Informal Design Guidelines for Relation Schemas  463\\nEname\\nEMPLOYEE\\nSmith, John B.\\nWong, Franklin T.\\nZelaya, Alicia J.\\nWallace, Jennifer S.\\nNarayan, Ramesh K.\\nEnglish, Joyce A.\\nJabbar, Ahmad V.\\nBorg, James E.\\n999887777\\n123456789\\n333445555\\n453453453\\n987654321\\n666884444\\n987987987\\n888665555\\n666884444\\n123456789\\n123456789\\n333445555\\n453453453\\n453453453\\n333445555\\n333445555\\n333445555\\n999887777\\n987987987\\n999887777\\n987987987\\n987654321\\n987654321\\n888665555\\n3\\n1\\n2\\n2\\n1\\n2\\n3\\n10\\n20\\n10\\n30\\n10\\n30\\n30\\n20\\n20\\n40.0\\n32.5\\n7. 5\\n10.0\\n20.0\\n20.0\\n10.0\\n10.0\\n10.0\\n35.0\\n30.0\\n10.0\\n5.0\\n20.0\\n15.0\\nNull\\n1937-11-10\\n1968-07-19\\n1965-01-09\\n1955-12-08\\n1972-07-31\\n1969-03-29\\n1941-06-20\\n1962-09-15\\nBdate\\n3321 Castle, Spring, TX\\n731 Fondren, Houston, TX 5\\n638 Voss, Houston, TX\\n5631 Rice, Houston, TX\\n980 Dallas, Houston, TX\\n450 Stone, Houston, TX\\n291Berry, Bellaire, TX\\n975 Fire Oak, Humble, TX\\nAddress\\n4\\n5\\n5\\n4\\n1\\n4\\n5\\nDnumber\\nDname\\nDEPARTMENT\\nResearch\\nAdministration\\nHeadquarters 888665555\\n333445555\\n987654321\\nDnumber\\n5\\n1\\n4\\nDEPT_LOCATIONS\\n1\\n4\\n5\\nDnumber\\nHouston\\nDlocation\\nBellaire\\nStafford\\nHouston\\nSugarland\\n5\\n5\\nPROJECT\\nProductX\\nProductY\\nProductZ\\nPname\\n1\\nPnumber Plocation Dnum\\n3\\n2\\n20\\n10\\nReorganization\\n30\\n5\\n5\\n5\\n1\\n4\\n4\\nBellaire\\nHouston\\nSugarland\\nHouston\\nStafford\\nStaffordNewbenefits\\nComputerization\\nWORKS_ON\\nPnumber Hours\\nSsn\\nDmgr_ssn\\nSsn\\nFigure 14.2 \\nSample database state for the relational database schema in Figure 14.1.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 477, 'page_label': '478'}, page_content='464 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\nThe semantics of the other two relation schemas in Figure 14.1 are slightly more \\ncomplex. Each tuple in DEPT_LOCATIONS gives a department number ( Dnumber) \\nand one of the locations of the department ( Dlocation). Each tuple in WORKS_ON \\ngives an employee Social Security number ( Ssn), the project number of one of the \\nprojects that the employee works on (Pnumber), and the number of hours per week \\nthat the employee works on that project ( Hours). However, both schemas have a \\nwell-defined and unambiguous interpretation. The schema DEPT_LOCATIONS rep-\\nresents a multivalued attribute of DEPARTMENT, whereas WORKS_ON represents \\nan M:N relationship between EMPLOYEE and PROJECT. Hence, all the relation \\nschemas in Figure 14.1 may be considered as easy to explain and therefore good \\nfrom the standpoint of having clear semantics. We can thus formulate the following \\ninformal design guideline.\\nGuideline 1. Design a relation schema so that it is easy to explain its meaning. Do \\nnot combine attributes from multiple entity types and relationship types into a sin-\\ngle relation. Intuitively, if a relation schema corresponds to one entity type or one \\nrelationship type, it is straightforward to explain its meaning. Otherwise, if the rela-\\ntion corresponds to a mixture of multiple entities and relationships, semantic ambi-\\nguities will result and the relation cannot be easily explained.\\nExamples of Violating Guideline 1. The relation schemas in Figures 14.3(a)  \\nand 14.3(b) also have clear semantics. (The reader should ignore the lines under the \\nrelations for now; they are used to illustrate functional dependency notation, dis-\\ncussed in Section 14.2.) A tuple in the \\nEMP_DEPT relation schema in Figure 14.3(a) \\nrepresents a single employee but includes, along with the Dnumber (the identifier \\nfor the department he/she works for), additional information—namely, the  \\nname ( Dname) of the department for which the employee works and the Social \\nSecurity number ( Dmgr_ssn) of the department manager. For the EMP_PROJ rela-\\ntion in Figure 14.3(b), each tuple relates an employee to a project but also includes \\nSsn\\nEMP_PROJ\\n(b)\\n(a)\\nFD1\\nFD2\\nFD3\\nPnumber Hours Ename Pname Plocation\\nEname Ssn\\nEMP_DEPT\\nBdate Address Dnumber Dname Dmgr_ssn\\nFigure 14.3 \\nTwo relation schemas \\nsuffering from update \\nanomalies.  \\n(a) EMP_DEPT and  \\n(b) EMP_PROJ.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 478, 'page_label': '479'}, page_content='14.1 Informal Design Guidelines for Relation Schemas  465\\nthe employee name (Ename), project name (Pname), and project location (Plocation). \\nAlthough there is nothing wrong logically with these two relations, they violate \\nGuideline 1 by mixing attributes from distinct real-world entities: \\nEMP_DEPT mixes \\nattributes of employees and departments, and EMP_PROJ  mixes attributes of \\nemployees and projects and the WORKS_ON relationship. Hence, they fare poorly \\nagainst the above measure of design quality. They may be used as views, but they \\ncause problems when used as base relations, as we discuss in the following section.\\n14.1.2 Redundant Information in Tuples and Update Anomalies\\nOne goal of schema design is to minimize the storage space used by the base rela-\\ntions (and hence the corresponding files). Grouping attributes into relation sche-\\nmas has a significant effect on storage space. For example, compare the space used \\nby the two base relations \\nEMPLOYEE and DEPARTMENT in Figure 14.2 with that \\nfor an EMP_DEPT base relation in Figure 14.4, which is the result of applying the \\nNATURAL JOIN operation to EMPLOYEE and DEPARTMENT. In EMP_DEPT, the attri-\\nbute values pertaining to a particular department ( Dnumber, Dname, Dmgr_ssn) are \\nrepeated for every employee who works for that department. In contrast, each depart-\\nment’s information appears only once in the DEPARTMENT relation in Figure 14.2. \\nOnly the department number ( Dnumber) is repeated in the EMPLOYEE relation for \\neach employee who works in that department as a foreign key. Similar comments \\napply to the \\nEMP_PROJ relation (see Figure 14.4), which augments the WORKS_ON \\nrelation with additional attributes from EMPLOYEE and PROJECT.\\nStoring natural joins of base relations leads to an additional problem referred to as \\nupdate anomalies. These can be classified into insertion anomalies, deletion anom-\\nalies, and modification anomalies.2\\nInsertion Anomalies. Insertion anomalies can be differentiated into two types, \\nillustrated by the following examples based on the EMP_DEPT relation:\\n ■ To insert a new employee tuple into EMP_DEPT, we must include either the \\nattribute values for the department that the employee works for, or NULLs (if \\nthe employee does not work for a department as yet). For example, to insert \\na new tuple for an employee who works in department number 5, we must \\nenter all the attribute values of department 5 correctly so that they are con-\\nsistent with the corresponding values for department 5 in other tuples in \\nEMP_DEPT. In the design of Figure 14.2, we do not have to worry about this \\nconsistency problem because we enter only the department number in the \\nemployee tuple; all other attribute values of department 5 are recorded only \\nonce in the database, as a single tuple in the \\nDEPARTMENT relation.\\n ■ It is difficult to insert a new department that has no employees as yet in the \\nEMP_DEPT relation. The only way to do this is to place NULL values in the \\n2These anomalies were identified by Codd (1972a) to justify the need for normalization of relations, as \\nwe shall discuss in Section 15.3.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 479, 'page_label': '480'}, page_content='466 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\nattributes for employee. This violates the entity integrity for EMP_DEPT \\nbecause its primary key Ssn cannot be null. Moreover, when the first \\nemployee is assigned to that department, we do not need this tuple with \\nNULL values anymore. This problem does not occur in the design of Fig- \\nure 14.2 because a department is entered in the DEPARTMENT relation whether \\nor not any employees work for it, and whenever an employee is assigned to \\nthat department, a corresponding tuple is inserted in \\nEMPLOYEE.\\nEname\\nEMP_DEPT\\nSmith, John B.\\nWong, Franklin T.\\nZelaya, Alicia J.\\nWallace, Jennifer S.\\nNarayan, Ramesh K.\\nEnglish, Joyce A.\\nJabbar, Ahmad V.\\nBorg, James E.\\n999887777\\n123456789\\n333445555\\n453453453\\n987654321\\n666884444\\n987987987\\n888665555 1937-11-10\\nSsn\\n1968-07-19\\n1965-01-09\\n1955-12-08\\n1972-07-31\\n1969-03-29\\n1941-06-20\\n1962-09-15\\nBdate\\n3321 Castle, Spring, TX\\n731 Fondren, Houston, TX 5\\n638 Voss, Houston, TX\\n5631 Rice, Houston, TX\\n980 Dallas, Houston, TX\\n450 Stone, Houston, TX\\n291 Berry, Bellaire, TX\\n975 FireOak, Humble, TX\\nAddress\\n4\\n5\\n5\\n4\\n1\\n4\\n5\\nAdministration\\nResearch\\nResearch\\nResearch\\nAdministration\\nHeadquarters\\nAdministration\\nResearch\\n987654321\\n333445555\\n333445555\\n333445555\\n987654321\\n888665555\\n987654321\\n333445555\\nDnumber Dname Dmgr_ssn\\nSsn\\nEMP_PROJ\\n123456789\\n123456789\\n666884444\\n453453453\\n453453453\\n333445555\\n333445555\\n333445555\\n333445555\\n999887777\\n999887777\\n987987987\\n987987987\\n987654321\\n987654321\\n888665555\\n3\\n1\\n2\\n2\\n1\\n2\\n30\\n30\\n30\\n10\\n10\\n3\\n10\\n20\\n20\\n20\\nPnumber\\n40.0\\n32.5\\n7. 5\\n10.0\\n10.0\\n10.0\\n10.0\\n20.0\\n20.0\\n30.0\\n5.0\\n10.0\\n35.0\\n20.0\\n15.0\\nNull\\nHours\\nNarayan, Ramesh K.\\nSmith, John B.\\nSmith, John B.\\nWong, Franklin T.\\nWong, Franklin T.\\nWong, Franklin T.\\nWong, Franklin T.\\nEnglish, Joyce A.\\nEnglish, Joyce A.\\nZelaya, Alicia J.\\nJabbar, Ahmad V.\\nZelaya, Alicia J.\\nJabbar, Ahmad V.\\nWallace, Jennifer S.\\nWallace, Jennifer S.\\nBorg, James E.\\nEname\\nProductZ\\nProductX\\nProductY\\nProductY\\nProductZ\\nReorganization\\nProductX\\nProductY\\nNewbenefits\\nNewbenefits\\nComputerization\\nComputerization\\nNewbenefits\\nReorganization\\nReorganization\\nHouston\\nBellaire\\nSugarland\\nSugarland\\nHouston\\nStafford\\nHouston\\nBellaire\\nSugarland\\nStafford\\nStafford\\nStafford\\nStafford\\nStafford\\nHouston\\nHouston\\nPname Plocation\\nComputerization\\nRedundancy Redundancy\\nRedundancy\\nFigure 14.4 \\nSample states for EMP_DEPT and EMP_PROJ resulting from applying NATURAL JOIN to the relations  \\nin Figure 14.2. These may be stored as base relations for performance reasons.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 480, 'page_label': '481'}, page_content='14.1 Informal Design Guidelines for Relation Schemas  467\\nDeletion Anomalies. The problem of deletion anomalies is related to the second \\ninsertion anomaly situation just discussed. If we delete from EMP_DEPT an employee \\ntuple that happens to represent the last employee working for a particular depart-\\nment, the information concerning that department is lost inadvertently from the \\ndatabase. This problem does not occur in the database of Figure 14.2 because \\nDEPARTMENT tuples are stored separately.\\nModification Anomalies. In EMP_DEPT, if we change the value of one of the attri-\\nbutes of a particular department—say, the manager of department 5—we must \\nupdate the tuples of all employees who work in that department; otherwise, the \\ndatabase will become inconsistent. If we fail to update some tuples, the same depart-\\nment will be shown to have two different values for manager in different employee \\ntuples, which would be wrong.\\n3\\nIt is easy to see that these three anomalies are undesirable and cause difficulties to \\nmaintain consistency of data as well as require unnecessary updates that can be \\navoided; hence, we can state the next guideline as follows.\\nGuideline 2. Design the base relation schemas so that no insertion, deletion, or \\nmodification anomalies are present in the relations. If any anomalies are present,\\n4 \\nnote them clearly and make sure that the programs that update the database will \\noperate correctly.\\nThe second guideline is consistent with and, in a way, a restatement of the first \\nguideline. We can also see the need for a more formal approach to evaluating \\nwhether a design meets these guidelines. Sections 14.2 through 14.4 provide these \\nneeded formal concepts. It is important to note that these guidelines may some-\\ntimes have to be violated  in order to improve the performance of certain queries. If \\nEMP_DEPT is used as a stored relation (known otherwise as a materialized view) in \\naddition to the base relations of EMPLOYEE and DEPARTMENT, the anomalies in \\nEMP_DEPT must be noted and accounted for (for example, by using triggers or \\nstored procedures that would make automatic updates). This way, whenever the \\nbase relation is updated, we do not end up with inconsistencies. In general, it is \\nadvisable to use anomaly-free base relations and to specify views that include the \\njoins for placing together the attributes frequently referenced in important queries.\\n14.1.3 NULL Values in Tuples\\nIn some schema designs we may group many attributes together into a “fat” rela-\\ntion. If many of the attributes do not apply to all tuples in the relation, we end up \\nwith many \\nNULLs in those tuples. This can waste space at the storage level and may \\nalso lead to problems with understanding the meaning of the attributes and with \\n3This is not as serious as the other problems, because all tuples can be updated by a single SQL query.\\n4Other application considerations may dictate and make certain anomalies unavoidable. For example, the \\nEMP_DEPT relation may correspond to a query or a report that is frequently required.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 481, 'page_label': '482'}, page_content='468 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\nspecifying JOIN operations at the logical level.5 Another problem with NULLs is how \\nto account for them when aggregate operations such as COUNT or SUM are applied. \\nSELECT and JOIN operations involve comparisons; if NULL values are present, the \\nresults may become unpredictable.6 Moreover, NULLs can have multiple interpreta-\\ntions, such as the following:\\n ■ The attribute does not apply to this tuple. For example, Visa_status may not \\napply to U.S. students.\\n ■ The attribute value for this tuple is unknown. For example, the Date_of_birth \\nmay be unknown for an employee.\\n ■ The value is known but absent ; that is, it has not been recorded yet. For \\nexample, the Home_Phone_Number for an employee may exist, but may not \\nbe available and recorded yet.\\nHaving the same representation for all NULLs compromises the different meanings \\nthey may have. Therefore, we state another guideline.\\nGuideline 3. As far as possible, avoid placing attributes in a base relation whose \\nvalues may frequently be NULL. If NULLs are unavoidable, make sure that they apply \\nin exceptional cases only and do not apply to a majority of tuples in the relation.\\nUsing space efficiently and avoiding joins with NULL values are the two overriding \\ncriteria that determine whether to include the columns that may have NULLs in a \\nrelation or to have a separate relation for those columns (with the appropriate key \\ncolumns). For example, if only 15% of employees have individual offices, there is \\nlittle justification for including an attribute Office_number in the EMPLOYEE rela-\\ntion; rather, a relation EMP_OFFICES(Essn, Office_number) can be created to include \\ntuples for only the employees with individual offices.\\n14.1.4 Generation of Spurious Tuples\\nConsider the two relation schemas EMP_LOCS and EMP_PROJ1 in Figure 14.5(a), \\nwhich can be used instead of the single EMP_PROJ relation in Figure 14.3(b). A \\ntuple in EMP_LOCS means that the employee whose name is Ename works on at \\nleast one project located at Plocation. A tuple in EMP_PROJ1 refers to the fact that the \\nemployee whose Social Security number is Ssn works the given Hours per week on \\nthe project whose name, number, and location are Pname, Pnumber, and Plocation. \\nFigure 14.5(b) shows relation states of EMP_LOCS and EMP_PROJ1 corresponding \\nto the EMP_PROJ relation in Figure 14.4, which are obtained by applying the appro-\\npriate PROJECT (π) operations to EMP_PROJ.\\n5This is because inner and outer joins produce different results when NULLs are involved in joins. The users \\nmust thus be aware of the different meanings of the various types of joins. Although this is reasonable for \\nsophisticated users, it may be difficult for others.\\n6In Section 5.5.1 we presented comparisons involving NULL values where the outcome (in three-valued \\nlogic) is TRUE, FALSE, and UNKNOWN.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 482, 'page_label': '483'}, page_content='14.1 Informal Design Guidelines for Relation Schemas  469\\nSuppose that we used EMP_PROJ1 and EMP_LOCS as the base relations instead of \\nEMP_PROJ. This produces a particularly bad schema design because we cannot \\nrecover the information that was originally in EMP_PROJ from EMP_PROJ1 and \\nEMP_LOCS . If we attempt a NATURAL JOIN  operation on EMP_PROJ1  and  \\nEMP_LOCS, the result produces many more tuples than the original set of tuples  \\nin EMP_PROJ. In Figure 14.6, the result of applying the join to only the tuples for \\nemployee with Ssn = “123456789” is shown (to reduce the size of the resulting rela-\\ntion). Additional tuples that were not in \\nEMP_PROJ  are called spurious tuples  \\nbecause they represent spurious information that is not valid. The spurious \\ntuples are marked by asterisks (*) in Figure 14.6. It is left to the reader to complete \\nthe result of NATURAL JOIN operation on the EMP_PROJ1 and EMP_LOCS \\ntables in their entirety and to mark the spurious tuples in this result.\\nSsn Pnumber Hours Pname Plocation\\nEname\\nP.K.\\nEMP_PROJ1\\nPlocation\\nP.K.\\nEMP_LOCS\\nEname\\nSmith, John B.\\nSmith, John B.\\nNarayan, Ramesh K.\\nEnglish, Joyce A.\\nEnglish, Joyce A.\\nWong, Franklin T.\\nWong, Franklin T.\\nWong, Franklin T.\\nZelaya, Alicia J.\\nJabbar, Ahmad V.\\nWallace, Jennifer S.\\nWallace, Jennifer S.\\nBorg, James E.\\nHouston\\nBellaire\\nSugarland\\nSugarland\\nBellaire\\nSugarland\\nStafford\\nHouston\\nStafford\\nHouston\\nHouston\\nStafford\\nStafford\\nPlocation\\n(b)\\n(a)\\nEMP_PROJ1\\nSsn\\n123456789\\n123456789\\n666884444\\n453453453\\n453453453\\n333445555\\n333445555\\n333445555\\n333445555\\n999887777\\n999887777\\n987987987\\n987987987\\n987654321\\n987654321\\n888665555\\n3\\n1\\n2\\n2\\n1\\n2\\n30\\n30\\n30\\n10\\n10\\n3\\n10\\n20\\n20\\n20\\nPnumber\\n40.0\\n32.5\\n7. 5\\n10.0\\n10.0\\n10.0\\n10.0\\n20.0\\n20.0\\n30.0\\n5.0\\n10.0\\n35.0\\n20.0\\n15.0\\nNULL\\nProductZ\\nProductX\\nProductY\\nProductY\\nProductZ\\nComputerization\\nReorganization\\nProductX\\nProductY\\nNewbenefits\\nNewbenefits\\nComputerization\\nComputerization\\nNewbenefits\\nReorganization\\nReorganization\\nHouston\\nBellaire\\nSugarland\\nSugarland\\nHouston\\nStafford\\nHouston\\nBellaire\\nSugarland\\nStafford\\nStafford\\nStafford\\nStafford\\nStafford\\nHouston\\nHouston\\nHours Pname Plocation\\nEMP_LOCS\\nFigure 14.5 \\nParticularly poor design for the EMP_PROJ relation in \\nFigure 14.3(b). (a) The two relation schemas EMP_LOCS \\nand EMP_PROJ1. (b) The result of projecting the  \\nextension of EMP_PROJ from Figure 14.4 onto the  \\nrelations EMP_LOCS and EMP_PROJ1.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 483, 'page_label': '484'}, page_content='470 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\nDecomposing EMP_PROJ into EMP_LOCS and EMP_PROJ1 is undesirable because \\nwhen we JOIN them back using NATURAL JOIN, we do not get the correct original \\ninformation. This is because in this case Plocation happens to be the attribute that \\nrelates EMP_LOCS and EMP_PROJ1, and Plocation is neither a primary key nor a \\nforeign key in either EMP_LOCS or EMP_PROJ1. We now informally state another \\ndesign guideline.\\nGuideline 4. Design relation schemas so that they can be joined with equality \\nconditions on attributes that are appropriately related (primary key, foreign key) \\npairs in a way that guarantees that no spurious tuples are generated. Avoid relations \\nthat contain matching attributes that are not (foreign key, primary key) combina-\\ntions because joining on such attributes may produce spurious tuples.\\nSsn\\n123456789\\n123456789\\n123456789\\n123456789\\n123456789\\n666884444\\n666884444\\n453453453\\n453453453\\n453453453\\n453453453\\n453453453\\n333445555\\n333445555\\n333445555\\n333445555\\n2\\n1\\n1\\n3\\n2\\n2\\n2\\n2\\n2\\n2\\n2\\n3\\n1\\n1\\n2\\n3\\nPnumber\\n7. 5\\n32.5\\n32.5\\n40.0\\n40.0\\n20.0\\n20.0\\n7. 5\\n7. 5\\n20.0\\n10.0\\n20.0\\n20.0\\n10.0\\n10.0\\n10.0\\nHours\\nProductY\\nProductX\\nProductX\\nProductZ\\nProductZ\\nProductX\\nProductX\\nProductY\\nProductY\\nProductY\\nProductY\\nProductY\\nProductY\\nProductY\\nProductY\\nProductZ\\nPname\\nSugarland\\nBellaire\\nBellaire\\nHouston\\nHouston\\nBellaire\\nBellaire\\nSugarland\\nSugarland\\nSugarland\\nSugarland\\nSugarland\\nSugarland\\nSugarland\\nSugarland\\nHouston\\n333445555 3 10.0 ProductZ Houston\\n333445555 10 10.0 Computerization Stafford\\n333445555 20 10.0 Reorganization Houston\\n333445555 20\\n*\\n*\\n*\\n*\\n*\\n*\\n*\\n*\\n*\\n*\\n*\\n10.0 Reorganization Houston\\nSmith, John B.\\nSmith, John B.\\nEnglish, Joyce A.\\nNarayan, Ramesh K.\\nWong, Franklin T.\\nSmith, John B.\\nEnglish, Joyce A.\\nEnglish, Joyce A.\\nWong, Franklin T.\\nSmith, John B.\\nSmith, John B.\\nEnglish, Joyce A.\\nWong, Franklin T.\\nEnglish, Joyce A.\\nWong, Franklin T.\\nNarayan, Ramesh K.\\nWong, Franklin T.\\nWong, Franklin T.\\nNarayan, Ramesh K.\\nWong, Franklin T.\\nPlocation Ename\\n* * *\\nFigure 14.6 \\nResult of applying NATURAL JOIN to the tuples in EMP_PROJ1 and EMP_LOCS  \\nof Figure 14.5 just for employee with Ssn = “123456789”. Generated spurious  \\ntuples are marked by asterisks.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 484, 'page_label': '485'}, page_content='14.2 Functional Dependencies  471\\nThis informal guideline obviously needs to be stated more formally. In Section 15.2 \\nwe discuss a formal condition called the nonadditive (or lossless) join property that \\nguarantees that certain joins do not produce spurious tuples.\\n14.1.5 Summary and Discussion of Design Guidelines\\nIn Sections 14.1.1 through 14.1.4, we informally discussed situations that lead to \\nproblematic relation schemas and we proposed informal guidelines for a good rela-\\ntional design. The problems we pointed out, which can be detected without addi-\\ntional tools of analysis, are as follows:\\n ■ Anomalies that cause redundant work to be done during insertion into and \\nmodification of a relation, and that may cause accidental loss of information \\nduring a deletion from a relation\\n ■ Waste of storage space due to NULLs and the difficulty of performing selec-\\ntions, aggregation operations, and joins due to NULL values\\n ■ Generation of invalid and spurious data during joins on base relations with \\nmatched attributes that may not represent a proper (foreign key, primary \\nkey) relationship\\nIn the rest of this chapter we present formal concepts and theory that may be used \\nto define the goodness and badness of individual relation schemas more precisely. \\nFirst we discuss functional dependency as a tool for analysis. Then we specify the \\nthree normal forms and Boyce-Codd normal form (BCNF) for relation schemas as \\nthe established and accepted standards of quality in relational design. The strategy \\nfor achieving a good design is to decompose a badly designed relation appropriately \\nto achieve higher normal forms. We also briefly introduce additional normal forms \\nthat deal with additional dependencies. In Chapter 15, we discuss the properties of \\ndecomposition in detail and provide a variety of algorithms related to functional \\ndependencies, goodness of decomposition, and the bottom-up design of relations \\nby using the functional dependencies as a starting point.\\n14.2 Functional Dependencies\\nSo far we have dealt with the informal measures of database design. We now intro-\\nduce a formal tool for analysis of relational schemas that enables us to detect and \\ndescribe some of the above-mentioned problems in precise terms. The single most \\nimportant concept in relational schema design theory is that of a functional depen-\\ndency. In this section we formally define the concept, and in Section 14.3 we see \\nhow it can be used to define normal forms for relation schemas.\\n14.2.1 Definition of Functional Dependency\\nA functional dependency is a constraint between two sets of attributes from the \\ndatabase. Suppose that our relational database schema has n attributes A1, A2, \\n… , An; let us think of the whole database as being described by a single universal'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 485, 'page_label': '486'}, page_content='472 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\n relation schema R = {A1, A2, … , An}.7 We do not imply that we will actually store \\nthe database as a single universal table; we use this concept only in developing the \\nformal theory of data dependencies.\\n8\\nDefinition. A functional dependency, denoted by X → Y, between two sets of \\nattributes X and Y that are subsets of R specifies a constraint on the possible \\ntuples that can form a relation state r of R. The constraint is that, for any two \\ntuples t1 and t2 in r that have t1[X] = t2[X], they must also have t1[Y] = t2[Y].\\nThis means that the values of the Y component of a tuple in r depend on, or are deter-\\nmined by, the values of the X component; alternatively, the values of the X component \\nof a tuple uniquely (or functionally) determine the values of the Y component. We \\nalso say that there is a functional dependency from X to Y, or that Y is functionally \\ndependent on X. The abbreviation for functional dependency is FD or f.d. The set of \\nattributes X is called the left-hand side of the FD, and Y is called the right-hand side.\\nThus, X functionally determines Y in a relation schema R if, and only if, whenever \\ntwo tuples of r(R) agree on their X-value, they must necessarily agree on their \\nY-value. Note the following:\\n ■ If a constraint on R states that there cannot be more than one tuple with a \\ngiven X-value in any relation instance r(R)—that is, X is a candidate key of \\nR—this implies that X → Y for any subset of attributes Y of R (because the \\nkey constraint implies that no two tuples in any legal state r(R) will have the \\nsame value of X). If X is a candidate key of R, then X → R.\\n ■ If X → Y in R, this does not say whether or not Y → X in R.\\nA functional dependency is a property of the semantics  or meaning of the  \\nattributes. The database designers will use their understanding of the semantics of the \\nattributes of R—that is, how they relate to one another—to specify the functional \\ndependencies that should hold on all relation states (extensions) r of R. Relation \\nextensions r(R) that satisfy the functional dependency constraints are called legal \\nrelation states (or legal extensions) of R. Hence, the main use of functional depen-\\ndencies is to describe further a relation schema R by specifying constraints on its \\nattributes that must hold at all times. Certain FDs can be specified without referring \\nto a specific relation, but as a property of those attributes given their commonly \\nunderstood meaning. For example, { State, Driver_license_number } → Ssn should \\nnormally hold for any adult in the United States and hence should hold whenever \\nthese attributes appear in a relation.\\n9 It is also possible that certain functional \\n7This concept of a universal relation is important when we discuss the algorithms for relational database \\ndesign in Chapter 15.\\n8This assumption implies that every attribute in the database should have a distinct name. In Chapter 5 \\nwe prefixed attribute names by relation names to achieve uniqueness whenever attributes in distinct  \\nrelations had the same name.\\n9Note that there are databases, such as those of credit card agencies or police departments, where this \\nfunctional dependency may not hold because of fraudulent records resulting from the same driver’s \\nlicense number being used by two or more different individuals.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 486, 'page_label': '487'}, page_content='14.2 Functional Dependencies  473\\ndependencies may cease to exist in the real world if the relationship changes. For \\nexample, the FD Zip_code → Area_code used to exist as a relationship between postal \\ncodes and telephone number codes in the United States, but with the proliferation \\nof telephone area codes it is no longer true.\\nConsider the relation schema \\nEMP_PROJ in Figure 14.3(b); from the semantics of \\nthe attributes and the relation, we know that the following functional dependencies \\nshould hold:\\n \\na. Ssn → Ename\\n b. Pnumber → {Pname, Plocation}\\n c. {Ssn, Pnumber} → Hours\\nThese functional dependencies specify that (a) the value of an employee’s Social \\nSecurity number ( Ssn) uniquely determines the employee name ( Ename), (b) the \\nvalue of a project’s number ( Pnumber ) uniquely determines the project name \\n(Pname) and location (Plocation), and (c) a combination of Ssn and Pnumber values \\nuniquely determines the number of hours the employee currently works on the \\nproject per week ( Hours). Alternatively, we say that Ename is functionally deter-\\nmined by (or functionally dependent on) Ssn, or given a value of Ssn, we know the \\nvalue of Ename, and so on.\\nA functional dependency is a property of the relation schema R , not of a particular \\nlegal relation state r of R. Therefore, an FD cannot be inferred automatically from a \\ngiven relation extension r but must be defined explicitly by someone who knows \\nthe semantics of the attributes of R. For example, Figure 14.7 shows a particular \\nstate of the TEACH relation schema. Although at first glance we may think that  \\nText → Course, we cannot confirm this unless we know that it is true for all possible \\nlegal states of TEACH. It is, however, sufficient to demonstrate a single counterexam-\\nple to disprove a functional dependency. For example, because ‘Smith’ teaches both \\n‘Data Structures’ and ‘Database Systems,’ we can conclude that Teacher does not  \\nfunctionally determine Course.\\nGiven a populated relation, we cannot determine which FDs hold and which do not \\nunless we know the meaning of and the relationships among the attributes. All we can \\nsay is that a certain FD may exist if it holds in that particular extension. We cannot \\nguarantee its existence until we understand the meaning of the corresponding attri-\\nbutes. We can, however, emphatically state that a certain FD does not hold if there are \\nTEACH\\nTeacher\\nSmith\\nSmith\\nHall\\nBrown\\nBartram\\nMartin\\nHoffman\\nHorowitz\\nCompilers\\nData Structures\\nData Management\\nData Structures\\nCourse Text\\nFigure 14.7 \\nA relation state of TEACH with a \\npossible functional dependency \\nTEXT → COURSE. However, \\nTEACHER → COURSE,  \\nTEXT → TEACHER and  \\nCOURSE → TEXT are ruled out.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 487, 'page_label': '488'}, page_content='474 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\ntuples that show the violation of such an FD. See the illustrative example relation in \\nFigure 14.8. Here, the following FDs may hold because the four tuples in the current \\nextension have no violation of these constraints: B → C; C → B; {A, B} → C; {A, B} → D; \\nand {C, D} → B. However, the following do not hold because we already have viola-\\ntions of them in the given extension: A → B (tuples 1 and 2 violate this constraint);  \\nB → A (tuples 2 and 3 violate this constraint); D → C (tuples 3 and 4 violate it).\\nFigure 14.3 introduces a diagrammatic notation  for displaying FDs: Each FD is \\ndisplayed as a horizontal line. The left-hand-side attributes of the FD are connected \\nby vertical lines to the line representing the FD, whereas the right-hand-side attri-\\nbutes are connected by the lines with arrows pointing toward the attributes.\\nWe denote by F the set of functional dependencies that are specified on relation \\nschema R. Typically, the schema designer specifies the functional dependencies that \\nare semantically obvious; usually, however, numerous other functional dependen-\\ncies hold in all legal relation instances among sets of attributes that can be derived \\nfrom and satisfy the dependencies in F. Those other dependencies can be inferred \\nor deduced from the FDs in F. We defer the details of inference rules and properties \\nof functional dependencies to Chapter 15.\\n14.3 Normal Forms Based on Primary Keys\\nHaving introduced functional dependencies, we are now ready to use them to spec-\\nify how to use them to develop a formal methodology for testing and improving \\nrelation schemas. We assume that a set of functional dependencies is given for each \\nrelation, and that each relation has a designated primary key; this information com-\\nbined with the tests (conditions) for normal forms drives the normalization process \\nfor relational schema design. Most practical relational design projects take one of \\nthe following two approaches:\\n ■ Perform a conceptual schema design using a conceptual model such as ER \\nor EER and map the conceptual design into a set of relations.\\n ■ Design the relations based on external knowledge derived from an existing \\nimplementation of files or forms or reports.\\nFollowing either of these approaches, it is then useful to evaluate the relations for \\ngoodness and decompose them further as needed to achieve higher normal forms \\nusing the normalization theory presented in this chapter and the next. We focus in \\nFigure 14.8\\nA relation R(A, B, C, D) \\nwith its extension.\\nABCD\\na1 b1 c1 d1\\na1 b2 c2 d2\\na2 b2 c2 d3\\na3 b3 c4 d3'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 488, 'page_label': '489'}, page_content='14.3 Normal Forms Based on Primary Keys  475\\nthis section on the first three normal forms for relation schemas and the intuition \\nbehind them, and we discuss how they were developed historically. More general \\ndefinitions of these normal forms, which take into account all candidate keys of a \\nrelation rather than just the primary key, are deferred to Section 14.4.\\nWe start by informally discussing normal forms and the motivation behind their \\ndevelopment, as well as reviewing some definitions from Chapter 3 that are needed \\nhere. Then we discuss the first normal form (1NF) in Section 14.3.4, and we present \\nthe definitions of second normal form (2NF) and third normal form (3NF), which \\nare based on primary keys, in Sections 14.3.5 and 14.3.6, respectively.\\n14.3.1 Normalization of Relations\\nThe normalization process, as first proposed by Codd (1972a), takes a relation \\nschema through a series of tests to certify whether it satisfies a certain normal form. \\nThe process, which proceeds in a top-down fashion by evaluating each relation \\nagainst the criteria for normal forms and decomposing relations as necessary, can \\nthus be considered as relational design by analysis.  Initially, Codd proposed three \\nnormal forms, which he called first, second, and third normal form. A stronger \\ndefinition of 3NF—called Boyce-Codd normal form (BCNF)—was proposed later \\nby Boyce and Codd. All these normal forms are based on a single analytical tool: the \\nfunctional dependencies among the attributes of a relation. Later, a fourth normal \\nform (4NF) and a fifth normal form (5NF) were proposed, based on the concepts of \\nmultivalued dependencies and join dependencies, respectively; these are briefly dis-\\ncussed in Sections 14.6 and 14.7.\\nNormalization of data can be considered a process of analyzing the given relation \\nschemas based on their FDs and primary keys to achieve the desirable properties of \\n(1) minimizing redundancy and (2) minimizing the insertion, deletion, and update \\nanomalies discussed in Section 14.1.2. It can be considered as a “filtering” or “purifi-\\ncation” process to make the design have successively better quality. An unsatisfactory \\nrelation schema that does not meet the condition for a normal form—the normal \\nform test—is decomposed into smaller relation schemas that contain a subset of the \\nattributes and meet the test that was otherwise not met by the original relation. Thus, \\nthe normalization procedure provides database designers with the following:\\n ■ A formal framework for analyzing relation schemas based on their keys and \\non the functional dependencies among their attributes\\n ■ A series of normal form tests that can be carried out on individual relation \\nschemas so that the relational database can be normalized to any desired \\ndegree\\nDefinition. The normal form of a relation refers to the highest normal form \\ncondition that it meets, and hence indicates the degree to which it has been \\nnormalized.\\nNormal forms, when considered in isolation from other factors, do not guarantee a \\ngood database design. It is generally not sufficient to check separately that each'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 489, 'page_label': '490'}, page_content='476 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\nrelation schema in the database is, say, in BCNF or 3NF. Rather, the process of nor-\\nmalization through decomposition must also confirm the existence of additional \\nproperties that the relational schemas, taken together, should possess. These would \\ninclude two properties:\\n ■ The nonadditive join or lossless join property , which guarantees that the \\nspurious tuple generation problem discussed in Section 14.1.4 does not \\noccur with respect to the relation schemas created after decomposition\\n ■ The dependency preservation property, which ensures that each functional \\ndependency is represented in some individual relation resulting after \\ndecomposition\\nThe nonadditive join property is extremely critical and must be achieved at any \\ncost, whereas the dependency preservation property, although desirable, is some-\\ntimes sacrificed, as we discuss in Section 15.2.2. We defer the discussion of the for-\\nmal concepts and techniques that guarantee the above two properties to Chapter 15.\\n14.3.2 Practical Use of Normal Forms\\nMost practical design projects in commercial and governmental environment acquire \\nexisting designs of databases from previous designs, from designs in legacy models, or \\nfrom existing files. They are certainly interested in assuring that the designs are good \\nquality and sustainable over long periods of time. Existing designs are evaluated by \\napplying the tests for normal forms, and normalization is carried out in practice so \\nthat the resulting designs are of high quality and meet the desirable properties stated \\npreviously. Although several higher normal forms have been defined, such as the 4NF \\nand 5NF that we discuss in Sections 14.6 and 14.7, the practical utility of these normal \\nforms becomes questionable. The reason is that the constraints on which they are \\nbased are rare and hard for the database designers and users to understand or to \\ndetect. Designers and users must either already know them or discover them as a part \\nof the business. Thus, database design as practiced in industry today pays particular \\nattention to normalization only up to 3NF, BCNF, or at most 4NF.\\nAnother point worth noting is that the database designers need not normalize to the \\nhighest possible normal form. Relations may be left in a lower normalization status, \\nsuch as 2NF, for performance reasons, such as those discussed at the end of Sec- \\ntion 14.1.2. Doing so incurs the corresponding penalties of dealing with the anomalies.\\nDefinition. Denormalization is the process of storing the join of higher nor-\\nmal form relations as a base relation, which is in a lower normal form.\\n14.3.3 Definitions of Keys and Attributes Participating in Keys\\nBefore proceeding further, let’s look again at the definitions of keys of a relation \\nschema from Chapter 3.\\nDefinition. A superkey of a relation schema R = {A\\n1, A2, … , An} is a set of attri-\\nbutes S ⊆ R with the property that no two tuples t1 and t2 in any legal relation \\nstate r of R will have t1[S] = t2[S]. A key K is a superkey with the additional property \\nthat removal of any attribute from K will cause K not to be a superkey anymore.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 490, 'page_label': '491'}, page_content='14.3 Normal Forms Based on Primary Keys  477\\nThe difference between a key and a superkey is that a key has to be minimal; that is, \\nif we have a key K = {A1, A2, … , Ak} of R, then K − {Ai} is not a key of R for any Ai, \\n1 ≤ i ≤ k. In Figure 14.1, {Ssn} is a key for EMPLOYEE, whereas {Ssn}, {Ssn, Ename}, \\n{Ssn, Ename, Bdate}, and any set of attributes that includes Ssn are all superkeys.\\nIf a relation schema has more than one key, each is called a candidate key. One of \\nthe candidate keys is arbitrarily designated to be the primary key, and the others \\nare called secondary keys. In a practical relational database, each relation schema \\nmust have a primary key. If no candidate key is known for a relation, the entire rela-\\ntion can be treated as a default superkey. In Figure 14.1, {\\nSsn} is the only candidate \\nkey for EMPLOYEE, so it is also the primary key.\\nDefinition. An attribute of relation schema R is called a prime attribute of R if \\nit is a member of some candidate key of R. An attribute is called nonprime if it \\nis not a prime attribute—that is, if it is not a member of any candidate key.\\nIn Figure 14.1, both Ssn and Pnumber are prime attributes of WORKS_ON, whereas \\nother attributes of WORKS_ON are nonprime.\\nWe now present the first three normal forms: 1NF, 2NF, and 3NF. These were pro-\\nposed by Codd (1972a) as a sequence to achieve the desirable state of 3NF relations \\nby progressing through the intermediate states of 1NF and 2NF if needed. As we \\nshall see, 2NF and 3NF independently attack different types of problems arising \\nfrom problematic functional dependencies among attributes. However, for histori-\\ncal reasons, it is customary to follow them in that sequence; hence, by definition a \\n3NF relation already satisfies 2NF.\\n14.3.4 First Normal Form\\nFirst normal form (1NF)is now considered to be part of the formal definition of a \\nrelation in the basic (flat) relational model; historically, it was defined to disallow \\nmultivalued attributes, composite attributes, and their combinations. It states that \\nthe domain of an attribute must include only atomic (simple, indivisible) values and \\nthat the value of any attribute in a tuple must be a single value from the domain of \\nthat attribute. Hence, 1NF disallows having a set of values, a tuple of values, or a \\ncombination of both as an attribute value for a single tuple.  In other words, 1NF \\ndisallows relations within relations or relations as attribute values within tuples. The \\nonly attribute values permitted by 1NF are single atomic (or indivisible) values.\\nConsider the \\nDEPARTMENT relation schema shown in Figure 14.1, whose primary \\nkey is Dnumber, and suppose that we extend it by including the Dlocations attribute \\nas shown in Figure 14.9(a). We assume that each department can have a number of \\nlocations. The DEPARTMENT schema and a sample relation state are shown in Fig-\\nure 14.9. As we can see, this is not in 1NF because Dlocations is not an atomic attri-\\nbute, as illustrated by the first tuple in Figure 14.9(b). There are two ways we can \\nlook at the Dlocations attribute:\\n ■ The domain of Dlocations contains atomic values, but some tuples can have a \\nset of these values. In this ca se, Dlocations is not functionally dependent on \\nthe primary key Dnumber.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 491, 'page_label': '492'}, page_content='478 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\n ■ The domain of Dlocations contains sets of values and hence is nonatomic. In \\nthis case, Dnumber → Dlocations because each set is considered a single mem-\\nber of the attribute domain.10\\nIn either case, the DEPARTMENT relation in Figure 14.9 is not in 1NF; in fact, it does \\nnot even qualify as a relation according to our definition of relation in Section 3.1. \\nThere are three main techniques to achieve first normal form for such a relation:\\n  1. Remove the attribute Dlocations that violates 1NF and place it in a separate \\nrelation DEPT_LOCATIONS  along with the primary key Dnumber  of  \\nDEPARTMENT. The primary key of this newly formed relation is the combi-\\nnation { Dnumber, Dlocation}, as shown in Figure 14.2. A distinct tuple in \\nDEPT_LOCATIONS  exists for each location  of a department. This decom-\\nposes the non-1NF relation into two 1NF relations.\\nDname\\nDEPARTMENT\\n(a)\\nDEPARTMENT\\n(b)\\nDEPARTMENT\\n(c)\\nDnumber Dmgr_ssn Dlocations\\nDname\\nResearch\\nAdministration\\nHeadquarters 1\\n5\\n4\\nDnumber\\n888665555\\n333445555\\n987654321\\nDmgr_ssn\\n{Houston}\\n{Bellaire, Sugarland, Houston}\\n{Stafford}\\nDlocations\\nDname\\nResearch\\nResearch\\nResearch\\nAdministration\\nHeadquarters\\nBellaire\\nSugarland\\nHouston\\nStafford\\nHouston\\n5\\n5\\n5\\n4\\n1\\nDnumber\\n333445555\\n333445555\\n333445555\\n987654321\\n888665555\\nDmgr_ssn Dlocation\\nFigure 14.9 \\nNormalization into 1NF. (a) A \\nrelation schema that is not in \\n1NF. (b) Sample state of  \\nrelation DEPARTMENT.  \\n(c) 1NF version of the same \\nrelation with redundancy.\\n10In this case we can consider the domain of Dlocations to be the power set of the set of single  \\nlocations; that is, the domain is made up of all possible subsets of the set of single locations.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 492, 'page_label': '493'}, page_content='14.3 Normal Forms Based on Primary Keys  479\\n  2. Expand the key so that there will be a separate tuple in the original  \\nDEPARTMENT relation for each location of a DEPARTMENT, as shown in Fig-\\nure 14.9(c). In this case, the primary key becomes the combination {Dnumber, \\nDlocation}. This solution has the disadvantage of introducing redundancy in \\nthe relation and hence is rarely adopted.\\n  3. If a maximum number of values is known for the attribute—for example, if it \\nis known that at most three locations can exist for a department—replace the \\nDlocations attribute by three atomic attributes: Dlocation1, Dlocation2, and \\nDlocation3. This solution has the disadvantage of introducing NULL values if \\nmost departments have fewer than three locations. It further introduces \\nspurious semantics about the ordering among the location values; that \\nordering is not originally intended. Querying on this attribute becomes more \\ndifficult; for example, consider how you would write the query: List the \\ndepartments that have ‘Bellaire’ as one of their locations in this design. For all \\nthese reasons, it is best to avoid this alternative.\\nOf the three solutions above, the first is generally considered best because it \\ndoes not suffer from redundancy and it is completely general; it places no max-\\nimum limit on the number of values. In fact, if we choose the second solution, it \\nwill be decomposed further during subsequent normalization steps into the \\nfirst solution.\\nFirst normal form also disallows multivalued attributes that are themselves com-\\nposite. These are called nested relations  because each tuple can have a relation \\nwithin it. Figure 14.10 shows how the \\nEMP_PROJ relation could appear if nesting is \\nallowed. Each tuple represents an employee entity, and a relation PROJS(Pnumber, \\nHours) within each tuple represents the employee’s projects and the hours per week \\nthat employee works on each project. The schema of this EMP_PROJ relation can be \\nrepresented as follows:\\nEMP_PROJ(Ssn, Ename, {PROJS(Pnumber, Hours)})\\nThe set braces { } identify the attribute PROJS as multivalued, and we list the com-\\nponent attributes that form PROJS between parentheses ( ). Interestingly, recent \\ntrends for supporting complex objects (see Chapter 12) and XML data (see Chap-\\nter 13) attempt to allow and formalize nested relations within relational database \\nsystems, which were disallowed early on by 1NF.\\nNotice that Ssn is the primary key of the EMP_PROJ relation in Figures 14.10(a)  \\nand (b), whereas Pnumber is the partial key of the nested relation; that is, within each \\ntuple, the nested relation must have unique values of Pnumber. To normalize this \\ninto 1NF, we remove the nested relation attributes into a new relation and propa-\\ngate the primary key  into it; the primary key of the new relation will combine the \\npartial key with the primary key of the original relation. Decomposition and pri-\\nmary key propagation yield the schemas EMP_PROJ1 and EMP_PROJ2, as shown in \\nFigure 14.10(c).\\nThis procedure can be applied recursively to a relation with multiple-level nesting \\nto unnest the relation into a set of 1NF relations. This is useful in converting an'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 493, 'page_label': '494'}, page_content='480 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\nunnormalized relation schema with many levels of nesting into 1NF relations. As \\nan example, consider the following:\\nCANDIDATE (Ssn, Name, {JOB_HIST (Company, Highest_position,  \\n{SAL_HIST (Y ear, Max_sal)})})\\nThe foregoing describes data about candidates applying for jobs with their job his-\\ntory as a nested relation within which the salary history is stored as a deeper nested \\nEMP_PROJ\\n(a)\\nProjs\\nPnumber HoursSsn Ename\\nEMP_PROJ1\\n(c)\\nSsn Ename\\nEMP_PROJ2\\nHoursSsn Pnumber\\nEMP_PROJ\\n(b)\\nSsn\\n123456789\\n666884444\\n453453453\\n333445555\\n999887777\\n987987987\\n987654321\\n888665555\\nZelaya, Alicia J.\\nJabbar, Ahmad V.\\nWallace, Jennifer S.\\nBorg, James E.\\n32.5\\n7. 5\\n40.0\\n20.0\\n20.0\\n10.0\\n10.0\\n10.0\\n10.0\\n30.0\\n10.0\\n35.0\\n5.0\\n20.0\\n15.0\\nNULL\\nEnglish, Joyce A.\\nNarayan, Ramesh K.\\nSmith, John B.\\nWong, Franklin  T.\\nEname\\n3\\n1\\n2\\n1\\n2\\n2\\n20\\n3\\n10\\n30\\n10\\n10\\n20\\n30\\n30\\n20\\nPnumber Hours\\nFigure 14.10 \\nNormalizing nested  \\nrelations into 1NF.  \\n(a) Schema of the  \\nEMP_PROJ relation with \\na nested relation attribute \\nPROJS. (b) Sample  \\nextension of the  \\nEMP_PROJ relation \\nshowing nested relations \\nwithin each tuple.  \\n(c) Decomposition of  \\nEMP_PROJ into relations \\nEMP_PROJ1 and  \\nEMP_PROJ2 by  \\npropagating the primary \\nkey.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 494, 'page_label': '495'}, page_content='14.3 Normal Forms Based on Primary Keys  481\\nrelation. The first normalization using internal partial keys Company and Year, \\nrespectively, results in the following 1NF relations:\\nCANDIDATE_1 (Ssn, Name)\\nCANDIDATE_JOB_HIST (Ssn, Company, Highest_position)\\nCANDIDATE_SAL_HIST (Ssn, Company, Year, Max-sal)\\nThe existence of more than one multivalued attribute in one relation must be han-\\ndled carefully. As an example, consider the following non-1NF relation:\\nPERSON (Ss#, {Car_lic#}, {Phone#})\\nThis relation represents the fact that a person has multiple cars and multiple phones. \\nIf strategy 2 above is followed, it results in an all-key relation:\\nPERSON_IN_1NF (Ss#, Car_lic#, Phone#)\\nTo avoid introducing any extraneous relationship between Car_lic# and Phone#, all \\npossible combinations of values are represented for every Ss#, giving rise to redun-\\ndancy. This leads to the problems that are typically discovered at a later stage of \\nnormalization and that are handled by multivalued dependencies and 4NF, which \\nwe will discuss in Section 14.6. The right way to deal with the two multivalued attri-\\nbutes in \\nPERSON shown previously is to decompose it into two separate relations, \\nusing strategy 1 discussed above: P1(Ss#, Car_lic#) and P2(Ss#, Phone#).\\nA note about the relations that involve attributes that go beyond just numeric and \\ncharacter string data. It is becoming common in today’s databases to incorporate \\nimages, documents, video clips, audio clips, and so on. When these are stored in a \\nrelation, the entire object or file is treated as an atomic value, which is stored as a \\nBLOB (binary large object) or CLOB (character large object) data type using SQL. \\nFor practical purposes, the object is treated as an atomic, single-valued attribute \\nand hence it maintains the 1NF status of the relation.\\n14.3.5 Second Normal Form\\nSecond normal form (2NF) is based on the concept of full functional dependency. \\nA functional dependency X → Y is a full functional dependency if removal of any \\nattribute A from X means that the dependency does not hold anymore; that is, for \\nany attribute A ε X, ( X − {A}) does not functionally determine Y. A functional \\ndependency X → Y is a partial dependency if some attribute A ε X can be removed \\nfrom X and the dependency still holds; that is, for some A ε X, (X − {A}) → Y. In \\nFigure 14.3(b), {Ssn, Pnumber} → Hours is a full dependency (neither Ssn → Hours \\nnor Pnumber → Hours holds). However, the dependency {Ssn, Pnumber} → Ename is \\npartial because Ssn → Ename holds.\\nDefinition. A relation schema R is in 2NF if every nonprime attribute A in R is \\nfully functionally dependent on the primary key of R.\\nThe test for 2NF involves testing for functional dependencies whose left-hand side \\nattributes are part of the primary key. If the primary key contains a single attribute, \\nthe test need not be applied at all. The \\nEMP_PROJ relation in Figure 14.3(b) is in'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 495, 'page_label': '496'}, page_content='482 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\n1NF but is not in 2NF. The nonprime attribute Ename violates 2NF because of FD2, \\nas do the nonprime attributes Pname and Plocation because of FD3. Each of the func-\\ntional dependencies FD2 and FD3 violates 2NF because Ename can be functionally \\ndetermined by only Ssn, and both Pname and Plocation can be functionally deter-\\nmined by only Pnumber. Attributes Ssn and Pnumber are a part of the primary key \\n{\\nSsn, Pnumber} of EMP_PROJ, thus violating the 2NF test.\\nIf a relation schema is not in 2NF, it can be second normalized or 2NF normalized \\ninto a number of 2NF relations in which nonprime attributes are associated only \\nwith the part of the primary key on which they are fully functionally dependent. \\nTherefore, the functional dependencies \\nFD1, FD2, and FD3 in Figure 14.3(b) lead to \\nthe decomposition of EMP_PROJ into the three relation schemas EP1, EP2, and EP3 \\nshown in Figure 14.11(a), each of which is in 2NF.\\nSsn\\nEMP_PROJ\\n(a)\\n(b)\\nFD1\\nFD2\\nFD3\\n2NF Normalization\\nPnumber Hours Ename Pname Plocation\\nSsn\\nEP1\\nFD1\\nPnumber Hours\\nEname Ssn\\nED1\\nBdate Address Dnumber\\nSsn\\nEP2\\nFD2\\nEname Pnumber\\nEP3\\nFD3\\nPname Plocation\\nEname Ssn\\nEMP_DEPT\\nBdate Address Dnumber Dname Dmgr_ssn\\nDnumber\\nED2\\nDname Dmgr_ssn\\n3NF Normalization\\nFigure 14.11 \\nNormalizing into 2NF and 3NF. (a) Normalizing EMP_PROJ into  \\n2NF relations. (b) Normalizing EMP_DEPT into 3NF relations.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 496, 'page_label': '497'}, page_content='14.4 General Definitions of Second and Third Normal Forms  483\\n14.3.6 Third Normal Form\\nThird normal form (3NF) is based on the concept of transitive dependency. A func-\\ntional dependency X → Y in a relation schema R is a transitive dependency if there \\nexists a set of attributes Z in R that is neither a candidate key nor a subset of any key of \\nR,11 and both X → Z and Z → Y hold. The dependency Ssn → Dmgr_ssn is transitive \\nthrough Dnumber in EMP_DEPT in Figure 14.3(a), because both the dependencies  \\nSsn → Dnumber and Dnumber → Dmgr_ssn hold and Dnumber is neither a key itself nor a \\nsubset of the key of EMP_DEPT. Intuitively, we can see that the dependency of Dmgr_ssn \\non Dnumber is undesirable in EMP_DEPT since Dnumber is not a key of EMP_DEPT.\\nDefinition. According to Codd’s original definition, a relation schema R is in \\n3NF if it satisfies 2NF and no nonprime attribute of R is transitively dependent \\non the primary key.\\nThe relation schema EMP_DEPT in Figure 14.3(a) is in 2NF, since no partial depen-\\ndencies on a key exist. However, EMP_DEPT is not in 3NF because of the transitive \\ndependency of Dmgr_ssn (and also Dname) on Ssn via Dnumber. We can normalize \\nEMP_DEPT by decomposing it into the two 3NF relation schemas ED1 and ED2 \\nshown in Figure 14.11(b). Intuitively, we see that ED1 and ED2 represent indepen-\\ndent facts about employees and departments, both of which are entities in their \\nown right. A \\nNATURAL JOIN  operation on ED1 and ED2 will recover the original \\nrelation EMP_DEPT without generating spurious tuples.\\nIntuitively, we can see that any functional dependency in which the left-hand side is \\npart (a proper subset) of the primary key, or any functional dependency in which the \\nleft-hand side is a nonkey attribute, is a problematic FD. 2NF and 3NF normalization \\nremove these problem FDs by decomposing the original relation into new relations. In \\nterms of the normalization process, it is not necessary to remove the partial dependen-\\ncies before the transitive dependencies, but historically, 3NF has been defined with the \\nassumption that a relation is tested for 2NF first before it is tested for 3NF. Moreover, \\nthe general definition of 3NF we present in Section 14.4.2 automatically covers the \\ncondition that the relation also satisfies 2NF. Table 14.1 informally summarizes the \\nthree normal forms based on primary keys, the tests used in each case, and the corre-\\nsponding remedy or normalization performed to achieve the normal form.\\n14.4  General Definitions of Second  \\nand Third Normal Forms\\nIn general, we want to design our relation schemas so that they have neither partial \\nnor transitive dependencies because these types of dependencies cause the update \\nanomalies discussed in Section 14.1.2. The steps for normalization into 3NF rela-\\ntions that we have discussed so far disallow partial and transitive dependencies on \\n11This is the general definition of transitive dependency. Because we are concerned only with primary \\nkeys in this section, we allow transitive dependencies where X is the primary key but Z may be (a subset \\nof) a candidate key.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 497, 'page_label': '498'}, page_content='484 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\nthe primary key. The normalization procedure described so far is useful for analysis \\nin practical situations for a given database where primary keys have already been \\ndefined. These definitions, however, do not take other candidate keys of a relation, if \\nany, into account. In this section we give the more general definitions of 2NF and \\n3NF that take all candidate keys of a relation into account. Notice that this does not \\naffect the definition of 1NF since it is independent of keys and functional depen-\\ndencies. As a general definition of prime attribute, an attribute that is part of any \\ncandidate key will be considered as prime. Partial and full functional dependencies \\nand transitive dependencies will now be considered with respect to all candidate keys \\nof a relation.\\n14.4.1 General Definition of Second Normal Form\\nDefinition.  A relation schema R is in second normal form (2NF)  if every \\nnonprime attribute A in R is not partially dependent on any key of R.12\\nThe test for 2NF involves testing for functional dependencies whose left-hand side \\nattributes are part of the primary key. If the primary key contains a single attribute, \\nthe test need not be applied at all. Consider the relation schema LOTS shown in \\nFigure 14.12(a), which describes parcels of land for sale in various counties of a \\nstate. Suppose that there are two candidate keys: Property_id# and { County_name, \\nLot#}; that is, lot numbers are unique only within each county, but Property_id# \\nnumbers are unique across counties for the entire state.\\nTable 14.1 Summary of Normal Forms Based on Primary Keys and Corresponding Normalization\\nNormal Form Test Remedy (Normalization)\\nFirst (1NF) Relation should have no multivalued  \\nattributes or nested relations.\\nForm new relations for each multivalued \\nattribute or nested relation.\\nSecond (2NF) For relations where primary key  \\ncontains multiple attributes, no nonkey \\nattribute should be functionally  \\ndependent on a part of the primary key.\\nDecompose and set up a new relation \\nfor each partial key with its dependent \\nattribute(s). Make sure to keep a relation \\nwith the original primary key and any \\nattributes that are fully functionally \\ndependent on it.\\nThird (3NF) Relation should not have a nonkey  \\nattribute functionally determined by \\nanother nonkey attribute (or by a set of \\nnonkey attributes). That is, there should \\nbe no transitive dependency of a nonkey \\nattribute on the primary key.\\nDecompose and set up a relation that \\nincludes the nonkey attribute(s) that \\nfunctionally determine(s) other nonkey \\nattribute(s).\\n12This definition can be restated as follows: A relation schema R is in 2NF if every nonprime attribute A \\nin R is fully functionally dependent on every key of R.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 498, 'page_label': '499'}, page_content='14.4 General Definitions of Second and Third Normal Forms  485\\nProperty_id#\\nLOTS\\n(a)\\nFD1\\nFD2\\nFD3\\nFD4\\nCounty_name Lot# Area Price Tax_rate\\nProperty_id#\\nLOTS1\\n(b)\\nFD1\\nFD2\\nFD4\\nCounty_name Lot# Area Price\\n(c)\\n(d)\\nProperty_id#\\nLOTS1A\\nFD1\\nFD2\\nCounty_name Lot# Area\\nLOTS2\\nFD3\\nCounty_name Tax_rate\\nLOTS1B\\nFD4\\nArea Price\\nLOTS 1NF\\nLOTS1\\nLOTS1A LOTS1B\\nLOTS2 2NF\\nLOTS2 3NF\\nCandidate Key\\nFigure 14.12 \\nNormalization into 2NF and 3NF. (a) The LOTS relation with its functional dependencies  \\nFD1 through FD4. (b) Decomposing into the 2NF relations LOTS1 and LOTS2.  \\n(c) Decomposing LOTS1 into the 3NF relations LOTS1A and LOTS1B. (d) Progressive  \\nnormalization of LOTS into a 3NF design.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 499, 'page_label': '500'}, page_content='486 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\nBased on the two candidate keys Property_id# and { County_name, Lot#}, the func-\\ntional dependencies FD1 and FD2 in Figure 14.12(a) hold. We choose Property_id# \\nas the primary key, so it is underlined in Figure 14.12(a), but no special consider-\\nation will be given to this key over the other candidate key. Suppose that the follow-\\ning two additional functional dependencies hold in \\nLOTS:\\nFD3: County_name → Tax_rate\\nFD4: Area → Price\\nIn words, the dependency FD3 says that the tax rate is fixed for a given county (does \\nnot vary lot by lot within the same county), whereas FD4 says that the price of a lot \\nis determined by its area regardless of which county it is in. (Assume that this is the \\nprice of the lot for tax purposes.)\\nThe \\nLOTS relation schema violates the general definition of 2NF because Tax_rate is \\npartially dependent on the candidate key { County_name, Lot#}, due to FD3. To nor-\\nmalize LOTS into 2NF, we decompose it into the two relations LOTS1 and LOTS2, \\nshown in Figure 14.12(b). We construct LOTS1 by removing the attribute Tax_rate \\nthat violates 2NF from LOTS and placing it with County_name (the left-hand side of \\nFD3 that causes the partial dependency) into another relation LOTS2. Both LOTS1 \\nand LOTS2 are in 2NF. Notice that FD4 does not violate 2NF and is carried over to \\nLOTS1.\\n14.4.2 General Definition of Third Normal Form\\nDefinition. A relation schema R is in third normal form (3NF) if, whenever a \\nnontrivial functional dependency X → A holds in R, either (a) X is a superkey \\nof R, or (b) A is a prime attribute of R.13\\nAccording to this definition, LOTS2 (Figure 14.12(b)) is in 3NF. However, FD4 in \\nLOTS1 violates 3NF because Area is not a superkey and Price is not a prime attribute \\nin LOTS1. To normalize LOTS1 into 3NF, we decompose it into the relation sche-\\nmas LOTS1A and LOTS1B shown in Figure 14.12(c). We construct LOTS1A by \\nremoving the attribute Price that violates 3NF from LOTS1 and placing it with Area \\n(the left-hand side of FD4 that causes the transitive dependency) into another rela-\\ntion LOTS1B. Both LOTS1A and LOTS1B are in 3NF.\\nTwo points are worth noting about this example and the general definition of 3NF:\\n ■ LOTS1 violates 3NF because Price is transitively dependent on each of the \\ncandidate keys of LOTS1 via the nonprime attribute Area.\\n ■ This general definition can be applied directly to test whether a relation schema \\nis in 3NF; it does not have to go through 2NF first. In other words, if a relation \\npasses the general 3NF test, then it automatically passes the 2NF test.\\n13Note that based on inferred f.d.’s (which are discussed in Section 15.1), the f.d. Y → YA also holds \\nwhenever Y → A is true. Therefore, a slightly better way of saying this statement is that {A-X} is a prime \\nattribute of R.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 500, 'page_label': '501'}, page_content='14.5 Boyce-Codd Normal Form  487\\nIf we apply the above 3NF definition to LOTS with the dependencies FD1 through \\nFD4, we find that both FD3 and FD4 violate 3NF by the general definition above \\nbecause the LHS County_name in FD3 is not a superkey. Therefore, we could \\ndecompose \\nLOTS into LOTS1A, LOTS1B, and LOTS2 directly. Hence, the transitive \\nand partial dependencies that violate 3NF can be removed in any order.\\n14.4.3 Interpreting the General Definition of Third Normal Form\\nA relation schema R violates the general definition of 3NF if a functional depen-\\ndency X → A holds in R that meets either of the two conditions, namely (a) and (b). \\nThe first condition “catches” two types of problematic dependencies:\\n ■ A nonprime attribute determines another nonprime attribute. Here we typi-\\ncally have a transitive dependency that violates 3NF.\\n ■ A proper subset of a key of R functionally determines a nonprime attribute. \\nHere we have a partial dependency that violates 2NF.\\nThus, condition (a) alone addresses the problematic dependencies that were causes \\nfor second and third normalization as we discussed.\\nTherefore, we can state a general alternative definition of 3NF as follows:\\nAlternative Definition. A relation schema R is in 3NF if every nonprime attribute \\nof R meets both of the following conditions:\\n ■ It is fully functionally dependent on every key of R.\\n ■ It is nontransitively dependent on every key of R.\\nHowever, note the clause (b) in the general definition of 3NF. It allows certain func-\\ntional dependencies to slip through or escape in that they are OK with the 3NF \\ndefinition and hence are not “caught” by the 3NF definition even though they may \\nbe potentially problematic. The Boyce-Codd normal form “catches” these depen-\\ndencies in that it does not allow them. We discuss that normal form next.\\n14.5 Boyce-Codd Normal Form\\nBoyce-Codd normal form (BCNF) was proposed as a simpler form of 3NF, but it \\nwas found to be stricter than 3NF. That is, every relation in BCNF is also in 3NF; \\nhowever, a relation in 3NF is not necessarily in BCNF. We pointed out in the last \\nsubsection that although 3NF allows functional dependencies that conform to the \\nclause (b) in the 3NF definition, BCNF disallows them and hence is a stricter defini-\\ntion of a normal form.\\nIntuitively, we can see the need for a stronger normal form than 3NF by going back to \\nthe \\nLOTS relation schema in Figure 14.12(a) with its four functional dependencies FD1 \\nthrough FD4. Suppose that we have thousands of lots in the relation but the lots are \\nfrom only two counties: DeKalb and Fulton. Suppose also that lot sizes in DeKalb \\nCounty are only 0.5, 0.6, 0.7, 0.8, 0.9, and 1.0 acres, whereas lot sizes in Fulton County'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 501, 'page_label': '502'}, page_content='488 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\nare restricted to 1.1, 1.2, … , 1.9, and 2.0 acres. In such a situation we would have the \\nadditional functional dependency FD5: Area → County_name. If we add this to the other \\ndependencies, the relation schema LOTS1A still is in 3NF because this f.d. conforms to \\nclause (b) in the general definition of 3NF, County_name being a prime attribute.\\nThe area of a lot that determines the county, as specified by FD5, can be represented \\nby 16 tuples in a separate relation R(Area, County_name), since there are only 16 pos-\\nsible Area values (see Figure 14.13). This representation reduces the redundancy of \\nrepeating the same information in the thousands of LOTS1A tuples. BCNF is a \\nstronger normal form that would disallow LOTS1A and suggest the need for decom-\\nposing it.\\nDefinition. A relation schema R is in BCNF if whenever a nontrivial functional \\ndependency X → A holds in R, then X is a superkey of R.\\nThe formal definition of BCNF differs from the definition of 3NF in that clause (b) \\nof 3NF, which allows f.d.’s having the RHS as a prime attribute, is absent from \\nBCNF. That makes BCNF a stronger normal form compared to 3NF. In our exam-\\nple, \\nFD5 violates BCNF in LOTS1A because Area is not a superkey of LOTS1A. We \\ncan decompose LOTS1A into two BCNF relations LOTS1AX and LOTS1AY, shown \\nin Figure 14.13(a). This decomposition loses the functional dependency FD2 \\nbecause its attributes no longer coexist in the same relation after decomposition.\\nIn practice, most relation schemas that are in 3NF are also in BCNF. Only if there \\nexists some f.d. X → A that holds in a relation schema R with X not being a superkey \\nProperty_id#\\nLOTS1A(a)\\n(b)\\nFD1\\nFD2\\nFD1\\nFD2\\nFD5\\nBCNF Normalization\\nCounty_name Lot# Area\\nProperty_id#\\nLOTS1AX\\nArea Lot#\\nA\\nR\\nBC\\nArea\\nLOTS1AY\\nCounty_name\\nFigure 14.13 \\nBoyce-Codd normal form. (a) BCNF \\nnormalization of LOTS1A with the \\nfunctional dependency FD2 being \\nlost in the decomposition. (b) A \\nschematic relation with FDs; it is in \\n3NF, but not in BCNF due to the \\nf.d. C → B.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 502, 'page_label': '503'}, page_content='14.5 Boyce-Codd Normal Form  489\\nand A being a prime attribute will R be in 3NF but not in BCNF. The relation schema \\nR shown in Figure 14.13(b) illustrates the general case of such a relation. Such  \\nan f.d. leads to potential redundancy of data, as we illustrated above in case of  \\nFD5: Area → County_name.in LOTS1A relation. Ideally, relational database design \\nshould strive to achieve BCNF or 3NF for every relation schema. Achieving the normal-\\nization status of just 1NF or 2NF is not considered adequate, since both were developed \\nhistorically to be intermediate normal forms as stepping stones to 3NF and BCNF.\\n14.5.1 Decomposition of Relations not in BCNF\\nAs another example, consider Figure 14.14, which shows a relation TEACH with the \\nfollowing dependencies:\\nFD1: {Student, Course}  → Instructor\\nFD2:14  Instructor → Course\\nNote that {Student, Course} is a candidate key for this relation and that the depen-\\ndencies shown follow the pattern in Figure 14.13(b), with Student as A, Course as B, \\nand Instructor as C. Hence this relation is in 3NF but not BCNF. Decomposition of \\nthis relation schema into two schemas is not straightforward because it may be \\ndecomposed into one of the three following possible pairs:\\n  1. R1 (Student, Instructor) and R2(Student, Course)\\n  2. R1 (Course, Instructor) and R2(Course, Student)\\n  3. R1 (Instructor, Course) and R2(Instructor, Student)\\nAll three decompositions lose the functional dependency FD1. The question then \\nbecomes: Which of the above three is a desirable decomposition? As we pointed out \\nearlier (Section 14.3.1), we strive to meet two properties of decomposition during \\n14This dependency means that each instructor teaches one course is a constraint for this application.\\nTEACH\\nStudent\\nNarayan\\nSmith\\nSmith\\nSmith\\nMark\\nNavathe\\nAmmar\\nSchulman\\nOperating Systems\\nDatabase\\nDatabase\\nTheory\\nWallace\\nWallace\\nWong\\nZelaya\\nMark\\nAhamad\\nOmiecinski\\nNavathe\\nDatabase\\nDatabase\\nOperating Systems\\nDatabase\\nCourse Instructor\\nNarayan Operating Systems Ammar\\nFigure 14.14 \\nA relation TEACH that is in \\n3NF but not BCNF.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 503, 'page_label': '504'}, page_content='490 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\nthe normalization process: the nonadditive join property and the functional depen-\\ndency preservation property. We are not able to meet the functional dependency \\npreservation for any of the above BCNF decompositions as seen above; but we must \\nmeet the nonadditive join property. A simple test comes in handy to test the binary \\ndecomposition of a relation into two relations:\\nNJB (Nonadditive Join Test for Binary Decompositions).  A decomposition \\nD = {R\\n1, R2} of R has the lossless (nonadditive) join property with respect to a \\nset of functional dependencies F on R if and only if either\\n ■ The FD ((R1 ∩ R2) → (R1 − R2)) is in F+15, or\\n ■ The FD ((R1 ∩ R2) → (R2 − R1)) is in F+\\nIf we apply this test to the above three decompositions, we find that only the third \\ndecomposition meets the test. In the third decomposition, the R1 ∩ R2 for the above \\ntest is Instructor and R1 − R2 is Course. Because Instructor → Course, the NJB test \\nis satisfied and the decomposition is nonadditive. (It is left as an exercise for the \\nreader to show that the first two decompositions do not meet the NJB test.) Hence, \\nthe proper decomposition of TEACH into BCNF relations is:\\nTEACH1 (\\nInstructor, Course) and TEACH2 (Instructor, Student)\\nWe make sure that we meet this property, because nonadditive decomposition is \\na must during normalization. You should verify that this property holds with \\nrespect to our informal successive normalization examples in Sections 14.3 \\nand\\xa0 14.4 and also by the decomposition of \\nLOTS1A into two BCNF relations \\n LOTS1AX and LOTS1AY.\\nIn general, a relation R not in BCNF can be decomposed so as to meet the nonaddi-\\ntive join property by the following procedure.16 It decomposes R successively into a \\nset of relations that are in BCNF:\\nLet R be the relation not in BCNF, let X ⊆ R, and let X → A be the FD that \\ncauses a violation of BCNF. R may be decomposed into two relations:\\nR –A\\nXA\\nIf either R –A or XA. is not in BCNF, repeat the process.\\nThe reader should verify that if we applied the above procedure to LOTS1A, we \\nobtain relations LOTS1AX and LOTS1AY as before. Similarly, applying this proce-\\ndure to TEACH results in relations TEACH1 and TEACH2\\n15The notation F+ refers to the cover of the set of functional dependencies and includes all f.d.’s implied \\nby F. It is discussed in detail in Section 15.1. Here, it is enough to make sure that one of the two f.d.’s \\nactually holds for the nonadditive decomposition into R1 and R2 to pass this test.\\n16Note that this procedure is based on Algorithm 15.5 from Chapter 15 for producing BCNF schemas \\nby decomposition of a universal schema.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 504, 'page_label': '505'}, page_content='14.6 Multivalued Dependency and Fourth Normal Form  491\\nNote that if we designate (Student, Instructor) as a primary key of the relation TEACH, \\nthe FD instructor → Course causes a partial (non-fully-functional) dependency of \\nCourse on a part of this key. This FD may be removed as a part of second normaliza-\\ntion (or by a direct application of the above procedure to achieve BCNF) yielding \\nexactly the same two relations in the result. This is an example of a case where we \\nmay reach the same ultimate BCNF design via alternate paths of normalization.\\n14.6  Multivalued Dependency  \\nand Fourth Normal Form\\nConsider the relation EMP shown in Figure 14.15(a). A tuple in this EMP relation \\nrepresents the fact that an employee whose name is Ename works on the project \\nwhose name is Pname and has a dependent whose name is Dname. An employee \\nmay work on several projects and may have several dependents, and the employee’s \\nprojects and dependents are independent of one another.\\n17 To keep the relation \\nstate consistent and to avoid any spurious relationship between the two indepen-\\ndent attributes, we must have a separate tuple to represent every combination of an \\nemployee’s dependent and an employee’s project. In the relation state shown in \\nFigure 14.15(a), the employee with Ename Smith works on two projects ‘X’ and ‘Y’ \\nand has two dependents ‘John’ and ‘Anna’, and therefore there are four tuples to \\nrepresent these facts together. The relation EMP is an all-key relation  (with key \\nmade up of all attributes) and therefore has no f.d.’s and as such qualifies to be a \\nBCNF relation. We can see that there is an obvious redundancy in the relation \\nEMP—the dependent information is repeated for every project and the project \\ninformation is repeated for every dependent.\\nAs illustrated by the EMP relation, some relations have constraints that cannot be \\nspecified as functional dependencies and hence are not in violation of BCNF. To \\naddress this situation, the concept of multivalued dependency (MVD) was proposed \\nand, based on this dependency, the fourth normal form was defined. A more formal \\ndiscussion of MVDs and their properties is deferred to Chapter 15. Multivalued depen-\\ndencies are a consequence of first normal form (1NF) (see Section 14.3.4), which disal-\\nlows an attribute in a tuple to have a set of values. If more than one multivalued attribute \\nis present, the second option of normalizing the relation (see Section 14.3.4) intro-\\nduces a multivalued dependency. Informally, whenever two independent 1:N relation-\\nships A:B and A:C are mixed in the same relation, R(A, B, C), an MVD may arise.\\n18\\n14.6.1 Formal Definition of Multivalued Dependency\\nDefinition. A multivalued dependency X → Y specified on relation schema R, \\nwhere X and Y are both subsets of R, specifies the following constraint on any \\n17In an ER diagram, each would be represented as a multivalued attribute or as a weak entity type  \\n(see Chapter 7).\\n18This MVD is denoted as A →→ B|C.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 505, 'page_label': '506'}, page_content='492 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\nrelation state r of R: If two tuples t1 and t2 exist in r such that t1[X] = t2[X], then \\ntwo tuples t3 and t4 should also exist in r with the following properties,19 where \\nwe use Z to denote (R − (X ∪ Y)):20\\n ■ t3[X] = t4[X] = t1[X] = t2[X]\\n ■ t3[Y] = t1[Y] and t4[Y] = t2[Y]\\n ■ t3[Z] = t2[Z] and t4[Z] = t1[Z]\\n(a) EMP\\nEname\\nSmith\\nSmith\\nSmith\\nSmith\\nJohn\\nAnna\\nAnna\\nJohn\\nX\\nY\\nX\\nY\\nPname Dname\\n(b) EMP_PROJECTS\\nEname\\nSmith\\nSmith\\nX\\nY\\nPname\\nEMP_DEPENDENTS\\nEname\\nSmith\\nSmith\\nJohn\\nAnna\\nDname\\n(c) SUPPL Y\\nSname\\nSmith\\nSmith\\nAdamsky\\nWalton\\nAdamsky\\nAdamsky\\nSmith\\nBolt\\nBolt\\nNut\\nBolt\\nNut\\nNail\\nBolt\\nProjY\\nProjX\\nProjY\\nProjX\\nProjZ\\nProjX\\nProjY\\nPart_name Proj_name\\n(d) R\\n1\\nSname\\nSmith\\nSmith\\nAdamsky\\nWalton\\nAdamsky\\nBolt\\nBolt\\nNut\\nNut\\nNail\\nBolt\\nBolt\\nNut\\nNut\\nNail\\nPart_name\\nR\\n2\\nSname\\nSmith\\nSmith\\nAdamsky\\nWalton\\nAdamsky\\nProj_name\\nProjY\\nProjX\\nProjY\\nProjZ\\nProjX\\nR\\n3\\nPart_name Proj_name\\nProjY\\nProjX\\nProjY\\nProjZ\\nProjX\\nFigure 14.15 \\nFourth and fifth normal forms.\\n(a) The EMP relation with two MVDs: Ename →→ Pname and Ename →→ Dname.\\n(b)  Decomposing the EMP relation into two 4NF relations EMP_PROJECTS and  \\nEMP_DEPENDENTS.\\n(c) The relation SUPPLY with no MVDs is in 4NF but not in 5NF if it has the JD(R1, R2, R3).\\n(d) Decomposing the relation SUPPLY into the 5NF relations R1, R2, R3.\\n19The tuples t1, t2, t3, and t4 are not necessarily distinct.\\n20Z is shorthand for the attributes in R after the attributes in (X ∪ Y ) are removed from R.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 506, 'page_label': '507'}, page_content='14.6 Multivalued Dependency and Fourth Normal Form  493\\nWhenever X →→ Y holds, we say that X multidetermines Y. Because of the symme-\\ntry in the definition, whenever X →→ Y holds in R, so does X →→ Z. Hence, X →→ Y \\nimplies X →→ Z and therefore it is sometimes written as X →→ Y|Z.\\nAn MVD X →→ Y in R is called a trivial MVD if (a) Y is a subset of X, or (b) X ∪ Y = R. \\nFor example, the relation EMP_PROJECTS  in Figure 14.15(b) has the trivial  \\nMVD Ename →→ Pname and the relation EMP_DEPENDENTS  has the trivial MVD \\nEname →→ Dname. An MVD that satisfies neither (a) nor (b) is called a nontrivial \\nMVD. A trivial MVD will hold in any relation state r of R; it is called trivial because \\nit does not specify any significant or meaningful constraint on R.\\nIf we have a nontrivial MVD  in a relation, we may have to repeat values redun-\\ndantly in the tuples. In the EMP relation of Figure 14.15(a), the values ‘X’ and ‘Y’ of \\nPname are repeated with each value of Dname (or, by symmetry, the values ‘John’ \\nand ‘Anna’ of Dname are repeated with each value of Pname). This redundancy is \\nclearly undesirable. However, the EMP schema is in BCNF because no functional \\ndependencies hold in EMP. Therefore, we need to define a fourth normal form that \\nis stronger than BCNF and disallows relation schemas such as EMP. Notice that \\nrelations containing nontrivial MVDs tend to be all-key relations —that is, their \\nkey is all their attributes taken together. Furthermore, it is rare that such all-key \\nrelations with a combinatorial occurrence of repeated values would be designed in \\npractice. However, recognition of MVDs as a potential problematic dependency is \\nessential in relational design.\\nWe now present the definition of fourth normal form (4NF) , which is violated \\nwhen a relation has undesirable multivalued dependencies and hence can be used \\nto identify and decompose such relations.\\nDefinition. A relation schema R is in 4NF with respect to a set of dependencies \\nF (that includes functional dependencies and multivalued dependencies) if, for \\nevery nontrivial multivalued dependency X →→ Y in F\\n+,21 X is a superkey for R.\\nWe can state the following points:\\n ■ An all-key relation is always in BCNF since it has no FDs.\\n ■ An all-key relation such as the EMP relation in Figure 14.15(a), which has no \\nFDs but has the MVD Ename →→ Pname | Dname, is not in 4NF.\\n ■ A relation that is not in 4NF due to a nontrivial MVD must be decomposed \\nto convert it into a set of relations in 4NF.\\n ■ The decomposition removes the redundancy caused by the MVD.\\nThe process of normalizing a relation involving the nontrivial MVDs that is not in 4NF \\nconsists of decomposing it so that each MVD is represented by a separate relation \\nwhere it becomes a trivial MVD. Consider the \\nEMP relation in Figure 14.15(a). EMP is \\nnot in 4NF because in the nontrivial MVDs Ename →→ Pname and Ename →→ Dname, \\n21F+ refers to the cover of functional dependencies F, or all dependencies that are implied by F. This is \\ndefined in Section 15.1.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 507, 'page_label': '508'}, page_content='494 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\nand Ename is not a superkey of EMP. We decompose EMP into EMP_PROJECTS and \\nEMP_DEPENDENTS , shown in Figure 14.15(b). Both EMP_PROJECTS  and \\nEMP _DEPENDENTS  are in 4NF, because the MVDs Ename  →→ Pname  in  \\nEMP_PROJECTS and Ename →→ Dname in EMP_DEPENDENTS are trivial MVDs. No \\nother nontrivial MVDs hold in either EMP_PROJECTS or EMP_DEPENDENTS. No \\nFDs hold in these relation schemas either.\\n14.7 Join Dependencies and Fifth Normal Form\\nIn our discussion so far, we have pointed out the problematic functional dependen-\\ncies and shown how they were eliminated by a process of repeated binary decompo-\\nsition during the process of normalization to achieve 1NF, 2NF, 3NF, and BCNF. \\nThese binary decompositions must obey the NJB property for which we introduced \\na test in Section 14.5 while discussing the decomposition to achieve BCNF. Achiev-\\ning 4NF typically involves eliminating MVDs by repeated binary decompositions as \\nwell. However, in some cases there may be no nonadditive join decomposition of R \\ninto two relation schemas, but there may be a nonadditive join decomposition into \\nmore than two relation schemas. Moreover, there may be no functional dependency \\nin R that violates any normal form up to BCNF, and there may be no nontrivial \\nMVD present in R either that violates 4NF. We then resort to another dependency \\ncalled the join dependency and, if it is present, carry out a multiway decomposition \\ninto fifth normal form (5NF). It is important to note that such a dependency is a \\npeculiar semantic constraint that is difficult to detect in practice; therefore, normal-\\nization into 5NF is rarely done in practice.\\nDefinition. A join dependency (JD), denoted by JD(R\\n1, R2, … , Rn), specified \\non relation schema R, specifies a constraint on the states r of R. The constraint \\nstates that every legal state r of R should have a nonadditive join decomposition \\ninto R1, R2, … , Rn. Hence, for every such r we have\\n* (πR1(r), πR2(r), … , πRn(r)) = r\\nNotice that an MVD is a special case of a JD where n = 2. That is, a JD denoted  \\nas JD( R1, R2) implies an MVD ( R1 ∩ R2) →→ ( R1 − R2)(or, by symmetry,  \\n(R1 ∩ R2) →→ (R2 − R1)). A join dependency JD(R1, R2, … , Rn), specified on relation \\nschema R, is a trivial JD if one of the relation schemas Ri in JD(R1, R2, … , Rn) is equal \\nto R. Such a dependency is called trivial because it has the nonadditive join property \\nfor any relation state r of R and thus does not specify any constraint on R. We can \\nnow define the fifth normal form, which is also called project-join normal form.\\nDefinition. A relation schema R is in fifth normal form (5NF) (or project-join \\nnormal form (PJNF) ) with respect to a set F of functional, multivalued, and \\njoin dependencies if, for every nontrivial join dependency JD(R1, R2, … , Rn) in \\nF+ (that is, implied by F),22 every Ri is a superkey of R.\\n22Again, F+ refers to the cover of functional dependencies F, or all dependencies that are implied by F. \\nThis is defined in Section 15.1.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 508, 'page_label': '509'}, page_content='14.6 Summary  495\\nFor an example of a JD, consider once again the SUPPLY all-key relation in Fig- \\nure 14.15(c). Suppose that the following additional constraint always holds: Whenever \\na supplier s supplies part p, and a project j uses part p, and the supplier s supplies at \\nleast one part to project j, then supplier s will also be supplying part p to project j. \\nThis constraint can be restated in other ways and specifies a join dependency \\nJD(R\\n1, R2, R3) among the three projections R1 ( Sname, Part_name ), R2 ( Sname, \\nProj_name), and R3 (Part_name, Proj_name) of SUPPLY. If this constraint holds, the \\ntuples below the dashed line in Figure 14.15(c) must exist in any legal state of the \\nSUPPLY relation that also contains the tuples above the dashed line. Figure 14.15(d) \\nshows how the SUPPLY relation with the join dependency is decomposed into three \\nrelations R1, R2, and R3 that are each in 5NF. Notice that applying a natural join to \\nany two of these relations produces spurious tuples,  but applying a natural join to \\nall three together  does not. The reader should verify this on the sample relation in \\nFigure 14.15(c) and its projections in Figure 14.15(d). This is because only the JD \\nexists, but no MVDs are specified. Notice, too, that the JD(R\\n1, R2, R3) is specified on \\nall legal relation states, not just on the one shown in Figure 14.15(c).\\nDiscovering JDs in practical databases with hundreds of attributes is next to impos-\\nsible. It can be done only with a great degree of intuition about the data on the part \\nof the designer. Therefore, the current practice of database design pays scant atten-\\ntion to them. One result due to Date and Fagin (1992) relates to conditions detected \\nusing f.d.’s alone and ignores JDs completely. It states: “If a relation schema is in \\n3NF and each of its keys consists of a single attribute, it is also in 5NF.”\\n14.8 Summary\\nIn this chapter we discussed several pitfalls in relational database design using intu-\\nitive arguments. We identified informally some of the measures for indicating \\nwhether a relation schema is good or bad, and we provided informal guidelines for \\na good design. These guidelines are based on doing a careful conceptual design in \\nthe ER and EER model, following the mapping procedure in Chapter 9 to map enti-\\nties and relationships into relations. Proper enforcement of these guidelines and \\nlack of redundancy will avoid the insertion/deletion/update anomalies and genera-\\ntion of spurious data. We recommended limiting \\nNULL values, which cause prob-\\nlems during SELECT, JOIN, and aggregation operations. Then we presented some \\nformal concepts that allow us to do relational design in a top-down fashion by ana-\\nlyzing relations individually. We defined this process of design by analysis and \\ndecomposition by introducing the process of normalization.\\nWe defined the concept of functional dependency, which is the basic tool for ana-\\nlyzing relational schemas, and we discussed some of its properties. Functional \\ndependencies specify semantic constraints among the attributes of a relation \\nschema. Next we described the normalization process for achieving good designs \\nby testing relations for undesirable types of problematic functional dependencies. \\nWe provided a treatment of successive normalization based on a predefined pri-\\nmary key in each relation, and we then relaxed this requirement and provided more'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 509, 'page_label': '510'}, page_content='496 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\ngeneral definitions of second normal form (2NF) and third normal form (3NF) that \\ntake all candidate keys of a relation into account. We presented examples to illus-\\ntrate how, by using the general definition of 3NF, a given relation may be analyzed \\nand decomposed to eventually yield a set of relations in 3NF.\\nWe presented Boyce-Codd normal form (BCNF) and discussed how it is a stronger \\nform of 3NF. We also illustrated how the decomposition of a non-BCNF relation \\nmust be done by considering the nonadditive decomposition requirement. We pre-\\nsented a test for the nonadditive join property of binary decompositions and also \\ngave a general algorithm to convert any relation not in BCNF into a set of BCNF \\nrelations. We motivated the need for an additional constraint beyond the functional \\ndependencies based on mixing of independent multivalued attributes into a single \\nrelation. We introduced multivalued dependency (MVD) to address such condi-\\ntions and defined the fourth normal form based on MVDs. Finally, we introduced \\nthe fifth normal form, which is based on join dependency and which identifies a \\npeculiar constraint that causes a relation to be decomposed into several compo-\\nnents so that they always yield the original relation after a join. In practice, most \\ncommercial designs have followed the normal forms up to BCNF. The need to \\ndecompose into 5NF rarely arises in practice, and join dependencies are difficult to \\ndetect for most practical situations, making 5NF more of theoretical value.\\nChapter 15 presents synthesis as well as decomposition algorithms for relational \\ndatabase design based on functional dependencies. Related to decomposition, we \\ndiscuss the concepts of nonadditive (or lossless) join and dependency preservation, \\nwhich are enforced by some of these algorithms. Other topics in Chapter 15 include \\na more detailed treatment of functional and multivalued dependencies, and other \\ntypes of dependencies.\\nReview Questions\\n 14.1. Discuss attribute semantics as an informal measure of goodness for a rela-\\ntion schema.\\n 14.2. Discuss insertion, deletion, and modification anomalies. Why are they con-\\nsidered bad? Illustrate with examples.\\n 14.3. Why should NULLs in a relation be avoided as much as possible? Discuss the \\nproblem of spurious tuples and how we may prevent it.\\n 14.4. State the informal guidelines for relation schema design that we discussed. \\nIllustrate how violation of these guidelines may be harmful.\\n 14.5. What is a functional dependency? What are the possible sources of the \\ninformation that defines the functional dependencies that hold among the \\nattributes of a relation schema?\\n 14.6. Why can we not infer a functional dependency automatically from a partic-\\nular relation state?'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 510, 'page_label': '511'}, page_content='Exercises 497\\n 14.7. What does the term unnormalized relation refer to? How did the normal forms \\ndevelop historically from first normal form up to Boyce-Codd normal form?\\n 14.8. Define first, second, and third normal forms when only primary keys are \\nconsidered. How do the general definitions of 2NF and 3NF, which consider \\nall keys of a relation, differ from those that consider only primary keys?\\n 14.9. What undesirable dependencies are avoided when a relation is in 2NF?\\n 14.10. What undesirable dependencies are avoided when a relation is in 3NF?\\n 14.11. In what way do the generalized definitions of 2NF and 3NF extend the defi-\\nnitions beyond primary keys?\\n 14.12. Define Boyce-Codd normal form . How does it differ from 3NF? Why is it \\nconsidered a stronger form of 3NF?\\n 14.13. What is multivalued dependency? When does it arise?\\n 14.14. Does a relation with two or more columns always have an MVD? Show with \\nan example.\\n 14.15. Define fourth normal form. When is it violated? When is it typically applicable?\\n 14.16. Define join dependency and fifth normal form.\\n 14.17. Why is 5NF also called project-join normal form (PJNF)?\\n 14.18. Why do practical database designs typically aim for BCNF and not aim for \\nhigher normal forms?\\nExercises\\n 14.19. Suppose that we have the following requirements for a university database \\nthat is used to keep track of students’ transcripts:\\na. The university keeps track of each student’s name (Sname), student num-\\nber (Snum), Social Security number ( Ssn), current address (Sc_addr) and \\nphone (Sc_phone), permanent address ( Sp_addr) and phone ( Sp_phone), \\nbirth date ( Bdate), sex ( Sex), class ( Class) (‘freshman’, ‘sophomore’, … , \\n‘graduate’), major department ( Major_code ), minor department  \\n(Minor_code) (if any), and degree program (Prog) (‘b.a.’, ‘b.s.’, … , ‘ph.d.’). \\nBoth Ssn and student number have unique values for each student.\\nb. Each department is described by a name ( Dname), department code \\n(Dcode), office number ( Doffice ), office phone ( Dphone), and college  \\n(Dcollege). Both name and code have unique values for each department.\\nc. Each course has a course name ( Cname), description ( Cdesc), course \\nnumber ( Cnum), number of semester hours ( Credit), level ( Level), and \\noffering department ( Cdept). The course number is unique for each \\ncourse.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 511, 'page_label': '512'}, page_content='498 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\nd. Each section has an instructor ( Iname), semester ( Semester), year ( Year), \\ncourse (Sec_course), and section number (Sec_num). The section number \\ndistinguishes different sections of the same course that are taught during \\nthe same semester/year; its values are 1, 2, 3, … , up to the total number of \\nsections taught during each semester.\\ne. A grade record refers to a student ( Ssn), a particular section, and a \\ngrade (Grade).\\nDesign a relational database schema for this database application. First show \\nall the functional dependencies that should hold among the attributes. Then \\ndesign relation schemas for the database that are each in 3NF or BCNF. Spec-\\nify the key attributes of each relation. Note any unspecified requirements, \\nand make appropriate assumptions to render the specification complete.\\n 14.20. What update anomalies occur in the EMP_PROJ and EMP_DEPT relations of \\nFigures 14.3 and 14.4?\\n 14.21. In what normal form is the LOTS relation schema in Figure 14.12(a) with \\nrespect to the restrictive interpretations of normal form that take only the \\nprimary key into account? Would it be in the same normal form if the gen-\\neral definitions of normal form were used?\\n 14.22. Prove that any relation schema with two attributes is in BCNF.\\n 14.23. Why do spurious tuples occur in the result of joining the EMP_PROJ1 and \\nEMP_ LOCS relations in Figure 14.5 (result shown in Figure 14.6)?\\n 14.24. Consider the universal relation R = {A, B, C, D, E, F, G, H, I, J} and the set \\nof functional dependencies F = {{ A, B}→{C}, { A}→{D, E}, { B}→{F},  \\n{F}→{G, H}, {D}→{I, J}}. What is the key for R? Decompose R into 2NF and \\nthen 3NF relations.\\n 14.25. Repeat Exercise 14.24 for the following different set of functional dependen-\\ncies G = {{A, B}→{C}, {B, D}→{E, F}, {A, D}→{G, H}, {A}→{I}, {H}→{J}}.\\n 14.26. Consider the following relation:\\nAB C T U P L E #\\n10 b1 c1 1\\n10 b2 c2 2\\n11 b4 c1 3\\n12 b3 c4 4\\n13 b1 c1 5\\n14 b3 c4 6\\na. Given the previous extension (state), which of the following dependen-\\ncies may hold  in the above relation? If the dependency cannot hold, \\nexplain why by specifying the tuples that cause the violation.\\n i. A → B, ii. B → C, iii. C → B, iv. B → A, v. C → A'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 512, 'page_label': '513'}, page_content='Exercises 499\\nb. Does the above relation have a potential candidate key? If it does, what is \\nit? If it does not, why not?\\n 14.27. Consider a relation R(A, B, C, D, E) with the following dependencies:\\nAB → C, CD → E, DE → B\\n  Is AB a candidate key of this relation? If not, is ABD? Explain your answer.\\n 14.28. Consider the relation R, which has attributes that hold schedules of courses \\nand sections at a university; R = { Course_no , Sec_no , Offering_dept ,  \\nCredit_hours, Course_level, Instructor_ssn, Semester, Year, Days_hours, Room_no, \\nNo_of_students}. Suppose that the following functional dependencies hold on R:\\n{Course_no} → {Offering_dept, Credit_hours, Course_level}\\n{Course_no, Sec_no, Semester, Year} → {Days_hours, Room_no,\\n No_of_students, Instructor_ssn}\\n{Room_no, Days_hours, Semester, Year} → {Instructor_ssn, Course_no,\\n Sec_no}\\n  Try to determine which sets of attributes form keys of R. How would you \\nnormalize this relation?\\n 14.29. Consider the following relations for an order-processing application data-\\nbase at ABC, Inc.\\nORDER (O#, Odate, Cust#, Total_amount)\\nORDER_ITEM(O#, I#, Qty_ordered, Total_price, Discount%)\\n  Assume that each item has a different discount. The Total_price refers to one \\nitem, Odate is the date on which the order was placed, and the Total_amount \\nis the amount of the order. If we apply a natural join on the relations  \\nORDER_ITEM and ORDER in this database, what does the resulting relation \\nschema RES look like? What will be its key? Show the FDs in this resulting \\nrelation. Is RES in 2NF? Is it in 3NF? Why or why not? (State assumptions, \\nif you make any.)\\n 14.30. Consider the following relation:\\n CAR_SALE(Car#, Date_sold, Salesperson#, Commission%, Discount_amt)\\n  Assume that a car may be sold by multiple salespeople, and hence { Car#, \\nSalesperson#} is the primary key. Additional dependencies are\\nDate_sold → Discount_amt and\\nSalesperson# → Commission%\\n  Based on the given primary key, is this relation in 1NF, 2NF, or 3NF? Why \\nor why not? How would you successively normalize it completely?\\n 14.31. Consider the following relation for published books:\\nBOOK (Book_title, Author_name, Book_type, List_price, Author_affil,\\n  Publisher)'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 513, 'page_label': '514'}, page_content='500 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\n  Author_affil refers to the affiliation of author. Suppose the following depen-\\ndencies exist:\\nBook_title → Publisher, Book_type\\nBook_type → List_price\\nAuthor_name → Author_affil\\na. What normal form is the relation in? Explain your answer.\\nb. Apply normalization until you cannot decompose the relations further. \\nState the reasons behind each decomposition.\\n 14.32. This exercise asks you to convert business statements into dependencies. \\nConsider the relation DISK_DRIVE (Serial_number, Manufacturer, Model, Batch, \\nCapacity, Retailer). Each tuple in the relation DISK_DRIVE contains information \\nabout a disk drive with a unique Serial_number, made by a manufacturer, with a \\nparticular model number, released in a certain batch, which has a certain stor-\\nage capacity and is sold by a certain retailer. For example, the tuple \\nDisk_drive \\n(‘1978619’, ‘WesternDigital’, ‘A2235X’, ‘765234’, 500, ‘CompUSA’) specifies \\nthat WesternDigital made a disk drive with serial number 1978619 and model \\nnumber A2235X, released in batch 765234; it is 500GB and sold by CompUSA.\\n  Write each of the following dependencies as an FD:\\na. The manufacturer and serial number uniquely identifies the drive.\\nb. A model number is registered by a manufacturer and therefore can’t be \\nused by another manufacturer.\\nc. All disk drives in a particular batch are the same model.\\nd. All disk drives of a certain model of a particular manufacturer have \\nexactly the same capacity.\\n 14.33. Consider the following relation:\\nR (Doctor#, Patient#, Date, Diagnosis, Treat_code, Charge)\\n  In the above relation, a tuple describes a visit of a patient to a doctor along \\nwith a treatment code and daily charge. Assume that diagnosis is determined \\n(uniquely) for each patient by a doctor. Assume that each treatment code \\nhas a fixed charge (regardless of patient). Is this relation in 2NF? Justify your \\nanswer and decompose if necessary. Then argue whether further normaliza-\\ntion to 3NF is necessary, and if so, perform it.\\n 14.34. Consider the following relation:\\nCAR_SALE (Car_id, Option_type, Option_listprice, Sale_date,\\n Option_discountedprice)\\n  This relation refers to options installed in cars (e.g., cruise control) that were \\nsold at a dealership, and the list and discounted prices of the options.\\n  If CarID → Sale_date and Option_type → Option_listprice and CarID, Option_type \\n→ Option_discountedprice, argue using the generalized definition of the 3NF'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 514, 'page_label': '515'}, page_content='Laboratory Exercises 501\\nthat this relation is not in 3NF. Then argue from your knowledge of 2NF, \\nwhy it is not even in 2NF.\\n 14.35. Consider the relation:\\nBOOK (Book_Name, Author, Edition, Year)\\n  with the data:\\nBook_Name Author Edition Copyright_Year\\nDB_fundamentals Navathe 4 2004\\nDB_fundamentals Elmasri 4 2004\\nDB_fundamentals Elmasri 5 2007\\nDB_fundamentals Navathe 5 2007\\na. Based on a common-sense understanding of the above data, what are the \\npossible candidate keys of this relation?\\nb. Justify that this relation has the MVD {Book} →→ {Author} | {Edition, Year}.\\nc. What would be the decomposition of this relation based on the above \\nMVD? Evaluate each resulting relation for the highest normal form it \\npossesses.\\n 14.36. Consider the following relation:\\nTRIP (Trip_id, Start_date, Cities_visited, Cards_used)\\n  This relation refers to business trips made by company salespeople. Suppose \\nthe TRIP has a single Start_date but involves many Cities and salespeople \\nmay use multiple credit cards on the trip. Make up a mock-up population of \\nthe table.\\na. Discuss what FDs and/or MVDs exist in this relation.\\nb. Show how you will go about normalizing the relation.\\nLaboratory Exercises\\nNote: The following exercises use the DBD (Data Base Designer) system that is \\ndescribed in the laboratory manual.\\nThe relational schema R and set of functional dependencies F need to be coded as \\nlists. As an example, R and F for this problem are coded as:\\n R = [a, b, c, d, e, f, g, h, i, j]\\n F = [[[a, b],[c]],\\n        [[a],[d, e]],\\n        [[b],[f]],\\n        [[f],[g, h]],\\n        [[d],[i, j]]]'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 515, 'page_label': '516'}, page_content='502 Chapter 14 Basics of Functional Dependencies and Normalization for Relational Databases\\nSince DBD is implemented in Prolog, use of uppercase terms is reserved for vari-\\nables in the language and therefore lowercase constants are used to code the attri-\\nbutes. For further details on using the DBD system, please refer to the laboratory \\nmanual.\\n 14.37. Using the DBD system, verify your answers to the following exercises:\\na. 14.24 (3NF only)\\nb. 14.25\\nc. 14.27\\nd. 14.28\\nSelected Bibliography\\nFunctional dependencies were originally introduced by Codd (1970). The original \\ndefinitions of first, second, and third normal form were also defined in Codd \\n(1972a), where a discussion on update anomalies can be found. Boyce-Codd nor-\\nmal form was defined in Codd (1974). The alternative definition of third normal \\nform is given in Ullman (1988), as is the definition of BCNF that we give here. Ull-\\nman (1988), Maier (1983), and Atzeni and De Antonellis (1993) contain many of \\nthe theorems and proofs concerning functional dependencies. Date and Fagin \\n(1992) give some simple and practical results related to higher normal forms.\\nAdditional references to relational design theory are given in Chapter 15.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 516, 'page_label': '517'}, page_content='503\\n15\\nRelational Database Design \\nAlgorithms and Further \\nDependencies\\nC\\nhapter 14 presented a top-down relational design \\ntechnique and related concepts used extensively \\nin commercial database design projects today. The procedure involves designing an \\nER or EER conceptual schema and then mapping it to the relational model by a \\nprocedure such as the one described in Chapter 9. Primary keys are assigned to \\neach relation based on known functional dependencies. In the subsequent process, \\nwhich may be called relational design by analysis, initially designed relations from \\nthe above procedure—or those inherited from previous files, forms, and other \\nsources—are analyzed to detect undesirable functional dependencies. These depen-\\ndencies are removed by the successive normalization procedure that we described \\nin Section 14.3 along with definitions of related normal forms, which are succes-\\nsively better states of design of individual relations. In Section 14.3 we assumed that \\nprimary keys were assigned to individual relations; in Section 14.4 a more general \\ntreatment of normalization was presented where all candidate keys are considered \\nfor each relation, and Section 14.5 discussed a further normal form called BCNF. \\nThen in Sections 14.6 and 14.7 we discussed two more types of dependencies—\\nmultivalued dependencies and join dependencies—that can also cause redundancies \\nand showed how they can be eliminated with further normalization.\\nIn this chapter, we use the theory of normal forms and functional, multivalued, and \\njoin dependencies developed in the last chapter and build upon it while maintain-\\ning three different thrusts. First, we discuss the concept of inferring new functional \\ndependencies from a given set and discuss notions including closure, cover, mini-\\nmal cover, and equivalence. Conceptually, we need to capture the semantics of \\nchapter 15'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 517, 'page_label': '518'}, page_content='504 Chapter 15 Relational Database Design Algorithms and Further Dependencies\\nattibutes within a relation completely and succinctly, and the minimal cover allows \\nus to do it. Second, we discuss the desirable properties of nonadditive (lossless) \\njoins and preservation of functional dependencies. A general algorithm to test for \\nnonadditivity of joins among a set of relations is presented. Third, we present an \\napproach to relational design by synthesis  of functional dependencies. This is a \\nbottom-up approach to design that presupposes that the known functional depen-\\ndencies among sets of attributes in the Universe of Discourse (UoD) have been \\ngiven as input. We present algorithms to achieve the desirable normal forms, \\nnamely 3NF and BCNF, and achieve one or both of the desirable properties of non-\\nadditivity of joins and functional dependency preservation. Although the synthesis \\napproach is theoretically appealing as a formal approach, it has not been used in \\npractice for large database design projects because of the difficulty of providing all \\npossible functional dependencies up front before the design can be attempted. \\nAlternately, with the approach presented in Chapter 14, successive decompositions \\nand ongoing refinements to design become more manageable and may evolve over \\ntime. The final goal of this chapter is to discuss further the multivalued dependency \\n(MVD) concept we introduced in Chapter 14 and briefly point out other types of \\ndependencies that have been identified.\\nIn Section 15.1 we discuss the rules of inference for functional dependencies and \\nuse them to define the concepts of a cover, equivalence, and minimal cover among \\nfunctional dependencies. In Section 15.2, first we describe the two desirable \\nproperties of decompositions , namely, the dependency preservation property \\nand the nonadditive (or lossless) join property, which are both used by the design \\nalgorithms to achieve desirable decompositions. It is important to note that it is \\ninsufficient to test the relation schemas independently of one another  for compli-\\nance with higher normal forms like 2NF, 3NF, and BCNF. The resulting relations \\nmust collectively satisfy these two additional properties to qualify as a good design. \\nSection 15.3 is devoted to the development of relational design algorithms that \\nstart off with one giant relation schema called the universal relation , which is a \\nhypothetical relation containing all the attributes. This relation is decomposed (or \\nin other words, the given functional dependencies are synthesized) into relations \\nthat satisfy a certain normal form like 3NF or BCNF and also meet one or both of \\nthe desirable properties.\\nIn Section 15.5 we discuss the multivalued dependency (MVD) concept further by \\napplying the notions of inference, and equivalence to MVDs. Finally, in Sec- \\ntion 15.6 we complete the discussion on dependencies among data by introducing \\ninclusion dependencies and template dependencies. Inclusion dependencies can \\nrepresent referential integrity constraints and class/subclass constraints across rela-\\ntions. We also describe some situations where a procedure or function is needed to \\nstate and verify a functional dependency among attributes. Then we briefly discuss \\ndomain-key normal form (DKNF), which is considered the most general normal \\nform. Section 15.7 summarizes this chapter.\\nIt is possible to skip some or all of Sections 15.3, 15.4, and 15.5 in an introductory \\ndatabase course.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 518, 'page_label': '519'}, page_content='15.1 Further Topics in Functional Dependencies: Inference Rules, Equivalence, and Minimal Cover   505\\n15.1  Further Topics in Functional  \\nDependencies: Inference Rules,  \\nEquivalence, and Minimal Cover\\nWe introduced the concept of functional dependencies (FDs) in Section 14.2, illus-\\ntrated it with some examples, and developed a notation to denote multiple FDs over \\na single relation. We identified and discussed problematic functional dependencies \\nin Sections 14.3 and 14.4 and showed how they can be eliminated by a proper decom-\\nposition of a relation. This process was described as normalization, and we showed \\nhow to achieve the first through third normal forms (1NF through 3NF) given pri-\\nmary keys in Section 14.3. In Sections 14.4 and 14.5 we provided generalized tests for \\n2NF, 3NF, and BCNF given any number of candidate keys in a relation and showed \\nhow to achieve them. Now we return to the study of functional dependencies and \\nshow how new dependencies can be inferred from a given set and discuss the con-\\ncepts of closure, equivalence, and minimal cover that we will need when we later \\nconsider a synthesis approach to design of relations given a set of FDs.\\n15.1.1 Inference Rules for Functional Dependencies\\nWe denote by F the set of functional dependencies that are specified on relation \\nschema R. Typically, the schema designer specifies the functional dependencies \\nthat are semantically obvious ; usually, however, numerous other functional \\ndependencies hold in all legal relation instances among sets of attributes that can \\nbe derived from and satisfy the dependencies in F. Those other dependencies can \\nbe inferred  or deduced from the FDs in F. We call them as inferred or implied \\nfunctional dependencies.\\nDefinition: An FD X → Y is inferred from or implied by a set of dependencies \\nF specified on R if X → Y holds in every legal relation state r of R; that is, when-\\never r satisfies all the dependencies in F, X → Y also holds in r.\\nIn real life, it is impossible to specify all possible functional dependencies for a given \\nsituation. For example, if each department has one manager, so that Dept_no \\nuniquely determines Mgr_ssn (Dept_no → Mgr_ssn), and a manager has a unique \\nphone number called Mgr_phone (Mgr_ssn → Mgr_phone), then these two dependen-\\ncies together imply that Dept_no → Mgr_phone. This is an inferred or implied FD \\nand need not be explicitly stated in addition to the two given FDs. Therefore, it is \\nuseful to define a concept called closure formally that includes all possible depen-\\ndencies that can be inferred from the given set F.\\nDefinition. Formally, the set of all dependencies that include F as well as all \\ndependencies that can be inferred from F is called the closure of F; it is denoted \\nby F+.\\nFor example, suppose that we specify the following set F of obvious functional \\ndependencies on the relation schema in Figure 14.3(a):\\nF = {Ssn → {Ename, Bdate, Address, Dnumber}, Dnumber → {Dname, Dmgr_ssn} }'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 519, 'page_label': '520'}, page_content='506 Chapter 15 Relational Database Design Algorithms and Further Dependencies\\nSome of the additional functional dependencies that we can infer from F are the \\nfollowing:\\nSsn → {Dname, Dmgr_ssn}\\nSsn → Ssn\\nDnumber → Dname\\nThe closure F+ of F is the set of all functional dependencies that can be inferred \\nfrom F. To determine a systematic way to infer dependencies, we must discover a \\nset of inference rules that can be used to infer new dependencies from a given set of \\ndependencies. We consider some of these inference rules next. We use the notation \\nF |=X → Y to denote that the functional dependency X → Y is inferred from the set \\nof functional dependencies F.\\nIn the following discussion, we use an abbreviated notation when discussing func-\\ntional dependencies. We concatenate attribute variables and drop the commas  \\nfor convenience. Hence, the FD { X,Y} → Z is abbreviated to XY → Z, and the  \\nFD {X, Y, Z} → {U, V} is abbreviated to XYZ → UV. We present below three rules \\nIR1 through IR3 that are well-known inference rules for functional dependencies. \\nThey were proposed first by Armstrong (1974) and hence are known as  \\nArmstrong’s axioms.1\\nIR1 (reflexive rule)2: If X ⊇ Y, then X →Y.\\nIR2 (augmentation rule)3: {X → Y} |=XZ → YZ.\\nIR3 (transitive rule): {X → Y, Y → Z} |=X → Z.\\nArmstrong has shown that inference rules IR1 through IR3 are sound and complete. \\nBy sound, we mean that given a set of functional dependencies F specified on a rela-\\ntion schema R, any dependency that we can infer from F by using IR1 through IR3 \\nholds in every relation state r of R that satisfies the dependencies in F. By complete, \\nwe mean that using IR1 through IR3 repeatedly to infer dependencies until no more \\ndependencies can be inferred results in the complete set of all possible dependencies \\nthat can be inferred from F. In other words, the set of dependencies F+, which we \\ncalled the closure of F, can be determined from F by using only inference rules IR1 \\nthrough IR3.\\nThe reflexive rule (IR1) states that a set of attributes always determines itself or any of its \\nsubsets, which is obvious. Because IR1 generates dependencies that are always true, such \\ndependencies are called trivial. Formally, a functional dependency X → Y is trivial if \\nX ⊇ Y; otherwise, it is nontrivial. The augmentation rule (IR2) says that adding the \\nsame set of attributes to both the left- and right-hand sides of a dependency results in \\nanother valid dependency. According to IR3, functional dependencies are transitive.\\n1They are actually inference rules rather than axioms. In the strict mathematical sense, the axioms (given \\nfacts) are the functional dependencies in F, since we assume that they are correct, whereas IR1 through \\nIR3 are the inference rules for inferring new functional dependencies (new facts).\\n2The reflexive rule can also be stated as X → X; that is, any set of attributes functionally determines itself.\\n3The augmentation rule can also be stated as X → Y |= XZ → Y; that is, augmenting the left-hand-side \\nattributes of an FD produces another valid FD.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 520, 'page_label': '521'}, page_content='15.1 Further Topics in Functional Dependencies: Inference Rules, Equivalence, and Minimal Cover   507\\nEach of the preceding inference rules can be proved from the definition of functional \\ndependency, either by direct proof or by contradiction. A proof by contradiction \\nassumes that the rule does not hold and shows that this is not possible. We now prove \\nthat the first three rules \\nIR1 through IR3 are valid. The second proof is by contradiction.\\nProof of IR1. Suppose that X ⊇ Y and that two tuples t1 and t2 exist in some rela-\\ntion instance r of R such that t1 [X] = t2 [X]. Then t1[Y] = t2[Y] because X ⊇ Y; \\nhence, X → Y must hold in r.\\nProof of IR2 (by contradiction).  Assume that X → Y holds in a relation instance \\nr of R but that XZ → YZ does not hold. Then there must exist two tuples t1 \\nand t2 in r such that (1) t1 [X] = t2 [X], (2) t1 [Y] = t2 [Y], (3) t1 [XZ] = t2 [XZ], \\nand (4) t1 [ YZ] ≠ t2 [ YZ]. This is not possible because from (1) and (3) we \\ndeduce (5) t1 [Z] = t2 [Z], and from (2) and (5) we deduce (6) t1 [YZ] = t2 [YZ], \\ncontradicting (4).\\nProof of IR3. Assume that (1) X → Y and (2) Y → Z both hold in a relation r. \\nThen for any two tuples t1 and t2 in r such that t1 [X] = t2 [X], we must have (3) \\nt1 [Y] = t2 [Y], from assumption (1); hence we must also have (4) t1 [Z] = t2 [Z] \\nfrom (3) and assumption (2); thus X → Z must hold in r.\\nThere are three other inference rules that follow from IR1, IR2 and IR3. They are \\nas follows:\\nIR4 (decomposition, or projective, rule): {X → YZ} |=X → Y.\\nIR5 (union, or additive, rule): {X → Y, X → Z} |=X → YZ.\\nIR6 (pseudotransitive rule): {X → Y, WY → Z} |=WX → Z.\\nThe decomposition rule ( IR4) says that we can remove attributes from the right-\\nhand side of a dependency; applying this rule repeatedly can decompose the  \\nFD X → {A\\n1, A2, … , An} into the set of dependencies {X → A1, X → A2, … , X → An}. \\nThe union rule ( IR5) allows us to do the opposite; we can combine a set of depen-\\ndencies {X → A1, X → A2, … , X → An} into the single FD X → {A1, A2, … , An}. \\nThe pseudotransitive rule (IR6) allows us to replace a set of attributes Y on the left-\\nhand side of a dependency with another set X that functionally determines Y, and \\ncan be derived from IR2 and IR3 if we augment the first functional dependency  \\nX → Y with W (the augmentation rule) and then apply the transitive rule.\\nOne important cautionary note regarding the use of these rules: Although X → A and \\nX → B implies X → AB by the union rule stated above, X → A and Y → B does imply \\nthat XY → AB. Also, XY → A does not necessarily imply either X → A or Y → A.\\nUsing similar proof arguments, we can prove the inference rules \\nIR4 to IR6 and any \\nadditional valid inference rules. However, a simpler way to prove that an inference \\nrule for functional dependencies is valid is to prove it by using inference rules that \\nhave already been shown to be valid. Thus IR4, IR5, and IR6 are regarded as a corol-\\nlary of the Armstrong’s basic inference rules. For example, we can prove IR4 through \\nIR6 by using IR1 through IR3. We present the proof of IR5 below. Proofs of IR4 and IR6 \\nusing IR1 through IR3 are left as an exercise for the reader.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 521, 'page_label': '522'}, page_content='508 Chapter 15 Relational Database Design Algorithms and Further Dependencies\\nProof of IR5 (using IR1 through IR3).\\n1. X →Y (given).\\n2. X → Z (given).\\n3. X → XY (using IR2 on 1 by augmenting with X; notice that XX = X).\\n4. XY → YZ (using IR2 on 2 by augmenting with Y).\\n5. X → YZ (using IR3 on 3 and 4).\\nTypically, database designers first specify the set of functional dependencies F that \\ncan easily be determined from the semantics of the attributes of R; then IR1, IR2, \\nand IR3 are used to infer additional functional dependencies that will also hold on \\nR. A systematic way to determine these additional functional dependencies is first \\nto determine each set of attributes X that appears as a left-hand side of some func-\\ntional dependency in F and then to determine the set of all attributes that are depen-\\ndent on X.\\nDefinition. For each such set of attributes X, we determine the set X+ of attri-\\nbutes that are functionally determined by X based on F; X+ is called the closure \\nof X under F.\\nAlgorithm 15.1 can be used to calculate X+.\\nAlgorithm 15.1. Determining X+, the Closure of X under F\\nInput: A set F of FDs on a relation schema R, and a set of attributes X, which is \\na subset of R.\\nX+ := X;\\nrepeat\\n old X+ := X+;\\n for each functional dependency Y → Z in F do\\n  if X+ ⊇ Y then X+ := X+ ∪ Z;\\n until ( X+ = oldX+);\\nAlgorithm 15.1 starts by setting X+ to all the attributes in X. By IR1, we know that all \\nthese attributes are functionally dependent on X. Using inference rules IR3 and IR4, \\nwe add attributes to X+, using each functional dependency in F. We keep going \\nthrough all the dependencies in F (the repeat loop) until no more attributes are \\nadded to X+ during a complete cycle (of the for loop) through the dependencies in F. \\nThe closure concept is useful in understanding the meaning and implications of \\nattributes or sets of attributes in a relation. For example, consider the following \\nrelation schema about classes held at a university in a given academic year.\\nCLASS ( Classid, Course#, Instr_name, Credit_hrs, Text, Publisher, \\nClassroom, Capacity).\\nLet F, the set of functional dependencies for the above relation include the \\nfollowing f.d.s:\\nFD1: Sectionid → Course#, Instr_name, Credit_hrs, Text, Publisher, \\nClassroom, Capacity;'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 522, 'page_label': '523'}, page_content='15.1 Further Topics in Functional Dependencies: Inference Rules, Equivalence, and Minimal Cover   509\\nFD2: Course# → Credit_hrs;\\nFD3: {Course#, Instr_name} → Text, Classroom;\\nFD4: Text → Publisher\\nFD5: Classroom → Capacity\\nNote that the above FDs express certain semantics about the data in the relation \\nCLASS. For example, FD1 states that each class has a unique Classid. FD3 states \\nthat when a given course is offered by a certain instructor, the text is fixed and the \\ninstructor teaches that class in a fixed room. Using the inference rules about the \\nFDs and applying the definition of closure, we can define the following closures:\\n{ Classid } + = { Classid , Course#, Instr_name, Credit_hrs, Text, Publisher, \\nClassroom, Capacity } = CLASS\\n{ Course#} + = { Course#, Credit_hrs}\\n{ Course#, Instr_name } + = { Course#, Credit_hrs, Text, Publisher, \\nClassroom, Capacity }\\nNote that each closure above has an interpretation that is revealing about the \\nattribute(s) on the left-hand side. For example, the closure of Course# has only \\nCredit_hrs besides itself. It does not include Instr_name because different instruc-\\ntors could teach the same course; it does not include Text because different instruc-\\ntors may use different texts for the same course. Note also that the closure of \\n{Course#, Instr_nam\\n} does not include Classid, which implies that it is not a candi-\\ndate key. This further implies that a course with given Course# could be offered by \\ndifferent instructors, which would make the courses distinct classes.\\n15.1.2 Equivalence of Sets of Functional Dependencies\\nIn this section, we discuss the equivalence of two sets of functional dependencies. \\nFirst, we give some preliminary definitions.\\nDefinition. A set of functional dependencies F is said to cover another set of \\nfunctional dependencies E if every FD in E i s  a l s o  i n  F\\n+; that is, if every \\ndependency in E can be inferred from F; alternatively, we can say that E is \\ncovered by  F.\\nDefinition. Two sets of functional dependencies E and F are equivalent if  \\nE+ = F+. Therefore, equivalence means that every FD in E can be inferred from \\nF, and every FD in F can be inferred from E; that is, E is equivalent to F if both \\nthe conditions—E covers F and F covers E—hold.\\nWe can determine whether F covers E by calculating X+ with respect to F  for each \\nFD X → Y in E, and then checking whether this X+ includes the attributes in Y. If \\nthis is the case for every FD in E, then F covers E. We determine whether E and F are \\nequivalent by checking that E covers F and F covers E. It is left to the reader as an \\nexercise to show that the following two sets of FDs are equivalent:\\nF = {A → C, AC → D, E → AD, E → H} \\nand G = {A → CD, E → AH}'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 523, 'page_label': '524'}, page_content='510 Chapter 15 Relational Database Design Algorithms and Further Dependencies\\n15.1.3 Minimal Sets of Functional Dependencies\\nJust as we applied inference rules to expand on a set F of FDs to arrive at F+, its closure, \\nit is possible to think in the opposite direction to see if we could shrink or reduce the set \\nF to its minimal form so that the minimal set is still equivalent to the original set F. \\nInformally, a minimal cover of a set of functional dependencies E is a set of functional \\ndependencies F that satisfies the property that every dependency in E is in the closure \\nF\\n+ of F. In addition, this property is lost if any dependency from the set F is removed; F \\nmust have no redundancies in it, and the dependencies in F are in a standard form.\\nWe will use the concept of an extraneous attribute in a functional dependency for \\ndefining the minimum cover.\\nDefinition: An attribute in a functional dependency is considered an extraneous \\nattribute if we can remove it without changing the closure of the set of depen-\\ndencies. Formally, given F, the set of functional dependencies, and a functional \\ndependency X → A in F, attribute Y is extraneous in X if Y ⊂ X, and F logically \\nimplies (F − (X → A) ∪ { (X − Y) → A } ).\\nWe can formally define a set of functional dependencies F to be minimal if it satis-\\nfies the following conditions:\\n  1. Every dependency in F has a single attribute for its right-hand side.\\n  2. We cannot replace any dependency X → A in F with a dependency Y → A, \\nwhere Y is a proper subset of X, and still have a set of dependencies that is \\nequivalent to F.\\n  3. We cannot remove any dependency from F and still have a set of dependen-\\ncies that is equivalent to F.\\nWe can think of a minimal set of dependencies as being a set of dependencies in a \\nstandard or canonical form and with no redundancies. Condition 1 just represents \\nevery dependency in a canonical form with a single attribute on the right-hand side, \\nand it is a preparatory step before we can evaluate if conditions 2 and 3 are met.\\n4 \\nConditions 2 and 3 ensure that there are no redundancies in the dependencies \\neither by having redundant attributes (referred to as extraneous attributes) on the \\nleft-hand side of a dependency (Condition 2) or by having a dependency that can be \\ninferred from the remaining FDs in F (Condition 3).\\nDefinition. A minimal cover of a set of functional dependencies E is a mini-\\nmal set of dependencies (in the standard canonical form\\n5 and without redun-\\ndancy) that is equivalent to E. We can always find at least one minimal cover F \\nfor any set of dependencies E using Algorithm 15.2.\\n4This is a standard form to simplify the conditions and algorithms that ensure no redundancy exists in F. \\nBy using the inference rule IR4, we can convert a single dependency with multiple attributes on the \\nright-hand side into a set of dependencies with single attributes on the right-hand side.\\n5It is possible to use the inference rule IR5 and combine the FDs with the same left-hand side into a \\nsingle FD in the minimum cover in a nonstandard form. The resulting set is still a minimum cover, as \\nillustrated in the example.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 524, 'page_label': '525'}, page_content='15.1 Further Topics in Functional Dependencies: Inference Rules, Equivalence, and Minimal Cover   511\\nIf several sets of FDs qualify as minimal covers of E by the definition above, it is \\ncustomary to use additional criteria for minimality. For example, we can choose the \\nminimal set with the smallest number of dependencies  or with the smallest total \\nlength (the total length of a set of dependencies is calculated by concatenating the \\ndependencies and treating them as one long character string).\\nAlgorithm 15.2. Finding a Minimal Cover F for a Set of Functional Depen-\\ndencies E\\nInput: A set of functional dependencies E.\\nNote: Explanatory comments are given at the end of some of the steps. They \\nfollow the format: (*comment*).\\n  1. Set F := E.\\n  2. Replace each functional dependency X → {A1, A2, … , An} in F by the n \\nfunctional dependencies X →A1, X →A2, … , X → An. (*This places the FDs \\nin a canonical form for subsequent testing*)\\n  3. For each functional dependency X → A in F\\n for each attribute B that is an element of X\\n  if { { F − {X → A} } ∪ { (X − {B} ) → A} } is equivalent to F\\n   then replace X → A with (X − {B} ) → A in F. \\n(*This constitutes removal of an extraneous attribute B contained in the left-\\nhand side X of a functional dependency X → A when possible*)\\n  4. For each remaining functional dependency X → A in F\\nif {F − {X → A} } is equivalent to F,\\nthen remove X → A from F. (*This constitutes removal of a redundant func-\\ntional dependency X → A from F when possible*)\\nWe illustrate the above algorithm with the following examples:\\nExample 1:  Let the given set of FDs be E: {B → A, D → A, AB → D}. We have to \\nfind the minimal cover of E.\\n ■ All above dependencies are in canonical form (that is, they have only one \\nattribute on the right-hand side), so we have completed step 1 of Algo- \\nrithm 15.2 and can proceed to step 2. In step 2 we need to determine if  \\nAB → D has any redundant (extraneous) attribute on the left-hand side; that \\nis, can it be replaced by B → D or A → D?\\n ■ Since B → A, by augmenting with B on both sides (IR2), we have BB → AB, \\nor B → AB (i). However, AB → D as given (ii).\\n ■ Hence by the transitive rule ( IR3), we get from (i) and (ii), B → D. Thus \\nAB → D may be replaced by B → D.\\n ■ We now have a set equivalent to original E, say E′: {B → A, D → A, B → D}. \\nNo further reduction is possible in step 2 since all FDs have a single attribute \\non the left-hand side.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 525, 'page_label': '526'}, page_content='512 Chapter 15 Relational Database Design Algorithms and Further Dependencies\\n ■ In step 3 we look for a redundant FD in E′. By using the transitive rule on \\nB → D and D → A, we derive B → A. Hence B → A is redundant in E′ and \\ncan be eliminated.\\n ■ Therefore, the minimal cover of E is F: {B → D, D → A}.\\nThe reader can verify that the original set F can be inferred from E; in other words, \\nthe two sets F and E are equivalent.\\nExample 2:  Let the given set of FDs be G: {A → BCDE, CD → E}.\\n ■ Here, the given FDs are NOT in the canonical form. So we first convert \\nthem into:\\nE: {A → B, A→ C, A→ D, A→ E, CD → E}.\\n ■ In step 2 of the algorithm, for CD → E, neither C nor D is extraneous on the \\nleft-hand side, since we cannot show that C → E or D → E from the given \\nFDs. Hence we cannot replace it with either.\\n ■ In step 3, we want to see if any FD is redundant. Since A→ CD and \\nCD → E, by transitive rule (IR3), we get A→ E. Thus, A→ E is redundant \\nin G.\\n ■ So we are left with the set F, equivalent to the original set G as: { A → B, \\nA→ C, A→ D, CD → E}. F is the minimum cover. As we pointed out in foot-\\nnote 6, we can combine the first three FDs using the union rule (IR5) and \\nexpress the minimum cover as:\\nMinimum cover of G, F: {A → BCD, CD → E}.\\nIn Section 15.3, we will show algorithms that synthesize 3NF or BCNF relations \\nfrom a given set of dependencies E by first finding the minimal cover F for E.\\nNext, we provide a simple algorithm to determine the key of a relation:\\nAlgorithm 15.2(a). Finding a Key K for R Given a Set F of Functional Depen-\\ndencies\\nInput: A relation R and a set of functional dependencies F on the attributes \\nof R.\\n  1. Set K := R.\\n  2. For each attribute A in K\\n{compute (K − A)+ with respect to F;\\nif (K − A)+ contains all the attributes in R, then set K := K − {A} };\\nIn Algorithm 15.2(a), we start by setting K to all the attributes of R; we can say \\nthat R itself is always a default superkey . We then remove one attribute at a time \\nand check whether the remaining attributes still form a superkey. Notice, too, \\nthat Algorithm 15.2(a) determines only one key out of the possible candidate keys \\nfor R; the key returned depends on the order in which attributes are removed \\nfrom R in step 2.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 526, 'page_label': '527'}, page_content='15.2 Properties of Relational Decompositions  513\\n15.2 Properties of Relational Decompositions\\nWe now turn our attention to the process of decomposition that we used through-\\nout Chapter 14 to get rid of unwanted dependencies and achieve higher normal \\nforms. In Section 15.2.1, we give examples to show that looking at an individual \\nrelation to test whether it is in a higher normal form does not, on its own, guarantee \\na good design; rather, a set of relations  that together form the relational database \\nschema must possess certain additional properties to ensure a good design. In Sec-\\ntions 15.2.2 and 15.2.3, we discuss two of these properties: the dependency preser-\\nvation property and the nonadditive (or lossless) join property. Section 15.2.4 \\ndiscusses binary decompositions, and Section 15.2.5 discusses successive nonaddi-\\ntive join decompositions.\\n15.2.1  Relation Decomposition and Insufficiency  \\nof Normal Forms\\nThe relational database design algorithms that we present in Section 15.3 start from \\na single universal relation schema R = {A1, A2, … , An} that includes all the attri-\\nbutes of the database. We implicitly make the universal relation assumption , \\nwhich states that every attribute name is unique. The set F of functional dependen-\\ncies that should hold on the attributes of R is specified by the database designers \\nand is made available to the design algorithms. Using the functional dependencies, \\nthe algorithms decompose the universal relation schema R into a set of relation \\nschemas D = {R1, R2, … , Rm} that will become the relational database schema; D is \\ncalled a decomposition of R.\\nWe must make sure that each attribute in R will appear in at least one relation \\nschema Ri in the decomposition so that no attributes are lost; formally, we have\\nRRi\\ni\\nm\\n=\\n=\\n1\\nU\\nThis is called the attribute preservation condition of a decomposition.\\nAnother goal is to have each individual relation Ri in the decomposition D be in \\nBCNF or 3NF. However, this condition is not sufficient to guarantee a good data-\\nbase design on its own. We must consider the decomposition of the universal rela-\\ntion as a whole, in addition to looking at the individual relations. To illustrate this \\npoint, consider the \\nEMP_LOCS(Ename, Plocation) relation in Figure 14.5, which is in \\n3NF and also in BCNF. In fact, any relation schema with only two attributes is auto-\\nmatically in BCNF.\\n6 Although EMP_LOCS is in BCNF, it still gives rise to spurious \\ntuples when joined with EMP_PROJ (Ssn, Pnumber, Hours, Pname, Plocation), which is \\nnot in BCNF (see the partial result of the natural join in Figure 14.6). Hence,  \\nEMP_LOCS represents a particularly bad relation schema because of its convoluted \\n6As an exercise, the reader should prove that this statement is true.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 527, 'page_label': '528'}, page_content='514 Chapter 15 Relational Database Design Algorithms and Further Dependencies\\nsemantics by which Plocation gives the location of one of the projects  on which an \\nemployee works. Joining EMP_LOCS  with PROJECT(Pname, Pnumber, Plocation, \\nDnum) in Figure 14.2—which is in BCNF—using Plocation as a joining attribute also \\ngives rise to spurious tuples. This underscores the need for other criteria that, \\ntogether with the conditions of 3NF or BCNF, prevent such bad designs. In the next \\nthree subsections we discuss such additional conditions that should hold on a \\ndecomposition D as a whole.\\n15.2.2  Dependency Preservation Property  \\nof a Decomposition\\nIt would be useful if each functional dependency X → Y specified in F either \\nappeared directly in one of the relation schemas Ri in the decomposition D or \\ncould be inferred from the dependencies that appear in some Ri. Informally, this \\nis the dependency preservation condition.  We want to preserve the dependencies \\nbecause each dependency in F represents a constraint on the database. If one of \\nthe dependencies is not represented in some individual relation Ri of the decom-\\nposition, we cannot enforce this constraint by dealing with an individual relation. \\nWe may have to join multiple relations so as to include all attributes involved in \\nthat dependency.\\nIt is not necessary that the exact dependencies specified in F appear themselves in \\nindividual relations of the decomposition D. It is sufficient that the union of the \\ndependencies that hold on the individual relations in D be equivalent to F. We now \\ndefine these concepts more formally.\\nDefinition. Given a set of dependencies F on R, the projection of F on Ri, \\ndenoted by πRi(F) where Ri is a subset of R, is the set of dependencies X → Y in \\nF+ such that the attributes in X ∪ Y are all contained in Ri. Hence, the projection \\nof F on each relation schema Ri in the decomposition D is the set of functional \\ndependencies in F+, the closure of F, such that all the left- and right-hand-side \\nattributes of those dependencies are in Ri. We say that a decomposition  \\nD = {R1, R2, … , Rm} of R is dependency-preserving  with respect to F if the \\nunion of the projections of F on each Ri in D is equivalent to F; that is, \\n((πR1(F)) ∪ K ∪ (πRm(F)))+ = F+.\\nIf a decomposition is not dependency-preserving, some dependency is lost in \\nthe decomposition. To check that a lost dependency holds, we must take the \\nJOIN of two or more relations in the decomposition to get a relation that \\nincludes all left- and right-hand-side attributes of the lost dependency, and \\nthen check that the dependency holds on the result of the JOIN—an option that \\nis not practical.\\nAn example of a decomposition that does not preserve dependencies is shown in \\nFigure 14.13(a), in which the functional dependency FD2 is lost when \\nLOTS1A is \\ndecomposed into {LOTS1AX, LOTS1AY}. The decompositions in Figure 14.12, how-\\never, are dependency-preserving. Similarly, for the example in Figure 14.14, no'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 528, 'page_label': '529'}, page_content='15.2 Properties of Relational Decompositions  515\\nmatter what decomposition is chosen for the relation TEACH(Student, Course, \\nInstructor) from the three provided in the text, one or both of the dependencies orig-\\ninally present are bound to be lost. We now state a claim related to this property \\nwithout providing any proof.\\nClaim 1. It is always possible to find a dependency-preserving decomposition \\nD with respect to F such that each relation R\\ni in D is in 3NF .\\n15.2.3  Nonadditive (Lossless) Join Property  \\nof a Decomposition\\nAnother property that a decomposition D should possess is the nonadditive join \\nproperty, which ensures that no spurious tuples are generated when a NATURAL \\nJOIN operation is applied to the relations resulting from the decomposition. We \\nalready illustrated this problem in Section 14.1.4 with the example in Fig- \\nures 14.5 and 14.6. Because this is a property of a decomposition of relation  \\nschemas,  the condition of no spurious tuples should hold on every legal relation \\nstate—that is, every relation state that satisfies the functional dependencies in F. \\nHence, the lossless join property is always defined with respect to a specific set F \\nof dependencies.\\nDefinition. Formally, a decomposition D = { R\\n1, R2, … , Rm} of R has the  \\nlossless (nonadditive) join property  with respect to the set of dependencies  \\nF on R if, for every relation state r of R that satisfies F, the following holds,  \\nwhere * is the NATURAL JOIN of all the relations in D: *(πR1(r), … , πRm(r)) = r.\\nThe word loss in lossless refers to loss of information , not to loss of tuples. If a \\ndecomposition does not have the lossless join property, we may get additional spu-\\nrious tuples after the \\nPROJECT (π) and NATURAL JOIN (*) operations are applied; \\nthese additional tuples represent erroneous or invalid information. We prefer the \\nterm nonadditive join because it describes the situation more accurately. Although \\nthe term lossless join has been popular in the literature, we used the term nonaddi-\\ntive join in describing the NJB property in Section 14.5.1. We will henceforth use the \\nterm nonadditive join , which is self-explanatory and unambiguous. The nonaddi-\\ntive join property ensures that no spurious tuples result after the application of \\nPROJECT and JOIN operations. We may, however, sometimes use the term lossy \\ndesign to refer to a design that represents a loss of information. The decomposition \\nof EMP_PROJ(Ssn, Pnumber, Hours, Ename, Pname, Plocation)  in Figure 14.3 into  \\nEMP_LOCS(Ename, Plocation) and EMP_PROJ1(Ssn, Pnumber, Hours, Pname, Plocation) \\nin Figure 14.5 obviously does not have the nonadditive join property, as illustrated \\nby the partial result of NATURAL JOIN in Figure 14.6. We provided a simpler test \\nin case of binary decompositions to check if the decomposition is nonadditive—it \\nwas called the NJB property in Section 14.5.1. We provide a general procedure for \\ntesting whether any decomposition D of a relation into n relations is nonadditive \\nwith respect to a set of given functional dependencies F in the relation; it is pre-\\nsented as Algorithm 15.3.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 529, 'page_label': '530'}, page_content='516 Chapter 15 Relational Database Design Algorithms and Further Dependencies\\nAlgorithm 15.3. Testing for Nonadditive Join Property\\nInput: A universal relation R, a decomposition D = {R1, R2, … , Rm} of R, and a \\nset F of functional dependencies.\\nNote: Explanatory comments are given at the end of some of the steps. They \\nfollow the format: (*comment*).\\n  1. Create an initial matrix S with one row i for each relation Ri in D, and one \\ncolumn j for each attribute Aj in R.\\n  2. Set S(i, j): = bij for all matrix entries. (*Each bij is a distinct symbol associated \\nwith indices (i, j)*)\\n  3. For each row i representing relation schema Ri\\n{for each column j representing attribute Aj\\n  {if (relation Ri includes attribute Aj) then set S(i, j): = aj;};}; (*Each aj is \\na distinct symbol associated with index ( j)*)\\n  4. Repeat the following loop until a complete loop execution  results in no \\nchanges to S\\n{for each functional dependency X → Y in F\\n{for all rows in S that have the same symbols in the columns corresponding \\nto attributes in X\\n{make the symbols in each column that correspond to an attribute \\nin Y be the same in all these rows as follows: If any of the rows has \\nan a symbol for the column, set the other rows to that same a symbol \\nin the column. If no a symbol exists for the attribute in any of the \\nrows, choose one of the b symbols that appears in one of the rows for \\nthe attribute and set the other rows to that same b symbol in the \\ncolumn ;} ; } ;};\\n  5. If a row is made up entirely of a symbols, then the decomposition has the \\nnonadditive join property; otherwise, it does not.\\nGiven a relation R that is decomposed into a number of relations R1, R2, … , Rm, \\nAlgorithm 15.3 begins the matrix S that we consider to be some relation state r of \\nR. Row i in S represents a tuple ti (corresponding to relation Ri) that has a symbols \\nin the columns that correspond to the attributes of Ri and b symbols in the remain-\\ning columns. The algorithm then transforms the rows of this matrix (during the \\nloop in step 4) so that they represent tuples that satisfy all the functional depen-\\ndencies in F. At the end of step 4, any two rows in S—which represent two tuples \\nin r—that agree in their values for the left-hand-side attributes X of a functional \\ndependency X → Y in F will also agree in their values for the right-hand-side attri-\\nbutes Y. It can be shown that after applying the loop of step 4, if any row in S ends \\nup with all a symbols, then the decomposition D has the nonadditive join property \\nwith respect to F.\\nIf, on the other hand, no row ends up being all a symbols, D does not satisfy the \\nlossless join property. In this case, the relation state r represented by S at the end of'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 530, 'page_label': '531'}, page_content='15.2 Properties of Relational Decompositions  517\\nthe algorithm will be an example of a relation state r of R that satisfies the depen-\\ndencies in F but does not satisfy the nonadditive join condition. Thus, this relation \\nserves as a counterexample that proves that D does not have the nonadditive join \\nproperty with respect to F. Note that the a and b symbols have no special meaning \\nat the end of the algorithm.\\nFigure 15.1(a) shows how we apply Algorithm 15.3 to the decomposition of the \\nEMP_PROJ  relation schema from Figure 14.3(b)into the two relation schemas  \\nEMP_PROJ1 and EMP_LOCS in Figure 14.5(a). The loop in step 4 of the algorithm \\ncannot change any b symbols to a symbols; hence, the resulting matrix S does not \\nhave a row with all a symbols, and so the decomposition does not have the non-\\nadditive join property.\\nFigure 15.1(b) shows another decomposition of EMP_PROJ (into EMP, PROJECT, \\nand WORKS_ON) that does have the nonadditive join property, and Figure 15.1(c) \\nshows how we apply the algorithm to that decomposition. Once a row consists only \\nof a symbols, we conclude that the decomposition has the nonadditive join prop-\\nerty, and we can stop applying the functional dependencies (step 4 in the algorithm) \\nto the matrix S.\\n15.2.4  Testing Binary Decompositions for the Nonadditive  \\nJoin Property\\nAlgorithm 15.3 allows us to test whether a particular decomposition D into n rela-\\ntions obeys the nonadditive join property with respect to a set of functional depen-\\ndencies F. There is a special case of a decomposition called a binary \\ndecomposition—decomposition of a relation R into two relations. A test called the \\nNJB property test, which is easier to apply than Algorithm 15.3 but is limited only to \\nbinary decompositions, was given in Section 14.5.1. It was used to do binary decom-\\nposition of the TEACH relation, which met 3NF but did not meet BCNF, into two \\nrelations that satisfied this property.\\n15.2.5 Successive Nonadditive Join Decompositions\\nWe saw the successive decomposition of relations during the process of second and \\nthird normalization in Sections 14.3 and 14.4. To verify that these decompositions \\nare nonadditive, we need to ensure another property, as set forth in Claim 2.\\nClaim 2 (Preservation of Nonadditivity in Successive Decompositions). If a \\ndecomposition D = { R\\n1, R2, … , Rm} of R has the nonadditive (lossless) join \\nproperty with respect to a set of functional dependencies F on R, and if a decom-\\nposition Di = { Q1, Q2, … , Qk} of Ri has the nonadditive join property with \\nrespect to the projection of F on Ri, then the decomposition D2 = {R1, R2, … , \\nRi−1, Q1, Q2, … , Qk, Ri+1, … , Rm} of R has the nonadditive join property with \\nrespect to F.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 531, 'page_label': '532'}, page_content='518 Chapter 15 Relational Database Design Algorithms and Further Dependencies\\nPnumber\\nPROJECT(b)\\nPname Plocation\\nSsn\\nR1 b11\\na1\\na2\\nb22\\nb13\\na3\\nb14\\na4\\na5\\na5\\nb16\\na6\\na1\\nb21\\na2\\nb22\\nb13\\na3\\nb14\\na4\\nb15\\na5\\nb16\\nb26\\nR2\\nR1\\nR2\\nR3\\nD = {R1, R2 }\\n(No changes to matrix after applying functional dependencies)\\nEname Pnumber Pname Hours Plocation\\nSsn\\nEMP\\n(a) R = {Ssn, Ename, Pnumber, Pname, Plocation, Hours}\\nR1 = EMP_LOCS = {Ename, Plocation}\\nR2 = EMP_PROJ1 = {Ssn, Pnumber, Hours, Pname, Plocation}\\n(c)\\nEname Ssn\\nWORKS_ON\\nPnumber Hours\\nSsn\\na1 b32 a3 b34 b35 a6\\na1\\nb21\\na2\\nb22\\nb13\\na3\\nb14\\na4\\nb15\\na5\\nb16\\nb26\\nR1\\nR2\\nR3 a1 a2b32 b34a3 a4 a5 a6\\n(Original matrix S at start of algorithm)\\nEname Pnumber Pname Hours Plocation\\nSsn\\n(Matrix S after applying the first two functional dependencies;\\nlast row is all “a” symbols so we stop)\\nEname Pnumber Pname Hours Plocation\\nF = {Ssn      Ename; Pnumber      {Pname, Plocation}; {Ssn, Pnumber}      Hours}\\nD = {R1, R2,  R3}R = {Ssn, Ename, Pnumber, Pname, Plocation, Hours}\\nR1 = EMP = {Ssn, Ename}\\nR2 = PROJ = {Pnumber, Pname, Plocation}\\nR3 = WORKS_ON = {Ssn, Pnumber, Hours}\\nF = {Ssn      Ename; Pnumber      {Pname, Plocation}; {Ssn, Pnumber}      Hours}\\nb35\\nFigure 15.1 \\nNonadditive join test for n-ary decompositions. (a) Case 1: Decomposition of EMP_PROJ into EMP_PROJ1  \\nand EMP_LOCS fails test. (b) A decomposition of EMP_PROJ that has the lossless join property.  \\n(c) Case 2: Decomposition of EMP_PROJ into EMP, PROJECT, and WORKS_ON satisfies test.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 532, 'page_label': '533'}, page_content='15.3 Algorithms for Relational Database Schema Design  519\\n15.3  Algorithms for Relational Database \\nSchema Design\\nWe now give two algorithms for creating a relational decomposition from a universal \\nrelation. The first algorithm decomposes a universal relation into dependency- \\npreserving 3NF relations that also possess the nonadditive join property. The second \\nalgorithm decomposes a universal relation schema into BCNF schemas that possess the \\nnonadditive join property. It is not possible to design an algorithm to produce BCNF \\nrelations that satisfy both dependency preservation and nonadditive join decomposition\\n15.3.1  Dependency-Preserving and Nonadditive (Lossless)  \\nJoin Decomposition into 3NF Schemas\\nBy now we know that it is not possible to have all three of the following : (1) guaran-\\nteed nonlossy (nonadditive) design, (2) guaranteed dependency preservation, and \\n(3) all relations in BCNF . As we have stressed repeatedly, the first condition is a \\nmust and cannot be compromised. The second condition is desirable, but not a \\nmust, and may have to be relaxed if we insist on achieving BCNF. The original lost \\nFDs can be recovered by a JOIN operation over the results of decomposition. Now \\nwe give an algorithm where we achieve conditions 1 and 2 and only guarantee 3NF. \\nAlgorithm 15.4 yields a decomposition D of R that does the following:\\n ■ Preserves dependencies\\n ■ Has the nonadditive join property\\n ■ Is such that each resulting relation schema in the decomposition is in 3NF\\nAlgorithm 15.4 Relational Synthesis into 3NF with Dependency Preservation \\nand Nonadditive Join Property\\nInput: A universal relation R and a set of functional dependencies F on the \\nattributes of R.\\n  1. Find a minimal cover G for F (use Algorithm 15.2).\\n  2. For each left-hand-side X of a functional dependency that appears in G, create \\na relation schema in D with attributes { X ∪ {A1} ∪ {A2} … ∪ {Ak} }, where \\nX → A1, X → A2, … , X → Ak are the only dependencies in G with X as left-\\nhand side (X is the key of this relation).\\n  3. If none of the relation schemas in D contains a key of R, then create one \\nmore relation schema in D that contains attributes that form a key of R. \\n(Algorithm 15.2(a) may be used to find a key.)\\n  4. Eliminate redundant relations from the resulting set of relations in the rela-\\ntional database schema. A relation R is considered redundant if R is a projec-\\ntion of another relation S in the schema; alternately, R is subsumed by S.7\\n7Note that there is an additional type of dependency: R is a projection of the join of two or more relations \\nin the schema. This type of redundancy is considered join dependency, as we discussed in Section 15.7 . \\nHence, technically, it may continue to exist without disturbing the 3NF status for the schema.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 533, 'page_label': '534'}, page_content='520 Chapter 15 Relational Database Design Algorithms and Further Dependencies\\nStep 3 of Algorithm 15.4 involves identifying a key K of R. Algorithm 15.2(a) can be \\nused to identify a key K of R based on the set of given functional dependencies F. \\nNotice that the set of functional dependencies used to determine a key in Algo-\\nrithm 15.2(a) could be either F or G, since they are equivalent.\\nExample 1 of Algorithm 15.4. Consider the following universal relation:\\nU\\n (Emp_ssn, Pno, Esal, Ephone, Dno, Pname, Plocation)\\nEmp_ssn, Esal, and Ephone refer to the Social Security number, salary, and phone \\nnumber of the employee. Pno, Pname, and Plocation refer to the number, name, and \\nlocation of the project. Dno is the department number.\\nThe following dependencies are present:\\nFD1: Emp_ssn → {Esal, Ephone, Dno}\\nFD2: Pno → { Pname, Plocation}\\nFD3: Emp_ssn, Pno → {Esal, Ephone, Dno, Pname, Plocation}\\nBy virtue of FD3, the attribute set { Emp_ssn, Pno} represents a key of the universal \\nrelation. Hence F, the set of given FDs, includes { Emp_ssn → Esal, Ephone, Dno; \\nPno → Pname, Plocation; Emp_ssn, Pno → Esal, Ephone, Dno, Pname, Plocation}.\\nBy applying the minimal cover Algorithm 15.2, in step 3 we see that Pno is an extra-\\nneous attribute in Emp_ssn, Pno → Esal, Ephone, Dno. Moreover, Emp_ssn is extrane-\\nous in Emp_ssn, Pno → Pname, Plocation. Hence the minimal cover consists of FD1 \\nand FD2 only (FD3 being completely redundant) as follows (if we group attributes \\nwith the same left-hand side into one FD):\\nMinimal cover G: {Emp_ssn → Esal, Ephone, Dno; Pno → Pname, Plocation}\\nThe second step of Algorithm 15.4 produces relations R1 and R2 as:\\nR1 (Emp_ssn, Esal, Ephone, Dno)\\nR2 (Pno, Pname, Plocation)\\nIn step 3, we generate a relation corresponding to the key { Emp_ssn, Pno} of U. \\nHence, the resulting design contains:\\nR1 (Emp_ssn, Esal, Ephone, Dno)\\nR2 (Pno, Pname, Plocation)\\nR3 (Emp_ssn, Pno)\\nThis design achieves both the desirable properties of dependency preservation and \\nnonadditive join.\\nExample 2 of Algorithm 15.4 (Case X). Consider the relation schema LOTS1A \\nshown in Figure 14.13(a).\\nAssume that this relation is given as a universal relation U (Property_id, County, Lot#, \\nArea) with the following functional dependencies:'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 534, 'page_label': '535'}, page_content='15.3 Algorithms for Relational Database Schema Design  521\\nFD1: Property_id → Lot#, County, Area\\nFD2: Lot#, County → Area, Property_id\\nFD3: Area → County\\nThese were called FD1, FD2, and FD5 in Figure 14.13(a). The meanings of the above \\nattributes and the implication of the above functional dependencies were explained \\nin Section 14.4.For ease of reference, let us abbreviate the above attributes with the \\nfirst letter for each and represent the functional dependencies as the set\\nF\\n: { P → LCA, LC → AP, A → C }\\nThe universal relation with abbreviated attributes is U ( P, C, L, A). If we apply the \\nminimal cover Algorithm 15.2 to F, (in step 2) we first represent the set F as\\nF: {P → L, P → C, P → A, LC → A, LC → P, A → C}\\nIn the set F, P → A can be inferred from P → LC and LC → A; hence P → A by tran-\\nsitivity and is therefore redundant. Thus, one possible minimal cover is\\nMinimal cover GX: {P → LC, LC → AP, A → C}\\nIn step 2 of Algorithm 15.4, we produce design X (before removing redundant rela-\\ntions) using the above minimal cover as\\nDesign X: R1 (P, L, C), R2 (L, C, A, P), and R3 (A, C)\\nIn step 4 of the algorithm, we find that R3 is subsumed by R2 (that is, R3 is always a \\nprojection of R2 and R1 is a projection of R2 as well). Hence both of those relations \\nare redundant. Thus the 3NF schema that achieves both of the desirable properties \\nis (after removing redundant relations)\\nDesign X: R\\n2 (L, C, A, P).\\nor, in other words it is identical to the relation LOTS1A (Property_id, Lot#, County, \\nArea) that we had determined to be in 3NF in Section 14.4.2.\\nExample 2 of Algorithm 15.4 (Case Y). Starting with LOTS1A as the universal \\nrelation and with the same given set of functional dependencies, the second step of \\nthe minimal cover Algorithm 15.2 produces, as before,\\nF\\n: {P → C, P → A, P → L, LC → A, LC → P, A → C}\\nThe FD LC → A may be considered redundant because LC → P and P → A implies  \\nLC → A by transitivity. Also, P → C may be considered to be redundant because  \\nP → A and A → C implies P → C by transitivity. This gives a different minimal cover as\\nMinimal cover GY: { P → LA, LC → P, A → C }\\nThe alternative design Y produced by the algorithm now is\\nDesign Y: S1 (P, A, L), S2 (L, C, P), and S3 (A, C)\\nNote that this design has three 3NF relations, none of which can be considered as \\nredundant by the condition in step 4. All FDs in the original set F are preserved. The'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 535, 'page_label': '536'}, page_content='522 Chapter 15 Relational Database Design Algorithms and Further Dependencies\\nreader will notice that of the above three relations, relations S1 and S3 were produced \\nas the BCNF design by the procedure given in Section 14.5 (implying that S2 is \\nredundant in the presence of S1 and S3). However, we cannot eliminate relation S2 \\nfrom the set of three 3NF relations above since it is not a projection of either S1 or S3. \\nIt is easy to see that S2 is a valid and meaningful relation that has the two candidate \\nkeys (L, C), and P placed side-by-side. Notice further that S2 preserves the FD LC → P, \\nwhich is lost if the final design contains only S1 and S3. Design Y therefore remains \\nas one possible final result of applying Algorithm 15.4 to the given universal relation \\nthat provides relations in 3NF .\\nThe above two variations of applying Algorithm 15.4 to the same universal relation \\nwith a given set of FDs have illustrated two things:\\n ■ It is possible to generate alternate 3NF designs by starting from the same set \\nof FDs.\\n ■ It is conceivable that in some cases the algorithm actually produces relations \\nthat satisfy BCNF and may include relations that maintain the dependency \\npreservation property as well.\\n15.3.2 Nonadditive Join Decomposition into BCNF Schemas\\nThe next algorithm decomposes a universal relation schema R = { A1, A2, … , An} \\ninto a decomposition D = { R1, R2, … , Rm} such that each Ri is in BCNF and the \\ndecomposition D has the lossless join property with respect to F. Algorithm 15.5 \\nutilizes property NJB and claim 2 (preservation of nonadditivity in successive \\ndecompositions) to create a nonadditive join decomposition D = {R1, R2, … , Rm} of \\na universal relation R based on a set of functional dependencies F, such that each Ri \\nin D is in BCNF.\\nAlgorithm 15.5.  Relational Decomposition into BCNF with Nonadditive \\nJoin Property\\nInput: A universal relation R and a set of functional dependencies F on the \\nattributes of R.\\n  1. Set D := {R} ;\\n  2. While there is a relation schema Q in D that is not in BCNF do\\n{\\nchoose a relation schema Q in D that is not in BCNF;\\nfind a functional dependency X → Y in Q that violates BCNF;\\nreplace Q in D by two relation schemas (Q − Y) and (X ∪ Y);\\n} ;\\nEach time through the loop in Algorithm 15.5, we decompose one relation schema \\nQ that is not in BCNF into two relation schemas. According to property NJB for \\nbinary decompositions and claim 2, the decomposition D has the nonadditive \\njoin property. At the end of the algorithm, all relation schemas in D will be in'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 536, 'page_label': '537'}, page_content='15.4 About Nulls, Dangling Tuples, and Alternative Relational Designs  523\\nBCNF. We illustrated the application of this algorithm to the TEACH relation \\nschema from Figure 14.14; it is decomposed into TEACH1(Instructor , Student ) \\nand TEACH2(Instructor , Course)  because the dependency FD2 Instructor  → Course \\nviolates BCNF.\\nIn step 2 of Algorithm 15.5, it is necessary to determine whether a relation schema \\nQ is in BCNF or not. One method for doing this is to test, for each functional depen-\\ndency X → Y in Q, whether X+ fails to include all the attributes in Q, thereby deter-\\nmining whether or not X is a (super) key in Q. Another technique is based on an \\nobservation that whenever a relation schema Q has a BCNF violation, there exists a \\npair of attributes A and B in Q such that {Q − {A, B} } → A; by computing the clo-\\nsure {Q − {A, B} }+ for each pair of attributes {A, B} of Q and checking whether the \\nclosure includes A (or B), we can determine whether Q is in BCNF.\\nIt is important to note that the theory of nonadditive join decompositions is based \\non the assumption that no NULL values are allowed for the join attributes. The next \\nsection discusses some of the problems that NULLs may cause in relational decom-\\npositions and provides a general discussion of the algorithms for relational design \\nby synthesis presented in this section.\\n15.4  About Nulls, Dangling Tuples, and \\nAlternative Relational Designs\\nIn this section, we discuss a few general issues related to problems that arise when \\nrelational design is not approached properly.\\n15.4.1 Problems with NULL Values and Dangling Tuples\\nWe must carefully consider the problems associated with NULLs when designing a \\nrelational database schema. There is no fully satisfactory relational design theory as \\nyet that includes NULL values. One problem occurs when some tuples have NULL \\nvalues for attributes that will be used to join individual relations in the decomposi-\\ntion. To illustrate this, consider the database shown in Figure 15.2(a), where two \\nrelations EMPLOYEE and DEPARTMENT are shown. The last two employee tuples—\\n‘Berger’ and ‘Benitez’—represent newly hired employees who have not yet been \\nassigned to a department (assume that this does not violate any integrity con-\\nstraints). Now suppose that we want to retrieve a list of (\\nEname, Dname) values for \\nall the employees. If we apply the NATURAL JOIN  operation on EMPLOYEE and \\nDEPARTMENT (Figure 15.2(b)), the two aforementioned tuples will not appear in \\nthe result. The OUTER JOIN operation, discussed in Chapter 8, can deal with this \\nproblem. Recall that if we take the LEFT OUTER JOIN of EMPLOYEE with DEPARTMENT, \\ntuples in EMPLOYEE that have NULL for the join attribute will still appear in the \\nresult, joined with an imaginary tuple in DEPARTMENT that has NULLs for all its \\nattribute values. Figure 15.2(c) shows the result.\\nIn general, whenever a relational database schema is designed in which two or \\nmore relations are interrelated via foreign keys, particular care must be devoted to'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 537, 'page_label': '538'}, page_content='524 Chapter 15 Relational Database Design Algorithms and Further Dependencies\\nwatching for potential NULL values in foreign keys. This can cause unexpected loss \\nof information in queries that involve joins on that foreign key. Moreover, if NULLs \\noccur in other attributes, such as Salary, their effect on built-in functions such as \\nSUM and AVERAGE must be carefully evaluated.\\nA related problem is that of dangling tuples, which may occur if we carry a decom-\\nposition too far. Suppose that we decompose the EMPLOYEE  relation in Fig- \\nure 15.2(a) further into EMPLOYEE_1 and EMPLOYEE_2, shown in Figures 15.3(a) \\nand 15.3(b). If we apply the NATURAL JOIN operation to EMPLOYEE_1 and EMPLOYEE_2, \\nwe get the original EMPLOYEE relation. However, we may use the alternative repre-\\nsentation, shown in Figure 15.3(c), where we do not include a tuple in EMPLOYEE_3 \\nif the employee has not been assigned a department (instead of including a tuple \\nwith \\nNULL for Dnum as in EMPLOYEE_2 ). If we use EMPLOYEE_3  instead of \\nEMPLOYEE_2 and apply a NATURAL JOIN on EMPLOYEE_1 and EMPLOYEE_3, the \\ntuples for Berger and Benitez will not appear in the result; these are called dangling \\ntuples in EMPLOYEE_1 because they are represented in only one of the two rela-\\ntions that represent employees, and hence they are lost if we apply an ( INNER) \\nJOIN operation.\\n15.4.2  Discussion of Normalization Algorithms  \\nand Alternative Relational Designs\\nOne of the problems with the normalization algorithms we described is that the \\ndatabase designer must first specify all the relevant functional dependencies among \\nthe database attributes. This is not a simple task for a large database with hundreds \\nof attributes. Failure to specify one or two important dependencies may result in an \\nundesirable design. Another problem is that these algorithms are not deterministic \\nin general. For example, the synthesis algorithms (Algorithms 15.4 and 15.5) require \\nthe specification of a minimal cover G for the set of functional dependencies F. \\nBecause there may be, in general, many minimal covers corresponding to F, as we \\nillustrated in Example 2 of Algorithm 15.4 above, the algorithm can give different \\ndesigns depending on the particular minimal cover used. Some of these designs \\nmay not be desirable. The decomposition algorithm to achieve BCNF (Algo- \\nrithm 15.5) depends on the order in which the functional dependencies are supplied \\nto the algorithm to check for BCNF violation. Again, it is possible that many different \\ndesigns may arise. Some of the designs may be preferred, whereas others may \\nbe undesirable.\\nIt is not always possible to find a decomposition into relation schemas that pre-\\nserves dependencies and allows each relation schema in the decomposition to be \\nin BCNF (instead of 3NF, as in Algorithm 15.4). We can check the 3NF relation \\nschemas in the decomposition individually to see whether each satisfies BCNF. If \\nsome relation schema R\\ni is not in BCNF, we can choose to decompose it further \\nor to leave it as it is in 3NF (with some possible update anomalies). We showed by \\nusing the bottom-up approach to design that different minimal covers in cases X \\nand Y of Example 2 under Algorithm 15.4 produced different sets of relations'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 538, 'page_label': '539'}, page_content='15.4 About Nulls, Dangling Tuples, and Alternative Relational Designs  525\\n(b)\\nEname\\nEMPLOYEE\\n(a)\\nSsn Bdate Address Dnum\\nSmith, John B.\\nWong, Franklin T.\\nZelaya, Alicia J.\\nWallace, Jennifer S.\\nNarayan, Ramesh K.\\nEnglish, Joyce A.\\nJabbar, Ahmad V.\\nBorg, James E.\\n987987987\\n888665555\\n1969-03-29\\n1937-11-10\\n980 Dallas, Houston, TX\\n450 Stone, Houston, TX\\n123456789\\n333445555\\n999887777\\n987654321\\n666884444\\n453453453\\n1965-01-09\\n1955-12-08\\n1968-07-19\\n1941-06-20\\n1962-09-15\\n1972-07-31\\n731 Fondren, Houston, TX\\n638 Voss, Houston, TX\\n3321 Castle, Spring, TX\\n291 Berry, Bellaire, TX\\n975 Fire Oak, Humble, TX\\n5631 Rice, Houston, TX\\n5\\n5\\n4\\n4\\n5\\n4\\n1\\nBerger, Anders C. 999775555 1965-04-26 6530 Braes, Bellaire, TX NULL\\nBenitez, Carlos M. 888664444 19 63-01-09 7654 Beech, Houston, TX NULL\\n5\\nDname\\nDEPARTMENT\\nDnum Dmgr_ssn\\nResearch\\nAdministration\\nHeadquarters\\n5\\n4\\n1\\n333445555\\n987654321\\n888665555\\nEname\\nSmith, John B.\\nWong, Franklin T.\\nZelaya, Alicia J.\\nWallace, Jennifer S.\\nNarayan, Ramesh K.\\nEnglish, Joyce A.\\nJabbar, Ahmad V.\\nBorg, James E.\\n999887777\\n123456789\\n333445555\\n453453453\\n987654321\\n666884444\\n987987987\\n888665555 1937-11-10\\nSsn\\n1968-07-19\\n1965-01-09\\n1955-12-08\\n1972-07-31\\n1969-03-29\\n1941-06-20\\n1962-09-15\\nBdate\\n3321 Castle, Spring, TX\\n731 Fondren, Houston, TX 5\\n638 Voss, Houston, TX\\n5631 Rice, Houston, TX\\n980 Dallas, Houston, TX\\n450 Stone, Houston, TX\\n291 Berry, Bellaire, TX\\n975 Fire Oak, Humble, TX\\nAddress\\n4\\n5\\n5\\n4\\n1\\n4\\n5\\nAdministration\\nResearch\\nResearch\\nResearch\\nAdministration\\nHeadquarters\\nAdministration\\nResearch\\n987654321\\n333445555\\n333445555\\n333445555\\n987654321\\n888665555\\n987654321\\n333445555\\nDnum Dname Dmgr_ssn\\n(c)\\nEname\\nSmith, John B.\\nWong, Franklin T.\\nZelaya, Alicia J.\\nWallace, Jennifer S.\\nNarayan, Ramesh K.\\nEnglish, Joyce A.\\nJabbar, Ahmad V.\\nBorg, James E.\\n999887777\\n123456789\\n333445555\\n453453453\\n987654321\\n666884444\\n987987987\\n888665555 1937-11-10\\n1968-07-19\\n1965-01-09\\n1955-12-08\\n1972-07-31\\n1969-03-29\\n1941-06-20\\n1962-09-15\\nBdate\\n3321 Castle, Spring, TX\\n731 Fondren, Houston, TX 5\\n638 Voss, Houston, TX\\n5631 Rice, Houston, TX\\n980 Dallas, Houston, TX\\n450 Stone, Houston, TX\\n291 Berry, Bellaire, TX\\n975 Fire Oak, Humble, TX\\nAddress\\n4\\n5\\n5\\n4\\n1\\n4\\n5\\nAdministration\\nResearch\\nResearch\\nResearch\\nAdministration\\nHeadquarters\\nAdministration\\nResearch\\n987654321\\n333445555\\n333445555\\n333445555\\n987654321\\n888665555\\nBerger, Anders C.\\nBenitez, Carlos M.\\n999775555\\n888665555 1963-01-09\\n1965-04-26 6530 Braes, Bellaire, TX\\n7654 Beech, Houston, TX\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\n987654321\\n333445555\\nDnum Dname Dmgr_ssnSsn\\nFigure 15.2 \\nIssues with NULL-value \\njoins. (a) Some \\nEMPLOYEE tuples have \\nNULL for the join attribute \\nDnum. (b) Result of  \\napplying NATURAL JOIN \\nto the EMPLOYEE and \\nDEPARTMENT relations. \\n(c) Result of applying \\nLEFT OUTER JOIN to \\nEMPLOYEE and \\nDEPARTMENT.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 539, 'page_label': '540'}, page_content='526 Chapter 15 Relational Database Design Algorithms and Further Dependencies\\nEname\\nEMPLOYEE_1(a)\\n(b)\\nSsn Bdate Address\\nSmith, John B.\\nWong, Franklin T.\\nZelaya, Alicia J.\\nWallace, Jennifer S.\\nNarayan, Ramesh K.\\nEnglish, Joyce A.\\nJabbar, Ahmad V.\\nBorg, James E.\\n987987987\\n888665555\\n1969-03-29\\n1937-11-10\\n980 Dallas, Houston, TX\\n450 Stone, Houston, TX\\n123456789\\n333445555\\n999887777\\n987654321\\n666884444\\n453453453\\n1965-01-09\\n1955-12-08\\n1968-07-19\\n1941-06-20\\n1962-09-15\\n1972-07-31\\n731 Fondren, Houston, TX\\n638 Voss, Houston, TX\\n3321 Castle, Spring, TX\\n291 Berry, Bellaire, TX\\n975 Fire Oak, Humble, TX\\n5631 Rice, Houston, TX\\nBerger, Anders C.\\nBenitez, Carlos M.\\n999775555\\n888665555\\n1965-04-26\\n1963-01-09\\n6530 Braes, Bellaire, TX\\n7654 Beech, Houston, TX\\nEMPLOYEE_2\\nSsn\\n123456789\\n333445555\\n999887777\\n987654321\\n666884444\\n453453453\\n987987987\\n888665555\\n999775555\\n888664444\\n4\\n5\\n5\\n5\\n4\\n5\\nNULL\\n4\\n1\\nNULL\\nDnum\\n(c) EMPLOYEE_3\\nSsn\\n123456789\\n333445555\\n999887777\\n987654321\\n666884444\\n453453453\\n987987987\\n888665555\\n4\\n5\\n5\\n5\\n4\\n5\\n4\\n1\\nDnum\\nFigure 15.3 \\nThe dangling tuple problem.\\n(a) The relation EMPLOYEE_1 (includes \\nall attributes of EMPLOYEE from  \\nFigure 15.2(a) except Dnum).\\n(b) The relation EMPLOYEE_2 (includes \\nDnum attribute with NULL values).\\n(c) The relation EMPLOYEE_3 (includes \\nDnum attribute but does not include \\ntuples for which Dnum has NULL  \\nvalues).\\nbased on minimal cover. The design X produced the 3NF design as LOTS1A \\n(Property_id , County, Lot #, Area) relation, which is in 3NF but not BCNF. Alternately, \\ndesign Y produced three relations:  S1 (Property_id, Area, Lot #), S2 (Lot#, County,  \\nProperty_id), and S3 (Area, County). If we test each of these three relations, we find that \\nthey are in BCNF. We also saw previously that if we apply Algorithm 15.5 to LOTS1Y \\nto decompose it into BCNF relations, the resulting design contains only S\\n1 and S3 as a \\nBCNF design. In summary, the above examples of cases (called Case X and Case Y) \\ndriven by different minimum covers for the same universal schema amply illustrate \\nthat alternate designs will result by the application of the bottom-up design algo-\\nrithms we presented in Section 15.3.\\nTable 15.1 summarizes the properties of the algorithms discussed in this chapter \\nso far.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 540, 'page_label': '541'}, page_content='15.5 Further Discussion of Multivalued Dependencies and 4NF  527\\nTable 15.1 Summary of the Algorithms Discussed in This Chapter\\nAlgorithm Input Output Properties/Purpose Remarks\\n15.1 An attribute or a set \\nof attributes X, and a \\nset of FDs F\\nA set of attributes in \\nthe closure of X with \\nrespect to F\\nDetermine all the \\nattributes that can be \\nfunctionally deter-\\nmined from X\\nThe closure of a key \\nis the entire relation\\n15.2 A set of functional \\ndependencies F\\nThe minimal cover \\nof functional depen-\\ndencies\\nTo determine the \\nminimal cover of a \\nset of dependencies F\\nMultiple minimal \\ncovers may exist—\\ndepends on the order \\nof selecting func-\\ntional dependencies\\n15.2a Relation schema R \\nwith a set of func-\\ntional dependencies F\\nKey K of R To find a key K (that \\nis a subset of R)\\nThe entire relation R \\nis always a default \\nsuperkey\\n15.3 A decomposition D \\nof R and a set F of \\nfunctional depen-\\ndencies\\nBoolean result: yes \\nor no for nonaddi-\\ntive join property\\nTesting for nonaddi-\\ntive join decomposi-\\ntion\\nSee a simpler test \\nNJB in Section 14.5 \\nfor binary decompo-\\nsitions\\n15.4 A relation R and a \\nset of functional \\ndependencies F\\nA set of relations in \\n3NF\\nNonadditive join \\nand dependency-\\npreserving decom-\\nposition\\nMay not achieve \\nBCNF , but achieves \\nall desirable proper-\\nties and 3NF\\n15.5 A relation R and a \\nset of functional \\ndependencies F\\nA set of relations in \\nBCNF\\nNonadditive join \\ndecomposition\\nNo guarantee of \\ndependency preser-\\nvation\\n15.6 A relation R and a \\nset of functional and \\nmultivalued depen-\\ndencies\\nA set of relations in \\n4NF\\nNonadditive join \\ndecomposition\\nNo guarantee of \\ndependency preser-\\nvation\\n15.5  Further Discussion of Multivalued \\nDependencies and 4NF\\nWe introduced and defined the concept of multivalued dependencies and used it to \\ndefine the fourth normal form in Section 14.6. In this section, we discuss MVDs to \\nmake our treatment complete by stating the rules of inference with MVDs.\\n15.5.1  Inference Rules for Functional  \\nand Multivalued Dependencies\\nAs with functional dependencies (FDs), inference rules for MVDs have been \\ndeveloped. It is better, though, to develop a unified framework that includes both \\nFDs and MVDs so that both types of constraints can be considered together. The'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 541, 'page_label': '542'}, page_content='528 Chapter 15 Relational Database Design Algorithms and Further Dependencies\\nfollowing inference rules IR1 through IR8 form a sound and complete set for infer-\\nring functional and multivalued dependencies from a given set of dependencies. \\nAssume that all attributes are included in a universal relation schema R = {A\\n1, A2, \\n… , An} and that X, Y, Z, and W are subsets of R.\\nIR1 (reflexive rule for FDs): If X ⊇ Y, then X → Y.\\nIR2 (augmentation rule for FDs): {X → Y} |= XZ → YZ.\\nIR3 (transitive rule for FDs): {X → Y, Y → Z} |= X → Z.\\nIR4 (complementation rule for MVDs): {X →→ R} |= {X →→(R − (X ∪))}.\\nIR5 (augmentation rule for MVDs): If X →→ Y and W ⊇ Z, then WX →→ YZ.\\nIR6 (transitive rule for MVDs): {X →→ Y, Y →→ Z} | = X →→ (X − Y).\\nIR7 (replication rule for FD to MVD): {X → Y} | = X →→ Y.\\nIR8 (coalescence rule for FDs and MVDs): If X →→ Y and there exists W with \\nthe properties that (a) W ∩ Y is empty, (b) W → Z, and (c) Y ⊇ Z, then X → Z.\\nIR1 through IR3 are Armstrong’s inference rules for FDs alone. IR4 through IR6 \\nare inference rules pertaining to MVDs only. IR7 and IR8 relate FDs and MVDs. \\nIn particular, IR7 says that a functional dependency is a special case  of a multi-\\nvalued dependency; that is, every FD is also an MVD because it satisfies the formal \\ndefinition of an MVD. However, this equivalence has a catch: An FD X → Y is an \\nMVD X →→ Y with the additional implicit restriction  that at most one value of Y \\nis associated with each value of X. 8 Given a set F of functional and multivalued \\ndependencies specified on R = {A1, A2, … , An}, we can use IR1 through IR8 to infer \\nthe (complete) set of all dependencies (functional or multivalued) F+ that will hold \\nin every relation state r of R that satisfies F. We again call F+ the closure of F.\\n15.5.2 Fourth Normal Form Revisited\\nWe restate the definition of fourth normal form (4NF) from Section 14.6:\\nDefinition. A relation schema R is in 4NF with respect to a set of dependencies F \\n(that includes functional dependencies and multivalued dependencies) if, for every \\nnontrivial multivalued dependency X →→ Y in F+, X in F+, X is a superkey for R.\\nTo illustrate the importance of 4NF, Figure 15.4(a) shows the EMP relation in Fig-\\nure 14.15 with an additional employee, ‘Brown’, who has three dependents (‘Jim’, \\n‘Joan’, and ‘Bob’) and works on four different projects (‘W’, ‘X’, ‘Y’, and ‘Z’). There \\nare 16 tuples in \\nEMP in Figure 15.4(a). If we decompose EMP into EMP_PROJECTS \\nand EMP_DEPENDENTS , as shown in Figure 15.4(b), we need to store a total of \\nonly 11 tuples in both relations. Not only would the decomposition save on stor-\\nage, but the update anomalies associated with multivalued dependencies would \\nalso be avoided. For example, if ‘Brown’ starts working on a new additional project \\n‘P’, we must insert three tuples in EMP—one for each dependent. If we forget to \\n8That is, the set of values of Y determined by a value of X is restricted to being a singleton set with only \\none value. Hence, in practice, we never view an FD as an MVD.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 542, 'page_label': '543'}, page_content='15.5 Further Discussion of Multivalued Dependencies and 4NF  529\\ninsert any one of those, the relation violates the MVD and becomes inconsistent in \\nthat it incorrectly implies a relationship between project and dependent.\\nIf the relation has nontrivial MVDs, then insert, delete, and update operations on \\nsingle tuples may cause additional tuples to be modified besides the one in ques-\\ntion. If the update is handled incorrectly, the meaning of the relation may change. \\nHowever, after normalization into 4NF, these update anomalies disappear. For \\nexample, to add the information that ‘Brown’ will be assigned to project ‘P’, only a \\nsingle tuple need be inserted in the 4NF relation \\nEMP_PROJECTS.\\nThe EMP relation in Figure 14.15(a) is not in 4NF because it represents two inde-\\npendent 1:N relationships—one between employees and the projects they work on \\nand the other between employees and their dependents. We sometimes have a rela-\\ntionship among three entities that is a legitimate three-way relationship and not a \\ncombination of two binary relationships among three participating entities, such as \\nthe \\nSUPPLY relation shown in Figure 14.15(c). (Consider only the tuples in Fig- \\nure 14.5(c) above the dashed line for now.) In this case a tuple represents a supplier sup-\\nplying a specific part to a particular project, so there are no nontrivial MVDs. Hence, \\nthe SUPPLY all-key relation is already in 4NF and should not be decomposed.\\n(a) EMP\\nEname\\nSmith\\nSmith\\nSmith\\nSmith\\nBrown\\nBrown\\nBrown\\nBrown\\nBrown\\nBrown\\nBrown\\nBrown\\nBrown\\nBrown\\nBrown\\nBrown\\nJohn\\nAnna\\nAnna\\nJohn\\nJim\\nJim\\nJim\\nJim\\nJoan\\nJoan\\nJoan\\nJoan\\nBob\\nBob\\nBob\\nBob\\nX\\nY\\nX\\nY\\nY\\nZ\\nW\\nX\\nY\\nZ\\nW\\nX\\nY\\nZ\\nW\\nX\\nPname\\nDname\\n(b) EMP_PROJECTS\\nEname\\nSmith\\nSmith\\nBrown\\nBrown\\nBrown\\nBrown\\nW\\nX\\nY\\nZ\\nX\\nY\\nPnameEMP_DEPENDENTS\\nEname\\nSmith\\nSmith\\nBrown\\nBrown\\nBrown\\nJim\\nJoan\\nBob\\nAnna\\nJohn\\nDname\\nFigure 15.4 \\nDecomposing a relation state of EMP that is not in 4NF. (a) EMP relation with  \\nadditional tuples. (b) Two corresponding 4NF relations EMP_PROJECTS and  \\nEMP_DEPENDENTS.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 543, 'page_label': '544'}, page_content='530 Chapter 15 Relational Database Design Algorithms and Further Dependencies\\n15.5.3 Nonadditive Join Decomposition into 4NF Relations\\nWhenever we decompose a relation schema R into R1 = (X ∪ Y) and R2 = (R − Y) \\nbased on an MVD X →→ Y that holds in R, the decomposition has the nonadditive \\njoin property. It can be shown that this is a necessary and sufficient condition for \\ndecomposing a schema into two schemas that have the nonadditive join property, \\nas given by Property NJB ′ that is a further generalization of Property NJB given \\nearlier in Section 14.5.1. Property NJB dealt with FDs only, whereas NJB′ deals with \\nboth FDs and MVDs (recall that an FD is also an MVD).\\nProperty NJB ′. The relation schemas R\\n1 and R2 form a nonadditive join \\ndecomposition of R with respect to a set F of functional and multivalued depen-\\ndencies if and only if\\n(R1 ∩ R2) →→ (R1 – R2)\\nor, by symmetry, if and only if\\n(R\\n1 ∩ R2) →→ (R2 – R1)\\nWe can use a slight modification of Algorithm 15.5 to develop Algorithm 15.7, \\nwhich creates a nonadditive join decomposition into relation schemas that are in \\n4NF (rather than in BCNF). As with Algorithm 15.5, Algorithm 15.7 does not nec-\\nessarily produce a decomposition that preserves FDs.\\nAlgorithm 15.7. Relational Decomposition into 4NF Relations with Nonad-\\nditive Join Property\\nInput: A universal relation R and a set of functional and multivalued depen-\\ndencies F\\n  1. Set D:= { R };\\n  2. While there is a relation schema Q in D that is not in 4NF, do\\n{ choose a relation schema Q in D that is not in 4NF;\\nfind a nontrivial MVD X →→ Y in Q that violates 4NF;\\nreplace Q in D by two relation schemas (Q − Y) and (X ∪ Y);\\n};\\n15.6 Other Dependencies and Normal Forms\\n15.6.1 Join Dependencies and the Fifth Normal Form\\nWe already introduced another type of dependency called join dependency (JD) in \\nSection 14.7. It arises when a relation is decomposable into a set of projected rela-\\ntions that can be joined back to yield the original relation. After defining JD, we \\ndefined the fifth normal form based on it in Section 14.7. Fifth normal form has also \\nbeen known as project join normal form or PJNF (Fagin, 1979). A practical problem \\nwith this and some additional dependencies (and related normal forms such as \\nDKNF, which is defined in Section 15.6.3) is that they are difficult to discover.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 544, 'page_label': '545'}, page_content='15.6 Other Dependencies and Normal Forms  531\\nFurthermore, there are no sets of sound and complete inference rules to reason \\nabout them. In the remaining part of this section, we introduce some other types of \\ndependencies that have been identified. Among them, the inclusion dependencies \\nand those based on arithmetic or similar functions are used frequently.\\n15.6.2 Inclusion Dependencies\\nInclusion dependencies were defined in order to formalize two types of interrela-\\ntional constraints:\\n ■ The foreign key (or referential integrity) constraint cannot be specified as a \\nfunctional or multivalued dependency because it relates attributes across \\nrelations.\\n ■ The constraint between two relations that represent a class/subclass rela-\\ntionship (see Chapters 4 and 9) also has no formal definition in terms of the \\nfunctional, multivalued, and join dependencies.\\nDefinition. An inclusion dependency  R.X < S.Y between two sets of attri-\\nbutes—X of relation schema R, and Y of relation schema S—specifies the con-\\nstraint that, at any specific time when r is a relation state of R and s is a relation \\nstate of S, we must have\\nπ\\nX(r(R)) ⊆ πY(s(S))\\nThe ⊆ (subset) relationship does not necessarily have to be a proper subset. Obviously, \\nthe sets of attributes on which the inclusion dependency is specified—X of R and Y of \\nS—must have the same number of attributes. In addition, the domains for each pair of \\ncorresponding attributes should be compatible. For example, if X = {A1, A2, … , An} \\nand Y = {B1, B2, … , Bn}, one possible correspondence is to have dom(Ai) compatible \\nwith dom(Bi) for 1 ≤ i ≤ n. In this case, we say that Ai corresponds to Bi.\\nFor example, we can specify the following inclusion dependencies on the relational \\nschema in Figure 14.1:\\nDEPARTMENT.Dmgr_ssn < EMPLOYEE.Ssn\\nWORKS_ON.Ssn < EMPLOYEE.Ssn\\nEMPLOYEE.Dnumber < DEPARTMENT.Dnumber\\nPROJECT.Dnum < DEPARTMENT.Dnumber\\nWORKS_ON.Pnumber < PROJECT.Pnumber\\nDEPT_LOCATIONS.Dnumber < DEPARTMENT.Dnumber\\nAll the preceding inclusion dependencies represent referential integrity  \\nconstraints. We can also use inclusion dependencies to represent class/subclass \\nrelationships. For example, in the relational schema of Figure 9.6, we can specify \\nthe following inclusion dependencies:\\nEMPLOYEE.Ssn < PERSON.Ssn\\nALUMNUS.Ssn < PERSON.Ssn\\nSTUDENT.Ssn < PERSON.Ssn'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 545, 'page_label': '546'}, page_content='532 Chapter 15 Relational Database Design Algorithms and Further Dependencies\\nAs with other types of dependencies, there are inclusion dependency inference rules \\n(IDIRs). The following are three examples:\\nIDIR1 (reflexivity): R.X < R.X.\\nIDIR2 (attribute correspondence): If R.X < S.Y, where X = {A1, A2, … , An} and \\nY = {B1, B2, … , Bn} and Ai corresponds to Bi, then R.Ai < S.Bi for 1 ≤ i ≤ n.\\nIDIR3 (transitivity): If R.X < S.Y and S.Y < T.Z, then R.X < T.Z.\\nThe preceding inference rules were shown to be sound and complete for inclusion \\ndependencies. So far, no normal forms have been developed based on inclusion \\ndependencies.\\n15.6.3  Functional Dependencies Based on Arithmetic  \\nFunctions and Procedures\\nSometimes some attributes in a relation may be related via some arithmetic func-\\ntion or a more complicated functional relationship. As long as a unique value of Y \\nis associated with every X, we can still consider that the FD X → Y exists. For exam-\\nple, in the relation\\nORDER_LINE (Order#, Item#, Quantity, Unit_price, Extended_price,  \\nDiscounted_price)\\neach tuple represents an item from an order with a particular quantity, and the \\nprice per unit for that item. In this relation, ( Quantity, Unit_price ) → Extended_price \\nby the formula\\nExtended_price = Unit_price * Quantity\\nHence, there is a unique value for Extended_price for every pair (Quantity, Unit_price), \\nand thus it conforms to the definition of functional dependency.\\nMoreover, there may be a procedure that takes into account the quantity discounts, \\nthe type of item, and so on and computes a discounted price for the total quantity \\nordered for that item. Therefore, we can say\\n(Item#, Quantity, Unit_price ) → Discounted_price, or\\n(Item#, Quantity, Extended_price) → Discounted_price\\nTo check the above FDs, a more complex procedure COMPUTE_TOTAL_PRICE may \\nhave to be called into play. Although the above kinds of FDs are technically present \\nin most relations, they are not given particular attention during normalization. They \\nmay be relevant during the loading of relations and during query processing because \\npopulating or retrieving the attribute on the right-hand side of the dependency \\nrequires the execution of a procedure such as the one mentioned above.\\n15.6.4 Domain-Key Normal Form\\nThere is no hard-and-fast rule about defining normal forms only up to 5NF. His-\\ntorically, the process of normalization and the process of discovering undesirable'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 546, 'page_label': '547'}, page_content='15.7 Summary  533\\ndependencies were carried through 5NF, but it has been possible to define stricter \\nnormal forms that take into account additional types of dependencies and con-\\nstraints. The idea behind domain-key normal form (DKNF) is to specify (theoreti-\\ncally, at least) the ultimate normal form that takes into account all possible types of \\ndependencies and constraints. A relation schema is said to be in DKNF if all con-\\nstraints and dependencies that should hold on the valid relation states can be \\nenforced simply by enforcing the domain constraints and key constraints on the \\nrelation. For a relation in DKNF, it becomes straightforward to enforce all database \\nconstraints by simply checking that each attribute value in a tuple is of the appro-\\npriate domain and that every key constraint is enforced.\\nHowever, because of the difficulty of including complex constraints in a DKNF \\nrelation, its practical utility is limited, since it may be quite difficult to specify gen-\\neral integrity constraints. For example, consider a relation \\nCAR(Make, Vin#) (where \\nVin# is the vehicle identification number) and another relation MANUFACTURE(Vin#, \\nCountry) (where Country is the country of manufacture). A general constraint may be \\nof the following form: If the Make is either ‘Toyota’ or ‘Lexus’, then the first character \\nof the Vin# is a ‘J’ if the country of manufacture is ‘Japan’; if the Make is ‘Honda’ or \\n‘Acura’, the second character of the Vin# is a ‘J’ if the country of manufacture is \\n‘Japan’. There is no simplified way to represent such constraints short of writing a \\nprocedure (or general assertions) to test them. The procedure COMPUTE_TOTAL_PRICE \\nabove is an example of such procedures needed to enforce an appropriate integrity \\nconstraint.\\nFor these reasons, although the concept of DKNF is appealing and appears straight-\\nforward, it cannot be directly tested or implemented with any guarantees of consis-\\ntency or non-redundancy of design. Hence it is not used much in practice.\\n15.7 Summary\\nIn this chapter we presented a further set of topics related to dependencies, a dis-\\ncussion of decomposition, and several algorithms related to them as well as to the \\nprocess of designing 3NF, BCNF, and 4NF relations from a given set of functional \\ndependencies and multivalued dependencies. In Section 15.1 we presented infer-\\nence rules for functional dependencies (FDs), the notion of closure of an attribute, \\nthe notion of closure of a set of functional dependencies, equivalence among sets \\nof functional dependencies, and algorithms for finding the closure of an attribute \\n(Algorithm 15.1) and the minimal cover of a set of FDs (Algorithm 15.2). We then \\ndiscussed two important properties of decompositions: the nonadditive join prop-\\nerty and the dependency-preserving property. An algorithm to test for an n-way \\nnonadditive decomposition of a relation (Algorithm 15.3) was presented. A sim-\\npler test for checking for nonadditive binary decompositions (property NJB) has \\nalready been described in Section 14.5.1. We then discussed relational design by \\nsynthesis, based on a set of given functional dependencies. The relational synthesis \\nalgorithm  (Algorithm 15.4) creates 3NF relations from a universal relation \\nschema based on a given set of functional dependencies that has been specified by'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 547, 'page_label': '548'}, page_content='534 Chapter 15 Relational Database Design Algorithms and Further Dependencies\\nthe database designer. The relational decomposition algorithms  (such as Algo-\\nrithms 15.5 and 15.6) create BCNF (or 4NF) relations by successive nonadditive \\ndecomposition of unnormalized relations into two component relations at a time. \\nWe saw that it is possible to synthesize 3NF relation schemas that meet both of the \\nabove properties; however, in the case of BCNF, it is possible to aim only for the \\nnonadditiveness of joins—dependency preservation cannot be necessarily guaran-\\nteed. If the designer has to aim for one of these two, the nonadditive join condition \\nis an absolute must. In Section 15.4 we showed how certain difficulties arise in a \\ncollection of relations due to null values that may exist in relations in spite of the \\nrelations being individually in 3NF or BCNF. Sometimes when decomposition is \\nimproperly carried too far, certain “dangling tuples” may result that do not par-\\nticipate in results of joins and hence may become invisible. We also showed how \\nalgorithms such as 15.4 for 3NF synthesis could lead to alternative designs based \\non the choice of minimum cover. We revisited multivalued dependencies (MVDs) \\nin Section 15.5. MVDs arise from an improper combination of two or more inde-\\npendent multivalued attributes in the same relation, and MVDs result in a combi-\\nnational expansion of the tuples used to define fourth normal form (4NF). We \\ndiscussed inference rules applicable to MVDs and discussed the importance of \\n4NF. Finally, in Section 15.6 we discussed inclusion dependencies, which are used \\nto specify referential integrity and class/subclass constraints, and pointed out the \\nneed for arithmetic functions or more complex procedures to enforce certain \\nfunctional dependency constraints. We concluded with a brief discussion of the \\ndomain-key normal form (DKNF).\\nReview Questions\\n 15.1. What is the role of Armstrong’s inference rules (inference rules IR1 through \\nIR3) in the development of the theory of relational design?\\n 15.2. What is meant by the completeness and soundness of Armstrong’s infer-\\nence rules?\\n 15.3. What is meant by the closure of a set of functional dependencies? Illustrate \\nwith an example.\\n 15.4. When are two sets of functional dependencies equivalent? How can we \\ndetermine their equivalence?\\n 15.5. What is a minimal set of functional dependencies? Does every set of depen-\\ndencies have a minimal equivalent set? Is it always unique?\\n 15.6. What is meant by the attribute preservation condition on a decomposition?\\n 15.7. Why are normal forms alone insufficient as a condition for a good schema \\ndesign?\\n 15.8. What is the dependency preservation property for a decomposition? Why is \\nit important?'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 548, 'page_label': '549'}, page_content='Exercises 535\\n 15.9. Why can we not guarantee that BCNF relation schemas will be produced by \\ndependency-preserving decompositions of non-BCNF relation schemas? \\nGive a counterexample to illustrate this point.\\n 15.10. What is the lossless (or nonadditive) join property of a decomposition? Why \\nis it important?\\n 15.11. Between the properties of dependency preservation and losslessness, which \\none must definitely be satisfied? Why?\\n 15.12. Discuss the NULL value and dangling tuple problems.\\n 15.13. Illustrate how the process of creating first normal form relations may lead to \\nmultivalued dependencies. How should the first normalization be done \\nproperly so that MVDs are avoided?\\n 15.14. What types of constraints are inclusion dependencies meant to represent?\\n 15.15. How do template dependencies differ from the other types of dependencies \\nwe discussed?\\n 15.16. Why is the domain-key normal form (DKNF) known as the ultimate nor-\\nmal form?\\nExercises\\n 15.17. Show that the relation schemas produced by Algorithm 15.4 are in 3NF.\\n 15.18. Show that, if the matrix S resulting from Algorithm 15.3 does not have a row \\nthat is all a symbols, projecting S on the decomposition and joining it back \\nwill always produce at least one spurious tuple.\\n 15.19. Show that the relation schemas produced by Algorithm 15.5 are in BCNF.\\n 15.20. Write programs that implement Algorithms 15.4 and 15.5.\\n 15.21. Consider the relation REFRIG(Model#, Year, Price, Manuf_plant, Color), which \\nis abbreviated as REFRIG(M, Y, P, MP, C), and the following set F of functional \\ndependencies: F = {M → MP, {M, Y} → P, MP → C}\\na. Evaluate each of the following as a candidate key for REFRIG, giving rea-\\nsons why it can or cannot be a key: {M}, {M, Y}, {M, C}.\\nb. Based on the above key determination, state whether the relation REFRIG \\nis in 3NF and in BCNF, and provide proper reasons.\\nc. Consider the decomposition of REFRIG  into D = { R1(M, Y, P),  \\nR2(M, MP, C)}. Is this decomposition lossless? Show why. (You may \\nconsult the test under Property NJB in Section 14.5.1.)\\n 15.22. Specify all the inclusion dependencies for the relational schema in Figure 5.5.\\n 15.23. Prove that a functional dependency satisfies the formal definition of multi-\\nvalued dependency.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 549, 'page_label': '550'}, page_content='536 Chapter 15 Relational Database Design Algorithms and Further Dependencies\\n 15.24. Consider the example of normalizing the LOTS relation in Sections 14.4 \\nand 14.5 . Determine whether the decomposition of LOTS into { LOTS1AX, \\nLOTS1AY , LOTS1B , LOTS2 } has the lossless join property by applying \\nAlgorithm 15.3 and also by using the test under property NJB from Sec-\\ntion 14.5.1.\\n 15.25. Show how the MVDs Ename →→ and Ename →→ Dname in Figure 14.15(a) \\nmay arise during normalization into 1NF of a relation, where the attributes \\nPname and Dname are multivalued.\\n 15.26. Apply Algorithm 15.2(a) to the relation in Exercise 14.24 to determine a key \\nfor R. Create a minimal set of dependencies G that is equivalent to F, and apply \\nthe synthesis algorithm (Algorithm 15.4) to decompose R into 3NF relations.\\n 15.27. Repeat Exercise 15.26 for the functional dependencies in Exercise 14.25.\\n 15.28. Apply the decomposition algorithm (Algorithm 15.5) to the relation R and \\nthe set of dependencies F in Exercise 15.24. Repeat for the dependencies G in \\nExercise 15.25.\\n 15.29. Apply Algorithm 15.2(a) to the relations in Exercises 14.27 and 14.28 to \\ndetermine a key for R. Apply the synthesis algorithm (Algorithm 15.4) to \\ndecompose R into 3NF relations and the decomposition algorithm (Algo-\\nrithm 15.5) to decompose R into BCNF relations.\\n 15.31. Consider the following decompositions for the relation schema R of Exer-\\ncise 14.24. Determine whether each decomposition has (1) the dependency \\npreservation property, and (2) the lossless join property, with respect to F. \\nAlso determine which normal form each relation in the decomposition is in.\\na. D1 = { R1, R2, R3, R4, R5}; R1 = { A, B, C}, R2 = { A, D, E}, R3 = { B, F},  \\nR4 = {F, G, H}, R5 = {D, I, J}\\nb. D2 = {R1, R2, R3}; R1 = {A, B, C, D, E}, R2 = {B, F, G, H}, R3 = {D, I, J}\\nc. D3 = { R1, R2, R3, R4, R5}; R1 = { A, B, C, D}, R2 = { D, E}, R3 = { B, F},  \\nR4 = {F, G, H}, R5 = {D, I, J}\\nLaboratory Exercises\\nNote: These exercises use the DBD (Data Base Designer) system that is described \\nin the laboratory manual. The relational schema R and set of functional dependen-\\ncies F need to be coded as lists. As an example, R and F for Problem 14.24 are \\ncoded as:\\nR = [a, b, c, d, e, f, g, h, i, j]\\nF = [[[a, b],[c]],\\n[[a],[d, e]],\\n[[b],[f]],\\n[[f],[g, h]],\\n[[d],[i, j]]]'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 550, 'page_label': '551'}, page_content='Selected Bibliography 537\\nSince DBD is implemented in Prolog, use of uppercase terms is reserved for variables \\nin the language and therefore lowercase constants are used to code the attributes. For \\nfurther details on using the DBD system, please refer to the laboratory manual.\\n 15.33. Using the DBD system, verify your answers to the following exercises:\\na. 15.24\\nb. 15.26\\nc. 15.27\\nd. 15.28\\ne. 15.29\\nf. 15.31 (a) and (b)\\ng. 15.32 (a) and (c)\\nSelected Bibliography\\nThe books by Maier (1983) and Atzeni and De Antonellis (1993) include a compre-\\nhensive discussion of relational dependency theory. Algorithm 15.4 is based on the \\nnormalization algorithm presented in Biskup et al. (1979). The decomposition \\nalgorithm (Algorithm 15.5) is due to Bernstein (1976). Tsou and Fischer (1982) \\ngive a polynomial-time algorithm for BCNF decomposition.\\nThe theory of dependency preservation and lossless joins is given in Ullman (1988), \\nwhere proofs of some of the algorithms discussed here appear. The lossless join \\nproperty is analyzed in Aho et al. (1979). Algorithms to determine the keys of a \\nrelation from functional dependencies are given in Osborn (1977); testing for \\nBCNF is discussed in Osborn (1979). Testing for 3NF is discussed in Tsou and \\nFischer (1982). Algorithms for designing BCNF relations are given in Wang (1990) \\nand Hernandez and Chan (1991).\\nMultivalued dependencies and fourth normal form are defined in Zaniolo (1976) \\nand Nicolas (1978). Many of the advanced normal forms are due to Fagin: the fourth \\nnormal form in Fagin (1977), PJNF in Fagin (1979), and DKNF in Fagin (1981). The \\nset of sound and complete rules for functional and multivalued dependencies was \\ngiven by Beeri et al. (1977). Join dependencies are discussed by Rissanen (1977) and \\nAho et al. (1979). Inference rules for join dependencies are given by Sciore (1982). \\nInclusion dependencies are discussed by Casanova et al. (1981) and analyzed further \\nin Cosmadakis et al. (1990). Their use in optimizing relational schemas is discussed \\nin Casanova et al. (1989). Template dependencies, which are a general form of \\ndependencies based on hypotheses and conclusion tuples, are discussed by Sadri and \\nUllman (1982). Other dependencies are discussed in Nicolas (1978), Furtado (1978), \\nand Mendelzon and Maier (1979). Abiteboul et al. (1995) provides a theoretical \\ntreatment of many of the ideas presented in this chapter and Chapter 14.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 551, 'page_label': '552'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 552, 'page_label': '553'}, page_content='part 7\\nFile Structures, Hashing, Indexing, \\nand Physical Database Design'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 553, 'page_label': '554'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 554, 'page_label': '555'}, page_content='541\\n16\\nDisk Storage, Basic File \\nStructures, Hashing, and Modern \\nStorage Architectures\\nD\\natabases are stored physically as files of records, \\nwhich are typically stored on magnetic disks. This \\nchapter and the next deal with the organization of databases in storage and the \\ntechniques for accessing them efficiently using various algorithms, some of which \\nrequire auxiliary data structures called indexes. These structures are often referred \\nto as physical database file structures  and are at the physical level of the three-\\nschema architecture described in Chapter 2. We start in Section 16.1 by introducing \\nthe concepts of computer storage hierarchies and how they are used in database \\nsystems. Section 16.2 is devoted to a description of magnetic disk storage devices \\nand their characteristics, flash memory, and solid-state drives and optical drives \\nand magnetic tape storage devices used for archiving data. We also discuss tech-\\nniques for making access from disks more efficient. After discussing different stor-\\nage technologies, we turn our attention to the methods for physically organizing \\ndata on disks. Section 16.3 covers the technique of double buffering, which is used \\nto speed retrieval of multiple disk blocks. We also discuss buffer management and \\nbuffer replacement strategies. In Section 16.4 we discuss various ways of formatting \\nand storing file records on disk. Section 16.5 discusses the various types of opera-\\ntions that are typically applied to file records. We present three primary methods \\nfor organizing file records on disk: unordered records, in Section 16.6; ordered \\nrecords, in Section 16.7; and hashed records, in Section 16.8.\\nSection 16.9 briefly introduces files of mixed records and other primary methods \\nfor organizing records, such as B-trees. These are particularly relevant for storage of \\nobject-oriented databases, which we discussed in Chapter 11. Section 16.10 \\nchapter 16'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 555, 'page_label': '556'}, page_content='542 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\ndescribes RAID (redundant arrays of inexpensive (or independent) disks)—a data \\nstorage system architecture that is commonly used in large organizations for better \\nreliability and performance. Finally, in Section 16.11 we describe modern develop-\\nments in the storage architectures that are important for storing enterprise data: \\nstorage area networks (SANs), network-attached storage (NAS), iSCSI (Internet \\nSCSI—small computer system interface), and other network-based storage proto-\\ncols, which make storage area networks more affordable without the use of the \\nFibre Channel infrastructure and hence are becoming widely accepted in industry. \\nWe also discuss storage tiering and object-based storage. Section 16.12 summarizes \\nthe chapter. In Chapter 17 we discuss techniques for creating auxiliary data struc-\\ntures, called indexes, which speed up the search for and retrieval of records. These \\ntechniques involve storage of auxiliary data, called index files, in addition to the file \\nrecords themselves.\\nChapters 16 and 17 may be browsed through or even omitted by readers who have \\nalready studied file organizations and indexing in a separate course. The material \\ncovered here, in particular Sections 16.1 through 16.8, is necessary for understand-\\ning Chapters 18 and 19, which deal with query processing and optimization, as well \\nas database tuning for improving performance of queries.\\n16.1 Introduction\\nThe collection of data that makes up a computerized database must be stored phys-\\nically on some computer storage medium. The DBMS software can then retrieve, \\nupdate, and process this data as needed. Computer storage media form a storage \\nhierarchy that includes two main categories:\\n ■ Primary storage. This category includes storage media that can be operated \\non directly by the computer’s central processing unit  (CPU), such as the \\ncomputer’s main memory and smaller but faster cache memories. Primary \\nstorage usually provides fast access to data but is of limited storage capacity. \\nAlthough main memory capacities have been growing rapidly in recent \\nyears, they are still more expensive and have less storage capacity than \\ndemanded by typical enterprise-level databases. The contents of main mem-\\nory are lost in case of power failure or a system crash.\\n ■ Secondary storage. The primary choice of storage medium for online stor-\\nage of enterprise databases has been magnetic disks. However, flash memo-\\nries are becoming a common medium of choice for storing moderate \\namounts of permanent data. When used as a substitute for a disk drive, such \\nmemory is called a solid-state drive (SSD).\\n ■ Tertiary storage. Optical disks (CD-ROMs, DVDs, and other similar stor-\\nage media) and tapes are removable media used in today’s systems as offline \\nstorage for archiving databases and hence come under the category called \\ntertiary storage. These devices usually have a larger capacity, cost less, and \\nprovide slower access to data than do primary storage devices. Data in sec-\\nondary or tertiary storage cannot be processed directly by the CPU; first it \\nmust be copied into primary storage and then processed by the CPU.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 556, 'page_label': '557'}, page_content='16.1 Introduction  543\\nWe first give an overview of the various storage devices used for primary, second-\\nary, and tertiary storage in Section 16.1.1, and in Section 16.1.2 we discuss how \\ndatabases are typically handled in the storage hierarchy.\\n16.1.1 Memory Hierarchies and Storage Devices 1\\nIn a modern computer system, data resides and is transported throughout a hierar-\\nchy of storage media. The highest-speed memory is the most expensive and is \\ntherefore available with the least capacity. The lowest-speed memory is offline tape \\nstorage, which is essentially available in indefinite storage capacity.\\nAt the primary storage level, the memory hierarchy includes, at the most expensive \\nend, cache memory, which is a static RAM (random access memory). Cache mem-\\nory is typically used by the CPU to speed up execution of program instructions \\nusing techniques such as prefetching and pipelining. The next level of primary stor-\\nage is DRAM (dynamic RAM), which provides the main work area for the CPU for \\nkeeping program instructions and data. It is popularly called main memory. The \\nadvantage of DRAM is its low cost, which continues to decrease; the drawback is its \\nvolatility\\n2 and lower speed compared with static RAM.\\nAt the secondary and tertiary storage level,  the hierarchy includes magnetic disks; \\nmass storage  in the form of CD-ROM (compact disk–read-only memory) and \\nDVD (digital video disk or digital versatile disk) devices; and finally tapes at the \\nleast expensive end of the hierarchy. The storage capacity is measured in kilobytes \\n(Kbyte or 1,000 bytes), megabytes (MB or 1 million bytes), gigabytes (GB or 1 bil-\\nlion bytes), and even terabytes (1,000 GB). The word petabyte (1,000 terabytes or \\n10**15 bytes) is now becoming relevant in the context of very large repositories of \\ndata in physics, astronomy, earth sciences, and other scientific applications.\\nPrograms reside and execute in dynamic random-access memory ( DRAM ). Gen-\\nerally, large permanent databases reside on secondary storage (magnetic disks), and \\nportions of the database are read into and written from buffers in main memory as \\nneeded. Nowadays, personal computers and workstations have large main memo-\\nries of hundreds of megabytes of RAM and DRAM, so it is becoming possible to \\nload a large part of the database into main memory. Eight to sixteen GB of main \\nmemory is becoming commonplace on laptops, and servers with 256 GB capacity \\nare not uncommon. In some cases, entire databases can be kept in main memory \\n(with a backup copy on magnetic disk), which results in main memory databases; \\nthese are particularly useful in real-time applications that require extremely fast \\nresponse times. An example is telephone switching applications, which store data-\\nbases that contain routing and line information in main memory.\\nFlash Memory. Between DRAM and magnetic disk storage, another form of \\nmemory, flash memory, is becoming common, particularly because it is nonvolatile. \\n2Volatile memory typically loses its contents in case of a power outage, whereas nonvolatile memory \\ndoes not.\\n1The authors appreciate the valuable input of Dan Forsyth regarding the current status of storage \\nsystems in enterprises. The authors also wish to thank Satish Damle for his suggestions.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 557, 'page_label': '558'}, page_content='544 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nFlash memories are high-density, high-performance memories using EEPROM \\n(electrically erasable programmable read-only memory) technology. The advantage \\nof flash memory is the fast access speed; the disadvantage is that an entire block \\nmust be erased and written over simultaneously. Flash memories come in two types \\ncalled NAND and NOR flash based on the type of logic circuits used. The NAND \\nflash devices have a higher storage capacity for a given cost and are used as the data \\nstorage medium in appliances with capacities ranging from 8 GB to 64 GB for the \\npopular cards that cost less than a dollar per GB. Flash devices are used in cameras, \\nMP3/MP4 players, cell phones, PDAs (personal digital assistants), and so on. USB \\n(universal serial bus) flash drives or USB sticks have become the most portable \\nmedium for carrying data between personal computers; they have a flash memory \\nstorage device integrated with a USB interface.\\nOptical Drives. The most popular form of optical removable storage is CDs (com-\\npact disks) and DVDs. CDs have a 700-MB capacity whereas DVDs have capacities \\nranging from 4.5 to 15 GB. CD-ROM(compact disk – read only memory) disks \\nstore data optically and are read by a laser. CD-ROMs contain prerecorded data \\nthat cannot be overwritten. The version of compact and digital video disks called \\nCD-R (compact disk recordable) and DVD-R or DVD+R, which are also known as \\nWORM (write-once-read-many) disks, are a form of optical storage used for \\narchiving data; they allow data to be written once and read any number of times \\nwithout the possibility of erasing. They hold about half a gigabyte of data per disk \\nand last much longer than magnetic disks.\\n3 A higher capacity format for DVDs \\ncalled Blu-ray DVD can store 27 GB per layer, or 54 GB in a two-layer disk. Optical \\njukebox memories use an array of CD-ROM platters, which are loaded onto drives \\non demand. Although optical jukeboxes have capacities in the hundreds of giga-\\nbytes, their retrieval times are in the hundreds of milliseconds, quite a bit slower \\nthan magnetic disks. This type of tertiary storage is continuing to decline because \\nof the rapid decrease in cost and the increase in capacities of magnetic disks. Most \\npersonal computer disk drives now read CD-ROM and DVD disks. Typically, \\ndrives are CD-R (compact disk recordable) that can create CD-ROMs and audio \\nCDs, as well as record on DVDs.\\nMagnetic Tapes. Finally, magnetic tapes are used for archiving and backup stor-\\nage of data. Tape jukeboxes —which contain a bank of tapes that are catalogued \\nand can be automatically loaded onto tape drives—are becoming popular as  tertiary \\nstorage to hold terabytes of data. For example, NASA’s EOS (Earth Observation \\n Satellite) system stores archived databases in this fashion.\\nMany large organizations are using terabyte-sized databases. The term very large \\ndatabase can no longer be precisely defined because disk storage capacities are on \\n3Their rotational speeds are lower (around 400 rpm), giving higher latency delays and low transfer \\nrates (around 100 to 200 KB/second) for a 1X drive. nX drives (e.g., 16X ( n = 16) are supposed to \\ngive n times higher transfer rate by multiplying the rpm n times. The 1X DVD transfer rate is about \\n1.385 MB/s.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 558, 'page_label': '559'}, page_content='16.1 Introduction  545\\nthe rise and costs are declining. Soon the term very large database may be reserved \\nfor databases containing hundreds of terabytes or petabytes.\\nTo summarize, a hierarchy of storage devices and storage systems is available today \\nfor storage of data. Depending upon the intended use and application requirements, \\ndata is kept in one or more levels of this hierarchy. Table 16.1 summarizes the cur-\\nrent state of these devices and systems and shows the range of capacities, average \\naccess times, bandwidths (transfer speeds), and costs on the open commodity mar-\\nket. Cost of storage is generally going down at all levels of this hierarchy.\\n16.1.2 Storage Organization of Databases\\nDatabases typically store large amounts of data that must persist over long periods \\nof time, and hence the data is often referred to as persistent data. Parts of this data \\nare accessed and processed repeatedly during the storage period. This contrasts \\nwith the notion of transient data , which persists for only a limited time during \\nprogram execution. Most databases are stored permanently (or persistently ) on \\nmagnetic disk secondary storage, for the following reasons:\\n ■ Generally, databases are too large to fit entirely in main memory.4\\n ■ The circumstances that cause permanent loss of stored data arise less fre-\\nquently for disk secondary storage than for primary storage. Hence, we refer \\nto disk—and other secondary storage devices—as nonvolatile storage , \\nwhereas main memory is often called volatile storage.\\n ■ The cost of storage per unit of data is an order of magnitude less for disk \\nsecondary storage than for primary storage.\\nTable 16.1 T ypes of Storage with Capacity, Access Time, Max Bandwidth (Transfer Speed), and Commodity Cost\\n \\nType\\n \\nCapacity*\\nAccess  \\nTime\\n \\nMax Bandwidth\\nCommodity \\nPrices (2014)**\\nMain Memory- RAM 4GB–1TB 30ns 35GB/sec $100–$20K\\nFlash Memory- SSD 64 GB–1TB 50μs 750MB/sec $50–$600\\nFlash Memory- USB stick 4GB–512GB 100μs 50MB/sec $2–$200\\nMagnetic Disk 400 GB–8TB 10ms 200MB/sec $70–$500\\nOptical Storage 50GB–100GB 180ms 72MB/sec $100\\nMagnetic Tape 2.5TB–8.5TB 10s–80s 40–250MB/sec $2.5K–$30K\\nTape jukebox 25TB–2,100,000TB 10s–80s 250MB/sec–1.2PB/sec $3K–$1M+\\n*Capacities are based on commercially available popular units in 2014.\\n**Costs are based on commodity online marketplaces.\\n4This statement is being challenged by recent developments in main memory database systems.  \\nExamles of prominent commercial systems include HANA by SAP and TIMESTEN by Oracle.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 559, 'page_label': '560'}, page_content='546 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nSome of the newer technologies—such as solid-state drive (SSD) disks are likely to \\nprovide viable alternatives to the use of magnetic disks. In the future, databases may \\ntherefore reside at different levels of the memory hierarchy from those described in \\nSection 16.1.1. The levels may range from the highest speed main memory level \\nstorage to the tape jukebox low speed offline storage. However, it is anticipated that \\nmagnetic disks will continue to be the primary medium of choice for large data-\\nbases for years to come. Hence, it is important to study and understand the proper-\\nties and characteristics of magnetic disks and the way data files can be organized on \\ndisk in order to design effective databases with acceptable performance.\\nMagnetic tapes are frequently used as a storage medium for backing up databases \\nbecause storage on tape costs much less than storage on disk. With some interven-\\ntion by an operator—or an automatic loading device—tapes or optical removable \\ndisks must be loaded and read before the data becomes available for processing. In \\ncontrast, disks are online devices that can be accessed directly at any time.\\nThe techniques used to store large amounts of structured data on disk are impor-\\ntant for database designers, the DBA, and implementers of a DBMS. Database \\ndesigners and the DBA must know the advantages and disadvantages of each stor-\\nage technique when they design, implement, and operate a database on a specific \\nDBMS. Usually, the DBMS has several options available for organizing the data. \\nThe process of physical database design  involves choosing the particular data \\norganization techniques that best suit the given application requirements from \\namong the options. DBMS system implementers must study data organization \\ntechniques so that they can implement them efficiently and thus provide the DBA \\nand users of the DBMS with sufficient options.\\nTypical database applications need only a small portion of the database at a time for \\nprocessing. Whenever a certain portion of the data is needed, it must be located on \\ndisk, copied to main memory for processing, and then rewritten to the disk if the \\ndata is changed. The data stored on disk is organized as files of records. Each record \\nis a collection of data values that can be interpreted as facts about entities, their \\nattributes, and their relationships. Records should be stored on disk in a manner \\nthat makes it possible to locate them efficiently when they are needed. We will dis-\\ncuss some of the techniques for making disk access more efficient in Section 17.2.2.\\nThere are several primary file organizations , which determine how the file \\nrecords are physically placed on the disk, and hence how the records can be accessed. \\nA heap file (or unordered file) places the records on disk in no particular order by \\nappending new records at the end of the file, whereas a sorted file  (or sequential \\nfile) keeps the records ordered by the value of a particular field (called the sort key). \\nA hashed file uses a hash function applied to a particular field (called the hash key) \\nto determine a record’s placement on disk. Other primary file organizations, such \\nas B-trees,  use tree structures. We discuss primary file organizations in Sec-\\ntions\\xa016.6 through 16.9. A secondary organization  or auxiliary access structure  \\nallows efficient access to file records based on alternate fields than those that have \\nbeen used for the primary file organization. Most of these exist as indexes and will \\nbe discussed in Chapter 17.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 560, 'page_label': '561'}, page_content='16.2 Secondary Storage Devices  547\\n16.2 Secondary Storage Devices\\nIn this section, we describe some characteristics of magnetic disk and magnetic tape \\nstorage devices. Readers who have already studied these devices may simply browse \\nthrough this section.\\n16.2.1 Hardware Description of Disk Devices\\nMagnetic disks are used for storing large amounts of data. The device that holds the \\ndisks is referred to as a hard disk drive, or HDD. The most basic unit of data on the \\ndisk is a single bit of information. By magnetizing an area on a disk in certain ways, \\none can make that area represent a bit value of either 0 (zero) or 1 (one). To code \\ninformation, bits are grouped into bytes (or characters). Byte sizes are typically 4 to \\n8 bits, depending on the computer and the device; 8 bits is the most common. We \\nassume that one character is stored in a single byte, and we use the terms byte and \\ncharacter interchangeably. The capacity of a disk is the number of bytes it can store, \\nwhich is usually very large. Small floppy disks were used with laptops and desk-\\ntops for many years—they contained a single disk typically holding from 400 KB \\nto\\xa01.5 MB; they are almost completely out of circulation. Hard disks for personal \\ncomputers currently hold from several hundred gigabytes up to a few terabytes; and \\nlarge disk packs used with servers and mainframes have capacities of hundreds of \\ngigabytes. Disk capacities continue to grow as technology improves.\\nWhatever their capacity, all disks are made of magnetic material shaped as a thin \\ncircular disk, as shown in Figure 16.1(a), and protected by a plastic or acrylic cover. \\nA disk is single-sided if it stores information on one of its surfaces only and double-\\nsided if both surfaces are used. To increase storage capacity, disks are assembled \\ninto a disk pack, as shown in Figure 16.1(b), which may include many disks and \\ntherefore many surfaces. The two most common form factors are 3.5 and 2.5 inch \\ndiameter. Information is stored on a disk surface in concentric circles of small \\nwidth,\\n5 each having a distinct diameter. Each circle is called a track. In disk packs, \\ntracks with the same diameter on the various surfaces are called a cylinder because \\nof the shape they would form if connected in space. The concept of a cylinder is \\nimportant because data stored on one cylinder can be retrieved much faster than if \\nit were distributed among different cylinders.\\nThe number of tracks on a disk ranges from a few thousand to 152,000 on the disk \\ndrives shown in Table 16.2, and the capacity of each track typically ranges from tens \\nof kilobytes to 150 Kbytes. Because a track usually contains a large amount of infor-\\nmation, it is divided into smaller blocks or sectors. The division of a track into \\n sectors is hard-coded on the disk surface and cannot be changed. One type of  sector \\norganization, as shown in Figure 16.2(a), calls a portion of a track that subtends a \\nfixed angle at the center a sector. Several other sector organizations are possible, \\none of which is to have the sectors subtend smaller angles at the center as one moves \\n5In some disks, the circles are now connected into a kind of continuous spiral.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 561, 'page_label': '562'}, page_content='548 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nActuator movement\\nTrack\\nArmActuator\\nRead/write\\nhead Spindle Disk rotation\\nCylinder\\nof tracks\\n(imaginary)\\n(a)\\n(b)\\nFigure 16.1 \\n(a) A single-sided disk with read/write hardware. (b) A disk pack with read/write hardware.\\nTrack(a) Sector (arc of track)\\n(b)\\nThree sectors\\nTwo sectors\\nOne sector\\nFigure 16.2 \\nDifferent sector  \\norganizations on disk.  \\n(a) Sectors subtending \\na fixed angle.  \\n(b) Sectors maintaining \\na uniform recording \\ndensity.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 562, 'page_label': '563'}, page_content='16.2 Secondary Storage Devices  549\\nTable 16.2  Speciﬁcations of T ypical High-End Enterprise Disks from Seagate (a) Seagate Enterprise Performance \\n10 K HDD - 1200 GB\\nSpecifications 1200GB\\nSED Model Number ST1200MM0017\\nSED FIPS 140-2 Model Number ST1200MM0027\\nModel Name Enterprise Performance 10K HDD v7\\nInterface 6Gb/s SAS\\nCapacity\\nFormatted 512 Bytes/Sector (GB) 1200\\nExternal Transfer Rate (MB/s) 600\\nPerformance\\nSpindle Speed (RPM) 10K\\nAverage Latency (ms) 2.9\\nSustained Transfer Rate Outer to Inner Diameter (MB/s) 204 to 125\\nCache, Multisegmented (MB) 64\\nConfiguration/Reliability\\nDisks 4\\nHeads 8\\nNonrecoverable Read Errors per Bits Read 1 per 10E16\\nAnnualized Failure Rate (AFR) 0.44%\\nPhysical\\nHeight (in/mm, max) 0.591/15.00\\nWidth (in/mm, max) 2.760/70.10\\nDepth (in/mm, max) 3.955/100.45\\nWeight (lb/kg) 0.450/0.204\\nCourtesy Seagate Technology\\n(Continued)\\naway, thus maintaining a uniform density of recording, as shown in Figure 16.2(b). \\nA technique called ZBR (zone bit recording) allows a range of cylinders to have the \\nsame number of sectors per arc. For example, cylinders 0–99 may have one sector \\nper track, 100–199 may have two per track, and so on. A common sector size is 512 \\nbytes. Not all disks have their tracks divided into sectors.\\nThe division of a track into equal-sized disk blocks (or pages) is set by the operat-\\ning system during disk formatting (or initialization). Block size is fixed during \\ninitialization and cannot be changed dynamically. Typical disk block sizes range'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 563, 'page_label': '564'}, page_content='550 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nfrom 512 to 8192 bytes. A disk with hard-coded sectors often has the sectors subdi-\\nvided or combined into blocks during initialization. Blocks are separated by fixed-\\nsize interblock gaps , which include specially coded control information written \\nduring disk initialization. This information is used to determine which block on the \\ntrack follows each interblock gap. Table 16.2 illustrates the specifications of typical \\ndisks used on large servers in industry. The 10K prefix on disk names refers to the \\nrotational speeds in rpm (revolutions per minute.\\nThere is continuous improvement in the storage capacity and transfer rates associ-\\nated with disks; they are also progressively getting cheaper—currently costing only \\na fraction of a dollar per megabyte of disk storage. Costs are going down so rapidly \\nthat costs as low as $100/TB are already on the market.\\nA disk is a random access addressable device. Transfer of data between main mem-\\nory and disk takes place in units of disk blocks. The hardware address of a block—\\na combination of a cylinder number, track number (surface number within the \\ncylinder on which the track is located), and block number (within the track)—is \\nsupplied to the disk I/O (input/output) hardware. In many modern disk drives, a \\nsingle number called LBA (logical block address), which is a number between 0 and \\nn (assuming the total capacity of the disk is n + 1 blocks), is mapped automatically \\nto the right block by the disk drive controller. The address of a buffer—a contiguous \\nTable 16.2 (b) Internal Drive Characteristics of 300 GB–900 GB Seagate Drives\\nST900MM0006\\nST900MM0026\\nST900MM0046\\nST900MM0036\\nST600MM0006\\nST600MM0026\\nST600MM0046\\nST450MM0006\\nST450MM0026\\nST450MM0046\\nST300MM0006\\nST300MM0026\\nST300MM0046\\nDrive capacity 900 600 450 300 GB (formatted, \\nrounded off value)\\nRead/write data \\nheads\\n64 32\\nBytes per track 997.9 997.9 997.9 997.9 KBytes (avg, rounded \\noff values)\\nBytes per surface 151,674 151,674 151,674 151,674 MB (unformatted, \\nrounded off value)\\nTracks per surface \\n(total)\\n152 152 152 152 KTracks (user  \\naccessible)\\nTracks per inch 279 279 279 279 KTPI (average)\\nPeak bits per inch 1925 1925 1925 1925 KBPI\\nAreal density 538 538 538 538 Gb/in2\\nDisk rotation speed 10K 10K 10K 10K rpm\\nAvg rotational \\nlatency\\n2.9 2.9 2.9 2.9 ms'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 564, 'page_label': '565'}, page_content='16.2 Secondary Storage Devices  551\\nreserved area in main storage that holds one disk block—is also provided. For a \\nread command, the disk block is copied into the buffer; whereas for a write com-\\nmand, the contents of the buffer are copied into the disk block. Sometimes several \\ncontiguous blocks, called a cluster, may be transferred as a unit. In this case, the \\nbuffer size is adjusted to match the number of bytes in the cluster.\\nThe actual hardware mechanism that reads or writes a block is the disk read/write \\nhead, which is part of a system called a disk drive. A disk or disk pack is mounted \\nin the disk drive, which includes a motor that rotates the disks. A read/write head \\nincludes an electronic component attached to a mechanical arm. Disk packs with \\nmultiple surfaces are controlled by several read/write heads—one for each surface, \\nas shown in Figure 16.1(b). All arms are connected to an actuator attached to \\nanother electrical motor, which moves the read/write heads in unison and positions \\nthem precisely over the cylinder of tracks specified in a block address.\\nDisk drives for hard disks rotate the disk pack continuously at a constant speed (typ-\\nically ranging between 5,400 and 15,000 rpm). Once the read/write head is posi-\\ntioned on the right track and the block specified in the block address moves under \\nthe read/write head, the electronic component of the read/write head is activated to \\ntransfer the data. Some disk units have fixed read/write heads, with as many heads as \\nthere are tracks. These are called fixed-head disks, whereas disk units with an actua-\\ntor are called movable-head disks . For fixed-head disks, a track or cylinder is \\nselected by electronically switching to the appropriate read/write head rather than by \\nactual mechanical movement; consequently, it is much faster. However, the cost of \\nthe additional read/write heads is high, so fixed-head disks are not commonly used.\\nInterfacing Disk Drives to Computer Systems. A disk controller , typically \\nembedded in the disk drive, controls the disk drive and interfaces it to the computer \\nsystem. One of the standard interfaces used for disk drives on PCs and workstations \\nwas called SCSI (small computer system interface). Today to connect HDDs, CDs, and \\nDVDs to a computer, the interface of choice is SATA. SATA stands for serial ATA, \\nwherein ATA represents attachment; so SATA becomes serial AT attachment. It has \\nits origin in PC/AT attachment, which referred to the direct attachment to the 16-bit \\nbus introduced by IBM. The AT referred to advanced technology but is not used in the \\nexpansion of SATA due to trademark issues. Another popular interface used today is \\ncalled SAS (serial attached SCSI). SATA was introduced in 2002 and allows the disk \\ncontroller to be in the disk drive; only a simple circuit is required on the motherboard. \\nSATA transfer speeds underwent an evolution from 2002 to 2008, going from 1.5\\xa0Gbps \\n(gigabits per second) to 6 Gbps. SATA is now called NL-SAS for nearline SAS. The \\nlargest 3.5-inch SATA and SAS drives are 8TB, whereas 2.5-inch SAS drives are smaller \\nand go up to 1.2TB. The 3.5-inch drives use 7,200 or 10,000 rpm speed whereas \\n 2.5-inch drives use up to 15,000 rpm. In terms of IOPs (input/output operations) per \\nsecond as a price to performance index, SAS is considered superior to SATA.\\nThe controller accepts high-level I/O commands and takes appropriate action to \\nposition the arm and causes the read/write action to take place. To transfer a disk \\nblock, given its address, the disk controller must first mechanically position the'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 565, 'page_label': '566'}, page_content='552 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nread/write head on the correct track. The time required to do this is called the seek \\ntime. Typical seek times are 5 to 10 msec on desktops and 3 to 8 msec on servers. \\nFollowing that, there is another delay—called the rotational delay or latency—while \\nthe beginning of the desired block rotates into position under the read/write head. It \\ndepends on the rpm of the disk. For example, at 15,000 rpm, the time per rotation is \\n4 msec and the average rotational delay is the time per half revolution, or 2 msec. At \\n10,000 rpm the average rotational delay increases to 3 msec. Finally, some additional \\ntime is needed to transfer the data; this is called the block transfer time. Hence, the \\ntotal time needed to locate and transfer an arbitrary block, given its address, is the \\nsum of the seek time, rotational delay, and block transfer time. The seek time and \\nrotational delay are usually much larger than the block transfer time. To make the \\ntransfer of multiple blocks more efficient, it is common to transfer several consecu-\\ntive blocks on the same track or cylinder. This eliminates the seek time and rota-\\ntional delay for all but the first block and can result in a substantial saving of time \\nwhen numerous contiguous blocks are transferred. Usually, the disk manufacturer \\nprovides a bulk transfer rate for calculating the time required to transfer consecu-\\ntive blocks. Appendix B contains a discussion of these and other disk parameters.\\nThe time needed to locate and transfer a disk block is in the order of milliseconds, \\nusually ranging from 9 to 60 msec. For contiguous blocks, locating the first block \\ntakes from 9 to 60 msec, but transferring subsequent blocks may take only 0.4 \\nto\\xa02\\xa0msec each. Many search techniques take advantage of consecutive retrieval of \\nblocks when searching for data on a disk. In any case, a transfer time in the order of \\nmilliseconds is considered high compared with the time required to process data in \\nmain memory by current CPUs. Hence, locating data on disk is a major bottleneck \\nin database applications. The file structures we discuss here and in Chapter 17 \\nattempt to minimize the number of block transfers needed to locate and transfer the \\nrequired data from disk to main memory. Placing “related information” on contig-\\nuous blocks is the basic goal of any storage organization on disk.\\n16.2.2 Making Data Access More Efficient on Disk\\nIn this subsection, we list some of the commonly used techniques to make accessing \\ndata more efficient on HDDs.\\n  1. Buffering of data:  In order to deal with the incompatibility of speeds \\nbetween a CPU and the electromechanical device such as an HDD, which is \\ninherently slower, buffering of data is done in memory so that new data can \\nbe held in a buffer while old data is processed by an application. We discuss \\nthe double buffering strategy followed by general issues of buffer manage-\\nment and buffer replacement strategies in Section 16.3.\\n  2. Proper organization of data on disk: Given the structure and organization \\nof data on disk, it is advantageous to keep related data on contiguous blocks; \\nwhen multiple cylinders are needed by a relation, contiguous cylinders \\nshould be used. Doing so avoids unnecessary movement of the read/write \\narm and related seek times.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 566, 'page_label': '567'}, page_content='16.2 Secondary Storage Devices  553\\n  3. Reading data ahead of request: To minimize seek times, whenever a block \\nis read into the buffer, blocks from the rest of the track can also be read even \\nthough they may not have been requested yet. This works well for applica-\\ntions that are likely to need consecutive blocks; for random block reads this \\nstrategy is counterproductive.\\n  4. Proper scheduling of I/O requests:  If it is necessary to read several blocks \\nfrom disk, total access time can be minimized by scheduling them so that the \\narm moves only in one direction and picks up the blocks along its move-\\nment. One popular algorithm is called the elevator algorithm; this algorithm \\nmimics the behavior of an elevator that schedules requests on multiple floors \\nin a proper sequence. In this way, the arm can service requests along its out-\\nward and inward movements without much disruption.\\n  5. Use of log disks to temporarily hold writes:  A single disk may be assigned \\nto just one function called logging of writes. All blocks to be written can go \\nto that disk sequentially, thus eliminating any seek time. This works much \\nfaster than doing the writes to a file at random locations, which requires a \\nseek for each write. The log disk can order these writes in (cylinder, track) \\nordering to minimize arm movement when writing. Actually, the log disk \\ncan only be an area (extent) of a disk. Having the data file and the log file on \\nthe same disk is a cheaper solution but compromises performance. Although \\nthe idea of a log disk can improve write performance, it is not feasible for \\nmost real-life application data.\\n  6. Use of SSDs or flash memory for recovery purposes:  In applications \\nwhere updates occur with high frequency, updates can be lost from main \\nmemory if the system crashes. A preventive measure would be to increase \\nthe speed of updates/writes to disk. One possible approach involves writing \\nthe updates to a nonvolatile SSD buffer, which may be a flash memory or \\nbattery-operated DRAM, both of which operate at must faster speeds \\n(see\\xa0Table\\xa016.1). The disk controller then updates the data file during its idle \\ntime and also when the buffer becomes full. During recovery from a crash, \\nunwritten SSD buffers must be written to the data file on HDD. For further \\ndiscussion of recovery and logs, consult Chapter 22.\\n16.2.3 SolidState Device (SSD) Storage\\nThis type of storage is sometimes known as flash storage because it is based on the \\nflash memory technology, which we discussed in Section 16.1.1.\\nThe recent trend is to use flash memories as an intermediate layer between main \\nmemory and secondary rotating storage in the form of magnetic disks (HDDs). \\nSince they resemble disks in terms of the ability to store data in secondary storage \\nwithout the need for continuous power supply, they are called solid-state disks or \\nsolid-state drives (SSDs) . We will discuss SSDs in general terms first and then \\ncomment on their use at the enterprise level, where they are sometimes referred to \\nas enterprise flash drives (EFDs), a term first introduced by EMC Corporation.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 567, 'page_label': '568'}, page_content='554 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nThe main component of an SSD is a controller and a set of interconnected flash \\nmemory cards. Use of NAND flash memory is most common. Using form factors \\ncompatible with 3.5 inch or 2.5 inch HDDs makes SSDs pluggable into slots already \\navailable for mounting HDDs on laptops and servers. For ultrabooks, tablets, and \\nthe like, card-based form factors such as mSATA and M.2 are being standardized. \\nInterfaces like SATA express have been created to keep up with advancements in \\nSSDs. Because there are no moving parts, the unit is more rugged, runs silently, is \\nfaster in terms of access time and provides higher transfer rates than HDD. As \\nopposed to HDDs, where related data from the same relation must be placed on \\ncontiguous blocks, preferably on contiguous cylinders, there is no restriction on \\nplacement of data on an SSD since any address is directly addressable. As a result, \\nthe data is less likely to be fragmented; hence no reorganization is needed. Typi-\\ncally, when a write to disk occurs on an HDD, the same block is overwritten with \\nnew data. In SDDs, the data is written to different NAND cells to attain wear-leveling, \\nwhich prolongs the life of the SSD. The main issue preventing a wide-scale adop-\\ntion of SSDs today is their prohibitive cost (see Table 16.1), which tends to be about \\n70 to 80 cents per GB as opposed to about 15 to 20 cents per GB for HDDs.\\nIn addition to flash memory, DRAM-based SSDs are also available. They are cost-\\nlier than flash memory, but they offer faster access times of around 10 μs (microsec-\\nonds) as opposed to 100 μs for flash. Their main drawback is that they need an \\ninternal battery or an adapter to supply power.\\nAs an example of an enterprise level SSD, we can consider CISCO’s UCS (Unified \\nComputing System\\n©) Invicta series SSDs. They have made it possible to deploy \\nSSDs at the data center level to unify workloads of all types, including databases and \\nvirtual desktop infrastructure (VDI), and to enable a cost-effective, energy-efficient, \\nand space-saving solution. CISCO’s claim is that Invicta SSDs offer a better price-\\nto-performance ratio to applications in a multitenant, multinetworked architecture \\nbecause of the advantages of SSDs stated above. CISCO states that typically four \\ntimes as many HDD drives may be needed to match an SSD-based RAID in perfor-\\nmance.\\n6 The SSD configuration can have a capacity from 6 to 144 TB, with up to 1.2 \\nmillion I/O operations/second, and a bandwidth of up to 7.2 GB/sec with an aver-\\nage latency of 200 μs. 7 Modern data centers are undergoing rapid transformation \\nand must provide real-time response using cloud-based architectures. In this envi-\\nronment, SSDs are likely to play a major role.\\n16.2.4 Magnetic Tape Storage Devices\\nDisks are random access secondary storage devices because an arbitrary disk block \\nmay be accessed at random once we specify its address. Magnetic tapes are sequen-\\ntial access devices; to access the nth block on tape, first we must scan the preceding \\n6Based on the CISCO White Paper (CISCO, 2014)\\n7Data sheet for CISCO UCS Invicta Scaling System.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 568, 'page_label': '569'}, page_content='16.2 Secondary Storage Devices  555\\nn – 1 blocks. Data is stored on reels of high-capacity magnetic tape, somewhat sim-\\nilar to audiotapes or videotapes. A tape drive is required to read the data from or \\nwrite the data to a tape reel. Usually, each group of bits that forms a byte is stored \\nacross the tape, and the bytes themselves are stored consecutively on the tape.\\nA read/write head is used to read or write data on tape. Data records on tape are \\nalso stored in blocks—although the blocks may be substantially larger than those \\nfor disks, and interblock gaps are also quite large. With typical tape densities of \\n1,600 to 6,250 bytes per inch, a typical interblock gap\\n8 of 0.6 inch corresponds to \\n960 to 3,750 bytes of wasted storage space. It is customary to group many records \\ntogether in one block for better space utilization.\\nThe main characteristic of a tape is its requirement that we access the data blocks in \\nsequential order. To get to a block in the middle of a reel of tape, the tape is mounted \\nand then scanned until the required block gets under the read/write head. For this \\nreason, tape access can be slow and tapes are not used to store online data, except for \\nsome specialized applications. However, tapes serve a very important function—\\nbacking up the database. One reason for backup is to keep copies of disk files in case \\nthe data is lost due to a disk crash, which can happen if the disk read/write head \\ntouches the disk surface because of mechanical malfunction. For this reason, disk \\nfiles are copied periodically to tape. For many online critical applications, such as \\nairline reservation systems, to avoid any downtime, mirrored systems are used to \\nkeep three sets of identical disks—two in online operation and one as backup. Here, \\noffline disks become a backup device. The three are rotated so that they can be \\nswitched in case there is a failure on one of the live disk drives. Tapes can also be \\nused to store excessively large database files. Database files that are seldom used or \\nare outdated but required for historical recordkeeping can be archived on tape. \\nOriginally, half-inch reel tape drives were used for data storage employing the so-\\ncalled nine-track tapes. Later, smaller 8-mm magnetic tapes (similar to those used in \\ncamcorders) that can store up to 50 GB, as well as 4-mm helical scan data cartridges \\nand writable CDs and DVDs, became popular media for backing up data files from \\nPCs and workstations. They are also used for storing images and system libraries.\\nBacking up enterprise databases so that no transaction information is lost is a major \\nundertaking. Tape libraries were in vogue and featured slots for several hundred \\ncartridges; these tape libraries used digital and superdigital linear tapes (DLTs and \\nSDLTs), both of which have capacities in the hundreds of gigabytes and record data \\non linear tracks. These tape libraries are no longer in further development. The LTO \\n(Linear Tape Open) consortium set up by IBM, HP, and Seagate released the latest \\nLTO-6 standard in 2012 for tapes. It uses \\n1/2-inch-wide magnetic tapes like those \\nused in earlier tape drives but in a somewhat smaller, single-reel enclosed cartridge. \\nCurrent generation of libraries use LTO-6 drives, at 2.5-TB cartridge with 160 MB/s \\ntransfer rate. Average seek time is about 80 seconds. The T10000D drive of  \\nOracle/StorageTek handles 8.5 TB on a single cartridge with transfer rate upto \\n252\\xa0MB/s.\\n8Called interrecord gaps in tape terminology.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 569, 'page_label': '570'}, page_content='556 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nRobotic arms write on multiple cartridges in parallel using multiple tape drives and \\nautomatic labeling software to identify the backup cartridges. An example of a giant \\nlibrary is the SL8500 model of Sun Storage Technology. The SL8500 scales from \\n1,450 to just over 10,000 slots and from 1 to 64 tape drives within each library. It \\naccepts both DLT/SDLT and LTO tapes. Up to 10 SL8500s can be connected within \\na single library complex for over 100,000 slots and up to 640 drives. With 100,000 \\nslots, the SL8500 can store 2.1 exabytes (exabyte = 1,000 petabytes, or million TB = \\n10**18 bytes). We defer the discussion of disk storage technology called RAID, and \\nof storage area networks, network-attached storage, and iSCSI storage systems, to \\nthe end of the chapter.\\n16.3 Buffering of Blocks\\nWhen several blocks need to be transferred from disk to main memory and all the \\nblock addresses are known, several buffers can be reserved in main memory to \\nspeed up the transfer. While one buffer is being read or written, the CPU can pro-\\ncess data in the other buffer because an independent disk I/O processor (controller) \\nexists that, once started, can proceed to transfer a data block between memory and \\ndisk independent of and in parallel to CPU processing.\\nFigure 16.3 illustrates how two processes can proceed in parallel. Processes A and B \\nare running concurrently in an interleaved fashion, whereas processes C and D are \\nrunning concurrently in a parallel fashion. When a single CPU controls multiple \\nprocesses, parallel execution is not possible. However, the processes can still run \\nconcurrently in an interleaved way. Buffering is most useful when processes can \\nrun concurrently in a parallel fashion, either because a separate disk I/O processor \\nis available or because multiple CPU processors exist.\\nFigure 16.4 illustrates how reading and processing can proceed in parallel when the \\ntime required to process a disk block in memory is less than the time required to \\nInterleaved concurrency\\n of operations A and B\\nParallel execution of\\n operations C and D\\nt1\\nAA\\nBB\\nt2 t3 t4\\nTime\\nFigure 16.3 \\nInterleaved concurrency \\nversus parallel execution.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 570, 'page_label': '571'}, page_content='16.3 Buffering of Blocks  557\\nread the next block and fill a buffer. The CPU can start processing a block once its \\ntransfer to main memory is completed; at the same time, the disk I/O processor can \\nbe reading and transferring the next block into a different buffer. This technique is \\ncalled double buffering and can also be used to read a continuous stream of blocks \\nfrom disk to memory. Double buffering permits continuous reading or writing of \\ndata on consecutive disk blocks, which eliminates the seek time and rotational delay \\nfor all but the first block transfer. Moreover, data is kept ready for processing, thus \\nreducing the waiting time in the programs.\\n16.3.1 Buffer Management\\nBuffer management and Replacement Strategies. For most large database \\nfiles containing millions of pages, it is not possible to bring all of the data into main \\nmemory at the same time. We alluded to double buffering as a technique whereby \\nwe can gain efficiency in terms of performing the I/O operation between the disk \\nand main memory into one buffer area concurrently with processing the data from \\nanother buffer. The actual management of buffers and decisions about what buffers \\nto use to place a newly read page in the buffer is a more complex process. We use \\nthe term buffer to refer to a part of main memory that is available to receive blocks \\nor pages of data from disk.\\n9 Buffer manager is a software component of a DBMS \\nthat responds to requests for data and decides what buffer to use and what pages to \\nreplace in the buffer to accommodate the newly requested blocks. The buffer man-\\nager views the available main memory storage as a buffer pool, which has a collec-\\ntion of pages. The size of the shared buffer pool is typically a parameter for the \\nDBMS controlled by DBAs. In this section, we briefly discuss the workings of the \\nbuffer manager and discuss a few replacement strategies.\\ni + 1\\nProcess B\\ni + 2\\nFill A\\nTime\\ni\\nProcess A\\ni + 1\\nFill B\\nDisk Block:\\nI/O:\\nDisk Block:\\nPROCESSING:\\ni\\nFill A\\ni + 2\\nProcess A\\ni + 3\\nFill A\\ni + 4\\nProcess A\\ni + 3\\nProcess B\\ni + 4\\nFill A\\nFigure 16.4 \\nUse of two buffers, A and B, for reading from disk.\\n9We use the terms page and block interchangeably in the current context.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 571, 'page_label': '572'}, page_content='558 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nThere are two kinds of buffer managers; the first kind controls the main memory \\ndirectly, as in most RDBMSs. The second kind allocates buffers in virtual memory, \\nwhich allows the control to transfer to the operating system (OS). The OS in turn con-\\ntrols which buffers are actually in main memory and which ones are on disk under the \\ncontrol of OS. This second kind of buffer manager is common in main memory data-\\nbase systems and some object-oriented DBMSs. The overall goal of the buffer manager \\nis twofold: (1) to maximize the probability that the requested page is found in main \\nmemory, and (2) in case of reading a new disk block from disk, to find a page to replace \\nthat will cause the least harm in the sense that it will not be required shortly again.\\nTo enable its operation, the buffer manager keeps two types of information on hand \\nabout each page in the buffer pool:\\n  1. A pin-count: the number of times that page has been requested, or the num-\\nber of current users of that page. If this count falls to zero, the page is consid-\\nered unpinned . Initially the pin-count for every page is set to zero. \\nIncrementing the pin-count is called pinning. In general, a pinned block \\nshould not be allowed to be written to disk.\\n  2. A dirty bit, which is initially set to zero for all pages but is set to 1 whenever \\nthat page is updated by any application program.\\nIn terms of storage management, the buffer manager has the following responsibil-\\nity: It must make sure that the number of buffers fits in main memory. If the \\nrequested amount of data exceeds available buffer space, the buffer manager must \\nselect what buffers must be emptied, as governed by the buffer replacement policy \\nin force. If the buffer manager allocates space in virtual memory and all buffers in \\nuse exceed the actual main memory, then the common operating system problem \\nof “thrashing” happens and pages get moved back and forth into the swap space on \\ndisk without performing useful work.\\nWhen a certain page is requested, the buffer manager takes following actions: it \\nchecks if the requested page is already in a buffer in the buffer pool; if so, it incre-\\nments its pin-count and releases the page. If the page is not in the buffer pool, the \\nbuffer manager does the following:\\na. It chooses a page for replacement, using the replacement policy, and incre-\\nments its pin-count.\\nb. If the dirty bit of the replacement page is on, the buffer manager writes that \\npage to disk by replacing its old copy on disk. If the dirty bit is not on, this page \\nis not modified and the buffer manager is not required to write it back to disk.\\nc. It reads the requested page into the space just freed up.\\nd. The main memory address of the new page is passed to the requesting \\napplication.\\nIf there is no unpinned page available in the buffer pool and the requested page is \\nnot available in the buffer pool, the buffer manager may have to wait until a page \\ngets released. A transaction requesting this page may go into a wait state or may \\neven be aborted.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 572, 'page_label': '573'}, page_content='16.3 Buffering of Blocks  559\\n16.3.2 Buffer Replacement Strategies:\\nThe following are some popular replacement strategies that are similar to those \\nused elsewhere, such as in operating systems:\\n  1. Least recently used (LRU): The strategy here is to throw out that page that \\nhas not been used (read or written) for the longest time. This requires the \\nbuffer manager to maintain a table where it records the time every time a \\npage in a buffer is accessed. Whereas this constitutes an overhead, the strat-\\negy works well because for a buffer that is not used for a long time, its chance \\nof being accessed again is small.\\n  2. Clock policy: This is a round-robin variant of the LRU policy. Imagine the \\nbuffers are arranged like a circle similar to a clock. Each buffer has a flag \\nwith a 0 or 1 value. Buffers with a 0 are vulnerable and may be used for \\nreplacement and their contents read back to disk. Buffers with a 1 are not \\nvulnerable. When a block is read into a buffer, the flag is set to 1. When the \\nbuffer is accessed, the flag is set to 1 also. The clock hand is positioned on a \\n“current buffer.” When the buffer manager needs a buffer for a new block, it \\nrotates the hand until it finds a buffer with a 0 and uses that to read and \\nplace the new block. (If the dirty bit is on for the page being replaced, that \\npage will be written to disk, thus overwriting the old page at its address on \\ndisk.) If the clock hand passes buffers with 1s, it sets them to a zero. Thus, a \\nblock is replaced from its buffer only if it is not accessed until the hand com-\\npletes a rotation and returns to it and finds the block with the 0 that it set the \\nlast time.\\n  3. First-in-first-out (FIFO): Under this policy, when a buffer is required, the \\none that has been occupied the longest by a page is used for replacement. \\nUnder this policy, the manager notes the time each page gets loaded into a \\nbuffer; but it does not have to keep track of the time pages are accessed. \\nAlthough FIFO needs less maintenance than LRU, it can work counter to \\ndesirable behavior. A block that remains in the buffer for a long time because \\nit is needed continuously, such as a root block of an index, may be thrown \\nout but may be immediately required to be brought back.\\nLRU and clock policies are not the best policies for database applications if they \\nrequire sequential scans of data and the file cannot fit into the buffer at one time. \\nThere are also situations when certain pages in buffers cannot be thrown out and \\nwritten out to disk because certain other pinned pages point to those pages. Also, \\npolicies like FIFO can be modified to make sure that pinned blocks, such as root \\nblock of an index, are allowed to remain in the buffer. Modification of the clock \\npolicy also exists where important buffers can be set to higher values than 1 and \\ntherefore will not be subjected to replacement for several rotations of the hand. \\nThere are also situations when the DBMS has the ability to write certain blocks to \\ndisk even when the space occupied by those blocks is not needed. This is called \\nforce-writing  and occurs typically when log records have to be written to disk \\nahead of the modified pages in a transaction for recovery purposes. (See Chapter\\xa022.) \\nThere are some other replacement strategies such as MRU (most recently used)'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 573, 'page_label': '574'}, page_content='560 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nthat work well for certain types of database transactions, such as when a block that \\nis used most recently is not needed until all the remaining blocks in the relation are \\nprocessed.\\n16.4 Placing File Records on Disk\\nData in a database is regarded as a set of records organized into a set of files. In this \\nsection, we define the concepts of records, record types, and files. Then we discuss \\ntechniques for placing file records on disk. Note that henceforth in this chapter we \\nwill be referring to the random access persistent secondary storage as “disk drive” or \\n“disk.” The disk may be in different forms; for example, magnetic disks with rota-\\ntional memory or solid-state disks with electronic access and no mechanical delays.\\n16.4.1 Records and Record Types\\nData is usually stored in the form of records. Each record consists of a collection of \\nrelated data values or items, where each value is formed of one or more bytes and \\ncorresponds to a particular field of the record. Records usually describe entities and \\ntheir attributes. For example, an EMPLOYEE record represents an employee entity, \\nand each field value in the record specifies some attribute of that employee, such as \\nName, Birth_date, Salary, or Supervisor. A collection of field names and their corre-\\nsponding data types constitutes a record type or record format definition. A data \\ntype, associated with each field, specifies the types of values a field can take.\\nThe data type of a field is usually one of the standard data types used in program-\\nming. These include numeric (integer, long integer, or floating point), string of \\ncharacters (fixed-length or varying), Boolean (having 0 and 1 or TRUE and FALSE \\nvalues only), and sometimes specially coded date and time data types. The number \\nof bytes required for each data type is fixed for a given computer system. An integer \\nmay require 4 bytes, a long integer 8 bytes, a real number 4 bytes, a Boolean 1 byte, \\na date 10 bytes (assuming a format of YYYY-MM-DD), and a fixed-length string of \\nk characters k bytes. Variable-length strings may require as many bytes as there are \\ncharacters in each field value. For example, an \\nEMPLOYEE record type may be \\ndefined—using the C programming language notation—as the following structure:\\nstruct employee{\\n char name[30];\\n char ssn[9];\\n int salary;\\n int job_code;\\n char department[20];\\n} ;\\nIn some database applications, the need may arise for storing data items that consist \\nof large unstructured objects, which represent images, digitized video or audio \\nstreams, or free text. These are referred to as BLOBs (binary large objects). A BLOB \\ndata item is typically stored separately from its record in a pool of disk blocks, and'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 574, 'page_label': '575'}, page_content='16.4 Placing File Records on Disk  561\\na pointer to the BLOB is included in the record. For storing free text, some DBMSs \\n(e.g., Oracle, DB2, etc.) provide a data type called CLOB (character large object); \\nsome DBMSs call this data type text.\\n16.4.2  Files, Fixed-Length Records,  \\nand Variable-Length Records\\nA file is a sequence of records. In many cases, all records in a file are of the same \\nrecord type. If every record in the file has exactly the same size (in bytes), the file is \\nsaid to be made up of fixed-length records. If different records in the file have dif-\\nferent sizes, the file is said to be made up of variable-length records . A file may \\nhave variable-length records for several reasons:\\n ■ The file records are of the same record type, but one or more of the fields are \\nof varying size ( variable-length fields ). For example, the Name field of \\nEMPLOYEE can be a variable-length field.\\n ■ The file records are of the same record type, but one or more of the fields may \\nhave multiple values for individual records; such a field is called a repeating \\nfield and a group of values for the field is often called a repeating group.\\n ■ The file records are of the same record type, but one or more of the fields are \\noptional; that is, they may have values for some but not all of the file records \\n(optional fields).\\n ■ The file contains records of different record types and hence of varying size \\n(mixed file). This would occur if related records of different types were clustered \\n(placed together) on disk blocks; for example, the GRADE_REPORT records of \\na particular student may be placed following that STUDENT’s record.\\nThe fixed-length EMPLOYEE records in Figure 16.5(a) have a record size of 71 bytes. \\nEvery record has the same fields, and field lengths are fixed, so the system can iden-\\ntify the starting byte position of each field relative to the starting position of the \\nrecord. This facilitates locating field values by programs that access such files. \\nNotice that it is possible to represent a file that logically should have variable-length \\nrecords as a fixed-length records file. For example, in the case of optional fields, we \\ncould have every field included in every file record but store a special \\nNULL value if \\nno value exists for that field. For a repeating field, we could allocate as many spaces \\nin each record as the maximum possible number of occurrences of the field. In either \\ncase, space is wasted when certain records do not have values for all the physical \\nspaces provided in each record. Now we consider other options for formatting \\nrecords of a file of variable-length records.\\nFor variable-length fields, each record has a value for each field, but we do not know \\nthe exact length of some field values. To determine the bytes within a particular \\nrecord that represent each field, we can use special separator characters (such as ? \\nor % or $)—which do not appear in any field value—to terminate variable-length \\nfields, as shown in Figure 16.5(b), or we can store the length in bytes of the field in \\nthe record, preceding the field value.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 575, 'page_label': '576'}, page_content='562 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nA file of records with optional fields can be formatted in different ways. If the total \\nnumber of fields for the record type is large, but the number of fields that actually \\nappear in a typical record is small, we can include in each record a sequence of \\n<field-name, field-value> pairs rather than just the field values. Three types of sepa-\\nrator characters are used in Figure 16.5(c), although we could use the same separa-\\ntor character for the first two purposes—separating the field name from the field \\nvalue and separating one field from the next field. A more practical option is to \\nassign a short field type code—say, an integer number—to each field and include in \\neach record a sequence of <field-type, field-value> pairs rather than <field-name, \\nfield-value> pairs.\\nA repeating field needs one separator character to separate the repeating values of \\nthe field and another separator character to indicate termination of the field. Finally, \\nfor a file that includes records of different types, each record is preceded by a record \\nName = Smith, John Ssn = 123456789 DEPARTMENT = Computer\\nSmith, John\\nName\\n1\\n(a)\\n(b)\\n(c)\\n11 22 1 2 5 2 9\\nName Ssn Salary Job_code Department Hire_date\\n31 40 44 48 68\\nSsn Salary Job_code Department\\nSeparator Characters123456789 XXXX XXXX Computer\\nSeparator Characters\\nSeparates field name\\n from field value\\nSeparates fields\\nTerminates record\\n=\\nFigure 16.5 \\nThree record storage formats. (a) A fixed-length record with six fields and size of 71 bytes. (b) A record with  \\ntwo variable-length fields and three fixed-length fields. (c) A variable-field record with three types of separator \\ncharacters.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 576, 'page_label': '577'}, page_content='16.4 Placing File Records on Disk  563\\ntype indicator. Understandably, programs that process files of variable-length \\nrecords—which are usually part of the file system and hence hidden from the typi-\\ncal programmers—need to be more complex than those for fixed-length records, \\nwhere the starting position and size of each field are known and fixed.\\n10\\n16.4.3  Record Blocking and Spanned  \\nversus Unspanned Records\\nThe records of a file must be allocated to disk blocks because a block is the unit of data \\ntransfer between disk and memory. When the block size is larger than the record size, \\neach block will contain numerous records, although some files may have unusually \\nlarge records that cannot fit in one block. Suppose that the block size is B bytes. For a \\nfile of fixed-length records of size R bytes, with B ≥ R, we can fit bfr = ⎣B/R⎦ records \\nper block, where the ⎣(x)⎦ (floor function) rounds down the number x to an integer. \\nThe value bfr is called the blocking factor for the file. In general, R may not divide B \\nexactly, so we have some unused space in each block equal to\\nB − (bfr * R) bytes\\nTo utilize this unused space, we can store part of a record on one block and the rest \\non another. A pointer at the end of the first block points to the block containing the \\nremainder of the record in case it is not the next consecutive block on disk. This \\norganization is called spanned because records can span more than one block. \\nWhenever a record is larger than a block, we must use a spanned organization. If \\nrecords are not allowed to cross block boundaries, the organization is called \\nunspanned. This is used with fixed-length records having B > R because it makes \\neach record start at a known location in the block, simplifying record processing. For \\nvariable-length records, either a spanned or an unspanned organization can be used. \\nIf the average record is large, it is advantageous to use spanning to reduce the lost \\nspace in each block. Figure 16.6 illustrates spanned versus unspanned organization.\\nFor variable-length records using spanned organization, each block may store a dif-\\nferent number of records. In this case, the blocking factor bfr represents the average \\n10Other schemes are also possible for representing variable-length records.\\nRecord 1Block i Record 2 Record 3 Record 4 P\\nRecord 4 (rest)Block i + 1 Record 5 Record 6 Record 7 P\\nRecord 1Block i\\n(b)\\n(a) Record 2 Record 3\\nRecord 4Block i + 1 Record 5 Record 6\\nFigure 16.6 \\nTypes of record \\norganization.  \\n(a) Unspanned.  \\n(b) Spanned.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 577, 'page_label': '578'}, page_content='564 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nnumber of records per block for the file. We can use bfr to calculate the number of \\nblocks b needed for a file of r records:\\nb = ⎡(r/bfr)⎤ blocks\\nwhere the ⎡(x)⎤ (ceiling function) rounds the value x up to the next integer.\\n16.4.4 Allocating File Blocks on Disk\\nThere are several standard techniques for allocating the blocks of a file on disk. In \\ncontiguous allocation, the file blocks are allocated to consecutive disk blocks. This \\nmakes reading the whole file very fast using double buffering, but it makes expanding \\nthe file difficult. In linked allocation, each file block contains a pointer to the next file \\nblock. This makes it easy to expand the file but makes it slow to read the whole file. A \\ncombination of the two allocates clusters of consecutive disk blocks, and the clusters \\nare linked. Clusters are sometimes called file segments or extents. Another possibil-\\nity is to use indexed allocation, where one or more index blocks contain pointers to \\nthe actual file blocks. It is also common to use combinations of these techniques.\\n16.4.5 File Headers\\nA file header or file descriptor contains information about a file that is needed by \\nthe system programs that access the file records. The header includes information \\nto determine the disk addresses of the file blocks as well as to record format descrip-\\ntions, which may include field lengths and the order of fields within a record for \\nfixed-length unspanned records and field type codes, separator characters, and \\nrecord type codes for variable-length records.\\nTo search for a record on disk, one or more blocks are copied into main memory \\nbuffers. Programs then search for the desired record or records within the buffers, \\nusing the information in the file header. If the address of the block that contains the \\ndesired record is not known, the search programs must do a linear search through \\nthe file blocks. Each file block is copied into a buffer and searched until the record \\nis located or all the file blocks have been searched unsuccessfully. This can be very \\ntime-consuming for a large file. The goal of a good file organization is to avoid lin-\\near search or full scan of the file and to locate the block that contains a desired \\nrecord with a minimal number of block transfers.\\n16.5 Operations on Files\\nOperations on files are usually grouped into retrieval operations  and update \\n operations. The former do not change any data in the file, but only locate certain \\nrecords so that their field values can be examined and processed. The latter change \\nthe file by insertion or deletion of records or by modification of field values. In \\neither case, we may have to select one or more records for retrieval, deletion, or \\nmodification based on a selection condition (or filtering condition), which specifies \\ncriteria that the desired record or records must satisfy.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 578, 'page_label': '579'}, page_content='16.5 Operations on Files  565\\nConsider an EMPLOYEE file with fields Name, Ssn, Salary, Job_code, and Department. \\nA simple selection condition  may involve an equality comparison on some field \\nvalue—for example, ( Ssn = ‘123456789’) or ( Department = ‘Research’). More com-\\nplex conditions can involve other types of comparison operators, such as > or ≥ ; an \\nexample is (Salary ≥ 30000). The general case is to have an arbitrary Boolean expres-\\nsion on the fields of the file as the selection condition.\\nSearch operations on files are generally based on simple selection conditions. A \\ncomplex condition must be decomposed by the DBMS (or the programmer) to \\nextract a simple condition that can be used to locate the records on disk. Each \\nlocated record is then checked to determine whether it satisfies the full selection \\ncondition. For example, we may extract the simple condition (\\nDepartment  = \\n‘Research’) from the complex condition (( Salary ≥ 30000) AND ( Department  = \\n‘Research’)); each record satisfying ( Department = ‘Research’) is located and then \\ntested to see if it also satisfies (Salary ≥ 30000).\\nWhen several file records satisfy a search condition, the first record—with respect \\nto the physical sequence of file records—is initially located and designated the \\n current record . Subsequent search operations commence from this record and \\nlocate the next record in the file that satisfies the condition.\\nActual operations for locating and accessing file records vary from system to sys-\\ntem. In the following list, we present a set of representative operations. Typically, \\nhigh-level programs, such as DBMS software programs, access records by using \\nthese commands, so we sometimes refer to program variables  in the following \\ndescriptions:\\n ■ Open. Prepares the file for reading or writing. Allocates appropriate buffers \\n(typically at least two) to hold file blocks from disk, and retrieves the file \\nheader. Sets the file pointer to the beginning of the file.\\n ■ Reset. Sets the file pointer of an open file to the beginning of the file.\\n ■ Find (or Locate). Searches for the first record that satisfies a search condi-\\ntion. Transfers the block containing that record into a main memory buffer \\n(if it is not already there). The file pointer points to the record in the buffer \\nand it becomes the current record.  Sometimes, different verbs are used to \\nindicate whether the located record is to be retrieved or updated.\\n ■ Read (or Get). Copies the current record from the buffer to a program vari-\\nable in the user program. This command may also advance the current \\nrecord pointer to the next record in the file, which may necessitate reading \\nthe next file block from disk.\\n ■ FindNext. Searches for the next record in the file that satisfies the search \\ncondition. Transfers the block containing that record into a main memory \\nbuffer (if it is not already there). The record is located in the buffer and \\nbecomes the current record. Various forms of FindNext (for example, \\n FindNext record within a current parent record, FindNext record of a given \\ntype, or FindNext record where a complex condition is met) are available in \\nlegacy DBMSs based on the hierarchical and network models.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 579, 'page_label': '580'}, page_content='566 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\n ■ Delete. Deletes the current record and (eventually) updates the file on disk \\nto reflect the deletion.\\n ■ Modify. Modifies some field values for the current record and (eventually) \\nupdates the file on disk to reflect the modification.\\n ■ Insert. Inserts a new record in the file by locating the block where the record \\nis to be inserted, transferring that block into a main memory buffer (if it is \\nnot already there), writing the record into the buffer, and (eventually) writ-\\ning the buffer to disk to reflect the insertion.\\n ■ Close. Completes the file access by releasing the buffers and performing any \\nother needed cleanup operations.\\nThe preceding (except for Open and Close) are called record-at-a-time operations \\nbecause each operation applies to a single record. It is possible to streamline the \\noperations Find, FindNext, and Read into a single operation, Scan, whose descrip-\\ntion is as follows:\\n ■ Scan. If the file has just been opened or reset, Scan returns the first record; \\notherwise it returns the next record. If a condition is specified with the oper-\\nation, the returned record is the first or next record satisfying the condition.\\nIn database systems, additional set-at-a-time  higher-level operations may be \\napplied to a file. Examples of these are as follows:\\n ■ FindAll. Locates all the records in the file that satisfy a search condition.\\n ■ Find (or Locate) n. Searches for the first record that satisfies a search condi-\\ntion and then continues to locate the next n − 1 records satisfying the same \\ncondition. Transfers the blocks containing the n records to the main mem-\\nory buffer (if not already there).\\n ■ FindOrdered. Retrieves all the records in the file in some specified order.\\n ■ Reorganize.  Starts the reorganization process. As we shall see, some file \\norganizations require periodic reorganization. An example is to reorder the \\nfile records by sorting them on a specified field.\\nAt this point, it is worthwhile to note the difference between the terms file organiza-\\ntion and access method. A file organization refers to the organization of the data of \\na file into records, blocks, and access structures; this includes the way records and \\nblocks are placed on the storage medium and interlinked. An access method, on \\nthe other hand, provides a group of operations—such as those listed earlier—that \\ncan be applied to a file. In general, it is possible to apply several access methods to a \\nfile organized using a certain organization. Some access methods, though, can be \\napplied only to files organized in certain ways. For example, we cannot apply an \\nindexed access method to a file without an index (see Chapter 17).\\nUsually, we expect to use some search conditions more than others. Some files may \\nbe static, meaning that update operations are rarely performed; other, more \\ndynamic files may change frequently, so update operations are constantly applied \\nto them. If a file is not updatable by the end user, it is regarded as a read-only file.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 580, 'page_label': '581'}, page_content='16.6 Files of Unordered Records (Heap Files)  567\\nMost data warehouses (see Chapter 29) predominantly contain read-only files. A \\nsuccessful file organization should perform as efficiently as possible the operations \\nwe expect to apply frequently to the file. For example, consider the \\nEMPLOYEE file, \\nas shown in Figure 16.5(a), which stores the records for current employees in a \\ncompany. We expect to insert records (when employees are hired), delete records \\n(when employees leave the company), and modify records (for example, when an \\nemployee’s salary or job is changed). Deleting or modifying a record requires a \\nselection condition to identify a particular record or set of records. Retrieving one \\nor more records also requires a selection condition.\\nIf users expect mainly to apply a search condition based on \\nSsn, the designer must \\nchoose a file organization that facilitates locating a record given its Ssn value. This \\nmay involve physically ordering the records by Ssn value or defining an index on \\nSsn (see Chapter 17). Suppose that a second application uses the file to generate \\nemployees’ paychecks and requires that paychecks are grouped by department. For \\nthis application, it is best to order employee records by department and then by \\nname within each department. The clustering of records into blocks and the orga-\\nnization of blocks on cylinders would now be different than before. However, this \\narrangement conflicts with ordering the records by \\nSsn values. If both applications \\nare important, the designer should choose an organization that allows both opera-\\ntions to be done efficiently. Unfortunately, in many cases a single organization does \\nnot allow all needed operations on a file to be implemented efficiently. Since a file \\ncan be stored only once using one particular organization, the DBAs are often faced \\nwith making a difficult design choice about the file organization. They make it \\nbased on the expected importance and mix of retrieval and update operations.\\nIn the following sections and in Chapter 17, we discuss methods for organizing \\nrecords of a file on disk. Several general techniques, such as ordering, hashing, and \\nindexing, are used to create access methods. Additionally, various general tech-\\nniques for handling insertions and deletions work with many file organizations.\\n16.6 Files of Unordered Records (Heap Files)\\nIn this simplest and most basic type of organization, records are placed in the file in \\nthe order in which they are inserted, so new records are inserted at the end of the \\nfile. Such an organization is called a heap or pile file.\\n11 This organization is often \\nused with additional access paths, such as the secondary indexes discussed in Chap-\\nter 17. It is also used to collect and store data records for future use.\\nInserting a new record is very efficient. The last disk block of the file is copied into a \\nbuffer, the new record is added, and the block is then rewritten back to disk. The \\naddress of the last file block is kept in the file header. However, searching for a \\nrecord using any search condition involves a linear search through the file block by \\nblock—an expensive procedure. If only one record satisfies the search condition, \\nthen, on the average, a program will read into memory and search half the file \\n11Sometimes this organization is called a sequential file.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 581, 'page_label': '582'}, page_content='568 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nblocks before it finds the record. For a file of b blocks, this requires searching (b/2) \\nblocks, on average. If no records or several records satisfy the search condition, the \\nprogram must read and search all b blocks in the file.\\nTo delete a record, a program must first find its block, copy the block into a buffer, \\ndelete the record from the buffer, and finally rewrite the block  back to the disk. \\nThis leaves unused space in the disk block. Deleting a large number of records in \\nthis way results in wasted storage space. Another technique used for record deletion \\nis to have an extra byte or bit, called a deletion marker, stored with each record. A \\nrecord is deleted by setting the deletion marker to a certain value. A different value \\nfor the marker indicates a valid (not deleted) record. Search programs consider \\nonly valid records in a block when conducting their search. Both of these deletion \\ntechniques require periodic reorganization of the file to reclaim the unused space \\nof deleted records. During reorganization, the file blocks are accessed consecu-\\ntively, and records are packed by removing deleted records. After such a reorgani-\\nzation, the blocks are filled to capacity once more. Another possibility is to use the \\nspace of deleted records when inserting new records, although this requires extra \\nbookkeeping to keep track of empty locations.\\nWe can use either spanned or unspanned organization for an unordered file, and it \\nmay be used with either fixed-length or variable-length records. Modifying a vari-\\nable-length record may require deleting the old record and inserting a modified \\nrecord because the modified record may not fit in its old space on disk.\\nTo read all records in order of the values of some field, we create a sorted copy of \\nthe file. Sorting is an expensive operation for a large disk file, and special techniques \\nfor external sorting are used (see Chapter 18).\\nFor a file of unordered fixed-length records using unspanned blocks and contiguous \\nallocation, it is straightforward to access any record by its position in the file. If the \\nfile records are numbered 0, 1, 2, … , r − 1 and the records in each block are num-\\nbered 0, 1, …, bfr − 1, where bfr is the blocking factor, then the ith record of the file \\nis located in block ⎣(i/bfr)⎦ and is the (i mod bfr)th record in that block. Such a file \\nis often called a relative or direct file because records can easily be accessed directly \\nby their relative positions. Accessing a record by its position does not help locate a \\nrecord based on a search condition; however, it facilitates the construction of access \\npaths on the file, such as the indexes discussed in Chapter 17.\\n16.7 Files of Ordered Records (Sorted Files)\\nWe can physically order the records of a file on disk based on the values of one of \\ntheir fields—called the ordering field. This leads to an ordered or sequential file.\\n12 \\nIf the ordering field is also a key field of the file—a field guaranteed to have a unique \\nvalue in each record—then the field is called the ordering key for the file. Figure 16.7 \\n12The term sequential file has also been used to refer to unordered files, although it is more appropriate \\nfor ordered files.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 582, 'page_label': '583'}, page_content='16.7 Files of Ordered Records (Sorted Files)  569\\nName\\nAaron, Ed\\nAbbott, Diane\\nBlock 1\\nAcosta, Marc\\nSsn Birth_date\\n..\\n.\\nJob\\nSalary Sex\\n...\\nAdams, John\\nAdams, Robin\\nBlock 2\\nAkers, Jan\\n..\\n.\\nAlexander, Ed\\nAlfred, Bob\\nBlock 3\\nAllen, Sam\\n..\\n.\\nAllen, Troy\\nAnders, Keith\\nBlock 4\\nAnderson, Rob\\n...\\nAnderson, Zach\\nAngeli, Joe\\nBlock 5\\nArcher, Sue\\n..\\n.\\nArnold, Mack\\nArnold, Steven\\nBlock 6\\nAtkins, Timothy\\nWong, James\\nWood, Donald\\nBlock n–1\\nWoods, Manny\\n...\\nWright, Pam\\nWyatt, Charles\\nBlock n\\nZimmer, Byron\\n...\\nFigure 16.7 \\nSome blocks of an ordered (sequential) file of EMPLOYEE records with \\nName as the ordering key field.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 583, 'page_label': '584'}, page_content='570 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nshows an ordered file with Name as the ordering key field (assuming that employees \\nhave distinct names).\\nOrdered records have some advantages over unordered files. First, reading the \\nrecords in order of the ordering key values becomes extremely efficient because no \\nsorting is required. The search condition may be of the type < key = value>, or a \\nrange condition such as < value1 < key < value2>. Second, finding the next record \\nfrom the current one in order of the ordering key usually requires no additional \\nblock accesses because the next record is in the same block as the current one \\n(unless the current record is the last one in the block). Third, using a search condi-\\ntion based on the value of an ordering key field results in faster access when the \\nbinary search technique is used, which constitutes an improvement over linear \\nsearches, although it is not often used for disk files. Ordered files are blocked and \\nstored on contiguous cylinders to minimize the seek time.\\nA binary search for disk files can be done on the blocks rather than on the records. \\nSuppose that the file has b blocks numbered 1, 2, …, b; the records are ordered by \\nascending value of their ordering key field; and we are searching for a record whose \\nordering key field value is K. Assuming that disk addresses of the file blocks are \\navailable in the file header, the binary search can be described by Algorithm 16.1. A \\nbinary search usually accesses log\\n2(b) blocks, whether the record is found or not—an \\nimprovement over linear searches, where, on the average, (b/2) blocks are accessed \\nwhen the record is found and b blocks are accessed when the record is not found.\\nAlgorithm 16.1. Binary Search on an Ordering Key of a Disk File\\nl ← 1; u ← b; (*b is the number of file blocks*)\\nwhile (u ≥ l ) do\\n begin i ← (l + u) div 2;\\n read block i of the file into the buffer;\\n if K < (ordering key field value of the first record in block i )\\n  then u ← i − 1\\n else if K > (ordering key field value of the last record in block i )\\n  then l ← i + 1\\n else if the record with ordering key field value = K is in the buffer\\n  then goto found\\n else goto notfound;\\n end;\\ngoto notfound;\\nA search criterion involving the conditions >, <, ≥, and ≤ on the ordering field is \\nefficient, since the physical ordering of records means that all records satisfying the \\ncondition are contiguous in the file. For example, referring to Figure 16.7, if the \\nsearch criterion is (\\nName > ‘G’)—where > means alphabetically before—the records \\nsatisfying the search criterion are those from the beginning of the file up to the first \\nrecord that has a Name value starting with the letter ‘G’.\\nOrdering does not provide any advantages for random or ordered access of the \\nrecords based on values of the other nonordering fields of the file. In these cases, we'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 584, 'page_label': '585'}, page_content='16.7 Files of Ordered Records (Sorted Files)  571\\ndo a linear search for random access. To access the records in order based on a non-\\nordering field, it is necessary to create another sorted copy—in a different order—of \\nthe file.\\nInserting and deleting records are expensive operations for an ordered file because \\nthe records must remain physically ordered. To insert a record, we must find its \\ncorrect position in the file, based on its ordering field value, and then make space in \\nthe file to insert the record in that position. For a large file this can be very time-\\nconsuming because, on the average, half the records of the file must be moved to \\nmake space for the new record. This means that half the file blocks must be read \\nand rewritten after records are moved among them. For record deletion, the prob-\\nlem is less severe if deletion markers and periodic reorganization are used.\\nOne option for making insertion more efficient is to keep some unused space in each \\nblock for new records. However, once this space is used up, the original problem \\nresurfaces. Another frequently used method is to create a temporary unordered file \\ncalled an overflow or transaction file. With this technique, the actual ordered file is \\ncalled the main or master file. New records are inserted at the end of the overflow \\nfile rather than in their correct position in the main file. Periodically, the overflow \\nfile is sorted and merged with the master file during file reorganization. Insertion \\nbecomes very efficient, but at the cost of increased complexity in the search algo-\\nrithm. One option is to keep the highest value of the key in each block in a separate \\nfield after taking into account the keys that have overflown from that block. Other-\\nwise, the overflow file must be searched using a linear search if, after the binary \\nsearch, the record is not found in the main file. For applications that do not require \\nthe most up-to-date information, overflow records can be ignored during a search.\\nModifying a field value of a record depends on two factors: the search condition to \\nlocate the record and the field to be modified. If the search condition involves the \\nordering key field, we can locate the record using a binary search; otherwise we \\nmust do a linear search. A nonordering field can be modified by changing the \\nrecord and rewriting it in the same physical location on disk—assuming fixed-\\nlength records. Modifying the ordering field means that the record can change its \\nposition in the file. This requires deletion of the old record followed by insertion of \\nthe modified record.\\nReading the file records in order of the ordering field is efficient if we ignore the \\nrecords in overflow, since the blocks can be read consecutively using double buffer-\\ning. To include the records in overflow, we must merge them in their correct posi-\\ntions; in this case, first we can reorganize the file, and then read its blocks \\nsequentially. To reorganize the file, first we sort the records in the overflow file, and \\nthen merge them with the master file. The records marked for deletion are removed \\nduring the reorganization.\\nTable 16.3 summarizes the average access time in block accesses to find a specific \\nrecord in a file with b blocks.\\nOrdered files are rarely used in database applications unless an additional access \\npath, called a primary index , is used; this results in an indexed-sequential file .'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 585, 'page_label': '586'}, page_content='572 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nThis further improves the random access time on the ordering key field. (We dis-\\ncuss indexes in Chapter 17.) If the ordering attribute is not a key, the file is called a \\nclustered file.\\n16.8 Hashing Techniques\\nAnother type of primary file organization is based on hashing, which provides very \\nfast access to records under certain search conditions. This organization is usually \\ncalled a hash file.\\n13 The search condition must be an equality condition on a single \\nfield, called the hash field. In most cases, the hash field is also a key field of the file, \\nin which case it is called the hash key. The idea behind hashing is to provide a func-\\ntion h, called a hash function  or randomizing function , which is applied to the \\nhash field value of a record and yields the address of the disk block in which the \\nrecord is stored. A search for the record within the block can be carried out in a \\nmain memory buffer. For most records, we need only a single-block access to \\nretrieve that record.\\nHashing is also used as an internal search structure within a program whenever \\na group of records is accessed exclusively by using the value of one field. We \\ndescribe the use of hashing for internal files in Section 16.8.1; then we show \\nhow it is modified to store external files on disk in Section 16.8.2. In Sec-\\ntion\\xa016.8.3 we discuss techniques for extending hashing to dynamically growing \\nfiles.\\n16.8.1 Internal Hashing\\nFor internal files, hashing is typically implemented as a hash table through the use \\nof an array of records. Suppose that the array index range is from 0 to M – 1, as \\nshown in Figure 16.8(a); then we have M slots whose addresses correspond to the \\narray indexes. We choose a hash function that transforms the hash field value into \\nan integer between 0 and M − 1. One common hash function is the h(K) = K mod \\nM function, which returns the remainder of an integer hash field value K after divi-\\nsion by M; this value is then used for the record address.\\nTable 16.3  Average Access Times for a File of b Blocks under Basic File Organizations\\n \\nType of Organization\\n \\nAccess/Search Method\\nAverage Blocks to Access  \\na Specific Record\\nHeap (unordered) Sequential scan (linear search) b/2\\nOrdered Sequential scan b/2\\nOrdered Binary search log 2 b\\n13A hash file has also been called a direct file.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 586, 'page_label': '587'}, page_content='16.8 Hashing Techniques  573\\nNoninteger hash field values can be transformed into integers before the mod func-\\ntion is applied. For character strings, the numeric (ASCII) codes associated with \\ncharacters can be used in the transformation—for example, by multiplying those \\ncode values. For a hash field whose data type is a string of 20 characters, Algo-\\nrithm\\xa016.2(a) can be used to calculate the hash address. We assume that the code \\nfunction returns the numeric code of a character and that we are given a hash field \\nvalue K of type K: array [1..20] of char (in Pascal) or char K[20] (in C).\\n(a)\\n–1\\n–1\\n–1\\nM + 2\\nM\\n0\\n1\\n2\\n3\\nM – 2\\nM – 1\\nData fields Overflow pointer\\nAddress space\\nOverflow space\\nM + 1\\nM + 5\\n–1\\nM + 4\\n–1\\nM + 0 – 2\\nM + 0 – 1\\nnull pointer = –1\\noverflow pointer refers to position of next record in linked list\\nM – 2\\nM\\nM + 1\\nM + 2\\nM – 1\\nName Ssn Job Salary\\n(b) 0\\n1\\n2\\n3\\n4\\n..\\n.\\nFigure 16.8 \\nInternal hashing data structures. (a) Array  \\nof M positions for use in internal hashing.  \\n(b) Collision resolution by chaining records.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 587, 'page_label': '588'}, page_content='574 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nAlgorithm 16.2. Two simple hashing algorithms: (a) Applying the mod hash \\nfunction to a character string K. (b) Collision resolution by open addressing.\\n(a) temp ← 1;\\nfor i ← 1 to 20 do temp ← temp * code(K[i ] ) mod M ;\\nhash_address ← temp mod M;\\n(b) i ← hash_address(K); a ← i;\\nif location i is occupied\\n then begin i ← (i + 1) mod M;\\n  while ( i ≠ a) and location i is occupied\\n   d o  i ← (i + 1) mod M;\\n  if ( i = a) then all positions are full\\n  e l s e  new_hash_address ← i;\\n  end;\\nOther hashing functions can be used. One technique, called folding, involves apply-\\ning an arithmetic function such as addition or a logical function such as exclusive or \\nto different portions of the hash field value to calculate the hash address (for exam-\\nple, with an address space from 0 to 999 to store 1,000 keys, a 6-digit key 235469 \\nmay be folded and stored at the address: (235+964) mod 1000 = 199). Another tech-\\nnique involves picking some digits of the hash field value—for instance, the third, \\nfifth, and eighth digits—to form the hash address (for example, storing 1,000 \\nemployees with Social Security numbers of 10 digits into a hash file with 1,000 posi-\\ntions would give the Social Security number 301-67-8923 a hash value of 172 by this \\nhash function). 14 The problem with most hashing functions is that they do not \\nguarantee that distinct values will hash to distinct addresses, because the hash field \\nspace—the number of possible values a hash field can take—is usually much larger \\nthan the address space—the number of available addresses for records. The hash-\\ning function maps the hash field space to the address space.\\nA collision occurs when the hash field value of a record that is being inserted hashes \\nto an address that already contains a different record. In this situation, we must \\ninsert the new record in some other position, since its hash address is occupied. The \\nprocess of finding another position is called collision resolution. There are numer-\\nous methods for collision resolution, including the following:\\n ■ Open addressing. Proceeding from the occupied position specified by the \\nhash address, the program checks the subsequent positions in order until an \\nunused (empty) position is found. Algorithm 16.2(b) may be used for this \\npurpose.\\n ■ Chaining. For this method, various overflow locations are kept, usually by \\nextending the array with a number of overflow positions. Additionally, a \\npointer field is added to each record location. A collision is resolved by plac-\\ning the new record in an unused overflow location and setting the pointer of \\nthe occupied hash address location to the address of that overflow location. \\n14 A detailed discussion of hashing functions is outside the scope of our presentation.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 588, 'page_label': '589'}, page_content='16.8 Hashing Techniques  575\\nA linked list of overflow records for each hash address is thus maintained, as \\nshown in Figure 16.8(b).\\n ■ Multiple hashing. The program applies a second hash function if the first \\nresults in a collision. If another collision results, the program uses open \\naddressing or applies a third hash function and then uses open addressing if \\nnecessary. Note that the series of hash functions are used in the same order \\nfor retrieval.\\nEach collision resolution method requires its own algorithms for insertion, retrieval, \\nand deletion of records. The algorithms for chaining are the simplest. Deletion \\nalgorithms for open addressing are rather tricky. Data structures textbooks discuss \\ninternal hashing algorithms in more detail.\\nThe goal of a good hashing function is twofold: first, to distribute the records uni-\\nformly over the address space so as to minimize collisions, thus making it possible \\nto locate a record with a given key in a single access. The second, somewhat con-\\nflicting, goal is to achieve the above yet occupy the buckets fully, thus not leaving \\nmany unused locations. Simulation and analysis studies have shown that it is usu-\\nally best to keep a hash file between 70 and 90% full so that the number of collisions \\nremains low and we do not waste too much space. Hence, if we expect to have r \\nrecords to store in the table, we should choose M locations for the address space \\nsuch that (r/M) is between 0.7 and 0.9. It may also be useful to choose a prime num-\\nber for M, since it has been demonstrated that this distributes the hash addresses \\nbetter over the address space when the mod hashing function is used modulo a \\nprime number. Other hash functions may require M to be a power of 2.\\n16.8.2 External Hashing for Disk Files\\nHashing for disk files is called external hashing . To suit the characteristics of disk \\nstorage, the target address space is made of buckets, each of which holds multiple \\nrecords. A bucket is either one disk block or a cluster of contiguous disk blocks. \\nThe hashing function maps a key into a relative bucket number rather than \\nassigning an absolute block address to the bucket. A table maintained in the file \\nheader converts the bucket number into the corresponding disk block address, as \\nillustrated in Figure 16.9.\\nThe collision problem is less severe with buckets, because as many records as will fit \\nin a bucket can hash to the same bucket without causing problems. However, we \\nmust make provisions for the case where a bucket is filled to capacity and a new \\nrecord being inserted hashes to that bucket. We can use a variation of chaining in \\nwhich a pointer is maintained in each bucket to a linked list of overflow records for \\nthe bucket, as shown in Figure 16.10. The pointers in the linked list should be \\nrecord pointers, which include both a block address and a relative record position \\nwithin the block.\\nHashing provides the fastest possible access for retrieving an arbitrary record given \\nthe value of its hash field. Although most good hash functions do not maintain'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 589, 'page_label': '590'}, page_content='576 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\n0\\n1\\n2\\nM – 2\\nM – 1\\nBucket \\nNumber Block address on disk\\nFigure 16.9 \\nMatching bucket numbers to disk \\nblock addresses.\\nBucket 0\\nMain buckets\\nOverflow buckets\\n340\\n460\\nRecord pointer\\nNULL\\nNULL\\nNULL\\nBucket 1 321\\n761\\n91\\nRecord pointer\\n981\\n182\\nRecord pointer\\n(Pointers are to records within the overflow blocks)\\nRecord pointer\\nRecord pointer\\n652 Record pointer\\nRecord pointer\\nRecord pointer\\nBucket 2 22\\n72\\n522\\nRecord pointer\\nBucket 9 399\\n89\\nRecord pointer\\nNULL\\n...\\nFigure 16.10 \\nHandling overflow for buckets \\nby chaining.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 590, 'page_label': '591'}, page_content='16.8 Hashing Techniques  577\\nrecords in order of hash field values, some functions—called order preserving —\\ndo. A simple example of an order-preserving hash function is to take the leftmost \\nthree digits of an invoice number field that yields a bucket address as the hash \\naddress and keep the records sorted by invoice number within each bucket. Another \\nexample is to use an integer hash key directly as an index to a relative file, if the hash \\nkey values fill up a particular interval; for example, if employee numbers in a com-\\npany are assigned as 1, 2, 3, … up to the total number of employees, we can use the \\nidentity hash function (i.e., Relative Address = Key) that maintains order. Unfortu-\\nnately, this only works if sequence keys are generated in order by some application.\\nThe hashing scheme described so far is called static hashing because a fixed num-\\nber of buckets M is allocated. The function does key-to-address mapping, whereby \\nwe are fixing the address space. This can be a serious drawback for dynamic files. \\nSuppose that we allocate M buckets for the address space and let m be the maxi-\\nmum number of records that can fit in one bucket; then at most ( m * M) records \\nwill fit in the allocated space. If the number of records turns out to be substantially \\nfewer than (m * M), we are left with a lot of unused space. On the other hand, if the \\nnumber of records increases to substantially more than ( m * M), numerous colli-\\nsions will result and retrieval will be slowed down because of the long lists of over-\\nflow records. In either case, we may have to change the number of blocks M \\nallocated and then use a new hashing function (based on the new value of M) to \\nredistribute the records. These reorganizations can be quite time-consuming for \\nlarge files. Newer dynamic file organizations based on hashing allow the number of \\nbuckets to vary dynamically with only localized reorganization (see Section 16.8.3).\\nWhen using external hashing, searching for a record given a value of some field \\nother than the hash field is as expensive as in the case of an unordered file. Record \\ndeletion can be implemented by removing the record from its bucket. If the bucket \\nhas an overflow chain, we can move one of the overflow records into the bucket to \\nreplace the deleted record. If the record to be deleted is already in overflow, we sim-\\nply remove it from the linked list. Notice that removing an overflow record implies \\nthat we should keep track of empty positions in overflow. This is done easily by \\nmaintaining a linked list of unused overflow locations.\\nModifying a specific record’s field value depends on two factors: the search condi-\\ntion to locate that specific record and the field to be modified. If the search condi-\\ntion is an equality comparison on the hash field, we can locate the record efficiently \\nby using the hashing function; otherwise, we must do a linear search. A nonhash \\nfield can be modified by changing the record and rewriting it in the same bucket. \\nModifying the hash field means that the record can move to another bucket, which \\nrequires deletion of the old record followed by insertion of the modified record.\\n16.8.3 Hashing Techniques That Allow Dynamic File Expansion\\nA major drawback of the static hashing scheme just discussed is that the hash \\naddress space is fixed. Hence, it is difficult to expand or shrink the file dynamically. \\nThe schemes described in this section attempt to remedy this situation. The first'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 591, 'page_label': '592'}, page_content='578 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nscheme—extendible hashing—stores an access structure in addition to the file, and \\nhence is somewhat similar to indexing (see Chapter 17). The main difference is that \\nthe access structure is based on the values that result after application of the hash \\nfunction to the search field. In indexing, the access structure is based on the values \\nof the search field itself. The second technique, called linear hashing, does not \\nrequire additional access structures. Another scheme, called dynamic hashing, uses \\nan access structure based on binary tree data structures.\\nThese hashing schemes take advantage of the fact that the result of applying a hash-\\ning function is a nonnegative integer and hence can be represented as a binary \\nnumber. The access structure is built on the binary representation of the hashing \\nfunction result, which is a string of bits. We call this the hash value of a record. \\nRecords are distributed among buckets based on the values of the leading bits  in \\ntheir hash values.\\nExtendible Hashing. In extendible hashing, proposed by Fagin (1979), a type of \\ndirectory—an array of 2\\nd bucket addresses—is maintained, where d is called the \\nglobal depth of the directory. The integer value corresponding to the first (high-\\norder) d bits of a hash value is used as an index to the array to determine a directory \\nentry, and the address in that entry determines the bucket in which the correspond-\\ning records are stored. However, there does not have to be a distinct bucket for each \\nof the 2d directory locations. Several directory locations with the same first d′ bits \\nfor their hash values may contain the same bucket address if all the records that \\nhash to these locations fit in a single bucket. A local depth  d′—stored with each \\nbucket—specifies the number of bits on which the bucket contents are based. Fig-\\nure 16.11 shows a directory with global depth d = 3.\\nThe value of d can be increased or decreased by one at a time, thus doubling or \\nhalving the number of entries in the directory array. Doubling is needed if a bucket, \\nwhose local depth d′ is equal to the global depth d, overflows. Halving occurs if \\nd > d′ for all the buckets after some deletions occur. Most record retrievals require \\ntwo block accesses—one to the directory and the other to the bucket.\\nTo illustrate bucket splitting, suppose that a new inserted record causes overflow in \\nthe bucket whose hash values start with 01—the third bucket in Figure 16.11. The \\nrecords will be distributed between two buckets: the first contains all records whose \\nhash values start with 010, and the second all those whose hash values start with\\xa0011. \\nNow the two directory locations for 010 and 011 point to the two new distinct \\nbuckets. Before the split, they pointed to the same bucket. The local depth d′ of the \\ntwo new buckets is 3, which is one more than the local depth of the old bucket.\\nIf a bucket that overflows and is split used to have a local depth d′ equal to the \\nglobal depth d of the directory, then the size of the directory must now be doubled \\nso that we can use an extra bit to distinguish the two new buckets. For example, if \\nthe bucket for records whose hash values start with 111 in Figure 16.11 overflows, \\nthe two new buckets need a directory with global depth d = 4, because the two \\nbuckets are now labeled 1110 and 1111, and hence their local depths are both 4. \\nThe directory size is hence doubled, and each of the other original locations in the'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 592, 'page_label': '593'}, page_content='16.8 Hashing Techniques  579\\ndirectory is also split into two locations, both of which have the same pointer value \\nas did the original location.\\nThe main advantage of extendible hashing that makes it attractive is that the perfor-\\nmance of the file does not degrade as the file grows , as opposed to static external \\nhashing, where collisions increase and the corresponding chaining effectively \\nincreases the average number of accesses per key. Additionally, no space is allocated \\nin extendible hashing for future growth, but additional buckets can be allocated \\nGlobal depth\\nd = 3\\n000\\n001\\n010\\n011\\n100\\n101\\n110\\n111\\nd\\n´ = 3 Bucket for records \\nwhose hash values \\nstart with 000\\nDirectory Data file buckets\\nLocal depth of\\neach bucket\\nd´ = 3 Bucket for records \\nwhose hash values \\nstart with 001\\nd´ = 2 Bucket for records \\nwhose hash values \\nstart with 01\\nd´ = 2 Bucket for records \\nwhose hash values \\nstart with 10\\nd´ = 3 Bucket for records \\nwhose hash values \\nstart with 110\\nd´ = 3 Bucket for records \\nwhose hash values \\nstart with 111Figure 16.11 \\nStructure of the \\nextendible hashing \\nscheme.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 593, 'page_label': '594'}, page_content='580 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\ndynamically as needed. The space overhead for the directory table is negligible. The \\nmaximum directory size is 2 k, where k is the number of bits in the hash value. \\nAnother advantage is that splitting causes minor reorganization in most cases, since \\nonly the records in one bucket are redistributed to the two new buckets. The only \\ntime reorganization is more expensive is when the directory has to be doubled (or \\nhalved). A disadvantage is that the directory must be searched before accessing the \\nbuckets themselves, resulting in two block accesses instead of one in static hashing. \\nThis performance penalty is considered minor and thus the scheme is considered \\nquite desirable for dynamic files.\\nDynamic Hashing. A precursor to extendible hashing was dynamic hashing pro-\\nposed by Larson (1978), in which the addresses of the buckets were either the n \\nhigh-order bits or n − 1 high-order bits, depending on the total number of keys \\nbelonging to the respective bucket. The eventual storage of records in buckets for \\ndynamic hashing is somewhat similar to extendible hashing. The major difference \\nis in the organization of the directory. Whereas extendible hashing uses the notion \\nof global depth (high-order d bits) for the flat directory and then combines adjacent \\ncollapsible buckets into a bucket of local depth d − 1, dynamic hashing maintains a \\ntree-structured directory with two types of nodes:\\n ■ Internal nodes that have two pointers—the left pointer corresponding to the \\n0 bit (in the hashed address) and a right pointer corresponding to the 1 bit.\\n ■ Leaf nodes—these hold a pointer to the actual bucket with records.\\nAn example of the dynamic hashing appears in Figure 16.12. Four buckets are \\nshown (“000”, “001”, “110”, and “111”) with high-order 3-bit addresses (corre-\\nsponding to the global depth of 3), and two buckets (“01” and “10”) are shown \\nwith high-order 2-bit addresses (corresponding to the local depth of 2). The latter \\ntwo are the result of collapsing the “010” and “011” into “01” and collapsing “100” \\nand “101” into “10”. Note that the directory nodes are used implicitly to deter-\\nmine the “global” and “local” depths of buckets in dynamic hashing. The search \\nfor a record given the hashed address involves traversing the directory tree, which \\nleads to the bucket holding that record. It is left to the reader to develop algo-\\nrithms for insertion, deletion, and searching of records for the dynamic hashing \\nscheme.\\nLinear Hashing. The idea behind linear hashing, proposed by Litwin (1980), is to \\nallow a hash file to expand and shrink its number of buckets dynamically without \\nneeding a directory. Suppose that the file starts with M buckets numbered 0, 1, … , \\nM − 1 and uses the mod hash function h(K) = K mod M; this hash function is called \\nthe initial hash function h\\ni. Overflow because of collisions is still needed and can \\nbe handled by maintaining individual overflow chains for each bucket. However, \\nwhen a collision leads to an overflow record in any file bucket, the first bucket in the \\nfile—bucket 0—is split into two buckets: the original bucket 0 and a new bucket M \\nat the end of the file. The records originally in bucket 0 are distributed between the \\ntwo buckets based on a different hashing function hi+1(K) = K mod 2M. A key prop-\\nerty of the two hash functions hi and hi+1 is that any records that hashed to bucket 0'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 594, 'page_label': '595'}, page_content='16.8 Hashing Techniques  581\\nbased on hi will hash to either bucket 0 or bucket M based on hi+1; this is necessary \\nfor linear hashing to work.\\nAs further collisions lead to overflow records, additional buckets are split in the \\nlinear order 1, 2, 3, … . If enough overflows occur, all the original file buckets 0, 1, \\n… , M − 1 will have been split, so the file now has 2M instead of M buckets, and all \\nbuckets use the hash function hi+1. Hence, the records in overflow are eventually \\nredistributed into regular buckets, using the function hi+1 via a delayed split of their \\nbuckets. There is no directory; only a value n—which is initially set to 0 and is \\nincremented by 1 whenever a split occurs—is needed to determine which buckets \\nhave been split. To retrieve a record with hash key value K, first apply the function \\nh\\ni to K; if hi(K) < n, then apply the function hi+1 on K because the bucket is already \\nsplit. Initially, n = 0, indicating that the function hi applies to all buckets; n grows \\nlinearly as buckets are split.\\nData File Buckets\\nBucket for records\\nwhose hash values\\nstart with 000\\nBucket for records\\nwhose hash values\\nstart with 001\\nBucket for records\\nwhose hash values\\nstart with 01\\nBucket for records\\nwhose hash values\\nstart with 10\\nBucket for records\\nwhose hash values\\nstart with 110\\nBucket for records\\nwhose hash values\\nstart with 111\\nDirectory\\n0\\n1\\n0\\n1\\n0\\n1\\n0\\n1\\n0\\n1\\ninternal directory node\\nleaf directory node\\nFigure 16.12 \\nStructure of the dynamic hashing scheme.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 595, 'page_label': '596'}, page_content='582 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nWhen n = M after being incremented, this signifies that all the original buckets have \\nbeen split and the hash function hi+1 applies to all records in the file. At this point, \\nn is reset to 0 (zero), and any new collisions that cause overflow lead to the use of a \\nnew hashing function hi+2(K) = K mod 4M. In general, a sequence of hashing func-\\ntions hi+j(K) = K mod (2jM) is used, where j = 0, 1, 2, … ; a new hashing function \\nhi+j+1 is needed whenever all the buckets 0, 1, …, (2jM) − 1 have been split and n is \\nreset to 0. The search for a record with hash key value K is given by Algorithm 16.3.\\nSplitting can be controlled by monitoring the file load factor instead of by splitting \\nwhenever an overflow occurs. In general, the file load factor  l can be defined as \\nl = r/(bfr * N), where r is the current number of file records, bfr is the maximum \\nnumber of records that can fit in a bucket, and N is the current number of file buck-\\nets. Buckets that have been split can also be recombined if the load factor of the file \\nfalls below a certain threshold. Blocks are combined linearly, and N is decremented \\nappropriately. The file load can be used to trigger both splits and combinations; in \\nthis manner the file load can be kept within a desired range. Splits can be triggered \\nwhen the load exceeds a certain threshold—say, 0.9—and combinations can be trig-\\ngered when the load falls below another threshold—say, 0.7. The main advantages \\nof linear hashing are that it maintains the load factor fairly constantly while the file \\ngrows and shrinks, and it does not require a directory.\\n15\\nAlgorithm 16.3. The Search Procedure for Linear Hashing\\nif n = 0\\n then m ← hj (K) (*m is the hash value of record with hash key K*)\\n else begin\\n  m ← hj (K);\\n  if m < n then m ← hj+1 (K)\\n  end;\\nsearch the bucket whose hash value is m (and its overflow, if any);\\n16.9 Other Primary File Organizations\\n16.9.1 Files of Mixed Records\\nThe file organizations we have studied so far assume that all records of a particular \\nfile are of the same record type. The records could be of EMPLOYEEs, PROJECTs, \\nSTUDENTs, or DEPARTMENTs, but each file contains records of only one type. In \\nmost database applications, we encounter situations in which numerous types of \\nentities are interrelated in various ways, as we saw in Chapter 7. Relationships among \\nrecords in various files can be represented by connecting fields.\\n16 For example, a \\n15For details of insertion and deletion into Linear hashed files, refer to Litwin (1980) and Salzberg (1988).\\n16The concept of foreign keys in the relational data model (Chapter 3) and references among objects in \\nobject-oriented models (Chapter 11) are examples of connecting fields.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 596, 'page_label': '597'}, page_content='16.9 Other Primary File Organizations  583\\nSTUDENT record can have a connecting field Major_dept whose value gives the name \\nof the DEPARTMENT in which the student is majoring. This Major_dept field refers to \\na DEPARTMENT entity, which should be represented by a record of its own in the \\nDEPARTMENT file. If we want to retrieve field values from two related records, we \\nmust retrieve one of the records first. Then we can use its connecting field value to \\nretrieve the related record in the other file. Hence, relationships are implemented by \\nlogical field references among the records in distinct files.\\nFile organizations in object DBMSs, as well as legacy systems such as hierarchical \\nand network DBMSs, often implement relationships among records as physical \\nrelationships realized by physical contiguity (or clustering) of related records or by \\nphysical pointers. These file organizations typically assign an area of the disk to \\nhold records of more than one type so that records of different types can be \\n physically clustered  on disk. If a particular relationship is expected to be used \\n frequently, implementing the relationship physically can increase the system’s \\n efficiency at retrieving related records. For example, if the query to retrieve a \\nDEPARTMENT record and all records for STUDENTs majoring in that department is \\nfrequent, it would be desirable to place each DEPARTMENT record and its cluster of \\nSTUDENT records contiguously on disk in a mixed file. The concept of physical \\nclustering of object types is used in object DBMSs to store related objects together \\nin a mixed file. In data warehouses (see Chapter 29), the input data comes from a \\nvariety of sources and undergoes an integration initially to collect the required data \\ninto an operational data store (ODS) . An ODS typically contains files where \\nrecords of multiple types are kept together. It is passed on to a data warehouse after \\nETL (extract, transform and load) processing operations are performed on it.\\nTo distinguish the records in a mixed file, each record has—in addition to its field \\nvalues—a record type field, which specifies the type of record. This is typically the \\nfirst field in each record and is used by the system software to determine the type of \\nrecord it is about to process. Using the catalog information, the DBMS can deter-\\nmine the fields of that record type and their sizes, in order to interpret the data \\nvalues in the record.\\n16.9.2  B-Trees and Other Data Structures  \\nas Primary Organization\\nOther data structures can be used for primary file organizations. For example, if \\nboth the record size and the number of records in a file are small, some DBMSs \\noffer the option of a B-tree data structure as the primary file organization. We \\nwill describe B-trees in Section 17.3.1, when we discuss the use of the B-tree data \\nstructure for indexing. In general, any data structure that can be adapted to the \\ncharacteristics of disk devices can be used as a primary file organization for \\nrecord placement on disk. Recently, column-based storage of data has been pro-\\nposed as a primary method for storage of relations in relational databases. We \\nwill briefly introduce it in Chapter 17 as a possible alternative storage scheme for \\nrelational databases.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 597, 'page_label': '598'}, page_content='584 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\n16.10  Parallelizing Disk Access Using  \\nRAID Technology\\nWith the exponential growth in the performance and capacity of semiconductor \\ndevices and memories, faster microprocessors with larger and larger primary mem-\\nories are continually becoming available. To match this growth, it is natural to \\nexpect that secondary storage technology must also take steps to keep up with pro-\\ncessor technology in performance and reliability.\\nA major advance in secondary storage technology is represented by the develop-\\nment of RAID, which originally stood for redundant arrays of inexpensive disks. \\nMore recently, the I in RAID is said to stand for independent . The RAID idea \\nreceived a very positive industry endorsement and has been developed into an elab-\\norate set of alternative RAID architectures (RAID levels 0 through 6). We highlight \\nthe main features of the technology in this section.\\nThe main goal of RAID is to even out the widely different rates of performance \\nimprovement of disks against those in memory and microprocessors.\\n17 Although \\nRAM capacities have quadrupled every two to three years, disk access times  are \\nimproving at less than 10% per year, and disk transfer rates are improving at roughly \\n20% per year. Disk capacities are indeed improving at more than 50% per year, but \\nthe speed and access time improvements are of a much smaller magnitude.\\nA second qualitative disparity exists between the ability of special microprocessors \\nthat cater to new applications involving video, audio, image, and spatial data pro-\\ncessing (see Chapters 26 for details of these applications), with corresponding lack \\nof fast access to large, shared data sets.\\nThe natural solution is a large array of small independent disks acting as a single \\nhigher performance logical disk. A concept called data striping is used, which utilizes \\nparallelism to improve disk performance. Data striping distributes data transpar-\\nently over multiple disks to make them appear as a single large, fast disk. Figure \\n16.13 shows a file distributed or striped over four disks. In bit-level striping, a byte is \\nsplit and individual bits are stored on independent disks. Figure 16.13(a) illustrates \\nbit-striping across four disks where the bits (0, 4) are assigned to disk 0, bits (1, 5) to \\ndisk 1, and so on. With this striping, every disk participates in every read or write \\noperation; the number of accesses per second would remain the same as on a single \\ndisk, but the amount of data read in a given time would increase fourfold. Thus, \\nstriping improves overall I/O performance by providing high overall transfer rates. \\nBlock-level striping stripes blocks across disks. It treats the array of disks as if it is \\none disk. Blocks are logically numbered from 0 in sequence. Disks in an m-disk array \\nare numbered 0 to m – 1. With striping, block j goes to disk (j mod m). Figure \\n16.13(b) illustrates block striping with four disks (m = 4). Data striping also accom-\\nplishes load balancing among disks. Moreover, by storing redundant information on \\n17This was predicted by Gordon Bell to be about 40% every year between 1974 and 1984 and is now \\nsupposed to exceed 50% per year.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 598, 'page_label': '599'}, page_content='16.10 Parallelizing Disk Access Using RAID Technology  585\\ndisks using parity or some other error-correction code, reliability can be improved. \\nIn Sections 16.10.1 and 16.10.2, we discuss how RAID achieves the two important \\nobjectives of improved reliability and higher performance. Section 16.10.3 discusses \\nRAID organizations and levels.\\n16.10.1 Improving Reliability with RAID\\nFor an array of n disks, the likelihood of failure is n times as much as that for one \\ndisk. Hence, if the MTBF (mean time between failures) of a disk drive is assumed to \\nbe 200,000 hours or about 22.8 years (for the disk drive in Table 16.1 called Seagate \\nEnterprise Performance 10K HDD, it is 1.4 million hours), the MTBF for a bank of \\n100 disk drives becomes only 2,000 hours or 83.3 days (for a bank of 1,000 Seagate \\nEnterprise Performance 10K HDD disks it would be 1,400 hours or 58.33 days). \\nKeeping a single copy of data in such an array of disks will cause a significant loss of \\nreliability. An obvious solution is to employ redundancy of data so that disk failures \\ncan be tolerated. The disadvantages are many: additional I/O operations for write, \\nextra computation to maintain redundancy and to do recovery from errors, and \\nadditional disk capacity to store redundant information.\\nOne technique for introducing redundancy is called mirroring  or shadowing . \\nData is written redundantly to two identical physical disks that are treated as one \\nlogical disk. When data is read, it can be retrieved from the disk with shorter \\nqueuing, seek, and rotational delays. If a disk fails, the other disk is used until the \\nfirst is repaired. Suppose the mean time to repair is 24 hours; then the mean time \\nto data loss of a mirrored disk system using 100 disks with MTBF of 200,000 \\nhours each is (200,000)\\n2/(2 * 24) = 8.33 * 10 8 hours, which is 95,028 years. 18 Disk \\nmirroring also doubles the rate at which read requests are handled, since a read \\ncan go to either disk. The transfer rate of each read, however, remains the same as \\nthat for a single disk.\\n(a) Disk 0\\nA0 | A4\\nB0 | B4\\nDisk 1\\nA1 | A5\\nB1 | B5\\nDisk 2\\nA2 | A6\\nB2 | B6\\nDisk 3\\nA3 | A7\\nB3 | B7\\nDisk 0\\nA1\\nDisk 1\\nA2\\nDisk 2\\nA3\\nDisk 3\\nA4\\nA0 | A1 | A2 | A3 | A4 | A5 | A6 | A7\\nB0 | B1 | B2 | B3 | B4 | B5 | B6 | B7\\nData\\nBlock A1\\nFile A:\\n(b)\\nBlock A2 Block A3 Block A4\\nFigure 16.13 \\nStriping of data \\nacross multiple disks. \\n(a) Bit-level striping \\nacross four disks.  \\n(b) Block-level striping \\nacross four disks.\\n18The formulas for MTBF calculations appear in Chen et al. (1994).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 599, 'page_label': '600'}, page_content='586 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nAnother solution to the problem of reliability is to store extra information that is not \\nnormally needed but that can be used to reconstruct the lost information in case of \\ndisk failure. The incorporation of redundancy must consider two problems: select-\\ning a technique for computing the redundant information, and selecting a method of \\ndistributing the redundant information across the disk array. The first problem is \\naddressed by using error-correcting codes involving parity bits, or specialized codes \\nsuch as Hamming codes. Under the parity scheme, a redundant disk may be consid-\\nered as having the sum of all the data in the other disks. When a disk fails, the miss-\\ning information can be constructed by a process similar to subtraction.\\nFor the second problem, the two major approaches are either to store the redun-\\ndant information on a small number of disks or to distribute it uniformly across all \\ndisks. The latter results in better load balancing. The different levels of RAID choose \\na combination of these options to implement redundancy and improve reliability.\\n16.10.2 Improving Performance with RAID\\nThe disk arrays employ the technique of data striping to achieve higher transfer \\nrates. Note that data can be read or written only one block at a time, so a typical \\ntransfer contains 512 to 8,192 bytes. Disk striping may be applied at a finer granu-\\nlarity by breaking up a byte of data into bits and spreading the bits to different \\ndisks. Thus, bit-level data striping  consists of splitting a byte of data and writing \\nbit j to the jth disk. With 8-bit bytes, eight physical disks may be considered as one \\nlogical disk with an eightfold increase in the data transfer rate. Each disk partici-\\npates in each I/O request and the total amount of data read per request is eight \\ntimes as much. Bit-level striping can be generalized to a number of disks that is \\neither a multiple or a factor of eight. Thus, in a four-disk array, bit n goes to the disk \\nwhich is (n mod 4). Figure 16.13(a) shows bit-level striping of data.\\nThe granularity of data interleaving can be higher than a bit; for example, blocks of \\na file can be striped across disks, giving rise to block-level striping. Figure 16.13(b) \\nshows block-level data striping assuming the data file contains four blocks. With \\nblock-level striping, multiple independent requests that access single blocks (small \\nrequests) can be serviced in parallel by separate disks, thus decreasing the queuing \\ntime of I/O requests. Requests that access multiple blocks (large requests) can be \\nparallelized, thus reducing their response time. In general, the more the number of \\ndisks in an array, the larger the potential performance benefit. However, assuming \\nindependent failures, the disk array of 100 disks collectively has 1/100th the reli-\\nability of a single disk. Thus, redundancy via error-correcting codes and disk mir-\\nroring is necessary to provide reliability along with high performance.\\n16.10.3 RAID Organizations and Levels\\nDifferent RAID organizations were defined based on different combinations of the \\ntwo factors of granularity of data interleaving (striping) and pattern used to com-\\npute redundant information. In the initial proposal, levels 1 through 5 of RAID \\nwere proposed, and two additional levels—0 and 6—were added later.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 600, 'page_label': '601'}, page_content='16.10 Parallelizing Disk Access Using RAID Technology  587\\nRAID level 0 uses data striping, has no redundant data, and hence has the best write \\nperformance since updates do not have to be duplicated. It splits data evenly across \\ntwo or more disks. However, its read performance is not as good as RAID level 1, \\nwhich uses mirrored disks. In the latter, performance improvement is possible by \\nscheduling a read request to the disk with shortest expected seek and rotational \\ndelay. RAID level 2 uses memory-style redundancy by using Hamming codes, \\nwhich contain parity bits for distinct overlapping subsets of components. Thus, in \\none particular version of this level, three redundant disks suffice for four original \\ndisks, whereas with mirroring—as in level 1—four would be required. Level 2 \\nincludes both error detection and correction, although detection is generally not \\nrequired because broken disks identify themselves.\\nRAID level 3 uses a single parity disk relying on the disk controller to figure out \\nwhich disk has failed. Levels 4 and 5 use block-level data striping, with level 5 dis-\\ntributing data and parity information across all disks. Figure 16.14(b) shows an \\nillustration of RAID level 5, where parity is shown with subscript p. If one disk fails, \\nthe missing data is calculated based on the parity available from the remaining \\ndisks. Finally, RAID level 6 applies the so-called P + Q redundancy scheme using \\nReed-Soloman codes to protect against up to two disk failures by using just two \\nredundant disks.\\nRebuilding in case of disk failure is easiest for RAID level 1. Other levels require \\nthe reconstruction of a failed disk by reading multiple disks. Level 1 is used for \\ncritical applications such as storing logs of transactions. Levels 3 and 5 are pre-\\nferred for large volume storage, with level 3 providing higher transfer rates. Most \\npopular use of RAID technology currently uses level 0 (with striping), level 1 (with \\nmirroring), and level 5 with an extra drive for parity. A combination of multiple \\nRAID levels are also used—for example, 0 + 1 combines striping and mirroring \\nDisk 0 Disk 1\\nA1\\nB1\\nC1\\nDp\\nA2\\nB2\\nCp\\nD1\\nA3\\nBp\\nC2\\nD2\\nAp\\nB3\\nC3\\nD3\\n(a)\\n(b)\\nFile A\\nFile B\\nFile C\\nFile D\\nFile A\\nFile B\\nFile C\\nFile D\\nFigure 16.14 \\nSome popular levels of RAID. \\n(a) RAID level 1: Mirroring of \\ndata on two disks. (b) RAID \\nlevel 5: Striping of data with \\ndistributed parity across four \\ndisks.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 601, 'page_label': '602'}, page_content='588 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nusing a  minimum of four disks. Other nonstandard RAID levels include: RAID 1.5, \\nRAID 7, RAID-DP, RAID S or Parity RAID, Matrix RAID, RAID-K, RAID-Z, \\nRAIDn, Linux MD RAID 10, IBM ServeRAID 1E, and unRAID. A discussion of \\nthese nonstandard levels is beyond the scope of this text. Designers of a RAID setup \\nfor a given application mix have to confront many design decisions such as the level \\nof RAID, the number of disks, the choice of parity schemes, and grouping of disks \\nfor block-level striping. Detailed performance studies on small reads and writes \\n(referring to I/O requests for one striping unit) and large reads and writes (referring \\nto I/O requests for one stripe unit from each disk in an error-correction group) have \\nbeen performed.\\n16.11 Modern Storage Architectures\\nIn this section, we describe some recent developments in storage systems that are \\nbecoming an integral part of most enterprise’s information system architectures. \\nWe already mentioned the SATA and SAS interface, which has almost replaced the \\npreviously popular SCSI (small computer system interface) in laptops and small \\nservers. The Fibre Channel (FC) interface is the predominant choice for storage \\nnetworks in data centers. We review some of the modern storage architectures next.\\n16.11.1 Storage Area Networks\\nWith the rapid growth of electronic commerce, enterprise resource planning (ERP) \\nsystems that integrate application data across organizations, and data warehouses \\nthat keep historical aggregate information (see Chapter 29), the demand for storage \\nhas gone up substantially. For today’s Internet-driven organizations, it has become \\nnecessary to move from a static fixed data center-oriented operation to a more flex-\\nible and dynamic infrastructure for the organizations’ information processing \\nrequirements. The total cost of managing all data is growing so rapidly that in many \\ninstances the cost of managing server-attached storage exceeds the cost of the server \\nitself. Furthermore, the procurement cost of storage is only a small fraction—typi-\\ncally, only 10 to 15% of the overall cost of storage management. Many users of \\nRAID systems cannot use the capacity effectively because it has to be attached in a \\nfixed manner to one or more servers. Therefore, most large organizations have \\nmoved to a concept called storage area networks (SANs). In a SAN, online storage \\nperipherals are configured as nodes on a high-speed network and can be attached \\nand detached from servers in a very flexible manner.\\nSeveral companies have emerged as SAN providers and supply their own proprie-\\ntary topologies. They allow storage systems to be placed at longer distances from \\nthe servers and provide different performance and connectivity options. Existing \\nstorage management applications can be ported into SAN configurations using \\nFibre Channel networks that encapsulate the legacy SCSI protocol. As a result, the \\nSAN-attached devices appear as SCSI devices.\\nCurrent architectural alternatives for SAN include the following: point-to-point \\nconnections between servers and storage systems via Fiber Channel; use of a Fiber'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 602, 'page_label': '603'}, page_content='16.11 Modern Storage Architectures  589\\nChannel switch to connect multiple RAID systems, tape libraries, and so on to serv-\\ners; and the use of Fiber Channel hubs and switches to connect servers and storage \\nsystems in different configurations. Organizations can slowly move up from sim-\\npler topologies to more complex ones by adding servers and storage devices as \\nneeded. We do not provide further details here because they vary among SAN ven-\\ndors. The main advantages claimed include:\\n ■ Flexible many-to-many connectivity among servers and storage devices \\nusing Fiber Channel hubs and switches\\n ■ Up to 10 km separation between a server and a storage system using appro-\\npriate fiber optic cables\\n ■ Better isolation capabilities allowing nondisruptive addition of new periph-\\nerals and servers\\n ■ High-speed data replication across multiple storage systems. Typical tech-\\nnologies use synchronous replication for local and asynchronous replication \\nfor disaster recovery (DR) solutions.\\nSANs are growing very rapidly but are still faced with many problems, such as com-\\nbining storage options from multiple vendors and dealing with evolving standards \\nof storage management software and hardware. Most major companies are evaluat-\\ning SANs as a viable option for database storage.\\n16.11.2 Network-Attached Storage\\nWith the phenomenal growth in digital data, particularly generated from multi-\\nmedia and other enterprise applications, the need for high-performance storage \\nsolutions at low cost has become extremely important. Network-attached storage \\n(NAS) devices are among the storage devices being used for this purpose. These \\ndevices are, in fact, servers that do not provide any of the common server services, \\nbut simply allow the addition of storage for file sharing. NAS devices allow vast \\namounts of hard-disk storage space to be added to a network and can make that \\nspace available to multiple servers without shutting them down for maintenance \\nand upgrades. NAS devices can reside anywhere on a local area network (LAN) and \\nmay be combined in different configurations. A single hardware device, often called \\nthe NAS box or NAS head, acts as the interface between the NAS system and net-\\nwork clients. These NAS devices require no monitor, keyboard, or mouse. One or \\nmore disk or tape drives can be attached to many NAS systems to increase total \\ncapacity. Clients connect to the NAS head rather than to the individual storage \\ndevices. A NAS can store any data that appears in the form of files, such as e-mail \\nboxes, Web content, remote system backups, and so on. In that sense, NAS devices \\nare being deployed as a replacement for traditional file servers.\\nNAS systems strive for reliable operation and easy administration. They include \\nbuilt-in features such as secure authentication, or the automatic sending of e-mail \\nalerts in case of error on the device. The NAS devices (or appliances, as some ven-\\ndors refer to them) are being offered with a high degree of scalability, reliability,'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 603, 'page_label': '604'}, page_content='590 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nflexibility, and performance. Such devices typically support RAID levels 0, 1, and 5. \\nTraditional storage area networks (SANs) differ from NAS in several ways. Specifi-\\ncally, SANs often utilize Fibre Channel rather than Ethernet, and a SAN often \\nincorporates multiple network devices or endpoints on a self-contained or private \\nLAN, whereas NAS relies on individual devices connected directly to the existing \\npublic LAN. Whereas Windows, UNIX, and NetWare file servers each demand \\nspecific protocol support on the client side, NAS systems claim greater operating \\nsystem independence of clients. In summary, NAS provides a file system interface \\nwith support for networked files using protocols such as common internet file sys-\\ntem (CIFS) or network file system (NFS).\\n16.11.3 iSCSI and Other Network-Based Storage Protocols\\nA new protocol called iSCSI (Internet SCSI) has been proposed recently. It is a \\nblock-storage protocol like SAN. It allows clients (called initiators) to send SCSI \\ncommands to SCSI storage devices on remote channels. The main advantage of \\niSCSI is that it does not require the special cabling needed by Fibre Channel and it \\ncan run over longer distances using existing network infrastructure. By carrying \\nSCSI commands over IP networks, iSCSI facilitates data transfers over intranets \\nand manages storage over long distances. It can transfer data over local area net-\\nworks (LANs), wide area networks (WANs), or the Internet.\\niSCSI works as follows. When a DBMS needs to access data, the operating system \\ngenerates the appropriate SCSI commands and data request, which then go through \\nencapsulation and, if necessary, encryption procedures. A packet header is added \\nbefore the resulting IP packets are transmitted over an Ethernet connection. When \\na packet is received, it is decrypted (if it was encrypted before transmission) and \\ndisassembled, separating the SCSI commands and request. The SCSI commands go \\nvia the SCSI controller to the SCSI storage device. Because iSCSI is bidirectional, \\nthe protocol can also be used to return data in response to the original request. \\nCisco and IBM have marketed switches and routers based on this technology.\\n iSCSI storage has mainly impacted small- and medium-sized businesses because \\nof its combination of simplicity, low cost, and the functionality of iSCSI devices. It \\nallows them not to learn the ins and outs of Fibre Channel (FC) technology and \\ninstead benefit from their familiarity with the IP protocol and Ethernet hardware. \\niSCSI implementations in the data centers of very large enterprise businesses are \\nslow in development due to their prior investment in Fibre Channel–based SANs.\\niSCSI is one of two main approaches to storage data transmission over IP networks. \\nThe other method, Fibre Channel over IP (FCIP), translates Fibre Channel control \\ncodes and data into IP packets for transmission between geographically distant \\nFibre Channel storage area networks. This protocol, known also as Fibre Channel \\ntunneling or storage tunneling, can only be used in conjunction with Fibre Channel \\ntechnology, whereas iSCSI can run over existing Ethernet networks.\\nThe latest idea to enter the enterprise IP storage race is Fibre Channel over \\n Ethernet (FCoE), which can be thought of as iSCSI without the IP. It uses many'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 604, 'page_label': '605'}, page_content='16.11 Modern Storage Architectures  591\\nelements of SCSI and FC (just like iSCSI), but it does not include TCP/IP compo-\\nnents. FCoE has been successfully productized by CISCO (termed “Data Center \\nEthernet”) and Brocade. It takes advantage of a reliable ethernet technology that \\nuses buffering and end-to-end flow control to avoid dropped packets. This prom-\\nises excellent performance, especially on 10 Gigabit Ethernet (10GbE), and is \\n relatively easy for vendors to add to their products.\\n16.11.4 Automated Storage Tiering\\nAnother trend in storage is automated storage tiering (AST), which automati-\\ncally moves data between different storage types such as SATA, SAS, and solid-\\nstate drives (SSDs) depending on the need. The storage administrator can set up \\na tiering policy in which less frequently used data is moved to slower and cheaper \\nSATA drives and more frequently used data is moved up to solid-state drives \\n(see Table \\xa016.1 for the various tiers of storage ordered by increasing speed of \\naccess). This automated tiering can improve database performance tremendously.\\nEMC has an implementation of this technology called FAST (fully automated stor-\\nage tiering) that does continuous monitoring of data activity and takes actions to \\nmove the data to the appropriate tier based on the policy.\\n16.11.5 Object-Based Storage\\nDuring the last few years, there have been major developments in terms of rapid \\ngrowth of the cloud concept, distributed architectures for databases and for analyt-\\nics, and development of data-intensive applications on the Web (see Chapters 23, \\n24, and 25). These developments have caused fundamental changes in enterprise \\nstorage infrastructure. The hardware-oriented file-based systems are evolving into \\nnew open-ended architectures for storage. The latest among these is object-based \\nstorage. Under this scheme, data is managed in the form of objects rather than files \\nmade of blocks. Objects carry metadata that contains properties that can be used for \\nmanaging those objects. Each object carries a unique global identifier that is used to \\nlocate it. Object storage has its origins in research projects at CMU (Gibson et al., \\n1996) on scaling up of network attached storage and in the Oceanstore system at \\nUC Berkeley (Kubiatowicz et al., 2000), which attempted to build a global infra-\\nstructure over all forms of trusted and untrusted servers for continuous access to \\npersistent data. There is no need to do lower level storage operations in terms of \\ncapacity management or making decisions like what type of RAID architecture \\nshould be used for fault protection.\\nObject storage also allows additional flexibility in terms of interfaces—it gives con-\\ntrol to applications that can control the objects directly and also allows the objects \\nto be addressable across a wide namespace spanning multiple devices. Replication \\nand distribution of objects is also supported. In general, object storage is ideally \\nsuited for scalable storage of massive amounts of unstructured data such as Web \\npages, images, and audio/video clips and files. Object-based storage device com-\\nmands (OSDs) were proposed as part of SCSI protocol a long time ago but did not'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 605, 'page_label': '606'}, page_content='592 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nbecome a commercial product until Seagate adopted OSDs in its Kinetic Open \\nStorage Platform. Currently, Facebook uses an object storage system to store pho-\\ntos at the level of over 350 Petabytes of storage; Spotify uses an object storage sys-\\ntem for storing songs; and Dropbox uses it for its storage infrastructure. Object \\nstorage is the choice of many cloud offerings, such as Amazon’s AWS (Amazon \\nWeb Service) S3, and Microsoft’s Azure, which stores files, relations, messages, and \\nso on as objects. Other examples of products include Hitachi’s HCP, EMC’s Atmos, \\nand Scality’s RING. Openstack Swift is an open source project that allows one to \\nuse HTTP GET and PUT to retrieve and store objects—that’s basically the whole \\nAPI. Openstack Swift uses very cheap hardware, is fully fault resistant, automati-\\ncally takes advantage of geographic redundancy, and scales to very large numbers of \\nobjects. Since object storage forces locking to occur at the object level, it is not \\nclear how suitable it is for concurrent transaction processing in high-throughput \\ntransaction-oriented systems. Therefore, it is still not considered viable for main-\\nstream enterprise-level database applications.\\n16.12  Summary\\nWe began this chapter by discussing the characteristics of memory hierarchies and \\nthen concentrated on secondary storage devices. In particular, we focused on mag-\\nnetic disks because they are still the preferred medium to store online database files. \\nTable 16.1 presented a perspective on the memory hierarchies and their current \\ncapacities, access speeds, transfer rates, and costs.\\nData on disk is stored in blocks; accessing a disk block is expensive because of the \\nseek time, rotational delay, and block transfer time. To reduce the average block \\naccess time, double buffering can be used when accessing consecutive disk blocks. \\n(Other disk parameters are discussed in Appendix B.) We introduced the various \\ninterface technologies in use today for disk drives and optical devices. We presented \\na list of strategies employed to improve access of data from disks. We also intro-\\nduced solid-state drives, which are rapidly becoming popular, and optical drives, \\nwhich are mainly used as tertiary storage. We discussed the working of the buffer \\nmanager, which is responsible for handling data requests and we presented various \\nbuffer replacement policies. We presented different ways of storing file records on \\ndisk. File records are grouped into disk blocks and can be fixed length or variable \\nlength, spanned or unspanned, and of the same record type or mixed types. We dis-\\ncussed the file header, which describes the record formats and keeps track of the disk \\naddresses of the file blocks. Information in the file header is used by system software \\naccessing the file records.\\nThen we presented a set of typical commands for accessing individual file records \\nand discussed the concept of the current record of a file. We discussed how com-\\nplex record search conditions are transformed into simple search conditions that \\nare used to locate records in the file.\\nThree primary file organizations were then discussed: unordered, ordered, and \\nhashed. Unordered files require a linear search to locate records, but record'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 606, 'page_label': '607'}, page_content='Review Questions 593\\ninsertion is very simple. We discussed the deletion problem and the use of dele-\\ntion markers.\\nOrdered files shorten the time required to read records in order of the ordering \\nfield. The time required to search for an arbitrary record, given the value of its \\nordering key field, is also reduced if a binary search is used. However, maintaining \\nthe records in order makes insertion very expensive; thus the technique of using an \\nunordered overflow file to reduce the cost of record insertion was discussed. Over-\\nflow records are merged with the master file periodically, and deleted records are \\nphysically dropped during file reorganization.\\nHashing provides very fast access to an arbitrary record of a file, given the value of \\nits hash key. The most suitable method for external hashing is the bucket technique, \\nwith one or more contiguous blocks corresponding to each bucket. Collisions caus-\\ning bucket overflow are handled by open addressing, chaining, or multiple hashing. \\nAccess on any nonhash field is slow, and so is ordered access of the records on any \\nfield. We discussed three hashing techniques for files that grow and shrink in the \\nnumber of records dynamically: extendible, dynamic, and linear hashing. The first \\ntwo use the higher-order bits of the hash address to organize a directory. Linear \\nhashing is geared to keep the load factor of the file within a given range and adds \\nnew buckets linearly.\\nWe briefly discussed other possibilities for primary file storage and organization, \\nsuch as B-trees, and files of mixed records, which implement relationships among \\nrecords of different types physically as part of the storage structure. We reviewed \\nthe recent advances in disk technology represented by RAID (redundant arrays of \\ninexpensive (or independent) disks), which has become a standard technique in \\nlarge enterprises to provide better reliability and fault tolerance features in storage. \\nFinally, we reviewed some modern trends in enterprise storage systems: storage \\narea networks (SANs), network-attached storage (NAS), iSCSI and other network \\nbased protocols, automatic storage tiering, and finally object-based storage, \\nwhich is playing a major role in storage architecture of data centers offering \\ncloud-based services.\\nReview Questions\\n 16.1. What is the difference between primary and secondary storage?\\n 16.2. Why are disks, not tapes, used to store online database files?\\n 16.3. Define the following terms: disk, disk pack, track, block, cylinder, sector, \\ninterblock gap, and read/write head.\\n 16.4. Discuss the process of disk initialization.\\n 16.5. Discuss the mechanism used to read data from or write data to the disk.\\n 16.6. What are the components of a disk block address?'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 607, 'page_label': '608'}, page_content='594 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\n 16.7. Why is accessing a disk block expensive? Discuss the time components \\ninvolved in accessing a disk block.\\n 16.8. How does double buffering improve block access time?\\n 16.9. What are the reasons for having variable-length records? What types of sep-\\narator characters are needed for each?\\n 16.10. Discuss the techniques for allocating file blocks on disk.\\n 16.11. What is the difference between a file organization and an access method?\\n 16.12. What is the difference between static and dynamic files?\\n 16.13. What are the typical record-at-a-time operations for accessing a file? Which \\nof these depend on the current file record?\\n 16.14. Discuss the techniques for record deletion.\\n 16.15. Discuss the advantages and disadvantages of using (a) an unordered file, \\n(b)\\xa0an ordered file, and (c) a static hash file with buckets and chaining. \\nWhich operations can be performed efficiently on each of these organiza-\\ntions, and which operations are expensive?\\n 16.16. Discuss the techniques for allowing a hash file to expand and shrink dynam-\\nically. What are the advantages and disadvantages of each?\\n 16.17. What is the difference between the directories of extendible and dynamic \\nhashing?\\n 16.18. What are mixed files used for? What are other types of primary file organi-\\nzations?\\n 16.19. Describe the mismatch between processor and disk technologies.\\n 16.20. What are the main goals of the RAID technology? How does it achieve them?\\n 16.21. How does disk mirroring help improve reliability? Give a quantitative \\nexample.\\n 16.22. What characterizes the levels in RAID organization?\\n 16.23. What are the highlights of the popular RAID levels 0, 1, and 5?\\n 16.24. What are storage area networks? What flexibility and advantages do they offer?\\n 16.25. Describe the main features of network-attached storage as an enterprise \\nstorage solution.\\n 16.26. How have new iSCSI systems improved the applicability of storage area  \\nnetworks?\\n 16.27. What are SATA, SAS, and FC protocols?\\n 16.28. What are solid-state drives (SSDs) and what advantage do they offer over \\nHDDs?'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 608, 'page_label': '609'}, page_content='Exercises 595\\n 16.29. What is the function of a buffer manager? What does it do to serve a request \\nfor data?\\n 16.30. What are some of the commonly used buffer replacement strategies?\\n 16.31. What are optical and tape jukeboxes? What are the different types of optical \\nmedia served by optical drives?\\n 16.32. What is automatic storage tiering? Why is it useful?\\n 16.33. What is object-based storage? How is it superior to conventional storage \\nsystems?\\nExercises\\n 16.34. Consider a disk with the following characteristics (these are not parameters \\nof any particular disk unit): block size B = 512 bytes; interblock gap size \\nG\\xa0=\\xa0128 bytes; number of blocks per track = 20; number of tracks per \\n surface = 400. A disk pack consists of 15 double-sided disks.\\na. What is the total capacity of a track, and what is its useful capacity \\n(excluding interblock gaps)?\\nb. How many cylinders are there?\\nc. What are the total capacity and the useful capacity of a cylinder?\\nd. What are the total capacity and the useful capacity of a disk pack?\\ne. Suppose that the disk drive rotates the disk pack at a speed of 2,400 rpm \\n(revolutions per minute); what are the transfer rate (tr) in bytes/msec and \\nthe block transfer time (btt) in msec? What is the average rotational delay \\n(rd) in msec? What is the bulk transfer rate? (See Appendix B.)\\nf. Suppose that the average seek time is 30 msec. How much time does it \\ntake (on the average) in msec to locate and transfer a single block, given \\nits block address?\\ng. Calculate the average time it would take to transfer 20 random blocks, \\nand compare this with the time it would take to transfer 20 consecutive \\nblocks using double buffering to save seek time and rotational delay.\\n 16.35. A file has r = 20,000 STUDENT records of fixed length. Each record has the \\nfollowing fields: Name (30 bytes), Ssn (9 bytes), Address (40 bytes), PHONE \\n(10 bytes), Birth_date  (8 bytes), Sex (1 byte), Major_dept_code  (4 bytes), \\nMinor_dept_code (4 bytes), Class_code (4 bytes, integer), and Degree_program \\n(3 bytes). An additional byte is used as a deletion marker. The file is stored \\non the disk whose parameters are given in Exercise 16.27.\\na. Calculate the record size R in bytes.\\nb. Calculate the blocking factor bfr and the number of file blocks b, assum-\\ning an unspanned organization.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 609, 'page_label': '610'}, page_content='596 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\nc. Calculate the average time it takes to find a record by doing a linear search \\non the file if (i) the file blocks are stored contiguously, and double buffer-\\ning is used; (ii) the file blocks are not stored contiguously.\\nd. Assume that the file is ordered by Ssn; by doing a binary search, calculate \\nthe time it takes to search for a record given its Ssn value.\\n 16.36. Suppose that only 80% of the STUDENT records from Exercise 16.28 have a \\nvalue for Phone, 85% for Major_dept_code, 15% for Minor_dept_code, and 90% \\nfor Degree_program; and suppose that we use a variable-length record file. \\nEach record has a 1-byte field type for each field in the record, plus the 1-byte \\ndeletion marker and a 1-byte end-of-record marker. Suppose that we use a \\nspanned record organization, where each block has a 5-byte pointer to the \\nnext block (this space is not used for record storage).\\na. Calculate the average record length R in bytes.\\nb. Calculate the number of blocks needed for the file.\\n 16.37. Suppose that a disk unit has the following parameters: seek time s = 20 msec; \\nrotational delay rd = 10 msec; block transfer time btt = 1 msec; block size \\nB = 2400 bytes; interblock gap size G = 600 bytes. An EMPLOYEE file has \\nthe following fields: Ssn, 9 bytes; Last_name, 20 bytes; First_name, 20 bytes; \\nMiddle_init, 1 byte; Birth_date, 10 bytes; Address, 35 bytes; Phone, 12 bytes; \\nSupervisor_ssn , 9 bytes; Department , 4 bytes; Job_code , 4 bytes; deletion \\nmarker, 1 byte. The EMPLOYEE file has r = 30,000 records, fixed-length  \\nformat, and unspanned blocking. Write appropriate formulas and calculate \\nthe following values for the above EMPLOYEE file:\\na. Calculate the record size R (including the deletion marker), the blocking \\nfactor bfr, and the number of disk blocks b.\\nb. Calculate the wasted space in each disk block because of the unspanned \\norganization.\\nc. Calculate the transfer rate tr and the bulk transfer rate btr for this disk \\nunit (see Appendix B for definitions of tr and btr).\\nd. Calculate the average number of block accesses  needed to search for an \\narbitrary record in the file, using linear search.\\ne. Calculate in msec the average time needed to search for an arbitrary \\nrecord in the file, using linear search, if the file blocks are stored on con-\\nsecutive disk blocks and double buffering is used.\\nf. Calculate in msec the average time needed to search for an arbitrary \\nrecord in the file, using linear search, if the file blocks are not stored on \\nconsecutive disk blocks.\\ng. Assume that the records are ordered via some key field. Calculate the \\naverage number of block accesses  and the average time needed to search \\nfor an arbitrary record in the file, using binary search.\\n 16.38. A PARTS file with Part# as the hash key includes records with the following \\nPart# values: 2369, 3760, 4692, 4871, 5659, 1821, 1074, 7115, 1620, 2428,'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 610, 'page_label': '611'}, page_content='Exercises 597\\n3943, 4750, 6975, 4981, and 9208. The file uses eight buckets, numbered 0 to \\n7. Each bucket is one disk block and holds two records. Load these records \\ninto the file in the given order, using the hash function h(K) = K mod 8. Cal-\\nculate the average number of block accesses for a random retrieval on \\nPart#.\\n 16.39. Load the records of Exercise 16.31 into expandable hash files based on \\nextendible hashing. Show the structure of the directory at each step, and the \\nglobal and local depths. Use the hash function h(K) = K mod 128.\\n 16.40. Load the records of Exercise 16.31 into an expandable hash file, using linear \\nhashing. Start with a single disk block, using the hash function h0 = K mod 20, \\nand show how the file grows and how the hash functions change as the \\nrecords are inserted. Assume that blocks are split whenever an overflow \\noccurs, and show the value of n at each stage.\\n 16.41. Compare the file commands listed in Section 16.5 to those available on a file \\naccess method you are familiar with.\\n 16.42. Suppose that we have an unordered file of fixed-length records that uses an \\nunspanned record organization. Outline algorithms for insertion, deletion, \\nand modification of a file record. State any assumptions you make.\\n 16.43. Suppose that we have an ordered file of fixed-length records and an unor-\\ndered overflow file to handle insertion. Both files use unspanned records. \\nOutline algorithms for insertion, deletion, and modification of a file record \\nand for reorganizing the file. State any assumptions you make.\\n 16.44. Can you think of techniques other than an unordered overflow file that can \\nbe used to make insertions in an ordered file more efficient?\\n 16.45. Suppose that we have a hash file of fixed-length records, and suppose that \\noverflow is handled by chaining. Outline algorithms for insertion, deletion, \\nand modification of a file record. State any assumptions you make.\\n 16.46. Can you think of techniques other than chaining to handle bucket overflow \\nin external hashing?\\n 16.47. Write pseudocode for the insertion algorithms for linear hashing and for \\nextendible hashing.\\n 16.48. Write program code to access individual fields of records under each of the fol-\\nlowing circumstances. For each case, state the assumptions you make concern-\\ning pointers, separator characters, and so on. Determine the type of information \\nneeded in the file header in order for your code to be general in each case.\\na. Fixed-length records with unspanned blocking\\nb. Fixed-length records with spanned blocking\\nc. Variable-length records with variable-length fields and spanned blocking\\nd. Variable-length records with repeating groups and spanned blocking\\ne. Variable-length records with optional fields and spanned blocking\\nf. Variable-length records that allow all three cases in parts c, d, and e'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 611, 'page_label': '612'}, page_content='598 Chapter 16 Disk Storage, Basic File Structures, Hashing, and Modern Storage Architectures\\n 16.49. Suppose that a file initially contains r = 120,000 records of R = 200 bytes each \\nin an unsorted (heap) file. The block size B = 2,400 bytes, the average seek \\ntime s = 16 ms, the average rotational latency rd = 8.3 ms, and the block \\ntransfer time btt = 0.8 ms. Assume that 1 record is deleted for every 2 records \\nadded until the total number of active records is 240,000.\\na. How many block transfers are needed to reorganize the file?\\nb. How long does it take to find a record right before reorganization?\\nc. How long does it take to find a record right after reorganization?\\n 16.50. Suppose we have a sequential (ordered) file of 100,000 records where each \\nrecord is 240 bytes. Assume that B = 2,400 bytes, s = 16 ms, rd = 8.3 ms, and \\nbtt = 0.8 ms. Suppose we want to make X independent random record reads \\nfrom the file. We could make X random block reads or we could perform \\none exhaustive read of the entire file looking for those X records. The ques-\\ntion is to decide when it would be more efficient to perform one exhaustive \\nread of the entire file than to perform X individual random reads. That is, \\nwhat is the value for X when an exhaustive read of the file is more efficient \\nthan random X reads? Develop this as a function of X.\\n 16.51. Suppose that a static hash file initially has 600 buckets in the primary area \\nand that records are inserted that create an overflow area of 600 buckets. If \\nwe reorganize the hash file, we can assume that most of the overflow is elim-\\ninated. If the cost of reorganizing the file is the cost of the bucket transfers \\n(reading and writing all of the buckets) and the only periodic file operation \\nis the fetch operation, then how many times would we have to perform a \\nfetch (successfully) to make the reorganization cost effective? That is, the \\nreorganization cost and subsequent search cost are less than the search \\ncost before reorganization. Support your answer. Assume s = 16 msec, \\nrd\\xa0=\\xa08.3\\xa0msec, and btt = 1 msec.\\n 16.52. Suppose we want to create a linear hash file with a file load factor of 0.7 and \\na blocking factor of 20 records per bucket, which is to contain 112,000 \\nrecords initially.\\na. How many buckets should we allocate in the primary area?\\nb. What should be the number of bits used for bucket addresses?\\nSelected Bibliography\\nWiederhold (1987) has a detailed discussion and analysis of secondary storage \\ndevices and file organizations as a part of database design. Optical disks are \\ndescribed in Berg and Roth (1989) and analyzed in Ford and Christodoulakis \\n(1991). Flash memory is discussed by Dipert and Levy (1993). Ruemmler and \\n Wilkes (1994) present a survey of the magnetic-disk technology. Most textbooks on \\ndatabases include discussions of the material presented here. Most data structures \\ntextbooks, including Knuth (1998), discuss static hashing in more detail; Knuth has'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 612, 'page_label': '613'}, page_content='Selected Bibliography 599\\na complete discussion of hash functions and collision resolution techniques, as well \\nas of their performance comparison. Knuth also offers a detailed discussion of tech-\\nniques for sorting external files. Textbooks on file structures include Claybrook \\n(1992), Smith and Barnes (1987), and Salzberg (1988); they discuss additional file \\norganizations including tree-structured files, and have detailed algorithms for \\noperations on files. Salzberg et al. (1990) describe a distributed external sorting \\nalgorithm. File organizations with a high degree of fault tolerance are described by \\nBitton and Gray (1988) and by Gray et al. (1990). Disk striping was proposed in \\nSalem and Garcia Molina (1986). The first paper on redundant arrays of inexpen-\\nsive disks (RAID) is by Patterson et al. (1988). Chen and Patterson (1990) and the \\nexcellent survey of RAID by Chen et al. (1994) are additional references. Gro-\\nchowski and Hoyt (1996) discuss future trends in disk drives. Various formulas for \\nthe RAID architecture appear in Chen et al. (1994).\\nMorris (1968) is an early paper on hashing. Extendible hashing is described in Fagin \\net al. (1979). Linear hashing is described by Litwin (1980). Algorithms for insertion \\nand deletion for linear hashing are discussed with illustrations in Salzberg (1988). \\nDynamic hashing, which we briefly introduced, was proposed by Larson (1978). \\nThere are many proposed variations for extendible and linear hashing; for examples, \\nsee Cesarini and Soda (1991), Du and Tong (1991), and Hachem and Berra (1992).\\nGibson et al. (1997) describe a file server scaling approach for network-attached \\nstorage, and Kubiatowicz et al. (2000) decribe the Oceanstore system for creating a \\nglobal utility infrastructure for storing persistent data. Both are considered pio-\\nneering approaches that led to the ideas for object-based storage. Mesnier et al. \\n(2003) give an overview of the object storage concept. The Lustre system (Braam & \\nSchwan, 2002) was one of the first object storage products and is used in the major-\\nity of supercomputers, including the top two, namely China’s Tianhe-2 and \\nOakridge National Lab’s Titan.\\nDetails of disk storage devices can be found at manufacturer sites (for example, \\nhttp://www.seagate.com, http://www.ibm.com, http://www.emc.com, http://www.\\nhp.com, http://www.storagetek.com). IBM has a storage technology research center \\nat IBM Almaden (http://www.almaden.ibm.com). Additional useful sites include \\nCISCO storage solutions at cisco.com; Network Appliance (NetApp) at www.\\nnetapp.com; Hitachi Data Storage (HDS) at www.hds.com, and SNIA (Storage Net-\\nworking Industry Association) at www.snia.org. A number of industry white papers \\nare available at the aforementioned sites.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 613, 'page_label': '614'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 614, 'page_label': '615'}, page_content='601\\n17\\nIndexing Structures for Files and \\nPhysical Database Design\\nI\\nn this chapter, we assume that a file already exists with \\nsome primary organization such as the unordered, \\nordered, or hashed organizations that were described in Chapter 16. We will \\ndescribe additional auxiliary access structures  called indexes, which are used to \\nspeed up the retrieval of records in response to certain search conditions. The index \\nstructures are additional files on disk that provide secondary access paths , which \\nprovide alternative ways to access the records without affecting the physical place-\\nment of records in the primary data file on disk. They enable efficient access to \\nrecords based on the indexing fields that are used to construct the index. Basically, \\nany field of the file can be used to create an index, and multiple indexes on different \\nfields—as well as indexes on multiple fields—can be constructed on the same file. A \\nvariety of indexes are possible; each of them uses a particular data structure to speed \\nup the search. To find a record or records in the data file based on a search condi-\\ntion on an indexing field, the index is searched, which leads to pointers to one or \\nmore disk blocks in the data file where the required records are located. The most \\nprevalent types of indexes are based on ordered files (single-level indexes) and use \\ntree data structures (multilevel indexes, B\\n+-trees) to organize the index. Indexes can \\nalso be constructed based on hashing or other search data structures. We also dis-\\ncuss indexes that are vectors of bits called bitmap indexes.\\nWe describe different types of single-level ordered indexes—primary, secondary, \\nand clustering—in Section 17.1. By viewing a single-level index as an ordered file, \\none can develop additional indexes for it, giving rise to the concept of multilevel \\nindexes. A popular indexing scheme called ISAM (indexed sequential access \\nmethod) is based on this idea. We discuss multilevel tree-structured indexes in Sec-\\ntion 17.2. In Section 17.3, we describe B-trees and B\\n+-trees, which are data struc-\\ntures that are commonly used in DBMSs to implement dynamically changing \\nchapter 17'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 615, 'page_label': '616'}, page_content='602 Chapter 17 Indexing Structures for Files and Physical Database Design\\nmultilevel indexes. B +-trees have become a commonly accepted default structure \\nfor generating indexes on demand in most relational DBMSs. Section 17.4 is devoted \\nto alternative ways to access data based on a combination of multiple keys. In Sec-\\ntion 17.5, we discuss hash indexes and introduce the concept of logical indexes, \\nwhich give an additional level of indirection from physical indexes and allow the \\nphysical index to be flexible and extensible in its organization. In Section 17.6, we \\ndiscuss multikey indexing and bitmap indexes used for searching on one or more keys. \\nSection 17.7 covers physical design and Section 7.8 summarizes the chapter.\\n17.1 Types of Single-Level Ordered Indexes\\nThe idea behind an ordered index is similar to that behind the index used in a text-\\nbook, which lists important terms at the end of the book in alphabetical order along \\nwith a list of page numbers where the term appears in the book. We can search the \\nbook index for a certain term in the textbook to find a list of addresses—page num-\\nbers in this case—and use these addresses to locate the specified pages first and then \\nsearch for the term on each specified page. The alternative, if no other guidance is \\ngiven, would be to sift slowly through the whole textbook word by word to find the \\nterm we are interested in; this corresponds to doing a linear search, which scans the \\nwhole file. Of course, most books do have additional information, such as chapter \\nand section titles, which help us find a term without having to search through the \\nwhole book. However, the index is the only exact indication of the pages where each \\nterm occurs in the book.\\nFor a file with a given record structure consisting of several fields (or attributes), an \\nindex access structure is usually defined on a single field of a file, called an indexing \\nfield (or indexing attribute).\\n1 The index typically stores each value of the index field \\nalong with a list of pointers to all disk blocks that contain records with that field \\nvalue. The values in the index are ordered so that we can do a binary search on the \\nindex. If both the data file and the index file are ordered, and since the index file is \\ntypically much smaller than the data file, searching the index using a binary search \\nis a better option. Tree-structured multilevel indexes (see Section 17.2) implement \\nan extension of the binary search idea that reduces the search space by two-way \\npartitioning at each search step to an n-ary partitioning approach that divides the \\nsearch space in the file n-ways at each stage.\\nThere are several types of ordered indexes. A primary index  is specified on the \\nordering key field  of an ordered file  of records. Recall from Section 16.7 that an \\nordering key field is used to physically order  the file records on disk, and every \\nrecord has a unique value for that field. If the ordering field is not a key field—that \\nis, if numerous records in the file can have the same value for the ordering field—\\nanother type of index, called a clustering index, can be used. The data file is called \\na clustered file in this latter case. Notice that a file can have at most one physical \\nordering field, so it can have at most one primary index or one clustering index, but \\n1We use the terms field and attribute interchangeably in this chapter.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 616, 'page_label': '617'}, page_content='17.1 Types of Single-Level Ordered Indexes  603\\nnot both. A third type of index, called a secondary index, can be specified on any \\nnonordering field of a file. A data file can have several secondary indexes in addition \\nto its primary access method. We discuss these types of single-level indexes in the \\nnext three subsections.\\n17.1.1 Primary Indexes\\nA primary index  is an ordered file whose records are of fixed length with two \\nfields, and it acts like an access structure to efficiently search for and access the \\ndata records in a data file. The first field is of the same data type as the ordering \\nkey field—called the primary key —of the data file, and the second field is a \\npointer to a disk block (a block address). There is one index entry  (or index \\nrecord) in the index file for each block in the data file. Each index entry has the \\nvalue of the primary key field for the first record in a block and a pointer to that \\nblock as its two field values. We will refer to the two field values of index entry i as \\n<K(i), P(i)>. In the rest of this chapter, we refer to different types of index entries \\n< K (i), X > as follows:\\n ■ X may be the physical address of a block (or page) in the file, as in the case of \\nP(i) above.\\n ■ X may be the record address made up of a block address and a record id (or \\noffset) within the block.\\n ■ X may be a logical address of the block or of the record within the file and is \\na relative number that would be mapped to a physical address (see further \\nexplanation in Section 17.6.1).\\nTo create a primary index on the ordered file shown in Figure 16.7, we use the \\nName \\nfield as primary key, because that is the ordering key field of the file (assuming that \\neach value of \\nName is unique). Each entry in the index has a Name value and a \\npointer. The first three index entries are as follows:\\n<K(1) = (Aaron, Ed), P(1) = address of block 1>\\n<K(2) = (Adams, John), P(2) = address of block 2>\\n<K(3) = (Alexander, Ed), P(3) = address of block 3>\\nFigure 17.1 illustrates this primary index. The total number of entries in the index is \\nthe same as the number of disk blocks  in the ordered data file. The first record in \\neach block of the data file is called the anchor record of the block, or simply the \\nblock anchor.2\\nIndexes can also be characterized as dense or sparse. A dense index has an index \\nentry for every search key value  (and hence every record) in the data file. A sparse \\n(or nondense ) index, on the other hand, has index entries for only some of the \\nsearch values. A sparse index has fewer entries than the number of records in \\nthe file. Thus, a primary index is a nondense (sparse) index, since it includes an \\n2We can use a scheme similar to the one described here, with the last record in each block (rather than \\nthe first) as the block anchor. This slightly improves the efficiency of the search algorithm.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 617, 'page_label': '618'}, page_content='604 Chapter 17 Indexing Structures for Files and Physical Database Design\\nIndex file\\n(< K(i), P(i)> entries)\\nBlock anchor\\nprimary key\\nvalue\\nBlock\\npointer\\nData file\\n(Primary\\nkey field)\\nName\\nAaron, Ed\\nAbbot, Diane\\n..\\n.\\n...\\n..\\n.\\n..\\n.\\n..\\n.\\nAcosta, Marc\\nAdams, John\\nAdams, Robin\\nAkers, Jan\\nAlexander, Ed\\nAlfred, Bob\\nAllen, Sam\\nAllen, Troy\\nAnders, Keith\\nAnderson, Rob\\nAnderson, Zach\\nAngel, Joe\\nArcher, Sue\\nArnold, Mack\\nArnold, Steven\\nAtkins, Timothy\\nWong, James\\nWood, Donald\\nWoods, Manny\\nWright, Pam\\nWyatt, Charles\\nZimmer, Byron\\nAaron, Ed\\nAdams, John\\nAlexander, Ed\\nAllen, Troy\\nAnderson, Zach\\nArnold, Mack\\nWong, James\\nWright, Pam\\n..\\n.\\n..\\n.\\n..\\n.\\n. . .. . .\\nSsn Birth_date Job Salary Sex\\nFigure 17.1 \\nPrimary index on the ordering \\nkey field of the file shown in \\nFigure 16.7.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 618, 'page_label': '619'}, page_content='17.1 Types of Single-Level Ordered Indexes  605\\nentry for each disk block of the data file and the keys of its anchor record rather \\nthan for every search value (or every record).3\\nThe index file for a primary index occupies a much smaller space than does the data \\nfile, for two reasons. First, there are fewer index entries than there are records in the \\ndata file. Second, each index entry is typically smaller in size  than a data record \\nbecause it has only two fields, both of which tend to be short in size; consequently, \\nmore index entries than data records can fit in one block. Therefore, a binary search \\non the index file requires fewer block accesses than a binary search on the data file. \\nReferring to Table 16.3, note that the binary search for an ordered data file required \\nlog\\n2b block accesses. But if the primary index file contains only bi blocks, then to \\nlocate a record with a search key value requires a binary search of that index and \\naccess to the block containing that record: a total of log\\n2bi + 1 accesses.\\nA record whose primary key value is K lies in the block whose address is P(i), where \\nK(i) ≤ K < K(i + 1). The ith block in the data file contains all such records because of \\nthe physical ordering of the file records on the primary key field. To retrieve a \\nrecord, given the value K of its primary key field, we do a binary search on the index \\nfile to find the appropriate index entry i, and then retrieve the data file block whose \\naddress is P(i).\\n4 Example 1 illustrates the saving in block accesses that is attainable \\nwhen a primary index is used to search for a record.\\nExample 1. Suppose that we have an ordered file with r = 300,000 records stored on \\na disk with block size B = 4,096 bytes.5 File records are of fixed size and are unspanned, \\nwith record length R = 100 bytes. The blocking factor for the file would be \\nbfr  = ⎣(B/R)⎦ = ⎣(4,096/100)⎦ = 40 records per block. The number of blocks needed \\nfor the file is b = ⎡(r/bfr)⎤ = ⎡(300,000/40)⎤ = 7,500 blocks. A binary search on the data \\nfile would need approximately ⎡log2 b⎤= ⎡(log2 7,500)⎤ = 13 block accesses.\\nNow suppose that the ordering key field of the file is V = 9 bytes long, a block pointer \\nis P = 6 bytes long, and we have constructed a primary index for the file. The size of \\neach index entry is Ri = (9 + 6) = 15 bytes, so the blocking factor for the index is  \\nbfri = ⎣(B/Ri)⎦ = ⎣(4,096/15)⎦ = 273 entries per block. The total number of index \\nentries ri is equal to the number of blocks in the data file, which is 7,500. The number \\nof index blocks is hence bi = ⎡(ri/bfri)⎤ = ⎡(7,500/273)⎤ = 28 blocks. To perform a \\nbinary search on the index file would need ⎡(log2 bi)⎤ = ⎡(log2 28)⎤ = 5 block accesses. \\nTo search for a record using the index, we need one additional block access to the data \\nfile for a total of 5 + 1 = 6 block accesses—an improvement over binary search on the \\ndata file, which required 13 disk block accesses. Note that the index with 7,500 entries \\nof 15 bytes each is rather small (112,500 or 112.5 Kbytes) and would typically be kept \\nin main memory thus requiring negligible time to search with binary search. In that \\ncase we simply make one block access to retrieve the record.\\n3The sparse primary index has been called clustered (primary) index in some books and articles.\\n4Notice that the above formula would not be correct if the data file were ordered on a nonkey field; in that \\ncase the same index value in the block anchor could be repeated in the last records of the previous block.\\n5Most DBMS vendors, including Oracle, are using 4K or 4,096 bytes as a standard block/page size.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 619, 'page_label': '620'}, page_content='606 Chapter 17 Indexing Structures for Files and Physical Database Design\\nA major problem with a primary index—as with any ordered file—is insertion and \\ndeletion of records. With a primary index, the problem is compounded because if \\nwe attempt to insert a record in its correct position in the data file, we must not \\nonly move records to make space for the new record but also change some index \\nentries, since moving records will change the anchor records of some blocks. Using \\nan unordered overflow file, as discussed in Section 16.7, can reduce this problem. \\nAnother possibility is to use a linked list of overflow records for each block in the \\ndata file. This is similar to the method of dealing with overflow records described \\nwith hashing in Section 16.8.2. Records within each block and its overflow linked \\nlist can be sorted to improve retrieval time. Record deletion is handled using dele-\\ntion markers.\\n17.1.2 Clustering Indexes\\nIf file records are physically ordered on a nonkey field—which does not have a dis-\\ntinct value for each record—that field is called the clustering field and the data file \\nis called a clustered file. We can create a different type of index, called a clustering \\nindex, to speed up retrieval of all the records that have the same value for the clus-\\ntering field. This differs from a primary index, which requires that the ordering \\nfield of the data file have a distinct value for each record.\\nA clustering index is also an ordered file with two fields; the first field is of the \\nsame type as the clustering field of the data file, and the second field is a disk block \\npointer. There is one entry in the clustering index for each distinct value  of the \\nclustering field, and it contains the value and a pointer to the first block in the data \\nfile that has a record with that value for its clustering field. Figure 17.2 shows an \\nexample. Notice that record insertion and deletion still cause problems because \\nthe data records are physically ordered. To alleviate the problem of insertion, it is \\ncommon to reserve a whole block (or a cluster of contiguous blocks) for each value \\nof the clustering field; all records with that value are placed in the block (or block \\ncluster). This makes insertion and deletion relatively straightforward. Figure 17.3 \\nshows this scheme.\\nA clustering index is another example of a nondense index because it has an entry \\nfor every distinct value of the indexing field, which is a nonkey by definition and \\nhence has duplicate values rather than a unique value for every record in the file.\\nExample 2. Suppose that we consider the same ordered file with r = 300,000 \\nrecords stored on a disk with block size B = 4,096 bytes. Imagine that it is ordered by \\nthe attribute Zipcode and there are 1,000 zip codes in the file (with an average 300 \\nrecords per zip code, assuming even distribution across zip codes.) The index in this \\ncase has 1,000 index entries of 11 bytes each (5-byte Zipcode and 6-byte block \\npointer) with a blocking factor bfr\\ni = ⎣(B/Ri)⎦ = ⎣(4,096/11)⎦ = 372 index entries per \\nblock. The number of index blocks is hence bi = ⎡(ri/bfri)⎤ = ⎡(1,000/372)⎤ = 3 blocks. \\nTo perform a binary search on the index file would need ⎡(log2 bi)⎤ = ⎡(log2 3)⎤ = 2 \\nblock accesses. Again, this index would typically be loaded in main memory (occu-\\npies 11,000 or 11 Kbytes) and takes negligible time to search in memory. One block \\naccess to the data file would lead to the first record with a given zip code.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 620, 'page_label': '621'}, page_content='17.1 Types of Single-Level Ordered Indexes  607\\nData file(Clustering\\nfield)\\nDept_number\\n1\\n1\\n1\\n2\\nName Ssn Birth_date SalaryJob\\n2\\n3\\n3\\n3\\n3\\n3\\n4\\n4\\n5\\n5\\n5\\n5\\n6\\n6\\n6\\n6\\n6\\n8\\n8\\n8\\n1\\n2\\n3\\n4\\n5\\n6\\n8\\nIndex file\\n(< K(i), P(i)> entries)\\nClustering\\nfield value\\nBlock\\npointer\\nFigure 17.2 \\nA clustering index on the Dept_number \\nordering nonkey field of an EMPLOYEE file.\\nThere is some similarity between Figures 17.1, 17.2, and 17.3 and Figures 16.11  \\nand 16.12. An index is somewhat similar to dynamic hashing (described in Sec- \\ntion 16.8.3) and to the directory structures used for extendible hashing. Both are \\nsearched to find a pointer to the data block containing the desired record. A main \\ndifference is that an index search uses the values of the search field itself, whereas a \\nhash directory search uses the binary hash value that is calculated by applying the \\nhash function to the search field.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 621, 'page_label': '622'}, page_content='608 Chapter 17 Indexing Structures for Files and Physical Database Design\\nData file\\nBlock pointer\\nNULL pointer\\n(Clustering\\nfield)\\nDept_number\\n1\\n1\\n2\\n3\\n4\\n5\\n6\\n8\\n1\\n1\\nName Ssn Birth_date SalaryJob\\nBlock pointer\\n2\\n2\\nBlock pointer\\n3\\n3\\n3\\n3\\nBlock pointer\\n3\\nBlock pointer\\n4\\n4\\nBlock pointer\\n5\\n5\\n5\\n5 Block pointer\\n6\\n6\\n6\\n6\\nBlock pointer\\n6\\nBlock pointer\\n8\\n8\\n8\\nNULL pointer\\nNULL pointer\\nNULL pointer\\nNULL pointer\\nNULL pointer\\nNULL pointer\\nIndex file\\n(< K(i), P(i)> entries)\\nClustering\\nfield value\\nBlock\\npointer\\nFigure 17.3 \\nClustering index with a \\nseparate block cluster \\nfor each group of \\nrecords that share the \\nsame value for the \\nclustering field.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 622, 'page_label': '623'}, page_content='17.1 Types of Single-Level Ordered Indexes  609\\n17.1.3 Secondary Indexes\\nA secondary index provides a secondary means of accessing a data file for which \\nsome primary access already exists. The data file records could be ordered, unor-\\ndered, or hashed. The secondary index may be created on a field that is a candidate \\nkey and has a unique value in every record, or on a nonkey field with duplicate \\nvalues. The index is again an ordered file with two fields. The first field is of the \\nsame data type as some nonordering field of the data file that is an indexing field. \\nThe second field is either a block pointer or a record pointer. Many secondary \\nindexes (and hence, indexing fields) can be created for the same file—each repre-\\nsents an additional means of accessing that file based on some specific field.\\nFirst we consider a secondary index access structure on a key (unique) field that has a \\ndistinct value for every record. Such a field is sometimes called a secondary key; in the \\nrelational model, this would correspond to any \\nUNIQUE key attribute or to the primary \\nkey attribute of a table. In this case there is one index entry for each record in the data \\nfile, which contains the value of the field for the record and a pointer either to the block \\nin which the record is stored or to the record itself. Hence, such an index is dense.\\nAgain we refer to the two field values of index entry i as <K(i), P(i)>. The entries are \\nordered by value of K(i), so we can perform a binary search. Because the records of \\nthe data file are not physically ordered by values of the secondary key field, we cannot \\nuse block anchors. That is why an index entry is created for each record in the data \\nfile, rather than for each block, as in the case of a primary index. Figure 17.4 illustrates \\na secondary index in which the pointers P(i) in the index entries are block pointers, \\nnot record pointers. Once the appropriate disk block is transferred to a main memory \\nbuffer, a search for the desired record within the block can be carried out.\\nA secondary index usually needs more storage space and longer search time than \\ndoes a primary index, because of its larger number of entries. However, the improve-\\nment in search time for an arbitrary record is much greater for a secondary index \\nthan for a primary index, since we would have to do a linear search on the data file \\nif the secondary index did not exist. For a primary index, we could still use a binary \\nsearch on the main file, even if the index did not exist. Example 3 illustrates the \\nimprovement in number of blocks accessed.\\nExample 3. Consider the file of Example 1 with r = 300,000 fixed-length records \\nof size R = 100 bytes stored on a disk with block size B = 4,096 bytes. The file has \\nb = 7,500 blocks, as calculated in Example 1. Suppose we want to search for a record \\nwith a specific value for the secondary key—a nonordering key field of the file that is \\nV = 9 bytes long. Without the secondary index, to do a linear search on the file would \\nrequire b/2 = 7,500/2 = 3,750 block accesses on the average. Suppose that we con-\\nstruct a secondary index on that nonordering key field of the file. As in Example 1, a \\nblock pointer is P = 6 bytes long, so each index entry is R\\ni = (9 + 6) = 15 bytes, and the \\nblocking factor for the index is bfri = ⎣(B/Ri)⎦ = ⎣(4,096/15)⎦ = 273 index entries per \\nblock. In a dense secondary index such as this, the total number of index entries ri is \\nequal to the number of records in the data file, which is 300,000. The number of blocks \\nneeded for the index is hence bi = ⎡(ri/bfri)⎤ = ⎡(300,000/273)⎤ = 1,099 blocks.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 623, 'page_label': '624'}, page_content='610 Chapter 17 Indexing Structures for Files and Physical Database Design\\nData file\\nIndexing field\\n(secondary\\nkey field)\\n6\\n15\\n3\\n17\\n9\\n5\\n13\\n8\\n21\\n11\\n16\\n2\\n24\\n10\\n20\\n1\\n4\\n23\\n18\\n14\\n12\\n7\\n19\\n22\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\n20\\n21\\n22\\n23\\n24\\nIndex file\\n(< K(i), P(i)> entries)\\nIndex\\nfield value\\nBlock\\npointer\\nFigure 17.4 \\nA dense secondary index (with block pointers) on a nonordering key field of a file.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 624, 'page_label': '625'}, page_content='17.1 Types of Single-Level Ordered Indexes  611\\nA binary search on this secondary index needs ⎡(log2 bi)⎤ = ⎡(log21,099)⎤ = 11 block \\naccesses. To search for a record using the index, we need an additional block access \\nto the data file for a total of 11 + 1 = 12 block accesses—a vast improvement over the \\n3,750 block accesses needed on the average fo r a linear search, but slightly worse \\nthan the 6 block accesses required for the primary index. This difference arose \\nbecause the primary index was nondense and hence shorter, with only 28 blocks in \\nlength as opposed to the 1,099 blocks dense index here.\\nWe can also create a secondary index on a nonkey, nonordering field of a file. In this \\ncase, numerous records in the data file can have the same value for the indexing \\nfield. There are several options for implementing such an index:\\n ■ Option 1 is to include duplicate index entries with the same K(i) value—one \\nfor each record. This would be a dense index.\\n ■ Option 2 is to have variable-length records for the index entries, with a \\nrepeating field for the pointer. We keep a list of pointers <P(i, 1), … , P(i, k)> \\nin the index entry for K(i)—one pointer to each block that contains a record \\nwhose indexing field value equals K(i). In either option 1 or option 2, the \\nbinary search algorithm on the index must be modified appropriately to \\naccount for a variable number of index entries per index key value.\\n ■ Option 3, which is more commonly used, is to keep the index entries them-\\nselves at a fixed length and have a single entry for each index field value, but \\nto create an extra level of indirection to handle the multiple pointers. In this \\nnondense scheme, the pointer P(i) in index entry < K(i), P(i)> points to a \\ndisk block, which contains a set of record pointers ; each record pointer in \\nthat disk block points to one of the data file records with value K(i) for the \\nindexing field. If some value K(i) occurs in too many records, so that their \\nrecord pointers cannot fit in a single disk block, a cluster or linked list of \\nblocks is used. This technique is illustrated in Figure 17.5. Retrieval via the \\nindex requires one or more additional block accesses because of the extra \\nlevel, but the algorithms for searching the index and (more importantly) for \\ninserting of new records in the data file are straightforward. The binary \\nsearch algorithm is directly applicable to the index file since it is ordered. \\nFor range retrievals such as retrieving records where V\\n1 ≤ K ≤ V2, block \\npointers may be used in the pool of pointers for each value instead of the \\nrecord pointers. Then a union operation can be used on the pools of block \\npointers corresponding to the entries from V\\n1 to V2 in the index to eliminate \\nduplicates and the resulting blocks can be accessed. In addition, retrievals on \\ncomplex selection conditions may be handled by referring to the record \\npointers from multiple non-key secondary indexes, without having to \\nretrieve many unnecessary records from the data file (see Exercise 17.24).\\nNotice that a secondary index provides a logical ordering  on the records by the \\nindexing field. If we access the records in order of the entries in the secondary \\nindex, we get them in order of the indexing field. The primary and clustering \\nindexes assume that the field used for physical ordering of records in the file is the \\nsame as the indexing field.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 625, 'page_label': '626'}, page_content='612 Chapter 17 Indexing Structures for Files and Physical Database Design\\nData file\\n(Indexing field)\\nDept_number\\n3\\n5\\n1\\n6\\nName Ssn Birth_date SalaryJob\\n2\\n3\\n4\\n8\\n6\\n8\\n4\\n1\\n6\\n5\\n2\\n5\\n5\\n1\\n6\\n3\\n6\\n3\\n8\\n3\\n1\\n2\\n3\\n4\\n5\\n6\\n8\\nBlocks of\\nrecord\\npointers\\nIndex file\\n(< K(i), P(i)> entries)\\nField \\nvalue\\nBlock\\npointer\\nFigure 17.5 \\nA secondary index \\n(with record pointers) \\non a nonkey field \\nimplemented using \\none level of indirection \\nso that index entries \\nare of fixed length  \\nand have unique  \\nfield values.\\n17.1.4 Summary\\nTo conclude this section, we summarize the discussion of index types in two tables. \\nTable 17.1 shows the index field characteristics of each type of ordered single-level \\nindex discussed—primary, clustering, and secondary. Table 17.2 summarizes the \\nproperties of each type of index by comparing the number of index entries and \\nspecifying which indexes are dense and which use block anchors of the data file.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 626, 'page_label': '627'}, page_content='17.2 Multilevel Indexes  613\\n17.2 Multilevel Indexes\\nThe indexing schemes we have described thus far involve an ordered index file. A \\nbinary search is applied to the index to locate pointers to a disk block or to a record \\n(or records) in the file having a specific index field value. A binary search requires \\napproximately (log\\n2 bi) block accesses for an index with bi blocks because each step \\nof the algorithm reduces the part of the index file that we continue to search by a \\nfactor of 2. This is why we take the log function to the base 2. The idea behind a \\nmultilevel index  is to reduce the part of the index that we continue to search by \\nbfr\\ni, the blocking factor for the index, which is larger than 2. Hence, the search \\nspace is reduced much faster. The value bfri is called the fan-out of the multilevel \\nindex, and we will refer to it by the symbol fo. Whereas we divide the record search \\nspace into two halves at each step during a binary search, we divide it n-ways \\n(where n = the fan-out) at each search step using the multilevel index. Searching a \\nmultilevel index requires approximately (log fo bi) block accesses, which is a sub-\\nstantially smaller number than for a binary search if the fan-out is larger than 2. In \\nmost cases, the fan-out is much larger than 2. Given a blocksize of 4,096, which is \\nmost common in today’s DBMSs, the fan-out depends on how many (key + block \\npointer) entries fit within a block. With a 4-byte block pointer (which would \\naccommodate 2\\n32 − 1 = 4.2 *109 blocks) and a 9-byte key such as SSN, the fan-out \\ncomes to 315.\\nA multilevel index considers the index file, which we will now refer to as the first \\n(or base) level of a multilevel index, as an ordered file with a distinct value for each \\nTable 17.1 T ypes of Indexes Based on the Properties of the Indexing Field\\nIndex Field Used for Physical \\nOrdering of the File\\nIndex Field Not Used for Physical \\nOrdering of the File\\nIndexing field is key Primary index Secondary index (Key)\\nIndexing field is nonkey Clustering index Secondary index (NonKey)\\nTable 17.2 Properties of Index T ypes\\n \\nType of Index\\nNumber of (First-Level)  \\nIndex Entries\\nDense or Nondense \\n(Sparse)\\nBlock Anchoring \\non the Data File\\nPrimary Number of blocks in data file Nondense Y es\\nClustering Number of distinct index field \\nvalues\\nNondense Y es/no a\\nSecondary (key) Number of records in data file Dense No\\nSecondary (nonkey) Number of records b or number \\nof distinct index field valuesc\\nDense or Nondense No\\naY es if every distinct value of the ordering ﬁeld starts a new block; no otherwise.\\nbFor option 1.\\ncFor options 2 and 3.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 627, 'page_label': '628'}, page_content='614 Chapter 17 Indexing Structures for Files and Physical Database Design\\nK(i). Therefore, by considering the first-level index file as a sorted data file, we can \\ncreate a primary index for the first level; this index to the first level is called the  \\nsecond level of the multilevel index. Because the second level is a primary index, we \\ncan use block anchors so that the second level has one entry for each block of the \\nfirst level. The blocking factor bfri for the second level—and for all subsequent \\nlevels—is the same as that for the first-level index because all index entries are the \\nsame size; each has one field value and one block address. If the first level has r\\n1 \\nentries, and the blocking factor—which is also the fan-out—for the index is  \\nbfr\\ni = fo, then the first level needs ⎡(r1/fo)⎤ blocks, which is therefore the number of \\nentries r2 needed at the second level of the index.\\nWe can repeat this process for the second level. The third level, which is a primary \\nindex for the second level, has an entry for each second-level block, so the number \\nof third-level entries is r\\n3 = ⎡(r2/fo)⎤. Notice that we require a second level only if the \\nfirst level needs more than one block of disk storage, and, similarly, we require a \\nthird level only if the second level needs more than one block. We can repeat the \\npreceding process until all the entries of some index level t fit in a single block. This \\nblock at the tth level is called the top index level.\\n6 Each level reduces the number of \\nentries at the previous level by a factor of fo—the index fan-out—so we can use the \\nformula 1 ≤ ( r1/((fo)t)) to calculate t. Hence, a multilevel index with r1 first-level \\nentries will have approximately t levels, where t = ⎡(logfo(r1))⎤. When searching the \\nindex, a single disk block is retrieved at each level. Hence, t disk blocks are accessed \\nfor an index search, where t is the number of index levels.\\nThe multilevel scheme described here can be used on any type of index—whether it \\nis primary, clustering, or secondary—as long as the first-level index has distinct val-\\nues for K(i) and fixed-length entries. Figure 17.6 shows a multilevel index built over \\na primary index. Example 3 illustrates the improvement in number of blocks \\naccessed when a multilevel index is used to search for a record.\\nExample 4. Suppose that the dense secondary index of Example 3 is converted \\ninto a multilevel index. We calculated the index blocking factor bfri = 273 index \\nentries per block, which is also the fan-out fo for the multilevel index; the number of \\nfirst-level blocks b1 = 1,099 blocks was also calculated. The number of second-level \\nblocks will be b2 = ⎡(b1/fo)⎤ = ⎡(1,099/273)⎤ = 5 blocks, and the number of third-\\nlevel blocks will be b3 = ⎡(b2/fo)⎤ = ⎡(5/273)⎤ = 1 block. Hence, the third level is the \\ntop level of the index, and t = 3. To access a record by searching the multilevel index, \\nwe must access one block at each level plus one block from the data file, so we need \\nt + 1 = 3 + 1 = 4 block accesses. Compare this to Example 3, where 12 block accesses \\nwere needed when a single-level index and binary search were used.\\nNotice that we could also have a multilevel primary index, which would be non-\\ndense. Exercise 17.18(c) illustrates this case, where we must access the data block \\nfrom the file before we can determine whether the record being searched for is in \\nthe file. For a dense index, this can be determined by accessing the first index level \\n6The numbering scheme for index levels used here is the reverse of the way levels are commonly defined \\nfor tree data structures. In tree data structures, t is referred to as level 0 (zero), t − 1 is level 1, and so on.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 628, 'page_label': '629'}, page_content='17.2 Multilevel Indexes  615\\nData file\\nPrimary\\nkey field\\nSecond (top)\\nlevel\\nTwo-level index\\n2\\n5\\n8\\n12\\n15\\n21\\n24\\n29\\n35\\n36\\n39\\n41\\n44\\n46\\n51\\n52\\n55\\n58\\n63\\n66\\n71\\n78\\n80\\n82\\n85\\n89\\n2\\n35\\n55\\n85\\nFirst (base)\\nlevel\\n2\\n8\\n15\\n2435\\n39\\n44\\n51\\n55\\n63\\n71\\n80\\n85\\nFigure 17.6 \\nA two-level primary index resembling ISAM (indexed sequential access method) organization.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 629, 'page_label': '630'}, page_content='616 Chapter 17 Indexing Structures for Files and Physical Database Design\\n(without having to access a data block), since there is an index entry for every \\nrecord in the file.\\nA common file organization used in business data processing is an ordered file with a \\nmultilevel primary index on its ordering key field. Such an organization is called an \\nindexed sequential file and was used in a large number of early IBM systems. IBM’s \\nISAM organization incorporates a two-level index that is closely related to the organi-\\nzation of the disk in terms of cylinders and tracks (see Section 16.2.1). The first level is \\na cylinder index, which has the key value of an anchor record for each cylinder of a \\ndisk pack occupied by the file and a pointer to the track index for the cylinder. The \\ntrack index has the key value of an anchor record for each track in the cylinder and a \\npointer to the track. The track can then be searched sequentially for the desired record \\nor block. Insertion is handled by some form of overflow file that is merged periodi-\\ncally with the data file. The index is re-created during file reorganization.\\nAlgorithm 17.1 outlines the search procedure for a record in a data file that uses a \\nnondense multilevel primary index with t levels. We refer to entry i at level j of the \\nindex as <K\\nj(i), Pj(i)>, and we search for a record whose primary key value is K. We \\nassume that any overflow records are ignored. If the record is in the file, there must \\nbe some entry at level 1 with K1(i) ≤ K < K1(i + 1) and the record will be in the block \\nof the data file whose address is P1(i). Exercise 17.23 discusses modifying the search \\nalgorithm for other types of indexes.\\nAlgorithm 17.1. Searching a Nondense Multilevel Primary Index with t Levels\\n(*We assume the index entry to be a block anchor that is the first key per block*)\\np ← address of top-level block of index;\\nfor j ← t step − 1 to 1 do\\n begin\\n  read the index block (at jth index level) whose address is p;\\n  search block p for entry i such that Kj (i) ≤ K < Kj(i + 1)\\n (* if Kj(i)\\n  is the last entry in the block, it is sufficient to satisfy Kj(i) ≤ K *);\\n  p ← Pj(i ) (* picks appropriate pointer at jth index level *)\\n end;\\n read the data file block whose address is p;\\n search block p for record with key = K;\\nAs we have seen, a multilevel index reduces the number of blocks accessed when \\nsearching for a record, given its indexing field value. We are still faced with the \\nproblems of dealing with index insertions and deletions, because all index levels are \\nphysically ordered files.  To retain the benefits of using multilevel indexing while \\nreducing index insertion and deletion problems, designers adopted a multilevel \\nindex called a dynamic multilevel index that leaves some space in each of its blocks \\nfor inserting new entries and uses appropriate insertion/deletion algorithms for \\ncreating and deleting new index blocks when the data file grows and shrinks. It is \\noften implemented by using data structures called B-trees and B\\n+-trees, which we \\ndescribe in the next section.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 630, 'page_label': '631'}, page_content='17.3 Dynamic Multilevel Indexes Using B-Trees and B +-Trees 617\\n17.3  Dynamic Multilevel Indexes Using  \\nB-Trees and B+-Trees\\nB-trees and B +-trees are special cases of the well-known search data structure \\nknown as a tree. We briefly introduce the terminology used in discussing tree data \\nstructures. A tree is formed of nodes. Each node in the tree, except for a special \\nnode called the root, has one parent node and zero or more child nodes. The root \\nnode has no parent. A node that does not have any child nodes is called a leaf node; \\na nonleaf node is called an internal node. The level of a node is always one more \\nthan the level of its parent, with the level of the root node being zero.7 A subtree of \\na node consists of that node and all its descendant nodes—its child nodes, the child \\nnodes of its child nodes, and so on. A precise recursive definition of a subtree is that \\nit consists of a node n and the subtrees of all the child nodes of n. Figure 17.7 illus-\\ntrates a tree data structure. In this figure the root node is A, and its child nodes are \\nB, C, and D. Nodes E, J, C, G, H, and K are leaf nodes. Since the leaf nodes are at \\ndifferent levels of the tree, this tree is called unbalanced.\\nIn Section 17.3.1, we introduce search trees and then discuss B-trees, which can be \\nused as dynamic multilevel indexes to guide the search for records in a data file. \\nB-tree nodes are kept between 50 and 100 percent full, and pointers to the data \\nblocks are stored in both internal nodes and leaf nodes of the B-tree structure. In \\nSection 17.3.2 we discuss B\\n+-trees, a variation of B-trees in which pointers to the \\ndata blocks of a file are stored only in leaf nodes, which can lead to fewer levels and \\n7This standard definition of the level of a tree node, which we use throughout Section 17 .3, is different \\nfrom the one we gave for multilevel indexes in Section 17 .2.\\nA\\nCB\\nSubtree for node B\\n(Nodes E, J, C, G, H, and K are leaf nodes of the tree)\\nRoot node (level 0)\\nNodes at level 1D\\nNodes at level 2DF I\\nNodes at level 3I\\nHG\\nJ\\nE\\nK\\nFigure 17.7 \\nA tree data structure that shows an unbalanced tree.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 631, 'page_label': '632'}, page_content='618 Chapter 17 Indexing Structures for Files and Physical Database Design\\nhigher-capacity indexes. In the DBMSs prevalent in the market today, the common \\nstructure used for indexing is B+-trees.\\n17.3.1 Search Trees and B-Trees\\nA search tree is a special type of tree that is used to guide the search for a record, \\ngiven the value of one of the record’s fields. The multilevel indexes discussed in Sec-\\ntion 17.2 can be thought of as a variation of a search tree; each node in the multi-\\nlevel index can have as many as fo pointers and fo key values, where fo is the index \\nfan-out. The index field values in each node guide us to the next node, until we \\nreach the data file block that contains the required records. By following a pointer, \\nwe restrict our search at each level to a subtree of the search tree and ignore all \\nnodes not in this subtree.\\nSearch Trees. A search tree is slightly different from a multilevel index. A \\nsearch tree of order  p is a tree such that each node contains at most p  − 1 search \\nvalues and p pointers in the order < P\\n1, K1, P2, K2, … , Pq−1, Kq−1, Pq>, where q ≤ p. \\nEach Pi is a pointer to a child node (or a NULL pointer), and each Ki is a search \\nvalue from some ordered set of values. All search values are assumed to be \\nunique.8 Figure 17.8 illustrates a node in a search tree. Two constraints must hold \\nat all times on the search tree:\\n  1. Within each node, K1 < K2 < … < Kq−1.\\n  2. For all values X in the subtree pointed at by Pi, we have Ki−1 < X < Ki for \\n1 < i < q; X < Ki for i = 1; and Ki−1 < X for i = q (see Figure 17.8).\\nWhenever we search for a value X, we follow the appropriate pointer Pi according \\nto the formulas in condition 2 above. Figure 17.9 illustrates a search tree of order  \\np = 3 and integer search values. Notice that some of the pointers P\\ni in a node may be \\nNULL pointers.\\nWe can use a search tree as a mechanism to search for records stored in a disk file. \\nThe values in the tree can be the values of one of the fields of the file, called the \\n8This restriction can be relaxed. If the index is on a nonkey field, duplicate search values may exist and \\nthe node structure and the navigation rules for the tree may be modified.\\nP1\\nP1\\nK1 Ki–1\\nKq–1 < X\\nX\\nKi–1 < X < Ki\\nX\\nX < K1\\nX\\nPi Ki Kq–1 Pq. . . . . .Figure 17.8 \\nA node in a search \\ntree with pointers to \\nsubtrees below it.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 632, 'page_label': '633'}, page_content='search field (which is the same as the index field if a multilevel index guides the \\nsearch). Each key value in the tree is associated with a pointer to the record in the \\ndata file having that value. Alternatively, the pointer could be to the disk block con-\\ntaining that record. The search tree itself can be stored on disk by assigning each \\ntree node to a disk block. When a new record is inserted in the file, we must update \\nthe search tree by inserting an entry in the tree containing the search field value of \\nthe new record and a pointer to the new record.\\nAlgorithms are necessary for inserting and deleting search values into and from the \\nsearch tree while maintaining the preceding two constraints. In general, these algo-\\nrithms do not guarantee that a search tree is balanced, meaning that all of its leaf \\nnodes are at the same level. 9 The tree in Figure 17.7 is not balanced because it has \\nleaf nodes at levels 1, 2, and 3. The goals for balancing a search tree are as follows:\\n ■ To guarantee that nodes are evenly distributed, so that the depth of the tree \\nis minimized for the given set of keys and that the tree does not get skewed \\nwith some nodes being at very deep levels\\n ■ To make the search speed uniform, so that the average time to find any ran-\\ndom key is roughly the same\\nMinimizing the number of levels in the tree is one goal, another implicit goal is to \\nmake sure that the index tree does not need too much restructuring as records are \\ninserted into and deleted from the main file. Thus we want the nodes to be as full as \\npossible and do not want any nodes to be empty if there are too many deletions. \\nRecord deletion may leave some nodes in the tree nearly empty, thus wasting stor-\\nage space and increasing the number of levels. The B-tree addresses both of these \\nproblems by specifying additional constraints on the search tree.\\nB-Trees. The B-tree has additional constraints that ensure that the tree is always \\nbalanced and that the space wasted by deletion, if any, never becomes excessive. \\nThe algorithms for insertion and deletion, though, become more complex in order \\nto maintain these constraints. Nonetheless, most insertions and deletions are sim-\\nple processes; they become complicated only under special circumstances—namely, \\nwhenever we attempt an insertion into a node that is already full or a deletion from \\n5\\n3\\nTree node pointer\\nNull tree pointer\\n69\\n78 1 21\\nFigure 17.9 \\nA search tree of \\norder p = 3.\\n9The definition of balanced is different for binary trees. Balanced binary trees are known as AVL trees.\\n 17.3 Dynamic Multilevel Indexes Using B-Trees and B +-Trees 619'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 633, 'page_label': '634'}, page_content='620 Chapter 17 Indexing Structures for Files and Physical Database Design\\na node that makes it less than half full. More formally, a B-tree of order  p, when \\nused as an access structure on a key field to search for records in a data file, can be \\ndefined as follows:\\n  1. Each internal node in the B-tree (Figure 17.10(a)) is of the form\\n<P1, <K1, Pr1>, P2, <K2, Pr2>, … , <Kq–1, Prq–1>, Pq>\\nwhere q ≤ p. Each Pi is a tree pointer—a pointer to another node in the \\nB-tree. Each Pri is a data pointer10—a pointer to the record whose search \\nkey field value is equal to Ki (or to the data file block containing that record).\\n  2. Within each node, K1 < K2 < … < Kq−1.\\n  3. For all search key field values X in the subtree pointed at by Pi (the ith sub-\\ntree, see Figure 17.10(a)), we have:\\nKi−1 < X < Ki for 1 < i < q; X < Ki for i = 1; and Ki−1 < X for i = q\\n  4. Each node has at most p tree pointers.\\n  5. Each node, except the root and leaf nodes, has at least ⎡(p/2)⎤ tree pointers. \\nThe root node has at least two tree pointers unless it is the only node in \\nthe tree.\\n  6. A node with q tree pointers, q ≤ p, has q − 1 search key field values (and \\nhence has q − 1 data pointers).\\n  7. All leaf nodes are at the same level. Leaf nodes have the same structure as \\ninternal nodes except that all of their tree pointers Pi are NULL.\\nFigure 17.10(b) illustrates a B-tree of order p = 3. Notice that all search values K in \\nthe B-tree are unique because we assumed that the tree is used as an access structure \\non a key field. If we use a B-tree on a nonkey field, we must change the definition of \\nthe file pointers Pr\\ni to point to a block—or a cluster of blocks—that contain the \\npointers to the file records. This extra level of indirection is similar to option 3, dis-\\ncussed in Section 17.1.3, for secondary indexes.\\nA B-tree starts with a single root node (which is also a leaf node) at level 0 (zero). \\nOnce the root node is full with p − 1 search key values and we attempt to insert \\nanother entry in the tree, the root node splits into two nodes at level 1. Only the \\nmiddle value is kept in the root node, and the rest of the values are split evenly \\nbetween the other two nodes. When a nonroot node is full and a new entry is \\ninserted into it, that node is split into two nodes at the same level, and the middle \\nentry is moved to the parent node along with two pointers to the new split nodes. If \\nthe parent node is full, it is also split. Splitting can propagate all the way to the root \\nnode, creating a new level if the root is split. We do not discuss algorithms for \\nB-trees in detail in this text,\\n11 but we outline search and insertion procedures for \\nB+-trees in the next section.\\n10A data pointer is either a block address or a record address; the latter is essentially a block address \\nand a record offset within the block.\\n11For details on insertion and deletion algorithms for B-trees, consult Ramakrishnan and Gehrke (2003).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 634, 'page_label': '635'}, page_content='If deletion of a value causes a node to be less than half full, it is combined with its \\nneighboring nodes, and this can also propagate all the way to the root. Hence, \\ndeletion can reduce the number of tree levels. It has been shown by analysis and \\nsimulation that, after numerous random insertions and deletions on a B-tree, the \\nnodes are approximately 69% full when the number of values in the tree stabilizes. \\nThis is also true of B\\n+-trees. If this happens, node splitting and combining will \\noccur only rarely, so insertion and deletion become quite efficient. If the number \\nof values grows, the tree will expand without a problem—although splitting of \\nnodes may occur, so some insertions will take more time. Each B-tree node can \\nhave at most p tree pointers, p − 1 data pointers, and p − 1 search key field values \\n(see Figure 17.10(a)).\\nIn general, a B-tree node may contain additional information needed by the algo-\\nrithms that manipulate the tree, such as the number of entries q in the node and a \\npointer to the parent node. Next, we illustrate how to calculate the number of blocks \\nand levels for a B-tree.\\nExample 5. Suppose that the search field is a nonordering key field, and we con-\\nstruct a B-tree on this field with p = 23. Assume that each node of the B-tree is 69% \\nfull. Each node, on the average, will have p * 0.69 = 23 * 0.69 or approximately  \\nX Tree\\npointer\\nTree\\npointer\\nTree\\npointer\\n(a)\\n(b)\\nP2\\nX\\nData\\npointer\\nData\\npointer\\nData\\npointer\\n5 o 8 Tree node pointero\\n6 o 7 o 9 o 12 o\\nData pointer\\nNull tree pointer\\n1 o 3 o  \\nData\\npointer\\nP1 Pr1K1 Ki–1 Prq–1Kq–1\\nX\\nKq–1 < XKi–1 < X < Ki X < K1\\nPi Pq. . . . . . Pri–1 Ki Pri\\nTree\\npointer\\no\\nFigure 17.10 \\nB-tree structures. (a) A node in a B-tree with q − 1 search values. (b) A B-tree of order p = 3. The values were \\ninserted in the order 8, 5, 1, 7, 3, 12, 9, 6.\\n 17.3 Dynamic Multilevel Indexes Using B-Trees and B +-Trees 621'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 635, 'page_label': '636'}, page_content='622 Chapter 17 Indexing Structures for Files and Physical Database Design\\n16 pointers and, hence, 15 search key field values. The average fan-out  fo = 16. \\nWe can start at the root and see how many values and pointers can exist, on the \\naverage, at each subsequent level:\\nRoot: 1 node 15 key entries 16 pointers\\nLevel 1: 16 nodes 240 key entries 256 pointers\\nLevel 2: 256 nodes 3,840 key entries 4,096 pointers\\nLevel 3: 4,096 nodes 61,440 key entries\\nAt each level, we calculated the number of key entries by multiplying the total num-\\nber of pointers at the previous level by 15, the average number of entries in each \\nnode. Hence, for the given block size (512 bytes), record/data pointer size (7 bytes), \\ntree/block pointer size (6 bytes), and search key field size (9bytes), a two-level B-tree \\nof order 23 with 69% occupancy holds 3,840 + 240 + 15 = 4,095 entries on the aver-\\nage; a three-level B-tree holds 65,535 entries on the average.\\nB-trees are sometimes used as primary file organizations . In this case, whole \\nrecords are stored within the B-tree nodes rather than just the <search key, record \\npointer> entries. This works well for files with a relatively small number of records \\nand a small record size. Otherwise, the fan-out and the number of levels become too \\ngreat to permit efficient access.\\nIn summary, B-trees provide a multilevel access structure that is a balanced tree \\nstructure in which each node is at least half full. Each node in a B-tree of order p can \\nhave at most p − 1 search values.\\n17.3.2 B +-Trees\\nMost implementations of a dynamic multilevel index use a variation of the B-tree data \\nstructure called a B+-tree. In a B-tree, every value of the search field appears once at \\nsome level in the tree, along with a data pointer. In a B+-tree, data pointers are stored \\nonly at the leaf nodes of the tree; hence, the structure of leaf nodes differs from the \\nstructure of internal nodes. The leaf nodes have an entry for every value of the search \\nfield, along with a data pointer to the record (or to the block that contains this record) \\nif the search field is a key field. For a nonkey search field, the pointer points to a block \\ncontaining pointers to the data file records, creating an extra level of indirection.\\nThe leaf nodes of the B\\n+-tree are usually linked to provide ordered access on the \\nsearch field to the records. These leaf nodes are similar to the first (base) level of an \\nindex. Internal nodes of the B\\n+-tree correspond to the other levels of a multilevel \\nindex. Some search field values from the leaf nodes are repeated in the internal \\nnodes of the B +-tree to guide the search. The structure of the internal nodes  of a  \\nB+-tree of order p (Figure 17.11(a)) is as follows:\\n  1. Each internal node is of the form\\n<P1, K1, P2, K2, … , Pq − 1, Kq −1, Pq>\\nwhere q ≤ p and each Pi is a tree pointer.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 636, 'page_label': '637'}, page_content='2. Within each internal node, K1 < K2 < … < Kq−1.\\n  3. For all search field values X in the subtree pointed at by Pi, we have Ki−1 < X \\n≤ Ki for 1 < i < q; X ≤ Ki for i = 1; and Ki−1 < X for i = q (see Figure 17.11(a)).12\\n  4. Each internal node has at most p tree pointers.\\n  5. Each internal node, except the root, has at least ⎡(p/2)⎤ tree pointers. The \\nroot node has at least two tree pointers if it is an internal node.\\n  6. An internal node with q pointers, q ≤ p, has q − 1 search field values.\\nThe structure of the leaf nodes of a B+-tree of order p (Figure 17.11(b)) is as follows:\\n  1. Each leaf node is of the form\\n<<K1, Pr1>, <K2, Pr2>, … , <Kq−1, Prq−1>, Pnext>\\nwhere q ≤ p, each Pri is a data pointer, and Pnext points to the next leaf node \\nof the B+-tree.\\n  2. Within each leaf node, K1 ≤ K2 … , Kq−1, q ≤ p.\\n  3. Each Pri is a data pointer that points to the record whose search field value is \\nKi or to a file block containing the record (or to a block of record pointers that \\npoint to records whose search field value is Ki if the search field is not a key).\\n  4. Each leaf node has at least ⎡(p/2)⎤ values.\\n  5. All leaf nodes are at the same level.\\n12Our definition follows Knuth (1998). One can define a B+-tree differently by exchanging the < and ≤ \\nsymbols (Ki−1 ≤ X < Ki; Kq−1 ≤ X), but the principles remain the same.\\n(b) Pointer to \\nnext leaf \\nnode in \\ntree\\nData\\npointer\\nData\\npointer\\nData\\npointer\\nData\\npointer\\nPr1K1 Pr2K2 Pri Prq–1 PnextKi Kq–1. . . . . .\\n(a) P1 K1 Ki–1\\nKq–1 < X\\nXX\\n X < K1\\nX\\nPi Ki Kq–1 Pq. . . . . .\\nTree\\npointer\\nTree\\npointer\\nTree\\npointer\\nKi–1 < X < Ki\\nFigure 17.11 \\nThe nodes of a B+-tree. (a) Internal node of a B+-tree with q − 1 search values. (b) Leaf node of a B+-tree with q − 1 \\nsearch values and q − 1 data pointers.\\n 17.3 Dynamic Multilevel Indexes Using B-Trees and B +-Trees 623'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 637, 'page_label': '638'}, page_content='624 Chapter 17 Indexing Structures for Files and Physical Database Design\\nThe pointers in internal nodes are tree pointers to blocks that are tree nodes, whereas \\nthe pointers in leaf nodes are data pointers to the data file records or blocks—except \\nfor the Pnext pointer, which is a tree pointer to the next leaf node. By starting at the \\nleftmost leaf node, it is possible to traverse leaf nodes as a linked list, using the Pnext \\npointers. This provides ordered access to the data records on the indexing field. A \\nP\\nprevious pointer can also be included. For a B+-tree on a nonkey field, an extra level \\nof indirection is needed similar to the one shown in Figure 17.5, so the Pr pointers \\nare block pointers to blocks that contain a set of record pointers to the actual \\nrecords in the data file, as discussed in option 3 of Section 17.1.3.\\nBecause entries in the internal nodes  of a B\\n+-tree include search values and tree \\npointers without any data pointers, more entries can be packed into an internal \\nnode of a B\\n+-tree than for a similar B-tree. Thus, for the same block (node) size, the \\norder p will be larger for the B+-tree than for the B-tree, as we illustrate in Example 6. \\nThis can lead to fewer B+-tree levels, improving search time. Because the structures \\nfor internal and for leaf nodes of a B+-tree are different, the order p can be different. \\nWe will use p to denote the order for internal nodes  and pleaf to denote the order \\nfor leaf nodes, which we define as being the maximum number of data pointers in \\na leaf node.\\nExample 6. To calculate the order p of a B+-tree, suppose that the search key field \\nis V = 9 bytes long, the block size is B = 512 bytes, a record pointer is Pr = 7 bytes, \\nand a block pointer/tree pointer is P = 6 bytes. An internal node of the B +-tree can \\nhave up to p tree pointers and p − 1 search field values; these must fit into a single \\nblock. Hence, we have:\\n(p * P) + ((p − 1) * V) ≤ B\\n(p * 6) + ((p − 1) * 9) ≤ 512\\n(15 * p) ≤ 512\\nWe can choose p to be the largest value satisfying the above inequality, which gives \\np = 34. This is larger than the value of 23 for the B-tree (it is left to the reader to \\ncompute the order of the B-tree assuming same size pointers), resulting in a larger \\nfan-out and more entries in each internal node of a B\\n+-tree than in the correspond-\\ning B-tree. The leaf nodes of the B +-tree will have the same number of values and \\npointers, except that the pointers are data pointers and a next pointer. Hence, the \\norder p\\nleaf for the leaf nodes can be calculated as follows:\\n(pleaf * (Pr + V)) + P ≤ B\\n(pleaf * (7 + 9)) + 6 ≤ 512\\n(16 * pleaf) ≤ 506\\nIt follows that each leaf node can hold up to pleaf = 31 key value/data pointer combi-\\nnations, assuming that the data pointers are record pointers.\\nAs with the B-tree, we may need additional information—to implement the inser-\\ntion and deletion algorithms—in each node. This information can include the type \\nof node (internal or leaf), the number of current entries q in the node, and pointers \\nto the parent and sibling nodes. Hence, before we do the above calculations for p'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 638, 'page_label': '639'}, page_content='and pleaf, we should reduce the block size by the amount of space needed for all such \\ninformation. The next example illustrates how we can calculate the number of \\nentries in a B\\n+-tree.\\nExample 7. Suppose that we construct a B +-tree on the field in Example 6. To  \\ncalculate the approximate number of entries in the B +- t r e e ,  w e  a s s u m e  t h a t  e a c h  \\nnode is 69% full. On the average, each internal node will have 34 * 0.69 or approxi-\\nmately 23 pointers, and hence 22 values. Each leaf node, on the average, will hold  \\n0.69 * p\\nleaf = 0.69 * 31 or approximately 21 data record pointers. A B+-tree will have \\nthe following average number of entries at each level:\\nRoot: 1 node 22 key entries 23 pointers\\nLevel 1: 23 nodes 506 key entries 529 pointers\\nLevel 2: 529 nodes 11,638 key entries 12,167 pointers\\nLeaf level: 12,167 nodes 255,507 data record pointers\\nFor the block size, pointer size, and search field size as in Example 6, a three-level \\nB+-tree holds up to 255,507 record pointers, with the average 69% occupancy of \\nnodes. Note that we considered the leaf node differently from the nonleaf nodes \\nand computed the data pointers in the leaf node to be 12,167 * 21 based on 69% \\noccupancy of the leaf node, which can hold 31 keys with data pointers. Compare \\nthis to the 65,535 entries for the corresponding B-tree in Example 5. Because a \\nB-tree includes a data/record pointer along with each search key at all levels of \\nthe tree, it tends to accommodate less number of keys for a given number of \\nindex levels. This is the main reason that B\\n+-trees are preferred to B-trees as \\nindexes to database files. Most DBMSs, such as Oracle, are creating all indexes as \\nB\\n+-trees.\\nSearch, Insertion, and Deletion with B +-Trees. Algorithm 17.2 outlines the \\nprocedure using the B +-tree as the access structure to search for a record. Algo-\\nrithm 17.3 illustrates the procedure for inserting a record in a file with a B +-tree \\naccess structure. These algorithms assume the existence of a key search field, and \\nthey must be modified appropriately for the case of a B\\n+-tree on a nonkey field. We \\nillustrate insertion and deletion with an example.\\nAlgorithm 17.2. Searching for a Record with Search Key Field Value K, Using \\na B+-Tree\\nn ← block containing root node of B+-tree;\\nread block n;\\nwhile (n is not a leaf node of the B+-tree) do\\n begin\\n q ← number of tree pointers in node n;\\n if K ≤ n.K1 (*n.Ki refers to the ith search field value in node n*)\\n  then n ← n.P1 (*n.Pi refers to the ith tree pointer in node n*)\\n  else if K > n.Kq−1\\n   then n ← n.Pq\\n 17.3 Dynamic Multilevel Indexes Using B-Trees and B +-Trees 625'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 639, 'page_label': '640'}, page_content='626 Chapter 17 Indexing Structures for Files and Physical Database Design\\n   else begin\\n    search node n for an entry i such that n.Ki−1 < K ≤n.Ki;\\n     n ← n.Pi\\n     end;\\n read block n\\n end;\\nsearch block n for entry (Ki, Pri) with K = Ki; (* search leaf node *)\\nif found\\n then read data file block with address Pri and retrieve record\\n else the record with search field value K is not in the data file;\\nAlgorithm 17.3.  Inserting a Record with Search Key Field Value K in a \\nB+-Tree of Order p\\nn ← block containing root node of B+-tree;\\nread block n; set stack S to empty;\\nwhile (n is not a leaf node of the B+-tree) do\\n begin\\n push address of n on stack S;\\n  (*stack S holds parent nodes that are needed in case of split*)\\n q ← number of tree pointers in node n;\\n if K ≤n.K1 (*n.Ki refers to the ith search field value in node n*)\\n  then n ← n.P1 (*n.Pi refers to the ith tree pointer in node n*)\\n  else if K ← n.Kq−1\\n   then n ← n.Pq\\n   else begin\\n    search node n for an entry i such that n.Ki−1 < K ≤n.Ki;\\n    n ← n.Pi\\n    end;\\n  read block n\\n end;\\nsearch block n for entry (Ki,Pri) with K = Ki; (*search leaf node n*)\\nif found\\n then record already in file; cannot insert\\n else (*insert entry in B+-tree to point to record*)\\n  begin\\n  create entry (K, Pr) where Pr points to the new record;\\n  if leaf node n is not full\\n   then insert entry (K, Pr) in correct position in leaf node n\\n   else begin (*leaf node n is full with pleaf record pointers; is split*)\\n    copy n to temp (*temp is an oversize leaf node to hold extra entries*);\\n    insert entry (K, Pr) in temp in correct position;\\n    (*temp now holds pleaf + 1 entries of the form (Ki, Pri)*)\\n    new ← a new empty leaf node for the tree; new.Pnext ← n.Pnext ;\\n    j ← ⎡(pleaf + 1)/2 ⎤ ;\\n    n ← first j entries in temp (up to entry (Kj, Prj)); n.Pnext ← new;'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 640, 'page_label': '641'}, page_content='new ← remaining entries in temp; K ← Kj ;\\n   (* now we must move ( K, new) and insert in parent internal node;  \\nhowever, if parent is full, split may propagate*)\\n   finished ← false;\\n   repeat\\n   if stack S is empty\\n    then (←no parent node; new root node is created for the tree*)\\n     begin\\n     root ← a new empty internal node for the tree;\\n     root ← <n, K, new>; finished ← true;\\n     end\\n    else begin\\n     n ← pop stack S;\\n     if internal node n is not full\\n      then\\n       begin (*parent node not full; no split*)\\n       insert (K, new) in correct position in internal node n;\\n       finished ← true\\n       end\\n      else begin (* internal node n is full with p tree pointers;  \\noverflow condition; node is split*)\\n      copy n to temp (*temp is an oversize internal node*);\\n      insert (K, new) in temp in correct position;\\n      (*temp now has p + 1 tree pointers*)\\n      new ← a new empty internal node for the tree;\\n      j ← ⎣((p + 1)/2⎦ ;\\n      n ← entries up to tree pointer Pj in temp;\\n      (*n contains <P1, K1, P2, K2, … , Pj−1, Kj−1, Pj >*)\\n      new ← entries from tree pointer Pj+1 in temp;\\n      (*new contains < Pj+1, Kj+1, … , Kp−1, Pp, Kp, Pp+1 >*)\\n      K ← Kj\\n      (* now we must move (K, new) and insert in  \\nparentinternal node*)\\n    end\\n   end\\n  until finished\\n  end;\\n end;\\nFigure 17.12 illustrates insertion of records in a B+-tree of order p = 3 and pleaf = 2. First, \\nwe observe that the root is the only node in the tree, so it is also a leaf node. As soon as \\nmore than one level is created, the tree is divided into internal nodes and leaf nodes. \\nNotice that every key value must exist at the leaf level, because all data pointers are at the \\nleaf level. However, only some values exist in internal nodes to guide the search. Notice \\nalso that every value appearing in an internal node also appears as the rightmost value in \\nthe leaf level of the subtree pointed at by the tree pointer to the left of the value.\\n 17.3 Dynamic Multilevel Indexes Using B-Trees and B +-Trees 627'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 641, 'page_label': '642'}, page_content='628 Chapter 17 Indexing Structures for Files and Physical Database Design\\n5 0 8 Insert 1: overflow (new level)0\\n5\\n1 0 5 0 8 0\\n5\\n3 5\\n5\\n3\\n3\\n8\\n3 7 8\\n8\\nTree node pointer\\nData pointer\\nNull tree pointerInsert 7\\nInsert 9\\nInsert 6: overflow (split, propagates)\\nInsert 3: overflow\\n(split)\\nInsert 12: overflow (split, propagates,\\nnew level)\\n1 0 5 0 7 0 8 0\\n1 0 5 0\\n5 0 12 0\\n3 0\\n1 0 3 0\\n5 01 0 3 0\\n7 0 8 0\\n7 0 8 0\\n12 09 07 0 8 0\\n5\\n5\\n5 01 0 3 0 8 0 12 09 06 0 7 0\\nInsertion sequence: 8, 5, 1, 7 , 3, 12, 9, 6\\n0\\nFigure 17.12 \\nAn example of insertion in a B\\n+-tree with p = 3 and pleaf = 2.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 642, 'page_label': '643'}, page_content='When a leaf node is full and a new entry is inserted there, the node overflows and \\nmust be split. The first j = ⎡((pleaf + 1)/2)⎤ entries in the original node are kept there, \\nand the remaining entries are moved to a new leaf node. The jth search value is \\nreplicated in the parent internal node, and an extra pointer to the new node is cre-\\nated in the parent. These must be inserted in the parent node in their correct \\nsequence. If the parent internal node is full, the new value will cause it to overflow \\nalso, so it must be split. The entries in the internal node up to P\\nj—the jth tree pointer \\nafter inserting the new value and pointer, where j = ⎣((p + 1)/2)⎦—are kept, whereas the \\njth search value is moved to the parent, not replicated. A new internal node will hold the \\nentries from Pj+1 to the end of the entries in the node (see Algorithm 17.3). This \\nsplitting can propagate all the way up to create a new root node and hence a new \\nlevel for the B\\n+-tree.\\nFigure 17.13 illustrates deletion from a B +-tree. When an entry is deleted, it is \\nalways removed from the leaf level. If it happens to occur in an internal node, it \\nmust also be removed from there. In the latter case, the value to its left in the leaf \\nnode must replace it in the internal node because that value is now the rightmost \\nentry in the subtree. Deletion may cause underflow by reducing the number of \\nentries in the leaf node to below the minimum required. In this case, we try to find \\na sibling leaf node—a leaf node directly to the left or to the right of the node with \\nunderflow—and redistribute the entries among the node and its sibling so that \\nboth are at least half full; otherwise, the node is merged with its siblings and the \\nnumber of leaf nodes is reduced. A common method is to try to redistribute  \\nentries with the left sibling; if this is not possible, an attempt to redistribute with \\nthe right sibling is made. If this is also not possible, the three nodes are merged \\ninto two leaf nodes. In such a case, underflow may propagate to internal nodes \\nbecause one fewer tree pointer and search value are needed. This can propagate \\nand reduce the tree levels.\\nNotice that implementing the insertion and deletion algorithms may require par-\\nent and sibling pointers for each node, or the use of a stack as in Algorithm 17.3. \\nEach node should also include the number of entries in it and its type (leaf or \\ninternal). Another alternative is to implement insertion and deletion as recursive \\nprocedures.\\n13\\nVariations of B-Trees and B+-Trees. To conclude this section, we briefly men-\\ntion some variations of B-trees and B +-trees. In some cases, constraint 5 on the \\nB-tree (or for the internal nodes of the B +–tree, except the root node), which \\nrequires each node to be at least half full, can be changed to require each node to be \\nat least two-thirds full. In this case the B-tree has been called a B*-tree. In general, \\nsome systems allow the user to choose a fill factor between 0.5 and 1.0, where the \\nlatter means that the B-tree (index) nodes are to be completely full. It is also possi-\\nble to specify two fill factors for a B\\n+-tree: one for the leaf level and one for the \\ninternal nodes of the tree. When the index is first constructed, each node is filled up \\n13For more details on insertion and deletion algorithms for B +-trees, consult Ramakrishnan and \\nGehrke (2003).\\n 17.3 Dynamic Multilevel Indexes Using B-Trees and B +-Trees 629'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 643, 'page_label': '644'}, page_content='630 Chapter 17 Indexing Structures for Files and Physical Database Design\\n7\\n16\\n7\\n16 9\\nDeletion sequence: 5, 12, 9\\n1 o 5 o 6\\nDelete 5\\no 8 o 9 o 12 o7 o\\n1 o 6 o 8 o 9 o 12 o7 o\\n9\\n7\\n16 8\\n1 o 6 o 8 o 9 o7 o\\nDelete 12: underflow\\n(redistribute)\\nDelete 9: underflow\\n(merge with left, redistribute)6\\n1 7\\n1 o 6 o 8 o7 o\\nFigure 17.13 \\nAn example of deletion from a B+-tree.\\nto approximately the fill factors specified. Some investigators have suggested relax-\\ning the requirement that a node be half full, and instead allow a node to become \\ncompletely empty before merging, to simplify the deletion algorithm. Simulation \\nstudies show that this does not waste too much additional space under randomly \\ndistributed insertions and deletions.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 644, 'page_label': '645'}, page_content='17.4 Indexes on Multiple Keys  631\\n17.4 Indexes on Multiple Keys\\nIn our discussion so far, we have assumed that the primary or secondary keys on \\nwhich files were accessed were single attributes (fields). In many retrieval and \\nupdate requests, multiple attributes are involved. If a certain combination of attri-\\nbutes is used frequently, it is advantageous to set up an access structure to provide \\nefficient access by a key value that is a combination of those attributes.\\nFor example, consider an \\nEMPLOYEE file containing attributes Dno (department \\nnumber), Age, Street, City, Zip_code, Salary and Skill_code, with the key of Ssn (Social \\nSecurity number). Consider the query: List the employees in department number 4 \\nwhose age is 59 . Note that both Dno and Age are nonkey attributes, which means \\nthat a search value for either of these will point to multiple records. The following \\nalternative search strategies may be considered:\\n  1. Assuming Dno has an index, but Age does not, access the records having \\nDno = 4 using the index, and then select from among them those records \\nthat satisfy Age = 59.\\n  2. Alternately, if Age is indexed but Dno is not, access the records having  \\nAge = 59 using the index, and then select from among them those records that \\nsatisfy Dno = 4.\\n  3. If indexes have been created on both Dno and Age, both indexes may be \\nused; each gives a set of records or a set of pointers (to blocks or records). An \\nintersection of these sets of records or pointers yields those records or point-\\ners that satisfy both conditions.\\nAll of these alternatives eventually give the correct result. However, if the set of \\nrecords that meet each condition (\\nDno = 4 or Age = 59) individually are large, yet \\nonly a few records satisfy the combined condition, then none of the above is an effi-\\ncient technique for the given search request. Note also that queries such as “find the \\nminimum or maximum age among all employees” can be answered just by using the \\nindex on Age, without going to the data file. Finding the maximum or minimum age \\nwithin Dno = 4, however, would not be answerable just by processing the index \\nalone. Also, listing the departments in which employees with Age = 59 work will also \\nnot be possible by processing just the indexes. A number of possibilities exist that \\nwould treat the combination <\\nDno, Age> or <Age, Dno> as a search key made up of \\nmultiple attributes. We briefly outline these techniques in the following sections. We \\nwill refer to keys containing multiple attributes as composite keys.\\n17.4.1 Ordered Index on Multiple Attributes\\nAll the discussion in this chapter so far still applies if we create an index on a search \\nkey field that is a combination of < Dno, Age>. The search key is a pair of values  \\n<4, 59> in the above example. In general, if an index is created on attributes  \\n<A1, A2, … , An>, the search key values are tuples with n values: <v1, v2, … , vn>.\\nA lexicographic ordering of these tuple values establishes an order on this compos-\\nite search key. For our example, all of the department keys for department number'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 645, 'page_label': '646'}, page_content='632 Chapter 17 Indexing Structures for Files and Physical Database Design\\n3 precede those for department number 4. Thus <3, n> precedes <4, m> for any \\nvalues of m and n. The ascending key order for keys with Dno = 4 would be <4, 18>, \\n<4, 19>, <4, 20>, and so on. Lexicographic ordering works similarly to ordering of \\ncharacter strings. An index on a composite key of n attributes works similarly to \\nany index discussed in this chapter so far.\\n17.4.2 Partitioned Hashing\\nPartitioned hashing is an extension of static external hashing (Section 16.8.2) that \\nallows access on multiple keys. It is suitable only for equality comparisons; range \\nqueries are not supported. In partitioned hashing, for a key consisting of n compo-\\nnents, the hash function is designed to produce a result with n separate hash \\naddresses. The bucket address is a concatenation of these n addresses. It is then pos-\\nsible to search for the required composite search key by looking up the appropriate \\nbuckets that match the parts of the address in which we are interested.\\nFor example, consider the composite search key <\\nDno, Age>. If Dno and Age are \\nhashed into a 3-bit and 5-bit address respectively, we get an 8-bit bucket address. \\nSuppose that Dno = 4 has a hash address ‘100’ and Age = 59 has hash address ‘10101’. \\nThen to search for the combined search value, Dno = 4 and Age = 59, one goes to \\nbucket address 100 10101; just to search for all employees with Age = 59, all buckets \\n(eight of them) will be searched whose addresses are ‘000 10101’, ‘001 10101’, … \\nand so on. An advantage of partitioned hashing is that it can be easily extended to \\nany number of attributes. The bucket addresses can be designed so that high-order \\nbits in the addresses correspond to more frequently accessed attributes. Addition-\\nally, no separate access structure needs to be maintained for the individual attri-\\nbutes. The main drawback of partitioned hashing is that it cannot handle range \\nqueries on any of the component attributes. Additionally, most hash functions do \\nnot maintain records in order by the key being hashed. Hence, accessing records in \\nlexicographic order by a combination of attributes such as <\\nDno, Age> used as a key \\nwould not be straightforward or efficient.\\n17.4.3 Grid Files\\nAnother alternative is to organize the EMPLOYEE file as a grid file. If we want to \\naccess a file on two keys, say Dno and Age as in our example, we can construct a grid \\narray with one linear scale (or dimension) for each of the search attributes. Fig-\\nure 17.14 shows a grid array for the EMPLOYEE file with one linear scale for Dno and \\nanother for the Age attribute. The scales are made in a way as to achieve a uniform \\ndistribution of that attribute. Thus, in our example, we show that the linear scale for \\nDno has Dno = 1, 2 combined as one value 0 on the scale, whereas Dno = 5 corre-\\nsponds to the value 2 on that scale. Similarly, Age is divided into its scale of 0 to 5 by \\ngrouping ages so as to distribute the employees uniformly by age. The grid array \\nshown for this file has a total of 36 cells. Each cell points to some bucket address \\nwhere the records corresponding to that cell are stored. Figure 17.14 also shows the \\nassignment of cells to buckets (only partially).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 646, 'page_label': '647'}, page_content='17.5 Other Types of Indexes  633\\nThus our request for Dno = 4 and Age = 59 maps into the cell (1, 5) corresponding \\nto the grid array. The records for this combination will be found in the correspond-\\ning bucket. This method is particularly useful for range queries that would map into \\na set of cells corresponding to a group of values along the linear scales. If a range \\nquery corresponds to a match on the some of the grid cells, it can be processed by \\naccessing exactly the buckets for those grid cells. For example, a query for \\nDno ≤ 5 \\nand Age > 40 refers to the data in the top bucket shown in Figure 17.14.\\nThe grid file concept can be applied to any number of search keys. For example, for \\nn search keys, the grid array would have n dimensions. The grid array thus allows a \\npartitioning of the file along the dimensions of the search key attributes and provides \\nan access by combinations of values along those dimensions. Grid files perform well \\nin terms of reduction in time for multiple key access. However, they represent a \\nspace overhead in terms of the grid array structure. Moreover, with dynamic files, a \\nfrequent reorganization of the file adds to the maintenance cost.\\n14\\n17.5 Other Types of Indexes\\n17.5.1 Hash Indexes\\nIt is also possible to create access structures similar to indexes that are based on \\nhashing. The hash index is a secondary structure to access the file by using hashing \\non a search key other than the one used for the primary data file organization. The \\nindex entries are of the type < K, Pr> or <K, P>, where Pr is a pointer to the record \\ncontaining the key, or P is a pointer to the block containing the record for that key. \\nThe index file with these index entries can be organized as a dynamically expand-\\nable hash file, using one of the techniques described in Section 16.8.3; searching for \\nan entry uses the hash search algorithm on K. Once an entry is found, the pointer Pr \\nLinear Scale for Age\\nEMPLOYEE file Bucket pool\\nBucket pool\\n4\\n5\\n3\\n2\\n1\\n0\\n01234 5\\n< 20 21–25 26–30 31–40 41–50 > 50\\n01234 5\\nDno\\nLinear scale\\nfor Dno\\n0 1, 2\\n3, 4\\n5\\n6, 7\\n8\\n9, 10\\n1\\n2\\n3\\n4\\n5\\nFigure 17.14 \\nExample of a grid array on \\nDno and Age attributes.\\n14Insertion/deletion algorithms for grid files may be found in Nievergelt et al. (1984).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 647, 'page_label': '648'}, page_content='634 Chapter 17 Indexing Structures for Files and Physical Database Design\\n(or P) is used to locate the corresponding record in the data file. Figure 17.15 illus-\\ntrates a hash index on the Emp_id field for a file that has been stored as a sequential \\nfile ordered by Name. The Emp_id is hashed to a bucket number by using a hashing \\nfunction: the sum of the digits of Emp_id modulo 10. For example, to find Emp_id \\n51024, the hash function results in bucket number 2; that bucket is accessed first. It \\ncontains the index entry < 51024, Pr >; the pointer Pr leads us to the actual record \\nin the file. In a practical application, there may be thousands of buckets; the bucket \\nnumber, which may be several bits long, would be subjected to the directory \\nschemes discussed in the context of dynamic hashing in Section 16.8.3. Other \\nsearch structures can also be used as indexes.\\n17.5.2 Bitmap Indexes\\nThe bitmap index  is another popular data structure that facilitates querying on \\nmultiple keys. Bitmap indexing is used for relations that contain a large number of \\nrows. It creates an index for one or more columns, and each value or value range in \\nBucket 0 Emp_id\\n. . . . . . . . . .\\n12676 Marcus M . .\\n. . . . . . . . . .\\n13646 Hanson M . .\\n. . . . . . . . . .\\n21124 Dunhill M . .\\n. . . . . . . . . .\\n23402 Clarke F . .\\n. . . . . . . . . .\\n34723 Ferragamo F . .\\n. . . . . . . . . .\\n41301 Zara F . .\\n. . . . . . . . . . \\n51024 Bass M . .\\n. . . . . . . . . .\\n62104 England M . .\\n. . . . . . . . . .\\n71221 Abercombe F . .\\n. . . . . . . . . .\\n81165 Gucci F . .\\n. . . . . . . . . .\\n13646\\n21124\\n. . . . .\\nLastname Sex    . . . . .\\nBucket 1\\n23402\\n81165\\n. . . . .\\nBucket 2\\n51024\\n12676\\n. . . . .\\nBucket 3\\n62104\\n71221\\n. . . . .\\nBucket 9\\n34723\\n41301\\n. . . . .\\nFigure 17.15 \\nHash-based \\nindexing.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 648, 'page_label': '649'}, page_content='17.5 Other Types of Indexes  635\\nthose columns is indexed. Typically, a bitmap index is created for those columns \\nthat contain a fairly small number of unique values. To build a bitmap index on a \\nset of records in a relation, the records must be numbered from 0 to n with an id (a \\nrecord id or a row id) that can be mapped to a physical address made of a block \\nnumber and a record offset within the block.\\nA bitmap index is built on one particular value of a particular field (the column in \\na relation) and is just an array of bits. Thus, for a given field, there is one separate \\nbitmap index (or a vector) maintained corresponding to each unique value in the \\ndatabase. Consider a bitmap index for the column C and a value V for that column. \\nFor a relation with n rows, it contains n bits. The ith bit is set to 1 if the row i has the \\nvalue V for column C; otherwise it is set to a 0. If C contains the valueset <v\\n1, v2, … , \\nvm> with m distinct values, then m bitmap indexes would be created for that col-\\numn. Figure 17.16 shows the relation EMPLOYEE with columns Emp_id, Lname, Sex, \\nZipcode, and Salary_grade (with just eight rows for illustration) and a bitmap index \\nfor the Sex and Zipcode columns. As an example, if the bitmap for Sex = F, the bits \\nfor Row_ids 1, 3, 4, and 7 are set to 1, and the rest of the bits are set to 0, the bitmap \\nindexes could have the following query applications:\\n ■ For the query C1 = V1, the corresponding bitmap for value V1 returns the \\nRow_ids containing the rows that qualify.\\n ■ For the query C1= V1 and C2 = V2 (a multikey search request), the two cor-\\nresponding bitmaps are retrieved and intersected (logically AND-ed) to \\nyield the set of Row_ids that qualify. In general, k bitvectors can be inter-\\nsected to deal with k equality conditions. Complex AND-OR conditions can \\nalso be supported using bitmap indexing.\\n /box4For the query C1 = V1 or C2 = V2 or C3 = V3 (a multikey search request), \\nthe three corresponding bitmaps for three different attributes are retrieved \\nand unioned (logically OR-ed) to yield the set of Row ids that qualify.\\nEMPLOYEE\\nRow_id Emp_id Lname Sex Zipcode Salary_grade\\n0 51024 Bass M 94040 ..\\n1 23402 Clarke F 30022 ..\\n2 62104 England M 19046 ..\\n3 34723 Ferragamo F 30022 ..\\n4 81165 Gucci F 19046 ..\\n5 13646 Hanson M 19046 ..\\n6 12676 Marcus M 30022 ..\\n7 41301 Zara F 94040 ..\\nBitmap index for Sex\\n        M          F\\n10100110 01011001\\nBitmap index for Zipcode\\nZipcode 19046 Zipcode 30022 Zipcode 94040\\n    00101100     01010010     10000001\\nFigure 17.16 \\nBitmap indexes for \\nSex and Zipcode.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 649, 'page_label': '650'}, page_content='636 Chapter 17 Indexing Structures for Files and Physical Database Design\\n ■ To retrieve a count of rows that qualify for the condition C1 = V1, the “1” \\nentries in the corresponding bitvector are counted.\\n ■ Queries with negation, such as C1 ¬ = V1, can be handled by applying the \\nBoolean complement operation on the corresponding bitmap.\\nConsider the example relation EMPLOYEE in Figure 17.16 with bitmap indexes \\non Sex and Zipcode. To find employees with Sex = F and Zipcode = 30022, we \\nintersect the bitmaps “01011001” and “01010010” yielding Row_id s 1 and 3. \\nEmployees who do not live in Zipcode = 94040 are obtained by complementing \\nthe bitvector “10000001” and yields Row_ids 1 through 6. In general, if we assume \\nuniform distribution of values for a given column, and if one column has 5 distinct \\nvalues and another has 10 distinct values, the join condition on these two can be \\nconsidered to have a selectivity of 1/50 (= 1/5 * 1/10). Hence, only about 2% of the \\nrecords would actually have to be retrieved. If a column has only a few values, like \\nthe \\nSex column in Figure 17.16, retrieval of the Sex = M condition on average \\nwould retrieve 50% of the rows; in such cases, it is better to do a complete scan \\nrather than use bitmap indexing.\\nIn general, bitmap indexes are efficient in terms of the storage space that they need. \\nIf we consider a file of 1 million rows (records) with record size of 100 bytes per \\nrow, each bitmap index would take up only one bit per row and hence would use 1 \\nmillion bits or 125 Kbytes. Suppose this relation is for 1 million residents of a state, \\nand they are spread over 200 ZIP Codes; the 200 bitmaps over \\nZipcodes contribute \\n200 bits (or 25 bytes) worth of space per row; hence, the 200 bitmaps occupy only \\n25% as much space as the data file. They allow an exact retrieval of all residents who \\nlive in a given ZIP Code by yielding their Row_ids.\\nWhen records are deleted, renumbering rows and shifting bits in bitmaps becomes \\nexpensive. Another bitmap, called the existence bitmap, can be used to avoid this \\nexpense. This bitmap has a 0 bit for the rows that have been deleted but are still \\nphysically present and a 1 bit for rows that actually exist. Whenever a row is inserted \\nin the relation, an entry must be made in all the bitmaps of all the columns that have \\na bitmap index; rows typically are appended to the relation or may replace deleted \\nrows to minimize the impact on the reorganization of the bitmaps. This process still \\nconstitutes an indexing overhead.\\nLarge bitvectors are handled by treating them as a series of 32-bit or 64-bit vectors, \\nand corresponding AND, OR, and NOT operators are used from the instruction set \\nto deal with 32- or 64-bit input vectors in a single instruction. This makes bitvector \\noperations computationally very efficient.\\nBitmaps for B\\n+-Tree Leaf Nodes. Bitmaps can be used on the leaf nodes of  \\nB+-tree indexes as well as to point to the set of records that contain each specific value \\nof the indexed field in the leaf node. When the B +-tree is built on a nonkey search \\nfield, the leaf record must contain a list of record pointers alongside each value of \\nthe indexed attribute. For values that occur very frequently, that is, in a large per-\\ncentage of the relation, a bitmap index may be stored instead of the pointers. As an'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 650, 'page_label': '651'}, page_content='17.5 Other Types of Indexes  637\\nexample, for a relation with n rows, suppose a value occurs in 10% of the file records. \\nA bitvector would have n bits, having the “1” bit for those Row_ids that contain that \\nsearch value, which is n/8 or 0.125 n bytes in size. If the record pointer takes up 4 \\nbytes (32 bits), then the n/10 record pointers would take up 4 * n/10 or 0.4n bytes. \\nSince 0.4n is more than 3 times larger than 0.125 n, it is better to store the bitmap \\nindex rather than the record pointers. Hence for search values that occur more fre-\\nquently than a certain ratio (in this case that would be 1/32), it is beneficial to use \\nbitmaps as a compressed storage mechanism for representing the record pointers in \\nB\\n+-trees that index a nonkey field.\\n17.5.3 Function-Based Indexing\\nIn this section, we discuss a new type of indexing, called function-based indexing, \\nthat has been introduced in the Oracle relational DBMS as well as in some other \\ncommercial products.\\n15\\nThe idea behind function-based indexing is to create an index such that the value \\nthat results from applying some function on a field or a collection of fields becomes \\nthe key to the index. The following examples show how to create and use function-\\nbased indexes.\\nExample 1. The following statement creates a function-based index on the \\nEMPLOYEE table based on an uppercase representation of the Lname column, which \\ncan be entered in many ways but is always queried by its uppercase representation.\\nCREATE INDEX upper_ix ON Employee (UPPER(Lname));\\nThis statement will create an index based on the function UPPER(Lname), which returns \\nthe last name in uppercase letters; for example, UPPER(\\'Smith\\') will return ‘SMITH’ .\\nFunction-based indexes ensure that Oracle Database system will use the index \\nrather than perform a full table scan, even when a function is used in the search \\npredicate of a query. For example, the following query will use the index:\\nSELECT First_name, Lname\\nFROM Employee\\nWHERE UPPER(Lname)= \"SMITH\".\\nWithout the function-based index, an Oracle Database might perform a full table \\nscan, since a B+-tree index is searched only by using the column value directly; the \\nuse of any function on a column prevents such an index from being used.\\nExample 2. In this example, the EMPLOYEE table is supposed to contain two \\nfields—salary and commission_pct (commission percentage)—and an index is being \\ncreated on the sum of salary and commission based on the commission_pct.\\nCREATE INDEX income_ix\\nON Employee(Salary + (Salary*Commission_pct));\\n15Rafi Ahmed contributed most of this section.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 651, 'page_label': '652'}, page_content='638 Chapter 17 Indexing Structures for Files and Physical Database Design\\nThe following query uses the income_ix index even though the fields salary and \\ncommission_pct are occurring in the reverse order in the query when compared to \\nthe index definition.\\nSELECT First_name, Lname\\nFROM Employee\\nWHERE ((Salary*Commission_pct) + Salary ) > 15000;\\nExample 3. This is a more advanced example of using function-based indexing \\nto define conditional uniqueness. The following statement creates a unique func-\\ntion-based index on the \\nORDERS table that prevents a customer from taking \\nadvantage of a promotion id (“blowout sale”) more than once. It creates a compos-\\nite index on the \\nCustomer_id and Promotion_id fields together, and it allows only one \\nentry in the index for a given Customer_id with the Promotion_id of “2” by declaring \\nit as a unique index.\\nCREATE UNIQUE INDEX promo_ix ON Orders\\n(CASE WHEN Promotion_id = 2 THEN Customer_id ELSE NULL END,\\nCASE WHEN Promotion_id = 2 THEN Promotion_id ELSE NULL END);\\nNote that by using the CASE statement, the objective is to remove from the index any \\nrows where Promotion_id is not equal to 2. Oracle Database does not store in the  \\nB+-tree index any rows where all the keys are NULL. Therefore, in this example, we \\nmap both Customer_id and Promotion_id to NULL unless Promotion_id is equal to 2. The \\nresult is that the index constraint is violated only if Promotion_id is equal to 2, for \\ntwo (attempted insertions of) rows with the same Customer_id value.\\n17.6 Some General Issues Concerning Indexing\\n17.6.1 Logical versus Physical Indexes\\nIn the earlier discussion, we have assumed that the index entries <K, Pr> (or <K, P>) \\nalways include a physical pointer Pr (or P) that specifies the physical record address \\non disk as a block number and offset. This is sometimes called a physical index, and \\nit has the disadvantage that the pointer must be changed if the record is moved to \\nanother disk location. For example, suppose that a primary file organization is \\nbased on linear hashing or extendible hashing; then, each time a bucket is split, \\nsome records are allocated to new buckets and hence have new physical addresses. \\nIf there was a secondary index on the file, the pointers to those records would have \\nto be found and updated, which is a difficult task.\\nTo remedy this situation, we can use a structure called a logical index, whose index \\nentries are of the form <K, K\\np>. Each entry has one value K for the secondary index-\\ning field matched with the value Kp of the field used for the primary file organiza-\\ntion. By searching the secondary index on the value of K, a program can locate the \\ncorresponding value of Kp and use this to access the record through the primary file \\norganization, using a primary index if available. Logical indexes thus introduce an'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 652, 'page_label': '653'}, page_content='17.6 Some General Issues Concerning Indexing  639\\nadditional level of indirection between the access structure and the data. They are \\nused when physical record addresses are expected to change frequently. The cost of \\nthis indirection is the extra search based on the primary file organization.\\n17.6.2 Index Creation\\nMany RDBMSs have a similar type of command for creating an index, although it is \\nnot part of the SQL standard. The general form of this command is:\\nCREATE [ UNIQUE ] INDEX <index name>\\nON <table name> ( <column name> [ <order> ] { , <column name> [ <order> ] } )\\n[ CLUSTER ] ;\\nThe keywords UNIQUE and CLUSTER are optional. The keyword CLUSTER is used \\nwhen the index to be created should also sort the data file records on the indexing \\nattribute. Thus, specifying \\nCLUSTER on a key (unique) attribute would create some \\nvariation of a primary index, whereas specifying CLUSTER on a nonkey (nonu-\\nnique) attribute would create some variation of a clustering index. The value for \\n<\\norder> can be either ASC (ascending) or DESC (descending), and it specifies \\nwhether the data file should be ordered in ascending or descending values of the \\nindexing attribute. The default is ASC. For example, the following would create a \\nclustering (ascending) index on the nonkey attribute Dno of the EMPLOYEE file:\\nCREATE INDEX DnoIndex\\nON EMPLOYEE (Dno)\\nCLUSTER ;\\nIndex Creation Process: In many systems, an index is not an integral part of the \\ndata file but can be created and discarded dynamically. That is why it is often called \\nan access structure. Whenever we expect to access a file frequently based on some \\nsearch condition involving a particular field, we can request the DBMS to create an \\nindex on that field as shown above for the DnoIndex. Usually, a secondary index is \\ncreated to avoid physical ordering of the records in the data file on disk.\\nThe main advantage of secondary indexes is that—theoretically, at least—they can \\nbe created in conjunction with virtually any primary record organization. Hence, a \\nsecondary index could be used to complement other primary access methods such \\nas ordering or hashing, or it could even be used with mixed files. To create a B\\n+-tree \\nsecondary index on some field of a file, if the file is large and contains millions of \\nrecords, neither the file nor the index would fit in main memory. Insertion of a \\nlarge number of entries into the index is done by a process called bulk loading the \\nindex. We must go through all records in the file to create the entries at the leaf level \\nof the tree. These entries are then sorted and filled according to the specified fill fac-\\ntor; simultaneously, the other index levels are created. It is more expensive and \\nmuch harder to create primary indexes and clustering indexes dynamically, because \\nthe records of the data file must be physically sorted on disk in order of the indexing \\nfield. However, some systems allow users to create these indexes dynamically on \\ntheir files by sorting the file during index creation.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 653, 'page_label': '654'}, page_content='640 Chapter 17 Indexing Structures for Files and Physical Database Design\\nIndexing of Strings: There are a couple of issues that are of particular concern \\nwhen indexing strings. Strings can be variable length (e.g., VARCHAR data type in \\nSQL; see Chapter 6) and strings may be too long limiting the fan-out. If a B\\n+-tree \\nindex is to be built with a string as a search key, there may be an uneven number of \\nkeys per index node and the fan-out may vary. Some nodes may be forced to split \\nwhen they become full regardless of the number of keys in them. The technique of \\nprefix compression alleviates the situation. Instead of storing the entire string in \\nthe intermediate nodes, it stores only the prefix of the search key adequate to distin-\\nguish the keys that are being separated and directed to the subtree. For example, if \\nLastname was a search key and we were looking for “Navathe”, the nonleaf node \\nmay contain “Nac” for Nachamkin and “Nay” for Nayuddin as the two keys on \\neither side of the subtree pointer that we need to follow.\\n17.6.3 Tuning Indexes\\nThe initial choice of indexes may have to be revised for the following reasons:\\n ■ Certain queries may take too long to run for lack of an index.\\n ■ Certain indexes may not get utilized at all.\\n ■ Certain indexes may undergo too much updating because the index is on an \\nattribute that undergoes frequent changes.\\nMost DBMSs have a command or trace facility, which can be used by the DBA to \\nask the system to show how a query was executed—what operations were per-\\nformed in what order and what secondary access structures (indexes) were used. By \\nanalyzing these execution plans (we will discuss this term further in Chapter 18), it \\nis possible to diagnose the causes of the above problems. Some indexes may be \\ndropped and some new indexes may be created based on the tuning analysis.\\nThe goal of tuning is to dynamically evaluate the requirements, which sometimes \\nfluctuate seasonally or during different times of the month or week, and to reorga-\\nnize the indexes and file organizations to yield the best overall performance. Drop-\\nping and building new indexes is an overhead that can be justified in terms of \\nperformance improvements. Updating of a table is generally suspended while an \\nindex is dropped or created; this loss of service must be accounted for.\\nBesides dropping or creating indexes and changing from a nonclustered to a clus-\\ntered index and vice versa, rebuilding the index may improve performance. Most \\nRDBMSs use B\\n+-trees for an index. If there are many deletions on the index key, \\nindex pages may contain wasted space, which can be claimed during a rebuild oper-\\nation. Similarly, too many insertions may cause overflows in a clustered index that \\naffect performance. Rebuilding a clustered index amounts to reorganizing the \\nentire table ordered on that key.\\nThe available options for indexing and the way they are defined, created, and \\nreorganized vary from system to system. As an illustration, consider the sparse \\nand dense indexes we discussed in Section 17.1. A sparse index such as a primary \\nindex will have one index pointer for each page (disk block) in the data file; a'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 654, 'page_label': '655'}, page_content='17.6 Some General Issues Concerning Indexing  641\\ndense index such as a unique secondary index will have an index pointer for each \\nrecord. Sybase provides clustering indexes as sparse indexes in the form of  \\nB\\n+-trees, whereas INGRES provides sparse clustering indexes as ISAM files and \\ndense clustering indexes as B +-trees. In some versions of Oracle and DB2, the \\noption of setting up a clustering index is limited to a dense index, and the DBA \\nhas to work with this limitation.\\n17.6.4  Additional Issues Related to Storage  \\nof Relations and Indexes\\nUsing an Index for Managing Constraints and Duplicates: It is common to \\nuse an index to enforce a key constraint on an attribute. While searching the index \\nto insert a new record, it is straightforward to check at the same time whether \\nanother record in the file—and hence in the index tree—has the same key attribute \\nvalue as the new record. If so, the insertion can be rejected.\\nIf an index is created on a nonkey field, duplicates occur; handling of these dupli-\\ncates is an issue the DBMS product vendors have to deal with and affects data stor-\\nage as well as index creation and management. Data records for the duplicate key \\nmay be contained in the same block or may span multiple blocks where many \\nduplicates are possible. Some systems add a row id to the record so that records \\nwith duplicate keys have their own unique identifiers. In such cases, the B\\n+-tree \\nindex may regard a <key, Row_id> combination as the de facto key for the index, \\nturning the index into a unique index with no duplicates. The deletion of a key K \\nfrom such an index would involve deleting all occurrences of that key K—hence the \\ndeletion algorithm has to account for this.\\nIn actual DBMS products, deletion from B +-tree indexes is also handled in various \\nways to improve performance and response times. Deleted records may be marked \\nas deleted and the corresponding index entries may also not be removed until a \\ngarbage collection process reclaims the space in the data file; the index is rebuilt \\nonline after garbage collection.\\nInverted Files and Other Access Methods: A file that has a secondary index \\non every one of its fields is often called a fully inverted file. Because all indexes are \\nsecondary, new records are inserted at the end of the file; therefore, the data file \\nitself is an unordered (heap) file. The indexes are usually implemented as B +-trees, \\nso they are updated dynamically to reflect insertion or deletion of records. Some \\ncommercial DBMSs, such as Software AG’s Adabas, use this method extensively.\\nWe referred to the popular IBM file organization called ISAM in Section 17.2. \\nAnother IBM method, the virtual storage access method  (VSAM), is somewhat \\nsimilar to the B +–tree access structure and is still being used in many commercial \\nsystems.\\nUsing Indexing Hints in Queries: DBMSs such as Oracle have a provision for \\nallowing hints in queries that are suggested alternatives or indicators to the query'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 655, 'page_label': '656'}, page_content='642 Chapter 17 Indexing Structures for Files and Physical Database Design\\nprocessor and optimizer for expediting query execution. One form of hints is called \\nindexing hints; these hints suggest the use of an index to improve the execution of a \\nquery. The hints appear as a special comment (which is preceded by +) and they \\noverride all optimizer decisions, but they may be ignored by the optimizer if they \\nare invalid, irrelevant, or improperly formulated. We do not get into a detailed dis-\\ncussion of indexing hints, but illustrate with an example query.\\nFor example, to retrieve the SSN, Salary, and department number for employees \\nworking in department numbers with Dno less than 10:\\nSELECT /*+ INDEX (EMPLOYEE emp_dno_index ) */ Emp_ssn, Salary, Dno\\nFROM EMPLOYEE\\nWHERE Dno < 10;\\nThe above query includes a hint to use a valid index called emp_dno_index (which \\nis an index on the EMPLOYEE relation on Dno).\\nColumn-Based Storage of Relations: There has been a recent trend to con-\\nsider a column-based storage of relations as an alternative to the traditional way of \\nstoring relations row by row. Commercial relational DBMSs have offered B\\n+-tree \\nindexing on primary as well as secondary keys as an efficient mechanism to support \\naccess to data by various search criteria and the ability to write a row or a set of rows \\nto disk at a time to produce write-optimized systems. For data warehouses (to be \\ndiscussed in Chapter 29), which are read-only databases, the column-based storage \\noffers particular advantages for read-only queries. Typically, the column-store \\nRDBMSs consider storing each column of data individually and afford performance \\nadvantages in the following areas:\\n ■ Vertically partitioning the table column by column, so that a two-column \\ntable can be constructed for every attribute and thus only the needed col-\\numns can be accessed\\n ■ Using column-wise indexes (similar to the bitmap indexes discussed in Sec-\\ntion 17.5.2) and join indexes on multiple tables to answer queries without \\nhaving to access the data tables\\n ■ Using materialized views (see Chapter 7) to support queries on multiple \\ncolumns\\nColumn-wise storage of data affords additional freedom in the creation of indexes, \\nsuch as the bitmap indexes discussed earlier. The same column may be present in \\nmultiple projections of a table and indexes may be created on each projection. To \\nstore the values in the same column, strategies for data compression, null-value \\nsuppression, dictionary encoding techniques (where distinct values in the column \\nare assigned shorter codes), and run-length encoding techniques have been devised. \\nMonetDB/X100, C-Store, and Vertica are examples of such systems Some popular \\nsystems (like Cassandra, Hbase, and Hypertable) have used column-based storage \\neffectively with the concept of wide column-stores . The storage of data in such \\nsystems will be explained in the context of NOSQL systems that we will discuss \\nin Chapter 24.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 656, 'page_label': '657'}, page_content='17.7 Physical Database Design in Relational Databases  643\\n17.7  Physical Database Design  \\nin Relational Databases\\nIn this section, we discuss the physical design factors that affect the performance of \\napplications and transactions, and then we comment on the specific guidelines for \\nRDBMSs in the context of what we discussed in Chapter 16 and this chapter so far.\\n17.7.1 Factors That Influence Physical Database Design\\nPhysical design is an activity where the goal is not only to create the appropriate \\nstructuring of data in storage, but also to do so in a way that guarantees good per-\\nformance. For a given conceptual schema, there are many physical design alterna-\\ntives in a given DBMS. It is not possible to make meaningful physical design \\ndecisions and performance analyses until the database designer knows the mix of \\nqueries, transactions, and applications that are expected to run on the database. \\nThis is called the job mix for the particular set of database system applications. The \\ndatabase administrators/designers must analyze these applications, their expected \\nfrequencies of invocation, any timing constraints on their execution speed, the \\nexpected frequency of update operations, and any unique constraints on attributes. \\nWe discuss each of these factors next.\\nA. Analyzing the Database Queries and Transactions. Before undertaking \\nthe physical database design, we must have a good idea of the intended use of the \\ndatabase by defining in a high-level form the queries and transactions that are \\nexpected to run on the database. For each retrieval query, the following informa-\\ntion about the query would be needed:\\n  1. The files (relations) that will be accessed by the query\\n  2. The attributes on which any selection conditions for the query are specified\\n  3. Whether the selection condition is an equality, inequality, or a range condition\\n  4. The attributes on which any join conditions or conditions to link multiple \\ntables or objects for the query are specified\\n  5. The attributes whose values will be retrieved by the query\\nThe attributes listed in items 2 and 4 above are candidates for the definition of \\naccess structures, such as indexes, hash keys, or sorting of the file.\\nFor each update operation  or update transaction , the following information \\nwould be needed:\\n  1. The files that will be updated\\n  2. The type of operation on each file (insert, update, or delete)\\n  3. The attributes on which selection conditions for a delete or update are specified\\n  4. The attributes whose values will be changed by an update operation\\nAgain, the attributes listed in item 3 are candidates for access structures on the files, \\nbecause they would be used to locate the records that will be updated or deleted. On'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 657, 'page_label': '658'}, page_content='644 Chapter 17 Indexing Structures for Files and Physical Database Design\\nthe other hand, the attributes listed in item 4 are candidates for avoiding an access \\nstructure, since modifying them will require updating the access structures.\\nB. Analyzing the Expected Frequency of Invocation of Queries and \\nTransactions. Besides identifying the characteristics of expected retrieval que-\\nries and update transactions, we must consider their expected rates of invocation. \\nThis frequency information, along with the attribute information collected on \\neach query and transaction, is used to compile a cumulative list of the expected \\nfrequency of use for all queries and transactions. This is expressed as the expected \\nfrequency of using each attribute in each file as a selection attribute or a join attri-\\nbute, over all the queries and transactions. Generally, for large volumes of pro-\\ncessing, the informal 80–20 rule can be used: approximately 80% of the processing \\nis accounted for by only 20% of the queries and transactions. Therefore, in practi-\\ncal situations, it is rarely necessary to collect exhaustive statistics and invocation \\nrates on all the queries and transactions; it is sufficient to determine the 20% or so \\nmost important ones.\\nC. Analyzing the Time Constraints of Queries and Transactions. Some que-\\nries and transactions may have stringent performance constraints. For example, a \\ntransaction may have the constraint that it should terminate within 5 seconds on \\n95% of the occasions when it is invoked, and that it should never take more than 20 \\nseconds. Such timing constraints place further priorities on the attributes that are \\ncandidates for access paths. The selection attributes used by queries and transac-\\ntions with time constraints become higher-priority candidates for primary access \\nstructures for the files, because the primary access structures are generally the most \\nefficient for locating records in a file.\\nD. Analyzing the Expected Frequencies of Update Operations. A minimum \\nnumber of access paths should be specified for a file that is frequently updated, \\nbecause updating the access paths themselves slows down the update operations. For \\nexample, if a file that has frequent record insertions has 10 indexes on 10 different \\nattributes, each of these indexes must be updated whenever a new record is inserted. \\nThe overhead for updating 10 indexes can slow down the insert operations.\\nE. Analyzing the Uniqueness Constraints on Attributes. Access paths should \\nbe specified on all candidate key attributes—or sets of attributes—that are either the \\nprimary key of a file or unique attributes. The existence of an index (or other access \\npath) makes it sufficient to search only the index when checking this uniqueness \\nconstraint, since all values of the attribute will exist in the leaf nodes of the index. \\nFor example, when inserting a new record, if a key attribute value of the new record \\nalready exists in the index, the insertion of the new record should be rejected, since \\nit would violate the uniqueness constraint on the attribute.\\nOnce the preceding information is compiled, it is possible to address the physical \\ndatabase design decisions, which consist mainly of deciding on the storage struc-\\ntures and access paths for the database files.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 658, 'page_label': '659'}, page_content='17.7 Physical Database Design in Relational Databases  645\\n17.7.2 Physical Database Design Decisions\\nMost relational systems represent each base relation as a physical database file. The \\naccess path options include specifying the type of primary file organization for each \\nrelation and the attributes that are candidates for defining individual or composite \\nindexes. At most, one of the indexes on each file may be a primary or a clustering \\nindex. Any number of additional secondary indexes can be created.\\nDesign Decisions about Indexing. The attributes whose values are required \\nin equality or range conditions (selection operation) are those that are keys or \\nthat participate in join conditions (join operation) requiring access paths, such \\nas indexes.\\nThe performance of queries largely depends upon what indexes or hashing schemes \\nexist to expedite the processing of selections and joins. On the other hand, during \\ninsert, delete, or update operations, the existence of indexes adds to the overhead. \\nThis overhead must be justified in terms of the gain in efficiency by expediting que-\\nries and transactions.\\nThe physical design decisions for indexing fall into the following categories:\\n  1. Whether to index an attribute.  The general rules for creating an index on \\nan attribute are that the attribute must either be a key (unique), or there \\nmust be some query that uses that attribute either in a selection condition \\n(equality or range of values) or in a join condition. One reason for creating \\nmultiple indexes is that some operations can be processed by just scanning \\nthe indexes, without having to access the actual data file.\\n  2. What attribute or attributes to index on. An index can be constructed on a \\nsingle attribute, or on more than one attribute if it is a composite index. If \\nmultiple attributes from one relation are involved together in several que-\\nries, (for example, \\n(Garment_style_#, Color) in a garment inventory database), \\na multiattribute (composite) index is warranted. The ordering of attributes \\nwithin a multiattribute index must correspond to the queries. For instance, \\nthe above index assumes that queries would be based on an ordering of col-\\nors within a \\nGarment_style_# rather than vice versa.\\n  3. Whether to set up a clustered index.  At most, one index per table can be a \\nprimary or clustering index, because this implies that the file be physically \\nordered on that attribute. In most RDBMSs, this is specified by the keyword \\nCLUSTER. (If the attribute is a key, a primary index  is created, whereas a \\nclustering index is created if the attribute is not a key.) If a table requires sev-\\neral indexes, the decision about which one should be the primary or cluster-\\ning index depends upon whether keeping the table ordered on that attribute \\nis needed. Range queries benefit a great deal from clustering. If several attri-\\nbutes require range queries, relative benefits must be evaluated before decid-\\ning which attribute to cluster on. If a query is to be answered by doing an \\nindex search only (without retrieving data records), the corresponding index \\nshould not be clustered, since the main benefit of clustering is achieved'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 659, 'page_label': '660'}, page_content='646 Chapter 17 Indexing Structures for Files and Physical Database Design\\nwhen retrieving the records themselves. A clustering index may be set up as \\na multiattribute index if range retrieval by that composite key is useful in \\nreport creation (for example, an index on \\nZip_code, Store_id, and Product_id \\nmay be a clustering index for sales data).\\n  4. Whether to use a hash index over a tree index.  In general, RDBMSs use  \\nB+-trees for indexing. However, ISAM and hash indexes are also provided in \\nsome systems. B+-trees support both equality and range queries on the attri-\\nbute used as the search key. Hash indexes work well with equality condi-\\ntions, particularly during joins to find a matching record(s), but they do not \\nsupport range queries.\\n  5. Whether to use dynamic hashing for the file. For files that are very volatile—\\nthat is, those that grow and shrink continuously—one of the dynamic hashing \\nschemes discussed in Section 16.9 would be suitable. Currently, such schemes \\nare not offered by many commercial RDBMSs.\\n17.8  Summary\\nIn this chapter, we presented file organizations that involve additional access struc-\\ntures, called indexes, to improve the efficiency of retrieval of records from a data \\nfile. These access structures may be used in conjunction with the primary file orga-\\nnizations discussed in Chapter 16, which are used to organize the file records them-\\nselves on disk.\\nThree types of ordered single-level indexes were introduced: primary, clustering, \\nand secondary. Each index is specified on a field of the file. Primary and cluster-\\ning indexes are constructed on the physical ordering field of a file, whereas sec-\\nondary indexes are specified on nonordering fields as additional access structures \\nto improve performance of queries and transactions. The field for a primary \\nindex must also be a key of the file, whereas it is a nonkey field for a clustering \\nindex. A single-level index is an ordered file and is searched using a binary search. \\nWe showed how multilevel indexes can be constructed to improve the efficiency \\nof searching an index. An example is IBM’s popular indexed sequential access \\nmethod (ISAM), which is a multilevel index based on the cylinder/track configu-\\nration on disk.\\nNext we showed how multilevel indexes can be implemented as B-trees and  \\nB\\n+-trees, which are dynamic structures that allow an index to expand and shrink \\ndynamically. The nodes (blocks) of these index structures are kept between half full \\nand completely full by the insertion and deletion algorithms. Nodes eventually sta-\\nbilize at an average occupancy of 69% full, allowing space for insertions without \\nrequiring reorganization of the index for the majority of insertions. B +-trees can \\ngenerally hold more entries in their internal nodes than can B-trees, so they may \\nhave fewer levels or hold more entries than does a corresponding B-tree.\\nWe gave an overview of multiple key access methods, and we showed how an index \\ncan be constructed based on hash data structures. We introduced the concept of'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 660, 'page_label': '661'}, page_content='Review Questions 647\\npartitioned hashing , which is an extension of external hashing to deal with mul-\\ntiple keys. We also introduced grid files, which organize data into buckets along \\nmultiple dimensions, We discussed the hash index in some detail—it is a second-\\nary structure to access the file by using hashing on a search key other than that \\nused for the primary organization. Bitmap indexing is another important type of \\nindexing used for querying by multiple keys and is particularly applicable on fields \\nwith a small number of unique values. Bitmaps can also be used at the leaf nodes of \\nB\\n+ tree indexes as well. We also discussed function-based indexing, which is being \\nprovided by relational vendors to allow special indexes on a function of one or \\nmore attributes.\\nWe introduced the concept of a logical index and compared it with the physical \\nindexes we described before. They allow an additional level of indirection in index-\\ning in order to permit greater freedom for movement of actual record locations on \\ndisk. We discussed index creation in SQL, the process of bulk loading of index files \\nand indexing of strings. We discussed circumstances that point to tuning of indexes. \\nThen we reviewed some general topics related to indexing, including managing \\nconstraints, using inverted indexes, and using indexing hints in queries; we com-\\nmented on column-based storage of relations, which is becoming a viable alterna-\\ntive for storing and accessing large databases. Finally, we discussed physical \\ndatabase design of relational databases, which involves decisions related to storage \\nand accessing of data that we have been discussing in the current and the previous \\nchapter. This discussion was divided into factors that influence the design and the \\ntypes of decisions regarding whether to index an attribute, what attributes to \\ninclude in an index, clustered versus nonclustered indexes, hashed indexes, and \\ndynamic hashing.\\nReview Questions\\n 17.1. Define the following terms: indexing field, primary key field, clustering field, \\nsecondary key field, block anchor, dense index, and nondense (sparse) index.\\n 17.2. What are the differences among primary, secondary, and clustering indexes? \\nHow do these differences affect the ways in which these indexes are imple-\\nmented? Which of the indexes are dense, and which are not?\\n 17.3. Why can we have at most one primary or clustering index on a file, but several \\nsecondary indexes?\\n 17.4. How does multilevel indexing improve the efficiency of searching an index file?\\n 17.5. What is the order p of a B-tree? Describe the structure of B-tree nodes.\\n 17.6. What is the order p of a B+-tree? Describe the structure of both internal and \\nleaf nodes of a B+-tree.\\n 17.7. How does a B-tree differ from a B +-tree? Why is a B+-tree usually preferred \\nas an access structure to a data file?'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 661, 'page_label': '662'}, page_content='648 Chapter 17 Indexing Structures for Files and Physical Database Design\\n 17.8. Explain what alternative choices exist for accessing a file based on multiple \\nsearch keys.\\n 17.9. What is partitioned hashing? How does it work? What are its limitations?\\n 17.10. What is a grid file? What are its advantages and disadvantages?\\n 17.11. Show an example of constructing a grid array on two attributes on some file.\\n 17.12. What is a fully inverted file? What is an indexed sequential file?\\n 17.13. How can hashing be used to construct an index?\\n 17.14. What is bitmap indexing? Create a relation with two columns and sixteen \\ntuples and show an example of a bitmap index on one or both.\\n 17.15. What is the concept of function-based indexing? What additional purpose \\ndoes it serve?\\n 17.16. What is the difference between a logical index and a physical index?\\n 17.17. What is column-based storage of a relational database?\\nExercises\\n 17.18. Consider a disk with block size B = 512 bytes. A block pointer is P = 6 bytes \\nlong, and a record pointer is PR = 7 bytes long. A file has r = 30,000 \\nEMPLOYEE records of fixed length . Each record has the following fields: \\nName (30 bytes),Ssn (9 bytes), Department_code (9 bytes), Address (40 bytes), \\nPhone (10 bytes), Birth_date (8 bytes), Sex (1 byte), Job_code (4 bytes), and \\nSalary (4 bytes, real number). An additional byte is used as a deletion marker.\\na. Calculate the record size R in bytes.\\nb. Calculate the blocking factor bfr and the number of file blocks b, assuming \\nan unspanned organization.\\nc. Suppose that the file is ordered by the key field Ssn and we want to con-\\nstruct a primary index on Ssn. Calculate (i) the index blocking factor bfri \\n(which is also the index fan-out fo); (ii) the number of first-level index \\nentries and the number of first-level index blocks; (iii) the number of lev-\\nels needed if we make it into a multilevel index; (iv) the total number of \\nblocks required by the multilevel index; and (v) the number of block \\naccesses needed to search for and retrieve a record from the file—given \\nits \\nSsn value—using the primary index.\\nd. Suppose that the file is not ordered by the key field Ssn and we want to \\nconstruct a secondary index on Ssn. Repeat the previous exercise (part c) \\nfor the secondary index and compare with the primary index.\\ne. Suppose that the file is not ordered by the nonkey field Department_code \\nand we want to construct a secondary index  on Department_code, using'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 662, 'page_label': '663'}, page_content='Exercises 649\\noption 3 of Section 17.1.3, with an extra level of indirection that stores \\nrecord pointers. Assume there are 1,000 distinct values of Department_code \\nand that the EMPLOYEE  records are evenly distributed among these  \\nvalues. Calculate (i) the index blocking factor bfri (which is also the index \\nfan-out fo); (ii) the number of blocks needed by the level of indirection \\nthat stores record pointers; (iii) the number of first-level index entries \\nand the number of first-level index blocks; (iv) the number of levels \\nneeded if we make it into a multilevel index; (v) the total number of \\nblocks required by the multilevel index and the blocks used in the extra \\nlevel of indirection; and (vi) the approximate number of block accesses \\nneeded to search for and retrieve all records in the file that have a specific \\nDepartment_code value, using the index.\\nf. Suppose that the file is ordered by the nonkey field Department_code and we \\nwant to construct a clustering index on Department_code that uses block \\nanchors (every new value of Department_code starts at the beginning of a \\nnew block). Assume there are 1,000 distinct values of Department_code and \\nthat the EMPLOYEE records are evenly distributed among these values. Cal-\\nculate (i) the index blocking factor bfri (which is also the index fan-out fo); \\n(ii) the number of first-level index entries and the number of first-level \\nindex blocks; (iii) the number of levels needed if we make it into a multi-\\nlevel index; (iv) the total number of blocks required by the multilevel index; \\nand (v) the number of block accesses needed to search for and retrieve all \\nrecords in the file that have a specific Department_code value, using the clus-\\ntering index (assume that multiple blocks in a cluster are contiguous).\\ng. Suppose that the file is not ordered by the key field Ssn and we want to \\nconstruct a B+-tree access structure (index) on Ssn. Calculate (i) the orders \\np and pleaf of the B +-tree; (ii) the number of leaf-level blocks needed if \\nblocks are approximately 69% full (rounded up for convenience); (iii) the \\nnumber of levels needed if internal nodes are also 69% full (rounded up \\nfor convenience); (iv) the total number of blocks required by the B+-tree; \\nand (v) the number of block accesses needed to search for and retrieve a \\nrecord from the file—given its Ssn value—using the B+-tree.\\nh. Repeat part g, but for a B-tree rather than for a B +-tree. Compare your \\nresults for the B-tree and for the B+-tree.\\n 17.19. A PARTS file with Part# as the key field includes records with the following \\nPart# values: 23, 65, 37, 60, 46, 92, 48, 71, 56, 59, 18, 21, 10, 74, 78, 15, 16, 20, \\n24, 28, 39, 43, 47, 50, 69, 75, 8, 49, 33, 38. Suppose that the search field values \\nare inserted in the given order in a B+-tree of order p = 4 and pleaf = 3; show \\nhow the tree will expand and what the final tree will look like.\\n 17.20. Repeat Exercise 17.19, but use a B-tree of order p = 4 instead of a B+-tree.\\n 17.21. Suppose that the following search field values are deleted, in the given order, \\nfrom the B+-tree of Exercise 17.19; show how the tree will shrink and show \\nthe final tree. The deleted values are 65, 75, 43, 18, 20, 92, 59, 37.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 663, 'page_label': '664'}, page_content='650 Chapter 17 Indexing Structures for Files and Physical Database Design\\n 17.22. Repeat Exercise 17.21, but for the B-tree of Exercise 17.20.\\n 17.23. Algorithm 17.1 outlines the procedure for searching a nondense multilevel \\nprimary index to retrieve a file record. Adapt the algorithm for each of the \\nfollowing cases:\\na. A multilevel secondary index on a nonkey nonordering field of a file. \\nAssume that option 3 of Section 17.1.3 is used, where an extra level of \\nindirection stores pointers to the individual records with the corres-\\nponding index field value.\\nb. A multilevel secondary index on a nonordering key field of a file.\\nc. A multilevel clustering index on a nonkey ordering field of a file.\\n 17.24. Suppose that several secondary indexes exist on nonkey fields of a file, \\nimplemented using option 3 of Section 17.1.3; for example, we could have \\nsecondary indexes on the fields \\nDepartment_code, Job_code, and Salary of the \\nEMPLOYEE file of Exercise 17.18. Describe an efficient way to search for and \\nretrieve records satisfying a complex selection condition on these fields, \\nsuch as (\\nDepartment_code = 5 AND Job_code = 12 AND Salary = 50,000), using \\nthe record pointers in the indirection level.\\n 17.25. Adapt Algorithms 17.2 and 17.3, which outline search and insertion proce-\\ndures for a B+-tree, to a B-tree.\\n 17.26. It is possible to modify the B +-tree insertion algorithm to delay the case \\nwhere a new level is produced by checking for a possible redistribution of \\nvalues among the leaf nodes. Figure 17.17 illustrates how this could be done \\nfor our example in Figure 17.12; rather than splitting the leftmost leaf \\nnode when 12 is inserted, we do a left redistribution by moving 7 to the leaf \\nnode to its left (if there is space in this node). Figure 17.17 shows how the \\ntree would look when redistribution is considered. It is also possible to consider \\nright redistribution . Try to modify the B\\n+-tree insertion algorithm to take \\nredistribution into account.\\n 17.27. Outline an algorithm for deletion from a B+-tree.\\n 17.28. Repeat Exercise 17.27 for a B-tree.\\nSelected Bibliography\\nIndexing: Bayer and McCreight (1972) introduced B-trees and associated algo-\\nrithms. Comer (1979) provides an excellent survey of B-trees and their history, and \\nvariations of B-trees. Knuth (1998) provides detailed analysis of many search tech-\\nniques, including B-trees and some of their variations. Nievergelt (1974) discusses \\nthe use of binary search trees for file organization. Textbooks on file structures, \\nincluding Claybrook (1992), Smith and Barnes (1987), and Salzberg (1988); the \\nalgorithms and data structures textbook by Wirth (1985); as well as the database \\ntextbook by Ramakrihnan and Gehrke (2003) discuss indexing in detail and may be'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 664, 'page_label': '665'}, page_content='Selected Bibliography 651\\n10 30 50 70 80\\n35\\nInsert 12: overflow (left\\nredistribution)\\nInsert 9: overflow (new level)\\nInsert 6: overflow (split)\\n10 30 50 70 80 12 0\\n10 30 50 70 80 90 12 0\\n12 0\\n37\\n3 9\\n7\\n10 30 50 60 70 80 90\\n36 9\\n7\\nFigure 17.17 \\nB+-tree insertion with left redistribution.\\nconsulted for search, insertion, and deletion algorithms for B-trees and B +-trees. \\nLarson (1981) analyzes index-sequential files, and Held and Stonebraker (1978) \\ncompare static multilevel indexes with B-tree dynamic indexes. Lehman and Yao \\n(1981) and Srinivasan and Carey (1991) did further analysis of concurrent access to \\nB-trees. The books by Wiederhold (1987), Smith and Barnes (1987), and Salzberg \\n(1988), among others, discuss many of the search techniques described in this \\nchapter. Grid files are introduced in Nievergelt et al. (1984). Partial-match retrieval, \\nwhich uses partitioned hashing, is discussed in Burkhard (1976, 1979).\\nNew techniques and applications of indexes and B\\n+-trees are discussed in Lanka \\nand Mays (1991), Zobel et al. (1992), and Faloutsos and Jagadish (1992). Mohan'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 665, 'page_label': '666'}, page_content='652 Chapter 17 Indexing Structures for Files and Physical Database Design\\nand Narang (1992) discuss index creation. The performance of various B–tree and \\nB+-tree algorithms is assessed in Baeza-Yates and Larson (1989) and Johnson and \\nShasha (1993). Buffer management for indexes is discussed in Chan et al. (1992). \\nColumn-based storage of databases was proposed by Stonebraker et al. (2005) in \\nthe C-Store database system; MonetDB/X100 by Boncz et al. (2008) is another \\nimplementation of the idea. Abadi et al. (2008) discuss the advantages of column \\nstores over row-stored databases for read-only database applications.\\nPhysical Database Design:  Wiederhold (1987) covers issues related to physical \\ndesign. O’Neil and O’Neil (2001) provides a detailed discussion of physical design \\nand transaction issues in reference to commercial RDBMSs. Navathe and Kersch-\\nberg (1986) discuss all phases of database design and point out the role of data dic-\\ntionaries. Rozen and Shasha (1991) and Carlis and March (1984) present different \\nmodels for the problem of physical database design. Shasha and Bonnet (2002) offer \\nan elaborate discussion of guidelines for database tuning. Niemiec (2008) is one \\namong several books available for Oracle database administration and tuning; \\nSchneider (2006) is focused on designing and tuning MySQL databases.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 666, 'page_label': '667'}, page_content='Query Processing  \\nand Optimization  \\npart 8'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 667, 'page_label': '668'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 668, 'page_label': '669'}, page_content='655\\n18\\nStrategies for Query Processing1\\nI\\nn this chapter, we discuss the techniques used inter-\\nnally by a DBMS to process high-level queries. A \\nquery expressed in a high-level query language such as SQL must first be scanned, \\nparsed, and validated.2 The scanner identifies the query tokens—such as SQL key-\\nwords, attribute names, and relation names—that appear in the text of the query, \\nwhereas the parser checks the query syntax to determine whether it is formulated \\naccording to the syntax rules (rules of grammar) of the query language. The query \\nmust also be validated by checking that all attribute and relation names are valid \\nand semantically meaningful names in the schema of the particular database being \\nqueried. An internal representation of the query is then created, usually as a tree \\ndata structure called a query tree. It is also possible to represent the query using a \\ngraph data structure called a query graph , which is generally a directed acyclic \\ngraph (DAG). The DBMS must then devise an execution strategy or query plan \\nfor retrieving the results of the query from the database files. A query has many pos-\\nsible execution strategies, and the process of choosing a suitable one for processing \\na query is known as query optimization.\\nWe defer a detailed discussion of query optimization to the next chapter. In this \\nchapter, we will primarily focus on how queries are processed and what algorithms \\nare used to perform individual operations within the query. Figure 18.1 shows the \\ndifferent steps of processing a high-level query. The query optimizer module has \\nthe task of producing a good execution plan, and the code generator generates the \\ncode to execute that plan. The runtime database processor has the task of running \\n(executing) the query code, whether in compiled or interpreted mode, to produce \\nthe query result. If a runtime error results, an error message is generated by the \\nruntime database processor.\\nchapter 18\\n1We appreciate Rafi Ahmed’s contributions in updating this chapter.\\n2We will not discuss the parsing and syntax-checking phase of query processing here; this material  \\nis discussed in compiler texts.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 669, 'page_label': '670'}, page_content='656 Chapter 18 Strategies for Query Processing\\nThe term optimization is actually a misnomer because in some cases the chosen \\nexecution plan is not the optimal (or absolute best) strategy—it is just a reasonably \\nefficient or the best available strategy  for executing the query. Finding the optimal \\nstrategy is usually too time-consuming—except for the simplest of queries. In addi-\\ntion, trying to find the optimal query execution strategy requires accurate and \\ndetailed information about the size of the tables and distributions of things such as \\ncolumn values, which may not be always available in the DBMS catalog. Further-\\nmore, additional information such as the size of the expected result must be derived \\nbased on the predicates in the query. Hence, planning of a good execution strategy  \\nmay be a more accurate description than query optimization.\\nFor lower-level navigational database languages in legacy systems—such as the net-\\nwork DML or the hierarchical DL/1 the programmer must choose the query execu-\\ntion strategy while writing a database program. If a DBMS provides only a \\nnavigational language, there is a limited opportunity for extensive query optimiza-\\ntion by the DBMS; instead, the programmer is given the capability to choose the \\nquery execution strategy. On the other hand, a high-level query language—such as \\nSQL for relational DBMSs (RDBMSs) or OQL (see Chapter 12) for object DBMSs \\n(ODBMSs)—is more declarative in nature because it specifies what the intended \\nresults of the query are rather than identifying the details of how the result should \\nbe obtained. Query optimization is thus necessary for queries that are specified in a \\nhigh-level query language.\\nQuery in a high-level language\\nScanning, parsing, and validating\\nImmediate form of query\\nQuery optimizer\\nExecution plan\\nQuery code generator\\nCode to execute the query\\nRuntime database processor\\nCode can be:\\nExecuted directly (interpreted mode)\\nStored and executed later whenever\\nneeded (compiled mode)\\nResult of query\\nFigure 18.1 \\nTypical steps when \\nprocessing a high-level \\nquery.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 670, 'page_label': '671'}, page_content='18.1 Translating SQL Queries into Relational Algebra and Other Operators  657\\nWe will concentrate on describing query processing and optimization in the context \\nof an RDBMS because many of the techniques we describe have also been adapted \\nfor other types of database management systems, such as ODBMSs. 3 A relational \\nDBMS must systematically evaluate alternative query execution strategies and \\nchoose a reasonably efficient or near-optimal strategy. Most DBMSs have a number \\nof general database access algorithms that implement relational algebra operations \\nsuch as \\nSELECT or JOIN (see Chapter 8) or combinations of these operations. Only \\nexecution strategies that can be implemented by the DBMS access algorithms and \\nthat apply to the particular query, as well as to the particular physical database design, \\ncan be considered by the query optimization module.\\nThis chapter is organized as follows. Section 18.1 starts with a general discussion of \\nhow SQL queries are typically translated into relational algebra queries and addi-\\ntional operations and then optimized. Then we discuss algorithms for implementing \\nrelational algebra operations in Sections 18.2 through 18.6. In Section 18.7, we dis-\\ncuss the strategy for execution called pipelining. Section 18.8 briefly reviews the \\nstrategy for parallel execution of the operators. Section 18.9 summarizes the chapter.\\nIn the next chapter, we will give an overview of query optimization strategies. There \\nare two main techniques of query optimization that we will be discussing. The first \\ntechnique is based on heuristic rules for ordering the operations in a query execu-\\ntion strategy that works well in most cases but is not guaranteed to work well in \\nevery case. The rules typically reorder the operations in a query tree. The second \\ntechnique involves cost estimation of different execution strategies and choosing \\nthe execution plan that minimizes estimated cost. The topics covered in this chapter \\nrequire that the reader be familiar with the material presented in several earlier chap-\\nters. In particular, the chapters on SQL (Chapters 6 and 7), relational algebra (Chap-\\nter 8), and file structures and indexing (Chapters 16 and 17) are a prerequisite to this \\nchapter. Also, it is important to note that the topic of query processing and optimiza-\\ntion is vast, and we can only give an introduction to the basic principles and tech-\\nniques in this and the next chapter. Several important works are mentioned in the \\nBibliography of this and the next chapter.\\n18.1  Translating SQL Queries into Relational \\nAlgebra and Other Operators\\nIn practice, SQL is the query language that is used in most commercial RDBMSs. \\nAn SQL query is first translated into an equivalent extended relational algebra \\nexpression—represented as a query tree data structure—that is then optimized. \\nTypically, SQL queries are decomposed into query blocks , which form the basic \\nunits that can be translated into the algebraic operators and optimized. A query \\nblock contains a single \\nSELECT-FROM-WHERE  expression, as well as GROUP BY  \\n3There are some query processing and optimization issues and techniques that are pertinent only to \\nODBMSs. However, we do not discuss them here because we give only an introduction to query \\nprocessing in this chapter and we do not discuss query optimization until Chapter 19.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 671, 'page_label': '672'}, page_content='658 Chapter 18 Strategies for Query Processing\\nand HAVING clauses if these are part of the block. Hence, nested queries within a \\nquery are identified as separate query blocks. Because SQL includes aggregate \\noperators—such as \\nMAX, MIN, SUM, and COUNT—these operators must also be \\nincluded in the extended algebra, as we discussed in Section 8.4.\\nConsider the following SQL query on the EMPLOYEE relation in Figure 5.5:\\nSELECT Lname, Fname\\nFROM EMPLOYEE\\nWHERE Salary > ( SELECT MAX (Salary)\\n    FROM    EMPLOYEE\\n    WHERE  Dno=5 );\\nThis query retrieves the names of employees (from any department in the com-\\npany) who earn a salary that is greater than the highest salary in department 5. The \\nquery includes a nested subquery and hence would be decomposed into two blocks. \\nThe inner block is:\\n( SELECT MAX (Salary)\\n  FROM    EMPLOYEE\\n  WHERE  Dno=5 )\\nThis retrieves the highest salary in department 5. The outer query block is:\\nSELECT  Lname, Fname\\nFROM   EMPLOYEE\\nWHERE Salary > c\\nwhere c represents the result returned from the inner block. The inner block could \\nbe translated into the following extended relational algebra expression:\\nℑMAX Salary(σDno=5(EMPLOYEE))\\nand the outer block into the expression:\\nπLname,Fname(σSalary>c(EMPLOYEE))\\nThe query optimizer  would then choose an execution plan for each query block. \\nNotice that in the above example, the inner block needs to be evaluated only once to \\nproduce the maximum salary of employees in department 5, which is then used—as \\nthe constant c—by the outer block. We called this a nested subquery block (which is \\nuncorrelated to the outer query block ) in Section 7.1.2. It is more involved to opti-\\nmize the more complex correlated nested subqueries  (see Section 7.1.3), where a \\ntuple variable from the outer query block appears in the WHERE-clause of the inner \\nquery block. Many techniques are used in advanced DBMSs to unnest and optimize \\ncorrelated nested subqueries.\\n18.1.1 Additional Operators Semi-Join and Anti-Join\\nMost RDBMSs currently process SQL queries arising from various types of enterprise \\napplications that include ad hoc queries, standard canned queries with parameters,'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 672, 'page_label': '673'}, page_content='18.1 Translating SQL Queries into Relational Algebra and Other Operators  659\\nand queries for report generation. Additionally, SQL queries originate from OLAP \\n(online analytical processing) applications on data warehouses (we discuss data \\nwarehousing in detail in Chapter 29). Some of these queries are transformed into \\noperations that are not part of the standard relational algebra we discussed in Chap-\\nter\\xa08. Two commonly used operations are semi-join and anti-join. Note that both \\nthese operations are a type of join. Semi-join is generally used for unnesting EXISTS, \\nIN, and ANY subqueries.\\n4 Here we represent semi-join by the following non- \\nstandard syntax: T1.X S = T2.Y, where T1 is the left table and T2 is the right table of \\nthe semi-join. The semantics of semi-join are as follows: A row of T1 is returned as \\nsoon as T1.X finds a match with any value of T2.Y without searching for further \\nmatches. This is in contrast to finding all possi ble matches in inner join.\\nConsider a slightly modified version of the schema in Figure 5.5 as follows:\\nEMPLOYEE ( Ssn, Bdate, Address, Sex, Salary, Dno)\\nDEPARTMENT ( Dnumber, Dname, Dmgrssn, Zipcode)\\nwhere a department is located in a specific zip code.\\nLet us consider the following query:\\nQ (SJ) : SELECT COUNT( *)\\nFROM DEPARTMENT D\\nWHERE D.Dnumber IN (  SELECT E.Dno\\n            FROM EMPLOYEE E\\n            WHERE E.Salary > 200000)\\nHere we have a nested query which is joined by the connector IN.\\nTo remove the nested query:\\n( SELECT E.Dno\\n  FROM EMPLOYEE E WHERE E.Salary > 200000)\\nis called as unnesting . It leads to the following query with an operation called \\nsemi-join,\\n5 which we show with a non-standard notation “ S=” below:\\nSELECT COUNT(*)\\nFROM EMPLOYEE E, DEPARTMENT D\\nWHERE D.Dnumber S= E.Dno and E.Salary > 200000;\\nThe above query is counting the number of departments that have employees who \\nmake more than $200,000 annually. Here, the operation is to find the department \\nwhose Dnumber attribute matches the value(s) for the Dno attribute of Employee \\nwith that high salary.\\n4In some cases where duplicate rows are not relevant, inner join can also be used to unnest EXISTS  \\nand ANY subqueries.\\n5Note that this semi-join operator is not the same as that used in distributed query processing.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 673, 'page_label': '674'}, page_content='660 Chapter 18 Strategies for Query Processing\\nIn algebra, alternate notations exist. One common notation is shown in the follow-\\ning figure.\\nSemi-join\\nNow consider another query:\\nQ (AJ) : SELECT COUNT( *)\\nFROM EMPLOYEE\\nWHERE EMPLOYEE .Dno NOT IN (SELECT DEPARTMENT .Dnumber\\n  FROM DEPARTMENT\\n  WHERE Zipcode =30332)\\nThe above query counts the number of employees who do not work in departments \\nlocated in zip code 30332. Here, the operation is to find the employee tuples \\nwhose Dno attribute does not match the value(s) for the Dnumber attribute in \\nDEPARTMENT for the given zip code. We are only interested in producing a \\ncount of such employees, and performing an inner join of the two tables would, of \\ncourse, produce wrong results. In this case, therefore, the anti-join operator is used \\nwhile unnesting this query.\\nAnti-join is used for unnesting NOT EXISTS, NOT IN, and ALL subqueries. We \\nrepresent anti-join by the following nonstandard syntax: T1.x A = T2.y, where T1 is \\nthe left table and T2 is the right table of the anti-join. The semantics of anti-join are \\nas follows: A row of T1 is rejected as soon as T1.x finds a match with any value  \\nof T2.y. A row of T1 is returned, only if T1.x does not match with any value of T2.y.\\nIn the following result of unnesting, we show the aforementioned anti-join with the \\nnonstandard symbol “A=” in the following:\\nSELECT COUNT(*)\\nFROM EMPLOYEE, DEPARTMENT\\nWHERE EMPLOYEE.Dno A = DEPARTMENT AND Zipcode =30332\\nIn algebra, alternate notations exist. One common notation is shown in the follow-\\ning figure.\\nAnti-join\\n18.2 Algorithms for External Sorting\\nSorting is one of the primary algorithms used in query processing. For example, \\nwhenever an SQL query specifies an \\nORDER BY -clause, the query result must be \\nsorted. Sorting is also a key component in sort-merge algorithms used for JOIN and'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 674, 'page_label': '675'}, page_content='18.2 Algorithms for External Sorting  661\\nother operations (such as UNION and INTERSECTION), and in duplicate elimination \\nalgorithms for the PROJECT operation (when an SQL query specifies the DISTINCT \\noption in the SELECT clause). We will discuss one of these algorithms in this sec-\\ntion. Note that sorting of a particular file may be avoided if an appropriate index—\\nsuch as a primary or clustering index (see Chapter 17)—exists on the desired file \\nattribute to allow ordered access to the records of the file.\\nExternal sorting  refers to sorting algorithms that are suitable for large files of \\nrecords stored on disk that do not fit entirely in main memory, such as most data-\\nbase files.\\n6 The typical external sorting algorithm uses a sort-merge strategy, which \\nstarts by sorting small subfiles—called runs—of the main file and then merges the \\nsorted runs, creating larger sorted subfiles that are merged in turn. The sort-merge \\nalgorithm, like other database algorithms, requires buffer space in main memory, \\nwhere the actual sorting and merging of the runs is performed. The basic algorithm, \\noutlined in Figure 18.2, consists of two phases: the sorting phase and the merging \\nphase. The buffer space in main memory is part of the DBMS cache—an area in the \\ncomputer’s main memory that is controlled by the DBMS. The buffer space is \\ndivided into individual buffers, where each buffer is the same size in bytes as the size \\nof one disk block. Thus, one buffer can hold the contents of exactly one disk block.\\nIn the sorting phase, runs (portions or pieces) of the file that can fit in the available \\nbuffer space are read into main memory, sorted using an internal sorting algorithm, \\nand written back to disk as temporary sorted subfiles (or runs). The size of each run \\nand the number of initial runs ( n\\nR) are dictated by the number of file blocks ( b) \\nand the available buffer space ( nB). For example, if the number of available main \\nmemory buffers nB = 5 disk blocks and the size of the file b = 1,024 disk blocks, then \\nnR= ⎡(b/nB)⎤ or 205 initial runs each of size 5 blocks (except the last run, which will \\nhave only 4 blocks). Hence, after the sorting phase, 205 sorted runs (or 205 sorted \\nsubfiles of the original file) are stored as temporary subfiles on disk.\\nIn the merging phase, the sorted runs are merged during one or more merge passes. \\nEach merge pass can have one or more merge steps. The degree of merging ( dM) \\nis the number of sorted subfiles that can be merged in each merge step. During each \\nmerge step, one buffer block is needed to hold one disk block from each of the \\nsorted subfiles being merged, and one additional buffer is needed for containing \\none disk block of the merge result, which will produce a larger sorted file that is the \\nresult of merging several smaller sorted subfiles. Hence, d\\nM is the smaller of (nB − 1) \\nand nR, and the number of merge passes is ⎡(log dM(nR))⎤. In our example, \\nwhere nB = 5, dM = 4 (four-way merging), so the 205 initial sorted runs would be \\nmerged 4 at a time in each step into 52 larger sorted subfiles at the end of the first \\nmerge pass. These 52 sorted files are then merged 4 at a time into 13 sorted files, \\nwhich are then merged into 4 sorted files, and then finally into 1 fully sorted file, \\nwhich means that four passes are needed.\\n6Internal sorting algorithms are suitable for sorting data structures, such as tables and lists, that can fit \\nentirely in main memory. These algorithms are described in detail in data structures and algorithms texts, \\nand include techniques such as quick sort, heap sort, bubble sort, and many others. We do not discuss \\nthese here. Also, main-memory DBMSs such as HANA employ their own techniques for sorting.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 675, 'page_label': '676'}, page_content='662 Chapter 18 Strategies for Query Processing\\nThe performance of the sort-merge algorithm can be measured in terms of the \\nnumber of disk block reads and writes (between the disk and main memory) \\nbefore the sorting of the whole file is completed. The following formula approxi-\\nmates this cost:\\n(2 * b) + (2 * b * (logdM nR))\\nThe first term (2 * b) represents the number of block accesses for the sorting phase, \\nsince each file block is accessed twice: once for reading into a main memory buffer \\nand once for writing the sorted records back to disk into one of the sorted subfiles. \\nThe second term represents the number of block accesses for the merging phase. \\nDuring each merge pass, a number of disk blocks approximately equal to the original \\nfile blocks b is read and written. Since the number of merge passes is (log\\ndM nR), we \\nget the total merge cost of (2 * b * (logdM nR)).\\nset i ← 1;\\n j ← b;  {size of the file in blocks}\\n k ← nB; {size of buffer in blocks}\\n m ← ⎡(j/k)⎤; {number of subfiles- each fits in buffer}\\n{Sorting Phase}\\nwhile (i\\n ≤m) \\ndo {\\n read next k blocks of the file into the buffer or if there are less than k blocks\\n  remaining, then read in the remaining blocks;\\n sort the records in the buffer and write as a temporary subfile;\\n i ← i + 1;\\n}\\n{Merging Phase: merge subfiles until only 1 remains}\\nset i \\n← 1; \\n p ← ⎡logk–1m⎤ {p is the number of passes for the merging phase}\\n j ← m; \\nwhile (i ≤ p) \\ndo {\\n n ← 1; \\n q ← ( j/(k–1)⎤ ;  {number of subfiles to write in this pass}\\n while (n ≤ q) \\n do {\\n  read next k–1 subfiles or remaining subfiles (from previous pass)\\n   one block at a time;\\n  merge and write as new subfile one block at a time;\\n  n ← n + 1;\\n }\\n j ← q;\\n i ← i + 1;\\n}\\nFigure 18.2 \\nOutline of the \\nsort-merge  \\nalgorithm for \\nexternal sorting.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 676, 'page_label': '677'}, page_content='18.3 Algorithms for SELECT Operation  663\\nThe minimum number of main memory buffers needed is nB = 3, which gives a dM \\nof 2 and an nR of ⎡(b/3)⎤. The minimum dM of 2 gives the worst-case performance \\nof the algorithm, which is:\\n(2 * b) + (2 * (b * (log2 nR))).\\nThe following sections discuss the various algorithms for the operations of the rela-\\ntional algebra (see Chapter 8).\\n18.3 Algorithms for SELECT Operation\\n18.3.1 Implemention Options for the SELECT Operation\\nThere are many algorithms for executing a SELECT operation, which is basically a \\nsearch operation to locate the records in a disk file that satisfy a certain condition. \\nSome of the search algorithms depend on the file having specific access paths, and \\nthey may apply only to certain types of selection conditions. We discuss some of the \\nalgorithms for implementing \\nSELECT in this section. We will use the following oper-\\nations, specified on the relational database in Figure 5.5, to illustrate our discussion:\\nOP1: σSsn = ‘123456789’ (EMPLOYEE)\\nOP2: σDnumber > 5 (DEPARTMENT) \\nOP3: σDno= 5 (EMPLOYEE) \\nOP4: σDno= 5 AND Salary > 30000 AND Sex = ‘F’ (EMPLOYEE)\\nOP5: σEssn = ‘123456789’ AND Pno =10(WORKS_ON) \\nOP6: An SQL Query:\\n SELECT *\\n FROM    EMPLOYEE\\n WHERE Dno IN (3,27, 49)\\nOP7: An SQL Query (from Section 17.5.3)\\nSELECT First_name, Lname\\nFROM Employee\\nWHERE ((Salary*Commission_pct) + Salary ) > 15000; \\nSearch Methods for Simple Selection. A number of search algorithms are pos-\\nsible for selecting records from a file. These are also known as file scans, because \\nthey scan the records of a file to search for and retrieve records that satisfy a selection \\ncondition.\\n7 If the search algorithm involves the use of an index, the index search is \\ncalled an index scan. The following search methods (S1 through S6) are examples of \\nsome of the search algorithms that can be used to implement a select operation:\\n ■ S1—Linear search (brute force algorithm). Retrieve every record in the file, \\nand test whether its attribute values satisfy the selection condition. Since the \\n7A selection operation is sometimes called a filter, since it filters out the records in the file that do not \\nsatisfy the selection condition.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 677, 'page_label': '678'}, page_content='664 Chapter 18 Strategies for Query Processing\\nrecords are grouped into disk blocks, each disk block is read into a main \\nmemory buffer, and then a search through the records within the disk block \\nis conducted in main memory.\\n ■ S2—Binary search. If the selection condition involves an equality compari-\\nson on a key attribute on which the file is ordered, binary search—which is \\nmore efficient than linear search—can be used. An example is OP1 if Ssn is \\nthe ordering attribute for the EMPLOYEE file.8\\n ■ S3a—Using a primary index. If the selection condition involves an equality \\ncomparison on a key attribute  with a primary index—for example,  \\nSsn = ‘123456789’ in OP1—use the primary index to retrieve the record. \\nNote that this condition retrieves a single record (at most).\\n ■ S3b—Using a hash key. If the selection condition involves an equality com-\\nparison on a key attribute with a hash key—for example, Ssn = ‘123456789’ \\nin OP1—use the hash key to retrieve the record. Note that this condition \\nretrieves a single record (at most).\\n ■ S4—Using a primary index to retrieve multiple records. If the comparison \\ncondition is >, >=, <, or <= on a key field with a primary index—for exam-\\nple, Dnumber > 5 in OP2—use the index to find the record satisfying the cor-\\nresponding equality condition ( Dnumber = 5); then retrieve all subsequent \\nrecords in the (ordered) file. For the condition Dnumber < 5, retrieve all the \\npreceding records.\\n ■ S5—Using a clustering index to retrieve multiple records.  If the selection \\ncondition involves an equality comparison on a nonkey attribute  with a \\nclustering index—for example, Dno = 5 in OP3—use the index to retrieve all \\nthe records satisfying the condition.\\n ■ S6—Using a secondary (B +-tree) index on an equality comparison.  This \\nsearch method can be used to retrieve a single record if the indexing field is \\na key (has unique values) or to retrieve multiple records if the indexing field \\nis not a key. This can also be used for comparisons involving >, >=, <, or <=. \\nQueries involving a range of values (e.g., 3,000 <= Salary <= 4,000) in their \\nselection are called range queries. In case of range queries, the B\\n+-tree index \\nleaf nodes contain the indexing field value in order—so a sequence of them \\nis used corresponding to the requested range of that field and provide record \\npointers to the qualifying records.\\n ■ S7a—Using a bitmap index.  (See Section 17.5.2.) If the selection condi-\\ntion involves a set of values for an attribute (e.g., Dnumber in (3,27,49) \\nin OP6), the corresponding bitmaps for each value can be OR-ed to give \\nthe set of record ids that qualify. In this example, that amounts to  \\nOR-ing three bitmap vectors whose length is the same as the number of \\nemployees.\\n8Generally, binary search is not used in database searches because ordered files are not used unless \\nthey also have a corresponding primary index.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 678, 'page_label': '679'}, page_content='18.3 Algorithms for SELECT Operation  665\\n ■ S7b—Using a functional index. (See Section 17.5.3.) In OP7, the selection con-\\ndition involves the expression ((Salary*Commission_pct) + Salary ). \\nIf there is a functional index defined as (as shown in Section 17.5.3):\\nCREATE INDEX income_ix\\nON EMPLOYEE (Salary + (Salary*Commission_pct)); \\nthen this index can be used to retrieve employee records that qualify. Note \\nthat the exact way in which the function is written while creating the index is \\nimmaterial. \\nIn the next chapter, we discuss how to develop formulas that estimate the access \\ncost of these search methods in terms of the number of block accesses and access \\ntime. Method S1 ( linear search ) applies to any file, but all the other methods \\ndepend on having the appropriate access path on the attribute used in the selection \\ncondition. Method S2 ( binary search) requires the file to be sorted on the search \\nattribute. The methods that use an index (S3a, S4, S5, and S6) are generally referred \\nto as index searches, and they require the appropriate index to exist on the search \\nattribute. Methods S4 and S6 can be used to retrieve records in a certain range in \\nrange queries. Method S7a ( bitmap index search ) is suitable for retrievals where \\nan attribute must match an enumerated set of values. Method S7b ( functional \\nindex search ) is suitable when the match is based on a function of one or more \\nattributes on which a functional index exists.\\n18.3.2 Search Methods for Conjunctive Selection\\nIf a condition of a SELECT operation is a conjunctive condition —that is, if it is \\nmade up of several simple conditions connected with the AND logical connective \\nsuch as OP4 above—the DBMS can use the following additional methods to \\nimplement the operation:\\n ■ S8—Conjunctive selection using an individual index.  If an attribute \\ninvolved in any single simple condition in the conjunctive select condition \\nhas an access path that permits the use of one of the methods S2 to S6, use \\nthat condition to retrieve the records and then check whether each retrieved \\nrecord satisfies the remaining simple conditions  in the conjunctive select \\ncondition.\\n ■ S9—Conjunctive selection using a composite index.  If two or more attri-\\nbutes are involved in equality conditions in the conjunctive select condition \\nand a composite index (or hash structure) exists on the combined fields—\\nfor example, if an index has been created on the composite key (\\nEssn, Pno) of \\nthe WORKS_ON file for OP5—we can use the index directly.\\n ■ S10—Conjunctive selection by intersection of record pointers.9 If second-\\nary indexes (or other access paths) are available on more than one of the \\nfields involved in simple conditions in the conjunctive select condition, and if \\n9A record pointer uniquely identifies a record and provides the address of the record on disk; hence, it is \\nalso called the record identifier or record id.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 679, 'page_label': '680'}, page_content='666 Chapter 18 Strategies for Query Processing\\nthe indexes include record pointers (rather than block pointers), then each \\nindex can be used to retrieve the set of record pointers that satisfy the indi-\\nvidual condition. The intersection of these sets of record pointers gives the \\nrecord pointers that satisfy the conjunctive select condition, which are then \\nused to retrieve those records directly. If only some of the conditions have \\nsecondary indexes, each retrieved record is further tested to determine \\nwhether it satisfies the remaining conditions.\\n10 In general, method S10 \\nassumes that each of the indexes is on a nonkey field of the file, because if one \\nof the conditions is an equality condition on a key field, only one record will \\nsatisfy the whole condition. The bitmap and functional indexes discussed \\nabove in S7 are applicable for conjunctive selection on multiple attributes as \\nwell. For conjunctive selection on multiple attributes, the resulting bitmaps \\nare AND-ed to produce the list of record ids; the same can be done when one \\nor more set of record ids comes from a functional index.\\nWhenever a single condition specifies the selection—such as \\nOP1, OP2, or OP3—\\nthe DBMS can only check whether or not an access path exists on the attribute \\ninvolved in that condition. If an access path (such as index or hash key or bitmap \\nindex or sorted file) exists, the method corresponding to that access path is used; \\notherwise, the brute force, linear search approach of method S1 can be used. Query \\noptimization for a SELECT operation is needed mostly for conjunctive select condi-\\ntions whenever more than one of the attributes involved in the conditions have an \\naccess path. The optimizer should choose the access path that retrieves the fewest \\nrecords in the most efficient way by estimating the different costs (see Section 19.3) \\nand choosing the method with the least estimated cost.\\n18.3.3 Search Methods for Disjunctive Selection\\nCompared to a conjunctive selection condition, a disjunctive condition  (where \\nsimple conditions are connected by the OR logical connective rather than by AND) \\nis much harder to process and optimize. For example, consider OP4′:\\nOP4′: σDno=5 OR Salary > 30000 OR Sex =‘F’ (EMPLOYEE)\\nWith such a condition, the records satisfying the disjunctive condition are the \\nunion of the records satisfying the individual conditions. Hence, if any one of the \\nconditions does not have an access path, we are compelled to use the brute force, \\nlinear search approach. Only if an access path exists on every simple condition in \\nthe disjunction can we optimize the selection by retrieving the records satisfying \\neach condition—or their record ids—and then applying the union operation to \\neliminate duplicates.\\nAll the methods discussed in S1 through S7 are applicable for each simple condition \\nyielding a possible set of record ids. The query optimizer must choose the appropri-\\nate one for executing each \\nSELECT operation in a query. This optimization uses \\n10The technique can have many variations—for example, if the indexes are logical indexes that store primary \\nkey values instead of record pointers.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 680, 'page_label': '681'}, page_content='18.3 Algorithms for SELECT Operation  667\\nformulas that estimate the costs for each available access method, as we will discuss \\nin Sections 19.4 and 19.5. The optimizer chooses the access method with the lowest \\nestimated cost.\\n18.3.4 Estimating the Selectivity of a Condition\\nTo minimize the overall cost of query execution in terms of resources used and \\nresponse time, the query optimizer receives valuable input from the system catalog, \\nwhich contains crucial statistical information about the database.\\nInformation in the Database Catalog. A typical RDBMS catalog contains the \\nfollowing types of information:\\nFor each relation (table) r with schema R containing r\\nR tuples:\\n /box4The number of rows/records or its cardinality: |r(R) |. We will refer to the \\nnumber of rows simply as rR.\\n /box4The “width” of the relation (i.e., the length of each tuple in the relation) \\nthis length of tuple is referred to as R.\\n /box4The number of blocks that relation occupies in storage: referred to as bR.\\n /box4The blocking factor bfr, which is the number of tuples per block.\\nFor each attribute A in relation R:\\n /box4The number of distinct values of A in R: NDV (A, R).\\n /box4The max and min values of attribute A in R: max (A, R) and min (A, R).\\nNote that many other forms of the statistics are possible and may be kept as needed. \\nIf there is a composite index on attributes < A, B>, then the NDV ( R, <A, B>) is of \\nsignificance. An effort is made to keep these statistics as accurate as possible; how-\\never, keeping them accurate up-to-the-minute is considered unnecessary since the \\noverhead of doing so in fairly active databases is too high. We will be revisiting \\nmany of the above parameters again in Section 19.3.2.\\nWhen the optimizer is choosing between multiple simple conditions in a conjunc-\\ntive select condition, it typically considers the selectivity of each condition. The \\nselectivity (sl) is defined as the ratio of the number of records (tuples) that satisfy \\nthe condition to the total number of records (tuples) in the file (relation), and thus \\nit is a number between zero and one. Zero selectivity means none of the records in \\nthe file satisfies the selection condition, and a selectivity of one means that all the \\nrecords in the file satisfy the condition. In general, the selectivity will not be either \\nof these two extremes, but will be a fraction that estimates the percentage of file \\nrecords that will be retrieved.\\nAlthough exact selectivities of all conditions may not be available, estimates of \\n selectivities are possible from the information kept in the DBMS catalog and are used \\nby the optimizer. For example, for an equality condition on a key attribute of relation \\nr(R), s = 1/|r(R)|, where |r(R)| is the number of tuples in relation r(R). For an equality \\ncondition on a nonkey attribute with i distinct values, s  can be estimated by'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 681, 'page_label': '682'}, page_content='668 Chapter 18 Strategies for Query Processing\\n(|r(R)|/i)/|r(R)| or 1/i, assuming that the records are evenly or uniformly distributed \\namong the distinct values. Under this assumption, | r(R)|/i records will satisfy an \\nequality condition on this attribute. For a range query with the selection condition,\\nA ≥ v, assuming uniform distribution,\\nsl = 0 if v > max (A, R)\\nsl = max (A, R) – v / max (A, R) – min (A, R)\\nIn general, the number of records satisfying a selection condition with selectivity sl is \\nestimated to be |r(R)| * sl. The smaller this estimate is, the higher the desirability of \\nusing that condition first to retrieve records. For a nonkey attribute with NDV (A, R) \\ndistinct values, it is often the case that those values are not uniformly distributed.\\nIf the actual distribution of records among the various distinct values of the attribute \\nis kept by the DBMS in the form of a histogram, it is possible to get more accurate \\nestimates of the number of records that satisfy a particular condition. We will discuss \\nthe catalog information and histograms in more detail in Section 19.3.3.\\n18.4 Implementing the JOI N Operation\\nThe JOIN operation is one of the most time-consuming operations in query pro-\\ncessing. Many of the join operations encountered in queries are of the EQUIJOIN \\nand NATURAL JOIN varieties, so we consider just these two here since we are only \\ngiving an overview of query processing and optimization. For the remainder of this \\nchapter, the term join refers to an \\nEQUIJOIN (or NATURAL JOIN).\\nThere are many possible ways to implement a two-way join, which is a join on two \\nfiles. Joins involving more than two files are called multiway joins. The number of \\npossible ways to execute multiway joins grows rapidly because of the combinatorial \\nexplosion of possible join orderings. In this section, we discuss techniques for \\nimplementing only two-way joins. To illustrate our discussion, we refer to the rela-\\ntional schema shown in Figure 5.5 once more—specifically, to the \\nEMPLOYEE, \\nDEPARTMENT, and PROJECT relations. The algorithms we discuss next are for a join \\noperation of the form:\\nR  A=B S\\nwhere A and B are the join attributes, which should be domain-compatible attri-\\nbutes of R and S, respectively. The methods we discuss can be extended to more \\ngeneral forms of join. We illustrate four of the most common techniques for per-\\nforming such a join, using the following sample operations:\\nOP6: EMPLOYEE  Dno=Dnumber DEPARTMENT\\nOP7: DEPARTMENT  Mgr_ssn=Ssn EMPLOYEE\\n18.4.1 Methods for Implementing Joins\\n ■ J1—Nested-loop join (or nested-block join). This is the default (brute force) \\nalgorithm because it does not require any special access paths on either file in the'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 682, 'page_label': '683'}, page_content='18.4 Implementing the JOIN Operation  669\\njoin. For each record t in R (outer loop), retrieve every record s from S (inner \\nloop) and test whether the two records satisfy the join condition t[A] = s[B].11\\n ■ J2—Index-based nested-loop join (using an access structure to retrieve \\nthe matching records).  If an index (or hash key) exists for one of the two \\njoin attributes—say, attribute B of file S—retrieve each record t in R (loop \\nover file R), and then use the access structure (such as an index or a hash \\nkey) to retrieve directly all matching records s from S that satisfy s[B] = t[A].\\n ■ J3—Sort-merge join. If the records of R and S are physically sorted (ordered) \\nby value of the join attributes A and B, respectively, we can implement the join \\nin the most efficient way possible. Both files are scanned concurrently in order \\nof the join attributes, matching the records that have the same values for A and \\nB. If the files are not sorted, they may be sorted first by using external sorting \\n(see Section 18.2). In this method, pairs of file blocks are copied into memory \\nbuffers in order and the records of each file are scanned only once each for \\nmatching with the other file—unless both A and B are nonkey attributes, in \\nwhich case the method needs to be modified slightly. A sketch of the sort-\\nmerge join algorithm is given in Figure 18.3(a). We use R(i) to refer to the ith \\nrecord in file R. A variation of the sort-merge join can be used when secondary \\nindexes exist on both join attributes. The indexes provide the ability to access \\n(scan) the records in order of the join attributes, but the records themselves \\nare physically scattered all over the file blocks, so this method may be ineffi-\\ncient because every record access may involve accessing a different disk block.\\n ■ J4—Partition-hash join (or just hash-join). The records of files R and S are \\npartitioned into smaller files. The partitioning of each file is done using the \\nsame hashing function h on the join attribute A of R (for partitioning file R) \\nand B of S (for partitioning file S). First, a single pass through the file with \\nfewer records (say, R) hashes its records to the various partitions of R; this is \\ncalled the partitioning phase, since the records of R are partitioned into the \\nhash buckets. In the simplest case, we assume that the smaller file can fit \\nentirely in main memory after it is partitioned, so that the partitioned subfiles \\nof R are all kept in main memory. The collection of records with the same \\nvalue of h(A) are placed in the same partition, which is a hash bucket in a hash \\ntable in main memory. In the second phase, called the probing phase, a single \\npass through the other file (S) then hashes each of its records using the same \\nhash function h(B) to probe the appropriate bucket, and that record is com-\\nbined with all matching records from R in that bucket. This simplified descrip-\\ntion of partition-hash join assumes that the smaller of the two files fits entirely \\ninto memory buckets after the first phase. We will discuss the general case of \\npartition-hash join below that does not require this assumption. In practice, \\ntechniques J1 to J4 are implemented by accessing whole disk blocks of a file, \\nrather than individual records. Depending on the available number of buffers \\nin memory, the number of blocks read in from the file can be adjusted.\\n11For disk files, it is obvious that the loops will be over disk blocks, so this technique has also been called \\nnested-block join.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 683, 'page_label': '684'}, page_content='670 Chapter 18 Strategies for Query Processing\\n(a) sort the tuples in R on attribute A;        (*assume R has n tuples (records)*) \\n sort the tuples in S on attribute B;        (*assume S has m tuples (records)*)\\n set i ←1, j ← 1; \\n while (i ≤n) and (j ≤ m) \\n do { if R(i)[A] > S(j)[B] \\n   then set j ← j + 1\\n  elseif R(i)[A] < S(j)[B] \\n      then set i ← i + 1\\n  else { (* R(i)[A] = S(j)[B], so we output a matched tuple *)\\n       output the combined tuple <R(i), S(j)> to T;\\n       (* output other tuples that match R(i), if any *)\\n       set I ← j + 1; \\n       while (l ≤ m) and (R(i)[A] = S(l)[B]) \\n       do { output the combined tuple < R(i), S(l)> to T; \\n           set l ← l + 1\\n       }\\n    (* output other tuples that match S(j), if any *)\\n    set k ← i + 1; \\n    while (k ≤ n) and (R(k)[A] = S(j)[B]) \\n    do { output the combined tuple < R(k), S(j)> to T; \\n           set k ← k + 1\\n    }\\n    set i ←k, j ← l\\n  }\\n }\\n(b) create a tuple t[<attribute list>] in T′ for each tuple t in R; \\n  (* T′ contains the projection results before duplicate elimination *)\\n if <attribute list> includes a key of R\\n  then T ← T′\\n else { sort the tuples in T ′;\\n    set i ← 1, j ← 2; \\n    while i ≤ n\\n    do { output the tuple T′[i] to T; \\n        while T′[i] = T′[j] and j ≤ n do j ← j + 1;    (* eliminate duplicates *)\\n        i ← j; j ← i + 1\\n    }\\n }\\n (*T contains the projection result after duplicate elimination*)\\nFigure 18.3 \\nImplementing JOIN, PROJECT, UNION, INTERSECTION, and SET DIFFERENCE by  \\nusing sort-merge, where R has n tuples and S has m tuples. (a) Implementing the operation  \\nT ← R \\n A=BS. (b) Implementing the operation T ← π<attribute list>(R).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 684, 'page_label': '685'}, page_content='18.4 Implementing the JOIN Operation  671\\n(c) sort the tuples in R and S using the same unique sort attributes;\\n set i ← 1, j ← 1; \\n while (i ≤ n) and ( j ≤ m) \\n do { if R(i) > S( j)\\n      then { output S(j) to T;\\n       set j ← j + 1\\n      }\\n   elseif R(i) < S( j)\\n      then { output R(i) to T;\\n       set i ← i + 1\\n      }\\n   else set j ← j + 1        (* R(i)=S(j), so we skip one of the duplicate tuples *)\\n }\\n if (i ≤ n) then add tuples R(i) to R(n) to T; \\n if (j ≤ m) then add tuples S(j) to S(m) to T; \\n(d) sort the tuples in R and S using the same unique sort attributes;\\n set i ← 1, j ← 1; \\n while (i ≤ n) and ( j ≤ m) \\n do { if R(i) > S(j)\\n      then set j ← j + 1\\n   elseif R(i) < S(j)\\n      then set i ← i + 1\\n   else { output R( j) to T;     (* R(i) = S( j), so we output the tuple *)\\n       set i ← i + 1, j ← j + 1\\n   }\\n }\\n(e) sort the tuples in R and S using the same unique sort attributes;\\n set i ← 1, j ← 1; \\n while (i ≤ n) and ( j ≤ m) \\n do { if R(i) > S(j )\\n      then set j ← j + 1\\n   elseif R(i) < S( j)\\n      then { output R(i) to T;    (* R(i) has no matching S( j), so output R(i) *)\\n           set i ← i + 1\\n      }\\n   else set i ← i + 1, j ← j + 1\\n }\\n if (i ≤ n) then add tuples R(i) to R(n) to T; \\nFigure 18.3 (continued)\\nImplementing JOIN, PROJECT, UNION, INTERSECTION, and SET DIFFERENCE by using  \\nsort-merge, where R has n tuples and S has m tuples. (c) Implementing the operation T ← R ∪ S.  \\n(d) Implementing the operation T ← R ∩ S. (e) Implementing the operation T ← R – S.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 685, 'page_label': '686'}, page_content='672 Chapter 18 Strategies for Query Processing\\n18.4.2  How Buffer Space and Choice of Outer-Loop  \\nFile Affect Performance of Nested-Loop Join\\nThe buffer space available has an important effect on some of the join algorithms. \\nFirst, let us consider the nested-loop approach (J1). Looking again at the operation \\nOP6 above, assume that the number of buffers available in main memory for imple-\\nmenting the join is nB = 7 blocks (buffers). Recall that we assume that each memory \\nbuffer is the same size as one disk block. For illustration, assume that the DEPARTMENT \\nfile consists of rD = 50 records stored in bD = 10 disk blocks and that the EMPLOYEE \\nfile consists of rE = 6,000 records stored in bE = 2,000 disk blocks. It is advantageous \\nto read as many blocks as possible at a time into memory from the file whose records \\nare used for the outer loop. Note that keeping one block for reading from the inner \\nfile and one block for writing to the output file, n\\nB − 2 blocks are available to read \\nfrom the outer relation, The algorithm can then read one block at a time for the \\ninner-loop file and use its records to probe (that is, search) the outer-loop blocks \\nthat are currently in main memory for matching records. This reduces the total \\nnumber of block accesses. An extra buffer in main memory is needed to contain \\nthe resulting records after they are joined, and the contents of this result buffer can \\nbe appended to the result file —the disk file that will contain the join result—\\nwhenever it is filled. This result buffer block then is reused to hold additional join \\nresult records.\\nIn the nested-loop join, it makes a difference which file is chosen for the outer loop \\nand which for the inner loop. If \\nEMPLOYEE is used for the outer loop, each block of \\nEMPLOYEE is read once, and the entire DEPARTMENT file (each of its blocks) is read \\nonce for each time we read in (nB – 2) blocks of the EMPLOYEE file. We get the fol-\\nlowing formulas for the number of disk blocks that are read from disk to main \\nmemory:\\nTotal number of blocks accessed (read) for outer-loop file = b\\nE\\nNumber of times ( nB − 2) blocks of outer file are loaded into main mem-\\nory = ⎡bE/(nB – 2)⎤\\nTotal number of blocks accessed (read) for inner-loop file = bD * ⎡bE/(nB – 2)⎤\\nHence, we get the following total number of block read accesses:\\nbE + ( ⎡bE/(nB − 2)⎤ * bD) = 2000 + ( ⎡(2000/5)⎤ * 10) = 6000 block accesses\\nOn the other hand, if we use the DEPARTMENT records in the outer loop, by sym-\\nmetry we get the following total number of block accesses:\\nbD + ( ⎡bD/(nB − 2)⎤ * bE) = 10 + ( ⎡(10/5)⎤ * 2000) = 4010 block accesses\\nThe join algorithm uses a buffer to hold the joined records of the result file. Once \\nthe buffer is filled, it is written to disk and its contents are appended to the result \\nfile, and then refilled with join result records.\\n12\\n12If we reserve two buffers for the result file, double buffering can be used to speed the algorithm (see \\nSection 16.3).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 686, 'page_label': '687'}, page_content='18.4 Implementing the JOIN Operation  673\\nIf the result file of the join operation has bRES disk blocks, each block is written once \\nto disk, so an additional bRES block accesses (writes) should be added to the preced-\\ning formulas in order to estimate the total cost of the join operation. The same \\nholds for the formulas developed later for other join algorithms. As this example \\nshows, it is advantageous to use the file with fewer blocks as the outer-loop file in the \\nnested-loop join.\\n18.4.3  How the Join Selection Factor Affects  \\nJoin Performance\\nAnother factor that affects the performance of a join, particularly the single-loop \\nmethod J2, is the fraction of records in one file that will be joined with records in \\nthe other file. We call this the join selection factor\\n13 of a file with respect to an \\nequijoin condition with another file. This factor depends on the particular equijoin \\ncondition between the two files. To illustrate this, consider the operation \\nOP7, \\nwhich joins each DEPARTMENT record with the EMPLOYEE record for the manager \\nof that department. Here, each DEPARTMENT record (there are 50 such records in \\nour example) will be joined with a single EMPLOYEE record, but many EMPLOYEE \\nrecords (the 5,950 of them that do not manage a department) will not be joined \\nwith any record from \\nDEPARTMENT.\\nSuppose that secondary indexes exist on both the attributes Ssn of EMPLOYEE and \\nMgr_ssn of DEPARTMENT, with the number of index levels xSsn = 4 and xMgr_ssn= 2, \\nrespectively. We have two options for implementing method J2. The first retrieves \\neach \\nEMPLOYEE record and then uses the index on Mgr_ssn of DEPARTMENT to find \\na matching DEPARTMENT record. In this case, no matching record will be found for \\nemployees who do not manage a department. The number of block accesses for this \\ncase is approximately:\\nb\\nE + (rE * (xMgr_ssn + 1)) = 2000 + (6000 * 3) = 20,000 block accesses\\nThe second option retrieves each DEPARTMENT record and then uses the index on \\nSsn of EMPLOYEE to find a matching manager EMPLOYEE record. In this case, every \\nDEPARTMENT record will have one matching EMPLOYEE record. The number of \\nblock accesses for this case is approximately:\\nbD + (rD * (xSsn + 1)) = 10 + (50 * 5) = 260 block accesses\\nThe second option is more efficient because the join selection factor of DEPARTMENT \\nwith respect to the join condition Ssn = Mgr_ssn is 1 (every record in DEPARTMENT  \\nwill be joined), whereas the join selection factor of EMPLOYEE with respect to the \\nsame join condition is (50/6,000), or 0.008 (only 0.8% of the records in EMPLOYEE \\nwill be joined). For method J2, either the smaller file or the file that has a match for \\nevery record (that is, the file with the high join selection factor) should be used in \\nthe (single) join loop. It is also possible to create an index specifically for perform-\\ning the join operation if one does not already exist.\\n13This is different from the join selectivity, which we will discuss in Chapter 19.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 687, 'page_label': '688'}, page_content='674 Chapter 18 Strategies for Query Processing\\nThe sort-merge join J3 is quite efficient if both files are already sorted by their join \\nattribute. Only a single pass is made through each file. Hence, the number of blocks \\naccessed is equal to the sum of the numbers of blocks in both files. For this method, \\nboth \\nOP6 and OP7 would need bE + bD = 2,000 + 10 = 2,010 block accesses. How-\\never, both files are required to be ordered by the join attributes; if one or both are \\nnot, a sorted copy of each file must be created specifically for performing the join \\noperation. If we roughly estimate the cost of sorting an external file by ( b log\\n2b) \\nblock accesses, and if both files need to be sorted, the total cost of a sort-merge join \\ncan be estimated by (b\\nE + bD + bE log2bE + bD log2bD).14\\n18.4.4 General Case for Partition-Hash Join\\nThe hash-join method J4 is also efficient. In this case, only a single pass is made \\nthrough each file, whether or not the files are ordered. If the hash table for the \\nsmaller of the two files can be kept entirely in main memory after hashing (parti-\\ntioning) on its join attribute, the implementation is straightforward. If, however, \\nthe partitions of both files must be stored on disk, the method becomes more com-\\nplex, and a number of variations to improve the efficiency have been proposed. We \\ndiscuss two techniques: the general case of partition-hash join and a variation called \\nhybrid hash-join algorithm, which has been shown to be efficient.\\nIn the general case of partition-hash join, each file is first partitioned into M parti-\\ntions using the same partitioning hash function on the join attributes. Then, each \\npair of corresponding partitions is joined. For example, suppose we are joining \\nrelations R and S on the join attributes R.A and S.B:\\nR \\n A=B S\\nIn the partitioning phase, R is partitioned into the M partitions R1, R2, … , RM, and S \\ninto the M partitions S1, S2, …, SM. The property of each pair of corresponding parti-\\ntions Ri, Si with respect to the join operation is that records in Ri only need to be joined \\nwith records in Si, and vice versa. This property is ensured by using the same hash \\nfunction to partition both files on their join attributes—attribute A for R and attribute \\nB for S. The minimum number of in-memory buffers needed for the partitioning \\nphase is M + 1. Each of the files R and S is partitioned separately. During partitioning \\nof a file, M in-memory buffers are allocated to store the records that hash to each par-\\ntition, and one additional buffer is needed to hold one block at a time of the input file \\nbeing partitioned. Whenever the in-memory buffer for a partition gets filled, its con-\\ntents are appended to a disk subfile that stores the partition. The partitioning phase \\nhas two iterations. After the first iteration, the first file R is partitioned into the subfiles \\nR\\n1, R2, … , RM, where all the records that hashed to the same buffer are in the same \\npartition. After the second iteration, the second file S is similarly partitioned.\\nIn the second phase, called the joining or probing phase, M iterations are needed. \\nDuring iteration i, two corresponding partitions Ri and Si are joined. The minimum \\n14We can use the more accurate formulas from Section 19.5 if we know the number of available buffers \\nfor sorting.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 688, 'page_label': '689'}, page_content='18.4 Implementing the JOIN Operation  675\\nnumber of buffers needed for iteration i is the number of blocks in the smaller of \\nthe two partitions, say Ri, plus two additional buffers. If we use a nested-loop join \\nduring iteration i, the records from the smaller of the two partitions Ri are copied \\ninto memory buffers; then all blocks from the other partition Si are read—one at a \\ntime—and each record is used to probe (that is, search) partition Ri for matching \\nrecord(s). Any matching records are joined and written into the result file. To \\nimprove the efficiency of in-memory probing, it is common to use an in-memory \\nhash table  for storing the records in partition R\\ni by using a different  hash func-\\ntion from the partitioning hash function. 15\\nWe can approximate the cost of this partition hash-join as 3 * (bR + bS) + bRES for our \\nexample, since each record is read once and written back to disk once during the \\npartitioning phase. During the joining (probing) phase, each record is read a second \\ntime to perform the join. The main difficulty of this algorithm is to ensure that the \\npartitioning hash function is uniform—that is, the partition sizes are nearly equal in \\nsize. If the partitioning function is skewed (nonuniform), then some partitions may \\nbe too large to fit in the available memory space for the second joining phase.\\nNotice that if the available in-memory buffer space n\\nB > ( bR + 2), where bR is the \\nnumber of blocks for the smaller of the two files being joined, say R, then there is no \\nreason to do partitioning since in this case the join can be performed entirely in \\nmemory using some variation of the nested-loop join based on hashing and probing. \\nFor illustration, assume we are performing the join operation \\nOP6, repeated below:\\nOP6: EMPLOYEE  Dno=Dnumber DEPARTMENT\\nIn this example, the smaller file is the DEPARTMENT file; hence, if the number of \\navailable memory buffers nB > ( bD + 2), the whole DEPARTMENT file can be read \\ninto main memory and organized into a hash table on the join attribute. Each \\nEMPLOYEE block is then read into a buffer, and each EMPLOYEE record in the buf-\\nfer is hashed on its join attribute and is used to probe the corresponding in-memory \\nbucket in the DEPARTMENT hash table. If a matching record is found, the records \\nare joined, and the result record(s) are written to the result buffer and eventually to \\nthe result file on disk. The cost in terms of block accesses is hence ( b\\nD + bE), plus \\nbRES—the cost of writing the result file.\\n18.4.5 Hybrid Hash-Join\\nThe hybrid hash-join algorithm is a variation of partition hash-join, where the join-\\ning phase for one of the partitions is included in the partitioning phase. To illustrate \\nthis, let us assume that the size of a memory buffer is one disk block; that nB such \\nbuffers are available ; and that the partitioning hash function used is h(K) =  \\nK mod M, so that M partitions are being created, where M < nB. For illustration, \\nassume we are performing the join operation OP6. In the first pass of the partitioning \\nphase, when the hybrid hash-join algorithm is partitioning the smaller of the two files \\n15If the hash function used for partitioning is used again, all records in a partition will hash to the same \\nbucket again.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 689, 'page_label': '690'}, page_content='676 Chapter 18 Strategies for Query Processing\\n(DEPARTMENT in OP6), the algorithm divides the buffer space among the M parti-\\ntions such that all the blocks of the first partition of DEPARTMENT completely reside \\nin main memory. For each of the other partitions, only a single in-memory buffer—\\nwhose size is one disk block—is allocated; the remainder of the partition is written to \\ndisk as in the regular partition-hash join. Hence, at the end of the first pass of the \\npartitioning phase, the first partition of \\nDEPARTMENT resides wholly in main mem-\\nory, whereas each of the other partitions of DEPARTMENT resides in a disk subfile.\\nFor the second pass of the partitioning phase, the records of the second file being \\njoined—the larger file, EMPLOYEE  in OP6—are being partitioned. If a record \\nhashes to the first partition, it is joined with the matching record in DEPARTMENT \\nand the joined records are written to the result buffer (and eventually to disk). If \\nan \\nEMPLOYEE record hashes to a partition other than the first, it is partitioned \\nnormally and stored to disk. Hence, at the end of the second pass of the partition-\\ning phase, all records that hash to the first partition have been joined. At this point, \\nthere are M − 1 pairs of partitions on disk. Therefore, during the second joining or \\nprobing phase, M − 1 iterations are needed instead of M. The goal is to join as \\nmany records during the partitioning phase so as to save the cost of storing those \\nrecords on disk and then rereading them a second time during the joining phase.\\n18.5  Algorithms for PROJECT  \\nand Set Operations\\nA PROJECT operation π <attribute list> (R) from relational algebra implies that after \\nprojecting R on only the columns in the list of attributes, any duplicates are removed \\nby treating the result strictly as a set of tuples. However, the SQL query:\\nSELECT Salary\\nFROM EMPLOYEE\\nproduces a list of salaries of all employees. If there are 10,000 employees and only 80 \\ndistinct values for salary, it produces a one column result with 10,000 tuples. This oper-\\nation is done by simple linear search by making a complete pass through the table.\\nGetting the true effect of the relational algebra π\\n<attribute list>(R) operator is straight-\\nforward to implement if <attribute list> includes a key of relation R, because in this \\ncase the result of the operation will have the same number of tuples as R, but with \\nonly the values for the attributes in <attribute list> in each tuple. If <attribute list> \\ndoes not include a key of R, duplicate tuples must be eliminated. This can be done by \\nsorting the result of the operation and then eliminating duplicate tuples, which \\nappear consecutively after sorting. A sketch of the algorithm is given in Fig-\\nure 18.3(b). Hashing can also be used to eliminate duplicates: as each record is \\nhashed and inserted into a bucket of the hash file in memory, it is checked against \\nthose records already in the bucket; if it is a duplicate, it is not inserted in the bucket. \\nIt is useful to recall here that in SQL queries, the default is not to eliminate dupli-\\ncates from the query result; duplicates are eliminated from the query result only if \\nthe keyword \\nDISTINCT is included.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 690, 'page_label': '691'}, page_content='18.5 Algorithms for PROJECT and Set Operations  677\\nSet operations— UNION , INTERSECTION , SET DIFFERENCE , and CARTESIAN  \\nPRODUCT —are sometimes expensive to implement, since UNION,  \\nINTERSECTION, MINUS or SET DIFFERENCE are set operators and must always \\nreturn distinct results.\\nIn particular, the \\nCARTESIAN PRODUCT operation R × S is expensive because its \\nresult includes a record for each combination of records from R and S. Also, each \\nrecord in the result includes all attributes of R and S. If R has n records and j attri-\\nbutes, and S has m records and k attributes, the result relation for R × S will have \\nn * m records and each record will have j + k attributes. Hence, it is important to \\navoid the CARTESIAN PRODUCT operation and to substitute other operations such \\nas join during query optimization. The other three set operations— UNION ,  \\nINTERSECTION , and SET DIFFERENCE 16—apply only to type-compatible  (or \\nunion-compatible) relations, which have the same number of attributes and the \\nsame attribute domains. The customary way to implement these operations is to \\nuse variations of the sort-merge technique:  the two relations are sorted on the \\nsame attributes, and, after sorting, a single scan through each relation is sufficient \\nto produce the result. For example, we can implement the \\nUNION operation, R ∪ S, \\nby scanning and merging both sorted files concurrently, and whenever the \\nsame tuple exists in both relations, only one is kept in the merged result. For the \\nINTERSECTION operation, R ∩ S, we keep in the merged result only those tuples \\nthat appear in both sorted relations. Figure 18.3(c) to (e) sketches the implementa-\\ntion of these operations by sorting and merging. Some of the details are not \\nincluded in these algorithms.\\nHashing  can also be used to implement UNION , INTERSECTION , and SET  \\nDIFFERENCE. One table is first scanned and then partitioned into an in-memory \\nhash table with buckets, and the records in the other table are then scanned one at a \\ntime and used to probe the appropriate partition. For example, to implement R ∪ S, \\nfirst hash (partition) the records of R; then, hash (probe) the records of S, but do not \\ninsert duplicate records in the buckets. To implement R ∩ S, first partition the \\nrecords of R to the hash file. Then, while hashing each record of S, probe to check if \\nan identical record from R is found in the bucket, and if so add the record to the \\nresult file. To implement R – S, first hash the records of R to the hash file buckets. \\nWhile hashing (probing) each record of S, if an identical record is found in the \\nbucket, remove that record from the bucket.\\n18.5.1  Use of Anti-Join for SET DIFFERENCE  \\n(or EXCEPT or MINUS in SQL)\\nThe MINUS operator in SQL is transformed into an anti-join (which we introduced \\nin Section 18.1) as follows. Suppose we want to find out which departments have no \\nemployees in the schema of Figure 5.5:\\nSelect Dnumber from DEPARTMENT MINUS Select Dno from EMPLOYEE;\\n16SET DIFFERENCE is called MINUS or EXCEPT in SQL.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 691, 'page_label': '692'}, page_content='678 Chapter 18 Strategies for Query Processing\\ncan be converted into the following:\\nSELECT DISTINCT DEPARTMENT.Dnumber\\nFROM DEPARTMENT, EMPLOYEE\\nWHERE DEPARTMENT.Dnumber A = EMPLOYEE.Dno\\nWe used the nonstandard notation for anti-join, “A=”, where DEPARTMENT is on \\nthe left of anti-join and EMPLOYEE is on the right.\\nIn SQL, there are two variations of these set operations. The operations \\nUNION , INTERSECTION , and EXCEPT  or MINUS (the SQL keywords for the SET \\nDIFFERENCE  operation) apply to traditional sets, where no duplicate records \\nexist in the result. The operations UNION ALL , INTERSECTION ALL , and EXCEPT \\nALL apply to multisets (or bags). Thus, going back to the database of Figure 5.5, \\nconsider a query that finds all departments that employees are working on \\nwhere at least one project exists controlled by that department, and this result \\nis written as:\\nSELECT Dno from EMPLOYEE\\nINTERSECT ALL\\nSELECT Dum from PROJECT\\nThis would not eliminate any duplicates of Dno from EMPLOYEE while perform-\\ning the INTERSECTION. If all 10,000 employees are assigned to departments \\nwhere some project is present in the PROJECT relation, the result would be the list \\nof all the 10,000 department numbers including duplicates.. This can be accom-\\nplished by the semi-join operation we introduced in Section 18.1 as follows:\\nSELECT DISTINCT EMPLOYEE.Dno\\nFROM DEPARTMENT, EMPLOYEE\\nWHERE EMPLOYEE.Dno\\n S = DEPARTMENT.Dnumber\\nIf INTERSECTION is used without the ALL, then an additional step of duplicate \\nelimination will be required for the selected department numbers.\\n18.6  Implementing Aggregate Operations  \\nand Different Types of JOINs\\n18.6.1 Implementing Aggregate Operations\\nThe aggregate operators ( MIN, MAX, COUNT, AVERAGE, SUM), when applied to an \\nentire table, can be computed by a table scan or by using an appropriate index, if \\navailable. For example, consider the following SQL query:\\nSELECT MAX(Salary)\\nFROM EMPLOYEE ;\\nIf an (ascending) B +-tree index on Salary exists for the EMPLOYEE relation, then \\nthe optimizer can decide on using the Salary index to search for the largest Salary \\nvalue in the index by following the rightmost pointer in each index node from the'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 692, 'page_label': '693'}, page_content='18.6 Implementing Aggregate Operations and Different Types of JOINs  679\\nroot to the rightmost leaf. That node would include the largest Salary value as its \\nlast entry. In most cases, this would be more efficient than a full table scan of \\nEMPLOYEE, since no actual records need to be retrieved. The MIN function can be \\nhandled in a similar manner, except that the leftmost pointer in the index is fol-\\nlowed from the root to leftmost leaf. That node would include the smallest Salary \\nvalue as its first entry.\\nThe index could also be used for the AVERAGE  and SUM aggregate functions, \\nbut only if it is a dense index —that is, if there is an index entry for every record \\nin the main file. In this case, the associated computation would be applied to \\nthe values in the index. For a nondense index , the actual number of records \\nassociated with each index value must be used for a correct computation. This \\ncan be done if the number of records associated with each value  in the index is \\nstored in each index entry. For the \\nCOUNT aggregate function, the number of \\nvalues can be also computed from the index in a similar manner. If a COUNT(*) \\nfunction is applied to a whole relation, the number of records currently in each \\nrelation are typically stored in the catalog, and so the result can be retrieved \\ndirectly from the catalog.\\nWhen a \\nGROUP BY clause is used in a query, the aggregate operator must be applied \\nseparately to each group of tuples as partitioned by the grouping attribute. Hence, \\nthe table must first be partitioned into subsets of tuples, where each partition \\n(group) has the same value for the grouping attributes. In this case, the computa-\\ntion is more complex. Consider the following query:\\nSELECT Dno , AVG(Salary) \\nFROM EMPLOYEE\\nGROUP BY Dno ;\\nThe usual technique for such queries is to first use either sorting or hashing on the \\ngrouping attributes to partition the file into the appropriate groups. Then the algo-\\nrithm computes the aggregate function for the tuples in each group, which have the \\nsame grouping attribute(s) value. In the sample query, the set of \\nEMPLOYEE tuples \\nfor each department number would be grouped together in a partition and the \\naverage salary computed for each group.\\nNotice that if a clustering index (see Chapter 17) exists on the grouping attribute(s), \\nthen the records are already partitioned (grouped) into the appropriate subsets. In \\nthis case, it is only necessary to apply the computation to each group.\\n18.6.2 Implementing Different Types of JOINs\\nIn addition to the standard JOIN (also called INNER JOIN in SQL), there are varia-\\ntions of JOIN that are frequently used. Let us briefly consider three of them below: \\nouter joins, semi-joins, and anti-joins.\\nOuter Joins.  In Section 6.4, we discussed the outer join operation , with its three \\nvariations: left outer join, right outer join, and full outer join. In Chapter 5, we'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 693, 'page_label': '694'}, page_content='680 Chapter 18 Strategies for Query Processing\\ndiscussed how these operations can be specified in SQL. The following is an exam-\\nple of a left outer join operation in SQL:\\nSELECT E.Lname , E.Fname, D.Dname\\nFROM (EMPLOYEE E LEFT OUTER JOIN DEPARTMENT D ON E.Dno = D.Dnumber);\\nThe result of this query is a table of employee names and their associated depart-\\nments. The table contains the same results as a regular (inner) join, with the excep-\\ntion that if an \\nEMPLOYEE  tuple (a tuple in the left relation) does not have an \\nassociated department, the employee’s name will still appear in the resulting table, \\nbut the department name would be NULL for such tuples in the query result. Outer \\njoin can be looked upon as a combination of inner join and anti-join.\\nOuter join can be computed by modifying one of the join algorithms, such as \\nnested-loop join or single-loop join. For example, to compute a left outer join, we \\nuse the left relation as the outer loop or index-based nested loop because every tuple \\nin the left relation must appear in the result. If there are matching tuples in the \\nother relation, the joined tuples are produced and saved in the result. However, if \\nno matching tuple is found, the tuple is still included in the result but is padded \\nwith \\nNULL value(s). The sort-merge and hash-join algorithms can also be extended \\nto compute outer joins.\\nTheoretically, outer join can also be computed by executing a combination of rela-\\ntional algebra operators. For example, the left outer join operation shown above is \\nequivalent to the following sequence of relational operations:\\n  1. Compute the (inner) JOIN of the EMPLOYEE and DEPARTMENT tables.\\nTEMP1 ← πLname, Fname, Dname (EMPLOYEE  Dno=Dnumber DEPARTMENT)\\n  2. Find the EMPLOYEE tuples that do not appear in the (inner) JOIN result.\\nTEMP2 ← πLname, Fname (EMPLOYEE) − πLname, Fname (TEMP1)\\nThis minus operation can be achieved by performing an anti-join on  \\nLname, Fname between EMPLOYEE and TEMP1, as we discussed above in \\nSection 18.5.2.\\n  3. Pad each tuple in TEMP2 with a NULL Dname field.\\nTEMP2 ← TEMP2 × NULL\\n  4. Apply the UNION operation to TEMP1, TEMP2 to produce the LEFT OUTER \\nJOIN result.\\nRESULT ← TEMP1 ∪ TEMP2\\nThe cost of the outer join as computed above would be the sum of the costs of the \\nassociated steps (inner join, projections, set difference, and union). However, note \\nthat step 3 can be done as the temporary relation is being constructed in step 2; that \\nis, we can simply pad each resulting tuple with a NULL. In addition, in step 4, we \\nknow that the two operands of the union are disjoint (no common tuples), so there \\nis no need for duplicate elimination. So the preferred method is to use a combina-\\ntion of inner join and anti-join rather than the above steps since the algebraic'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 694, 'page_label': '695'}, page_content='18.7 Combining Operations Using Pipelining  681\\napproach of projection followed by set difference causes temporary tables to be \\nstored and processed multiple times.\\nThe right outer join can be converted to a left outer join by switching the operands \\nand hence needs no separate discussion. Full outer join  requires computing the \\nresult of inner join and then padding to the result extra tuples arising from \\nunmatched tuples from both the left and right operand relations. Typically, full \\nouter join would be computed by extending sort-merge or hashed join algorithms \\nto account for the unmatched tuples.\\nImplementing Semi-Join and Anti-Join. In Section 18.1, we introduced these types \\nof joins as possible operations to which some queries with nested subqueries get \\nmapped. The purpose is to be able to perform some variant of join instead of evaluat-\\ning the subquery multiple times. Use of inner join would be invalid in these cases, since \\nfor every tuple of the outer relation, the inner join looks for all possible matches on the \\ninner relation. In semi-join, the search stops as soon as the first match is found and the \\ntuple from outer relation is selected; in anti-join, search stops as soon as the first match \\nis found and the tuple from outer relation is rejected. Both these types of joins can be \\nimplemented as an extension of the join algorithms we discussed in Section 18.4.\\nImplementing Non-Equi-Join  Join operation may also be performed when the \\njoin condition is one of inequality. In Chapter 6, we referred to this operation as \\ntheta-join.This functionality is based on a condition involving any operators, such \\nas <, >, ≥, ≤, ≠, and so on. All of the join methods discussed are again applicable \\nhere with the exception that hash-based algorithms cannot be used.\\n18.7 Combining Operations Using Pipelining\\nA query specified in SQL will typically be translated into a relational algebra expres-\\nsion that is a sequence of relational operations. If we execute a single operation at a \\ntime, we must generate temporary files on disk to hold the results of these tempo-\\nrary operations, creating excessive overhead. Evaluating a query by creating and \\nstoring each temporary result and then passing it as an argument for the next oper-\\nator is called materialized evaluation. Each temporary materialized result is then \\nwritten to disk and adds to the overall cost of query processing.\\nGenerating and storing large temporary files on disk is time-consuming and can be \\nunnecessary in many cases, since these files will immediately be used as input to the \\nnext operation. To reduce the number of temporary files, it is common to generate \\nquery execution code that corresponds to algorithms for combinations of opera-\\ntions in a query.\\nFor example, rather than being implemented separately, a \\nJOIN can be combined \\nwith two SELECT operations on the input files and a final PROJECT operation on \\nthe resulting file; all this is implemented by one algorithm with two input files and \\na single output file. Rather than creating four temporary files, we apply the algo-\\nrithm directly and get just one result file.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 695, 'page_label': '696'}, page_content='682 Chapter 18 Strategies for Query Processing\\nIn Section 19.1, we discuss how heuristic relational algebra optimization can group \\noperations together for execution. Combining several operations into one and \\navoiding the writing of temporary results to disk is called pipelining or stream-\\nbased processing.\\nIt is common to create the query execution code dynamically to implement multi-\\nple operations. The generated code for producing the query combines several algo-\\nrithms that correspond to individual operations. As the result tuples from one \\noperation are produced, they are provided as input for subsequent operations. For \\nexample, if a join operation follows two select operations on base relations, the \\ntuples resulting from each select are provided as input for the join algorithm in a \\nstream or pipeline as they are produced. The corresponding evaluation is consid-\\nered a pipelined evaluation. It has two distinct benefits:\\n ■ Avoiding the additional cost and time delay incurred for writing the inter-\\nmediate results to disk.\\n ■ Being able to start generating results as quickly as possible when the root \\noperator is combined with some of the operators discussed in the follow-\\ning section means that the pipelined evaluation can start generating tuples \\nof the result while rest of the pipelined intermediate tables are undergoing \\nprocessing.\\n18.7.1 Iterators for implementing Physical Operations\\nVarious algorithms for algebraic operations involve reading some input in the form \\nof one or more files, processing it, and generating an output file as a relation. If the \\noperation is implemented in such a way that it outputs one tuple at a time, then it \\ncan be regarded as an iterator. For example, we can devise a tuple-based imple-\\nmentation of the nested-loop join that will generate a tuple at a time as output. \\nIterators work in contrast with the materialization approach wherein entire rela-\\ntions are produced as temporary results and stored on disk or main memory and \\nare read back again by the next algorithm. The query plan that contains the query \\ntree may be executed by invoking the iterators in a certain order. Many iterators \\nmay be active at one time, thereby passing results up the execution tree and avoid-\\ning the need for additional storage of temporary results. The iterator interface typi-\\ncally consists of the following methods:\\n  1. Open (): This method initializes the operator by allocating buffers for its \\ninput and output and initializing any data structures needed for the opera-\\ntor. It is also used to pass arguments such as selection conditions needed to \\nperform the operation. It in turn calls Open() to get the arguments it needs.\\n  2. Get_Next (): This method calls the Get_next() on each of its input argu-\\nments and calls the code specific to the operation being performed on \\nthe inputs. The next output tuple generated is returned and the state of \\nthe iterator is updated to keep track of the amount of input processed. \\nWhen no more tuples can be returned, it places some special value in the \\noutput buffer.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 696, 'page_label': '697'}, page_content='18.8 Parallel Algorithms for Query Processing  683\\n  3. Close(): This method ends the iteration after all tuples that can be generated \\nhave been generated, or the required/demanded number of tuples have been \\nreturned. It also calls Close() on the arguments of the iterator.\\nEach iterator may be regarded as a class for its implementation with the above \\nthree methods applicable to each instance of that class. If the operator to be imple-\\nmented allows a tuple to be completely processed when it is received, it may be \\npossible to use the pipelining strategy effectively. However, if the input tuples need \\nto be examined over multiple passes, then the input has to be received as a materi-\\nalized relation. This becomes tantamount to the Open () method doing most of the \\nwork and the benefit of pipelining not being fully achieved. Some physical opera-\\ntors may not lend themselves to the iterator interface concept and hence may not \\nsupport pipelining.\\nThe iterator concept may also be applied to access methods. Accessing a B\\n+-tree or \\na hash-based index may be regarded as a function that can be implemented as an \\niterator; it produces as output a series of tuples that meet the selection condition \\npassed to the Open() method.\\n18.8 Parallel Algorithms for Query Processing\\nIn Chapter 2, we mentioned several variations of the client/server architectures, \\nincluding two-tier and three-tier architectures. There is another type of architec-\\nture, called parallel database architecture , that is prevalent for data-intensive \\napplications. We will discuss it in further detail in Chapter 23 in conjunction with \\ndistributed databases and the big data and NOSQL emerging technologies.\\nThree main approaches have been proposed for parallel databases. They corre-\\nspond to three different hardware configurations of processors and secondary stor-\\nage devices (disks) to support parallelism. In shared-memory architecture , \\nmultiple processors are attached to an interconnection network and can access a \\ncommon main memory region. Each processor has access to the entire memory \\naddress space from all machines. The memory access to local memory and local \\ncache is faster; memory access to the common memory is slower. This architecture \\nsuffers from interference because as more processors are added, there is increasing \\ncontention for the common memory. The second type of architecture is known as \\nshared-disk architecture . In this architecture, every processor has its own mem-\\nory, which is not accessible from other processors. However, every machine has \\naccess to all disks through the interconnection network. Every processor may not \\nnecessarily have a disk of its own. We discussed two forms of enterprise-level sec-\\nondary storage systems in Section 16.11. Both storage area networks (SANs) and \\nnetwork attached storage (NAS) fall into the shared-disk architecture and lend \\nthemselves to parallel processing. They have different units of data transfer; SANs \\ntransfer data in units of blocks or pages to and from disks to processors; NAS \\nbehaves like a file server that transfers files using some file transfer protocol. In \\nthese systems, as more processors are added, there is more contention for the lim-\\nited network bandwidth.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 697, 'page_label': '698'}, page_content='684 Chapter 18 Strategies for Query Processing\\nThe above difficulties have led to shared-nothing architecture becoming the most \\ncommonly used architecture in parallel database systems. In this architecture, each \\nprocessor accesses its own main memory and disk storage. When a processor A \\nrequests data located on the disk D\\nB attached to processor B, processor A sends the \\nrequest as a message over a network to processor B, which accesses its own disk DB \\nand ships the data over the network in a message to processor A. Parallel databases \\nusing shared-nothing architecture are relatively inexpensive to build. Today, com-\\nmodity processors are being connected in this fashion on a rack, and several racks \\ncan be connected by an external network. Each processor has its own memory and \\ndisk storage.\\nThe shared-nothing architecture affords the possibility of achieving parallelism in \\nquery processing at three levels, which we will discuss below: individual operator \\nparallelism, intraquery parallelism, and interquery parallelism. Studies have shown \\nthat by allocating more processors and disks, linear speed-up—a linear reduction \\nin the time taken for operations—is possible. Linear scale-up, on the other hand, \\nrefers to being able to give a constant sustained performance by increasing the \\nnumber of processors and disks proportional to the size of data. Both of these are \\nimplicit goals of parallel processing.\\n18.8.1 Operator-Level Parallelism\\nIn the operations that can be implemented with parallel algorithms, one of the main \\nstrategies is to partition data across disks. Horizontal partitioning  of a relation \\ncorresponds to distributing the tuples across disks based on some partitioning \\nmethod. Given n disks, assigning the ith tuple to disk i mod n is called round-robin \\npartitioning. Under range partitioning, tuples are equally distributed (as much as \\npossible) by dividing the range of values of some attribute. For example, employee \\ntuples from the EMPLOYEE relation may be assigned to 10 disks by dividing the \\nage range into 10 ranges—say 22–25, 26–28, 29–30, and so on—such that each has \\nroughly one-tenth of the total number of employees. Range partitioning is a chal-\\nlenging operation and requires a good understanding of the distribution of data \\nalong the attribute involved in the range clause. The ranges used for partitioning \\nare represented by the range vector. With hash partitioning, tuple i is assigned to \\nthe disk h(i), where h is the hashing function. Next, we briefly discuss how parallel \\nalgorithms are designed for various individual operations.\\nSorting. If the data has been range partitioned on an attribute—say, age—into n \\ndisks on n processors, then to sort the entire relation on age, each partition can be \\nsorted separately in parallel and the results can be concatenated. This potentially \\ncauses close to an n-fold reduction in the overall sorting time. If the relation has \\nbeen partitioned using another scheme, the following approaches are possible:\\n ■ Repartition the relation by using range partitioning on the same attribute \\nthat is the target for sorting; then sort each partition individually followed \\nby concatenation, as mentioned above.\\n ■ Use a parallel version of the external sort-merge algorithm shown in Figure 18.2.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 698, 'page_label': '699'}, page_content='18.8 Parallel Algorithms for Query Processing  685\\nSelection. For a selection based on some condition, if the condition is an equality \\ncondition, <A = v> and the same attribute A has been used for range partitioning, the \\nselection can be performed on only that partition to which the value v belongs. In other \\ncases, the selection would be performed in parallel on all the processors and the results \\nmerged. If the selection condition is v1 ≤ A ≤ v2 and attribute A is used for range par-\\ntitioning, then the range of values (v1, v2) must overlap a certain number of partitions. \\nThe selection operation needs to be performed only in those processors in parallel.\\nProjection and Duplicate Elimination. Projection without duplicate elimination \\ncan be achieved by performing the operation in parallel as data is read from each \\npartition. Duplicate elimination can be achieved by sorting the tuples and discard-\\ning duplicates. For sorting, any of the techniques mentioned above can be used \\nbased on how the data is partitioned.\\nJoin. The basic idea of parallel join is to split the relations to be joined, say R and S, \\nin such a way that the join is divided into multiple n smaller joins, and then perform \\nthese smaller joins in parallel on n processors and take a union of the result. Next, \\nwe discuss the various techniques involved to achieve this.\\na. Equality-based partitioned join: If both the relations R and S are parti-\\ntioned into n partitions on n processors such that partition ri and parti-\\ntion si are both assigned to the same processor Pi, then the join can be \\ncomputed locally provided the join is an equality join or natural join. \\nNote that the partitions must be non-overlapping on the join key; in that \\nsense, the partitioning is a strict set-theoretic partitioning. Furthermore, \\nthe attribute used in the join condition must also satisfy these conditions:\\n /box4It is the same as that used for range partitioning, and the ranges used \\nfor each partition are also the same for both R and S. Or,\\n /box4It is the same as that used to partition into n partitions using hash \\npartitioning. The same hash function must be used for R and S. If the \\ndistributions of values of the joining attribute are different in R and S, \\nit is difficult to come up with a range vector that will uniformly distrib-\\nute both R and S into equal partitions. Ideally, the size of | r\\ni | + | si | \\nshould be even for all partitions i. Otherwise, if there is too much data \\nskew, then the benefits of parallel processing are not fully achieved. \\nThe local join at each processor may be performed using any of the \\ntechniques discussed for join: sort merge, nested loop, and hash join.\\nb. Inequality join with partitioning and replication:  If the join condition \\nis an inequality condition, involving <, ≤, >, ≥, ≠, and so on, then it is not \\npossible to partition R and S in such a way that the ith partition of R—\\nnamely, ri— joins the jth partition of S—namely, si only. Such a join can \\nbe parallelized in two ways:\\n /box4Asymmetric case: Partitioning a relation R using one of the partitioning \\nschemes; replicating one of the relations (say S) to all the n partitions; \\nand performing the join between ri and the entire S at processor Pi. \\nThis method is preferred when S is much smaller than R.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 699, 'page_label': '700'}, page_content='686 Chapter 18 Strategies for Query Processing\\n /box4Symmetric case: Under this general method, which is applicable to any \\ntype of join, both R and S are partitioned. R is partitioned n ways, and \\nS is partitioned m ways. A total of m * n processors are used for the \\nparallel join. These partitions are appropriately replicated so that pro-\\ncessors P\\n0,0 thru Pn-1,m-1 (total of m * n processors) can perform the \\njoin locally. The processor Pi,j performs the join of ri with si using any \\nof the join techniques. The system replicates the partition ri to proces-\\nsors Pi,0, Pi,1 thru Pi,m-1. Similarly, partition si is replicated to processors \\nP0,j, P1,j, P n-1,j. In general, partitioning with replication has a higher \\ncost than just partitioning; thus partitioning with replication costs \\nmore in the case of an equijoin.\\nc. Parallel partitioned hash join: The partitioned hash join we described as \\nalgorithm J4 in Section 18.4 can be parallelized. The idea is that when R and S \\nare large relations, even if we partition each relation into n partitions equaling \\nthe number of processors, the local join at each processor can still be costly. \\nThis join proceeds as follows; assume that s is the smaller of r and s:\\n  1. Using a hash function h1 on the join attribute, map each tuple of rela-\\ntions r and s to one of the n processors. Let ri and si be the partitions \\nhashed to Pi.. First, read the s tuples at each processor on its local disk \\nand map them to the appropriate processor using h1.\\n  2. Within each processor  Pi, the tuples of S received in step 1 are parti-\\ntioned using a different hash function h2 to, say, k buckets. This step is \\nidentical to the partitioning phase of the partitioned hash algorithm \\nwe described as J4 in Section 18.4.\\n  3. Read the r tuples from each local disk at each processor and map them \\nto the appropriate processor using hashing function h1. As they are \\nreceived at each processor, the processor partitions them using the \\nsame hash function h2 used in step 2 for the k buckets; this process is \\njust as in the probing phase of algorithm J4.\\n  4. The processor Pi executes the partitioned hash algorithm locally on the \\npartitions ri and si using the joining phase on the k buckets (as \\ndescribed in algorithm J4) and produces a join result.\\nThe results from all processors P i are independently computed and \\nunioned to produce the final result.\\nAggregation. Aggregate operations with grouping are achieved by partitioning \\non the grouping attribute and then computing the aggregate function locally at \\neach processor using any of the uni-processor algorithms. Either range partitioning \\nor hash partitioning can be used.\\nSet Operations. For union, intersection, and set difference operations, if the \\nargument relations R and S are partitioned using the same hash function, they can \\nbe done in parallel on each processor. If the partitioning is based on unmatched \\ncriteria, R and S may need to be redistributed using an identical hash function.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 700, 'page_label': '701'}, page_content='18.8 Parallel Algorithms for Query Processing  687\\n18.8.2 Intraquery Parallelism\\nWe have discussed how each individual operation may be executed by distrib-\\nuting the data among multiple processors and performing the operation in \\nparallel on those processors. A query execution plan can be modeled as a graph \\nof operations. To achieve a parallel execution of a query, one approach is to \\nuse a parallel algorithm for each operation involved in the query, with appro-\\npriate partitioning of the data input to that operation. Another opportunity to \\nparallelize comes from the evaluation of an operator tree where some of the \\noperations may be executed in parallel because they do not depend on one \\nanother. These operations may be executed on separate processors. If the out-\\nput of one of the operations can be generated tuple-by-tuple and fed into \\nanother operator, the result is pipelined parallelism . An operator that does \\nnot produce any output until it has consumed all its inputs is said to block the \\npipelining .\\n18.8.3 Interquery Parallelism\\nInterquery parallelism refers to the execution of multiple queries in parallel. In \\nshared-nothing or shared-disk architectures, this is difficult to achieve. Activi-\\nties of locking, logging, and so on among processors (see the chapters in Part 9 \\non Transaction Processing) must be coordinated, and simultaneous conflicting \\nupdates of the same data by multiple processors must be avoided. There must be \\ncache coherency , which guarantees that the processor updating a page has the \\nlatest version of that page in the buffer. The cache-coherency and concurrency \\ncontrol protocols (see Chapter 21) must work in coordination as well.\\nThe main goal behind interquery parallelism is to scale up (i.e., to increase the \\noverall rate at which queries or transactions can be processed by increasing the \\nnumber of processors). Because single-processor multiuser systems themselves \\nare designed to support concurrency control among transactions with the goal \\nof increasing transaction throughput (see Chapter 21), database systems using \\nshared memory parallel architecture can achieve this type of parallelism more \\neasily without significant changes.\\nFrom the above discussion it is clear that we can speed up the query execution by \\nperforming various operations, such as sorting, selection, projection, join, and \\naggregate operations, individually using their parallel execution. We may achieve \\nfurther speed-up by executing parts of the query tree that are independent in \\nparallel on different processors. However, it is difficult to achieve interquery \\nparallelism in shared-nothing parallel architectures. One area where the shared-\\ndisk architecture has an edge is that it has a more general applicability, since it, \\nunlike the shared-nothing architecture, does not require data to be stored in a \\npartitioned manner. Current SAN- and NAS-based systems afford this advan-\\ntage. A number of parameters—such as available number of processors and \\navailable buffer space—play a role in determining the overall speed-up. A \\ndetailed discussion of the effect of these parameters is outside our scope.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 701, 'page_label': '702'}, page_content='688 Chapter 18 Strategies for Query Processing\\n18.9 Summary\\nIn this chapter, we gave an overview of the techniques used by DBMSs in processing \\nhigh-level queries. We first discussed how SQL queries are translated into relational \\nalgebra. We introduced the operations of semi-join and anti-join, to which certain \\nnested queries are mapped to avoid doing the regular inner join. We discussed exter-\\nnal sorting, which is commonly needed during query processing to order the tuples \\nof a relation while dealing with aggregation, duplicate elimination, and so forth. We \\nconsidered various cases of selection and discussed the algorithms employed for \\nsimple selection based on one attribute and complex selections using conjunctive \\nand disjunctive clauses. Many techniques were discussed for the different selection \\ntypes, including linear and binary search, use of B\\n+-tree index, bitmap indexes, clus-\\ntering index, and functional index. The idea of selectivity of conditions and the typi-\\ncal information placed in a DBMS catalog was discussed. Then we considered the \\njoin operation in detail and proposed algorithms called nested-loop join, index-\\nbased nested-loop join, sort-merge join, and hash join.\\nWe gave illustrations of how buffer space, join selection factor, and inner–outer rela-\\ntion choice affect the performance of the join algorithms. We also discussed the hybrid \\nhash algorithm, which avoids some of the cost of writing during the joining phase. We \\ndiscussed algorithms for projection and set operations as well as algorithms for aggre-\\ngation. Then we discussed the algorithms for different types of joins, including outer \\njoins, semi-join, anti-join, and non-equi-join. We also discussed how operations can \\nbe combined during query processing to create pipelined or stream-based execution \\ninstead of materialized execution. We introduced how operators may be implemented \\nusing the iterator concept. We ended the discussion of query processing strategies with \\na quick introduction to the three types of parallel database system architectures. Then \\nwe briefly summarized how parallelism can be achieved at the individual operations \\nlevel and discussed intraquery and interquery parallelism as well.\\nReview Questions\\n 18.1. Discuss the reasons for converting SQL queries into relational algebra que-\\nries before optimization is done.\\n 18.2. Discuss semi-join and anti-join as operations to which nested queries may \\nbe mapped; provide an example of each.\\n 18.3. How are large tables that do not fit in memory sorted? Give the overall \\nprocedure.\\n 18.4. Discuss the different algorithms for implementing each of the following rela-\\ntional operators and the circumstances under which each algorithm can be \\nused: \\nSELECT , JOIN, PROJECT , UNION, INTERSECT , SET DIFFERENCE ,  \\nCARTESIAN PRODUCT.\\n 18.4. Give examples of a conjunctive selection and a disjunctive selection query \\nand discuss how there may be multiple options for their execution.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 702, 'page_label': '703'}, page_content='Selected Bibliography 689\\n 18.5. Discuss alternative ways of eliminating duplicates when a  \\n“SELECT Distinct <attribute>” query is evaluated.\\n 18.6. How are aggregate operations implemented?\\n 18.7. How are outer join and non–equi-join implemented?\\n 18.8. What is the iterator concept? What methods are part of an iterator?\\n 18.9. What are the three types of parallel architectures applicable to database sys-\\ntems? Which one is most commonly used?\\n 18.10. What are the parallel implementations of join?\\n 18.11. What are intraquery and interquery parallelisms? Which one is harder to \\nachieve in the shared-nothing architecture? Why?\\n 18.12. Under what conditions is pipelined parallel execution of a sequence of oper-\\nations prevented?\\nExercises\\n 18.13. Consider SQL queries Q1, Q8, Q1B, and Q4 in Chapter 6 and Q27 in \\nChapter 7.\\na. Draw at least two query trees that can represent each of these queries. \\nUnder what circumstances would you use each of your query trees?\\nb. Draw the initial query tree for each of these queries, and then show how \\nthe query tree is optimized by the algorithm outlined in Section 18.7.\\nc. For each query, compare your own query trees of part (a) and the initial \\nand final query trees of part (b).\\n 18.14. A file of 4,096 blocks is to be sorted with an available buffer space of 64 \\nblocks. How many passes will be needed in the merge phase of the external \\nsort-merge algorithm?\\n 18.15. Can a nondense index be used in the implementation of an aggregate opera-\\ntor? Why or why not? Illustrate with an example.\\n 18.16. Extend the sort-merge join algorithm to implement the LEFT OUTER JOIN  \\noperation.\\nSelected Bibliography\\nWe will give references to the literature for the query processing and optimization \\narea together at the end of Chapter19. Thus the Chapter19 references apply to this \\nchapter and the next chapter. It is difficult to separate the literature that addresses \\njust query processing strategies and algorithms from the literature that discusses \\nthe optimization area.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 703, 'page_label': '704'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 704, 'page_label': '705'}, page_content='691\\n19\\nQuery Optimization\\nI\\nn this chapter, 1 we will assume that the reader is \\nalready familiar with the strategies for query process-\\ning in relational DBMSs that we discussed in the previous chapter. The goal of \\nquery optimization is to select the best possible strategy for query evaluation. As we \\nsaid before, the term optimization is a misnomer because the chosen execution plan \\nmay not always be the most optimal plan possible. The primary goal is to arrive at \\nthe most efficient and cost-effective plan using the available information about the \\nschema and the content of relations involved, and to do so in a reasonable amount \\nof time. Thus a proper way to describe query optimization would be that it is an \\nactivity conducted by a query optimizer in a DBMS to select the best available strat-\\negy for executing the query.\\nThis chapter is organized as follows. In Section 19.1 we describe the notation for \\nmapping of the queries from SQL into query trees and graphs. Most RDBMSs use \\nan internal representation of the query as a tree. We present heuristics to transform \\nthe query into a more efficient equivalent form followed by a general procedure for \\napplying those heuristics. In Section 19.2, we discuss the conversion of queries into \\nexecution plans. We discuss nested subquery optimization. We also present exam-\\nples of query transformation in two cases: merging of views in Group By queries \\nand transformation of Star Schema queries that arise in data warehouses. We also \\nbriefly discuss materialized views. Section 19.3 is devoted to a discussion of selectiv-\\nity and result-size estimation and presents a cost-based approach to optimization. \\nWe revisit the information in the system catalog that we presented in Section 18.3.4 \\nearlier and present histograms. Cost models for selection and join operation are \\npresented in Sections 19.4 and 19.5. We discuss the join ordering problem, which is \\na critical one, in some detail in Section 19.5.3. Section 19.6 presents an example of \\ncost-based optimization. Section 19.7 discusses some additional issues related to \\nchapter 19\\n1The substantial contribution of Rafi Ahmed to this chapter is appreciated.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 705, 'page_label': '706'}, page_content='692 Chapter 19 Query Optimization\\nquery optimization. Section 19.8 is devoted to a discussion of query optimization in \\ndata warehouses. Section 19.9 gives an overview of query optimization in Oracle. \\nSection 19.10 briefly discusses semantic query optimization. We end the chapter \\nwith a summary in Section 19.11.\\n19.1  Query Trees and Heuristics  \\nfor Query Optimization\\nIn this section, we discuss optimization techniques that apply heuristic rules to modify \\nthe internal representation of a query—which is usually in the form of a query tree or a \\nquery graph data structure—to improve its expected performance. The scanner and \\nparser of an SQL query first generate a data structure that corresponds to an initial \\nquery representation, which is then optimized according to heuristic rules. This leads \\nto an optimized query representation, which corresponds to the query execution strat-\\negy. Following that, a query execution plan is generated to execute groups of opera-\\ntions based on the access paths available on the files involved in the query.\\nOne of the main heuristic rules is to apply \\nSELECT and PROJECT operations before \\napplying the JOIN or other binary operations, because the size of the file resulting \\nfrom a binary operation—such as JOIN—is usually a multiplicative function of the \\nsizes of the input files. The SELECT and PROJECT operations reduce the size of a file \\nand hence should be applied before a join or other binary operation.\\nIn Section 19.1.1, we reiterate the query tree and query graph notations that we \\nintroduced earlier in the context of relational algebra and calculus in Sections 8.3.5 \\nand 8.6.5, respectively. These can be used as the basis for the data structures that are \\nused for internal representation of queries. A query tree is used to represent a rela-\\ntional algebra or extended relational algebra expression, whereas a query graph is \\nused to represent a relational calculus expression. Then, in Section 19.1.2, we show \\nhow heuristic optimization rules are applied to convert an initial query tree into an \\nequivalent query tree , which represents a different relational algebra expression \\nthat is more efficient to execute but gives the same result as the original tree. We \\nalso discuss the equivalence of various relational algebra expressions. Finally, Sec-\\ntion 19.1.3 discusses the generation of query execution plans.\\n19.1.1 Notation for Query Trees and Query Graphs\\nA query tree is a tree data structure that corresponds to an extended relational alge-\\nbra expression. It represents the input relations of the query as leaf nodes of the tree, \\nand it represents the relational algebra operations as internal nodes. An execution of \\nthe query tree consists of executing an internal node operation whenever its operands \\nare available and then replacing that internal node by the relation that results from \\nexecuting the operation. The order of execution of operations starts at the leaf nodes, \\nwhich represents the input database relations for the query, and ends at the root node, \\nwhich represents the final operation of the query. The execution terminates when the \\nroot node operation is executed and produces the result relation for the query.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 706, 'page_label': '707'}, page_content='19.1 Query Trees and Heuristics for Query Optimization  693\\nFigure 19.1(a) shows a query tree (the same as shown in Figure 6.9) for query Q2 \\nin Chapters 6 to 8: For every project located in ‘Stafford’, retrieve the project \\nnumber, the controlling department number, and the department manager’s last \\nname, address, and birthdate. This query is specified on the COMPANY rela-\\ntional schema in Figure 5.5 and corresponds to the following relational algebra \\nexpression:\\nπPnumber, Dnum, Lname, Address, Bdate (((σPlocation=‘Stafford’(PROJECT))\\n Dnum=Dnumber(DEPARTMENT))  Mgr_ssn=Ssn(EMPLOYEE))\\n(b)\\n(a)\\nE\\nDP\\nP.Pnumber, P.Dnum, E.Lname, E.Address, E.Bdateπ\\nP.Dnum=D.Dnumber AND D.Mgr_ssn=E.Ssn AND P.Plocation=‘Stafford’\\nσ\\n(c)\\nEDP\\n[P.Pnumber, P.Dnum] [E.Lname, E.Address, E.Bdate]\\nP.Dnum=D.Dnumber\\nP.Plocation=‘Stafford’\\nD.Mgr_ssn=E.Ssn\\n‘Stafford’\\nX\\nX\\n(1)\\n(2)\\n(3)\\nP.Pnumber,P.Dnum,E.Lname,E.Address,E.Bdateπ\\nD.Mgr_ssn=E.Ssn\\nP.Dnum=D.Dnumber\\nσ P.Plocation= ‘Stafford’\\nE\\nD\\nP\\nEMPLOYEE\\nDEPARTMENT\\nPROJECT\\nFigure 19.1 \\nTwo query trees for the query Q2. (a) Query tree corresponding to the relational algebra  \\nexpression for Q2. (b) Initial (canonical) query tree for SQL query Q2. (c) Query graph for Q2.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 707, 'page_label': '708'}, page_content='694 Chapter 19 Query Optimization\\nThis corresponds to the following SQL query:\\nQ2: SELECT P.Pnumber, P.Dnum, E.Lname, E.Address, E.Bdate\\n FROM PROJECT P, DEPARTMENT D, EMPLOYEE E\\n WHERE P.Dnum=D.Dnumber AND D.Mgr_ssn=E.Ssn AND\\n  P.Plocation= ‘Stafford’;\\nIn Figure 19.1(a), the leaf nodes P, D, and E represent the three relations PROJECT, \\nDEPARTMENT, and EMPLOYEE, respectively, and the internal tree nodes represent \\nthe relational algebra operations of the expression. When this query tree is executed, \\nthe node marked (1) in Figure 19.1(a) must begin execution before node (2) because \\nsome resulting tuples of operation (1) must be available before we can begin execut-\\ning operation (2). Similarly, node (2) must begin executing and producing results \\nbefore node (3) can start execution, and so on.\\nAs we can see, the query tree represents a specific order of operations for executing \\na query. A more neutral data structure for representation of a query is the query \\ngraph notation. Figure 19.1(c) (the same as shown in Figure 6.13) shows the query \\ngraph for query \\nQ2. Relations in the query are represented by relation nodes, which \\nare displayed as single circles. Constant values, typically from the query selection \\nconditions, are represented by constant nodes, which are displayed as double cir-\\ncles or ovals. Selection and join conditions are represented by the graph edges, as \\nshown in Figure 19.1(c). Finally, the attributes to be retrieved from each relation are \\ndisplayed in square brackets above each relation.\\nThe query graph representation does not indicate an order on which operations to \\nperform first. There is only a single graph corresponding to each query. 2 Although \\nsome optimization techniques were based on query graphs such as those originally \\nin the INGRES DBMS, it is now generally accepted that query trees are preferable \\nbecause, in practice, the query optimizer needs to show the order of operations for \\nquery execution, which is not possible in query graphs.\\n19.1.2 Heuristic Optimization of Query Trees\\nIn general, many different relational algebra expressions—and hence many differ-\\nent query trees—can be semantically equivalent; that is, they can represent the \\nsame query and produce the same results.\\n3\\nThe query parser will typically generate a standard initial query tree to correspond \\nto an SQL query, without doing any optimization. For example, for a SELECT-\\nPROJECT-JOIN query, such as Q2, the initial tree is shown in Figure 19.1(b). The \\nCARTESIAN PRODUCT of the relations specified in the FROM clause is first applied; \\nthen the selection and join conditions of the WHERE clause are applied, followed by \\n2Hence, a query graph corresponds to a relational calculus expression as shown in Section 8.6.5.\\n3The same query may also be stated in various ways in a high-level query language such as SQL (see \\nChapters 7 and 8).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 708, 'page_label': '709'}, page_content='19.1 Query Trees and Heuristics for Query Optimization  695\\nthe projection on the SELECT clause attributes. Such a canonical query tree repre-\\nsents a relational algebra expression that is very inefficient if executed directly,  \\nbecause of the CARTESIAN PRODUCT (×) operations. For example, if the PROJECT, \\nDEPARTMENT, and EMPLOYEE relations had record sizes of 100, 50, and 150 bytes \\nand contained 100, 20, and 5,000 tuples, respectively, the result of the CARTESIAN \\nPRODUCT would contain 10 million tuples of record size 300 bytes each. However, \\nthis canonical query tree in Figure 19.1(b) is in a simple standard form that can be \\neasily created from the SQL query. It will never be executed. The heuristic query \\noptimizer will transform this initial query tree into an equivalent final query tree \\nthat is efficient to execute.\\nThe optimizer must include rules for equivalence among extended relational algebra \\nexpressions that can be applied to transform the initial tree into the final, optimized \\nquery tree. First we discuss informally how a query tree is transformed by using \\nheuristics, and then we discuss general transformation rules and show how they can \\nbe used in an algebraic heuristic optimizer.\\nExample of Transforming a Query. Consider the following query \\nQ on the \\ndatabase in Figure 5.5: Find the last names of employees born after 1957 who work on \\na project named ‘Aquarius’. This query can be specified in SQL as follows:\\nQ: SELECT E.Lname\\n FROM EMPLOYEE E , WORKS_ON W, PROJECT P\\n WHERE  P.Pname=‘Aquarius’ AND P.Pnumber=W.Pno AND E.Essn=W.Ssn\\n  AND E.Bdate > ‘1957-12-31’;\\nThe initial query tree for Q is shown in Figure 19.2(a). Executing this tree directly \\nfirst creates a very large file containing the CARTESIAN PRODUCT  of the entire \\nEMPLOYEE, WORKS_ON, and PROJECT files. That is why the initial query tree is \\nnever executed, but is transformed into another equivalent tree that is efficient to \\nexecute. This particular query needs only one record from the PROJECT relation—\\nfor the ‘Aquarius’ project—and only the EMPLOYEE records for those whose date of \\nbirth is after ‘1957-12-31’. Figure 19.2(b) shows an improved query tree that first \\napplies the SELECT operations to reduce the number of tuples that appear in the \\nCARTESIAN PRODUCT.\\nA further improvement is achieved by switching the positions of the EMPLOYEE  \\nand PROJECT  relations in the tree, as shown in Figure 19.2(c). This uses the \\ninformation that Pnumber  is a key attribute of the PROJECT  relation, and hence \\nthe SELECT  operation on the PROJECT  relation will retrieve a single record \\nonly. We can further improve the query tree by replacing any CARTESIAN \\nPRODUCT  operation that is followed by a join condition as a selection with a \\nJOIN operation, as shown in Figure 19.2(d). Another improvement is to keep \\nonly the attributes needed by subsequent operations in the intermediate rela-\\ntions, by including PROJECT  ( π) operations as early as possible in the query \\ntree, as shown in Figure 19.2(e). This reduces the attributes (columns) of the \\nintermediate relations, whereas the SELECT  operations reduce the number of \\ntuples (records).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 709, 'page_label': '710'}, page_content='696 Chapter 19 Query Optimization\\n(a) Lname\\nPname=‘Aquarius’ AND Pnumber=Pno AND Essn=Ssn AND Bdate>‘1957-12-31’\\nPROJECT\\nWORKS_ONEMPLOYEE\\n(b) Lname\\nPnumber=Pno\\nBdate>‘1957-12-31’\\nPname=‘Aquarius’Essn=Ssn\\nπ\\nπ\\nσ\\nσ\\nσσ\\nσ\\nEMPLOYEE\\nPROJECT\\nWORKS_ON\\nX\\nX\\nX\\nX\\n(c)\\nσ Essn=Ssn\\nπ Lname\\nσ Pnumber=Pno σ Bdate>‘1957-12-31’ \\nσPname=‘Aquarius’\\nEMPLOYEE\\nWORKS_ON\\nPROJECT\\nX\\nX\\nFigure 19.2 \\nSteps in converting a query tree during heuristic optimization. (a) Initial (canonical) query tree for SQL query Q. \\n(b) Moving SELECT operations down the query tree. (c) Applying the more restrictive SELECT operation first.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 710, 'page_label': '711'}, page_content='19.1 Query Trees and Heuristics for Query Optimization  697\\n(e) π Lname\\nσBdate>‘1957-12-31’ \\nσPname=‘Aquarius’\\nπ Pnumber π Essn,Pno\\nπ Essn πSsn, Lname \\nEMPLOYEE\\nWORKS_ON\\nPROJECT\\n(d) π Lname\\nσ Bdate>‘1957-12-31’ \\nσPname=‘Aquarius’ EMPLOYEEWORKS_ON\\nPROJECT\\nEssn=Ssn\\nPnumber=Pno\\nPnumber=Pno\\nEssn=Ssn\\nFigure 19.2 (continued)\\nSteps in converting a query tree during heuristic optimization. (d) Replacing CARTESIAN PRODUCT and SELECT \\nwith JOIN operations.  (e) Moving PROJECT operations down the query tree.\\nAs the preceding example demonstrates, a query tree can be transformed step by \\nstep into an equivalent query tree that is more efficient to execute. However, we \\nmust make sure that the transformation steps always lead to an equivalent query \\ntree. To do this, the query optimizer must know which transformation rules pre-\\nserve this equivalence. We discuss some of these transformation rules next.\\nGeneral Transformation Rules for Relational Algebra Operations. There \\nare many rules for transforming relational algebra operations into equivalent ones. \\nFor query optimization purposes, we are interested in the meaning of the opera-\\ntions and the resulting relations. Hence, if two relations have the same set of attri-\\nbutes in a different order but the two relations represent the same information, we \\nconsider the relations to be equivalent. In Section 5.1.2 we gave an alternative defi-\\nnition of relation that makes the order of attributes unimportant; we will use this'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 711, 'page_label': '712'}, page_content='698 Chapter 19 Query Optimization\\ndefinition here. We will state some transformation rules that are useful in query \\noptimization, without proving them:\\n  1. Cascade of σ.  A conjunctive selection condition can be broken up into a \\ncascade (that is, a sequence) of individual σ operations:\\nσc1 AND c2 AND … AND cn(R) ≡ σc1 (σc2 (…(σcn(R))…))\\n  2. Commutativity of σ. The σ operation is commutative:\\nσc1 (σc2(R)) ≡ σc2 (σc1(R))\\n  3. Cascade of π.  In a cascade (sequence) of π operations, all but the last one \\ncan be ignored:\\nπList1 (πList2 (…(πListn(R))…)) ≡ πList1(R)\\n  4. Commuting σ with π. If the selection condition c involves only those attri-\\nbutes A1, … , An in the projection list, the two operations can be commuted:\\nπA1, A2, … , An (σc (R)) ≡ σc (πA1, A2, … , An (R))\\n  5. Commutativity of  (and ×). The join operation is commutative, as is the × \\noperation:\\nR c S ≡ S c R\\nR × S ≡ S × R\\nNotice that although the order of attributes may not be the same in the rela-\\ntions resulting from the two joins (or two Cartesian products), the meaning \\nis the same because the order of attributes is not important in the alternative \\ndefinition of relation.\\n  6. Commuting σ with  (or ×). If all the attributes in the selection condition c \\ninvolve only the attributes of one of the relations being joined—say, R—the \\ntwo operations can be commuted as follows:\\nσc (R  S) ≡ (σc (R))  S\\nAlternatively, if the selection condition c can be written as (c1 AND c2), where \\ncondition c1 involves only the attributes of R and condition c2 involves only \\nthe attributes of S, the operations commute as follows:\\nσc (R  S) ≡ (σc1 (R))  (σc2 (S))\\nThe same rules apply if the  is replaced by a × operation.\\n  7. Commuting π with  (or ×). Suppose that the projection list is L = {A1, … , \\nAn, B1, … , Bm} , where A1, … , An are attributes of R and B1, … , Bm are \\nattributes of S. If the join condition c involves only attributes in L, the two \\noperations can be commuted as follows:\\nπL (R c S) ≡ (πA1, … , An (R)) c (πB1, … , Bm (S))\\nIf the join condition c contains additional attributes not in L, these must be added \\nto the projection list, and a final π operation is needed. For example, if attributes'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 712, 'page_label': '713'}, page_content='19.1 Query Trees and Heuristics for Query Optimization  699\\nAn+1, … , An+k of R and Bm+1, … , Bm+p of S are involved in the join condition c \\nbut are not in the projection list L, the operations commute as follows:\\nπL (R c S) ≡ πL ((πA1, … , An, An+1, … , An+k(R)) c (πB1, … , Bm, Bm+1, … , Bm+p (S)))\\nFor ×, there is no condition c, so the first transformation rule always applies \\nby replacing c with ×.\\n  8. Commutativity of set operations. The set operations ∪ and ∩ are commu-\\ntative, but − is not.\\n  9. Associativity of , ×, ∪, and ∩. These four operations are individually asso-\\nciative; that is, if both occurrences of θ stand for the same operation that is \\nany one of these four operations (throughout the expression), we have:\\n(R θ S) θ T ≡ R θ (S θ T)\\n 10. Commuting σ with set operations.  The σ operation commutes with ∪, ∩, \\nand −. If θ stands for any one of these three operations (throughout the \\nexpression), we have:\\nσc (R θ S) ≡ (σc (R)) θ (σc (S))\\n 11. The π operation commutes with ∪.\\nπL (R ∪ S) ≡ (πL (R)) ∪ (πL (S))\\n 12. Converting a (σ, ×) sequence into . If the condition c of a σ that follows a × \\ncorresponds to a join condition, convert the (σ, ×) sequence into a  as follows:\\n(σc (R × S)) ≡ (R c S)\\n 13. Pushing σ in conjunction with set difference.\\nσc (R − S) = σc (R) – σc ( S)\\nHowever, σ may be applied to only one relation:\\nσc (R – S) = σc (R) – S\\n 14. Pushing σ to only one argument in ∩.\\nIf in the condition σc all attributes are from relation R, then:\\nσc (R ∩ S) = σc (R) ∩ S\\n 15. Some trivial transformations.\\nIf S is empty, then R ∪ S = R\\nIf the condition c in σc is true for the entire R, then σc (R) = R.\\nThere are other possible transformations. For example, a selection or join condition \\nc can be converted into an equivalent condition by using the following standard \\nrules from Boolean algebra (De Morgan’s laws):\\nNOT (c1 AND c2) ≡ (NOT c1) OR (NOT c2)\\nNOT (c1 OR c2) ≡ (NOT c1) AND (NOT c2)'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 713, 'page_label': '714'}, page_content='700 Chapter 19 Query Optimization\\nAdditional transformations discussed in Chapters 4, 5, and 6 are not repeated here. \\nWe discuss next how transformations can be used in heuristic optimization.\\nOutline of a Heuristic Algebraic Optimization Algorithm. We can now out-\\nline the steps of an algorithm that utilizes some of the above rules to transform an \\ninitial query tree into a final tree that is more efficient to execute (in most cases). \\nThe algorithm will lead to transformations similar to those discussed in our exam-\\nple in Figure 19.2. The steps of the algorithm are as follows:\\n  1. Using Rule 1, break up any SELECT operations with conjunctive conditions \\ninto a cascade of SELECT operations. This permits a greater degree of free-\\ndom in moving SELECT operations down different branches of the tree.\\n  2. Using Rules 2, 4, 6, and 10, 13, 14 concerning the commutativity of SELECT \\nwith other operations, move each SELECT operation as far down the query \\ntree as is permitted by the attributes involved in the select condition. If the \\ncondition involves attributes from only one table, which means that it repre-\\nsents a selection condition , the operation is moved all the way to the leaf \\nnode that represents this table. If the condition involves attributes from two \\ntables, which means that it represents a join condition , the condition is \\nmoved to a location down the tree after the two tables are combined.\\n  3. Using Rules 5 and 9 concerning commutativity and associativity of binary oper-\\nations, rearrange the leaf nodes of the tree using the following criteria. First, \\nposition the leaf node relations with the most restrictive \\nSELECT operations so \\nthey are executed first in the query tree representation. The definition of most \\nrestrictive SELECT can mean either the ones that produce a relation with the \\nfewest tuples or with the smallest absolute size.4 Another possibility is to define \\nthe most restrictive SELECT as the one with the smallest selectivity; this is more \\npractical because estimates of selectivities are often available in the DBMS  \\ncatalog. Second, make sure that the ordering of leaf nodes does not cause  \\nCARTESIAN PRODUCT operations; for example, if the two relations with the \\nmost restrictive SELECT do not have a direct join condition between them, it \\nmay be desirable to change the order of leaf nodes to avoid Cartesian products.5\\n  4. Using Rule 12, combine a CARTESIAN PRODUCT  operation with a subse-\\nquent SELECT operation in the tree into a JOIN operation, if the condition \\nrepresents a join condition.\\n  5. Using Rules 3, 4, 7, and 11 concerning the cascading of PROJECT and the com-\\nmuting of PROJECT with other operations, break down and move lists of pro-\\njection attributes down the tree as far as possible by creating new PROJECT \\noperations as needed. Only those attributes needed in the query result and in \\nsubsequent operations in the query tree should be kept after each PROJECT \\noperation.\\n4Either definition can be used, since these rules are heuristic.\\n5Note that a CARTESIAN PRODUCT is acceptable in some cases—for example, if each relation has only \\na single tuple because each had a previous select condition on a key field.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 714, 'page_label': '715'}, page_content='19.2 Choice of Query Execution Plans  701\\n  6. Identify subtrees that represent groups of operations that can be executed by \\na single algorithm.\\nIn our example, Figure 19.2(b) shows the tree in Figure 19.2(a) after applying steps 1 \\nand 2 of the algorithm; Figure 19.2(c) shows the tree after step 3; Figure 19.2(d) \\nafter step 4; and Figure 19.2(e) after step 5. In step 6, we may group together the \\noperations in the subtree whose root is the operation π\\nEssn into a single algorithm. \\nWe may also group the remaining operations into another subtree, where the tuples \\nresulting from the first algorithm replace the subtree whose root is the operation \\nπ\\nEssn, because the first grouping means that this subtree is executed first.\\nSummary of Heuristics for Algebraic Optimization. The main heuristic is to \\napply first the operations that reduce the size of intermediate results. This includes \\nperforming as early as possible \\nSELECT operations to reduce the number of tuples \\nand PROJECT operations to reduce the number of attributes—by moving SELECT \\nand PROJECT operations as far down the tree as possible. Additionally, the SELECT \\nand JOIN operations that are most restrictive—that is, result in relations with the \\nfewest tuples or with the smallest absolute size—should be executed before other \\nsimilar operations. The latter rule is accomplished through reordering the leaf \\nnodes of the tree among themselves while avoiding Cartesian products, and adjust-\\ning the rest of the tree appropriately.\\n19.2 Choice of Query Execution Plans\\n19.2.1 Alternatives for Query Evaluation\\nAn execution plan for a relational algebra expression represented as a query tree \\nincludes information about the access methods available for each relation as well as \\nthe algorithms to be used in computing the relational operators represented in the \\ntree. As a simple example, consider query Q1 from Chapter 7, whose corresponding \\nrelational algebra expression is\\nπFname, Lname, Address(σDname=‘Research’(DEPARTMENT)  Dnumber=Dno EMPLOYEE)\\nThe query tree is shown in Figure 19.3. To convert this into an execution plan, the \\noptimizer might choose an index search for the SELECT operation on DEPARTMENT \\n(assuming one exists), an index-based nested-loop join algorithm that loops over \\nthe records in the result of the SELECT operation on DEPARTMENT for the join \\noperation (assuming an index exists on the Dno attribute of EMPLOYEE), and a scan \\nof the JOIN result for input to the PROJECT operator. Additionally, the approach \\ntaken for executing the query may specify a materialized or a pipelined evaluation, \\nalthough in general a pipelined evaluation is preferred whenever feasible.\\nWith materialized evaluation, the result of an operation is stored as a temporary \\nrelation (that is, the result is physically materialized). For instance, the \\nJOIN opera-\\ntion can be computed and the entire result stored as a temporary relation, which is \\nthen read as input by the algorithm that computes the \\nPROJECT operation, which'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 715, 'page_label': '716'}, page_content='702 Chapter 19 Query Optimization\\nwould produce the query result table. On the other hand, with pipelined evaluation, \\nas the resulting tuples of an operation are produced, they are forwarded directly \\nto the next operation in the query sequence. We discussed pipelining as a strategy \\nfor query processing in Section 18.7. For example, as the selected tuples from \\nDEPARTMENT are produced by the SELECT operation, they are placed in a buffer; \\nthe JOIN operation algorithm then consumes the tuples from the buffer, and those \\ntuples that result from the JOIN operation are pipelined to the projection operation \\nalgorithm. The advantage of pipelining is the cost savings in not having to write  \\nthe intermediate results to disk and not having to read them back for the next  \\noperation.\\nWe discussed in Section 19.1 the possibility of converting query trees into equiva-\\nlent trees so that the evaluation of the query is more efficient in terms of its execu-\\ntion time and overall resources consumed. There are more elaborate transformations \\nof queries that are possible to optimize, or rather to “improve.” Transformations \\ncan be applied either in a heuristic-based or cost-based manner.\\nAs we discussed in Sections 7.1.2 and 7.1.3, nested subqueries may occur in the \\nWHERE clause as well as in the FROM clause of SQL queries. In the WHERE \\nclause, if an inner block makes a reference to the relation used in the outer block, it \\nis called a correlated nested query. When a query is used within the FROM clause to \\ndefine a resulting or derived relation, which participates as a relation in the outer \\nquery, it is equivalent to a view. Both these types of nested subqueries are handled \\nby the optimizer, which transforms them and rewrites the entire query. In the next \\ntwo subsections, we consider these two variations of query transformation and \\nrewriting with examples. We will call them nested subquery optimization and sub-\\nquery (view) merging transformation. In Section 19.8, we revisit this topic in the \\ncontext of data warehouses and illustrate star transformation optimizations.\\n19.2.2 Nested Subquery Optimization\\nWe discussed nested queries in Section 7.1.2. Consider the query:\\nSELECT E1.Fname, E1.Lname\\nFROM EMLOYEE E1\\nWHERE E1.Salary = ( SELECT MAX (Salary)\\n     FROM EMPLOYEE E2)\\nπ  Fname, Lname, Address\\nσ Dname=‘Research’\\nDEPARTMENT\\nEMPLOYEE\\nDnumber=Dno\\nFigure 19.3 \\nA query tree for query Q1.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 716, 'page_label': '717'}, page_content='19.2 Choice of Query Execution Plans  703\\nIn the above nested query, there is a query block inside an outer query block. \\nEvaluation of this query involves executing the nested query first, which yields a \\nsingle value of the maximum salary M in the EMPLOYEE relation; then the \\nouter block is simply executed with the selection condition Salary = M. The max-\\nimum salary could be obtained just from the highest value in the index on salary \\n(if one exists) or from the catalog if it is up-to-date. The outer query is evaluated \\nbased on the same index. If no index exists, then linear search would be needed \\nfor both.\\nWe discussed correlated nested SQL queries in Section 7.1.3. In a correlated sub-\\nquery, the inner query contains a reference to the outer query via one or more vari-\\nables. The subquery acts as a function that returns a set of values for each value of \\nthis variable or combination of variables.\\nSuppose in the database of Figure 5.5, we modify the DEPARTMENT relation as:\\nDEPARTMENT (Dnumber, Dname, Mgr_ssn, Mgr_start_date, Zipcode)\\nConsider the query:\\nSELECT Fname, Lname, Salary\\nFROM EMPLOYEE E\\nWHERE EXISTS ( SELECT *\\n             FROM DEPARTMENT D\\n             WHERE D.Dnumber = E.Dno AND D.Zipcode=30332);\\nIn the above, the nested subquery takes the E.Dno, the department where the \\nemployee works, as a parameter and returns a true or false value as a function \\ndepending on whether the department is located in zip code 30332. The naïve strat-\\negy for evaluating the query is to evaluate the inner nested subquery for every tuple \\nof the outer relation, which is inefficient. Wherever possible, SQL optimizer tries to \\nconvert queries with nested subqueries into a join operation. The join can then be \\nevaluated with one of the options we considered in Section 18.4. The above query \\nwould be converted to\\nSELECT Fname, Lname, Salary\\nFROM EMPLOYEE E, DEPARTMENT D\\nWHERE WHERE D.Dnumber = E.Dno AND D.Zipcode=30332\\nThe process of removing the nested query and converting the outer and inner \\nquery into one block is called unnesting . Here inner join is used, since  \\nD.Dnumber is unique and the join is an equi-join; this guarantees that a tuple \\nfrom relation Employee will match with at most one tuple from relation  \\nDepartment. We showed in Chapter 7 that the query Q16, which has a subquery \\nconnected with the IN connector, was also unnested into a single block query \\ninvolving a join. In general, queries involving a nested subquery connected by \\nIN or ANY connector in SQL can always be converted into a single block query. \\nOther techniques used include creation of temporary result tables from sub-\\nqueries and using them in joins.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 717, 'page_label': '718'}, page_content='704 Chapter 19 Query Optimization\\nWe repeat the example query shown in Section 18.1. (Note that the IN operator is \\nequivalent to the =ANY operator.):\\nQ (SJ) :\\nSELECT COUNT(*)\\nFROM DEPARTMENT D\\nWHERE D.Dnumber IN ( SELECT E.Dno\\n             FROM EMPLOYEE E\\n             WHERE E.Salary > 200000)\\nIn this case again, there are two options for the optimizer:\\n  1. Evaluate the nested subquery for each outer tuple; it is inefficient to do so.\\n  2. Unnest the subquery using semi-join, which is much more efficient than \\noption 1. In Section 18.1, we used this alternative to introduce and define the \\nsemi-join operator. Note that for unnesting this subquery, which refers to \\nexpressing it as a single block, inner join cannot be used, since in inner join \\na tuple of DEPARTMENT may match more than one tuple of EMPLOYEE \\nand thus produce wrong results. It is easy to see that a nested subquery acts \\nas a filter and thus it cannot, unlike inner join, produce more rows than \\nthere are in the DEPARTMENT table. Semi-join simulates this behavior.\\nThe process we described as unnesting is sometimes called decorrelation . We \\nshowed another example in Section 18.1 using the connector “NOT IN”, which was \\nconverted into a single block query using the operation anti-join. Optimization of \\ncomplex nested subqueries is difficult and requires techniques that can be quite \\ninvolved. We illustrate two such techniques in Section 19.2.3 below. Unnesting is a \\npowerful optimization technique and is used widely by SQL optimizers.\\n19.2.3 Subquery (View) Merging Transformation\\nThere are instances where a subquery appears in the FROM clause of a query and \\namounts to including a derived relation, which is similar to a predefined view that \\nis involved in the query. This FROM clause subquery is often referred to as an inline \\nview. Sometimes, an actual view defined earlier as a separate query is used as one of \\nthe argument relations in a new query. In such cases, the transformation of the \\nquery can be referred to as a view-merging or subquery merging transformation. \\nThe techniques of view merging discussed here apply equally to both inline and \\npredefined views,\\nConsider the following three relations:\\nEMP (Ssn, Fn, Ln, Dno)\\nDEPT (Dno, Dname, Dmgrname, Bldg_id)\\nBLDG (Bldg_id, No_storeys, Addr, Phone)\\nThe meaning of the relations is self-explanatory; the last one represents build-\\nings where departments are located; the phone refers to a phone number for the \\nbuilding lobby.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 718, 'page_label': '719'}, page_content='19.2 Choice of Query Execution Plans  705\\nThe following query uses an inline view in the FROM clause; it retrieves for employ-\\nees named “John” the last name, address and phone number of building where they \\nwork:\\nSELECT E.Ln, V.Addr, V.Phone\\nFROM EMP E, ( SELECT D.Dno, D.Dname, B.Addr, B.Phone\\n          FROM DEPT D, BLDG B\\n          WHERE D.Bldg_id = B.Bldg_id ) V\\nWHERE V.Dno = E.Dno AND E.Fn = “John”;\\nThe above query joins the EMP table with a view called V that provides the address \\nand phone of the building where the employee works. In turn, the view joins the \\ntwo tables DEPT and BLDG. This query may be executed by first temporarily \\nmaterializing the view and then joining it with the EMP table. The optimizer is \\nthen constrained to consider the join order E, V or V, E; and for computing the \\nview, the join orders possible are D, B and B, D. Thus the total number of join \\norder candidates is limited to 4. Also, index-based join on E, V is precluded since \\nthere is no index on V on the join column Dno. The view-merging  operation \\nmerges the tables in the view with the tables from the outer query block and pro-\\nduces the following query:\\nSELECT E.Ln, B.Addr, B.Phone\\nFROM EMP E, DEPT D, BLDG B\\nWHERE D.Bldg_id = B.Bldg_id AND D.Dno = E.Dno AND E.Fn = “John”;\\nWith the merged query block above, three tables appear in the FROM clause, thus \\naffording eight possible join orders and indexes on Dno in DEPT, and Bldg_id in \\nBLDG can be used for index-based nested loop joins that were previously excluded. \\nWe leave it to the reader to develop execution plans with and without merging to \\nsee the comparison.\\nIn general, views containing select-project-join operations are considered simple \\nviews and they can always be subjected to this type of view-merging. Typically, view \\nmerging enables additional options to be considered and results in an execution \\nplan that is better than one without view merging. Sometimes other optimizations \\nare enabled, such as dropping a table in the outer query if it is used within the view. \\nView-merging may be invalid under certain conditions where the view is more \\ncomplex and involves DISTINCT, OUTER JOIN, AGGREGATION, GROUP BY \\nset operations, and so forth. We next consider a possible situation of GROUP-BY \\nview-merging.\\nGROUP-BY View-Merging: When the view has additional constructs besides \\nselect-project-join as we mentioned above, merging of the view as shown above \\nmay or may not be desirable. Delaying the Group By operation after performing \\njoins may afford the advantage of reducing the data subjected to grouping in case \\nthe joins have low join selectivity. Alternately, performing early Group By may be \\nadvantageous by reducing the amount of data subjected to subsequent joins. The \\noptimizer would typically consider execution plans with and without merging and'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 719, 'page_label': '720'}, page_content='706 Chapter 19 Query Optimization\\ncompare their cost to determine the viability of doing the merging. We illustrate \\nwith an example.\\nConsider the following relations:\\nSALES (Custid, Productid, Date, Qty_sold)\\nCUST (Custid, Custname, Country, Cemail)\\nPRODUCT (Productid, Pname, Qty_onhand)\\nThe query: List customers from France who have bought more than 50 units \\nof a product “Ring_234” may be set up as follows:\\nA view is created to count total quantity of any item bought for the  \\n<Custid, Productid> pairs:\\nCREATE VIEW CP_BOUGHT_VIEW AS\\nSELECT SUM (S.Qty_sold) as Bought, S.Custid, S.Productid\\nFROM SALES S\\nGROUP BY S.Custid, S.Productid;\\nThen the query using this view becomes:\\nQG: SELECT C.Custid, C.Custname, C.Cemail\\nFROM CUST C, PRODUCT P, CP_BOUGHT_VIEW V1\\nWHERE P.Productid = V1.Productid AND C.Custid = V1.Custid AND V1.\\nBought >50\\nAND Pname = “Ring_234” AND C.Country = “France”;\\nThe view V1 may be evaluated first and its results temporarily materialized, then \\nthe query QG may be evaluated using the materialized view as one of the tables in \\nthe join. By using the merging transformation, this query becomes:\\nQT: SELECT C.Custid, C.Custname, C.Cemail\\nFROM CUST C, PRODUCT P, SALES S\\nWHERE P.Productid = S.Productid AND C.Custid = S.Custid AND\\n          Pname = “Ring_234” AND C.Country = “France”\\nGROUP BY, P.Productid, P.rowid, C.rowid, C.Custid, C.Custname, C.Cemail\\nHAVING SUM (S.Qty_sold) > 50;\\nAfter merging, the resulting query QT is much more efficient and cheaper to exe-\\ncute. The reasoning is as follows. Before merging, the view V1 does grouping on the \\nentire SALES table and materializes the result, and it is expensive to do so. In the \\ntransformed query, the grouping is applied to the join of the three tables; in this \\noperation, a single product tuple is involved from the PRODUCT table, thus filter-\\ning the data from SALES considerably. The join in QT after transformation may \\nbe slightly more expensive in that the whole SALES relation is involved rather than \\nthe aggregated view table CP_BOUGHT_VIEW in QG. Note, however, that the \\nGROUP-BY operation in V1 produces a table whose cardinality is not considerably \\nsmaller than the cardinality of SALES, because the grouping is on <Custid, Productid>, \\nwhich may not have high repetition in SALES. Also note the use of P.rowid and  \\nC.rowid, which refer to the unique row identifiers that are added to maintain equiv-\\nalence with the original query. We reiterate that the decision to merge GROUP-BY \\nviews must be made by the optimizer based on estimated costs.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 720, 'page_label': '721'}, page_content='19.2 Choice of Query Execution Plans  707\\n19.2.4 Materialized Views\\nWe discussed the concept of views in Section 7.3 and also introduced the concept \\nof materialization of views. A view is defined in the database as a query, and a \\nmaterialized view  stores the results of that query. Using materialized views to \\navoid some of the computation involved in a query is another query optimiza-\\ntion technique. A materialized view may be stored temporarily to allow more \\nqueries to be processed against it or permanently, as is common in data ware-\\nhouses (see Chapter 29). A materialized view constitutes derived data because its \\ncontent can be computed as a result of processing the defining query of the \\nmaterialized view. The main idea behind materialization is that it is much \\ncheaper to read it when needed and query against it than to recompute it from \\nscratch. The savings can be significant when the view involves costly operations \\nlike join, aggregation, and so forth.\\nConsider, for example, view V2 in Section 7.3, which defines the view as a relation \\nby joining the DEPARTMENT and EMPLOYEE relations. For every department, it \\ncomputes the total number of employees and the total salary paid to employees in \\nthat department. If this information is frequently required in reports or queries, \\nthis view may be permanently stored. The materialized view may contain data \\nrelated only to a fragment or sub-expression of the user query. Therefore, an \\ninvolved algorithm is needed to replace only the relevant fragments of the query \\nwith one or more materialized views and compute the rest of the query in a conven-\\ntional way. We also mentioned in Section 7.3 three update (also known as refresh) \\nstrategies for updating the view:\\n ■ Immediate update, which updates the view as soon as any of the relations \\nparticipating in the view are updated\\n ■ Lazy update, which recomputes the view only upon demand\\n ■ Periodic update (or deferred update), which updates the view later, possibly \\nwith some regular frequency\\nWhen immediate update is in force, it constitutes a large amount of overhead to keep \\nthe view updated when any of the underlying base relations have a change in the form \\nof insert, delete, and modify. For example, deleting an employee from the database, or \\nchanging the salary of an employee, or hiring a new employee affects the tuple corre-\\nsponding to that department in the view and hence would require the view V2 in \\nSection 7.3 to be immediately updated. These updates are handled sometimes manu-\\nally by programs that update all views defined on top of a base relation whenever the \\nbase relation is updated. But there is obviously no guarantee that all views may be \\naccounted for. Triggers (see Section 7.2) that are activated upon an update to the base \\nrelation may be used to take action and make appropriate changes to the materialized \\nviews. The straightforward and naive approach is to recompute the entire view for \\nevery update to any base table and is prohibitively costly. Hence incremental view \\nmaintenance is done in most RDBMSs today. We discuss that next.\\nIncremental View Maintenance. The basic idea behind incremental view mainte-\\nnance is that instead of creating the view from scratch, it can be updated incrementally'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 721, 'page_label': '722'}, page_content='708 Chapter 19 Query Optimization\\nby accounting for only the changes that occurred since the last time it was  \\ncreated/updated. The trick is in figuring out exactly what is the net change to the \\nmaterialized view based on a set of inserted or deleted tuples in the base relation. \\nWe describe below the general approaches to incremental view maintenance for \\nviews involving join, selection, projection, and a few types of aggregation. To deal \\nwith modification, we can consider these approaches as a combination of delete of \\nthe old tuple followed by an insert of the new tuple. Assume a view V defined over \\nrelations R and S. The respective instances are v, r, and s.\\nJoin: If a view contains inner join of relations r and s, v\\nold = r  s, and there is a new \\nset of tuples inserted: ri, in r, then the new value of the view contains (r ∪ ri)  s. The \\nincremental change to the view can be computed as vnew = r  s ∪ ri  s. Similarly, \\ndeleting a set of tuples rd from r results in the new view as vnew = r  s − rd  s. We \\nwill have similar expressions symmetrically when s undergoes addition or deletion.\\nSelection: If a view is defined as V = σC R with condition C for selection, when a \\nset of tuples ri are inserted into r, the view can be modified as vnew = vold ∪ σC ri. On \\nthe other hand, upon deletion of tuples rd from r, we get vnew = vold − σC rd.\\nProjection: Compared to the above strategy, projection requires additional work. \\nConsider the view defined as V = πSex, SalaryR, where R is the EMPLOYEE relation, \\nand suppose the following <Sex, Salary> pairs exist for Salary of 50,000 in r in three \\ndistinct tuples: t 5 contains <M, 50000>, t17 contains <M, 50000> and t 23 contains \\n<F, 50000>. The view v therefore contains <M, 50000> and <F, 50000> as two tuples \\nderived from the three tuples of r. If tuple t5 were to be deleted from r, it would have \\nno effect on the view. However, if t23 were to be deleted from r, the tuple <F, 50000> \\nwould have to be removed from the view. Similarly, if another new tuple t 77 con-\\ntaining <M, 50000> were to be inserted in the relation r, it also would have no effect \\non the view. Thus, view maintenance of projection views requires a count to be \\nmaintained in addition to the actual columns in the view. In the above example, the \\noriginal count values are 2 for <M, 50000 > and 1 for <F, 50000 >. Each time an \\ninsert to the base relation results in contributing to the view, the count is incre-\\nmented; if a deleted tuple from the base relation has been represented in the view, \\nits count is decremented. When the count of a tuple in the view reaches zero, the \\ntuple is actually dropped from the view. When a new inserted tuple contributes to \\nthe view, its count is set to 1. Note that the above discussion assumes that SELECT \\nDISTINCT is being used in defining the view to correspond to the project (\\nπ) opera-\\ntion. If the multiset version of projection is used with no DISTINCT, the counts would \\nstill be used. There is an option to display the view tuple as many times as its count \\nin case the view must be displayed as a multiset.\\nIntersection: If the view is defined as V= R ∩ S, when a new tuple ri is inserted, it \\nis compared against the s relation to see if it is present there. If present, it is inserted \\nin v, else not. If tuple rd is deleted, it is matched against the view v and, if present \\nthere, it is removed from the view.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 722, 'page_label': '723'}, page_content='19.2 Choice of Query Execution Plans  709\\nAggregation (Group By):  For aggregation, let us consider that GROUP BY  \\nis used on column G in relation R and the view contains (SELECT G, aggregate-\\nfunction (A)). The view is a result of some aggregation function applied to attribute A, \\nwhich corresponds to (see Section 8.4.2):\\nGℑAggregate-function(A)\\nWe consider a few aggregate-functions below:\\n ■ Count: For keeping the count of tuples for each group, if a new tuple is \\ninserted in r, and if it has a value for G = g1, and if g1 is present in the view, \\nthen its count is incremented by 1. If there is no tuple with the value g1 in the \\nview, then a new tuple is inserted in the view: <g1, 1>. When the tuple being \\ndeleted has the value G = g1, its count is decremented by 1. If the count of g1 \\nreaches zero after deletion in the view, that tuple is removed from the view.\\n ■ Sum: Suppose the view contains (G, sum(A)). There is a count maintained \\nfor each group in the view. If a tuple is inserted in the relation r and has (g1, \\nx1) under the columns R.G and R.A, and if the view does not have an entry \\nfor g1, a new tuple <g1, x1> is inserted in the view and its count is set to 1. If \\nthere is already an entry for g1 as <g1, s1> in the old view, it is modified as \\n<g1, s1 + x1> and its count is incremented by 1. For the deletion from base \\nrelation of a tuple with R.G, R.A being <g1, x1>, if the count of the corre-\\nsponding group g1 is 1, the tuple for group g1 would be removed from the \\nview. If it is present and has count higher than 1, the count would be decre-\\nmented by 1 and the sum s1 would be decremented to s1– x1.\\n ■ Average: The aggregate function cannot be maintained by itself without main-\\ntaining the sum and the count functions and then computing the average as sum \\ndivided by count. So both the sum and count functions need to be maintained \\nand incrementally updated as discussed above to compute the new average.\\n ■ Max and Min: We can just consider Max. Min would be symmetrically han-\\ndled. Again for each group, the (g, max(a), count) combination is main-\\ntained, where max(a) represents the maximum value of R.A in the base \\nrelation. If the inserted tuple has R.A value lower than the current max(a) \\nvalue, or if it has a value equal to max(a) in the view, only the count for the \\ngroup is incremented. If it has a value greater than max(a), the max value in \\nthe view is set to the new value and the count is incremented. Upon deletion \\nof a tuple, if its R.A value is less than the max(a), only the count is decre-\\nmented. If the R.A value matches the max(a), the count is decremented by 1; \\nso the tuple that represented the max value of A has been deleted. Therefore, \\na new max must be computed for A for the group that requires substantial \\namount of work. If the count becomes 0, that group is removed from the \\nview because the deleted tuple was the last tuple in the group.\\nWe discussed incremental materialization as an optimization technique for main-\\ntaining views. However, we can also look upon materialized views as a way to \\nreduce the effort in certain queries. For example, if a query has a component, say, \\nR \\n S or πLR that is available as a view, then the query may be modified to use the'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 723, 'page_label': '724'}, page_content='710 Chapter 19 Query Optimization\\nview and avoid doing unnecessary computation. Sometimes an opposite situation \\nhappens. A view V is used in the query Q, and that view has been materialized as v; \\nlet us say the view includes R \\n S; however, no access structures like indexes are \\navailable on v. Suppose that indexes are available on certain attributes, say, A of the \\ncomponent relation R and that the query Q involves a selection condition on A. In \\nsuch cases, the query against the view can benefit by using the index on a compo-\\nnent relation, and the view is replaced by its defining query; the relation represent-\\ning the materialized view is not used at all.\\n19.3  Use of Selectivities  \\nin Cost-Based Optimization\\nA query optimizer does not depend solely on heuristic rules or query transforma-\\ntions; it also estimates and compares the costs of executing a query using different \\nexecution strategies and algorithms, and it then chooses the strategy with the lowest \\ncost estimate. For this approach to work, accurate cost estimates are required so that \\ndifferent strategies can be compared fairly and realistically. In addition, the opti-\\nmizer must limit the number of execution strategies to be considered; otherwise, \\ntoo much time will be spent making cost estimates for the many possible execution \\nstrategies. Hence, this approach is more suitable for compiled queries, rather than \\nad-hoc queries where the optimization is done at compile time and the resulting \\nexecution strategy code is stored and executed directly at runtime. For interpreted \\nqueries, where the entire process shown in Figure 18.1 occurs at runtime, a full-\\nscale optimization may slow down the response time. A more elaborate optimiza-\\ntion is indicated for compiled queries, whereas a partial, less time-consuming \\noptimization works best for interpreted queries.\\nThis approach is generally referred to as cost-based query optimization .\\n6 It uses \\ntraditional optimization techniques that search the solution space to a problem for a \\nsolution that minimizes an objective (cost) function. The cost functions used in \\nquery optimization are estimates and not exact cost functions, so the optimization \\nmay select a query execution strategy that is not the optimal (absolute best) one. In \\nSection 19.3.1, we discuss the components of query execution cost. In Sec- \\ntion 19.3.2, we discuss the type of information needed in cost functions. This infor-\\nmation is kept in the DBMS catalog. In Section 19.3.3, we describe histograms that \\nare used to keep details on the value distributions of important attributes.\\nThe decision-making process during query optimization is nontrivial and has mul-\\ntiple challenges. We can abstract the overall cost-based query optimization \\napproach in the following way:\\n ■ For a given subexpression in the query, there may be multiple equivalence \\nrules that apply. The process of applying equivalences is a cascaded one; it \\n6This approach was first used in the optimizer for the SYSTEM R in an experimental DBMS developed at \\nIBM (Selinger et al., 1979).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 724, 'page_label': '725'}, page_content='19.3 Use of Selectivities in Cost-Based Optimization  711\\ndoes not have any limit and there is no definitive convergence. It is difficult \\nto conduct this in a space-efficient manner.\\n ■ It is necessary to resort to some quantitative measure for evaluation of alter-\\nnatives. By using the space and time requirements and reducing them to \\nsome common metric called cost, it is possible to devise some methodology \\nfor optimization.\\n ■ Appropriate search strategies can be designed by keeping the cheapest alter-\\nnatives and pruning the costlier alternatives.\\n ■ The scope of query optimization is generally a query block. Various table \\nand index access paths, join permutations (orders), join methods, group-by \\nmethods, and so on provide the alternatives from which the query optimizer \\nmust chose.\\n ■ In a global query optimization, the scope of optimization is multiple query \\nblocks.7\\n19.3.1 Cost Components for Query Execution\\nThe cost of executing a query includes the following components:\\n  1. Access cost to secondary storage. This is the cost of transferring (reading \\nand writing) data blocks between secondary disk storage and main mem-\\nory buffers. This is also known as disk I/O (input/output) cost . The cost of \\nsearching for records in a disk file depends on the type of access struc-\\ntures on that file, such as ordering, hashing, and primary or secondary \\nindexes. In addition, factors such as whether the file blocks are allocated \\ncontiguously on the same disk cylinder or scattered on the disk affect the \\naccess cost.\\n  2. Disk storage cost. This is the cost of storing on disk any intermediate files \\nthat are generated by an execution strategy for the query.\\n  3. Computation cost. This is the cost of performing in-memory operations on \\nthe records within the data buffers during query execution. Such operations \\ninclude searching for and sorting records, merging records for a join or a \\nsort operation, and performing computations on field values. This is also \\nknown as CPU (central processing unit) cost.\\n  4. Memory usage cost.  This is the cost pertaining to the number of main \\nmemory buffers needed during query execution.\\n  5. Communication cost. This is the cost of shipping the query and its results \\nfrom the database site to the site or terminal where the query originated. \\nIn distributed databases (see Chapter 23), it would also include the cost of \\ntransferring tables and results among various computers during query \\nevaluation.\\n7We do not discuss global optimization in this sense in the present chapter. Details may be found in \\nAhmed et al. (2006).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 725, 'page_label': '726'}, page_content='712 Chapter 19 Query Optimization\\nFor large databases, the main emphasis is often on minimizing the access cost to \\nsecondary storage. Simple cost functions ignore other factors and compare dif-\\nferent query execution strategies in terms of the number of block transfers \\nbetween disk and main memory buffers. For smaller databases, where most of \\nthe data in the files involved in the query can be completely stored in memory, \\nthe emphasis is on minimizing computation cost. In distributed databases, \\nwhere many sites are involved (see Chapter 23), communication cost must be \\nminimized. It is difficult to include all the cost components in a (weighted) cost \\nfunction because of the difficulty of assigning suitable weights to the cost com-\\nponents. This is why some cost functions consider a single factor only—disk \\naccess. In the next section, we discuss some of the information that is needed for \\nformulating cost functions.\\n19.3.2 Catalog Information Used in Cost Functions\\nTo estimate the costs of various execution strategies, we must keep track of any \\ninformation that is needed for the cost functions. This information may be stored \\nin the DBMS catalog, where it is accessed by the query optimizer. First, we must \\nknow the size of each file. For a file whose records are all of the same type, the  \\nnumber of records (tuples) ( r), the (average) record size (R), and the number of \\nfile blocks (b) (or close estimates of them) are needed. The blocking factor (bfr) for \\nthe file may also be needed. These were mentioned in Section 18.3.4, and we utilized \\nthem while illustrating the various implementation algorithms for relational opera-\\ntions. We must also keep track of the primary file organization  for each file. The \\nprimary file organization records may be unordered, ordered by an attribute with or \\nwithout a primary or clustering index, or hashed (static hashing or one of the \\ndynamic hashing methods) on a key attribute. Information is also kept on all pri-\\nmary, secondary, or clustering indexes and their indexing attributes. The number \\nof levels (x) of each multilevel index (primary, secondary, or clustering) is needed \\nfor cost functions that estimate the number of block accesses that occur during \\nquery execution. In some cost functions the number of first-level index blocks \\n(b\\nI1) is needed.\\nAnother important parameter is the number of distinct values NDV (A, R)  of an \\nattribute in relation R and the attribute selectivity ( sl), which is the fraction of \\nrecords satisfying an equality condition on the attribute. This allows estimation of \\nthe selection cardinality (s = sl*r) of an attribute, which is the average number of \\nrecords that will satisfy an equality selection condition on that attribute.\\nInformation such as the number of index levels is easy to maintain because it does \\nnot change very often. However, other information may change frequently; for \\nexample, the number of records r in a file changes every time a record is inserted or \\ndeleted. The query optimizer will need reasonably close but not necessarily com-\\npletely up-to-the-minute values of these parameters for use in estimating the cost of \\nvarious execution strategies. To help with estimating the size of the results of que-\\nries, it is important to have as good an estimate of the distribution of values as pos-\\nsible. To that end, most systems store a histogram.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 726, 'page_label': '727'}, page_content='19.3 Use of Selectivities in Cost-Based Optimization  713\\n19.3.3 Histograms\\nHistograms are tables or data structures maintained by the DBMS to record infor-\\nmation about the distribution of data. It is customary for most RDBMSs to store \\nhistograms for most of the important attributes. Without a histogram, the best \\nassumption is that values of an attribute are uniformly distributed over its range \\nfrom high to low. Histograms divide the attribute over important ranges (called \\nbuckets) and store the total number of records that belong to that bucket in that \\nrelation. Sometimes they may also store the number of distinct values in each \\nbucket as well. An implicit assumption is made sometimes that among the distinct \\nvalues within a bucket there is a uniform distribution. All these assumptions are \\noversimplifications that rarely hold. So keeping a histogram with a finer granularity \\n(i.e., larger number of buckets) is always useful. A couple of variations of histo-\\ngrams are common: in equi-width histograms, the range of values is divided into \\nequal subranges. In equi-height histograms, the buckets are so formed that each \\none contains roughly the same number of records. Equi-height histograms are con-\\nsidered better since they keep fewer numbers of more frequently occurring values \\nin one bucket and more numbers of less frequently occurring ones in a different \\nbucket. So the uniform distribution assumption within a bucket seems to hold bet-\\nter. We show an example of a histogram for salary information in a company in \\nFigure 19.4. This histogram divides the salary range into five buckets that may cor-\\nrespond to the important sub-ranges over which the queries may be likely because \\nthey belong to certain types of employees. It is neither an equi-width nor an equi-\\nheight histogram.\\n30k–40k 40k–70k 70k–120k 120k–200k 200k–500k\\nSalary\\n100\\n200\\n300\\n400\\n500\\n600\\n700\\nNo. of Employees\\nFigure 19.4 \\nHistogram of salary in the relation EMPLOYEE.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 727, 'page_label': '728'}, page_content='714 Chapter 19 Query Optimization\\n19.4 Cost Functions for SELECT Operation\\nWe now provide cost functions for the selection algorithms S1 to S8 discussed in \\nSection 18.3.1 in terms of number of block transfers  between memory and disk. \\nAlgorithm S9 involves an intersection of record pointers after they have been \\nretrieved by some other means, such as algorithm S6, and so the cost function will \\nbe based on the cost for S6. These cost functions are estimates that ignore computa-\\ntion time, storage cost, and other factors. To reiterate, the following notation is \\nused in the formulas hereafter:\\nC\\nSi: Cost for method Si in block accesses\\nrX: Number of records (tuples) in a relation X\\nbX: Number of blocks occupied by relation X (also referred to as b)\\nbfrX: Blocking factor (i.e., number of records per block) in relation X\\nslA: Selectivity of an attribute A for a given condition\\nsA: Selection cardinality of the attribute being selected (= slA * r)\\nxA: Number of levels of the index for attribute A\\nbI1A: Number of first-level blocks of the index on attribute A\\nNDV (A, X): Number of distinct values of attribute A in relation X\\nNote: In using the above notation in formulas, we have omitted the relation name \\nor attribute name when it is obvious.\\n ■ S1—Linear search (brute force) approach.  We search all the file blocks to \\nretrieve all records satisfying the selection condition; hence, CS1a = b. For an \\nequality condition on a key attribute, only half the file blocks are searched on \\nthe average before finding the record, so a rough estimate for CS1b = (b/2) if \\nthe record is found; if no record is found that satisfies the condition, CS1b = b.\\n ■ S2—Binary search.  This search accesses approximately CS2 =  \\nlog2b + ⎡(s/bfr)⎤ − 1 file blocks. This reduces to log2b if the equality condition \\nis on a unique (key) attribute, because s = 1 in this case.\\n ■ S3a—Using a primary index to retrieve a single record.  For a primary \\nindex, retrieve one disk block at each index level, plus one disk block from \\nthe data file. Hence, the cost is one more disk block than the number of \\nindex levels: C\\nS3a = x + 1.\\n ■ S3b—Using a hash key to retrieve a single record.  For hashing, only one \\ndisk block needs to be accessed in most cases. The cost function is approxi-\\nmately C\\nS3b = 1 for static hashing or linear hashing, and it is 2 disk block \\naccesses for extendible hashing (see Section 16.8).\\n ■ S4—Using an ordering index to retrieve multiple records. If the compari-\\nson condition is >, >=, <, or <= on a key field with an ordering index, roughly \\nhalf the file records will satisfy the condition. This gives a cost function of \\nC\\nS4 = x + (b/2). This is a very rough estimate, and although it may be correct \\non the average, it may be inaccurate in individual cases. A more accurate \\nestimate is possible if the distribution of records is stored in a histogram.\\n ■ S5—Using a clustering index to retrieve multiple records. One disk block \\nis accessed at each index level, which gives the address of the first file disk'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 728, 'page_label': '729'}, page_content='19.4 Cost Functions for SELECT Operation  715\\nblock in the cluster. Given an equality condition on the indexing attribute, s \\nrecords will satisfy the condition, where s is the selection cardinality of the \\nindexing attribute. This means that ⎡(s/bfr)⎤ file blocks will be in the cluster \\nof file blocks that hold all the selected records, giving CS5 = x + ⎡(s/bfr)⎤.\\n ■ S6—Using a secondary (B +-tree) index.  For a secondary index on a key \\n(unique) attribute, with an equality (i.e., <attribute = value>) selection condi-\\ntion, the cost is x + 1 disk block accesses. For a secondary index on a nonkey \\n(nonunique) attribute, s records will satisfy an equality condition, where s is \\nthe selection cardinality of the indexing attribute. However, because the \\nindex is nonclustering, each of the records may reside on a different disk \\nblock, so the (worst case) cost estimate is C\\nS6a = x + 1 + s. The additional 1 is \\nto account for the disk block that contains the record pointers after the index \\nis searched (see Figure 17.5). For range queries, if the comparison condition \\nis >, >=, <, or <= and half the file records are assumed to satisfy the condition, \\nthen (very roughly) half the first-level index blocks are accessed, plus half the \\nfile records via the index. The cost estimate for this case, approximately, is \\nC\\nS6b = x + (bI1/2) + (r/2). The r/2 factor can be refined if better selectivity \\nestimates are available through a histogram. The latter method CS6b can be \\nvery costly. For a range condition such as v1 < A < v2, the selection cardinal-\\nity s must be computed from the histogram or as a default, under the uniform \\ndistribution assumption; then the cost would be computed based on whether \\nor not A is a key or nonkey with a B +-tree index on A. (We leave this as an \\nexercise for the reader to compute under the different conditions.)\\n ■ S7—Conjunctive selection. We can use either S1 or one of the methods S2 \\nto S6 discussed above. In the latter case, we use one condition to retrieve the \\nrecords and then check in the main memory buffers whether each retrieved \\nrecord satisfies the remaining conditions in the conjunction. If multiple \\nindexes exist, the search of each index can produce a set of record pointers \\n(record ids) in the main memory buffers. The intersection of the sets of \\nrecord pointers (referred to in S9) can be computed in main memory, and \\nthen the resulting records are retrieved based on their record ids.\\n ■ S8—Conjunctive selection using a composite index.  Same as S3 a, S5, or \\nS6a, depending on the type of index.\\n ■ S9—Selection using a bitmap index. (See Section 17.5.2.) Depending on the \\nnature of selection, if we can reduce the selection to a set of equality condi-\\ntions, each equating the attribute with a value (e.g., A = {7, 13, 17, 55}), then \\na bit vector for each value is accessed which is r bits or r/8 bytes long. A \\nnumber of bit vectors may fit in one block. Then, if s records qualify, s blocks \\nare accessed for the data records.\\n ■ S10—Selection using a functional index.  (See Section 17.5.3.) This works \\nsimilar to S6 except that the index is based on a function of multiple attributes; \\nif that function is appearing in the SELECT clause, the corresponding index \\nmay be utilized.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 729, 'page_label': '730'}, page_content='716 Chapter 19 Query Optimization\\nCost-Based Optimization Approach. In a query optimizer, it is common to \\nenumerate the various possible strategies for executing a query and to estimate the \\ncosts for different strategies. An optimization technique, such as dynamic program-\\nming, may be used to find the optimal (least) cost estimate efficiently without hav-\\ning to consider all possible execution strategies. Dynamic programming  is an \\noptimization technique\\n8 in which subproblems are solved only once. This tech-\\nnique is applicable when a problem may be broken down into subproblems that \\nthemselves have subproblems. We will visit the dynamic programming approach \\nwhen we discuss join ordering in Section 19.5.5. We do not discuss optimization \\nalgorithms here; rather, we use a simple example to illustrate how cost estimates \\nmay be used.\\n19.4.1  Example of Optimization of Selection Based  \\non Cost Formulas:\\nSuppose that the EMPLOYEE file in Figure 5.5 has rE = 10,000 records stored in  \\nbE = 2,000 disk blocks with blocking factor bfrE = 5 records/block and the following \\naccess paths:\\n  1. A clustering index on Salary, with levels xSalary = 3 and average selection cardi-\\nnality sSalary = 20. (This corresponds to a selectivity of slSalary = 20/10000 = 0.002.)\\n  2. A secondary index on the key attribute Ssn, with xSsn = 4 (sSsn = 1, slSsn = 0.0001).\\n  3. A secondary index on the nonkey attribute Dno, with xDno = 2 and first-level \\nindex blocks bI1Dno = 4. There are NDV (Dno, EMPLOYEE) = 125 distinct val-\\nues for Dno, so the selectivity of Dno is slDno = (1/ NDV (Dno, EMPLOYEE)) = \\n0.008, and the selection cardinality is sDno = (rE * slDno) = (rE/NDV (Dno, \\nEMPLOYEE)) = 80.\\n  4. A secondary index on Sex, with xSex = 1. There are NDV (Sex, EMPLOYEE) = \\n2 values for the Sex attribute, so the average selection cardinality is sSex = \\n(rE/NDV (Sex, EMPLOYEE) ) = 5000. (Note that in this case, a histogram  \\ngiving the percentage of male and female employees may be useful, unless \\nthe percentages are approximately equal.)\\nWe illustrate the use of cost functions with the following examples:\\nOP1: σSsn=‘123456789’ (EMPLOYEE)\\nOP2: σDno>5(EMPLOYEE)\\nOP3: σDno=5(EMPLOYEE)\\nOP4: σDno=5 AND SALARY>30000 AND Sex=‘F’ (EMPLOYEE)\\nThe cost of the brute force (linear search or file scan) option S1 will be estimated as \\nCS1a = bE = 2000 (for a selection on a nonkey attribute) or CS1b = (bE/2) = 1,000 \\n8For a detailed discussion of dynamic programming as a technique of optimization, the reader may con-\\nsult an algorithm textbook such as Corman et al. (2003).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 730, 'page_label': '731'}, page_content='19.5 Cost Functions for the JOIN Operation  717\\n(average cost for a selection on a key attribute). For OP1 we can use either method \\nS1 or method S6 a; the cost estimate for S6 a is CS6a = xSsn + 1 = 4 + 1 = 5, and it is \\nchosen over method S1, whose average cost is C S1b = 1,000. For OP2 we can use \\neither method S1 (with estimated cost CS1a = 2,000) or method S6b (with estimated \\ncost CS6b = xDno + (bI1Dno/2) + (rE /2) = 2 + (4/2) + (10,000/2) = 5,004), so we choose \\nthe linear search approach for OP2. For OP3 we can use either method S1 (with \\nestimated cost CS1a = 2,000) or method S6a (with estimated cost CS6a = xDno + sDno = \\n2 + 80 = 82), so we choose method S6a.\\nFinally, consider OP4, which has a conjunctive selection condition. We need to esti-\\nmate the cost of using any one of the three components of the selection condition to \\nretrieve the records, plus the linear search approach. The latter gives cost estimate \\nC\\nS1a = 2000. Using the condition ( Dno = 5) first gives the cost estimate CS6a = 82. \\nUsing the condition (Salary > 30000) first gives a cost estimate CS4 = xSalary + (bE/2) = \\n3 + (2000/2) = 1003. Using the condition (Sex = ‘F’) first gives a cost estimate CS6a = \\nxSex + sSex = 1 + 5000 = 5001. The optimizer would then choose method S6a on the \\nsecondary index on Dno because it has the lowest cost estimate. The condition  \\n(Dno = 5) is used to retrieve the records, and the remaining part of the conjunctive \\ncondition (Salary > 30,000 AND Sex = ‘F’) is checked for each selected record after it \\nis retrieved into memory. Only the records that satisfy these additional conditions \\nare included in the result of the operation. Consider the Dno = 5 condition in OP3 \\nabove; Dno has 125 values and hence a B+-tree index would be appropriate. Instead, \\nif we had an attribute Zipcode in EMPLOYEE and if the condition were Zipcode = \\n30332 and we had only five zip codes, bitmap indexing could be used to know what \\nrecords qualify. Assuming uniform distribution, sZipcode = 2,000. This would result \\nin a cost of 2,000 for bitmap indexing.\\n19.5 Cost Functions for the JOI N Operation\\nTo develop reasonably accurate cost functions for JOIN operations, we must have an \\nestimate for the size (number of tuples) of the file that results after the JOIN opera-\\ntion. This is usually kept as a ratio of the size (number of tuples) of the resulting join \\nfile to the size of the \\nCARTESIAN PRODUCT file, if both are applied to the same input \\nfiles, and it is called the join selectivity (js). If we denote the number of tuples of a \\nrelation R by |R|, we have:\\n js = |(R c S)| / |(R × S)| = |(R c S)| / (|R| * |S|)\\nIf there is no join condition c, then js = 1 and the join is the same as the CARTESIAN \\nPRODUCT. If no tuples from the relations satisfy the join condition, then js = 0. In \\ngeneral, 0 ≤ js ≤ 1. For a join where the condition c is an equality comparison  \\nR.A = S.B, we get the following two special cases:\\n  1. If A is a key of R, then |( R c S)| ≤ | S|, so js ≤ (1/| R|). This is because each \\nrecord in file S will be joined with at most one record in file R, since A is a \\nkey of R. A special case of this condition is when attribute B is a foreign key \\nof S that references the primary key A of R. In addition, if the foreign key B'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 731, 'page_label': '732'}, page_content='718 Chapter 19 Query Optimization\\nhas the NOT NULL constraint, then js = (1/|R|), and the result file of the join \\nwill contain |S| records.\\n  2. If B is a key of S, then |(R c S)| ≤ |R|, so js ≤ (1/|S|).\\nHence a simple formula to use for join selectivity is:\\njs = 1/ max (NDV (A, R), NDV (B,S) )\\nHaving an estimate of the join selectivity for commonly occurring join conditions \\nenables the query optimizer to estimate the size of the resulting file after the join \\noperation, which we call join cardinality (jc).\\njc = |(R\\nc S)| = js * |R| * |S|.\\nWe can now give some sample approximate cost functions for estimating the cost of \\nsome of the join algorithms given in Section 18.4. The join operations are of the form:\\nR  A=B S\\nwhere A and B are domain-compatible attributes of R and S, respectively. Assume \\nthat R has bR blocks and that S has bS blocks:\\n ■ J1—Nested-loop join. Suppose that we use R for the outer loop; then we get \\nthe following cost function to estimate the number of block accesses for this \\nmethod, assuming three memory buffers. We assume that the blocking factor \\nfor the resulting file is bfrRS and that the join selectivity is known:\\nCJ1 = bR + (bR * bS) + ((js * |R| * |S|)/bfrRS)\\nThe last part of the formula is the cost of writing the resulting file to disk. This \\ncost formula can be modified to take into account different numbers of \\nmemory buffers, as presented in Section 19.4. If n\\nB main memory buffer \\nblocks are available to perform the join, the cost formula becomes:\\nCJ1 = bR + ( ⎡bR/(nB – 2)⎤ * bS) + ((js * |R| * |S|)/bfrRS)\\n ■ J2—Index-based nested-loop join (using an access structure to retrieve \\nthe matching record(s)). If an index exists for the join attribute B of S with \\nindex levels xB, we can retrieve each record s in R and then use the index to \\nretrieve all the matching records t from S that satisfy t[B] = s[A]. The cost \\ndepends on the type of index. For a secondary index where sB is the selection \\ncardinality for the join attribute B of S,9 we get:\\nCJ2a = bR + (|R| * (xB + 1 + sB)) + (( js * |R| * |S|)/bfrRS)\\nFor a clustering index where sB is the selection cardinality of B, we get\\nCJ2b = bR + (|R| * (xB + (sB/bfrB))) + (( js * |R| * |S|)/bfrRS)\\n9Selection cardinality was defined as the average number of records that satisfy an equality condition on \\nan attribute, which is the average number of records that have the same value for the attribute and \\nhence will be joined to a single record in the other file.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 732, 'page_label': '733'}, page_content='19.5 Cost Functions for the JOIN Operation  719\\nFor a primary index, we get\\nCJ2c = bR + (|R| * (xB + 1)) + ((js * |R| * |S|)/bfrRS)\\nIf a hash key exists for one of the two join attributes—say, B of S—we get\\nCJ2d = bR + (|R| * h) + ((js * |R| * |S|)/bfrRS)\\nwhere h ≥ 1 is the average number of block accesses to retrieve a record, \\ngiven its hash key value. Usually, h is estimated to be 1 for static and linear \\nhashing and 2 for extendible hashing. This is an optimistic estimate, and typ-\\nically h ranges from 1.2 to 1.5 in practical situations.\\n ■ J3—Sort-merge join. If the files are already sorted on the join attributes, the \\ncost function for this method is\\nCJ3a = bR + bS + ((js * |R| * |S|)/bfrRS)\\nIf we must sort the files, the cost of sorting must be added. We can use the \\nformulas from Section 18.2 to estimate the sorting cost.\\n ■ J4—Partition–hash join (or just hash join). The records of files R and S are \\npartitioned into smaller files. The partitioning of each file is done using the \\nsame hashing function h on the join attribute A of R (for partitioning file R) \\nand B of S (for partitioning file S). As we showed in Section 18.4, the cost of \\nthis join can be approximated to:\\nCJ4 = 3 * (bR + bS) + ((js * |R| * |S|)/bfrRS)\\n19.5.1  Join Selectivity and Cardinality  \\nfor Semi-Join and Anti-Join\\nWe consider these two important operations, which are used when unnesting cer-\\ntain queries. In Section 18.1 we showed examples of subqueries that are transformed \\ninto these operations. The goal of these operations is to avoid the unnecessary effort \\nof doing exhaustive pairwise matching of two tables based on the join condition. \\nLet us consider the join selectivity and cardinality of these two types of joins.\\nSemi-Join \\nSELECT COUNT(*)\\nFROM T1\\nWHERE T1.X IN (SELECT T2.Y\\n FROM T2);\\nUnnesting of the query above leads to semi-join. (In the following query, the nota-\\ntion “S=” for semi-join is nonstandard.)\\nSELECT COUNT(*)\\nFROM T1, T2\\nWHERE T1.X S= T2.Y;'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 733, 'page_label': '734'}, page_content='720 Chapter 19 Query Optimization\\nThe join selectivity of the semi-join above is given by:\\njs = MIN(1,NDV(Y , T2)/NDV(X, T1))\\nThe join cardinality of the semi-join is given by:\\njc = |T1|* js\\nAnti-Join Consider the following query:\\nSELECT COUNT (*)\\nFROM T1\\nWHERE T1.X NOT IN (SELECT T2.Y\\nFROM T2);\\nUnnesting of the query above leads to anti-join.10 (In the following query, the notation \\n“A=” for anti-join is nonstandard.)\\nSELECT COUNT(*)\\nFROM T1, T2\\nWHERE T1.X A= T2.Y;\\nThe join selectivity of the anti-join above is given by:\\njs = 1 – MIN(1,NDV(T2.y)/NDV(T1.x))\\nThe join cardinality of the anti-join is given by:\\njc = |T1|*js\\n19.5.2 Example of Join Optimization Based on Cost Formulas\\nSuppose that we have the EMPLOYEE  file described in the example in the previ-\\nous section, and assume that the DEPARTMENT  file in Figure 5.5 consists of  \\nrD = 125 records stored in bD = 13 disk blocks. Consider the following two join \\n operations:\\nOP6: EMPLOYEE Dno=Dnumber DEPARTMENT\\nOP7: DEPARTMENT Mgr_ssn=Ssn EMPLOYEE\\nSuppose that we have a primary index on Dnumber of DEPARTMENT with xDnumber= 1 \\nlevel and a secondary index on Mgr_ssn of DEPARTMENT with selection cardinality \\nsMgr_ssn = 1 and levels xMgr_ssn = 2. Assume that the join selectivity for OP6 is  \\njsOP6 = (1/| DEPARTMENT|) = 1/125 11 because Dnumber is a key of DEPARTMENT. \\nAlso assume that the blocking factor for the resulting join file is bfrED= 4 records  \\n10Note that in order for anti-join to be used in the NOT IN subquery, both the join attributes, T1.X and \\nT2.Y, must have non-null values. For a detailed discussion, consult Bellamkonda et al. (2009).\\n11Note that this coincides with our other formula: = 1/ max (NDV (Dno, EMPLOYEEE), NDV (Dnumber, \\nDEPARTMENT) = 1/max (125,125) = 1/125.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 734, 'page_label': '735'}, page_content='19.5 Cost Functions for the JOIN Operation  721\\nper block. We can estimate the worst-case costs for the JOIN operation OP6 using \\nthe applicable methods J1 and J2 as follows:\\n  1. Using method J1 with EMPLOYEE as outer loop:\\nCJ1 = bE + (bE * bD) + (( jsOP6 * rE* rD)/bfrED)\\n  = 2,000 + (2,000 * 13) + (((1/125) * 10,000 * 125)/4) = 30,500\\n  2. Using method J1 with DEPARTMENT as outer loop:\\nCJ1 = bD + (bE * bD) + (( jsOP6* rE* rD)/bfrED)\\n  = 13 + (13 * 2,000) + (((1/125) * 10,000 * 125/4) = 28,513\\n  3. Using method J2 with EMPLOYEE as outer loop:\\nCJ2c = bE + (rE * (xDnumber+ 1)) + (( jsOP6 * rE * rD)/bfrED\\n  = 2,000 + (10,000 * 2) + (((1/125) * 10,000 * 125/4) = 24,500\\n  4. Using method J2 with DEPARTMENT as outer loop:\\nCJ2a = bD + (rD * (xDno + sDno)) + (( jsOP6 * rE * rD)/bfrED)\\n  = 13 + (125 * (2 + 80)) + (((1/125) * 10,000 * 125/4) = 12,763\\n  5. Using method J4 gives:\\nCJ4 = 3* ( bD + bE ) + (( jsOP6 * rE * rD)/bfrED)\\n  = 3* (13+2,000) + 2,500 = 8,539\\nCase 5 has the lowest cost estimate and will be chosen. Notice that in case 2 above, \\nif 15 memory buffer blocks (or more) were available for executing the join instead \\nof just 3, 13 of them could be used to hold the entire \\nDEPARTMENT relation (outer \\nloop relation) in memory, one could be used as buffer for the result, and one would \\nbe used to hold one block at a time of the \\nEMPLOYEE file (inner loop file), and the \\ncost for case 2 could be drastically reduced to just bE + bD + (( jsOP6 * rE * rD)/bfrED) \\nor 4,513, as discussed in Section 18.4. If some other number of main memory buf-\\nfers was available, say nB = 10, then the cost for case 2 would be calculated as fol-\\nlows, which would also give better performance than case 4:\\nCJ1 = bD + (⎡bD/(nB – 2)⎤ * bE) + ((js * |R| * |S|)/bfrRS)\\n  = 13 + ( ⎡13/8⎤ * 2,000) + (((1/125) * 10,000 * 125/4) = 28,513\\n  = 13 + (2 * 2,000) + 2,500 = 6,513\\nAs an exercise, the reader should perform a similar analysis for OP7.\\n19.5.3 Multirelation Queries and JOIN Ordering Choices\\nThe algebraic transformation rules in Section 19.1.2 include a commutative rule \\nand an associative rule for the join operation. With these rules, many equivalent \\njoin expressions can be produced. As a result, the number of alternative query trees \\ngrows very rapidly as the number of joins in a query increases. A query block that \\njoins n relations will often have n − 1 join operations, and hence can have a large \\nnumber of different join orders. In general, for a query block that has n relations,'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 735, 'page_label': '736'}, page_content='722 Chapter 19 Query Optimization\\nthere are n! join orders; Cartesian products are included in this total number. Esti-\\nmating the cost of every possible join tree for a query with a large number of joins \\nwill require a substantial amount of time by the query optimizer. Hence, some \\npruning of the possible query trees is needed. Query optimizers typically limit the \\nstructure of a (join) query tree to that of left-deep (or right-deep) trees. A left-deep \\njoin tree is a binary tree in which the right child of each non–leaf node is always a \\nbase relation. The optimizer would choose the particular left-deep join tree with the \\nlowest estimated cost. Two examples of left-deep trees are shown in Figure 19.5(a). \\n(Note that the trees in Figure 19.2 are also left-deep trees.) A right-deep join tree is \\na binary tree where the left child of every leaf node is a base relation (Figure 19.5(b)).\\nA bushy join tree is a binary tree where the left or right child of an internal node \\nmay be an internal node. Figure 19.5(b) shows a right-deep join tree whereas Fig-\\nure 19.5(c) shows a bushy one using four base relations. Most query optimizers con-\\nsider left-deep join trees as the preferred join tree and then choose one among the \\nn! possible join orderings, where n is the number of relations. We discuss the join \\nordering issue in more detail in Sections 19.5.4 and 19.5.5. The left-deep tree has \\nexactly one shape, and the join orders for N tables in a left-deep tree are given by N!. \\nIn contrast, the shapes of a bushy tree are given by the following recurrence relation \\n(i.e., recursive function), with S(n) defined as follows: S(1) = 1.\\nS(n) = \\nn-1\\nΣ\\ni =1\\n S(i) * S(n − i)\\nThe above recursive equation for S(n) can be explained as follows. It states that, for \\ni between 1 and N – 1 as the number of leaves in the left subtree, those leaves may \\nbe rearranged in S(i) ways. Similarly, the remaining N – i leaves in the right subtree \\ncan be rearranged in S(N – i) ways. The number of permutations of the bushy trees \\nis given by:\\nP(n) = n! * S(n) = (2n – 2)!/(n – 1)!\\nTable 19.1 shows the number of possible left-deep (or right-deep) join trees and \\nbushy join trees for joins of up to seven relations.\\nIt is clear from Table 19.1 that the possible space of alternatives becomes rapidly \\nunmanageable if all possible bushy tree alternatives were to be considered. In certain \\nTable19.1  Number of Permutations of Left-Deep and Bushy Join Trees of n Relations\\n \\nNo. of Relations N\\nNo. of Left-Deep \\nTrees N!\\nNo. of Bushy  \\nShapes S(N)\\nNo. of Bushy Trees \\n(2N − 2)!/( N − 1)!\\n2     2   1       2\\n3     6   2      1 2\\n4    24   5     120\\n5   120  14   1,680\\n6   720  42  30,240\\n7 5,040 132 665,280'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 736, 'page_label': '737'}, page_content='19.5 Cost Functions for the JOIN Operation  723\\ncases like complex versions of snowflake schemas (see Section 29.3), approaches to \\nconsidering bushy tree alternatives have been proposed.12\\nWith left-deep trees, the right child is considered to be the inner relation when exe-\\ncuting a nested-loop join, or the probing relation when executing an index-based \\nnested-loop join. One advantage of left-deep (or right-deep) trees is that they are \\namenable to pipelining, as discussed in Section 18.7. For instance, consider the first \\nleft-deep tree in Figure 19.5(a) and assume that the join algorithm is the index-based \\nnested-loop method; in this case, a disk page of tuples of the outer relation is used to \\nprobe the inner relation for matching tuples. As resulting tuples (records) are pro-\\nduced from the join of R1 and R2, they can be used to probe R3 to locate their match-\\ning records for joining. Likewise, as resulting tuples are produced from this join, \\nthey could be used to probe R4. Another advantage of left-deep (or right-deep) trees \\nis that having a base relation as one of the inputs of each join allows the optimizer to \\nutilize any access paths on that relation that may be useful in executing the join.\\nIf materialization is used instead of pipelining (see Sections 18.7 and 19.2), the join \\nresults could be materialized and stored as temporary relations. The key idea from \\n12As a representative case for bushy trees, refer to Ahmed et al. (2014).\\nR1 R2\\n(a)\\n(c)\\nR3\\nR4\\nR4\\n(b)\\nR1\\nR3 R4\\nR2\\nR3\\nR2\\nR2R1 R4R3\\nR1\\nFigure 19.5 \\n(a) Two left-deep join query trees.  \\n(b) A right-deep join query tree.  \\n(c) A bushy query tree.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 737, 'page_label': '738'}, page_content='724 Chapter 19 Query Optimization\\nthe optimizer’s standpoint with respect to join ordering is to find an ordering that \\nwill reduce the size of the temporary results, since the temporary results (pipelined \\nor materialized) are used by subsequent operators and hence affect the execution \\ncost of those operators.\\n19.5.4 Physical Optimization\\nFor a given logical query plan based on the heuristics we have been discussing so \\nfar, each operation needs a further decision in terms of executing the operation by a \\nspecific algorithm at the physical level. This is referred to as physical optimization. \\nIf this optimization is based on the relative cost of each possible implementation, \\nwe call it cost-based physical optimization. The two sets of approaches to this deci-\\nsion making may be broadly classified as top-down and bottom-up approaches. In \\nthe top-down approach, we consider the options for implementing each operation \\nworking our way down the tree and choosing the best alternative at each stage. In \\nthe bottom-up approach, we consider the operations working up the tree, evaluat-\\ning options for physical execution, and choosing the best at each stage. Theoreti-\\ncally, both approaches amount to evaluation of the entire space of possible \\nimplementation solutions to minimize the cost of evaluation; however, the bottom-\\nup strategy lends itself naturally to pipelining and hence is used in commercial \\nRDBMSs. Among the most important physical decisions is the ordering of join \\noperations, which we will briefly discuss in Section 19.5.5. There are certain heuris-\\ntics applied at the physical optimization stage that make elaborate cost computa-\\ntions unnecessary. These heuristics include:\\n ■ For selections, use index scans wherever possible.\\n ■ If the selection condition is conjunctive, use the selection that results in the \\nsmallest cardinality first.\\n ■ If the relations are already sorted on the attributes being matched in a join, \\nthen prefer sort-merge join to other join methods.\\n ■ For union and intersection of more than two relations, use the associative \\nrule; consider the relations in the ascending order of their estimated car-\\ndinalities.\\n ■ If one of the arguments in a join has an index on the join attribute, use that \\nas the inner relation.\\n ■ If the left relation is small and the right relation is large and it has index on \\nthe joining column, then try index-based nested-loop join.\\n ■ Consider only those join orders where there are no Cartesian products or \\nwhere all joins appear before Cartesian products.\\nThe following are only some of the types of physical level heuristics used by the \\noptimizer. If the number of relations is small (typically less than 6) and, there-\\nfore, possible implementations options are limited, then most optimizers would \\nelect to apply a cost-based optimization approach directly rather than to explore \\nheuristics.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 738, 'page_label': '739'}, page_content='19.5 Cost Functions for the JOIN Operation  725\\n19.5.5 Dynamic Programming Approach to Join Ordering\\nWe saw in Section 19.5.3 that there are many possible ways to order n relations in \\nan n-way join. Even for n = 5, which is not uncommon in practical applications, the \\npossible permutations are 120 with left-deep trees and 1,680 with bushy trees. Since \\nbushy trees expand the solution space tremendously, left-deep trees are generally \\npreferred (over both bushy and right-deep trees). They have multiple advantages: \\nFirst, they work well with the common algorithms for join, including nested-loop, \\nindex-based nested-loop, and other one-pass algorithms. Second, they can generate \\nfully pipelined plans (i.e., plans where all joins can be evaluated using pipelining). \\nNote that inner tables must always be materialized because in the join implementa-\\ntion algorithms, the entire inner table is needed to perform the matching on the \\njoin attribute. This is not possible with right-deep trees.\\nThe common approach to evaluate possible permutations of joining relations is a greedy \\nheuristic approach called dynamic programming. Dynamic programming is an opti-\\nmization technique\\n13 where subproblems are solved only once, and it is applicable when \\na problem may be broken down into subproblems that themselves have subproblems. A \\ntypical dynamic programming algorithm has the following characteristics\\n14:\\n  1. The structure of an optimal solution is developed.\\n  2. The value of the optimal solution is recursively defined.\\n  3. The optimal solution is computed and its value developed in a bottom-up \\nfashion.\\nNote that the solution developed by this procedure is an optimal solution and not the \\nabsolute optimal solution. To consider how dynamic programming may be applied to \\nthe join order selection, consider the problem of ordering a 5-way join of relations r1, \\nr2, r3, r4, r5. This problem has 120 (=5!) possible left-deep tree solutions. Ideally, the \\ncost of each of them can be estimated and compared and the best one selected. Dynamic \\nprogramming takes an approach that breaks down this problem to make it more man-\\nageable. We know that for three relations, there are only six possible left-deep tree \\nsolutions. Note that if all possible bushy tree join solutions were to be evaluated, there \\nwould be 12 of them. We can therefore consider the join to be broken down as:\\nr1 \\n r2  r3  r4  r5 = (r1  r2  r3)  r4  r5\\nThe 6 (= 3!) possible options of (r1  r2  r3) may then be combined with the 6 pos-\\nsible options of taking the result of the first join, say, temp1, and then considering \\nthe next join:\\n(temp1 \\n r4  r5)\\nIf we were to consider the 6 options for evaluating temp1 and, for each of them, \\nconsider the 6 options of evaluating the second join (temp1  r4  r5), the possible \\n13For a detailed discussion of dynamic programming as a technique of optimization, the reader may con-\\nsult an algorithm textbook such as Corman et al. (2003).\\n14Based on Chapter 16 in Corman et al. (2003).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 739, 'page_label': '740'}, page_content='726 Chapter 19 Query Optimization\\nsolution space has 6 * 6 = 36 alternatives. This is where dynamic programming can \\nbe used to do a sort of greedy optimization. It takes the “optimal” plan for evaluating \\ntemp1 and does not revisit that plan. So the solution space now reduces to only 6 \\noptions to be considered for the second join. Thus the total number of options con-\\nsidered becomes 6 + 6 instead of 120 (=5!) in the nonheuristic exhaustive approach.\\nThe order in which the result of the join is generated is also important for finding \\nthe best overall order of joins since for using sort-merge join with the next relation, \\nit plays an important role. The ordering beneficial for the next join is considered an \\ninteresting  join  order . This approach was first proposed in System R at IBM \\nResearch.\\n15 Besides the join attributes of the later join, System R also included \\ngrouping attributes of a later GROUP BY or a sort order at the root of the tree \\namong interesting sort orders. For example, in the case we discussed above, the \\ninteresting join orders for the temp1 relation will include those that match the join \\nattribute(s) required to join with either r4 or with r5. The dynamic programming \\nalgorithm can be extended to consider best join orders for each interesting sort \\norder. The number of subsets of n relations is 2\\nn (for n = 5 it is 32; n = 10 gives \\n1,024, which is still manageable), and the number of interesting join orders is small. \\nThe complexity of the extended dynamic programming algorithm to determine the \\noptimal left-deep join tree permutation has been shown to be O(3\\nn).\\n19.6  Example to Illustrate Cost-Based  \\nQuery Optimization\\nWe will consider query Q2 and its query tree shown in Figure 19.1(a) to illustrate \\ncost-based query optimization:\\nQ2: SELECT Pnumber, Dnum, Lname, Address, Bdate\\n FROM PROJECT, DEPARTMENT, EMPLOYEE\\n WHERE Dnum=Dnumber AND Mgr_ssn=Ssn AND\\n  Plocation=‘Stafford’;\\nSuppose we have the information about the relations shown in Figure 19.6. The \\nLOW_VALUE and HIGH_VALUE statistics have been normalized for clarity. The tree \\nin Figure 19.1(a) is assumed to represent the result of the algebraic heuristic optimi-\\nzation process and the start of cost-based optimization (in this example, we assume \\nthat the heuristic optimizer does not push the projection operations down the tree).\\nThe first cost-based optimization to consider is join ordering. As previously men-\\ntioned, we assume the optimizer considers only left-deep trees, so the potential join \\norders—without \\nCARTESIAN PRODUCT—are:\\n  1. PROJECT  DEPARTMENT  EMPLOYEE\\n  2. DEPARTMENT  PROJECT  EMPLOYEE\\n15See the classic reference in this area by Selinger et al. (1979).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 740, 'page_label': '741'}, page_content='19.6 Example to Illustrate Cost-Based Query Optimization  727\\n  3. DEPARTMENT  EMPLOYEE  PROJECT\\n  4. EMPLOYEE  DEPARTMENT  PROJECT\\nAssume that the selection operation has already been applied to the PROJECT rela-\\ntion. If we assume a materialized approach, then a new temporary relation is cre-\\nated after each join operation. To examine the cost of join order (1), the first join is \\nbetween \\nPROJECT and DEPARTMENT. Both the join method and the access methods \\nfor the input relations must be determined. Since DEPARTMENT  has no index \\naccording to Figure 19.6, the only available access method is a table scan (that is, a \\nlinear search). The \\nPROJECT relation will have the selection operation performed \\nbefore the join, so two options exist—table scan (linear search) or use of the  \\nPROJ_PLOC index—so the optimizer must compare the estimated costs of these \\ntwo options. The statistical information on the PROJ_PLOC index (see Figure 19.6) \\nshows the number of index levels x = 2 (root plus leaf levels). The index is nonunique \\n(a) Table_name\\nPROJECT\\nPROJECT\\nPROJECT\\nDEPARTMENT\\nDEPARTMENT\\nEMPLOYEE\\nEMPLOYEE\\nEMPLOYEE\\n200\\n2000\\n50\\n50\\n50\\n10000\\n50\\n500\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n200\\n2000\\n50\\n50\\n50\\n10000\\n50\\n500\\nDnum\\nDnumber\\nPlocation\\nPnumber\\nDno\\nSalary\\nMgr_ssn\\nSsn\\nColumn_name Num_distinct Low_value High_value\\n(c) Index_name\\n*Blevel is the number of levels without the leaf level.\\nPROJ_PLOC\\nEMP_SSN\\nEMP_SAL\\n1\\n1\\n1\\n4\\n50\\n50\\n200\\n10000\\n500NONUNIQUE\\nNONUNIQUE\\nUNIQUE\\nUniqueness Blevel* Leaf_blocks Distinct_keys\\n(b) Table_name\\nPROJECT\\nDEPARTMENT\\nEMPLOYEE\\n100\\n5\\n200010000\\n2000\\n50\\nNum_rows Blocks\\nFigure 19.6 \\nSample statistical information for relations in Q2. (a) Column information.  \\n(b) Table information. (c) Index information.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 741, 'page_label': '742'}, page_content='728 Chapter 19 Query Optimization\\n(because Plocation is not a key of PROJECT), so the optimizer assumes a uniform \\ndata distribution and estimates the number of record pointers for each Plocation \\nvalue to be 10. This is computed from the tables in Figure 19.6 by multiplying \\nSelectivity * Num_rows, where Selectivity is estimated by 1/Num_distinct. So the cost of \\nusing the index and accessing the records is estimated to be 12 block accesses (2 for \\nthe index and 10 for the data blocks). The cost of a table scan is estimated to be 100 \\nblock accesses, so the index access is more efficient as expected.\\nIn the materialized approach, a temporary file \\nTEMP1 of size 1 block is created to \\nhold the result of the selection operation. The file size is calculated by determin-\\ning the blocking factor using the formula \\nNum_rows/Blocks, which gives 2,000/100 \\nor 20 rows per block. Hence, the 10 records selected from the PROJECT relation \\nwill fit into a single block. Now we can compute the estimated cost of the first \\njoin. We will consider only the nested-loop join method, where the outer relation \\nis the temporary file, \\nTEMP1, and the inner relation is DEPARTMENT . Since the \\nentire TEMP1 file fits in the available buffer space, we need to read each of the \\nDEPARTMENT table’s five blocks only once, so the join cost is six block accesses \\nplus the cost of writing the temporary result file, TEMP2. The optimizer would \\nhave to determine the size of TEMP2. Since the join attribute Dnumber is the key \\nfor DEPARTMENT, any Dnum value from TEMP1 will join with at most one record \\nfrom DEPARTMENT, so the number of rows in TEMP2 will be equal to the number \\nof rows in TEMP1, which is 10. The optimizer would determine the record size for \\nTEMP2 and the number of blocks needed to store these 10 rows. For brevity, \\nassume that the blocking factor for TEMP2 is five rows per block, so a total of two \\nblocks are needed to store TEMP2.\\nFinally, the cost of the last join must be estimated. We can use a single-loop join on \\nTEMP2 since in this case the index EMP_SSN (see Figure 19.6) can be used to probe \\nand locate matching records from EMPLOYEE . Hence, the join method would \\ninvolve reading in each block of TEMP2 and looking up each of the five Mgr_ssn \\nvalues using the EMP_SSN index. Each index lookup would require a root access, a \\nleaf access, and a data block access (x + 1, where the number of levels x is 2). So, 10 \\nlookups require 30 block accesses. Adding the two block accesses for TEMP2 gives a \\ntotal of 32 block accesses for this join.\\nFor the final projection, assume pipelining is used to produce the final result, which \\ndoes not require additional block accesses, so the total cost for join order (1) is esti-\\nmated as the sum of the previous costs. The optimizer would then estimate costs in \\na similar manner for the other three join orders and choose the one with the lowest \\nestimate. We leave this as an exercise for the reader.\\n19.7  Additional Issues Related  \\nto Query Optimization\\nIn this section, we will discuss a few issues of interest that we have not been able to \\ndiscuss earlier.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 742, 'page_label': '743'}, page_content='19.7 Additional Issues Related to Query Optimization  729\\n19.7.1 Displaying the System’s Query Execution Plan\\nMost commercial RDBMSs have a provision to display the execution plan produced \\nby the query optimizer so that DBA-level personnel can view such execution plans \\nand try to understand the descision made by the optimizer.\\n16 The common syntax \\nis some variation of EXPLAIN <query>.\\n ■ Oracle uses\\n EXPLAIN PLAN FOR\\n <SQL Query>\\nThe query may involve INSERT, DELETE, and UPDATE statements; the output \\ngoes into a table called PLAN_TABLE. An appropriate SQL query is written to read \\nthe PLAN_TABLE. Alternately, Oracle provides two scripts UTLXPLS.SQL and \\nUTLXPLP.SQL to display the plan table output for serial and parallel execution, \\nrespectively.\\n ■ IBM DB2 uses\\n EXPLAIN PLAN SELECTION [additional options] FOR <SQL-query>\\nThere is no plan table. The PLAN SELECTION is a command to indicate that the \\nexplain tables should be loaded with the explanations during the plan selection \\nphase. The same statement is also used to explain XQUERY statements.\\n ■ SQL SERVER uses\\n SET SHOWPLAN_TEXT ON or SET SHOWPLAN_XML ON or SET \\nSHOWPLAN_ALL ON\\nThe above statements are used before issuing the TRANSACT-SQL, so the plan \\noutput is presented as text or XML or in a verbose form of text corresponding to the \\nabove three options.\\n ■ PostgreSQL uses\\n EXPLAIN [set of options] <query>.where the options include ANALYZE, \\nVERBOSE, COSTS, BUFFERS, TIMING, etc.\\n19.7.2 Size Estimation of Other Operations\\nIn Sections 19.4 and 19.5, we discussed the SELECTION and JOIN operations and \\nsize estimation of the query result when the query involves those operations. Here \\nwe consider the size estimation of some other operations.\\nProjection: For projection of the form \\nπList (R) expressed as SELECT <attribute-\\nlist> FROM R, since SQL treats it as a multiset, the estimated number of tuples in \\nthe result is |R|. If the DISTINCT option is used, then size of πA (R) is NDV (A, R).\\n16We have just illustrated this facility without describing the syntactic details of each system.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 743, 'page_label': '744'}, page_content='730 Chapter 19 Query Optimization\\nSet Operations: If the arguments for an intersection, union, or set difference are \\nmade of selections on the same relation, they can be rewritten as conjunction, dis-\\njunction, or negation, respectively. For example, \\nσc1 (R) ∩ σc2 (R) can be rewritten \\nas σc1 AND c2 (R); and σc1 (R) ∪ σc2 (R) can be rewritten as σc1 OR c2 (R). The size \\nestimation can be made based on the selectivity of conditions c1 and c2. Otherwise, \\nthe estimated upper bound on the size of r ∩ s is the minimum of the sizes of r and s; \\nthe estimated upper bound on the size of r \\n∪ s is the sum of their sizes.\\nAggregation: The size of GℑAggregate-function(A) R is NDV (G, R) since there is one \\ngroup for each unique value of G.\\nOuter Join : the size of R LEFT OUTER JOIN S would be |R  S| plus |R anti-join S|. \\nSimilarly, the size of R FULL OUTER JOIN S would be |r  s| plus |r anti-join s| plus \\n|s anti-join r|. We discussed anti-join selectivity estimation in Section 19.5.1.\\n19.7.3 Plan Caching\\nIn Chapter 2, we referred to parametric users who run the same queries or transac-\\ntions repeatedly, but each time with a different set of parameters. For example, a \\nbank teller uses an account number and some function code to check the balance in \\nthat account. To run such queries or transactions repeatedly, the query optimizer \\ncomputes the best plan when the query is submitted for the first time and caches the \\nplan for future use. This storing of the plan and reusing it is referred to as plan \\ncaching. When the query is resubmitted with different constants as parameters, the \\nsame plan is reused with the new parameters. It is conceivable that the plan may \\nneed to be modified under certain situations; for example, if the query involves \\nreport generation over a range of dates or range of accounts, then, depending on \\nthe amount of data involved, different strategies may apply. Under a variation \\ncalled parametric query optimization, a query is optimized without a certain set of \\nvalues for its parameters and the optimizer outputs a number of plans for different \\npossible value sets, all of which are cached. As a query is submitted, the parameters \\nare compared to the ones used for the various plans and the cheapest among the \\napplicable plans is used.\\n19.7.4 Top- k Results Optimization\\nWhen the output of a query is expected to be large, sometimes the user is satisfied \\nwith only the top-k results based on some sort order. Some RDBMSs have a limit K \\nclause to limit the result to that size. Similarly, hints may be specified to inform the \\noptimizer to limit the generation of the result. Trying to generate the entire result \\nand then presenting only the top-k results by sorting is a naive and inefficient strat-\\negy. Among the suggested strategies, one uses generation of results in a sorted order \\nso that it can be stopped after K tuples. Other strategies, such as introducing addi-\\ntional selection conditions based on the estimated highest value, have been pro-\\nposed. Details are beyond our scope here. The reader may consult the bibliographic \\nnotes for details.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 744, 'page_label': '745'}, page_content='19.8 An Example of Query Optimization in Data Warehouses  731\\n19.8  An Example of Query Optimization  \\nin Data Warehouses\\nIn this section, we introduce another example of query transformation and rewrit-\\ning as a technique for query optimization. In Section 19.2, we saw examples of \\nquery transformation and rewriting. Those examples dealt with nested subqueries \\nand used heuristics rather than cost-based optimization. The subquery (view) \\nmerging example we showed can be considered a heuristic transformation; but the \\ngroup-by view merging uses cost-based optimization as well. In this section, we \\nconsider a transformation of star-schema queries in data warehouses based on cost \\nconsiderations. These queries are commonly used in data warehouse applications \\nthat follow the star schema. (See Section 29.3 for a discussion of star schemas.)\\nWe will refer to this procedure as s tar-transformation optimization . The star \\nschema contains a collection of tables; it gets its name because of the schema’s \\nresemblance to a star-like shape whose center contains one or more fact tables \\n(relations) that reference multiple dimension tables (relations). The fact table con-\\ntains information about the relationships (e.g., sales) among the various dimension \\ntables (e.g., customer, part, supplier, channel, year, etc.) and measure columns (e.g., \\namount_sold, etc.). Consider the representative query called QSTAR given below. \\nAssume that D1, D2, D3 are aliases for the dimension tables DIM1, DIM2, DIM3, \\nwhose primary keys are, respectively, D1.Pk, D2.Pk, and D3.Pk . These dimensions \\nhave corresponding foreign key attributes in the fact table FACT with alias F—\\nnamely, F.Fk1, F.Fk2, F.Fk3—on which joins can be defined. The query creates a \\ngrouping on attributes D1.X, D2.Y and produces a sum of the so-called “measure” \\nattribute (see Section 29.3) F.M from the fact table F. There are conditions on attri-\\nbutes A, B, C in DIM1, DIM2, DIM3, respectively:\\nQuery QSTAR:\\nSELECT D1.X, D2.Y, SUM (F.M)\\nFROM FACT F, DIM1 D1, DIM2 D2, DIM3 D3\\nWHERE F.Fk1 = D1.Pk and F.Fk2 = D2.Pk and F.Fk3 = D3.Pk and\\n          D1.A > 5 and D2.B < 77 and D3.C = 11\\nGROUP BY D1.X, D2.Y\\nThe fact table is generally very large in comparison with the dimension tables. \\nQSTAR is a typical star query, and its fact table tends to be generally very large and \\njoined with several tables of small dimension tables. The query may also contain \\nsingle-table filter predicates on other columns of the dimension tables, which are \\ngenerally restrictive. The combination of these filters helps to significantly reduce \\nthe data set processed from the fact table (such as D1.A > 5 in the above query). \\nThis type of query generally does grouping on columns coming from dimension \\ntables and aggregation on measure columns coming from the fact table.\\nThe goal of star-transformation optimization is to access only this reduced set of \\ndata from the fact table and avoid using a full table scan on it. Two types of star-\\ntransformation optimizations are possible: (A) classic star transformation, and'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 745, 'page_label': '746'}, page_content='732 Chapter 19 Query Optimization\\n(B) bitmap index star transformation. Both these optimizations are performed on \\nthe basis of comparative costs of the original and the transformed queries.\\n A. Classic Star Transformation\\n  In this optimization, a Cartesian product of the dimension tables is per-\\nformed first after applying the filters (such as D1.A > 5 ) to each dimension \\ntable. Note that generally there are no join predicates between dimension \\ntables. The result of this Cartesian product is then joined with the fact table \\nusing B-tree indexes (if any) on the joining keys of the fact table.\\n B. Bitmap Index Star Transformation\\n  The requirement with this optimization is that there must be bitmap\\n17 \\nindexes on the fact-table joining keys referenced in the query. For example, \\nin QSTAR, there must be bitmap indexes (see Section 17.5.2) on FACT.Fk1, \\nFACT.Fk2, and FACT.Fk3 attributes; each bit in the bitmap corresponds to \\na row in the fact table. The bit is set if the key value of the attribute appears \\nin a row of the fact table. The given query QSTAR is transformed into \\nQ2STAR as shown below.\\nQ2STAR:\\nSELECT D1.X, D2.Y, SUM (F.M)\\nFROM FACT F, DIM1 D1, DIM2 D2\\nWHERE F.Fk1 = D1.Pk and F.Fk2 = D2.Pk and D1.A > 5 and D2.B < 77 and\\n F.Fk1 IN (SELECT D1.Pk\\n  FROM DIM1 D1\\n  WHERE D1.A > 5) AND\\n F.Fk2 IN (SELECT D2.Pk\\n  FROM DIM2 D2\\n  WHERE D2.B < 77) AND\\n F.Fk3 IN (SELECT D3.pk\\n  FROM DIM3 D3\\n  WHERE D3.C = 11)\\nGROUP BY D1.X, D2.Y;\\n  The bitmap star transformation adds subquery predicates corresponding to \\nthe dimension tables. Note that the subqueries introduced in Q2STAR may \\nbe looked upon as a set membership operation; for example, F.Fk1 IN (5, 9, \\n12, 13, 29 …).\\nWhen driven by bitmap AND and OR operations of the key values supplied by the \\ndimension subqueries, only the relevant rows from the fact table need to be \\nretrieved. If the filter predicates on the dimension tables and the intersection of the \\nfact table joining each dimension table filtered out a significant subset of the fact \\ntable rows, then this optimization would prove to be much more efficient than a \\nbrute force full-table scan of the fact table.\\n17In some cases, the B-tree index keys can be converted into bitmaps, but we will not discuss this  \\ntechnique here.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 746, 'page_label': '747'}, page_content='19.9 Overview of Query Optimization in Oracle  733\\nThe following operations are performed in Q2STAR in order to access and join the \\nFACT table.\\n  1. By iterating over the key values coming from a dimension subquery, the \\nbitmaps are retrieved for a given key value from a bitmap index on the \\nFACT table.\\n  2. For a subquery, the bitmaps retrieved for various key values are merged \\n(OR-ed).\\n  3. The merged bitmaps for each dimension subqueries are AND-ed; that is, a \\nconjunction of the joins is performed.\\n  4. From the final bitmap, the corresponding tuple-ids for the FACT table are \\ngenerated.\\n  5. The FACT table rows are directly retrieved using the tuple-ids.\\nJoining Back:  The subquery bitmap trees filter the fact table based on the filter \\npredicates on the dimension tables; therefore, it may still be necessary to join the \\ndimension tables back to the relevant rows in the fact table using the original join \\npredicates. The join back of a dimension table can be avoided if the column(s) \\nselected from the subquery are unique and the columns of the dimension table are \\nnot referenced in the SELECT and GROUP-BY clauses. Note that in Q2STAR, the \\ntable DIM3 is not joined back to the FACT table, since it is not referenced in the \\nSELECT and GROUP-BY clauses, and DIM3.Pk is unique.\\n19.9 Overview of Query Optimization in Oracle 18\\nThis section provides a broad overview of various features in Oracle query process-\\ning, including query optimization, execution, and analytics.\\n19\\n19.9.1 Physical Optimizer\\nThe Oracle physical optimizer is cost based and was introduced in Oracle 7.1. The \\nscope of the physical optimizer is a single query block. The physical optimizer \\nexamines alternative table and index access paths, operator algorithms, join order-\\nings, join methods, parallel execution distribution methods, and so on. It chooses \\nthe execution plan with the lowest estimated cost. The estimated query cost is a \\nrelative number proportional to the expected elapsed time needed to execute the \\nquery with the given execution plan.\\nThe physical optimizer calculates this cost based on object statistics (such as table \\ncardinalities, number of distinct values in a column, column high and low values, \\ndata distribution of column values), the estimated usage of resources (such as I/O \\nand CPU time), and memory needed. Its estimated cost is an internal metric that \\n18This section is contributed by Rafi Ahmed of Oracle Corporation.\\n19Support for analytics was introduced in Oracle 10.2.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 747, 'page_label': '748'}, page_content='734 Chapter 19 Query Optimization\\nroughly corresponds to the run time and the required resources. The goal of cost-\\nbased optimization in Oracle is to find the best trade-off between the lowest run \\ntime and the least resource utilization.\\n19.9.2 Global Query Optimizer\\nIn traditional RDBMSs, query optimization consists of two distinct logical and \\nphysical optimization phases. In contrast, Oracle has a global query optimizer, \\nwhere logical transformation and physical optimization phases have been inte-\\ngrated to generate an optimal execution plan for the entire query tree. The architec-\\nture of the Oracle query processing is illustrated in Figure 19.7.\\nOracle performs a multitude of query transformations, which change and trans-\\nform the user queries into equivalent but potentially more optimal forms. Transfor-\\nmations can be either heuristic-based or cost-based. The cost-based query \\ntransformation (CBQT) framework\\n20 introduced in Oracle 10g provides efficient \\nmechanisms for exploring the state space generated by applying one or more trans-\\nformations. During cost-based transformation, an SQL statement, which may com-\\nprise multiple query blocks, is copied and transformed and its cost is computed \\nusing the physical optimizer. This process is repeated multiple times, each time \\napplying a new set of possibly interdependent transformations; and, at the end, one \\nor more transformations are selected and applied to the original SQL statement, if \\nthose transformations result in an optimal execution plan. To deal with the combi-\\nnatorial explosion, the CBQT framework provides efficient strategies for searching \\nthe state space of various transformations.\\nThe availability of the general framework for cost-based transformation has made it \\npossible for other innovative transformations to be added to the vast repertoire of \\n20As presented in Ahmed et al. (2006).\\nParser\\nFront-End\\nExecution\\nPhysical\\nOptimization\\nCost-Based\\nTransformation\\nCBQT\\nFramework\\nHeuristic-Based\\nTransformation\\nFigure 19.7 \\nCost-based query  \\ntransformation  \\nframework (based on \\nAhmed et al., 2006).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 748, 'page_label': '749'}, page_content='19.9 Overview of Query Optimization in Oracle  735\\nOracle’s query transformation techniques. Major among these transformations are \\ngroup-by and distinct subquery merging (in the FROM clause of the query), sub-\\nquery unnesting, predicate move-around, common subexpression elimination, join \\npredicate push down, OR expansion, subquery coalescing, join factorization,  \\nsubquery removal through window function, star transformation, group-by placement, \\nand bushy join trees.\\n21\\nThe cost-based transformation framework of Oracle 10g is a good example of the \\nsophisticated approach taken to optimize SQL queries.\\n19.9.3 Adaptive Optimization\\nOracle’s physical optimizer is adaptive and uses a feedback loop from the execu-\\ntion level to improve on its previous decisions. The optimizer selects the most \\noptimal execution plan for a given SQL statement using the cost model, which \\nrelies on object statistics (e.g., number of rows, distribution of column values, \\netc.) and system statistics (e.g., I/O bandwidth of the storage subsystem). The \\noptimality of the final execution plan depends primarily on the accuracy of the \\nstatistics fed into the cost model as well as on the sophistication of the cost model \\nitself. In Oracle, the feedback loop shown in Figure 19.7 establishes a bridge \\nbetween the execution engine and the physical optimizer. The bridge brings \\nvaluable statistical information to enable the physical optimizer to assess the \\nimpact of its decisions and make better decisions for the current and future exe-\\ncutions. For example, based on the estimated value of table cardinality, the opti-\\nmizer may choose the index-based nested-loop join method. However, during \\nthe execution phase, the actual table cardinality may be detected to diverge sig-\\nnificantly from the estimated value. This information may trigger the physical \\noptimizer to revise its decision and dynamically change the index access join \\nmethod to the hash join method.\\n19.9.4 Array Processing\\nOne of the critical deficiencies of SQL implementations is its lack of support for \\nN-dimensional array-based computation. Oracle has made extensions for analyt-\\nics and OLAP features; these extensions have been integrated into the Oracle \\nRDBMS engine.\\n22 We will illustrate the need for OLAP queries when we discuss \\ndata warehousing in Chapter 29. These SQL extensions involving array-based \\ncomputations for complex modeling and optimizations include access structures \\nand execution strategies for processing these computations efficiently. The com-\\nputation clause (details are beyond our scope here) allows the Oracle RDBMS to \\ntreat a table as a multidimensional array and specify a set of formulas over it. The \\nformulas replace multiple joins and UNION operations that must be performed \\nfor equivalent computation with current ANSI SQL (where ANSI stands for \\n21More details can be found in Ahmed et al. (2006, 2014).\\n22See Witkowski et al. (2003) for more details.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 749, 'page_label': '750'}, page_content='736 Chapter 19 Query Optimization\\nAmerican National Standards Institute). The computation clause not only allows \\nfor ease of application development but also offers the Oracle RDBMS an opportu-\\nnity to perform better optimization.\\n19.9.5 Hints\\nAn interesting addition to the Oracle query optimizer is the capability for an applica-\\ntion developer to specify hints (also called query annotations or directives in other \\nsystems) to the optimizer. Hints are embedded in the text of an SQL statement. Hints \\nare commonly used to address the infrequent cases where the optimizer chooses a \\nsuboptimal plan. The idea is that an application developer occasionally might need \\nto override the optimizer decisions based on cost or cardinality mis-estimations. For \\nexample, consider the \\nEMPLOYEE table shown in Figure 5.6. The Sex column of that \\ntable has only two distinct values. If there are 10,000 employees, then the optimizer, \\nin the absence of a histogram on the \\nSex column, would estimate that half are male \\nand half are female, assuming a uniform data distribution. If a secondary index \\nexists, it would more than likely not be used. However, if the application developer \\nknows that there are only 100 male employees, a hint could be specified in an SQL \\nquery whose \\nWHERE-clause condition is Sex = ‘M’ so that the associated index would \\nbe used in processing the query. Various types of hints can be specified for different \\noperations; these hints include but are not limited to the following:\\n ■ The access path for a given table\\n ■ The join order for a query block\\n ■ A particular join method for a join between tables\\n ■ The enabling or disabling of a transformation\\n19.9.6 Outlines\\nIn Oracle RDBMSs, outlines are used to preserve execution plans of SQL state-\\nments or queries. Outlines are implemented and expressed as a collection of \\nhints, because hints are easily portable and comprehensible. Oracle provides an \\nextensive set of hints that are powerful enough to specify any execution plan, no \\nmatter how complex. When an outline is used during the optimization of an SQL \\nstatement, these hints are applied at appropriate stages by the optimizer (and \\nother components). Every SQL statement processed by the Oracle optimizer \\nautomatically generates an outline that can be displayed with the execution plan. \\nOutlines are used for purposes such as plan stability, what-if analysis, and perfor-\\nmance experiments.\\n19.9.7 SQL Plan Management\\nExecution plans for SQL statements have a significant impact on the overall perfor-\\nmance of a database system. New optimizer statistics, configuration parameter \\nchanges, software updates, introduction of new query optimization and processing \\ntechniques, and hardware resource utilizations are among a multitude of factors'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 750, 'page_label': '751'}, page_content='19.10 Semantic Query Optimization  737\\nthat may cause the Oracle query optimizer to generate a new execution plan for the \\nsame SQL queries or statements. Although most of the changes in the execution \\nplans are beneficial or benign, a few execution plans may turn out to be suboptimal, \\nwhich can have a negative impact on system performance.\\nIn Oracle 11g, a novel feature called SQL plan management (SPM) was introduced\\n23 \\nfor managing execution plans for a set of queries or workloads. SPM provides stable \\nand optimal performance for a set of SQL statements by preventing new subopti-\\nmal plans from being executed while allowing other new plans to be executed if \\nthey are verifiably better than the previous plans. SPM encapsulates an elaborate \\nmechanism for managing the execution plans of a set of SQL statements, for which \\nthe user has enabled SPM. SPM maintains the previous execution plans in the form \\nof stored outlines associated with texts of SQL statements and compares the perfor-\\nmances of the old and new execution plans for a given SQL statement before per-\\nmitting them to be used by the user. SPM can be configured to work automatically, \\nor it can be manually controlled for one or more SQL statements.\\n19.10 Semantic Query Optimization\\nA different approach to query optimization, called semantic query optimization, \\nhas been suggested. This technique, which may be used in combination with the \\ntechniques discussed previously, uses constraints specified on the database schema—\\nsuch as unique attributes and other more complex constraints—to modify one query \\ninto another query that is more efficient to execute. We will not discuss this approach \\nin detail but we will illustrate it with a simple example. Consider the SQL query:\\nSELECT E.Lname, M.Lname\\nFROM EMPLOYEE AS E, EMPLOYEE AS M\\nWHERE E.Super_ssn=M.Ssn AND E.Salary > M.Salary\\nThis query retrieves the names of employees who earn more than their supervisors. \\nSuppose that we had a constraint on the database schema that stated that no \\nemployee can earn more than his or her direct supervisor. If the semantic query \\noptimizer checks for the existence of this constraint, it does not need to execute the \\nquery because it knows that the result of the query will be empty. This may save \\nconsiderable time if the constraint checking can be done efficiently. However, \\nsearching through many constraints to find those that are applicable to a given \\nquery and that may semantically optimize it can also be time-consuming.\\nConsider another example:\\nSELECT Lname, Salary\\nFROM EMPLOYEE, DEPARTMENT\\nWHERE EMPLOYEE.Dno = DEPARTMENT.Dnumber and  \\nEMPLOYEE.Salary>100000\\n23See Ziauddin et al. (2008).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 751, 'page_label': '752'}, page_content='738 Chapter 19 Query Optimization\\nIn this example, the attributes retrieved are only from one relation: EMPLOYEE; the \\nselection condition is also on that one relation. However, there is a referential integ-\\nrity constraint that Employee.Dno is a foreign key that refers to the primary key \\nDepartment.Dnumber. Therefore, this query can be transformed by removing the \\nDEPARTMENT relation from the query and thus avoiding the inner join as follows:\\nSELECT Lname, Salary\\nFROM EMPLOYEE\\nWHERE EMPLOYEE.Dno IS NOT NULL and EMPLOYEE.Salary>100000\\nThis type of transformation is based on the primary-key/foreign-key relationship \\nsemantics, which are a constraint between the two relations.\\nWith the inclusion of active rules and additional metadata in database systems (see \\nChapter 26), semantic query optimization techniques are being gradually incorpo-\\nrated into DBMSs.\\n19.11 Summary\\n In the previous chapter, we presented the strategies for query processing used by \\nrelational DBMSs. We considered algorithms for various standard relational opera-\\ntors, including selection, projection, and join. We also discussed other types of \\njoins, including outer join, semi-join, and anti-join, and we discussed aggregation \\nas well as external sorting. In this chapter, our goal was to focus on query optimiza-\\ntion techniques used by relational DBMSs. In Section 19.1 we introduced the nota-\\ntion for query trees and graphs and described heuristic approaches to query \\noptimization; these approaches use heuristic rules and algebraic techniques to \\nimprove the efficiency of query execution. We showed how a query tree that repre-\\nsents a relational algebra expression can be heuristically optimized by reorganizing \\nthe tree nodes and transforming the tree into another equivalent query tree that is \\nmore efficient to execute. We also gave equivalence-preserving transformation \\nrules and a systematic procedure for applying them to a query tree. In Section 19.2 \\nwe described alternative query evaluation plans, including pipelining and material-\\nized evaluation. Then we introduced the notion of query transformation of SQL \\nqueries; this transformation optimizes nested subqueries. We also illustrated with \\nexamples of merging subqueries occurring in the FROM clause, which act as \\nderived relations or views. We also discussed the technique of materializing views.\\nWe discussed in some detail the cost-based approach to query optimization in \\nSection 19.3. We discussed information maintained in catalogs that the query \\noptimizer consults. We also discussed histograms to maintain distribution of \\nimportant attributes. We showed how cost functions are developed for some \\ndatabase access algorithms for selection and join in Sections 19.4 and 19.5, respec-\\ntively. We illustrated with an example in Section 19.6 how these cost functions \\nare used to estimate the costs of different execution strategies. A number of addi-\\ntional issues such as display of query plans, size estimation of results, plan cach-\\ning and top-k results optimization were discussed in Section 19.7. Section 19.8'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 752, 'page_label': '753'}, page_content='Review Questions 739\\nwas devoted to a discussion of how typical queries in data warehouses are opti-\\nmized. We gave an example of cost-based query transformation in data ware-\\nhouse queries on the so-called star schema. In Section 19.9 we presented a detailed \\noverview of the Oracle query optimizer, which uses a number of additional tech-\\nniques, details of which were beyond our scope. Finally, in Section 19.10 we men-\\ntioned the technique of semantic query optimization, which uses the semantics or \\nintegrity constraints to simplify the query or completely avoid accessing the data \\nor the actual execution of the query.\\nReview Questions\\n 19.1. What is a query execution plan?\\n 19.2. What is meant by the term heuristic optimization? Discuss the main heuris-\\ntics that are applied during query optimization.\\n 19.3. How does a query tree represent a relational algebra expression? What is \\nmeant by an execution of a query tree? Discuss the rules for transformation \\nof query trees, and identify when each rule should be applied during optimi-\\nzation.\\n 19.4. How many different join orders are there for a query that joins 10 relations? \\nHow many left-deep trees are possible?\\n 19.5. What is meant by cost-based query optimization?\\n 19.6. What is the optimization approach based on dynamic programming? How \\nis it used during query optimization?\\n 19.7. What are the problems associated with keeping views materialized?\\n 19.8. What is the difference between pipelining and materialization?\\n 19.9. Discuss the cost components for a cost function that is used to estimate \\nquery execution cost. Which cost components are used most often as the \\nbasis for cost functions?\\n 19.10. Discuss the different types of parameters that are used in cost functions. \\nWhere is this information kept?\\n 19.11. What are semi-join and anti-join? What are the join selectivity and join car-\\ndinality parameters associated with them? Provide appropriate formulas.\\n 19.12. List the cost functions for the SELECT  and JOIN methods discussed in \\nSections19.4 and 19.5.\\n 19.13. What are the special features of query optimization in Oracle that we did not \\ndiscuss in the chapter?\\n 19.14. What is meant by semantic query optimization ? How does it differ from \\nother query optimization techniques?'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 753, 'page_label': '754'}, page_content='740 Chapter 19 Query Optimization\\nExercises\\n 19.15. Develop cost functions for the PROJECT , UNION, INTERSECTION , SET \\n DIFFERENCE, and CARTESIAN PRODUCT algorithms discussed in Section 19.4.\\n 19.16. Develop cost functions for an algorithm that consists of two SELECTs, a \\nJOIN, and a final PROJECT, in terms of the cost functions for the individual \\noperations.\\n 19.17. Develop a pseudo-language-style algorithm for describing the dynamic \\n programming procedure for join-order selection.\\n 19.18. Calculate the cost functions for different options of executing the JOIN \\n operation OP7 discussed in Section 19.4.\\n 19.19. Develop formulas for the hybrid hash-join algorithm for calculating the size \\nof the buffer for the first bucket. Develop more accurate cost estimation \\n formulas for the algorithm.\\n 19.20. Estimate the cost of operations OP6 and OP7 using the formulas developed \\nin Exercise 19.19.\\n 19.21. Compare the cost of two different query plans for the following query:\\n σSalary< 40000(EMPLOYEE  Dno=DnumberDEPARTMENT)\\nUse the database statistics shown in Figure 19.6.\\nSelected Bibliography\\nThis bibliography provides literature references for the topics of query processing \\nand optimization. We discussed query processing algorithms and strategies in the \\nprevious chapter, but it is difficult to separate the literature that addresses optimiza-\\ntion from the literature that addresses query processing strategies and algorithms. \\nHence, the bibliography is consolidated.\\nA detailed algorithm for relational algebra optimization is given by Smith and \\nChang (1975). The Ph.D. thesis of Kooi (1980) provides a foundation for query \\nprocessing techniques. A survey paper by Jarke and Koch (1984) gives a taxonomy \\nof query optimization and includes a bibliography of work in this area. A survey by \\nGraefe (1993) discusses query execution in database systems and includes an exten-\\nsive bibliography.\\nWhang (1985) discusses query optimization in OBE (Office-By-Example), which is \\na system based on the language QBE. Cost-based optimization was introduced in \\nthe SYSTEM R experimental DBMS and is discussed in Astrahan et al. (1976). \\nSelinger et al. (1979) is a classic paper that discussed cost-based optimization of \\nmultiway joins in SYSTEM R. Join algorithms are discussed in Gotlieb (1975), Blas-\\ngen and Eswaran (1976), and Whang et al. (1982). Hashing algorithms for imple-\\nmenting joins are described and analyzed in DeWitt et al. (1984), Bratbergsengen'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 754, 'page_label': '755'}, page_content='Selected Bibliography 741\\n(1984), Shapiro (1986), Kitsuregawa et al. (1989), and Blakeley and Martin (1990), \\namong others. Blakely et al. (1986) discuss maintenance of materialized views. \\nChaudhari et al. (1995) discuss optimization of queries with materialized views. \\nApproaches to finding a good join order are presented in Ioannidis and Kang \\n(1990) and in Swami and Gupta (1989). A discussion of the implications of left-\\ndeep and bushy join trees is presented in Ioannidis and Kang (1991). Kim (1982) \\ndiscusses transformations of nested SQL queries into canonical representations. \\nOptimization of aggregate functions is discussed in Klug (1982) and Muralikrishna \\n(1992). Query optimization with Group By is presented in Chaudhari and Shim \\n(1994). Yan and Larson (1995) discuss eager and lazy aggregation. Salzberg et al. \\n(1990) describe a fast external sorting algorithm. Estimating the size of temporary \\nrelations is crucial for query optimization. Sampling-based estimation schemes are \\npresented in Haas et al. (1995), Haas and Swami (1995), and Lipton et al. (1990). \\nHaving the database system store and use more detailed statistics in the form of \\nhistograms is the topic of Muralikrishna and DeWitt (1988) and Poosala et al. \\n(1996). Galindo-Legaria and Joshi (2001) discuss nested subquery and aggregation \\noptimization.\\nO’Neil and Graefe (1995) discuss multi-table joins using bitmap indexes. Kim et al. \\n(1985) discuss advanced topics in query optimization. Semantic query optimization \\nis discussed in King (1981) and Malley and Zdonick (1986). Work on semantic \\nquery optimization is reported in Chakravarthy et al. (1990), Shenoy and Ozsoyo-\\nglu (1989), and Siegel et al. (1992). Volcano, a query optimizer based on query \\nequivalence rules, was developed by Graefe and Mckenna (1993). Volcano and the \\nfollow-on Cascades approach by Graefe (1995) are the basis for Microsoft’s SQL \\nServer query optimization. Carey and Kossman (1998) and Bruno et al. (2002) pres-\\nent approaches to query optimization for top-k results. Galindo Legaria et al. (2004) \\ndiscuss processing and optimizing database updates.\\nAhmed et al. (2006) discuss cost-based query transformation in Oracle and give a \\ngood overview of the global query optimization architecture in Oracle 10g. Ziaud-\\ndin et al. (2008) discuss the idea of making the optimizer change the execution plan \\nfor a query. They discuss Oracle’s SQL plan management (SPM) feature, which \\nlends stability to performance. Bellamkonda et al. (2009) provide additional tech-\\nniques for query optimization. Ahmed et al. (2014) consider the advantages of \\nbushy trees over alternatives for execution. Witkowski et al. (2003) discuss support \\nfor N-dimensional array-based computation for analytics that has been integrated \\ninto the Oracle RDBMS engine.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 755, 'page_label': '756'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 756, 'page_label': '757'}, page_content='Transaction Processing, \\nConcurrency Control,  \\nand Recovery   \\npart 9'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 757, 'page_label': '758'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 758, 'page_label': '759'}, page_content='745\\n20\\nIntroduction to Transaction \\nProcessing Concepts  \\nand Theory\\nT\\nhe concept of transaction  provides a mechanism \\nfor describing logical units of database processing. \\nTransaction processing systems are systems with large databases and hundreds of \\nconcurrent users executing database transactions. Examples of such systems \\ninclude airline reservations, banking, credit card processing, online retail purchas-\\ning, stock markets, supermarket checkouts, and many other applications. These \\nsystems require high availability and fast response time for hundreds of concur-\\nrent users. In this chapter, we present the concepts that are needed in transaction \\nprocessing systems. We define the concept of a transaction, which is used to repre-\\nsent a logical unit of database processing that must be completed in its entirety to \\nensure correctness. A transaction is typically implemented by a computer program \\nthat includes database commands such as retrievals, insertions, deletions, and \\nupdates. We introduced some of the basic techniques for database programming \\nin Chapters 10 and 11.\\nIn this chapter, we focus on the basic concepts and theory that are needed to ensure \\nthe correct executions of transactions. We discuss the concurrency control prob-\\nlem, which occurs when multiple transactions submitted by various users interfere \\nwith one another in a way that produces incorrect results. We also discuss the prob-\\nlems that can occur when transactions fail, and how the database system can recover \\nfrom various types of failures.\\nThis chapter is organized as follows. Section 20.1 informally discusses why concur-\\nrency control and recovery are necessary in a database system. Section 20.2 defines \\nthe term transaction  and discusses additional concepts related to transaction \\nchapter 20'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 759, 'page_label': '760'}, page_content='746 Chapter 20 Introduction to Transaction Processing Concepts and Theory\\nprocessing in database systems. Section 20.3 presents the important properties of \\natomicity, consistency preservation, isolation, and durability or permanency—\\ncalled the ACID properties—that are considered desirable in transaction process-\\ning systems. Section 20.4 introduces the concept of schedules (or histories) of \\nexecuting transactions and characterizes the recoverability  of schedules. Sec-\\ntion\\xa020.5 discusses the notion of serializability of concurrent transaction execution, \\nwhich can be used to define correct execution sequences (or schedules) of concur-\\nrent transactions. In Section 20.6, we present some of the commands that support \\nthe transaction concept in SQL, and we introduce the concepts of isolation levels. \\nSection 20.7 summarizes the chapter.\\nThe two following chapters continue with more details on the actual methods and \\ntechniques used to support transaction processing. Chapter 21 gives an overview \\nof the basic concurrency control protocols and Chapter 22 introduces recovery \\ntechniques.\\n20.1 Introduction to Transaction Processing\\nIn this section, we discuss the concepts of concurrent execution of transactions and \\nrecovery from transaction failures. Section 20.1.1 compares single-user and multi-\\nuser database systems and demonstrates how concurrent execution of transactions \\ncan take place in multiuser systems. Section 20.1.2 defines the concept of transac-\\ntion and presents a simple model of transaction execution based on read and write \\ndatabase operations. This model is used as the basis for defining and formalizing \\nconcurrency control and recovery concepts. Section 20.1.3 uses informal examples \\nto show why concurrency control techniques are needed in multiuser systems. \\nFinally, Section 20.1.4 discusses why techniques are needed to handle recovery \\nfrom system and transaction failures by discussing the different ways in which \\ntransactions can fail while executing.\\n20.1.1 Single-User versus Multiuser Systems\\nOne criterion for classifying a database system is according to the number of users \\nwho can use the system concurrently. A DBMS is single-user if at most one user at \\na time can use the system, and it is multiuser if many users can use the system—\\nand hence access the database—concurrently. Single-user DBMSs are mostly \\nrestricted to personal computer systems; most other DBMSs are multiuser. For \\nexample, an airline reservations system is used by hundreds of users and travel \\nagents concurrently. Database systems used in banks, insurance agencies, stock \\nexchanges, supermarkets, and many other applications are multiuser systems. In \\nthese systems, hundreds or thousands of users are typically operating on the data-\\nbase by submitting transactions concurrently to the system.\\nMultiple users can access databases—and use computer systems—simultaneously \\nbecause of the concept of multiprogramming, which allows the operating system of \\nthe computer to execute multiple programs—or processes—at the same time. A single'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 760, 'page_label': '761'}, page_content='20.1 Introduction to Transaction Processing  747\\ncentral processing unit (CPU) can only execute at most one process at a time. How-\\never, multiprogramming operating systems execute some commands from one pro-\\ncess, then suspend that process and execute some commands from the next process, \\nand so on. A process is resumed at the point where it was suspended whenever it gets \\nits turn to use the CPU again. Hence, concurrent execution of processes is actually \\ninterleaved, as illustrated in Figure 20.1, which shows two processes, A and B, execut-\\ning concurrently in an interleaved fashion. Interleaving keeps the CPU busy when a \\nprocess requires an input or output (I/O) operation, such as reading a block from disk. \\nThe CPU is switched to execute another process rather than remaining idle during I/O \\ntime. Interleaving also prevents a long process from delaying other processes.\\nIf the computer system has multiple hardware processors (CPUs), parallel processing \\nof multiple processes is possible, as illustrated by processes C and D in Figure 20.1. \\nMost of the theory concerning concurrency control in databases is developed in terms \\nof interleaved concurrency, so for the remainder of this chapter we assume this model. \\nIn a multiuser DBMS, the stored data items are the primary resources that may be \\naccessed concurrently by interactive users or application programs, which are con-\\nstantly retrieving information from and modifying the database.\\n20.1.2  Transactions, Database Items, Read  \\nand Write Operations, and DBMS Buffers\\nA transaction is an executing program that forms a logical unit of database pro-\\ncessing. A transaction includes one or more database access operations—these can \\ninclude insertion, deletion, modification (update), or retrieval operations. The \\ndatabase operations that form a transaction can either be embedded within an \\napplication program or they can be specified interactively via a high-level query \\nlanguage such as SQL. One way of specifying the transaction boundaries is by \\nspecifying explicit begin transaction and end transaction statements in an appli-\\ncation program; in this case, all database access operations between the two are \\nconsidered as forming one transaction. A single application program may contain \\nmore than one transaction if it contains several transaction boundaries. If the \\ndatabase operations in a transaction do not update the database but only retrieve \\nAA\\nBB\\nC\\nD\\nCPU1\\nCPU2\\nt1 t2 t3 t4\\nTime\\nFigure 20.1 \\nInterleaved \\n processing versus \\nparallel processing \\nof concurrent \\n transactions.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 761, 'page_label': '762'}, page_content='748 Chapter 20 Introduction to Transaction Processing Concepts and Theory\\ndata, the transaction is called a read-only transaction ; otherwise it is known as a \\nread-write transaction .\\nThe database model that is used to present transaction processing concepts is sim-\\nple when compared to the data models that we discussed earlier in the book, such as \\nthe relational model or the object model. A database is basically represented as a \\ncollection of named data items. The size of a data item is called its granularity. A \\ndata item can be a database record, but it can also be a larger unit such as a whole \\ndisk block , or even a smaller unit such as an individual field (attribute) value  of \\nsome record in the database. The transaction processing concepts we discuss are \\nindependent of the data item granularity (size) and apply to data items in general. \\nEach data item has a unique name, but this name is not typically used by the pro-\\ngrammer; rather, it is just a means to uniquely identify each data item. For example, \\nif the data item granularity is one disk block, then the disk block address can be \\nused as the data item name. If the item granularity is a single record, then the record \\nid can be the item name. Using this simplified database model, the basic database \\naccess operations that a transaction can include are as follows:\\n ■ read_item(X). Reads a database item named X into a program variable. To \\nsimplify our notation, we assume that the program variable is also named X.\\n ■ write_item(X). Writes the value of program variable X into the database \\nitem named X.\\nAs we discussed in Chapter 16, the basic unit of data transfer from disk to main \\nmemory is one disk page (disk block). Executing a read_item(X) command includes \\nthe following steps:\\n  1. Find the address of the disk block that contains item X.\\n  2. Copy that disk block into a buffer in main memory (if that disk block is not \\nalready in some main memory buffer). The size of the buffer is the same as \\nthe disk block size.\\n  3. Copy item X from the buffer to the program variable named X.\\nExecuting a write_item(X) command includes the following steps:\\n  1. Find the address of the disk block that contains item X.\\n  2. Copy that disk block into a buffer in main memory (if that disk block is not \\nalready in some main memory buffer).\\n  3. Copy item X from the program variable named X into its correct location in \\nthe buffer.\\n  4. Store the updated disk block from the buffer back to disk (either immedi-\\nately or at some later point in time).\\nIt is step 4 that actually updates the database on disk. Sometimes the buffer is not \\nimmediately stored to disk, in case additional changes are to be made to the buffer. \\nUsually, the decision about when to store a modified disk block whose contents are in \\na main memory buffer is handled by the recovery manager of the DBMS in cooperation \\nwith the underlying operating system. The DBMS will maintain in the database cache'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 762, 'page_label': '763'}, page_content='20.1 Introduction to Transaction Processing  749\\na number of data buffers in main memory. Each buffer typically holds the contents \\nof one database disk block, which contains some of the database items being pro-\\ncessed. When these buffers are all occupied, and additional database disk blocks \\nmust be copied into memory, some buffer replacement policy  is used to choose \\nwhich of the current occupied buffers is to be replaced. Some commonly used buffer \\nreplacement policies are LRU (least recently used). If the chosen buffer has been \\nmodified, it must be written back to disk before it is reused.\\n1 There are also buffer \\nreplacement policies that are specific to DBMS characteristics. We briefly discuss a \\nfew of these in Section 20.2.4.\\nA transaction includes \\nread_item and write_item operations to access and update the \\ndatabase. Figure 20.2 shows examples of two very simple transactions. The read-set \\nof a transaction is the set of all items that the transaction reads, and the write-set is \\nthe set of all items that the transaction writes. For example, the read-set of T1 in \\nFigure 20.2 is {X, Y} and its write-set is also {X, Y}.\\nConcurrency control and recovery mechanisms are mainly concerned with the \\ndatabase commands in a transaction. Transactions submitted by the various users \\nmay execute concurrently and may access and update the same database items. If \\nthis concurrent execution is uncontrolled , it may lead to problems, such as an \\ninconsistent database. In the next section, we informally introduce some of the \\nproblems that may occur.\\n20.1.3 Why Concurrency Control Is Needed\\nSeveral problems can occur when concurrent transactions execute in an uncontrolled \\nmanner. We illustrate some of these problems by referring to a much simplified air-\\nline reservations database in which a record is stored for each airline flight. Each \\nrecord includes the number of reserved seats on that flight as a named (uniquely iden-\\ntifiable) data item, among other information. Figure 20.2(a) shows a transaction T\\n1 \\nthat transfers N reservations from one flight whose number of reserved seats is stored \\nin the database item named X to another flight whose number of reserved seats is \\nstored in the database item named Y. Figure 20.2(b) shows a simpler transaction T2 \\nthat just reserves M seats on the first flight (X) referenced in transaction T1.2 To sim-\\nplify our example, we do not show additional portions of the transactions, such as \\nchecking whether a flight has enough seats available before reserving additional seats.\\nWhen a database access program is written, it has the flight number, the flight date, \\nand the number of seats to be booked as parameters; hence, the same program can \\nbe used to execute many different transactions, each with a different flight number, \\ndate, and number of seats to be booked. For concurrency control purposes, a trans-\\naction is a particular execution of a program on a specific date, flight, and number \\n1We will not discuss general-purpose buffer replacement policies here because they are typically discussed \\nin operating systems texts.\\n2A similar, more commonly used example assumes a bank database, with one transaction doing a transfer \\nof funds from account X to account Y and the other transaction doing a deposit to account X.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 763, 'page_label': '764'}, page_content='750 Chapter 20 Introduction to Transaction Processing Concepts and Theory\\nof seats. In Figures 20.2(a) and (b), the transactions T1 and T2 are specific executions \\nof the programs that refer to the specific flights whose numbers of seats are stored \\nin data items X and Y in the database. Next we discuss the types of problems we \\nmay encounter with these two simple transactions if they run concurrently.\\nThe Lost Update Problem. This problem occurs when two transactions that access \\nthe same database items have their operations interleaved in a way that makes the value \\nof some database items incorrect. Suppose that transactions T\\n1 and T2 are submitted at \\napproximately the same time, and suppose that their operations are interleaved as \\nshown in Figure 20.3(a); then the final value of item X is incorrect because T\\n2 reads the \\nvalue of X before T1 changes it in the database, and hence the updated value resulting \\nfrom T1 is lost. For example, if X = 80 at the start (originally there were 80 reservations \\non the flight), N = 5 (T1 transfers 5 seat reservations from the flight corresponding to X \\nto the flight corresponding to Y), and M = 4 (T2 reserves 4 seats on X), the final result \\nshould be X = 79. However, in the interleaving of operations shown in Figure 20.3(a), it \\nis X = 84 because the update in T1 that removed the five seats from X was lost.\\nThe Temporary Update (or Dirty Read) Problem. This problem occurs when one \\ntransaction updates a database item and then the transaction fails for some reason (see \\nSection 20.1.4). Meanwhile, the updated item is accessed (read) by another transaction \\nbefore it is changed back (or rolled back) to its original value. Figure 20.3(b) shows an \\nexample where T\\n1 updates item X and then fails before completion, so the system must \\nroll back X to its original value. Before it can do so, however, transaction T2 reads the \\ntemporary value of X, which will not be recorded permanently in the database because \\nof the failure of T1. The value of item X that is read by T2 is called dirty data because it \\nhas been created by a transaction that has not completed and committed yet; hence, \\nthis problem is also known as the dirty read problem.\\nThe Incorrect Summary Problem. If one transaction is calculating an aggregate \\nsummary function on a number of database items while other transactions are \\nupdating some of these items, the aggregate function may calculate some values \\nbefore they are updated and others after they are updated. For example, suppose \\nthat a transaction T\\n3 is calculating the total number of reservations on all the flights; \\nmeanwhile, transaction T1 is executing. If the interleaving of operations shown in \\nFigure 20.3(c) occurs, the result of T3 will be off by an amount N because T3 reads \\nthe value of X after N  seats have been subtracted from it but reads the value of Y \\nbefore those N seats have been added to it.\\n(a)\\nread_item(X );\\nX := X – N;\\nwrite_item(X );\\nread_item(Y );\\nY := Y + N;\\nwrite_item(Y );\\n(b)\\nread_item(X );\\nX := X + M;\\nwrite_item(X );\\nT1 T2\\nFigure 20.2 \\nTwo sample \\n transactions. \\n(a) Transaction T\\n1. \\n(b) Transaction T2.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 764, 'page_label': '765'}, page_content='20.1 Introduction to Transaction Processing  751\\n(a)\\nread_item(X );\\nX := X – N;\\nwrite_item(X );\\nread_item(Y );\\nread_item(X );\\nX := X + M;\\nwrite_item(X );\\nTime\\nItem X has an incorrect value because\\nits update by T1 is lost (overwritten).\\nY := Y + N;\\nwrite_item(Y );\\n(b)\\nread_item(X );\\nX := X – N;\\nwrite_item(X );\\nread_item(X );\\nX := X + M;\\nwrite_item(X );\\nTime\\nTransaction T1 fails and must change\\nthe value of X back to its old value;\\nmeanwhile T2 has read the temporary\\nincorrect value of X.\\nread_item(Y );\\nT1\\nT1\\n(c)\\nread_item(X );\\nX := X – N;\\nwrite_item(X );\\nread_item(Y );\\nY := Y + N;\\nwrite_item(Y );\\nread_item(X );\\nsum := sum + X;\\nread_item(Y );\\nsum := sum + Y;\\nT3 reads X after N is subtracted and reads\\nY before N is added; a wrong summary\\nis the result (off by N ).\\nT3\\nT2\\nsum := 0;\\nread_item(A);\\nsum := sum + A;\\nT1 T2\\nFigure 20.3 \\nSome problems that occur when concurrent execution is uncontrolled. (a) The lost update \\nproblem. (b) The temporary update problem. (c) The incorrect summary problem.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 765, 'page_label': '766'}, page_content='752 Chapter 20 Introduction to Transaction Processing Concepts and Theory\\nThe Unrepeatable Read Problem. Another problem that may occur is called \\nunrepeatable read, where a transaction T reads the same item twice and the item is \\nchanged by another transaction T′ between the two reads. Hence, T receives differ-\\nent values for its two reads of the same item. This may occur, for example, if during \\nan airline reservation transaction, a customer inquires about seat availability on \\nseveral flights. When the customer decides on a particular flight, the transaction \\nthen reads the number of seats on that flight a second time before completing the \\nreservation, and it may end up reading a different value for the item.\\n20.1.4 Why Recovery Is Needed\\nWhenever a transaction is submitted to a DBMS for execution, the system is \\nresponsible for making sure that either all the operations in the transaction are \\ncompleted successfully and their effect is recorded permanently in the database, \\nor that the transaction does not have any effect on the database or any other \\ntransactions. In the first case, the transaction is said to be committed , whereas \\nin the second case, the transaction is aborted. The DBMS must not permit some \\noperations of a transaction T to be applied to the database while other opera-\\ntions of T are not, because the whole transaction  is a logical unit of database \\nprocessing. If a transaction fails after executing some of its operations but before \\nexecuting all of them, the operations already executed must be undone and have \\nno lasting effect.\\nTypes of Failures. Failures are generally classified as transaction, system, and \\nmedia failures. There are several possible reasons for a transaction to fail in the \\nmiddle of execution:\\n  1. A computer failure (system crash). A hardware, software, or network error \\noccurs in the computer system during transaction execution. Hardware \\ncrashes are usually media failures—for example, main memory failure.\\n  2. A transaction or system error.  Some operation in the transaction may \\ncause it to fail, such as integer overflow or division by zero. Transaction fail-\\nure may also occur because of erroneous parameter values or because of a \\nlogical programming error.\\n3 Additionally, the user may interrupt the trans-\\naction during its execution.\\n  3. Local errors or exception conditions detected by the transaction.  During \\ntransaction execution, certain conditions may occur that necessitate cancel-\\nlation of the transaction. For example, data for the transaction may not be \\nfound. An exception condition,\\n4 such as insufficient account balance in a \\nbanking database, may cause a transaction, such as a fund withdrawal, to be \\ncanceled. This exception could be programmed in the transaction itself, and \\nin such a case would not be considered as a transaction failure.\\n3In general, a transaction should be thoroughly tested to ensure that it does not have any bugs (logical \\nprogramming errors).\\n4Exception conditions, if programmed correctly, do not constitute transaction failures.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 766, 'page_label': '767'}, page_content='20.2 Transaction and System Concepts  753\\n  4. Concurrency control enforcement.  The concurrency control method (see \\nChapter 21)may abort a transaction because it violates serializability (see \\nSection 20.5), or it may abort one or more transactions to resolve a state of \\ndeadlock among several transactions (see Section 21.1.3). Transactions \\naborted because of serializability violations or deadlocks are typically \\nrestarted automatically at a later time.\\n  5. Disk failure. Some disk blocks may lose their data because of a read or write \\nmalfunction or because of a disk read/write head crash. This may happen \\nduring a read or a write operation of the transaction.\\n  6. Physical problems and catastrophes. This refers to an endless list of problems \\nthat includes power or air-conditioning failure, fire, theft, sabotage, overwrit-\\ning disks or tapes by mistake, and mounting of a wrong tape by the operator.\\nFailures of types 1, 2, 3, and 4 are more common than those of types 5 or 6. When-\\never a failure of type 1 through 4 occurs, the system must keep sufficient informa-\\ntion to quickly recover from the failure. Disk failure or other catastrophic failures of \\ntype 5 or 6 do not happen frequently; if they do occur, recovery is a major task. We \\ndiscuss recovery from failure in Chapter 22.\\nThe concept of transaction is fundamental to many techniques for concurrency \\ncontrol and recovery from failures.\\n20.2 Transaction and System Concepts\\nIn this section, we discuss additional concepts relevant to transaction processing. \\nSection 20.2.1 describes the various states a transaction can be in and discusses \\nother operations needed in transaction processing. Section 20.2.2 discusses the \\n system log, which keeps information about transactions and data items that will \\nbe\\xa0needed for recovery. Section 20.2.3 describes the concept of commit points of \\ntransactions and why they are important in transaction processing. Finally, \\n Sec tion\\xa020.2.4 briefly discusses DBMS buffer replacement policies.\\n20.2.1 Transaction States and Additional Operations\\nA transaction is an atomic unit of work that should either be completed in its entirety \\nor not done at all. For recovery purposes, the system needs to keep track of when each \\ntransaction starts, terminates, and commits, or aborts (see Section 20.2.3). Therefore, \\nthe recovery manager of the DBMS needs to keep track of the following operations:\\n ■ BEGIN_TRANSACTION. This marks the beginning of transaction execution.\\n ■ READ or WRITE. These specify read or write operations on the database \\nitems that are executed as part of a transaction.\\n ■ END_TRANSACTION. This specifies that READ and WRITE transaction opera-\\ntions have ended and marks the end of transaction execution. However, at \\nthis point it may be necessary to check whether the changes introduced by \\nthe transaction can be permanently applied to the database (committed) or'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 767, 'page_label': '768'}, page_content='754 Chapter 20 Introduction to Transaction Processing Concepts and Theory\\nwhether the transaction has to be aborted because it violates serializability \\n(see Section 20.5) or for some other reason.\\n ■ COMMIT_TRANSACTION. This signals a successful end of the transaction so that \\nany changes (updates) executed by the transaction can be safely committed to \\nthe database and will not be undone.\\n ■ ROLLBACK (or ABORT). This signals that the transaction has ended unsuc-\\ncessfully, so that any changes or effects that the transaction may have applied \\nto the database must be undone.\\nFigure 20.4 shows a state transition diagram that illustrates how a transaction \\nmoves through its execution states. A transaction goes into an active state immedi-\\nately after it starts execution, where it can execute its READ and WRITE operations. \\nWhen the transaction ends, it moves to the partially committed state . At this \\npoint, some types of concurrency control protocols may do additional checks to see \\nif the transaction can be committed or not. Also, some recovery protocols need to \\nensure that a system failure will not result in an inability to record the changes of \\nthe transaction permanently (usually by recording changes in the system log, \\n discussed in the next section).\\n5 If these checks are successful, the transaction is said \\nto have reached its commit point and enters the committed state. Commit points \\nare discussed in more detail in Section 20.2.3. When a transaction is committed, it \\nhas concluded its execution successfully and all its changes must be recorded \\nperma nently in the database, even if a system failure occurs.\\nHowever, a transaction can go to the failed state if one of the checks fails or if the trans-\\naction is aborted during its active state. The transaction may then have to be rolled back \\nto undo the effect of its \\nWRITE operations on the database. The terminated state corre-\\nsponds to the transaction leaving the system. The transaction information that is main-\\ntained in system tables while the transaction has been running is removed when the \\ntransaction terminates. Failed or aborted transactions may be restarted later—either \\nautomatically or after being resubmitted by the user—as brand new transactions.\\n5Optimistic concurrency control (see Section 21.4) also requires that certain checks are made at this \\npoint to ensure that the transaction did not interfere with other executing transactions.\\nActive\\nBegin \\ntransaction\\nEnd \\ntransaction Commit\\nAbortAbort\\nRead, Write\\nPartially committed\\nFailed Terminated\\nCommitted\\nFigure 20.4 \\nState transition diagram illustrating the states for transaction execution.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 768, 'page_label': '769'}, page_content='20.2 Transaction and System Concepts  755\\n20.2.2 The System Log\\nTo be able to recover from failures that affect transactions, the system maintains \\na log6 to keep track of all transaction operations that affect the values of database \\nitems, as well as other transaction information that may be needed to permit \\nrecovery from failures. The log is a sequential, append-only file that is kept on \\ndisk, so it is not affected by any type of failure except for disk or catastrophic \\nfailure. Typically, one (or more) main memory buffers, called the log buffers , \\nhold the last part of the log file, so that log entries are first added to the log main \\nmemory buffer. When the log buffer  is filled, or when certain other conditions \\noccur, the log buffer is appended to the end of the log file on disk . In addition, the \\nlog file from disk is periodically backed up to archival storage (tape) to guard \\nagainst catastrophic failures. The following are the types of entries—called log \\nrecords—that are written to the log file and the corresponding action for each \\nlog record. In these entries, T refers to a unique transaction-id  that is generated \\nautomatically by the system for each transaction and that is used to identify each \\ntransaction:\\n  1. [start_transaction, T]. Indicates that transaction T has started execution.\\n  2. [write_item, T, X, old_value, new_value]. Indicates that transaction T has \\nchanged the value of database item X from old_value to new_value.\\n  3. [read_item, T, X]. Indicates that transaction T has read the value of database \\nitem X.\\n  4. [commit, T]. Indicates that transaction T has completed successfully, and affirms \\nthat its effect can be committed (recorded permanently) to the database.\\n  5. [abort, T]. Indicates that transaction T has been aborted.\\nProtocols for recovery that avoid cascading rollbacks (see Section 20.4.2)—which \\ninclude nearly all practical protocols— do not require  that READ operations are \\nwritten to the system log. However, if the log is also used for other purposes—such \\nas auditing (keeping track of all database operations)—then such entries can be \\nincluded. Additionally, some recovery protocols require simpler \\nWRITE entries \\nthat only include one of new_value or old_value instead of including both (see Sec-\\ntion 20.4.2).\\nNotice that we are assuming that all permanent changes to the database occur \\nwithin transactions, so the notion of recovery from a transaction failure amounts \\nto either undoing or redoing transaction operations individually from the log. If \\nthe system crashes, we can recover to a consistent database state by examining the \\nlog and using one of the techniques described in Chapter 22. Because the log con-\\ntains a record of every \\nWRITE operation that changes the value of some database \\nitem, it is possible to undo the effect of these WRITE operations of a transaction T \\nby tracing backward through the log and resetting all items changed by a WRITE \\noperation of T to their old_values. Redo of an operation may also be necessary if a \\ntransaction has its updates recorded in the log but a failure occurs before the sys-\\n6The log has sometimes been called the DBMS journal.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 769, 'page_label': '770'}, page_content='756 Chapter 20 Introduction to Transaction Processing Concepts and Theory\\ntem can be sure that all these new_values have been written to the actual database \\non disk from the main memory buffers. 7\\n20.2.3 Commit Point of a Transaction\\nA transaction T reaches its commit point  when all its operations that access the \\ndatabase have been executed successfully and the effect of all the transaction opera-\\ntions on the database have been recorded in the log. Beyond the commit point, the \\ntransaction is said to be committed, and its effect must be permanently recorded in \\nthe database. The transaction then writes a commit record [\\ncommit, T] into the log. \\nIf a system failure occurs, we can search back in the log for all transactions T that \\nhave written a [ start_transaction, T] record into the log but have not written their \\n[commit, T] record yet; these transactions may have to be rolled back to undo their \\neffect on the database during the recovery process. Transactions that have written \\ntheir commit record in the log must also have recorded all their WRITE operations \\nin the log, so their effect on the database can be redone from the log records.\\nNotice that the log file must be kept on disk. As discussed in Chapter 16, updating \\na disk file involves copying the appropriate block of the file from disk to a buffer in \\nmain memory, updating the buffer in main memory, and copying the buffer to \\ndisk. As we mentioned earlier, it is common to keep one or more blocks of the log \\nfile in main memory buffers, called the log buffer , until they are filled with log \\nentries and then to write them back to disk only once, rather than writing to disk \\nevery time a log entry is added. This saves the overhead of multiple disk writes of \\nthe same log file buffer. At the time of a system crash, only the log entries that have \\nbeen written back to disk  are considered in the recovery process if the contents of \\nmain memory are lost. Hence, before a transaction reaches its commit point, any \\nportion of the log that has not been written to the disk yet must now be written to \\nthe disk. This process is called force-writing the log buffer to disk before commit-\\nting a transaction.\\n20.2.4 DBMS-Specific Buffer Replacement Policies\\nThe DBMS cache will hold the disk pages that contain information currently being \\nprocessed in main memory buffers. If all the buffers in the DBMS cache are occu-\\npied and new disk pages are required to be loaded into main memory from disk, a \\npage replacement policy  is needed to select the particular buffers to be replaced. \\nSome page replacement policies that have been developed specifically for database \\nsystems are briefly discussed next.\\nDomain Separation (DS) Method. In a DBMS, various types of disk pages \\nexist: index pages, data file pages, log file pages, and so on. In this method, the \\nDBMS cache is divided into separate domains (sets of buffers). Each domain han-\\ndles one type of disk pages, and page replacements within each domain are han-\\n7Undo and redo are discussed more fully in Chapter 22.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 770, 'page_label': '771'}, page_content='20.3 Desirable Properties of Transactions  757\\ndled via the basic LRU (least recently used) page replacement. Although this \\nachieves better performance on average that basic LRU, it is a static algorithm, and \\nso does not adapt to dynamically changing loads because the number of available \\nbuffers for each domain is predetermined. Several variations of the DS page \\nreplacement policy have been proposed, which add dynamic load-balancing fea-\\ntures. For example, the GRU (Group LRU) gives each domain a priority level and \\nselects pages from the lowest-priority level domain first for replacement, whereas \\nanother method dynamically changes the number of buffers in each domain based \\non current workload.\\nHot Set Method. This page replacement algorithm is useful in queries that have \\nto scan a set of pages repeatedly, such as when a join operation is performed using \\nthe nested-loop method (see Chapter 18). If the inner loop file is loaded completely \\ninto main memory buffers without replacement (the hot set), the join will be per-\\nformed efficiently because each page in the outer loop file will have to scan all the \\nrecords in the inner loop file to find join matches. The hot set method determines \\nfor each database processing algorithm the set of disk pages that will be accessed \\nrepeatedly, and it does not replace them until their processing is completed.\\nThe DBMIN Method. This page replacement policy uses a model known as QLSM \\n(query locality set model), which predetermines the pattern of page references for \\neach algorithm for a particular type of database operation. We discussed various \\nalgorithms for relational operations such as SELECT and JOIN in Chapter 18. \\nDepending on the type of access method, the file characteristics, and the algorithm \\nused, the QLSM will estimate the number of main memory buffers needed for each \\nfile involved in the operation. The DBMIN page replacement policy will calculate a \\nlocality set using QLSM for each file instance involved in the query (some queries \\nmay reference the same file twice, so there would be a locality set for each file \\ninstance needed in the query). DBMIN then allocates the appropriate number of \\nbuffers to each file instance involved in the query based on the locality set for that \\nfile instance. The concept of locality set is analogous to the concept of working set, \\nwhich is used in page replacement policies for processes by the operating system \\nbut there are multiple locality sets, one for each file instance in the query.\\n20.3 Desirable Properties of Transactions\\nTransactions should possess several properties, often called the ACID properties; \\nthey should be enforced by the concurrency control and recovery methods of the \\nDBMS. The following are the ACID properties:\\n ■ Atomicity. A transaction is an atomic unit of processing; it should either be \\nperformed in its entirety or not performed at all.\\n ■ Consistency preservation. A transaction should be consistency preserving, \\nmeaning that if it is completely executed from beginning to end without \\ninterference from other transactions, it should take the database from one \\nconsistent state to another.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 771, 'page_label': '772'}, page_content='758 Chapter 20 Introduction to Transaction Processing Concepts and Theory\\n ■ Isolation. A transaction should appear as though it is being executed in iso-\\nlation from other transactions, even though many transactions are execut-\\ning concurrently. That is, the execution of a transaction should not be \\ninterfered with by any other transactions executing concurrently.\\n ■ Durability or permanency. The changes applied to the database by a com-\\nmitted transaction must persist in the database. These changes must not be \\nlost because of any failure.\\nThe atomicity property requires that we execute a transaction to completion. It is \\nthe responsibility of the transaction recovery subsystem of a DBMS to ensure atomi-\\ncity. If a transaction fails to complete for some reason, such as a system crash in the \\nmidst of transaction execution, the recovery technique must undo any effects of the \\ntransaction on the database. On the other hand, write operations of a committed \\ntransaction must be eventually written to disk.\\nThe preservation of consistency  is generally considered to be the responsibility of \\nthe programmers who write the database programs and of the DBMS module \\nthat enforces integrity constraints. Recall that a database state  is a collection of \\nall the stored data items (values) in the database at a given point in time. A \\n consistent state  of the database satisfies the constraints specified in the schema \\nas well as any other constraints on the database that should hold. A database \\nprogram should be written in a way that guarantees that, if the database is in a \\nconsistent state before executing the transaction, it will be in a consistent state \\nafter the complete  execution of the transaction, assuming that no interference \\nwith other transactions  occurs.\\nThe isolation property  is enforced by the concurrency control subsystem  of the \\nDBMS.\\n8 If every transaction does not make its updates (write operations) visible to \\nother transactions until it is committed, one form of isolation is enforced that \\nsolves the temporary update problem and eliminates cascading rollbacks (see \\nChapter 22) but does not eliminate all other problems.\\nThe durability property is the responsibility of the recovery subsystem of the DBMS. \\nIn the next section, we introduce how recovery protocols enforce durability and \\natomicity and then discuss this in more detail in Chapter 22.\\nLevels of Isolation. There have been attempts to define the level of isolation of a \\ntransaction. A transaction is said to have level 0 (zero) isolation if it does not over-\\nwrite the dirty reads of higher-level transactions. Level 1 (one) isolation has no lost \\nupdates, and level 2 isolation has no lost updates and no dirty reads. Finally, level 3 \\nisolation (also called true isolation) has, in addition to level 2 properties, repeatable \\nreads.\\n9 Another type of isolation is called snapshot isolation, and several practical \\nconcurrency control methods are based on this. We shall discuss snapshot isolation \\nin Section 20.6, and again in Chapter 21, Section 21.4.\\n8We will discuss concurrency control protocols in Chapter 21.\\n9The SQL syntax for isolation level discussed in Section 20.6 is closely related to these levels.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 772, 'page_label': '773'}, page_content='20.4 Characterizing Schedules Based on Recoverability  759\\n20.4  Characterizing Schedules Based  \\non Recoverability\\nWhen transactions are executing concurrently in an interleaved fashion, then the \\norder of execution of operations from all the various transactions is known as a \\nschedule (or history). In this section, first we define the concept of schedules, and \\nthen we characterize the types of schedules that facilitate recovery when failures \\noccur. In Section 20.5, we characterize schedules in terms of the interference of \\nparticipating transactions; this discussion leads to the concepts of serializability and \\nserializable schedules.\\n20.4.1 Schedules (Histories) of Transactions\\nA schedule  (or history) S of n transactions T1, T2, … , Tn is an ordering of the \\noperations of the transactions. Operations from different transactions can be \\ninterleaved in the schedule S. However, for each transaction T\\ni that participates \\nin the schedule S, the operations of Ti in S must appear in the same order in \\nwhich they occur in Ti. The order of operations in S is considered to be a total \\nordering , meaning that for any two operations  in the schedule, one must occur \\nbefore the other. It is possible theoretically to deal with schedules whose opera-\\ntions form partial orders , but we will assume for now total ordering of the opera-\\ntions in a schedule.\\nFor the purpose of recovery and concurrency control, we are mainly interested in \\nthe \\nread_item and write_item operations of the transactions, as well as the commit and \\nabort operations. A shorthand notation for describing a schedule uses the symbols \\nb, r, w, e, c, and a for the operations begin_transaction , read_item , write_item ,  \\nend_transaction , commit, and abort, respectively, and appends as a subscript  the \\ntransaction id (transaction number) to each operation in the schedule. In this \\nnotation, the database item X that is read or written follows the r and w operations \\nin parentheses. In some schedules, we will only show the read and write operations, \\nwhereas in other schedules we will show additional operations, such as commit or \\nabort. The schedule in Figure 20.3(a), which we shall call S\\na, can be written as  follows \\nin this notation:\\nSa: r1(X); r2(X); w1(X); r1(Y); w2(X); w1(Y);\\nSimilarly, the schedule for Figure 20.3(b), which we call Sb, can be written as fol-\\nlows, if we assume that transaction T1 aborted after its read_item(Y) operation:\\nSb: r1(X); w1(X); r2(X); w2(X); r1(Y); a1;\\nConflicting Operations in a Schedule. Two operations in a schedule are said to \\nconflict if they satisfy all three of the following conditions: (1) they belong to differ-\\nent transactions; (2) they access the same item X; and (3) at least one of the opera-\\ntions is a write_item(X). For example, in schedule Sa, the operations r1(X) and w2(X) \\nconflict, as do the operations r2(X) and w1(X), and the operations w1(X) and w2(X). \\nHowever, the operations r1(X) and r2(X) do not conflict, since they are both read'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 773, 'page_label': '774'}, page_content='760 Chapter 20 Introduction to Transaction Processing Concepts and Theory\\noperations; the operations w2(X) and w1(Y) do not conflict because they operate on \\ndistinct data items X and Y; and the operations r1(X) and w1(X) do not conflict \\nbecause they belong to the same transaction.\\nIntuitively, two operations are conflicting if changing their order can result in a dif-\\nferent outcome. For example, if we change the order of the two operations r1(X); \\nw2(X) to w2(X); r1(X), then the value of X that is read by transaction T1 changes, \\nbecause in the second ordering the value of X is read by r1(X) after it is changed by \\nw2(X), whereas in the first ordering the value is read before it is changed. This is \\ncalled a read-write conflict. The other type is called a write-write conflict and is \\nillustrated by the case where we change the order of two operations such as w1(X); \\nw2(X) to w2(X); w1(X). For a write-write conflict, the last value  of X will differ \\nbecause in one case it is written by T2 and in the other case by T1. Notice that two \\nread operations are not conflicting because changing their order makes no differ-\\nence in outcome.\\nThe rest of this section covers some theoretical definitions concerning schedules. A \\nschedule S of n transactions T\\n1, T2, … , Tn is said to be a complete schedule if the \\nfollowing conditions hold:\\n  1. The operations in S are exactly those operations in T1, T2, … , Tn, including \\na commit or abort operation as the last operation for each transaction in \\nthe schedule.\\n  2. For any pair of operations from the same transaction Ti, their relative order \\nof appearance in S is the same as their order of appearance in Ti.\\n  3. For any two conflicting operations, one of the two must occur before the \\nother in the schedule.10\\nThe preceding condition (3) allows for two nonconflicting operations  to occur in \\nthe schedule without defining which occurs first, thus leading to the definition of \\na schedule as a partial order  of the operations in the n transactions. 11 However, a \\ntotal order must be specified in the schedule for any pair of conflicting operations \\n(condition 3) and for any pair of operations from the same transaction (condi-\\ntion 2). Condition 1 simply states that all operations in the transactions must \\nappear in the complete schedule. Since every transaction has either committed \\nor\\xa0aborted, a complete schedule will not contain any active transactions  at the end \\nof the schedule.\\nIn general, it is difficult to encounter complete schedules in a transaction process-\\ning system because new transactions are continually being submitted to the system. \\nHence, it is useful to define the concept of the committed projection  C(S) of a \\nschedule S, which includes only the operations in S that belong to committed trans-\\nactions—that is, transactions T\\ni whose commit operation ci is in S.\\n10Theoretically, it is not necessary to determine an order between pairs of nonconflicting operations.\\n11In practice, most schedules have a total order of operations. If parallel processing is employed, it is \\ntheoretically possible to have schedules with partially ordered nonconflicting operations.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 774, 'page_label': '775'}, page_content='20.4 Characterizing Schedules Based on Recoverability  761\\n20.4.2 Characterizing Schedules Based on Recoverability\\nFor some schedules it is easy to recover from transaction and system failures, \\nwhereas for other schedules the recovery process can be quite involved. In some \\ncases, it is even not possible to recover correctly after a failure. Hence, it is impor-\\ntant to characterize the types of schedules for which recovery is possible, as well as \\nthose for which recovery is relatively simple. These characterizations do not actually \\nprovide the recovery algorithm; they only attempt to theoretically characterize the \\ndifferent types of schedules.\\nFirst, we would like to ensure that, once a transaction T is committed, it should \\nnever be necessary to roll back T. This ensures that the durability property of \\ntransactions is not violated (see Section 20.3). The schedules that theoretically \\nmeet this criterion are called recoverable schedules. A schedule where a committed \\ntransaction may have to be rolled back during recovery is called nonrecoverable \\nand hence should not be permitted by the DBMS. The condition for a recoverable \\nschedule is as follows: A schedule S is recoverable if no transaction T in S commits \\nuntil all transactions T′ that have written some item X that T reads have commit-\\nted. A transaction T reads from transaction T′ in a schedule S if some item X is \\nfirst written by T′ and later read by T. In addition, T′ should not have been aborted \\nbefore T reads item X, and there should be no transactions that write X after T′ \\nwrites it and before T reads it (unless those transactions, if any, have aborted \\nbefore T reads X).\\nSome recoverable schedules may require a complex recovery process, as we shall \\nsee, but if sufficient information is kept (in the log), a recovery algorithm can be \\ndevised for any recoverable schedule. The (partial) schedules S\\na and Sb from the \\npreceding section are both recoverable, since they satisfy the above definition. Con-\\nsider the schedule S\\na′ given below, which is the same as schedule Sa except that two \\ncommit operations have been added to Sa:\\nSa′: r1(X); r2(X); w1(X); r1(Y); w2(X); c2; w1(Y); c1;\\nSa′ is recoverable, even though it suffers from the lost update problem; this problem \\nis handled by serializability theory (see Section 20.5). However, consider the two \\n(partial) schedules S\\nc and Sd that follow:\\nSc: r1(X); w1(X); r2(X); r1(Y); w2(X); c2; a1;\\nSd: r1(X); w1(X); r2(X); r1(Y); w2(X); w1(Y); c1; c2;\\nSe: r1(X); w1(X); r2(X); r1(Y); w2(X); w1(Y); a1; a2;\\nSc is not recoverable because T2 reads item X from T1, but T2 commits before T1 \\ncommits. The problem occurs if T1 aborts after the c2 operation in Sc; then the value \\nof X that T2 read is no longer valid and T2 must be aborted after it is committed, \\nleading to a schedule that is not recoverable. For the schedule to be recoverable, the \\nc2 operation in Sc must be postponed until after T1 commits, as shown in Sd. If T1 \\naborts instead of committing, then T2 should also abort as shown in Se, because the \\nvalue of X it read is no longer valid. In Se, aborting T2 is acceptable since it has not \\ncommitted yet, which is not the case for the nonrecoverable schedule Sc.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 775, 'page_label': '776'}, page_content='762 Chapter 20 Introduction to Transaction Processing Concepts and Theory\\nIn a recoverable schedule, no committed transaction ever needs to be rolled back, \\nand so the definition of a committed transaction as durable is not violated. How-\\never, it is possible for a phenomenon known as cascading rollback (or cascading \\nabort) to occur in some recoverable schedules, where an uncommitted transaction \\nhas to be rolled back because it read an item from a transaction that failed. This is \\nillustrated in schedule S\\ne, where transaction T2 has to be rolled back because it read \\nitem X from T1, and T1 then aborted.\\nBecause cascading rollback can be time-consuming—since numerous transactions \\ncan be rolled back (see Chapter 22)—it is important to characterize the schedules \\nwhere this phenomenon is guaranteed not to occur. A schedule is said to be \\ncascadeless , or to avoid cascading rollback , if every transaction in the schedule \\nreads only items that were written by committed transactions. In this case, all items \\nread will not be discarded because the transactions that wrote them have commit-\\nted, so no cascading rollback will occur. To satisfy this criterion, the r\\n2(X) com-\\nmand in schedules Sd and Se must be postponed until after T1 has committed (or \\naborted), thus delaying T2 but ensuring no cascading rollback if T1 aborts.\\nFinally, there is a third, more restrictive type of schedule, called a strict schedule, in \\nwhich transactions can neither read nor write  an item X until the last transaction \\nthat wrote X has committed (or aborted). Strict schedules simplify the recovery \\nprocess. In a strict schedule, the process of undoing a write_item(X) operation of an \\naborted transaction is simply to restore the before image  (old_value or BFIM) of \\ndata item X. This simple procedure always works correctly for strict schedules, but \\nit may not work for recoverable or cascadeless schedules. For example, consider \\nschedule Sf :\\nSf : w1(X, 5); w2(X, 8); a1;\\nSuppose that the value of X was originally 9, which is the before image stored in the \\nsystem log along with the w1(X, 5) operation. If T1 aborts, as in Sf, the recovery pro-\\ncedure that restores the before image of an aborted write operation will restore the \\nvalue of X to 9, even though it has already been changed to 8 by transaction T2, thus \\nleading to potentially incorrect results. Although schedule Sf is cascadeless, it is not \\na strict schedule, since it permits T2 to write item X even though the transaction T1 \\nthat last wrote X had not yet committed (or aborted). A strict schedule does not \\nhave this problem.\\nIt is important to note that any strict schedule is also cascadeless, and any cascade-\\nless schedule is also recoverable. Suppose we have i transactions T1, T2, … , Ti, and \\ntheir number of operations are n1, n2, … , ni, respectively. If we make a set of all \\npossible schedules of these transactions, we can divide the schedules into two dis-\\njoint subsets: recoverable and nonrecoverable. The cascadeless schedules will be a \\nsubset of the recoverable schedules, and the strict schedules will be a subset of the \\ncascadeless schedules. Thus, all strict schedules are cascadeless, and all cascadeless \\nschedules are recoverable.\\nMost recovery protocols allow only strict schedules, so that the recovery process \\nitself is not complicated (see Chapter 22).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 776, 'page_label': '777'}, page_content='20.5 Characterizing Schedules Based on Serializability  763\\n20.5  Characterizing Schedules Based  \\non Serializability\\nIn the previous section, we characterized schedules based on their recoverability \\nproperties. Now we characterize the types of schedules that are always considered \\nto be correct when concurrent transactions are executing. Such schedules are known \\nas serializable schedules. Suppose that two users—for example, two airline reserva-\\ntions agents—submit to the DBMS transactions T\\n1 and T2 in Figure 20.2 at approx-\\nimately the same time. If no interleaving of operations is permitted, there are only \\ntwo possible outcomes:\\n  1. Execute all the operations of transaction T1 (in sequence) followed by all the \\noperations of transaction T2 (in sequence).\\n  2. Execute all the operations of transaction T2 (in sequence) followed by all the \\noperations of transaction T1 (in sequence).\\nThese two schedules—called serial schedules—are shown in Figures 20.5(a) and (b), \\nrespectively. If interleaving of operations is allowed, there will be many possible \\norders in which the system can execute the individual operations of the trans-\\nactions. Two possible schedules are shown in Figure 20.5(c). The concept of \\n serializability of schedules  is used to identify which schedules are correct when \\ntransaction executions have interleaving of their operations in the schedules. This \\nsection defines serializability and discusses how it may be used in practice.\\n20.5.1 Serial, Nonserial, and Conflict-Serializable Schedules\\nSchedules A and B in Figures 20.5(a) and (b) are called serial because the operations \\nof each transaction are executed consecutively, without any interleaved operations \\nfrom the other transaction. In a serial schedule, entire transactions are performed \\nin serial order: T\\n1 and then T2 in Figure 20.5(a), and T2 and then T1 in Figure\\xa020.5(b). \\nSchedules C and D in Figure 20.5(c) are called nonserial because each sequence \\ninterleaves operations from the two transactions.\\nFormally, a schedule S is serial if, for every transaction T participating in the sched-\\nule, all the operations of T are executed consecutively in the schedule; otherwise, the \\nschedule is called nonserial. Therefore, in a serial schedule, only one transaction at a \\ntime is active—the commit (or abort) of the active transaction initiates execution of \\nthe next transaction. No interleaving occurs in a serial schedule. One reasonable \\nassumption we can make, if we consider the transactions to be independent, is that \\nevery serial schedule is considered correct. We can assume this because every transac-\\ntion is assumed to be correct if executed on its own (according to the consistency \\npreservation property of Section 20.3). Hence, it does not matter which transaction is \\nexecuted first. As long as every transaction is executed from beginning to end in \\nisolation from the operations of other transactions, we get a correct end result.\\nThe problem with serial schedules is that they limit concurrency by prohibiting \\ninterleaving of operations. In a serial schedule, if a transaction waits for an I/O'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 777, 'page_label': '778'}, page_content='764 Chapter 20 Introduction to Transaction Processing Concepts and Theory\\noperation to complete, we cannot switch the CPU processor to another transaction, \\nthus wasting valuable CPU processing time. Additionally, if some transaction T is \\nlong, the other transactions must wait for T to complete all its operations before \\nstarting. Hence, serial schedules are unacceptable in practice. However, if we can \\ndetermine which other schedules are equivalent to a serial schedule, we can allow \\nthese schedules to occur.\\nTo illustrate our discussion, consider the schedules in Figure 20.5, and assume that \\nthe initial values of database items are X = 90 and Y = 90 and that N = 3 and M = 2. \\nAfter executing transactions T1 and T2, we would expect the database values to be \\nX = 89 and Y = 93, according to the meaning of the transactions. Sure enough, exe-\\ncuting either of the serial schedules A or B gives the correct results. Now consider \\n(a)\\nSchedule A Schedule B\\nread_item(X );\\nX := X – N;\\nwrite_item(X );\\nread_item(Y );\\nread_item(X );\\nX := X + M;\\nwrite_item(X );\\nTime\\nY := Y + N;\\nwrite_item(Y );\\n (b)\\nread_item(X );\\nX := X + M;\\nwrite_item(X );\\nTime read_item(X );\\nX := X – N;\\nwrite_item(X );\\nread_item(Y );\\nY := Y + N;\\nwrite_item(Y );\\n(c) T1 T2\\nSchedule C Schedule D\\nread_item(X );\\nX := X – N;\\nwrite_item(X );\\nread_item(Y );\\nread_item(X );\\nX := X + M;\\nwrite_item(X );\\nTime\\nY := Y + N;\\nwrite_item(Y );\\nread_item(X );\\nX := X + M;\\nwrite_item(X );\\nread_item(X );\\nX := X – N;\\nwrite_item(X );\\nread_item(Y );\\nY := Y + N;\\nwrite_item(Y );\\nT1 T2\\nT1 T2 T1 T2\\nTime\\nFigure 20.5 \\nExamples of serial and nonserial schedules involving transactions T1 and T2. (a) Serial schedule A: T1 followed by \\nT2. (b) Serial schedule B: T2 followed by T1. (c) Two nonserial schedules C and D with interleaving of operations.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 778, 'page_label': '779'}, page_content='20.5 Characterizing Schedules Based on Serializability  765\\nthe nonserial schedules C and D. Schedule C (which is the same as Figure 20.3(a)) \\ngives the results X = 92 and Y = 93, in which the X value is erroneous, whereas \\nschedule D gives the correct results.\\nSchedule C gives an erroneous result because of the lost update problem discussed \\nin Section 20.1.3; transaction T2 reads the value of X before it is changed by transac-\\ntion T1, so only the effect of T2 on X is reflected in the database. The effect of T1 on \\nX is lost, overwritten by T2, leading to the incorrect result for item X. However, \\nsome nonserial schedules give the correct expected result, such as schedule D. We \\nwould like to determine which of the nonserial schedules always give a correct \\nresult and which may give erroneous results. The concept used to characterize \\nschedules in this manner is that of serializability of a schedule.\\nThe definition of serializable schedule  is as follows: A schedule S of n transactions \\nis serializable  if it is equivalent to some serial schedule  of the same n transactions. \\nWe will define the concept of equivalence of schedules  shortly. Notice that there \\nare n! possible serial schedules of n transactions and many more possible non-\\nserial schedules. We can form two disjoint groups of the nonserial schedules—\\nthose that are equivalent to one (or more) of the serial schedules and hence are \\nserializable, and those that are not equivalent to any serial schedule and hence are \\nnot serializable.\\nSaying that a nonserial schedule S is serializable is equivalent to saying that it is cor-\\nrect, because it is equivalent to a serial schedule, which is considered correct. The \\nremaining question is: When are two schedules considered equivalent?\\nThere are several ways to define schedule equivalence. The simplest but least sat-\\nisfactory definition involves comparing the effects of the schedules on the data-\\nbase. Two schedules are called result equivalent  if they produce the same final \\nstate of the database. However, two different schedules may accidentally produce \\nthe same final state. For example, in Figure 20.6, schedules S\\n1 and S2 will produce \\nthe same final database state if they execute on a database with an initial value of \\nX = 100; however, for other initial values of X, the schedules are not result equiva-\\nlent. Additionally, these schedules execute different transactions, so they defi-\\nnitely should not be considered equivalent. Hence, result equivalence alone \\ncannot be used to define equivalence of schedules. The safest and most general \\napproach to defining schedule equivalence is to focus only on the read_item and \\nwrite_item operations of the transactions, and not make any assumptions about \\nthe other internal operations included in the transactions. For two schedules to \\nbe equivalent, the operations applied to each data item affected by the schedules \\nshould be applied to that item in both schedules in the same order . Two defini-\\ntions of equivalence of schedules are generally used: conflict equivalence  and view \\nequivalence. We discuss conflict equivalence next, which is the more commonly \\nused definition.\\nConflict Equivalence of Two Schedules. Two schedules are said to be conflict \\nequivalent if the relative order of any two conflicting operations is the same in both \\nschedules. Recall from Section 20.4.1 that two operations in a schedule are said to'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 779, 'page_label': '780'}, page_content='766 Chapter 20 Introduction to Transaction Processing Concepts and Theory\\nconflict if they belong to different transactions, access the same database item, and \\neither both are write_item operations or one is a write_item and the other a read_item. \\nIf two conflicting operations are applied in different orders  in two schedules, the \\neffect can be different on the database or on the transactions in the schedule, and \\nhence the schedules are not conflict equivalent. For example, as we discussed in \\nSection 20.4.1, if a read and write operation occur in the order r\\n1(X), w2(X) in \\nschedule S1, and in the reverse order w2(X), r1(X) in schedule S2, the value read by \\nr1(X) can be different in the two schedules. Similarly, if two write operations occur \\nin the order w1(X), w2(X) in S1, and in the reverse order w2(X), w1(X) in S2, the next \\nr(X) operation in the two schedules will read potentially different values; or if these \\nare the last operations writing item X in the schedules, the final value of item X in \\nthe database will be different.\\nSerializable Schedules. Using the notion of conflict equivalence, we define a \\nschedule S to be serializable12 if it is (conflict) equivalent to some serial schedule S′. \\nIn such a case, we can reorder the nonconflicting operations in S until we form the \\nequivalent serial schedule S′. According to this definition, schedule D in Fig-\\nure\\xa020.5(c) is equivalent to the serial schedule A in Figure 20.5(a). In both schedules, \\nthe read_item(X) of T2 reads the value of X written by T1, whereas the other read_item \\noperations read the database values from the initial database state. Additionally, T1 \\nis the last transaction to write Y, and T2 is the last transaction to write X in both \\nschedules. Because A is a serial schedule and schedule D is equivalent to A, D is a \\nserializable schedule. Notice that the operations r\\n1(Y) and w1(Y) of schedule D do \\nnot conflict with the operations r2(X) and w2(X), since they access different data \\nitems. Therefore, we can move r1(Y), w1(Y) before r2(X), w2(X), leading to the \\nequivalent serial schedule T1, T2.\\nSchedule C in Figure 20.5(c) is not equivalent to either of the two possible serial \\nschedules A and B, and hence is not serializable. Trying to reorder the operations of \\nschedule C to find an equivalent serial schedule fails because r2(X) and w1(X) con-\\nflict, which means that we cannot move r2(X) down to get the equivalent serial \\nschedule T1, T2. Similarly, because w1(X) and w2(X) conflict, we cannot move w1(X) \\ndown to get the equivalent serial schedule T2, T1.\\nAnother, more complex definition of equivalence—called view equivalence, which \\nleads to the concept of view serializability—is discussed in Section 20.5.4.\\nS1\\nread_item(X );\\nX := X + 10;\\nwrite_item(X );\\nS2\\nread_item(X );\\nX := X * 1.1;\\nwrite_item (X );\\nFigure 20.6 \\nTwo schedules that are result \\nequivalent for the initial value \\nof X = 100 but are not result \\nequivalent in general.\\n12We will use serializable to mean conflict serializable. Another definition of serializable used in \\n practice (see Section 20.6) is to have repeatable reads, no dirty reads, and no phantom records \\n(see Section 22.7 .1 for a discussion on phantoms).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 780, 'page_label': '781'}, page_content='20.5 Characterizing Schedules Based on Serializability  767\\n20.5.2 Testing for Serializability of a Schedule\\nThere is a simple algorithm for determining whether a particular schedule is (con-\\nflict) serializable or not. Most concurrency control methods do not actually test for \\nserializability. Rather protocols, or rules, are developed that guarantee that any \\nschedule that follows these rules will be serializable. Some methods guarantee seri-\\nalizability in most cases, but do not guarantee it absolutely, in order to reduce the \\noverhead of concurrency control. We discuss the algorithm for testing conflict seri-\\nalizability of schedules here to gain a better understanding of these concurrency \\ncontrol protocols, which are discussed in Chapter 21.\\nAlgorithm 20.1 can be used to test a schedule for conflict serializability. The algo-\\nrithm looks at only the \\nread_item and write_item operations in a schedule to con-\\nstruct a precedence graph  (or serialization graph ), which is a directed graph   \\nG = (N, E) that consists of a set of nodes N = {T1, T2, … , Tn } and a set of directed \\nedges E = {e1, e2, … , em }. There is one node in the graph for each transaction Ti in \\nthe schedule. Each edge ei in the graph is of the form (Tj → Tk ), 1 ≤ j ≤ n, 1 ≤ k ≤ n, \\nwhere Tj is the starting node of ei and Tk is the ending node of e i. Such an edge \\nfrom node Tj to node Tk is created by the algorithm if a pair of conflicting operations \\nexist in Tj and Tk and the conflicting operation in Tj appears in the schedule before \\nthe conflicting operation in Tk.\\nAlgorithm 20.1. Testing Conflict Serializability of a Schedule S\\n  1. For each transaction Ti participating in schedule S, create a node labeled \\nTi in the precedence graph.\\n  2. For each case in S where Tj executes a read_item(X) after Ti executes a \\nwrite_item (X), create an edge ( Ti → Tj) in the precedence graph.\\n  3. For each case in S where Tj executes a write_item (X) after Ti executes a \\nread_item(X), create an edge ( Ti → Tj) in the precedence graph.\\n  4. For each case in S where Tj executes a write_item(X) after Ti executes a \\nwrite_item(X), create an edge ( Ti → Tj) in the precedence graph.\\n  5. The schedule S is serializable if and only if the precedence graph has no \\ncycles.\\nThe precedence graph is constructed as described in Algorithm 20.1. If there is a \\ncycle in the precedence graph, schedule S is not (conflict) serializable; if there is no \\ncycle, S is serializable. A cycle in a directed graph is a sequence of edges C = ((Tj → Tk), \\n(Tk → Tp), … , ( Ti → Tj)) with the property that the starting node of each edge—\\nexcept the first edge—is the same as the ending node of the previous edge, and the \\nstarting node of the first edge is the same as the ending node of the last edge (the \\nsequence starts and ends at the same node).\\nIn the precedence graph, an edge from T\\ni to Tj means that transaction Ti must come \\nbefore transaction Tj in any serial schedule that is equivalent to S, because two con-\\nflicting operations appear in the schedule in that order. If there is no cycle in the pre-\\ncedence graph, we can create an equivalent serial schedule S′ that is equivalent to S, \\nby ordering the transactions that participate in S as follows: Whenever an edge exists'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 781, 'page_label': '782'}, page_content='768 Chapter 20 Introduction to Transaction Processing Concepts and Theory\\nin the precedence graph from Ti to Tj, Ti must appear before Tj in the equivalent serial \\nschedule S′.13 Notice that the edges (Ti → Tj) in a precedence graph can optionally be \\nlabeled by the name(s) of the data item(s) that led to creating the edge. Figure 20.7 \\nshows such labels on the edges. When checking for a cycle, the labels are not relevant.\\nIn general, several serial schedules can be equivalent to S if the precedence graph for \\nS has no cycle. However, if the precedence graph has a cycle, it is easy to show that \\nwe cannot create any equivalent serial schedule, so S is not serializable. The prece-\\ndence graphs created for schedules A to D, respectively, in Figure 20.5 appear in \\nFigures 20.7(a) to (d). The graph for schedule C has a cycle, so it is not serializable. \\nThe graph for schedule D has no cycle, so it is serializable, and the equivalent serial \\nschedule is T\\n1 followed by T2. The graphs for schedules A and B have no cycles, as \\nexpected, because the schedules are serial and hence serializable.\\nAnother example, in which three transactions participate, is shown in Figure 20.8. \\nFigure 20.8(a) shows the read_item and write_item operations in each transaction. \\nTwo schedules E and F for these transactions are shown in Figures 20.8(b) and (c), \\nrespectively, and the precedence graphs for schedules E and F are shown in Fig-\\nures\\xa020.8(d) and (e). Schedule E is not serializable because the corresponding prece-\\ndence graph has cycles. Schedule F is serializable, and the serial schedule equivalent \\nto F is shown in Figure 20.8(e). Although only one equivalent serial schedule exists \\nfor F, in general there may be more than one equivalent serial schedule for a serial-\\nizable schedule. Figure 20.8(f) shows a precedence graph representing a schedule \\n13This process of ordering the nodes of an acrylic graph is known as topological sorting.\\nT1(a)\\n(c)\\n(b)\\n(d)\\nT2\\nT1\\nX\\nX\\nX\\nX\\nT2\\nT1 T2\\nT1 T2\\nX\\nFigure 20.7 \\nConstructing the precedence graphs for schedules A to D from Figure 20.5 to test  \\nfor conflict serializability. (a) Precedence graph for serial schedule A. (b) Precedence  \\ngraph for serial schedule B. (c) Precedence graph for schedule C (not serializable).  \\n(d) Precedence graph for schedule D (serializable, equivalent to schedule A).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 782, 'page_label': '783'}, page_content='20.5 Characterizing Schedules Based on Serializability  769\\nTransaction T1\\nread_item(X );\\nwrite_item(X );\\nread_item(Y );\\nwrite_item(Y );\\nread_item(X );\\nwrite_item(X );\\nread_item(Y );\\nwrite_item(Y );\\nTransaction T3\\nread_item(Y );\\nread_item(Z );\\nwrite_item(Y );\\nwrite_item(Z );\\nread_item(Y );\\nread_item(Z );\\nwrite_item(Y);\\nwrite_item(Z );\\nTransaction T2\\nread_item(Z );\\nread_item(Y );\\nwrite_item(Y );\\nread_item(X );\\nwrite_item(X );\\nread_item(Z );\\nread_item(Y );\\nwrite_item(Y );\\nread_item(X );\\nwrite_item(X );\\n(b)\\n(a)\\nSchedule E\\nTime\\nread_item(X );\\nwrite_item(X );\\nread_item(Y );\\nwrite_item(Y );\\nread_item(Y );\\nread_item(Z );\\nwrite_item(Y );\\nwrite_item(Z );\\nread_item(Z );\\nread_item(Y );\\nwrite_item(Y );\\nread_item(X );\\nwrite_item(X );\\n(c)\\nSchedule F\\nTime\\nTransaction T1 Transaction T2 Transaction T3\\nTransaction T1 Transaction T2 Transaction T3\\nFigure 20.8 \\nAnother example of serializability testing. (a) The read and write operations of three  \\ntransactions T\\n1, T2, and T3. (b) Schedule E. (c) Schedule F.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 783, 'page_label': '784'}, page_content='770 Chapter 20 Introduction to Transaction Processing Concepts and Theory\\nthat has two equivalent serial schedules. To find an equivalent serial schedule, start \\nwith a node that does not have any incoming edges, and then make sure that the \\nnode order for every edge is not violated.\\n20.5.3 How Serializability Is Used for Concurrency Control\\nAs we discussed earlier, saying that a schedule S is (conflict) serializable—that is, S \\nis (conflict) equivalent to a serial schedule—is tantamount to saying that S is cor-\\nrect. Being serializable is distinct from being serial, however. A serial schedule rep-\\nresents inefficient processing because no interleaving of operations from different \\ntransactions is permitted. This can lead to low CPU utilization while a transaction \\nwaits for disk I/O, or for a long transaction to delay other transactions, thus slowing \\ndown transaction processing considerably. A serializable schedule gives the benefits \\nof concurrent execution without giving up any correctness. In practice, it is difficult \\nto test for the serializability of a schedule. The interleaving of operations from con-\\ncurrent transactions—which are usually executed as processes by the operating \\nsystem—is typically determined by the operating system scheduler, which allocates \\n(d)\\nX\\nY\\nY Y, Z\\nT1\\nEquivalent serial schedules\\nNone\\nReason\\nCycle X(T\\n1        T2),Y(T2        T1)\\nCycle X(T1        T2),YZ (T2       T3),Y(T3        T1)\\n(e) X,Y\\nY Y, Z\\nEquivalent serial schedules\\n(f) Equivalent serial schedules\\nT2\\nT3\\nT1 T2\\nT3\\nT1 T2\\nT3\\nT2T3 T1\\nT2T3 T1\\nT1T3 T2\\nFigure 20.8 (continued) \\nAnother example of serializability testing. (d) Precedence graph for schedule E. (e) Precedence graph for  \\nschedule F. (f) Precedence graph with two equivalent serial schedules.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 784, 'page_label': '785'}, page_content='20.5 Characterizing Schedules Based on Serializability  771\\nresources to all processes. Factors such as system load, time of transaction submis-\\nsion, and priorities of processes contribute to the ordering of operations in a sched-\\nule. Hence, it is difficult to determine how the operations of a schedule will be \\ninterleaved beforehand to ensure serializability. \\nIf transactions are executed at will and then the resulting schedule is tested for seri-\\nalizability, we must cancel the effect of the schedule if it turns out not to be serializ-\\nable. This is a serious problem that makes this approach impractical. The approach \\ntaken in most commercial DBMSs is to design protocols (sets of rules) that—if \\nfollowed by every individual transaction or if enforced by a DBMS concurrency \\ncontrol subsystem—will ensure serializability of all schedules in which the transac-\\ntions participate. Some protocols may allow nonserializable schedules in rare cases \\nto reduce the overhead of the concurrency control method (see Section 20.6).\\nAnother problem is that transactions are submitted continuously to the system, so \\nit is difficult to determine when a schedule begins and when it ends. Serializability \\ntheory can be adapted to deal with this problem by considering only the committed \\nprojection of a schedule S. Recall from Section 20.4.1 that the committed projection \\nC(S) of a schedule S includes only the operations in S that belong to committed \\ntransactions. We can theoretically define a schedule S to be serializable if its com-\\nmitted projection C(S) is equivalent to some serial schedule, since only committed \\ntransactions are guaranteed by the DBMS.\\nIn Chapter 21, we discuss a number of different concurrency control protocols \\nthat guarantee serializability. The most common technique, called two-phase \\nlocking, is based on locking data items to prevent concurrent transactions from \\ninterfering with one another, and enforcing an additional condition that guaran-\\ntees serializability. This is used in some commercial DBMSs. We will also discuss \\na protocol based on the concept of snapshot isolation  that ensures serializability \\nin most but not all cases; this is used in some commercial DBMSs because it has \\nless overhead than the two-phase locking protocol. Other protocols have been \\nproposed\\n14; these include timestamp ordering , where each transaction is assigned \\na unique timestamp and the protocol ensures that any conflicting operations are \\nexecuted in the order of the transaction timestamps; multiversion protocols , \\nwhich are based on maintaining multiple versions of data items; and optimistic  \\n(also called certification  or validation ) protocols , which check for possible serial-\\nizability violations after the transactions terminate but before they are permitted \\nto commit.\\n20.5.4 View Equivalence and View Serializability\\nIn Section 20.5.1, we defined the concepts of conflict equivalence of schedules and \\nconflict serializability. Another less restrictive definition of equivalence of sched-\\nules is called view equivalence . This leads to another definition of serializability \\n14These other protocols have not been incorporated much into commercial systems; most relational \\nDBMSs use some variation of two-phase locking or snapshot isolation.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 785, 'page_label': '786'}, page_content='772 Chapter 20 Introduction to Transaction Processing Concepts and Theory\\ncalled view serializability. Two schedules S and S′ are said to be view equivalent if \\nthe following three conditions hold:\\n  1. The same set of transactions participates in S and S′, and S and S′ include the \\nsame operations of those transactions.\\n  2. For any operation ri(X) of Ti in S, if the value of X read by the operation has \\nbeen written by an operation wj(X) of Tj (or if it is the original value of X \\nbefore the schedule started), the same condition must hold for the value of X \\nread by operation ri(X) of Ti in S′.\\n  3. If the operation wk(Y) of Tk is the last operation to write item Y in S, then \\nwk(Y) of Tk must also be the last operation to write item Y in S′.\\nThe idea behind view equivalence is that, as long as each read operation of a trans-\\naction reads the result of the same write operation in both schedules, the write \\noperations of each transaction must produce the same results. The read operations \\nare hence said to see the same view in both schedules. Condition 3 ensures that the \\nfinal write operation on each data item is the same in both schedules, so the data-\\nbase state should be the same at the end of both schedules. A schedule S is said to be \\nview serializable if it is view equivalent to a serial schedule.\\nThe definitions of conflict serializability and view serializability are similar if a \\ncondition known as the constrained write assumption  (or no blind writes) holds \\non all transactions in the schedule. This condition states that any write operation \\nw\\ni(X) in Ti is preceded by a ri(X) in Ti and that the value written by wi(X) in Ti \\ndepends only on the value of X read by ri(X). This assumes that computation of \\nthe new value of X is a function f(X) based on the old value of X read from the \\ndatabase. A blind write is a write operation in a transaction T on an item X that is \\nnot dependent on the old value of X, so it is not preceded by a read of X in the \\ntransaction T.\\nThe definition of view serializability is less restrictive than that of conflict serializ-\\nability under the unconstrained write assumption, where the value written by an \\noperation wi(X) in Ti can be independent of its old value. This is possible when \\nblind writes are allowed, and it is illustrated by the following schedule Sg of three \\ntransactions T1: r1(X); w1(X); T2: w2(X); and T3: w3(X):\\nSg: r1(X); w2(X); w1(X); w3(X); c1; c2; c3;\\nIn Sg the operations w2(X) and w3(X) are blind writes, since T2 and T3 do not read \\nthe value of X. The schedule Sg is view serializable, since it is view equivalent to the \\nserial schedule T1, T2, T3. However, Sg is not conflict serializable, since it is not con-\\nflict equivalent to any serial schedule (as an exercise, the reader should construct \\nthe serializability graph for S\\ng and check for cycles). It has been shown that any \\nconflict-serializable schedule is also view serializable but not vice versa, as illus-\\ntrated by the preceding example. There is an algorithm to test whether a schedule S \\nis view serializable or not. However, the problem of testing for view serializability \\nhas been shown to be NP-hard, meaning that finding an efficient polynomial time \\nalgorithm for this problem is highly unlikely.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 786, 'page_label': '787'}, page_content='20.6 Transaction Support in SQL  773\\n20.5.5 Other Types of Equivalence of Schedules\\nSerializability of schedules is sometimes considered to be too restrictive as a \\ncondition for ensuring the correctness of concurrent executions. Some applica-\\ntions can produce schedules that are correct by satisfying conditions less strin-\\ngent than either conflict serializability or view serializability. An example is the \\ntype of transactions known as debit-credit transactions —for example, those \\nthat apply deposits and withdrawals to a data item whose value is the current \\nbalance of a bank account. The semantics of debit-credit operations is that they \\nupdate the value of a data item X by either subtracting from or adding to the \\nvalue of the data item. Because addition and subtraction operations are com-\\nmutative—that is, they can be applied in any order—it is possible to produce \\ncorrect schedules that are not serializable. For example, consider the following \\ntransactions, each of which may be used to transfer an amount of money \\nbetween two bank accounts:\\nT\\n1: r1(X); X :{equal} X − 10; w1(X); r1(Y); Y :{equal} Y + 10; w1(Y);\\nT2: r2(Y); Y :{equal} Y − 20; w2(Y); r2(X); X :{equal} X + 20; w2(X);\\nConsider the following nonserializable schedule Sh for the two transactions:\\nSh: r1(X); w1(X); r2(Y); w2(Y); r1(Y); w1(Y); r2(X); w2(X);\\nWith the additional knowledge, or semantics , that the operations between each \\nri(I) and wi(I) are commutative, we know that the order of executing the \\nsequences consisting of (read, update, write) is not important as long as each \\n(read, update, write) sequence by a particular transaction T\\ni on a particular item \\nI is not interrupted by conflicting operations. Hence, the schedule Sh is consid-\\nered to be correct even though it is not serializable. Researchers have been work-\\ning on extending concurrency control theory to deal with cases where \\nserializability is considered to be too restrictive as a condition for correctness of \\nschedules. Also, in certain domains of applications, such as computer-aided \\ndesign (CAD) of complex systems like aircraft, design transactions last over a \\nlong time period. In such applications, more relaxed schemes of concurrency \\ncontrol have been proposed to maintain consistency of the database, such as \\neventual consistency . We shall discuss eventual consistency in the context of dis-\\ntributed databases in Chapter 23.\\n20.6 Transaction Support in SQL\\nIn this section, we give a brief introduction to transaction support in SQL. There \\nare many more details, and the newer standards have more commands for trans-\\naction processing. The basic definition of an SQL transaction is similar to our \\nalready defined concept of a transaction. That is, it is a logical unit of work and is \\nguaranteed to be atomic. A single SQL statement is always considered to be \\natomic—either it completes execution without an error or it fails and leaves the \\ndatabase unchanged.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 787, 'page_label': '788'}, page_content='774 Chapter 20 Introduction to Transaction Processing Concepts and Theory\\nWith SQL, there is no explicit Begin_Transaction statement. Transaction initiation is \\ndone implicitly when particular SQL statements are encountered. However, every \\ntransaction must have an explicit end statement, which is either a \\nCOMMIT or a \\nROLLBACK. Every transaction has certain characteristics attributed to it. These \\ncharacteristics are specified by a SET TRANSACTION statement in SQL. The charac-\\nteristics are the access mode, the diagnostic area size, and the isolation level.\\nThe access mode  can be specified as READ ONLY  or READ WRITE . The default is \\nREAD WRITE , unless the isolation level of READ UNCOMMITTED  is specified (see \\nbelow), in which case READ ONLY is assumed. A mode of READ WRITE allows select, \\nupdate, insert, delete, and create commands to be executed. A mode of READ ONLY, \\nas the name implies, is simply for data retrieval.\\nThe diagnostic area size option, DIAGNOSTIC SIZE n, specifies an integer value n, \\nwhich indicates the number of conditions that can be held simultaneously in the \\ndiagnostic area. These conditions supply feedback information (errors or excep-\\ntions) to the user or program on the n most recently executed SQL statement.\\nThe isolation level option is specified using the statement \\nISOLATION LEVEL <isolation>, \\nwhere the value for < isolation> can be READ UNCOMMITTED , READ COMMITTED , \\nREPEATABLE READ, or SERIALIZABLE.15 The default isolation level is SERIALIZABLE, \\nalthough some systems use READ COMMITTED as their default. The use of the term \\nSERIALIZABLE here is based on not allowing violations that cause dirty read, unre-\\npeatable read, and phantoms,16 and it is thus not identical to the way serializability \\nwas defined earlier in Section 20.5. If a transaction executes at a lower isolation level \\nthan SERIALIZABLE, then one or more of the following three violations may occur:\\n  1. Dirty read. A transaction T1 may read the update of a transaction T2, which \\nhas not yet committed. If T2 fails and is aborted, then T1 would have read a \\nvalue that does not exist and is incorrect.\\n  2. Nonrepeatable read. A transaction T1 may read a given value from a table. \\nIf another transaction T2 later updates that value and T1 reads that value \\nagain, T1 will see a different value.\\n  3. Phantoms. A transaction T1 may read a set of rows from a table, perhaps \\nbased on some condition specified in the SQL WHERE-clause. Now suppose \\nthat a transaction T2 inserts a new row r that also satisfies the WHERE-clause \\ncondition used in T1, into the table used by T1. The record r is called a \\n phantom record because it was not there when T1 starts but is there when \\nT1 ends. T1 may or may not see the phantom, a row that previously did not \\nexist. If the equivalent serial order is T1 followed by T2, then the record r \\nshould not be seen; but if it is T2 followed by T1,then the phantom record \\nshould be in the result given to T1. If the system cannot ensure the correct \\nbehavior, then it does not deal with the phantom record problem.\\n15These are similar to the isolation levels discussed briefly at the end of Section 20.3.\\n16The dirty read and unrepeatable read problems were discussed in Section 20.1.3. Phantoms are dis-\\ncussed in Section 22.7 .1.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 788, 'page_label': '789'}, page_content=\"20.6 Transaction Support in SQL  775\\nTable 20.1 summarizes the possible violations for the different isolation levels. An \\nentry of Yes indicates that a violation is possible and an entry of No indicates that it \\nis not possible. READ UNCOMMITTED is the most forgiving, and SERIALIZABLE is the \\nmost restrictive in that it avoids all three of the problems mentioned above.\\nA sample SQL transaction might look like the following:\\nEXEC SQL WHENEVER SQLERROR GOTO UNDO;\\nEXEC SQL SET TRANSACTION\\n READ WRITE\\n DIAGNOSTIC SIZE 5\\n ISOLATION LEVEL SERIALIZABLE;\\nEXEC SQL INSERT INTO EMPLOYEE (Fname, Lname, Ssn, Dno, Salary)\\n VALUES ('Robert', 'Smith', '991004321', 2, 35000);\\nEXEC SQL UPDATE EMPLOYEE\\n SET Salary = Salary * 1.1 WHERE Dno = 2;\\nEXEC SQL COMMIT;\\nGOTO THE_END;\\nUNDO: EXEC SQL ROLLBACK;\\nTHE_END: ... ;\\nThe above transaction consists of first inserting a new row in the EMPLOYEE table \\nand then updating the salary of all employees who work in department 2. If an error \\noccurs on any of the SQL statements, the entire transaction is rolled back. This \\nimplies that any updated salary (by this transaction) would be restored to its previ-\\nous value and that the newly inserted row would be removed.\\nAs we have seen, SQL provides a number of transaction-oriented features. The \\nDBA or database programmers can take advantage of these options to try improv-\\ning transaction performance by relaxing serializability if that is acceptable for \\ntheir applications.\\nSnapshot Isolation.  Another isolation level, known as snapshot isolation, is \\nused in some commercial DBMSs, and some concurrency control protocols exist \\nthat are based on this concept. The basic definition of snapshot isolation is that a \\ntransaction sees the data items that it reads based on the committed values of the \\nitems in the database snapshot (or database state) when the transaction starts. Snap-\\nshot isolation will ensure that the phantom record problem does not occur, since \\nTable 20.1 Possible Violations Based on Isolation Levels as Deﬁned in SQL\\nType of Violation\\nIsolation Level Dirty Read Nonrepeatable Read Phantom\\nREAD UNCOMMITTED Ye s Ye s Ye s\\nREAD COMMITTED No Yes Yes\\nREPEATABLE READ No No Yes\\nSERIALIZABLE No No No\"),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 789, 'page_label': '790'}, page_content='776 Chapter 20 Introduction to Transaction Processing Concepts and Theory\\nthe database transaction, or in some cases the database statement, will only see the \\nrecords that were committed in the database at the time the transaction starts. Any \\ninsertions, deletions, or updates that occur after the transaction starts will not be \\nseen by the transaction. We will discuss a concurrency control protocol based on \\nthis concept in Chapter 21.\\n20.7 Summary\\nIn this chapter, we discussed DBMS concepts for transaction processing. We intro-\\nduced the concept of a database transaction and the operations relevant to transac-\\ntion processing in Section 20.1. We compared single-user systems to multiuser \\nsystems and then presented examples of how uncontrolled execution of concurrent \\ntransactions in a multiuser system can lead to incorrect results and database values \\nin Section 20.1.1. We also discussed the various types of failures that may occur \\nduring transaction execution in Section 20.1.4.\\nNext, in Section 20.2, we introduced the typical states that a transaction passes \\nthrough during execution, and discussed several concepts that are used in recovery \\nand concurrency control methods. The system log (Section 20.2.2) keeps track of \\ndatabase accesses, and the system uses this information to recover from failures. A \\ntransaction can succeed and reach its commit point, or it can fail and has to be \\nrolled back. A committed transaction (Section 20.2.3) has its changes permanently \\nrecorded in the database. In Section 20.3, we presented an overview of the desirable \\nproperties of transactions—atomicity, consistency preservation, isolation, and \\ndurability—which are often referred to as the ACID properties.\\nThen we defined a schedule (or history) as an execution sequence of the opera-\\ntions of several transactions with interleaving in Section 20.4.1. We character-\\nized schedules in terms of their recoverability in Section 20.4.2. Recoverable \\nschedules ensure that, once a transaction commits, it never needs to be undone. \\nCascadeless schedules add an additional condition to ensure that no aborted \\ntransaction requires the cascading abort of other transactions. Strict schedules \\nprovide an even stronger condition that allows a simple recovery scheme con-\\nsisting of restoring the old values of items that have been changed by an aborted \\ntransaction.\\nThen in Section 20.5 we defined the equivalence of schedules and saw that a serial-\\nizable schedule is equivalent to some serial schedule. We defined the concepts of \\nconflict equivalence and view equivalence. A serializable schedule is considered \\ncorrect. We presented an algorithm for testing the (conflict) serializability of a \\nschedule in Section 20.5.2. We discussed why testing for serializability is impracti-\\ncal in a real system, although it can be used to define and verify concurrency con-\\ntrol protocols in Section 20.5.3, and we briefly mentioned less restrictive definitions \\nof schedule equivalence in Sections 20.5.4 and 20.5.5. Finally, in Section 20.6, we \\ngave a brief overview of how transaction concepts are used in practice within SQL, \\nand we introduced the concept of snapshot isolation, which is used in several com-\\nmercial DBMSs.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 790, 'page_label': '791'}, page_content='Exercises 777\\nReview Questions\\n 20.1. What is meant by the concurrent execution of database transactions in a \\nmultiuser system? Discuss why concurrency control is needed, and give \\ninformal examples.\\n 20.2. Discuss the different types of failures. What is meant by catastrophic failure?\\n 20.3. Discuss the actions taken by the read_item and write_item operations on a \\ndatabase.\\n 20.4. Draw a state diagram and discuss the typical states that a transaction goes \\nthrough during execution.\\n 20.5. What is the system log used for? What are the typical kinds of records in a \\nsystem log? What are transaction commit points, and why are they \\nimportant?\\n 20.6. Discuss the atomicity, durability, isolation, and consistency preservation \\nproperties of a database transaction.\\n 20.7. What is a schedule (history)? Define the concepts of recoverable, cascade-\\nless, and strict schedules, and compare them in terms of their recoverability.\\n 20.8. Discuss the different measures of transaction equivalence. What is the dif-\\nference between conflict equivalence and view equivalence?\\n 20.9. What is a serial schedule? What is a serializable schedule? Why is a serial \\nschedule considered correct? Why is a serializable schedule considered \\ncorrect?\\n 20.10. What is the difference between the constrained write and the unconstrained \\nwrite assumptions? Which is more realistic?\\n 20.11. Discuss how serializability is used to enforce concurrency control in a data-\\nbase system. Why is serializability sometimes considered too restrictive as a \\nmeasure of correctness for schedules?\\n 20.12. Describe the four levels of isolation in SQL. Also discuss the concept of \\nsnapshot isolation and its effect on the phantom record problem.\\n 20.13. Define the violations caused by each of the following: dirty read, nonrepeat-\\nable read, and phantoms.\\nExercises\\n 20.14. Change transaction T2 in Figure 20.2(b) to read\\nread_item(X);\\nX := X + M;\\nif X > 90 then exit\\nelse write_item(X);'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 791, 'page_label': '792'}, page_content='778 Chapter 20 Introduction to Transaction Processing Concepts and Theory\\n  Discuss the final result of the different schedules in Figures 20.3(a) and (b), \\nwhere M = 2 and N = 2, with respect to the following questions: Does adding \\nthe above condition change the final outcome? Does the outcome obey the \\nimplied consistency rule (that the capacity of X is 90)?\\n 20.15. Repeat Exercise 20.14, adding a check in T1 so that Y does not exceed 90.\\n 20.16. Add the operation commit at the end of each of the transactions T1 and T2 \\nin Figure 20.2, and then list all possible schedules for the modified transac-\\ntions. Determine which of the schedules are recoverable, which are cascade-\\nless, and which are strict.\\n 20.17. List all possible schedules for transactions T1 and T2 in Figure 20.2, and \\ndetermine which are conflict serializable (correct) and which are not.\\n 20.18. How many serial schedules exist for the three transactions in Figure 20.8(a)? \\nWhat are they? What is the total number of possible schedules?\\n 20.19. Write a program to create all possible schedules for the three transactions \\nin Figure 20.8(a), and to determine which of those schedules are conflict \\nserializable and which are not. For each conflict-serializable schedule, \\nyour program should print the schedule and list all equivalent serial \\nschedules.\\n 20.20. Why is an explicit transaction end statement needed in SQL but not an \\nexplicit begin statement?\\n 20.21. Describe situations where each of the different isolation levels would be use-\\nful for transaction processing.\\n 20.22. Which of the following schedules is (conflict) serializable? For each serializ-\\nable schedule, determine the equivalent serial schedules.\\na. r1(X); r3(X); w1(X); r2(X); w3(X);\\nb. r1(X); r3(X); w3(X); w1(X); r2(X);\\nc. r3(X); r2(X); w3(X); r1(X); w1(X);\\nd. r3(X); r2(X); r1(X); w3(X); w1(X);\\n 20.23. Consider the three transactions T1, T2, and T3, and the schedules S1 and S2 \\ngiven below. Draw the serializability (precedence) graphs for S1 and S2, and \\nstate whether each schedule is serializable or not. If a schedule is serializable, \\nwrite down the equivalent serial schedule(s).\\nT\\n1: r1 (X); r1 (Z); w1 (X);\\nT2: r2 (Z); r2 (Y); w2 (Z); w2 (Y);\\nT3: r3 (X); r3 (Y); w3 (Y);\\nS1: r1 (X); r2 (Z); r1 (Z); r3 (X); r3 (Y); w1 (X); w3 (Y); r2 (Y); w2 (Z); \\nw2 (Y);\\nS2: r1 (X); r2 (Z); r3 (X); r1 (Z); r2 (Y); r3 (Y); w1 (X); w2 (Z); w3 (Y); \\nw2 (Y);'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 792, 'page_label': '793'}, page_content='Selected Bibliography 779\\n 20.24. Consider schedules S3, S4, and S5 below. Determine whether each schedule is \\nstrict, cascadeless, recoverable, or nonrecoverable. (Determine the strictest \\nrecoverability condition that each schedule satisfies.)\\nS\\n3: r1 (X); r2 (Z); r1 (Z); r3 (X); r3 (Y); w1 (X); c1; w3 (Y); c3; r2 (Y);  \\nw2 (Z); w2 (Y); c2;\\nS4: r1 (X); r2 (Z); r1 (Z); r3 (X); r3 (Y); w1 (X); w3 (Y); r2 (Y); w2 (Z);  \\nw2 (Y); c1; c2; c3;\\nS5: r1 (X); r2 (Z); r3 (X); r1 (Z); r2 (Y); r3 (Y); w1 (X); c1; w2 (Z); w3 (Y); \\nw2 (Y); c3; c2;\\nSelected Bibliography\\nThe concept of serializability and related ideas to maintain consistency in a data-\\nbase were introduced in Gray et al. (1975). The concept of the database transaction \\nwas first discussed in Gray (1981). Gray won the coveted ACM Turing Award in \\n1998 for his work on database transactions and implementation of transactions in \\nrelational DBMSs. Bernstein, Hadzilacos, and Goodman (1988) focus on concur-\\nrency control and recovery techniques in both centralized and distributed database \\nsystems; it is an excellent reference. Papadimitriou (1986) offers a more theoretical \\nperspective. A large reference book of more than a thousand pages by Gray and \\nReuter (1993) offers a more practical perspective of transaction processing concepts \\nand techniques. Elmagarmid (1992) offers collections of research papers on trans-\\naction processing for advanced applications. Transaction support in SQL is \\ndescribed in Date and Darwen (1997). View serializability is defined in Yannakakis \\n(1984). Recoverability of schedules and reliability in databases is discussed in \\nHadzilacos (1983, 1988). Buffer replacement policies are discussed in Chou and \\nDeWitt (1985). Snapshot isolation is discussed in Ports and Grittner (2012).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 793, 'page_label': '794'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 794, 'page_label': '795'}, page_content='781\\n21\\nConcurrency Control  \\nTechniques\\nI\\nn this chapter, we discuss a number of concurrency \\ncontrol techniques that are used to ensure the nonin-\\nterference or isolation property of concurrently executing transactions. Most of \\nthese techniques ensure serializability of schedules—which we defined in Sec-\\ntion\\xa021.5—using concurrency control protocols (sets of rules) that guarantee serializ-\\nability. One important set of protocols—known as two-phase locking protocols — \\nemploys the technique of locking data items to prevent multiple transactions from \\naccessing the items concurrently; a number of locking protocols are described in \\nSections 21.1 and 21.3.2. Locking protocols are used in some commercial DBMSs, \\nbut they are considered to have high overhead. Another set of concurrency control \\nprotocols uses timestamps. A timestamp is a unique identifier for each transaction, \\ngenerated by the system. Timestamp values are generated in the same order as the \\ntransaction start times. Concurrency control protocols that use timestamp ordering \\nto ensure serializability are introduced in Section 21.2. In Section 21.3, we discuss \\nmultiversion concurrency control protocols that use multiple versions of a data \\nitem. One multiversion protocol extends timestamp order to multiversion time-\\nstamp ordering (Section 21.3.1), and another extends timestamp order to two-\\nphase locking (Section 21.3.2). In Section 21.4, we present a protocol based on the \\nconcept of validation or certification of a transaction after it executes its opera-\\ntions; these are sometimes called optimistic protocols, and they also assume that \\nmultiple versions of a data item can exist. In Section 21.4, we discuss a protocol that \\nis based on the concept of snapshot isolation, which can utilize techniques similar \\nto those proposed in validation-based and multiversion methods; these protocols \\nare used in a number of commercial DBMSs and in certain cases are considered to \\nhave lower overhead than locking-based protocols.\\nchapter 21'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 795, 'page_label': '796'}, page_content='782 Chapter 21 Concurrency Control Techniques\\nAnother factor that affects concurrency control is the granularity  of the data \\nitems—that is, what portion of the database a data item represents. An item can be \\nas small as a single attribute (field) value or as large as a disk block, or even a whole \\nfile or the entire database. We discuss granularity of items and a multiple granular-\\nity concurrency control protocol, which is an extension of two-phase locking, in \\nSection 21.5. In Section 21.6, we describe concurrency control issues that arise \\nwhen indexes are used to process transactions, and in Section 21.7 we discuss some \\nadditional concurrency control concepts. Section 21.8 summarizes the chapter.\\nIt is sufficient to read Sections 21.1, 21.5, 21.6, and 21.7, and possibly 21.3.2, if your \\nmain interest is an introduction to the concurrency control techniques that are \\nbased on locking.\\n21.1  Two-Phase Locking Techniques  \\nfor Concurrency Control\\nSome of the main techniques used to control concurrent execution of transactions \\nare based on the concept of locking data items. A lock is a variable associated with \\na data item that describes the status of the item with respect to possible operations \\nthat can be applied to it. Generally, there is one lock for each data item in the data-\\nbase. Locks are used as a means of synchronizing the access by concurrent transac-\\ntions to the database items. In Section 21.1.1, we discuss the nature and types of \\nlocks. Then, in Section 21.1.2, we present protocols that use locking to guarantee \\nserializability of transaction schedules. Finally, in Section 21.1.3, we describe two \\nproblems associated with the use of locks—deadlock and starvation—and show \\nhow these problems are handled in concurrency control protocols.\\n21.1.1 Types of Locks and System Lock Tables\\nSeveral types of locks are used in concurrency control. To introduce locking con-\\ncepts gradually, first we discuss binary locks, which are simple but are also too \\nrestrictive for database concurrency control purposes  and so are not used much. \\nThen we discuss shared/exclusive  locks—also known as read/write locks—which \\nprovide more general locking capabilities and are used in database locking schemes. \\nIn Section 21.3.2, we describe an additional type of lock called a certify lock, and we \\nshow how it can be used to improve performance of locking protocols.\\nBinary Locks. A binary lock can have two states or values: locked and unlocked \\n(or 1 and 0, for simplicity). A distinct lock is associated with each database item X. \\nIf the value of the lock on X is 1, item X cannot be accessed by a database operation \\nthat requests the item. If the value of the lock on X is 0, the item can be accessed \\nwhen requested, and the lock value is changed to 1. We refer to the current value \\n(or state) of the lock associated with item X as lock(X).\\nTwo operations, \\nlock_item and unlock_item, are used with binary locking. A trans-\\naction requests access to an item X by first issuing a lock_item(X) operation. If'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 796, 'page_label': '797'}, page_content='21.1 Two-Phase Locking Techniques for Concurrency Control  783\\nLOCK(X) = 1, the transaction is forced to wait. If LOCK(X) = 0, it is set to 1 (the \\ntransaction locks the item) and the transaction is allowed to access item X. When \\nthe transaction is through using the item, it issues an unlock_item( X) operation, \\nwhich sets LOCK(X) back to 0 ( unlocks the item) so that X may be accessed by \\nother transactions. Hence, a binary lock enforces mutual exclusion  on the data \\nitem. A description of the lock_item(X) and unlock_item(X) operations is shown in \\nFigure 21.1.\\nNotice that the lock_item and unlock_item operations must be implemented as indi-\\nvisible units (known as critical sections in operating systems); that is, no interleav-\\ning should be allowed once a lock or unlock operation is started until the operation \\nterminates or the transaction waits. In Figure 21.1, the wait command within the \\nlock_item(X) operation is usually implemented by putting the transaction in a wait-\\ning queue for item X until X is unlocked and the transaction can be granted access \\nto it. Other transactions that also want to access X are placed in the same queue. \\nHence, the wait command is considered to be outside the lock_item operation.\\nIt is simple to implement a binary lock; all that is needed is a binary-valued variable, \\nLOCK, associated with each data item X in the database. In its simplest form, each \\nlock can be a record with three fields: < Data_item_name, LOCK, Locking_transaction> \\nplus a queue for transactions that are waiting to access the item. The system needs \\nto maintain only these records for the items that are currently locked in a lock table, \\nwhich could be organized as a hash file on the item name. Items not in the lock \\ntable are considered to be unlocked. The DBMS has a lock manager subsystem to \\nkeep track of and control access to locks.\\nIf the simple binary locking scheme described here is used, every transaction must \\nobey the following rules:\\n  1. A transaction T must issue the operation lock_item (X) before any  \\nread_item(X) or write_item(X) operations are performed in T.\\n  2. A transaction T must issue the operation unlock_item(X) after all read_item(X) \\nand write_item(X) operations are completed in T.\\nlock_item(X):\\nB: if LOCK( X) = 0 (*item is unlocked*)\\n  then LOCK(X) ←1 (*lock the item*)\\n else\\n  begin\\n  wait (until LOCK(X) = 0\\n   and the lock manager wakes up the transaction);\\n  go to B\\n  end;\\nunlock_item(X):\\n LOCK(X) ← 0; (* unlock the item *)\\n if any transactions are waiting\\n  then wakeup one of the waiting transactions;\\nFigure 21.1 \\nLock and unlock operations \\nfor binary locks.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 797, 'page_label': '798'}, page_content='784 Chapter 21 Concurrency Control Techniques\\n  3. A transaction T will not issue a lock_item(X) operation if it already holds the \\nlock on item X.1\\n  4. A transaction T will not issue an unlock_item(X) operation unless it already \\nholds the lock on item X.\\nThese rules can be enforced by the lock manager module of the DBMS. Between the \\nlock_item(X) and unlock_item(X) operations in transaction T, T is said to hold the \\nlock on item X. At most one transaction can hold the lock on a particular item. \\nThus no two transactions can access the same item concurrently.\\nShared/Exclusive (or Read/Write) Locks. The preceding binary locking \\nscheme is too restrictive for database items because at most one transaction can \\nhold a lock on a given item. We should allow several transactions to access the \\nsame item X if they all access X for reading purposes only . This is because read \\noperations on the same item by different transactions are not conflicting  (see Sec-\\ntion 21.4.1). However, if a transaction is to write an item X, it must have exclusive \\naccess to X. For this purpose, a different type of lock, called a multiple-mode \\nlock, is used. In this scheme—called shared/exclusive  or read/write locks—there \\nare three locking operations: \\nread_lock (X), write_lock (X), and unlock(X). A lock \\nassociated with an item X, LOCK(X), now has three possible states: read-locked , \\nwrite-locked , or unlocked. A read-locked item  is also called share-locked  because \\nother transactions are allowed to read the item, whereas a write-locked item  is \\ncalled exclusive-locked  because a single transaction exclusively holds the lock on \\nthe item.\\nOne method for implementing the preceding operations on a read/write lock is \\nto keep track of the number of transactions that hold a shared (read) lock on an \\nitem in the lock table, as well as a list of transaction ids that hold a shared lock. \\nEach record in the lock table will have four fields: <\\nData_item_name , LOCK,  \\nNo_of_reads , Locking_transaction(s) >. The system needs to maintain lock records \\nonly for locked items in the lock table. The value (state) of LOCK is either read-\\nlocked or write-locked, suitably coded (if we assume no records are kept in \\nthe\\xa0 lock table for unlocked items). If LOCK(X) = write-locked, the value of \\n locking_transaction(s) is a single transaction  that holds the exclusive (write) lock \\non X. If LOCK(X)=read-locked, the value of locking transaction(s) is a list of one \\nor more transactions that hold the shared (read) lock on X. The three operations \\nread_lock(X), write_lock (X), and unlock(X) are described in Figure 21.2. 2 As before, \\neach of the three locking operations should be considered indivisible; no inter-\\nleaving should be allowed once one of the operations is started until either the \\noperation terminates by granting the lock or the transaction is placed in a wait-\\ning queue for the item.\\n1This rule may be removed if we modify the lock_item (X) operation in Figure 21.1 so that if the item is \\ncurrently locked by the requesting transaction, the lock is granted.\\n2These algorithms do not allow upgrading or downgrading of locks, as described later in this section. The \\nreader can extend the algorithms to allow these additional operations.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 798, 'page_label': '799'}, page_content='21.1 Two-Phase Locking Techniques for Concurrency Control  785\\nWhen we use the shared/exclusive locking scheme, the system must enforce the \\nfollowing rules:\\n  1. A transaction T must issue the operation read_lock(X) or write_lock(X) before \\nany read_item(X) operation is performed in T.\\n  2. A transaction T must issue the operation write_lock(X) before any write_item(X) \\noperation is performed in T.\\n  3. A transaction T must issue the operation unlock(X) after all read_item(X) and \\nwrite_item(X) operations are completed in T.3\\nread_lock(X):\\nB: if LOCK( X) = “unlocked”\\n  then begin LOCK(X) ← “read-locked”;\\n   no_of_reads(X) ← 1\\n   end\\n else if LOCK(X) = “read-locked”\\n  then no_of_reads(X) ← no_of_reads(X) + 1\\n else begin\\n   wait (until LOCK(X) = “unlocked”\\n    and the lock manager wakes up the transaction);\\n   go to B\\n   end;\\nwrite_lock(X):\\nB: if LOCK( X) = “unlocked”\\n  then LOCK(X) ← “write-locked”\\n else begin\\n   wait (until LOCK(X) = “unlocked”\\n    and the lock manager wakes up the transaction);\\n   go to B\\n   end;\\nunlock (X):\\n if LOCK(X) = “write-locked”\\n  then begin LOCK(X) ← “unlocked”;\\n    wakeup one of the waiting transactions, if any\\n    end\\n else it LOCK(X) = “read-locked”\\n  then begin\\n    no_of_reads(X) ← no_of_reads(X) −1;\\n    if no_of_reads(X) = 0\\n     then begin LOCK(X) = “unlocked”;\\n       wakeup one of the waiting transactions, if any\\n       end\\n    end;\\nFigure 21.2 \\nLocking and unlocking \\noperations for two-\\nmode (read/write, or \\nshared/exclusive) \\nlocks.\\n3This rule may be relaxed to allow a transaction to unlock an item, then lock it again later. However, two-\\nphase locking does not allow this.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 799, 'page_label': '800'}, page_content='786 Chapter 21 Concurrency Control Techniques\\n  4. A transaction T will not issue a read_lock(X) operation if it already holds a \\nread (shared) lock or a write (exclusive) lock on item X. This rule may be \\nrelaxed for downgrading of locks, as we discuss shortly.\\n  5. A transaction T will not issue a write_lock(X) operation if it already holds a \\nread (shared) lock or write (exclusive) lock on item X. This rule may also be \\nrelaxed for upgrading of locks, as we discuss shortly.\\n  6. A transaction T will not issue an unlock(X) operation unless it already holds \\na read (shared) lock or a write (exclusive) lock on item X.\\nConversion (Upgrading, Downgrading) of Locks. It is desirable to relax con-\\nditions 4 and 5 in the preceding list in order to allow lock conversion ; that is, a \\ntransaction that already holds a lock on item X is allowed under certain conditions \\nto convert the lock from one locked state to another. For example, it is possible for \\na transaction T to issue a read_lock(X) and then later to upgrade the lock by issuing \\na write_lock(X) operation. If T is the only transaction holding a read lock on X at the \\ntime it issues the write_lock(X) operation, the lock can be upgraded; otherwise, the \\ntransaction must wait. It is also possible for a transaction T to issue a write_lock(X) \\nand then later to downgrade the lock by issuing a read_lock(X) operation. When \\nupgrading and downgrading of locks is used, the lock table must include transac-\\ntion identifiers in the record structure for each lock (in the locking_transaction(s) \\nfield) to store the information on which transactions hold locks on the item. The \\ndescriptions of the read_lock(X) and write_lock(X) operations in Figure 21.2 must be \\nchanged appropriately to allow for lock upgrading and downgrading. We leave this \\nas an exercise for the reader.\\nUsing binary locks or read/write locks in transactions, as described earlier, does not \\nguarantee serializability of schedules on its own. Figure 21.3 shows an example \\nwhere the preceding locking rules are followed but a nonserializable schedule may \\nresult. This is because in Figure 21.3(a) the items Y in T1 and X in T2 were unlocked \\ntoo early. This allows a schedule such as the one shown in Figure 21.3(c) to occur, \\nwhich is not a serializable schedule and hence gives incorrect results. To guarantee \\nserializability, we must follow an additional protocol concerning the positioning of \\nlocking and unlocking operations in every transaction. The best-known protocol, \\ntwo-phase locking, is described in the next section.\\n21.1.2 Guaranteeing Serializability by Two-Phase Locking\\nA transaction is said to follow the two-phase locking protocol if all locking opera-\\ntions (read_lock, write_lock) precede the first unlock operation in the transaction. 4 \\nSuch a transaction can be divided into two phases: an expanding  or growing \\n(first) phase , during which new locks on items can be acquired but none can be \\nreleased; and a shrinking (second) phase , during which existing locks can be \\nreleased but no new locks can be acquired. If lock conversion is allowed, then \\nupgrading of locks (from read-locked to write-locked) must be done during the \\n4This is unrelated to the two-phase commit protocol for recovery in distributed databases (see Chapter 23).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 800, 'page_label': '801'}, page_content='21.1 Two-Phase Locking Techniques for Concurrency Control  787\\nexpanding phase, and downgrading of locks (from write-locked to read-locked) \\nmust be done in the shrinking phase.\\nTransactions T1 and T2 in Figure 21.3(a) do not follow the two-phase locking pro-\\ntocol because the write_lock(X) operation follows the unlock(Y) operation in T1, and \\nsimilarly the write_lock(Y) operation follows the unlock(X) operation in T2. If we \\nenforce two-phase locking, the transactions can be rewritten as T1′ and T2′, as \\nshown in Figure 21.4. Now, the schedule shown in Figure 21.3(c) is not permitted \\nfor T\\n1′ and T2′ (with their modified order of locking and unlocking operations) \\nunder the rules of locking described in Section 21.1.1 because T1′ will issue its  \\nwrite_lock(X) before it unlocks item Y; consequently, when T2′ issues its read_lock(X), \\nit is forced to wait until T1′ releases the lock by issuing an unlock (X) in the schedule. \\nHowever, this can lead to deadlock (see Section 21.1.3).\\n(a) T1 Initial values: X=20, Y=30\\nResult serial schedule T1\\nfollowed by T2: X=50, Y=80\\nResult of serial schedule T2\\nfollowed by T1: X=70, Y=50\\nread_lock(Y );\\nread_item(Y );\\nunlock(Y );\\nwrite_lock(X );\\nread_item(X );\\nX := X + Y;\\nwrite_item(X );\\nunlock(X );\\nwrite_lock(X );\\nread_item(X );\\nX := X + Y;\\nwrite_item(X );\\nunlock(X );\\nread_lock(X );\\nread_item(X );\\nunlock(X );\\nwrite_lock(Y );\\nread_item(Y );\\nY := X + Y;\\nwrite_item(Y );\\nunlock(Y );\\nread_lock(X );\\nread_item(X );\\nunlock(X );\\nwrite_lock(Y );\\nread_item(Y );\\nY := X + Y;\\nwrite_item(Y );\\nunlock(Y );\\n(b)\\n(c)\\nTime\\nread_lock(Y );\\nread_item(Y );\\nunlock(Y );\\nResult of schedule S:\\nX=50, Y=50\\n(nonserializable)\\nT2\\nT1 T2\\nFigure 21.3 \\nTransactions that do not obey two-phase locking. \\n(a) Two transactions T\\n1 and T2. (b) Results of \\npossible serial schedules of T1 and T2. (c) A  \\nnonserializable schedule S that uses locks.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 801, 'page_label': '802'}, page_content='788 Chapter 21 Concurrency Control Techniques\\nIt can be proved that, if every transaction in a schedule follows the two-phase lock-\\ning protocol, the schedule is guaranteed to be serializable, obviating the need to test \\nfor serializability of schedules. The locking protocol, by enforcing two-phase lock-\\ning rules, also enforces serializability.\\nTwo-phase locking may limit the amount of concurrency that can occur in a sched-\\nule because a transaction T may not be able to release an item X after it is through \\nusing it if T must lock an additional item Y later; or, conversely, T must lock the \\nadditional item Y before it needs it so that it can release X. Hence, X must remain \\nlocked by T until all items that the transaction needs to read or write have been \\nlocked; only then can X be released by T. Meanwhile, another transaction seeking to \\naccess X may be forced to wait, even though T is done with X; conversely, if Y is \\nlocked earlier than it is needed, another transaction seeking to access Y is forced to \\nwait even though T is not using Y yet. This is the price for guaranteeing serializabil-\\nity of all schedules without having to check the schedules themselves.\\nAlthough the two-phase locking protocol guarantees serializability (that is, every \\nschedule that is permitted is serializable), it does not permit all possible serializable \\nschedules (that is, some serializable schedules will be prohibited by the protocol).\\nBasic, Conservative, Strict, and Rigorous Two-Phase Locking. There are a \\nnumber of variations of two-phase locking (2PL). The technique just described is \\nknown as basic 2PL . A variation known as conservative 2PL  (or static 2PL ) \\nrequires a transaction to lock all the items it accesses before the transaction begins \\nexecution, by predeclaring its read-set and write-set. Recall from Section 21.1.2 that \\nthe read-set of a transaction is the set of all items that the transaction reads, and the \\nwrite-set is the set of all items that it writes. If any of the predeclared items needed \\ncannot be locked, the transaction does not lock any item; instead, it waits until all \\nthe items are available for locking. Conservative 2PL is a deadlock-free protocol, as \\nwe will see in Section 21.1.3 when we discuss the deadlock problem. However, it is \\ndifficult to use in practice because of the need to predeclare the read-set and write-\\nset, which is not possible in some situations.\\nIn practice, the most popular variation of 2PL is strict 2PL, which guarantees strict \\nschedules (see Section 21.4). In this variation, a transaction T does not release any \\nread_lock(Y );\\nread_item(Y );\\nwrite_lock(X );\\nunlock(Y )\\nread_item(X );\\nX := X + Y;\\nwrite_item(X );\\nunlock(X );\\nread_lock(X );\\nread_item(X );\\nwrite_lock(Y );\\nunlock(X )\\nread_item(Y );\\nY := X + Y;\\nwrite_item(Y );\\nunlock(Y );\\nT1/H11032 T2/H11032\\nFigure 21.4 \\nTransactions T1′ and T2′, which are the \\nsame as T1 and T2 in Figure 21.3 but \\nfollow the two-phase locking protocol. \\nNote that they can produce a deadlock.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 802, 'page_label': '803'}, page_content='21.1 Two-Phase Locking Techniques for Concurrency Control  789\\nof its exclusive (write) locks until after it commits or aborts. Hence, no other trans-\\naction can read or write an item that is written by T unless T has committed, lead-\\ning to a strict schedule for recoverability. Strict 2PL is not deadlock-free. A more \\nrestrictive variation of strict 2PL is rigorous 2PL , which also guarantees strict \\nschedules. In this variation, a transaction T does not release any of its locks (exclu-\\nsive or shared) until after it commits or aborts, and so it is easier to implement \\nthan strict 2PL.\\nNotice the difference between strict and rigorous 2PL: the former holds write-locks \\nuntil it commits, whereas the latter holds all locks (read and write). Also, the differ-\\nence between conservative and rigorous 2PL is that the former must lock all its \\nitems before it starts , so once the transaction starts it is in its shrinking phase; the \\nlatter does not unlock any of its items until after it terminates  (by committing or \\naborting), so the transaction is in its expanding phase until it ends.\\nUsually the concurrency control subsystem  itself is responsible for generating \\nthe\\xa0\\nread_lock and write_lock requests. For example, suppose the system is to enforce \\nthe strict 2PL protocol. Then, whenever transaction T issues a read_item(X), the \\n system calls the read_lock(X) operation on behalf of T. If the state of LOCK(X) is \\nwrite_locked by some other transaction T′, the system places T in the waiting queue \\nfor item X; otherwise, it grants the read_lock(X) request and permits the read_item(X) \\noperation of T to execute. On the other hand, if transaction T issues a write_item(X), \\nthe system calls the write_lock(X) operation on behalf of T. If the state of LOCK(X) is \\nwrite_locked or read_locked by some other transaction T′, the system places T in \\nthe waiting queue for item X; if the state of LOCK(X) is read_locked and T itself is \\nthe only transaction holding the read lock on X, the system upgrades the lock to \\nwrite_locked and permits the write_item(X) operation by T. Finally, if the state of \\nLOCK(X) is unlocked, the system grants the write_lock(X) request and permits the \\nwrite_item(X) operation to execute. After each action, the system must update its \\nlock table appropriately.\\nLocking is generally considered to have a high overhead, because every read or \\nwrite operation is preceded by a system locking request. The use of locks can also \\ncause two additional problems: deadlock and starvation. We discuss these problems \\nand their solutions in the next section.\\n21.1.3 Dealing with Deadlock and Starvation\\nDeadlock occurs when each transaction T in a set of two or more transactions  is \\nwaiting for some item that is locked by some other transaction T′ in the set. Hence, \\neach transaction in the set is in a waiting queue, waiting for one of the other trans-\\nactions in the set to release the lock on an item. But because the other transaction is \\nalso waiting, it will never release the lock. A simple example is shown in Fig-\\nure\\xa021.5(a), where the two transactions T\\n1′ and T2′ are deadlocked in a partial \\nschedule; T1′ is in the waiting queue for X, which is locked by T2′, whereas T2′ is in \\nthe waiting queue for Y, which is locked by T1′. Meanwhile, neither T1′ nor T2′ nor \\nany other transaction can access items X and Y.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 803, 'page_label': '804'}, page_content='790 Chapter 21 Concurrency Control Techniques\\nDeadlock Prevention Protocols. One way to prevent deadlock is to use a deadlock \\nprevention protocol.5 One deadlock prevention protocol, which is used in conserva-\\ntive two-phase locking, requires that every transaction lock all the items it needs in \\nadvance (which is generally not a practical assumption)—if any of the items cannot be \\nobtained, none of the items are locked. Rather, the transaction waits and then tries \\nagain to lock all the items it needs. Obviously, this solution further limits concurrency. \\nA second protocol, which also limits concurrency, involves ordering all the items in the \\ndatabase and making sure that a transaction that needs several items will lock them \\naccording to that order. This requires that the programmer (or the system) is aware of \\nthe chosen order of the items, which is also not practical in the database context.\\nA number of other deadlock prevention schemes have been proposed that make a \\ndecision about what to do with a transaction involved in a possible deadlock situation: \\nShould it be blocked and made to wait or should it be aborted, or should the transac-\\ntion preempt and abort another transaction? Some of these techniques use the concept \\nof transaction timestamp \\nTS(T′), which is a unique identifier assigned to each trans-\\naction. The timestamps are typically based on the order in which transactions are \\nstarted; hence, if transaction T\\n1 starts before transaction T2, then TS(T1) < TS(T2). \\nNotice that the older transaction (which starts first) has the smaller timestamp value. \\nTwo schemes that prevent deadlock are called wait-die and wound-wait. Suppose that \\ntransaction Ti tries to lock an item X but is not able to because X is locked by some \\nother transaction Tj with a conflicting lock. The rules followed by these schemes are:\\n ■ Wait-die. If TS(Ti) < TS(Tj), then ( Ti older than Tj) Ti is allowed to wait; \\notherwise (Ti younger than Tj) abort Ti (Ti dies) and restart it later with the \\nsame timestamp.\\n ■ Wound-wait. If TS(Ti) < TS(Tj), then (Ti older than Tj) abort Tj (Ti wounds \\nTj) and restart it later with the same timestamp; otherwise (Ti younger than \\nTj) Ti is allowed to wait.\\n(a) T1/H11032 (b)\\nread_lock(Y );\\nread_item(Y );\\nTime\\nwrite_lock(X );\\nread_lock(X );\\nread_item(X );\\nwrite_lock(Y );\\nT2/H11032\\n   T2/H11032T1/H11032\\nX\\nY\\nFigure 21.5 \\nIllustrating the deadlock problem. (a) A partial schedule of T1′ and T2′ that is  \\nin a state of deadlock. (b) A wait-for graph for the partial schedule in (a).\\n5These protocols are not generally used in practice, either because of unrealistic assumptions or \\nbecause of their possible overhead. Deadlock detection and timeouts (covered in the following sections) \\nare more practical.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 804, 'page_label': '805'}, page_content='21.1 Two-Phase Locking Techniques for Concurrency Control  791\\nIn wait-die, an older transaction is allowed to wait for a younger transaction, whereas \\na younger transaction requesting an item held by an older transaction is aborted and \\nrestarted. The wound-wait approach does the opposite: A younger transaction is \\nallowed to wait for an older one, whereas an older transaction requesting an item held \\nby a younger transaction preempts the younger transaction by aborting it. Both \\nschemes end up aborting the younger of the two transactions (the transaction that \\nstarted later) that may be involved in a deadlock, assuming that this will waste less \\nprocessing. It can be shown that these two techniques are deadlock-free, since in wait-\\ndie, transactions only wait for younger transactions so no cycle is created. Similarly, in \\nwound-wait, transactions only wait for older transactions so no cycle is created. How-\\never, both techniques may cause some transactions to be aborted and restarted need-\\nlessly, even though those transactions may never actually cause a deadlock.\\nAnother group of protocols that prevent deadlock do not require timestamps. \\nThese include the no waiting (NW) and cautious waiting (CW) algorithms. In the \\nno waiting algorithm, if a transaction is unable to obtain a lock, it is immediately \\naborted and then restarted after a certain time delay without checking whether a \\ndeadlock will actually occur or not. In this case, no transaction ever waits, so no \\ndeadlock will occur. However, this scheme can cause transactions to abort and \\nrestart needlessly. The cautious waiting algorithm was proposed to try to reduce \\nthe number of needless aborts/restarts. Suppose that transaction T\\ni tries to lock an \\nitem X but is not able to do so because X is locked by some other transaction Tj with \\na conflicting lock. The cautious waiting rule is as follows:\\n ■ Cautious waiting.  If Tj is not blocked (not waiting for some other locked \\nitem), then Ti is blocked and allowed to wait; otherwise abort Ti.\\nIt can be shown that cautious waiting is deadlock-free, because no transaction will \\never wait for another blocked transaction. By considering the time b(T) at which \\neach blocked transaction T was blocked, if the two transactions Ti and Tj above both \\nbecome blocked and Ti is waiting for Tj, then b(Ti) < b(Tj), since Ti can only wait for \\nTj at a time when Tj is not blocked itself. Hence, the blocking times form a total \\nordering on all blocked transactions, so no cycle that causes deadlock can occur.\\nDeadlock Detection. An alternative approach to dealing with deadlock is \\n deadlock detection, where the system checks if a state of deadlock actually exists. \\nThis solution is attractive if we know there will be little interference among the \\ntransactions—that is, if different transactions will rarely access the same items at \\nthe same time. This can happen if the transactions are short and each transaction \\nlocks only a few items, or if the transaction load is light. On the other hand, if trans-\\nactions are long and each transaction uses many items, or if the transaction load is \\nheavy, it may be advantageous to use a deadlock prevention scheme.\\nA simple way to detect a state of deadlock is for the system to construct and main-\\ntain a wait-for graph. One node is created in the wait-for graph for each transac-\\ntion that is currently executing. Whenever a transaction T\\ni is waiting to lock an \\nitem X that is currently locked by a transaction Tj, a directed edge (Ti → Tj) is cre-\\nated in the wait-for graph. When Tj releases the lock(s) on the items that Ti was'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 805, 'page_label': '806'}, page_content='792 Chapter 21 Concurrency Control Techniques\\nwaiting for, the directed edge is dropped from the wait-for graph. We have a state of \\ndeadlock if and only if the wait-for graph has a cycle. One problem with this \\napproach is the matter of determining when the system should check for a dead-\\nlock. One possibility is to check for a cycle every time an edge is added to the wait-\\nfor graph, but this may cause excessive overhead. Criteria such as the number of \\ncurrently executing transactions or the period of time several transactions have \\nbeen waiting to lock items may be used instead to check for a cycle. Figure 21.5(b) \\nshows the wait-for graph for the (partial) schedule shown in Figure 21.5(a).\\nIf the system is in a state of deadlock, some of the transactions causing the deadlock \\nmust be aborted. Choosing which transactions to abort is known as victim \\n selection. The algorithm for victim selection should generally avoid selecting trans-\\nactions that have been running for a long time and that have performed many \\nupdates, and it should try instead to select transactions that have not made many \\nchanges (younger transactions).\\nTimeouts. Another simple scheme to deal with deadlock is the use of timeouts. \\nThis method is practical because of its low overhead and simplicity. In this method, \\nif a transaction waits for a period longer than a system-defined timeout period, the \\nsystem assumes that the transaction may be deadlocked and aborts it—regardless of \\nwhether a deadlock actually exists.\\nStarvation. Another problem that may occur when we use locking is starvation, \\nwhich occurs when a transaction cannot proceed for an indefinite period of time \\nwhile other transactions in the system continue normally. This may occur if the \\nwaiting scheme for locked items is unfair in that it gives priority to some transac-\\ntions over others. One solution for starvation is to have a fair waiting scheme, such \\nas using a first-come-first-served queue; transactions are enabled to lock an item \\nin the order in which they originally requested the lock. Another scheme allows \\nsome transactions to have priority over others but increases the priority of a trans-\\naction the longer it waits, until it eventually gets the highest priority and proceeds. \\nStarvation can also occur because of victim selection if the algorithm selects the \\nsame transaction as victim repeatedly, thus causing it to abort and never finish exe-\\ncution. The algorithm can use higher priorities for transactions that have been \\naborted multiple times to avoid this problem. The wait-die and wound-wait \\nschemes discussed previously avoid starvation, because they restart a transaction \\nthat has been aborted with its same original timestamp, so the possibility that the \\nsame transaction is aborted repeatedly is slim.\\n21.2  Concurrency Control Based  \\non Timestamp Ordering\\nThe use of locking, combined with the 2PL protocol, guarantees serializability of \\nschedules. The serializable schedules produced by 2PL have their equivalent serial \\nschedules based on the order in which executing transactions lock the items they \\nacquire. If a transaction needs an item that is already locked, it may be forced to \\nwait until the item is released. Some transactions may be aborted and restarted'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 806, 'page_label': '807'}, page_content='21.2 Concurrency Control Based on Timestamp Ordering  793\\nbecause of the deadlock problem. A different approach to concurrency control \\ninvolves using transaction timestamps to order transaction execution for an equiv-\\nalent serial schedule. In Section 21.2.1, we discuss timestamps; and in Section 21.2.2, \\nwe discuss how serializability is enforced by ordering conflicting operations in dif-\\nferent transactions based on the transaction timestamps.\\n21.2.1 Timestamps\\nRecall that a timestamp is a unique identifier created by the DBMS to identify a \\ntransaction. Typically, timestamp values are assigned in the order in which the \\ntransactions are submitted to the system, so a timestamp can be thought of as the \\ntransaction start time . We will refer to the timestamp of transaction T as TS(T). \\nConcurrency control techniques based on timestamp ordering do not use locks; \\nhence, deadlocks cannot occur.\\nTimestamps can be generated in several ways. One possibility is to use a counter that \\nis incremented each time its value is assigned to a transaction. The transaction time-\\nstamps are numbered 1, 2, 3, … in this scheme. A computer counter has a finite \\nmaximum value, so the system must periodically reset the counter to zero when no \\ntransactions are executing for some short period of time. Another way to implement \\ntimestamps is to use the current date/time value of the system clock and ensure that \\nno two timestamp values are generated during the same tick of the clock.\\n21.2.2  The Timestamp Ordering Algorithm  \\nfor Concurrency Control\\nThe idea for this scheme is to enforce the equivalent serial order on the transac-\\ntions based on their timestamps. A schedule in which the transactions participate \\nis then serializable, and the only equivalent serial schedule permitted  has the trans-\\nactions in order of their timestamp values. This is called timestamp ordering \\n(TO). Notice how this differs from 2PL, where a schedule is serializable by being \\nequivalent to some serial schedule allowed by the locking protocols. In timestamp \\nordering, however, the schedule is equivalent to the particular serial order  corre-\\nsponding to the order of the transaction timestamps. The algorithm allows inter-\\nleaving of transaction operations, but it must ensure that for each pair of conflicting \\noperations in the schedule, the order in which the item is accessed must follow the \\ntimestamp order. To do this, the algorithm associates with each database item X \\ntwo timestamp (TS) values:\\n  1. read_TS( X). The read timestamp  of item X is the largest timestamp \\namong all the timestamps of transactions that have successfully read item \\nX—that is, read_TS(X) = TS(T), where T is the youngest transaction that \\nhas read X successfully.\\n  2. write_TS( X). The write timestamp  of item X is the largest of all the time-\\nstamps of transactions that have successfully written item X—that is, \\nwrite_TS(X) = TS(T), where T is the youngest  transaction that has written \\nX successfully. Based on the algorithm, T will also be the last transaction \\nto write item X, as we shall see.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 807, 'page_label': '808'}, page_content='794 Chapter 21 Concurrency Control Techniques\\nBasic Timestamp Ordering (TO). Whenever some transaction T tries to issue a \\nread_item(X) or a write_item(X) operation, the basic TO  algorithm compares the \\ntimestamp of T with read_TS(X) and write_TS(X) to ensure that the timestamp order \\nof transaction execution is not violated. If this order is violated, then transaction T \\nis aborted and resubmitted to the system as a new transaction with a new time-\\nstamp. If T is aborted and rolled back, any transaction T1 that may have used a value \\nwritten by T must also be rolled back. Similarly, any transaction T2 that may have \\nused a value written by T1 must also be rolled back, and so on. This effect is known \\nas cascading rollback and is one of the problems associated with basic TO, since \\nthe schedules produced are not guaranteed to be recoverable. An additional proto-\\ncol must be enforced to ensure that the schedules are recoverable, cascadeless, or \\nstrict. We first describe the basic TO algorithm here. The concurrency control algo-\\nrithm must check whether conflicting operations violate the timestamp ordering in \\nthe following two cases:\\n  1. Whenever a transaction T issues a write_item(X) operation, the following \\ncheck is performed:\\na. If read_TS(X) > TS(T) or if write_TS(X) > TS(T), then abort and roll back T \\nand reject the operation. This should be done because some younger trans-\\naction with a timestamp greater than TS(T)—and hence after T in the \\ntimestamp ordering—has already read or written the value of item X \\nbefore T had a chance to write X, thus violating the timestamp ordering.\\nb. If the condition in part (a) does not occur, then execute the write_item(X) \\noperation of T and set write_TS(X) to TS(T).\\n  2. Whenever a transaction T issues a read_item(X) operation, the following \\ncheck is performed:\\na. If write_TS(X) > TS(T), then abort and roll back T and reject the operation. \\nThis should be done because some younger transaction with timestamp \\ngreater than \\nTS(T)—and hence after T in the timestamp ordering—has \\nalready written the value of item X before T had a chance to read X.\\nb. If write_TS(X) ≤ TS(T), then execute the read_item(X) operation of T and \\nset read_TS(X) to the larger of TS(T) and the current read_TS(X).\\nWhenever the basic TO algorithm detects two conflicting operations that occur in \\nthe incorrect order, it rejects the later of the two operations by aborting the transac-\\ntion that issued it. The schedules produced by basic TO are hence guaranteed to be \\nconflict serializable. As mentioned earlier, deadlock does not occur with timestamp \\nordering. However, cyclic restart (and hence starvation) may occur if a transaction \\nis continually aborted and restarted.\\nStrict Timestamp Ordering (TO). A variation of basic TO called strict TO ensures \\nthat the schedules are both strict (for easy recoverability) and (conflict) serializable. \\nIn this variation, a transaction T issues a \\nread_item(X) or write_item(X) such that  \\nTS(T) > write_TS(X) has its read or write operation delayed until the transaction T′ \\nthat wrote the value of X (hence TS(T′) = write_TS(X)) has committed or aborted.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 808, 'page_label': '809'}, page_content='21.3 Multiversion Concurrency Control Techniques  795\\nTo\\xa0implement this algorithm, it is necessary to simulate the locking of an item X that \\nhas been written by transaction T′ until T′ is either committed or aborted. This \\n algorithm does not cause deadlock, since T waits for T′ only if TS(T) > TS(T′).\\nThomas’s Write Rule. A modification of the basic TO algorithm, known as \\nThomas’s write rule , does not enforce conflict serializability, but it rejects fewer \\nwrite operations by modifying the checks for the write_item(X) operation as follows:\\n  1. If read_TS(X) > TS(T), then abort and roll back T and reject the operation.\\n  2. If write_TS(X) > TS(T), then do not execute the write operation but continue \\nprocessing. This is because some transaction with timestamp greater than \\nTS(T)—and hence after T in the timestamp ordering—has already written \\nthe value of X. Thus, we must ignore the write_item(X) operation of T because \\nit is already outdated and obsolete. Notice that any conflict arising from this \\nsituation would be detected by case (1).\\n  3. If neither the condition in part (1) nor the condition in part (2) occurs, then \\nexecute the \\nwrite_item(X) operation of T and set write_TS(X) to TS(T).\\n21.3  Multiversion Concurrency  \\nControl Techniques\\nThese protocols for concurrency control keep copies of the old values of a data item \\nwhen the item is updated (written); they are known as multiversion concurrency \\ncontrol because several versions (values) of an item are kept by the system. When a \\ntransaction requests to read an item, the appropriate version is chosen to maintain \\nthe serializability of the currently executing schedule. One reason for keeping mul-\\ntiple versions is that some read operations that would be rejected in other tech-\\nniques can still be accepted by reading an older version  of the item to maintain \\nserializability. When a transaction writes an item, it writes a new version and the old \\nversion(s) of the item is retained. Some multiversion concurrency control algo-\\nrithms use the concept of view serializability rather than conflict serializability.\\nAn obvious drawback of multiversion techniques is that more storage is needed to \\nmaintain multiple versions of the database items. In some cases, older versions can \\nbe kept in a temporary store. It is also possible that older versions may have to be \\nmaintained anyway—for example, for recovery purposes. Some database applica-\\ntions may require older versions to be kept to maintain a history of the changes of \\ndata item values. The extreme case is a temporal database (see Section 26.2), which \\nkeeps track of all changes and the times at which they occurred. In such cases, there \\nis no additional storage penalty for multiversion techniques, since older versions \\nare already maintained.\\nSeveral multiversion concurrency control schemes have been proposed. We dis-\\ncuss two schemes here, one based on timestamp ordering and the other based on \\n2PL. In addition, the validation concurrency control method (see Section 21.4) \\nalso maintains multiple versions, and the snapshot isolation  technique used in'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 809, 'page_label': '810'}, page_content='796 Chapter 21 Concurrency Control Techniques\\nseveral commercial systems (see Section 21.4) can be implemented by keeping \\nolder versions of items in a temporary store.\\n21.3.1 Multiversion Technique Based on Timestamp Ordering\\nIn this method, several versions X1, X2, … , Xk of each data item X are maintained. \\nFor each version, the value of version Xi and the following two timestamps associated \\nwith version Xi are kept:\\n  1. read_TS(Xi). The read timestamp of Xi is the largest of all the timestamps \\nof transactions that have successfully read version Xi.\\n  2. write_TS(Xi). The write timestamp of Xi is the timestamp of the transac-\\ntion that wrote the value of version Xi.\\nWhenever a transaction T is allowed to execute a write_item(X) operation, a new ver-\\nsion Xk+1 of item X is created, with both the write_TS(Xk+1) and the read_TS(Xk+1) set to \\nTS(T). Correspondingly, when a transaction T is allowed to read the value of version \\nXi, the value of read_TS(Xi) is set to the larger of the current read_TS(Xi) and TS(T).\\nTo ensure serializability, the following rules are used:\\n  1. If transaction T issues a write_item(X) operation, and version i of X has the \\nhighest write_TS(Xi) of all versions of X that is also less than or equal to TS(T), \\nand read_TS(Xi) > TS(T), then abort and roll back transaction T; otherwise, \\ncreate a new version Xj of X with read_TS(Xj) = write_TS(Xj) = TS(T).\\n  2. If transaction T issues a read_item(X) operation, find the version i of X that \\nhas the highest write_TS(Xi) of all versions of X that is also less than or equal \\nto TS(T); then return the value of Xi to transaction T, and set the value of \\nread_TS(Xi) to the larger of TS(T) and the current read_TS(Xi).\\nAs we can see in case 2, a read_item(X) is always successful, since it finds the appro-\\npriate version Xi to read based on the write_TS of the various existing versions of X. \\nIn case 1, however, transaction T may be aborted and rolled back. This happens if T \\nattempts to write a version of X that should have been read by another transaction \\nT′ whose timestamp is read_TS(Xi); however, T′ has already read version Xi, which \\nwas written by the transaction with timestamp equal to write_TS(Xi). If this conflict \\noccurs, T is rolled back; otherwise, a new version of X, written by transaction T, is \\ncreated. Notice that if T is rolled back, cascading rollback may occur. Hence, to \\nensure recoverability, a transaction T should not be allowed to commit until after \\nall the transactions that have written some version that T has read have committed.\\n21.3.2 Multiversion Two-Phase Locking Using Certify Locks\\nIn this multiple-mode locking scheme, there are three locking modes for an item—\\nread, write, and certify—instead of just the two modes (read, write) discussed previ-\\nously. Hence, the state of LOCK(X) for an item X can be one of read-locked, \\nwrite-locked, certify-locked, or unlocked. In the standard locking scheme, with \\nonly read and write locks (see Section 21.1.1), a write lock is an exclusive lock. We \\ncan describe the relationship between read and write locks in the standard scheme'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 810, 'page_label': '811'}, page_content='21.3 Multiversion Concurrency Control Techniques  797\\nby means of the lock compatibility table shown in Figure 21.6(a). An entry of Yes \\nmeans that if a transaction T holds the type of lock specified in the column header \\non item X and if transaction T′ requests the type of lock specified in the row header \\non the same item X, then T′ can obtain the lock because the locking modes are com-\\npatible. On the other hand, an entry of No in the table indicates that the locks are \\nnot compatible, so T′ must wait until T releases the lock.\\nIn the standard locking scheme, once a transaction obtains a write lock on an item, \\nno other transactions can access that item. The idea behind multiversion 2PL is to \\nallow other transactions T′ to read an item X while a single transaction T holds a \\nwrite lock on X. This is accomplished by allowing two versions for each item X; one \\nversion, the committed version, must always have been written by some commit-\\nted transaction. The second local version X′ can be created when a transaction T \\nacquires a write lock on X. Other transactions can continue to read the committed \\nversion of X while T holds the write lock. Transaction T can write the value of X′ as \\nneeded, without affecting the value of the committed version X. However, once T is \\nready to commit, it must obtain a certify lock on all items that it currently holds \\nwrite locks on before it can commit; this is another form of lock upgrading. The \\ncertify lock is not compatible with read locks, so the transaction may have to delay \\nits commit until all its write-locked items are released by any reading transactions \\nin order to obtain the certify locks. Once the certify locks—which are exclusive \\nlocks—are acquired, the committed version X of the data item is set to the value of \\nversion X′, version X′ is discarded, and the certify locks are then released. The lock \\ncompatibility table for this scheme is shown in Figure 21.6(b).\\nIn this multiversion 2PL scheme, reads can proceed concurrently with a single write \\noperation—an arrangement not permitted under the standard 2PL schemes. The \\ncost is that a transaction may have to delay its commit until it obtains exclusive \\ncertify locks on all the items it has updated. It can be shown that this scheme avoids \\ncascading aborts, since transactions are only allowed to read the version X that was \\nwritten by a committed transaction. However, deadlocks may occur, and these \\nmust be handled by variations of the techniques discussed in Section 21.1.3.\\n(b) Read Write\\nRead\\nWrite\\nCertify\\nYes No No\\nNo No No\\nYes Yes No\\nCertify\\n(a) Read Write\\nRead\\nWrite No No\\nYes No\\nFigure 21.6 \\nLock compatibility tables.  \\n(a) Lock compatibility table for  \\nread/write locking scheme.  \\n(b) Lock compatibility table for \\nread/write/certify locking  \\nscheme.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 811, 'page_label': '812'}, page_content='798 Chapter 21 Concurrency Control Techniques\\n21.4  Validation (Optimistic) Techniques and \\nSnapshot Isolation Concurrency Control\\nIn all the concurrency control techniques we have discussed so far, a certain degree \\nof checking is done before a database operation can be executed. For example, in \\nlocking, a check is done to determine whether the item being accessed is locked. In \\ntimestamp ordering, the transaction timestamp is checked against the read and \\nwrite timestamps of the item. Such checking represents overhead during transac-\\ntion execution, with the effect of slowing down the transactions.\\nIn optimistic concurrency control techniques , also known as validation  or \\n certification techniques , no checking  is done while the transaction is executing. \\nSeveral concurrency control methods are based on the validation technique. We \\nwill describe only one scheme in Section 21.4.1. Then, in Section 21.4.2, we discuss \\nconcurrency control techniques that are based on the concept of snapshot  isolation. \\nThe implementations of these concurrency control methods can utilize a combina-\\ntion of the concepts from validation-based techniques and versioning techniques, \\nas well as utilizing timestamps. Some of these methods may suffer from anomalies \\nthat can violate serializability, but because they generally have lower overhead than \\n2PL, they have been implemented in several relational DBMSs.\\n21.4.1 Validation-Based (Optimistic) Concurrency Control\\nIn this scheme, updates in the transaction are not applied directly to the database \\nitems on disk until the transaction reaches its end and is validated. During transac-\\ntion execution, all updates are applied to local copies  of the data items that are \\nkept for the transaction. 6 At the end of transaction execution, a validation phase \\nchecks whether any of the transaction’s updates violate serializability. Certain \\ninformation needed by the validation phase must be kept by the system. If serializ-\\nability is not violated, the transaction is committed and the database is updated \\nfrom the local copies; otherwise, the transaction is aborted and then restarted later.\\nThere are three phases for this concurrency control protocol:\\n  1. Read phase. A transaction can read values of committed data items from the \\ndatabase. However, updates are applied only to local copies (versions) of the \\ndata items kept in the transaction workspace.\\n  2. Validation phase. Checking is performed to ensure that serializability will \\nnot be violated if the transaction updates are applied to the database.\\n  3. Write phase.  If the validation phase is successful, the transaction updates \\nare applied to the database; otherwise, the updates are discarded and the \\ntransaction is restarted.\\nThe idea behind optimistic concurrency control is to do all the checks at once; hence, \\ntransaction execution proceeds with a minimum of overhead until the validation \\n6Note that this can be considered as keeping multiple versions of items!'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 812, 'page_label': '813'}, page_content='21.4 Validation (Optimistic) Techniques and Snapshot Isolation Concurrency Control  799\\nphase is reached. If there is little interference among transactions, most will be vali-\\ndated successfully. However, if there is much interference, many transactions that \\nexecute to completion will have their results discarded and must be restarted later; \\nunder such circumstances, optimistic techniques do not work well. The techniques \\nare called optimistic because they assume that little interference will occur and hence \\nmost transaction will be validated successfully, so that there is no need to do check-\\ning during transaction execution. This assumption is generally true in many transac-\\ntion processing workloads.\\nThe optimistic protocol we describe uses transaction timestamps and also requires \\nthat the \\nwrite_sets and read_sets of the transactions be kept by the system. Addition-\\nally, start and end times for the three phases need to be kept for each transaction. \\nRecall that the write_set of a transaction is the set of items it writes, and the read_set \\nis the set of items it reads. In the validation phase for transaction Ti, the protocol \\nchecks that Ti does not interfere with any recently committed transactions or with \\nany other concurrent transactions that have started their validation phase. The vali-\\ndation phase for T\\ni checks that, for each such transaction Tj that is either recently \\ncommitted or is in its validation phase, one of the following conditions holds:\\n  1. Transaction Tj completes its write phase before Ti starts its read phase.\\n  2. Ti starts its write phase after Tj completes its write phase, and the read_set of \\nTi has no items in common with the write_set of Tj.\\n  3. Both the read_set  and write_set  of Ti have no items in common with the \\nwrite_set  of Tj, and Tj completes its read phase before Ti completes its \\nread phase.\\nWhen validating transaction Ti against each one of the transactions Tj, the first \\n condition is checked first since (1) is the simplest condition to check. Only if \\ncondi tion 1 is false is condition 2 checked, and only if (2) is false is condition 3—the \\nmost complex to evaluate—checked. If any one of these three conditions holds with \\neach transaction T\\nj, there is no interference and Ti is validated successfully. If none \\nof these three conditions holds for any one Tj, the validation of transaction Ti fails \\n(because Ti and Tj may violate serializability) and so Ti is aborted and restarted later \\nbecause interference with Tj may have occurred.\\n21.4.2 Concurrency Control Based on Snapshot Isolation\\nAs we discussed in Section 20.6, the basic definition of snapshot isolation is that a \\ntransaction sees the data items that it reads based on the committed values of the \\nitems in the database snapshot (or database state) when the transaction starts. Snap-\\nshot isolation will ensure that the phantom record problem does not occur, since \\nthe database transaction, or, in some cases, the database statement, will only see the \\nrecords that were committed in the database at the time the transaction started. \\nAny insertions, deletions, or updates that occur after the transaction starts will not \\nbe seen by the transaction. In addition, snapshot isolation does not allow the prob-\\nlems of dirty read and nonrepeatable read to occur. However, certain anomalies \\nthat violate serializability can occur when snapshot isolation is used as the basis for'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 813, 'page_label': '814'}, page_content='800 Chapter 21 Concurrency Control Techniques\\nconcurrency control. Although these anomalies are rare, they are very difficult to \\ndetect and may result in an inconsistent or corrupted database. The interested \\nreader can refer to the end-of-chapter bibliography for papers that discuss in detail \\nthe rare types of anomalies that can occur.\\nIn this scheme, read operations do not require read locks to be applied to the items, \\nthus reducing the overhead associated with two-phase locking. However, write \\noperations do require write locks. Thus, for transactions that have many reads, the \\nperformance is much better than 2PL. When writes do occur, the system will have \\nto keep track of older versions of the updated items in a temporary version store \\n(sometimes known as tempstore), with the timestamps of when the version was \\ncreated. This is necessary so that a transaction that started before the item was writ-\\nten can still read the value (version) of the item that was in the database snapshot \\nwhen the transaction started.\\nTo keep track of versions, items that have been updated will have pointers to a list \\nof recent versions of the item in the tempstore, so that the correct item can be read \\nfor each transaction. The tempstore items will be removed when no longer needed, \\nso a method to decide when to remove unneeded versions will be needed.\\nVariations of this method have been used in several commercial and open source \\nDBMSs, including Oracle and PostGRES. If the users require guaranteed serializ-\\nability, then the problems with anomalies that violate serializability will have to be \\nsolved by the programmers/software engineers by analyzing the set of transactions \\nto determine which types of anomalies can occur, and adding checks that do not \\npermit these anomalies. This can place a burden on the software developers when \\ncompared to the DBMS enforcing serializability in all cases.\\nVariations of snapshot isolation (SI) techniques, known as serializable snapshot \\nisolation (SSI), have been proposed and implemented in some of the DBMSs that \\nuse SI as their primary concurrency control method. For example, recent versions of \\nthe PostGRES DBMS allow the user to choose between basic SI and SSI. The tradeoff \\nis ensuring full serializability with SSI versus living with possible rare anomalies but \\nhaving better performance with basic SI. The interested reader is referred to the end-\\nof-chapter bibliography for more complete discussions of these topics.\\n21.5  Granularity of Data Items and  \\nMultiple Granularity Locking\\nAll concurrency control techniques assume that the database is formed of a number \\nof named data items. A database item could be chosen to be one of the following:\\n ■ A database record\\n ■ A field value of a database record\\n ■ A disk block\\n ■ A whole file\\n ■ The whole database'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 814, 'page_label': '815'}, page_content='21.5 Granularity of Data Items and Multiple Granularity Locking  801\\nThe particular choice of data item type can affect the performance of concurrency \\ncontrol and recovery. In Section 21.5.1, we discuss some of the tradeoffs with regard \\nto choosing the granularity level used for locking; and in Section 21.5.2, we discuss \\na multiple granularity locking scheme, where the granularity level (size of the data \\nitem) may be changed dynamically.\\n21.5.1 Granularity Level Considerations for Locking\\nThe size of data items is often called the data item granularity . Fine granularity  \\nrefers to small item sizes, whereas coarse granularity refers to large item sizes. Sev-\\neral tradeoffs must be considered in choosing the data item size. We will discuss \\ndata item size in the context of locking, although similar arguments can be made for \\nother concurrency control techniques.\\nFirst, notice that the larger the data item size is, the lower the degree of concurrency \\npermitted. For example, if the data item size is a disk block, a transaction T that \\nneeds to lock a single record B must lock the whole disk block X that contains B \\nbecause a lock is associated with the whole data item (block). Now, if another trans-\\naction S wants to lock a different record C that happens to reside in the same disk \\nblock X in a conflicting lock mode, it is forced to wait. If the data item size was a \\nsingle record instead of a disk block, transaction S would be able to proceed, because \\nit would be locking a different data item (record).\\nOn the other hand, the smaller the data item size is, the more the number of items \\nin the database. Because every item is associated with a lock, the system will have a \\nlarger number of active locks to be handled by the lock manager. More lock and \\nunlock operations will be performed, causing a higher overhead. In addition, more \\nstorage space will be required for the lock table. For timestamps, storage is required \\nfor the \\nread_TS and write_TS for each data item, and there will be similar overhead \\nfor handling a large number of items.\\nGiven the above tradeoffs, an obvious question can be asked: What is the best item \\nsize? The answer is that it depends on the types of transactions involved . If a typical \\ntransaction accesses a small number of records, it is advantageous to have the data \\nitem granularity be one record. On the other hand, if a transaction typically accesses \\nmany records in the same file, it may be better to have block or file granularity so \\nthat the transaction will consider all those records as one (or a few) data items.\\n21.5.2 Multiple Granularity Level Locking\\nSince the best granularity size depends on the given transaction, it seems appropri-\\nate that a database system should support multiple levels of granularity, where the \\ngranularity level can be adjusted dynamically for various mixes of transactions. Fig-\\nure 21.7 shows a simple granularity hierarchy with a database containing two files, \\neach file containing several disk pages, and each page containing several records. \\nThis can be used to illustrate a multiple granularity level  2PL protocol, with \\nshared/exclusive locking modes, where a lock can be requested at any level. How-\\never, additional types of locks will be needed to support such a protocol efficiently.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 815, 'page_label': '816'}, page_content='802 Chapter 21 Concurrency Control Techniques\\nConsider the following scenario, which refers to the example in Figure 21.7. Sup-\\npose transaction T1 wants to update all the records in file f1, and T1 requests and is \\ngranted an exclusive lock for f1. Then all of f1’s pages ( p11 through p1n)—and the \\nrecords contained on those pages—are locked in exclusive mode. This is beneficial \\nfor T\\n1 because setting a single file-level lock is more efficient than setting n page-\\nlevel locks or having to lock each record individually. Now suppose another trans-\\naction T\\n2 only wants to read record r1nj from page p1n of file f1; then T2 would \\nrequest a shared record-level lock on r1nj. However, the database system (that is, the \\ntransaction manager or, more specifically, the lock manager) must verify the com-\\npatibility of the requested lock with already held locks. One way to verify this is to \\ntraverse the tree from the leaf r\\n1nj to p1n to f1 to db. If at any time a conflicting lock \\nis held on any of those items, then the lock request for r1nj is denied and T2 is \\nblocked and must wait. This traversal would be fairly efficient.\\nHowever, what if transaction T2’s request came before transaction T1’s request? In \\nthis case, the shared record lock is granted to T2 for r1nj, but when T1’s file-level lock \\nis requested, it can be time-consuming for the lock manager to check all nodes \\n(pages and records) that are descendants of node f\\n1 for a lock conflict. This would \\nbe very inefficient and would defeat the purpose of having multiple granularity \\nlevel locks.\\nTo make multiple granularity level locking practical, additional types of locks, \\ncalled intention locks, are needed. The idea behind intention locks is for a transac-\\ntion to indicate, along the path from the root to the desired node, what type of lock \\n(shared or exclusive) it will require from one of the node’s descendants. There are \\nthree types of intention locks:\\n  1. Intention-shared (IS) indicates that one or more shared locks will be \\nrequested on some descendant node(s).\\n  2. Intention-exclusive (IX) indicates that one or more exclusive locks will be \\nrequested on some descendant node(s).\\ndb\\nr111 r11j r121 r12j r1n1 r1nj r211 r21k r221 r22k r2m1 r2mk. . . . . . . . .\\n. . .\\n. . . . . . . . . . . .\\n. . .\\n. . .\\np11 p12\\nf1\\np1n p21 p22 p2m\\nf2\\nFigure 21.7 \\nA granularity hierarchy for illustrating multiple granularity level locking.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 816, 'page_label': '817'}, page_content='21.5 Granularity of Data Items and Multiple Granularity Locking  803\\n  3. Shared-intention-exclusive (SIX) indicates that the current node is locked in \\nshared mode but that one or more exclusive locks will be requested on some \\ndescendant node(s).\\nThe compatibility table of the three intention locks, and the actual shared and \\nexclusive locks, is shown in Figure 21.8. In addition to the three types of intention \\nlocks, an appropriate locking protocol must be used. The multiple granularity \\nlocking (MGL) protocol consists of the following rules:\\n  1. The lock compatibility (based on Figure 21.8) must be adhered to.\\n  2. The root of the tree must be locked first, in any mode.\\n  3. A node N can be locked by a transaction T in S or IS mode only if the parent \\nnode N is already locked by transaction T in either IS or IX mode.\\n  4. A node N can be locked by a transaction T in X, IX, or SIX mode only if the \\nparent of node N is already locked by transaction T in either IX or SIX mode.\\n  5. A transaction T can lock a node only if it has not unlocked any node (to \\nenforce the 2PL protocol).\\n  6. A transaction T can unlock a node, N, only if none of the children of node N \\nare currently locked by T.\\nRule 1 simply states that conflicting locks cannot be granted. Rules 2, 3, and 4 state \\nthe conditions when a transaction may lock a given node in any of the lock modes. \\nRules 5 and 6 of the MGL protocol enforce 2PL rules to produce serializable sched-\\nules. Basically, the locking starts from the root  and goes down the tree until the \\nnode that needs to be locked is encountered, whereas unlocking starts from the \\nlocked node and goes up the tree until the root itself is unlocked. To illustrate the \\nMGL protocol with the database hierarchy in Figure 21.7, consider the following \\nthree transactions:\\n  1. T1 wants to update record r111 and record r211.\\n  2. T2 wants to update all records on page p12.\\n  3. T3 wants to read record r11j and the entire f2 file.\\nIS\\nIX\\nS\\nSIX\\nX\\nIS\\nYes\\nYes\\nYes\\nYes\\nNo\\nIX\\nYes\\nNo\\nYes\\nNo\\nNo\\nS\\nNo\\nYes\\nYes\\nNo\\nNo\\nSIX\\nNo\\nNo\\nYes\\nNo\\nNo\\nX\\nNo\\nNo\\nNo\\nNo\\nNo\\nFigure 21.8 \\nLock compatibility matrix for \\nmultiple granularity locking.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 817, 'page_label': '818'}, page_content='804 Chapter 21 Concurrency Control Techniques\\nFigure 21.9 shows a possible serializable schedule for these three transactions. \\nOnly the lock and unlock operations are shown. The notation < lock_type>(<item>) \\nis used to display the locking operations in the schedule.\\nThe multiple granularity level protocol is especially suited when processing a \\nmix of transactions that include (1) short transactions that access only a few \\nitems (records or fields) and (2) long transactions that access entire files. In \\nthis environment, less transaction blocking and less locking overhead are \\nincurred by such a protocol when compared to a single-level granularity lock-\\ning approach.\\nIX(db)\\nIX(f1)\\nT1\\nIX(p11)\\nX(r111)\\nIX(f2)\\nIX(p21)\\nX(p211)\\nunlock(r211)\\nunlock(p21)\\nunlock(f2)\\nunlock(r111)\\nunlock(p11)\\nunlock(f1)\\nunlock(db)\\nT3\\nIS(db)\\nIS(f1)\\nIS(p11)\\nS(r11j)\\nS(f2)\\nunlock(r11j)\\nunlock(p11)\\nunlock(f1)\\nunlock(f2)\\nunlock(db)\\nIX(db)\\nT2\\nIX(f1)\\nX(p12)\\nunlock(p12)\\nunlock(f1)\\nunlock(db)\\nFigure 21.9 \\nLock operations to \\nillustrate a serializable \\nschedule.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 818, 'page_label': '819'}, page_content='21.6 Using Locks for Concurrency Control in Indexes  805\\n21.6  Using Locks for Concurrency  \\nControl in Indexes\\nTwo-phase locking can also be applied to B-tree and B +-tree indexes (see Chap-\\nter\\xa019), where the nodes of an index correspond to disk pages. However, holding \\nlocks on index pages until the shrinking phase of 2PL could cause an undue \\namount of transaction blocking because searching an index always starts at the \\nroot. For example, if a transaction wants to insert a record (write operation), the \\nroot would be locked in exclusive mode, so all other conflicting lock requests for \\nthe index must wait until the transaction enters its shrinking phase. This blocks all \\nother transactions from accessing the index, so in practice other approaches to \\nlocking an index must be used.\\nThe tree structure of the index can be taken advantage of when developing a con-\\ncurrency control scheme. For example, when an index search (read operation) is \\nbeing executed, a path in the tree is traversed from the root to a leaf. Once a lower-\\nlevel node in the path has been accessed, the higher-level nodes in that path will not \\nbe used again. So once a read lock on a child node is obtained, the lock on the par-\\nent node can be released. When an insertion is being applied to a leaf node (that is, \\nwhen a key and a pointer are inserted), then a specific leaf node must be locked in \\nexclusive mode. However, if that node is not full, the insertion will not cause \\nchanges to higher-level index nodes, which implies that they need not be locked \\nexclusively.\\nA conservative approach for insertions would be to lock the root node in exclusive \\nmode and then to access the appropriate child node of the root. If the child node is \\nnot full, then the lock on the root node can be released. This approach can be \\napplied all the way down the tree to the leaf, which is typically three or four levels \\nfrom the root. Although exclusive locks are held, they are soon released. An alterna-\\ntive, more optimistic approach would be to request and hold shared locks on the \\nnodes leading to the leaf node, with an exclusive lock on the leaf. If the insertion \\ncauses the leaf to split, insertion will propagate to one or more higher-level nodes. \\nThen, the locks on the higher-level nodes can be upgraded to exclusive mode.\\nAnother approach to index locking is to use a variant of the B\\n+-tree, called the \\nB-link tree. In a B-link tree, sibling nodes on the same level are linked at every level. \\nThis allows shared locks to be used when requesting a page and requires that the \\nlock be released before accessing the child node. For an insert operation, the shared \\nlock on a node would be upgraded to exclusive mode. If a split occurs, the parent \\nnode must be relocked in exclusive mode. One complication is for search opera-\\ntions executed concurrently with the update. Suppose that a concurrent update \\noperation follows the same path as the search and inserts a new entry into the leaf \\nnode. Additionally, suppose that the insert causes that leaf node to split. When the \\ninsert is done, the search process resumes, following the pointer to the desired leaf, \\nonly to find that the key it is looking for is not present because the split has moved \\nthat key into a new leaf node, which would be the right sibling of the original leaf'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 819, 'page_label': '820'}, page_content='806 Chapter 21 Concurrency Control Techniques\\nnode. However, the search process can still succeed if it follows the pointer (link) in \\nthe original leaf node to its right sibling, where the desired key has been moved.\\nHandling the deletion case, where two or more nodes from the index tree merge, is \\nalso part of the B-link tree concurrency protocol. In this case, locks on the nodes to \\nbe merged are held as well as a lock on the parent of the two nodes to be merged.\\n21.7 Other Concurrency Control Issues\\nIn this section, we discuss some other issues relevant to concurrency control. In \\nSection 21.7.1, we discuss problems associated with insertion and deletion of \\nrecords and we revisit the phantom problem , which may occur when records are \\ninserted. This problem was described as a potential problem requiring a concur-\\nrency control measure in Section 20.6. In Section 21.7.2, we discuss problems that \\nmay occur when a transaction outputs some data to a monitor before it commits, \\nand then the transaction is later aborted.\\n21.7.1 Insertion, Deletion, and Phantom Records\\nWhen a new data item is inserted in the database, it obviously cannot be accessed \\nuntil after the item is created and the insert operation is completed. In a locking \\nenvironment, a lock for the item can be created and set to exclusive (write) mode; \\nthe lock can be released at the same time as other write locks would be released, \\nbased on the concurrency control protocol being used. For a timestamp-based pro-\\ntocol, the read and write timestamps of the new item are set to the timestamp of the \\ncreating transaction.\\nNext, consider a deletion operation  that is applied on an existing data item. For \\nlocking protocols, again an exclusive (write) lock must be obtained before the trans-\\naction can delete the item. For timestamp ordering, the protocol must ensure that no \\nlater transaction has read or written the item before allowing the item to be deleted.\\nA situation known as the phantom problem can occur when a new record that is \\nbeing inserted by some transaction T satisfies a condition that a set of records \\naccessed by another transaction T′ must satisfy. For example, suppose that transac-\\ntion T is inserting a new \\nEMPLOYEE record whose Dno = 5, whereas transaction T′ \\nis accessing all EMPLOYEE records whose Dno = 5 (say, to add up all their Salary \\nvalues to calculate the personnel budget for department 5). If the equivalent serial \\norder is T followed by T′, then T′ must read the new \\nEMPLOYEE record and include \\nits Salary in the sum calculation. For the equivalent serial order T′ followed by T, the \\nnew salary should not be included. Notice that although the transactions logically \\nconflict, in the latter case there is really no record (data item) in common between \\nthe two transactions, since T′ may have locked all the records with \\nDno = 5 before T \\ninserted the new record. This is because the record that causes the conflict is a \\nphantom record that has suddenly appeared in the database on being inserted. If \\nother operations in the two transactions conflict, the conflict due to the phantom \\nrecord may not be recognized by the concurrency control protocol.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 820, 'page_label': '821'}, page_content='21.8 Summary  807\\nOne solution to the phantom record problem is to use index locking, as discussed \\nin Section 21.6. Recall from Chapter 19 that an index includes entries that have an \\nattribute value plus a set of pointers to all records in the file with that value. For \\nexample, an index on \\nDno of EMPLOYEE would include an entry for each distinct \\nDno value plus a set of pointers to all EMPLOYEE records with that value. If the index \\nentry is locked before the record itself can be accessed, then the conflict on the \\nphantom record can be detected, because transaction T′ would request a read lock \\non the index entry for \\nDno = 5, and T would request a write lock on the same entry \\nbefore it could place the locks on the actual records. Since the index locks conflict, \\nthe phantom conflict would be detected.\\nA more general technique, called predicate locking, would lock access to all records \\nthat satisfy an arbitrary predicate (condition) in a similar manner; however, predi-\\ncate locks have proved to be difficult to implement efficiently. If the concurrency \\ncontrol method is based on snapshot isolation (see Section 21.4.2), then the trans-\\naction that reads the items will access the database snapshot at the time the transac-\\ntion starts; any records inserted after that will not be retrieved by the transaction.\\n21.7.2 Interactive Transactions\\nAnother problem occurs when interactive transactions read input and write output \\nto an interactive device, such as a monitor screen, before they are committed. The \\nproblem is that a user can input a value of a data item to a transaction T that is \\nbased on some value written to the screen by transaction T′, which may not have \\ncommitted. This dependency between T and T′ cannot be modeled by the system \\nconcurrency control method, since it is only based on the user interacting with the \\ntwo transactions.\\nAn approach to dealing with this problem is to postpone output of transactions to \\nthe screen until they have committed.\\n21.7.3 Latches\\nLocks held for a short duration are typically called latches. Latches do not follow \\nthe usual concurrency control protocol such as two-phase locking. For example, a \\nlatch can be used to guarantee the physical integrity of a disk page when that page is \\nbeing written from the buffer to disk. A latch would be acquired for the page, the \\npage written to disk, and then the latch released.\\n21.8 Summary\\nIn this chapter, we discussed DBMS techniques for concurrency control. We \\nstarted in Section 21.1 by discussing lock-based protocols, which are commonly \\nused in practice. In Section 21.1.2 we described the two-phase locking (2PL) pro-\\ntocol and a number of its variations: basic 2PL, strict 2PL, conservative 2PL, and \\nrigorous 2PL. The strict and rigorous variations are more common because of'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 821, 'page_label': '822'}, page_content='808 Chapter 21 Concurrency Control Techniques\\ntheir better recoverability properties. We introduced the concepts of shared (read) \\nand exclusive (write) locks (Section 21.1.1) and showed how locking can guarantee \\nserializability when used in conjunction with the two-phase locking rule. We also \\npresented various techniques for dealing with the deadlock problem in Sec-\\ntion\\xa021.1.3, which can occur with locking. In practice, it is common to use time-\\nouts and deadlock detection (wait-for graphs). Deadlock prevention protocols, \\nsuch as no waiting and cautious waiting, can also be used.\\nWe then presented other concurrency control protocols. These include the time-\\nstamp ordering protocol (Section 21.2), which ensures serializability based on the \\norder of transaction timestamps. Timestamps are unique, system-generated trans-\\naction identifiers. We discussed Thomas’s write rule, which improves performance \\nbut does not guarantee serializability. The strict timestamp ordering protocol was \\nalso presented. We discussed two multiversion protocols (Section 21.3), which \\nassume that older versions of data items can be kept in the database. One tech-\\nnique, called multiversion two-phase locking (which has been used in practice), \\nassumes that two versions can exist for an item and attempts to increase concur-\\nrency by making write and read locks compatible (at the cost of introducing an \\nadditional certify lock mode). We also presented a multiversion protocol based on \\ntimestamp ordering. In Section 21.4.1, we presented an example of an optimistic \\nprotocol, which is also known as a certification or validation protocol.\\nWe then discussed concurrency control methods that are based on the concept of \\nsnapshot isolation in Section 21.4.2; these are used in several DBMSs because of \\ntheir lower overhead. The basic snapshot isolation method can allow nonserializ-\\nable schedules in rare cases because of certain anomalies that are difficult to detect; \\nthese anomalies may cause a corrupted database. A variation known as serializable \\nsnapshot isolation has been recently developed and ensures serializable schedules.\\nThen in Section 21.5 we turned our attention to the important practical issue of \\ndata item granularity. We described a multigranularity locking protocol that \\nallows the change of granularity (item size) based on the current transaction \\nmix, with the goal of improving the performance of concurrency control. An \\nimportant practical issue was then presented in Section 21.6, which is to develop \\nlocking protocols for indexes so that indexes do not become a hindrance to con-\\ncurrent access. Finally, in Section 21.7, we introduced the phantom problem and \\nproblems with interactive transactions, and we briefly described the concept of \\nlatches and how this concept differs from locks.\\nReview Questions\\n 21.1. What is the two-phase locking protocol? How does it guarantee serializability?\\n 21.2. What are some variations of the two-phase locking protocol? Why is strict \\nor rigorous two-phase locking often preferred?\\n 21.3. Discuss the problems of deadlock and starvation, and the different \\napproaches to dealing with these problems.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 822, 'page_label': '823'}, page_content='Exercises 809\\n 21.4. Compare binary locks to exclusive/shared locks. Why is the latter type of \\nlocks preferable?\\n 21.5. Describe the wait-die and wound-wait protocols for deadlock prevention.\\n 21.6. Describe the cautious waiting, no waiting, and timeout protocols for dead-\\nlock prevention.\\n 21.7. What is a timestamp? How does the system generate timestamps?\\n 21.8. Discuss the timestamp ordering protocol for concurrency control. How \\ndoes strict timestamp ordering differ from basic timestamp ordering?\\n 21.9. Discuss two multiversion techniques for concurrency control. What is a cer-\\ntify lock? What are the advantages and disadvantages of using certify locks?\\n 21.10. How do optimistic concurrency control techniques differ from other con-\\ncurrency control techniques? Why are they also called validation or certifi-\\ncation techniques? Discuss the typical phases of an optimistic concurrency \\ncontrol method.\\n 21.11. What is snapshot isolation? What are the advantages and disadvantages of \\nconcurrency control methods that are based on snapshot isolation?\\n 21.12. How does the granularity of data items affect the performance of concurrency \\ncontrol? What factors affect selection of granularity size for data items?\\n 21.13. What type of lock is needed for insert and delete operations?\\n 21.14. What is multiple granularity locking? Under what circumstances is it used?\\n 21.15. What are intention locks?\\n 21.16. When are latches used?\\n 21.17. What is a phantom record? Discuss the problem that a phantom record can \\ncause for concurrency control.\\n 21.18. How does index locking resolve the phantom problem?\\n 21.19. What is a predicate lock?\\nExercises\\n 21.20. Prove that the basic two-phase locking protocol guarantees conflict serializ-\\nability of schedules. (Hint: Show that if a serializability graph for a schedule \\nhas a cycle, then at least one of the transactions participating in the schedule \\ndoes not obey the two-phase locking protocol.)\\n 21.21. Modify the data structures for multiple-mode locks and the algorithms for \\nread_lock(X), write_lock(X), and unlock(X) so that upgrading and downgrad-\\ning of locks are possible. (Hint: The lock needs to check the transaction id(s) \\nthat hold the lock, if any.)'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 823, 'page_label': '824'}, page_content='810 Chapter 21 Concurrency Control Techniques\\n 21.22. Prove that strict two-phase locking guarantees strict schedules.\\n 21.23. Prove that the wait-die and wound-wait protocols avoid deadlock and \\nstarvation.\\n 21.24. Prove that cautious waiting avoids deadlock.\\n 21.25. Apply the timestamp ordering algorithm to the schedules in Figures 21.8(b) \\nand (c), and determine whether the algorithm will allow the execution of the \\nschedules.\\n 21.26. Repeat Exercise 21.25, but use the multiversion timestamp ordering method.\\n 21.27. Why is two-phase locking not used as a concurrency control method for \\nindexes such as B+-trees?\\n 21.28. The compatibility matrix in Figure 21.8 shows that IS and IX locks are com-\\npatible. Explain why this is valid.\\n 21.29. The MGL protocol states that a transaction T can unlock a node N, only if \\nnone of the children of node N are still locked by transaction T. Show that \\nwithout this condition, the MGL protocol would be incorrect.\\nSelected Bibliography\\nThe two-phase locking protocol and the concept of predicate locks were first pro-\\nposed by Eswaran et al. (1976). Bernstein et al. (1987), Gray and Reuter (1993), and \\nPapadimitriou (1986) focus on concurrency control and recovery. Kumar (1996) \\nfocuses on performance of concurrency control methods. Locking is discussed in \\nGray et al. (1975), Lien and Weinberger (1978), Kedem and Silbershatz (1980), and \\nKorth (1983). Deadlocks and wait-for graphs were formalized by Holt (1972), and \\nthe wait-wound and wound-die schemes are presented in Rosenkrantz et al. (1978). \\nCautious waiting is discussed in Hsu and Zhang (1992). Helal et al. (1993) com-\\npares various locking approaches.\\nTimestamp-based concurrency control techniques are discussed in Bernstein and \\nGoodman (1980) and Reed (1983). Optimistic concurrency control is discussed in \\nKung and Robinson (1981) and Bassiouni (1988). Papadimitriou and Kanellakis \\n(1979) and Bernstein and Goodman (1983) discuss multiversion techniques. Multi-\\nversion timestamp ordering was proposed in Reed (1979, 1983), and multiversion \\ntwo-phase locking is discussed in Lai and Wilkinson (1984). A method for multiple \\nlocking granularities was proposed in Gray et al. (1975), and the effects of locking \\ngranularities are analyzed in Ries and Stonebraker (1977). Bhargava and Reidl \\n(1988) presents an approach for dynamically choosing among various concurrency \\ncontrol and recovery methods. Concurrency control methods for indexes are pre-\\nsented in Lehman and Yao (1981) and in Shasha and Goodman (1988). A perfor-\\nmance study of various B\\n+-tree concurrency control algorithms is presented in \\nSrinivasan and Carey (1991).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 824, 'page_label': '825'}, page_content='Selected Bibliography 811\\nAnomalies that can occur with basic snapshot isolation are discussed in Fekete \\net al. (2004), Jorwekar et al. (2007), and Ports and Grittner (2012), among \\n others. Modifying snapshot isolation to make it serializable is discussed in \\nCahill et al. (2008), Fekete et al. (2005), Revilak et al. (2011), and Ports and \\nGrittner (2012).\\nOther work on concurrency control includes semantic-based concurrency \\ncontrol (Badrinath & Ramamritham, 1992), transaction models for long- \\nrunning activities (Dayal et al., 1991), and multilevel transaction management \\n(Hasse & Weikum, 1991).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 825, 'page_label': '826'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 826, 'page_label': '827'}, page_content='813\\n22\\nDatabase Recovery Techniques\\nI\\nn this chapter, we discuss some of the techniques that \\ncan be used for database recovery in case of system \\nfailure. In Section 20.1.4 we discussed the different causes of failure, such as system \\ncrashes and transaction errors. In Section 20.2, we introduced some of the concepts \\nthat are used by recovery processes, such as the system log and commit points.\\nThis chapter presents additional concepts that are relevant to recovery protocols \\nand provides an overview of the various database recovery algorithms. We start \\nin Section 22.1 with an outline of a typical recovery procedure and a categoriza-\\ntion of recovery algorithms, and then we discuss several recovery concepts, \\nincluding write-ahead logging, in-place versus shadow updates, and the process \\nof rolling back (undoing) the effect of an incomplete or failed transaction. In Sec-\\ntion 22.2, we present recovery techniques based on deferred update,  also known \\nas the \\nNO-UNDO/REDO  technique, where the data on disk is not updated until \\nafter a transaction commits. In Section 22.3, we discuss recovery techniques based \\non immediate update , where data can be updated on disk during transaction exe-\\ncution; these include the UNDO/REDO and UNDO/NO-REDO  algorithms. In Sec-\\ntion 22.4, we discuss the technique known as shadowing or shadow paging, which \\ncan be categorized as a \\nNO-UNDO/NO-REDO  algorithm. An example of a practical \\nDBMS recovery scheme, called ARIES, is presented in Section 22.5. Recovery in \\nmultidatabases is briefly discussed in Section 22.6. Finally, techniques for recov-\\nery from catastrophic failure are discussed in Section 22.7. Section 22.8 summa-\\nrizes the chapter.\\nOur emphasis is on conceptually describing several different approaches to recov-\\nery. For descriptions of recovery features in specific systems, the reader should con-\\nsult the bibliographic notes at the end of the chapter and the online and printed \\nuser manuals for those systems. Recovery techniques are often intertwined with the \\nconcurrency control mechanisms. Certain recovery techniques are best used with \\nchapter 22'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 827, 'page_label': '828'}, page_content='814 Chapter 22 Database Recovery Techniques\\nspecific concurrency control methods. We will discuss recovery concepts indepen-\\ndently of concurrency control mechanisms.\\n22.1 Recovery Concepts\\n22.1.1  Recovery Outline and Categorization  \\nof Recovery Algorithms\\nRecovery from transaction failures usually means that the database is restored to \\nthe most recent consistent state before the time of failure. To do this, the system \\nmust keep information about the changes that were applied to data items by the \\nvarious transactions. This information is typically kept in the system log , as we \\ndiscussed in Section 21.2.2. A typical strategy for recovery may be summarized \\ninformally as follows:\\n  1. If there is extensive damage to a wide portion of the database due to cata-\\nstrophic failure, such as a disk crash, the recovery method restores a past \\ncopy of the database that was backed up to archival storage (typically tape or \\nother large capacity offline storage media) and reconstructs a more current \\nstate by reapplying or redoing the operations of committed transactions \\nfrom the backed-up log, up to the time of failure.\\n  2. When the database on disk is not physically damaged, and a noncatastrophic \\nfailure of types 1 through 4 in Section 21.1.4 has occurred, the recovery \\nstrategy is to identify any changes that may cause an inconsistency in the \\ndatabase. For example, a transaction that has updated some database items \\non disk but has not been committed needs to have its changes reversed by \\nundoing its write operations. It may also be necessary to redo some opera-\\ntions in order to restore a consistent state of the database; for example, if a \\ntransaction has committed but some of its write operations have not yet \\nbeen written to disk. For noncatastrophic failure, the recovery protocol does \\nnot need a complete archival copy of the database. Rather, the entries kept in \\nthe online system log on disk are analyzed to determine the appropriate \\nactions for recovery.\\nConceptually, we can distinguish two main policies for recovery from non-\\ncatastrophic transaction failures: deferred update and immediate update. The \\ndeferred update techniques do not physically update the database on disk until after \\na transaction commits; then the updates are recorded in the database. Before reach-\\ning commit, all transaction updates are recorded in the local transaction workspace \\nor in the main memory buffers that the DBMS maintains (the DBMS main memory \\ncache; see Section 20.2.4). Before commit, the updates are recorded persistently in \\nthe log file on disk, and then after commit, the updates are written to the database \\nfrom the main memory buffers. If a transaction fails before reaching its commit \\npoint, it will not have changed the database on disk in any way, so \\nUNDO is not \\nneeded. It may be necessary to REDO the effect of the operations of a committed'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 828, 'page_label': '829'}, page_content='22.1 Recovery Concepts  815\\ntransaction from the log, because their effect may not yet have been recorded in the \\ndatabase on disk. Hence, deferred update is also known as the NO-UNDO/REDO  \\nalgorithm. We discuss this technique in Section 22.2.\\nIn the immediate update techniques, the database may be updated by some opera-\\ntions of a transaction before the transaction reaches its commit point. However, \\nthese operations must also be recorded in the log on disk by force-writing before \\nthey are applied to the database on disk, making recovery still possible. If a trans-\\naction fails after recording some changes in the database on disk but before reach-\\ning its commit point, the effect of its operations on the database must be undone; \\nthat is, the transaction must be rolled back. In the general case of immediate \\nupdate, both undo and redo may be required during recovery. This technique, \\nknown as the \\nUNDO/REDO algorithm, requires both operations during recovery \\nand is used most often in practice. A variation of the algorithm where all updates \\nare required to be recorded in the database on disk before a transaction commits \\nrequires undo only, so it is known as the \\nUNDO/NO-REDO algorithm. We discuss \\nthese two techniques in Section 22.3.\\nThe UNDO and REDO operations are required to be idempotent—that is, executing \\nan operation multiple times is equivalent to executing it just once. In fact, the whole \\nrecovery process should be idempotent because if the system were to fail during the \\nrecovery process, the next recovery attempt might UNDO and REDO certain  \\nwrite_item operations that had already been executed during the first recovery pro-\\ncess. The result of recovery from a system crash during recovery should be the same \\nas the result of recovering when there is no crash during recovery!\\n22.1.2 Caching (Buffering) of Disk Blocks\\nThe recovery process is often closely intertwined with operating system func-\\ntions—in particular, the buffering of database disk pages in the DBMS main \\nmemory cache. Typically, multiple disk pages that include the data items to be \\nupdated are cached  into main memory buffers and then updated in memory \\nbefore being written back to disk. The caching of disk pages is traditionally an \\noperating system function, but because of its importance to the efficiency of \\nrecovery procedures, it is handled by the DBMS by calling low-level operating \\nsystems routines (see Section 20.2.4).\\nIn general, it is convenient to consider recovery in terms of the database disk pages \\n(blocks). Typically a collection of in-memory buffers, called the DBMS cache , is \\nkept under the control of the DBMS for the purpose of holding these buffers. A \\ndirectory for the cache is used to keep track of which database items are in the buf-\\nfers.\\n1 This can be a table of < Disk_page_address, Buffer_location, … > entries. When \\nthe DBMS requests action on some item, first it checks the cache directory to deter-\\nmine whether the disk page containing the item is in the DBMS cache. If it is not, \\n1This is somewhat similar to the concept of page tables used by the operating system.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 829, 'page_label': '830'}, page_content='816 Chapter 22 Database Recovery Techniques\\nthe item must be located on disk, and the appropriate disk pages are copied into the \\ncache. It may be necessary to replace (or flush) some of the cache buffers to make \\nspace available for the new item (see Section 20.2.4).\\nThe entries in the DBMS cache directory hold additional information relevant to \\nbuffer management. Associated with each buffer in the cache is a dirty bit, which \\ncan be included in the directory entry to indicate whether or not the buffer has been \\nmodified. When a page is first read from the database disk into a cache buffer, a new \\nentry is inserted in the cache directory with the new disk page address, and the dirty \\nbit is set to 0 (zero). As soon as the buffer is modified, the dirty bit for the corre-\\nsponding directory entry is set to 1 (one). Additional information, such as the trans-\\naction id(s) of the transaction(s) that modified the buffer, are also kept in the \\ndirectory. When the buffer contents are replaced (flushed) from the cache, the con-\\ntents must first be written back to the corresponding disk page only if its dirty bit is 1.\\nAnother bit, called the pin-unpin bit, is also needed—a page in the cache is pinned \\n(bit value 1 (one)) if it cannot be written back to disk as yet. For example, the recov-\\nery protocol may restrict certain buffer pages from being written back to the disk \\nuntil the transactions that changed this buffer have committed.\\nTwo main strategies can be employed when flushing a modified buffer back to disk. \\nThe first strategy, known as in-place updating, writes the buffer to the same origi-\\nnal disk location, thus overwriting the old value of any changed data items on disk.\\n2 \\nHence, a single copy of each database disk block is maintained. The second strategy, \\nknown as shadowing, writes an updated buffer at a different disk location, so mul-\\ntiple versions of data items can be maintained, but this approach is not typically \\nused in practice.\\nIn general, the old value of the data item before updating is called the before image \\n(BFIM), and the new value after updating is called the after image (AFIM). If shad-\\nowing is used, both the BFIM and the AFIM can be kept on disk; hence, it is not \\nstrictly necessary to maintain a log for recovering. We briefly discuss recovery \\nbased on shadowing in Section 22.4.\\n22.1.3  Write-Ahead Logging, Steal/No-Steal,  \\nand Force/No-Force\\nWhen in-place updating is used, it is necessary to use a log for recovery (see Sec-\\ntion\\xa021.2.2). In this case, the recovery mechanism must ensure that the BFIM of the \\ndata item is recorded in the appropriate log entry and that the log entry is flushed to \\ndisk before the BFIM is overwritten with the AFIM in the database on disk. This \\nprocess is generally known as write-ahead logging  and is necessary so we can \\nUNDO the operation if this is required during recovery. Before we can describe a \\nprotocol for write-ahead logging, we need to distinguish between two types of log \\nentry information included for a write command: the information needed for \\nUNDO \\n2In-place updating is used in most systems in practice.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 830, 'page_label': '831'}, page_content='22.1 Recovery Concepts  817\\nand the information needed for REDO. A REDO-type log entry  includes the new \\nvalue (AFIM) of the item written by the operation since this is needed to redo the \\neffect of the operation from the log (by setting the item value in the database on \\ndisk to its AFIM). The \\nUNDO-type log entries include the old value (BFIM) of the \\nitem since this is needed to undo the effect of the operation from the log (by setting \\nthe item value in the database back to its BFIM). In an UNDO/REDO algorithm, both \\nBFIM and AFIM are recorded into a single log entry. Additionally, when cascading \\nrollback (see Section 22.1.5) is possible, \\nread_item entries in the log are considered to \\nbe UNDO-type entries.\\nAs mentioned, the DBMS cache holds the cached database disk blocks in main \\nmemory buffers. The DBMS cache includes not only data file blocks, but also index \\nfile blocks and log file blocks from the disk. When a log record is written, it is stored \\nin the current log buffer in the DBMS cache. The log is simply a sequential (append-\\nonly) disk file, and the DBMS cache may contain several log blocks in main mem-\\nory buffers (typically, the last n log blocks of the log file). When an update to a data \\nblock—stored in the DBMS cache—is made, an associated log record is written to \\nthe last log buffer in the DBMS cache. With the write-ahead logging approach, the \\nlog buffers (blocks) that contain the associated log records for a particular data \\nblock update must first be written to disk before the data block itself can be written \\nback to disk from its main memory buffer.\\nStandard DBMS recovery terminology includes the terms steal/no-steal  and  \\nforce/no-force, which specify the rules that govern when a page from the database \\ncache can be written to disk:\\n  1. If a cache buffer page updated by a transaction cannot be written to disk before \\nthe transaction commits, the recovery method is called a no-steal approach. \\nThe pin-unpin bit will be set to 1 (pin) to indicate that a cache buffer cannot be \\nwritten back to disk. On the other hand, if the recovery protocol allows writing \\nan updated buffer before the transaction commits, it is called steal. Steal is \\nused when the DBMS cache (buffer) manager needs a buffer frame for another \\ntransaction and the buffer manager replaces an existing page that had been \\nupdated but whose transaction has not committed. The no-steal rule means \\nthat \\nUNDO will never be needed during recovery, since a committed transac-\\ntion will not have any of its updates on disk before it commits.\\n  2. If all pages updated by a transaction are immediately written to disk before \\nthe transaction commits, the recovery approach is called a force approach. \\nOtherwise, it is called no-force. The force rule means that REDO will never \\nbe needed during recovery, since any committed transaction will have all its \\nupdates on disk before it is committed.\\nThe deferred update (NO-UNDO) recovery scheme discussed in Section 22.2 follows \\na no-steal approach. However, typical database systems employ a steal/no-force  \\n(UNDO/REDO) strategy. The advantage of steal is that it avoids the need for a very \\nlarge buffer space to store all updated pages in memory. The advantage of no-force \\nis that an updated page of a committed transaction may still be in the buffer when'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 831, 'page_label': '832'}, page_content='818 Chapter 22 Database Recovery Techniques\\nanother transaction needs to update it, thus eliminating the I/O cost to write that \\npage multiple times to disk and possibly having to read it again from disk. This may \\nprovide a substantial saving in the number of disk I/O operations when a specific \\npage is updated heavily by multiple transactions.\\nTo permit recovery when in-place updating is used, the appropriate entries required \\nfor recovery must be permanently recorded in the log on disk before changes are \\napplied to the database. For example, consider the following write-ahead logging \\n(WAL) protocol for a recovery algorithm that requires both \\nUNDO and REDO:\\n  1. The before image of an item cannot be overwritten by its after image in the \\ndatabase on disk until all UNDO-type log entries for the updating transaction—\\nup to this point—have been force-written to disk.\\n  2. The commit operation of a transaction cannot be completed until all the \\nREDO-type and UNDO-type log records for that transaction have been force-\\nwritten to disk.\\nTo facilitate the recovery process, the DBMS recovery subsystem may need to \\nmaintain a number of lists related to the transactions being processed in the system. \\nThese include a list for active transactions that have started but not committed as \\nyet, and they may also include lists of all committed and aborted transactions  \\nsince the last checkpoint (see the next section). Maintaining these lists makes the \\nrecovery process more efficient.\\n22.1.4  Checkpoints in the System Log  \\nand Fuzzy Checkpointing\\nAnother type of entry in the log is called a checkpoint.3 A [checkpoint, list of active \\ntransactions] record is written into the log periodically at that point when the system \\nwrites out to the database on disk all DBMS buffers that have been modified. As a \\nconsequence of this, all transactions that have their \\n[commit, T ] entries in the log \\nbefore a [checkpoint] entry do not need to have their WRITE operations redone in \\ncase of a system crash, since all their updates will be recorded in the database on \\ndisk during checkpointing. As part of checkpointing, the list of transaction ids for \\nactive transactions at the time of the checkpoint is included in the checkpoint \\nrecord, so that these transactions can be easily identified during recovery.\\nThe recovery manager of a DBMS must decide at what intervals to take a check-\\npoint. The interval may be measured in time—say, every m minutes—or in the \\nnumber t of committed transactions since the last checkpoint, where the values of \\nm or t are system parameters. Taking a checkpoint consists of the following actions:\\n  1. Suspend execution of transactions temporarily.\\n  2. Force-write all main memory buffers that have been modified to disk.\\n3The term checkpoint has been used to describe more restrictive situations in some systems, such as \\nDB2. It has also been used in the literature to describe entirely different concepts.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 832, 'page_label': '833'}, page_content='22.1 Recovery Concepts  819\\n  3. Write a [checkpoint] record to the log, and force-write the log to disk.\\n  4. Resume executing transactions.\\nAs a consequence of step 2, a checkpoint record in the log may also include addi-\\ntional information, such as a list of active transaction ids, and the locations \\n(addresses) of the first and most recent (last) records in the log for each active \\ntransaction. This can facilitate undoing transaction operations in the event that a \\ntransaction must be rolled back.\\nThe time needed to force-write all modified memory buffers may delay transaction \\nprocessing because of step 1, which is not acceptable in practice. To overcome this, \\nit is common to use a technique called fuzzy checkpointing. In this technique, the \\nsystem can resume transaction processing after a \\n[begin_checkpoint] record is writ-\\nten to the log without having to wait for step 2 to finish. When step 2 is completed, \\nan \\n[end_checkpoint, … ]  record is written in the log with the relevant information \\ncollected during checkpointing. However, until step 2 is completed, the previous \\ncheckpoint record should remain valid. To accomplish this, the system maintains a \\nfile on disk that contains a pointer to the valid checkpoint, which continues to point \\nto the previous checkpoint record in the log. Once step 2 is concluded, that pointer \\nis changed to point to the new checkpoint in the log.\\n22.1.5 Transaction Rollback and Cascading Rollback\\nIf a transaction fails for whatever reason after updating the database, but before the \\ntransaction commits, it may be necessary to roll back the transaction. If any data \\nitem values have been changed by the transaction and written to the database on \\ndisk, they must be restored to their previous values (BFIMs). The undo-type log \\nentries are used to restore the old values of data items that must be rolled back.\\nIf a transaction T is rolled back, any transaction S that has, in the interim, read the \\nvalue of some data item X written by T must also be rolled back. Similarly, once S is \\nrolled back, any transaction R that has read the value of some data item Y written by \\nS must also be rolled back; and so on. This phenomenon is called cascading \\n rollback, and it can occur when the recovery protocol ensures recoverable schedules \\nbut does not ensure strict or cascadeless schedules (see Section 20.4.2). Understand-\\nably, cascading rollback can be complex and time-consuming. That is why almost all \\nrecovery mechanisms are designed so that cascading rollback is never required.\\nFigure 22.1 shows an example where cascading rollback is required. The read and \\nwrite operations of three individual transactions are shown in Figure 22.1(a). Fig-\\nure\\xa022.1(b) shows the system log at the point of a system crash for a particular execution \\nschedule of these transactions. The values of data items A, B, C, and D, which are used \\nby the transactions, are shown to the right of the system log entries. We assume that the \\noriginal item values, shown in the first line, are A = 30, B = 15, C = 40, and D = 20. At the \\npoint of system failure, transaction T\\n3 has not reached its conclusion and must be rolled \\nback. The WRITE operations of T3, marked by a single * in Figure 22.1(b), are the T3 \\noperations that are undone during transaction rollback. Figure 22.1(c) graphically \\nshows the operations of the different transactions along the time axis.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 833, 'page_label': '834'}, page_content='820 Chapter 22 Database Recovery Techniques\\n(a)\\n(b)\\n*\\n**\\n**\\n[start_transaction,T3]\\n[read_item,T3,C]\\n[write_item,T3,B,15,12]\\n[start_transaction,T2]\\n[read_item,T2,B]\\n[write_item,T2,B,12,18]\\n[write_item,T1,D,20,25]\\n[write_item,T2,D,25,26]\\n[start_transaction,T1]\\n[read_item,T1,A]\\n[read_item,T1,D]\\n[read_item,T2,D]\\n[read_item,T3,A]\\n* T3 is rolled back because it \\ndid not reach its commit point.\\n** T2 is rolled back because it \\nreads the value of item B written by T3.\\nread_item(A)\\nread_item(D)\\nwrite_item(D)\\nread_item(B)\\nwrite_item(B)\\nread_item(D)\\nwrite_item(D)\\nSystem crash\\nT3T2T1\\nread_item(C)\\nwrite_item(B)\\nread_item(A)\\nwrite_item(A)\\nA\\n30\\nB\\n15\\n12\\n18\\nC\\n40\\nD\\n20\\n25\\n26\\n(c) READ(C)\\nBEGIN\\nREAD(A)WRITE(B)\\nT3\\nREAD(B)\\nBEGIN\\nWRITE(D)READ(D)WRITE(B)\\nREAD(A)\\nBEGIN\\nSystem crash\\nTime\\nREAD(D) WRITE(D)\\nT2\\nT1\\nFigure 22.1 \\nIllustrating cascading rollback \\n(a process that never occurs \\nin strict or cascadeless  \\nschedules). (a) The read and \\nwrite operations of three \\ntransactions. (b) System log at \\npoint of crash. (c) Operations \\nbefore the crash.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 834, 'page_label': '835'}, page_content='22.2 NO-UNDO/REDO Recovery Based on Deferred Update  821\\nWe must now check for cascading rollback. From Figure 22.1(c), we see that trans-\\naction T2 reads the value of item B that was written by transaction T3; this can also \\nbe determined by examining the log. Because T3 is rolled back, T2 must now be \\nrolled back, too. The WRITE operations of T2, marked by ** in the log, are the ones \\nthat are undone. Note that only write_item operations need to be undone during \\ntransaction rollback; read_item operations are recorded in the log only to determine \\nwhether cascading rollback of additional transactions is necessary.\\nIn practice, cascading rollback of transactions is never required because practical \\nrecovery methods guarantee cascadeless or strict  schedules. Hence, there is also no \\nneed to record any read_item operations in the log because these are needed only for \\ndetermining cascading rollback.\\n22.1.6 Transaction Actions That Do Not Affect the Database\\nIn general, a transaction will have actions that do not affect the database, such as \\ngenerating and printing messages or reports from information retrieved from the \\ndatabase. If a transaction fails before completion, we may not want the user to get \\nthese reports, since the transaction has failed to complete. If such erroneous reports \\nare produced, part of the recovery process would have to inform the user that these \\nreports are wrong, since the user may take an action that is based on these reports \\nand that affects the database. Hence, such reports should be generated only after the \\ntransaction reaches its commit point.  A common method of dealing with such \\nactions is to issue the commands that generate the reports but keep them as batch \\njobs, which are executed only after the transaction reaches its commit point. If the \\ntransaction fails, the batch jobs are canceled.\\n22.2  NO-UNDO/REDO Recovery Based  \\non Deferred Update\\nThe idea behind deferred update is to defer or postpone any actual updates to the \\ndatabase on disk until the transaction completes its execution successfully and \\nreaches its commit point.4\\nDuring transaction execution, the updates are recorded only in the log and in the \\ncache buffers. After the transaction reaches its commit point and the log is force-\\nwritten to disk, the updates are recorded in the database. If a transaction fails before \\nreaching its commit point, there is no need to undo any operations because the \\ntransaction has not affected the database on disk in any way. Therefore, only \\nREDO-\\ntype log entries are needed in the log, which include the new value (AFIM) of the \\nitem written by a write operation. The UNDO-type log entries are not needed since \\nno undoing of operations will be required during recovery. Although this may sim-\\nplify the recovery process, it cannot be used in practice unless transactions are short \\nand each transaction changes few items. For other types of transactions, there is the \\npotential for running out of buffer space because transaction changes must be held \\n4Hence deferred update can generally be characterized as a no-steal approach.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 835, 'page_label': '836'}, page_content='822 Chapter 22 Database Recovery Techniques\\nin the cache buffers until the commit point, so many cache buffers will be pinned \\nand cannot be replaced.\\nWe can state a typical deferred update protocol as follows:\\n  1. A transaction cannot change the database on disk until it reaches its commit \\npoint; hence all buffers that have been changed by the transaction must be \\npinned until the transaction commits (this corresponds to a no-steal policy).\\n  2. A transaction does not reach its commit point until all its REDO-type log \\nentries are recorded in the log and the log buffer is force-written to disk.\\nNotice that step 2 of this protocol is a restatement of the write-ahead logging (WAL) \\nprotocol. Because the database is never updated on disk until after the transaction \\ncommits, there is never a need to \\nUNDO any operations. REDO is needed in case the \\nsystem fails after a transaction commits but before all its changes are recorded in \\nthe database on disk. In this case, the transaction operations are redone from the \\nlog entries during recovery.\\nFor multiuser systems with concurrency control, the concurrency control and \\nrecovery processes are interrelated. Consider a system in which concurrency con-\\ntrol uses strict two-phase locking, so the locks on written items remain in effect \\nuntil the transaction reaches its commit point.  After that, the locks can be released. \\nThis ensures strict and serializable schedules. Assuming that \\n[checkpoint] entries are \\nincluded in the log, a possible recovery algorithm for this case, which we call RDU_M \\n(Recovery using Deferred Update in a Multiuser environment), is given next.\\nProcedure RDU_M (NO-UNDO/REDO with checkpoints). Use two lists of trans-\\nactions maintained by the system: the committed transactions T since the last \\ncheckpoint (commit list), and the active transactions T′ (active list). REDO all \\nthe WRITE operations of the committed transactions from the log, in the order \\nin which they were written into the log. The transactions that are active and did \\nnot commit are effectively canceled and must be resubmitted.\\nThe REDO procedure is defined as follows:\\nProcedure REDO (WRITE_OP). Redoing a write_item operation WRITE_OP con-\\nsists of examining its log entry [write_item, T, X, new_value] and setting the value \\nof item X in the database to new_value, which is the after image (AFIM).\\nFigure 22.2 illustrates a timeline for a possible schedule of executing transactions. \\nWhen the checkpoint was taken at time t1, transaction T1 had committed, whereas \\ntransactions T3 and T4 had not. Before the system crash at time t2, T3 and T2 were \\ncommitted but not T4 and T5. According to the RDU_M method, there is no need to \\nredo the write_item operations of transaction T1—or any transactions committed \\nbefore the last checkpoint time t1. The write_item operations of T2 and T3 must be \\nredone, however, because both transactions reached their commit points after the \\nlast checkpoint. Recall that the log is force-written before committing a transaction. \\nTransactions T4 and T5 are ignored: They are effectively canceled or rolled back \\nbecause none of their write_item operations were recorded in the database on disk \\nunder the deferred update protocol (no-steal policy).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 836, 'page_label': '837'}, page_content='22.3 Recovery Techniques Based on Immediate Update  823\\nWe can make the NO-UNDO/REDO recovery algorithm more efficient by noting that, \\nif a data item X has been updated—as indicated in the log entries—more than once \\nby committed transactions since the last checkpoint, it is only necessary to REDO \\nthe last update of X  from the log during recovery because the other updates would \\nbe overwritten by this last REDO. In this case, we start from the end of the log; then, \\nwhenever an item is redone, it is added to a list of redone items. Before REDO is \\napplied to an item, the list is checked; if the item appears on the list, it is not redone \\nagain, since its latest value has already been recovered.\\nIf a transaction is aborted for any reason (say, by the deadlock detection method), it \\nis simply resubmitted, since it has not changed the database on disk. A drawback of \\nthe method described here is that it limits the concurrent execution of transactions \\nbecause all write-locked items remain locked until the transaction reaches its commit \\npoint. Additionally, it may require excessive buffer space to hold all updated items \\nuntil the transactions commit. The method’s main benefit is that transaction opera-\\ntions never need to be undone, for two reasons:\\n  1. A transaction does not record any changes in the database on disk until after \\nit reaches its commit point—that is, until it completes its execution success-\\nfully. Hence, a transaction is never rolled back because of failure during \\ntransaction execution.\\n  2. A transaction will never read the value of an item that is written by an \\nuncommitted transaction, because items remain locked until a transaction \\nreaches its commit point. Hence, no cascading rollback will occur.\\nFigure 22.3 shows an example of recovery for a multiuser system that utilizes the \\nrecovery and concurrency control method just described.\\n22.3  Recovery Techniques Based  \\non Immediate Update\\nIn these techniques, when a transaction issues an update command, the database on \\ndisk can be updated immediately, without any need to wait for the transaction to \\nreach its commit point. Notice that it is not a requirement  that every update be \\nSystem crash TimeCheckpoint\\nT2\\nT1\\nT3\\nT5\\nT4\\nt1 t2\\nFigure 22.2 \\nAn example of a \\nrecovery timeline to \\nillustrate the effect of \\ncheckpointing.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 837, 'page_label': '838'}, page_content='824 Chapter 22 Database Recovery Techniques\\napplied immediately to disk; it is just possible that some updates are applied to disk \\nbefore the transaction commits.\\nProvisions must be made for undoing the effect of update operations that have been \\napplied to the database by a failed transaction. This is accomplished by rolling back \\nthe transaction and undoing the effect of the transaction’s write_item operations. \\nTherefore, the UNDO-type log entries, which include the old value (BFIM) of the \\nitem, must be stored in the log. Because UNDO can be needed during recovery, these \\nmethods follow a steal strategy for deciding when updated main memory buffers \\ncan be written back to disk (see Section 22.1.3).\\nTheoretically, we can distinguish two main categories of immediate update algorithms.\\n  1. If the recovery technique ensures that all updates of a transaction are \\nrecorded in the database on disk before the transaction commits , there is \\nnever a need to REDO any operations of committed transactions. This is \\ncalled the UNDO/NO-REDO recovery algorithm. In this method, all updates \\nby a transaction must be recorded on disk before the transaction commits, so \\nthat REDO is never needed. Hence, this method must utilize the steal/force \\n(a) T1\\nread_item(A)\\nread_item(D)\\nwrite_item(D)\\n[checkpoint]\\n(b)\\nread_item(B)\\nwrite_item(B)\\nread_item(D)\\nwrite_item(D)\\nread_item(A)\\nwrite_item(A)\\nread_item(C)\\nwrite_item(C)\\nread_item(B)\\nwrite_item(B)\\nread_item(A)\\nwrite_item(A)\\n[start_transaction,T1]\\n[start_transaction, T2]\\n[write_item, T1, D, 20]\\n[commit, T1]\\n[commit, T4]\\n[start_transaction, T4]\\n[start_transaction, T3]\\n[write_item, T4, B, 15]\\n[write_item, T2, B, 12]\\n[write_item, T4, A, 20]\\n[write_item, T3, A, 30]\\n[write_item,T2, D, 25]\\nT2 and T3 are ignored because they did not reach their commit points.\\nT4 is redone because its commit point is after the last system checkpoint.\\nSystem crash\\nT2 T3 T4\\nFigure 22.3 \\nAn example of  recovery \\nusing deferred update \\nwith concurrent \\n transactions. (a) The \\nREAD and WRITE \\noperations of four \\ntransactions.  \\n(b) System log at the \\npoint of crash.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 838, 'page_label': '839'}, page_content='22.3 Recovery Techniques Based on Immediate Update  825\\nstrategy for deciding when updated main memory buffers are written back \\nto disk (see Section 22.1.3).\\n  2. If the transaction is allowed to commit before all its changes are written to \\nthe database, we have the most general case, known as the \\nUNDO/REDO \\nrecovery algorithm. In this case, the steal/no-force strategy is applied (see \\nSection 22.1.3). This is also the most complex technique, but the most com-\\nmonly used in practice. We will outline an \\nUNDO/REDO recovery algorithm \\nand leave it as an exercise for the reader to develop the UNDO/NO-REDO \\nvariation. In Section 22.5, we describe a more practical approach known as \\nthe ARIES recovery technique.\\nWhen concurrent execution is permitted, the recovery process again depends on \\nthe protocols used for concurrency control. The procedure \\nRIU_M (Recovery using \\nImmediate Updates for a Multiuser environment) outlines a recovery algorithm for \\nconcurrent transactions with immediate update (\\nUNDO/REDO recovery). Assume \\nthat the log includes checkpoints and that the concurrency control protocol \\nproduces strict schedules —as, for example, the strict two-phase locking protocol \\ndoes. Recall that a strict schedule does not allow a transaction to read or write an \\nitem unless the transaction that wrote the item has committed. However, deadlocks \\ncan occur in strict two-phase locking, thus requiring abort and \\nUNDO of transac-\\ntions. For a strict schedule, UNDO of an operation requires changing the item back \\nto its old value (BFIM).\\nProcedure RIU_M (UNDO/REDO with checkpoints).\\n  1. Use two lists of transactions maintained by the system: the committed \\ntransactions since the last checkpoint and the active transactions.\\n  2. Undo all the write_item operations of the active (uncommitted) transac-\\ntions, using the UNDO procedure. The operations should be undone in \\nthe reverse of the order in which they were written into the log.\\n  3. Redo all the write_item operations of the committed transactions from \\nthe log, in the order in which they were written into the log, using the \\nREDO procedure defined earlier.\\nThe UNDO procedure is defined as follows:\\nProcedure UNDO (WRITE_OP). Undoing a write_item operation write_op consists \\nof examining its log entry [write_item, T, X, old_value, new_value] and setting the \\nvalue of item X in the database to old_value, which is the before image (BFIM). \\nUndoing a number of write_item operations from one or more transactions from \\nthe log must proceed in the reverse order from the order in which the operations \\nwere written in the log.\\nAs we discussed for the NO-UNDO/REDO procedure, step 3 is more efficiently done \\nby starting from the end of the log and redoing only the last update of each item X.  \\nWhenever an item is redone, it is added to a list of redone items and is not redone \\nagain. A similar procedure can be devised to improve the efficiency of step 2 so \\nthat an item can be undone at most once during recovery. In this case, the earliest \\nUNDO is applied first by scanning the log in the forward direction (starting from'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 839, 'page_label': '840'}, page_content='826 Chapter 22 Database Recovery Techniques\\nthe beginning of the log). Whenever an item is undone, it is added to a list of \\nundone items and is not undone again.\\n22.4 Shadow Paging\\nThis recovery scheme does not require the use of a log in a single-user environ-\\nment. In a multiuser environment, a log may be needed for the concurrency control \\nmethod. Shadow paging considers the database to be made up of a number of fixed-\\nsize disk pages (or disk blocks)—say, n—for recovery purposes. A directory with n \\nentries\\n5 is constructed, where the ith entry points to the ith database page on disk. \\nThe directory is kept in main memory if it is not too large, and all references—reads \\nor writes—to database pages on disk go through it. When a transaction begins exe-\\ncuting, the current directory—whose entries point to the most recent or current \\ndatabase pages on disk—is copied into a shadow directory. The shadow directory \\nis then saved on disk while the current directory is used by the transaction.\\nDuring transaction execution, the shadow directory is never modified. When a \\nwrite_item operation is performed, a new copy of the modified database page is cre-\\nated, but the old copy of that page is not overwritten. Instead, the new page is writ-\\nten elsewhere—on some previously unused disk block. The current directory entry \\nis modified to point to the new disk block, whereas the shadow directory is not \\nmodified and continues to point to the old unmodified disk block. Figure 22.4 illus-\\ntrates the concepts of shadow and current directories. For pages updated by the \\ntransaction, two versions are kept. The old version is referenced by the shadow \\ndirectory and the new version by the current directory.\\n5The directory is similar to the page table maintained by the operating system for each process.\\nCurrent directory\\n(after updating \\npages 2, 5)\\nDatabase disk \\nblocks (pages)\\nShadow directory\\n(not updated)\\nPage 5 (old)\\nPage 1\\nPage 4\\nPage 2 (old)\\nPage 3\\nPage 6\\nPage 2 (new)\\nPage 5 (new)\\n1\\n2\\n3\\n4\\n5\\n6\\n1\\n2\\n3\\n4\\n5\\n6\\nFigure 22.4 \\nAn example of shadow paging.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 840, 'page_label': '841'}, page_content='22.5 The ARIES Recovery Algorithm  827\\nTo recover from a failure during transaction execution, it is sufficient to free the \\nmodified database pages and to discard the current directory. The state of the data-\\nbase before transaction execution is available through the shadow directory, and \\nthat state is recovered by reinstating the shadow directory. The database thus is \\nreturned to its state prior to the transaction that was executing when the crash \\noccurred, and any modified pages are discarded. Committing a transaction corre-\\nsponds to discarding the previous shadow directory. Since recovery involves nei-\\nther undoing nor redoing data items, this technique can be categorized as a \\nNO-UNDO/NO-REDO technique for recovery.\\nIn a multiuser environment with concurrent transactions, logs and checkpoints must \\nbe incorporated into the shadow paging technique. One disadvantage of shadow pag-\\ning is that the updated database pages change location on disk. This makes it difficult \\nto keep related database pages close together on disk without complex storage man-\\nagement strategies. Furthermore, if the directory is large, the overhead of writing \\nshadow directories to disk as transactions commit is significant. A further complica-\\ntion is how to handle garbage collection when a transaction commits. The old pages \\nreferenced by the shadow directory that have been updated must be released and \\nadded to a list of free pages for future use. These pages are no longer needed after the \\ntransaction commits. Another issue is that the operation to migrate between current \\nand shadow directories must be implemented as an atomic operation.\\n22.5 The ARIES Recovery Algorithm\\nWe now describe the ARIES algorithm as an example of a recovery algorithm used \\nin database systems. It is used in many relational database-related products of IBM. \\nARIES uses a steal/no-force approach for writing, and it is based on three concepts: \\nwrite-ahead logging, repeating history during redo, and logging changes during \\nundo. We discussed write-ahead logging in Section 22.1.3. The second concept, \\nrepeating history, means that ARIES will retrace all actions of the database system \\nprior to the crash to reconstruct the database state when the crash occurred. Trans-\\nactions that were uncommitted at the time of the crash (active transactions) are \\nundone. The third concept, logging during undo, will prevent ARIES from repeat-\\ning the completed undo operations if a failure occurs during recovery, which causes \\na restart of the recovery process.\\nThe ARIES recovery procedure consists of three main steps: analysis, \\nREDO, and \\nUNDO. The analysis step identifies the dirty (updated) pages in the buffer 6 and the \\nset of transactions active at the time of the crash. The appropriate point in the log \\nwhere the \\nREDO operation should start is also determined. The REDO phase actu-\\nally reapplies updates from the log to the database. Generally, the REDO operation \\nis applied only to committed transactions. However, this is not the case in ARIES. \\n6The actual buffers may be lost during a crash, since they are in main memory. Additional tables stored in \\nthe log during checkpointing (Dirty Page Table, Transaction Table) allow ARIES to identify this information \\n(as discussed later in this section).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 841, 'page_label': '842'}, page_content='828 Chapter 22 Database Recovery Techniques\\nCertain information in the ARIES log will provide the start point for REDO, from \\nwhich REDO operations are applied until the end of the log is reached. Additionally, \\ninformation stored by ARIES and in the data pages will allow ARIES to determine \\nwhether the operation to be redone has actually been applied to the database and \\ntherefore does not need to be reapplied. Thus, only the necessary REDO operations \\nare applied during recovery. Finally, during the \\nUNDO phase, the log is scanned \\nbackward and the operations of transactions that were active at the time of the crash \\nare undone in reverse order. The information needed for ARIES to accomplish its \\nrecovery procedure includes the log, the Transaction Table, and the Dirty Page \\nTable. Additionally, checkpointing is used. These tables are maintained by the \\ntransaction manager and written to the log during checkpointing.\\nIn ARIES, every log record has an associated log sequence number (LSN)  that is \\nmonotonically increasing and indicates the address of the log record on disk. Each \\nLSN corresponds to a specific change (action) of some transaction. Also, each data \\npage will store the LSN of the latest log record corresponding to a change for that \\npage. A log record is written for any of the following actions: updating a page \\n(write), committing a transaction (commit), aborting a transaction (abort), undo-\\ning an update (undo), and ending a transaction (end). The need for including the \\nfirst three actions in the log has been discussed, but the last two need some explana-\\ntion. When an update is undone, a compensation log record is written in the log so \\nthat the undo does not have to be repeated. When a transaction ends, whether by \\ncommitting or aborting, an end log record is written.\\nCommon fields in all log records include the previous LSN for that transaction, the \\ntransaction ID, and the type of log record. The previous LSN is important because \\nit links the log records (in reverse order) for each transaction. For an update (write) \\naction, additional fields in the log record include the page ID for the page that con-\\ntains the item, the length of the updated item, its offset from the beginning of the \\npage, the before image of the item, and its after image.\\nIn addition to the log, two tables are needed for efficient recovery: the Transaction \\nTable and the Dirty Page Table, which are maintained by the transaction manager. \\nWhen a crash occurs, these tables are rebuilt in the analysis phase of recovery. The \\nTransaction Table contains an entry for each active transaction,  with information \\nsuch as the transaction ID, transaction status, and the LSN of the most recent log \\nrecord for the transaction. The Dirty Page Table contains an entry for each dirty \\npage in the DBMS cache, which includes the page ID and the LSN corresponding to \\nthe earliest update to that page.\\nCheckpointing  in ARIES consists of the following: writing a \\nbegin_checkpoint  \\nrecord to the log, writing an end_checkpoint record to the log, and writing the LSN \\nof the begin_checkpoint record to a special file. This special file is accessed during \\nrecovery to locate the last checkpoint information. With the end_checkpoint record, \\nthe contents of both the Transaction Table and Dirty Page Table are appended to \\nthe end of the log. To reduce the cost, fuzzy checkpointing  is used so that the \\nDBMS can continue to execute transactions during checkpointing (see Sec-\\ntion\\xa022.1.4). Additionally, the contents of the DBMS cache do not have to be flushed'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 842, 'page_label': '843'}, page_content='22.5 The ARIES Recovery Algorithm  829\\nto disk during checkpoint, since the Transaction Table and Dirty Page Table—\\nwhich are appended to the log on disk—contain the information needed for \\n recovery. Note that if a crash occurs during checkpointing, the special file will refer \\nto the previous checkpoint, which would be used for recovery.\\nAfter a crash, the ARIES recovery manager takes over. Information from the \\nlast checkpoint is first accessed through the special file. The analysis phase  \\nstarts at the \\nbegin_checkpoint record and proceeds to the end of the log. When the \\nend_checkpoint record is encountered, the Transaction Table and Dirty Page Table \\nare accessed (recall that these tables were written in the log during checkpointing). \\nDuring analysis, the log records being analyzed may cause modifications to these \\ntwo tables. For instance, if an end log record was encountered for a transaction T in \\nthe Transaction Table, then the entry for T is deleted from that table. If some other \\ntype of log record is encountered for a transaction T′, then an entry for T′ is inserted \\ninto the Transaction Table, if not already present, and the last LSN field is modified. \\nIf the log record corresponds to a change for page P, then an entry would be made \\nfor page P (if not present in the table) and the associated LSN field would be \\n modified. When the analysis phase is complete, the necessary information for \\nREDO and UNDO has been compiled in the tables.\\nThe REDO phase follows next. To reduce the amount of unnecessary work, ARIES \\nstarts redoing at a point in the log where it knows (for sure) that previous changes \\nto dirty pages have already been applied to the database on disk.  It can determine \\nthis by finding the smallest LSN, M, of all the dirty pages in the Dirty Page Table, \\nwhich indicates the log position where ARIES needs to start the REDO phase. Any \\nchanges corresponding to an LSN < M, for redoable transactions, must have already \\nbeen propagated to disk or already been overwritten in the buffer; otherwise, those \\ndirty pages with that LSN would be in the buffer (and the Dirty Page Table). So, \\nREDO starts at the log record with LSN = M and scans forward to the end of the log.\\nFor each change recorded in the log, the REDO algorithm would verify whether or \\nnot the change has to be reapplied. For example, if a change recorded in the log \\npertains to page P that is not in the Dirty Page Table, then this change is already on \\ndisk and does not need to be reapplied. Or, if a change recorded in the log (with \\nLSN = N, say) pertains to page P and the Dirty Page Table contains an entry for P \\nwith LSN greater than N, then the change is already present. If neither of these two \\nconditions holds, page P is read from disk and the LSN stored on that page, LSN(P), \\nis compared with N. If N < LSN(P), then the change has been applied and the page \\ndoes not need to be rewritten to disk.\\nOnce the \\nREDO phase is finished, the database is in the exact state that it was in \\nwhen the crash occurred. The set of active transactions—called the undo_set—has \\nbeen identified in the Transaction Table during the analysis phase. Now, the UNDO \\nphase proceeds by scanning backward from the end of the log and undoing the \\nappropriate actions. A compensating log record is written for each action that is \\nundone. The UNDO reads backward in the log until every action of the set of trans-\\nactions in the undo_set has been undone. When this is completed, the recovery pro-\\ncess is finished and normal processing can begin again.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 843, 'page_label': '844'}, page_content='830 Chapter 22 Database Recovery Techniques\\nConsider the recovery example shown in Figure 22.5. There are three transactions: \\nT1, T2, and T3. T1 updates page C, T2 updates pages B and C, and T3 updates page A. \\nFigure 22.5(a) shows the partial contents of the log, and Figure 22.5(b) shows the \\ncontents of the Transaction Table and Dirty Page Table. Now, suppose that a crash \\noccurs at this point. Since a checkpoint has occurred, the address of the associated \\nbegin_checkpoint record is retrieved, which is location 4. The analysis phase starts \\nfrom location 4 until it reaches the end. The end_checkpoint  record contains the \\nTransaction Table and Dirty Page Table in Figure 22.5(b), and the analysis phase \\nwill further reconstruct these tables. When the analysis phase encounters log record 6, \\na new entry for transaction T\\n3 is made in the Transaction Table and a new entry for \\npage A is made in the Dirty Page Table. After log record 8 is analyzed, the status of \\ntransaction T\\n2 is changed to committed in the Transaction Table. Figure 22.5(c) \\nshows the two tables after the analysis phase.\\nTRANSACTION TABLE\\nLast_lsn Status(b)\\n(c)\\n(a) Lsn\\n1\\nLast_lsn Tran_id Type Page_id Other_information\\nTransaction_id\\nTRANSACTION TABLE DIRTY PAGE TABLE\\nTransaction_id\\nT1 3\\nLast_lsn\\ncommit\\nStatus Page_id\\nC\\nLsn\\n7\\nT3\\nT2 8\\n6 in progress\\ncommit\\nA\\nB\\n6\\n2\\nT2\\nT1\\nDIRTY PAGE TABLE\\nPage_id\\nC\\nLsn\\n1\\nB 22\\n3 commit\\nin progress\\n8\\n7\\n6\\n5\\n4\\n3\\n2\\n0\\n7\\n2\\n0\\nend checkpoint\\nbegin checkpoint\\n1\\n0\\nT1\\nT2\\nT1\\nT3\\nT2\\nT2\\nupdate\\ncommit\\nupdate\\nupdate\\ncommit\\nupdate B\\nC\\nA\\nC . . .\\n. . .\\n. . .\\n. . .\\n. . .\\n. . .\\nFigure 22.5 \\nAn example of recovery in ARIES. (a) The log at point of crash. (b) The Transaction and Dirty Page Tables at time of \\ncheckpoint. (c) The Transaction and Dirty Page Tables after the analysis phase.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 844, 'page_label': '845'}, page_content='22.6 Recovery in Multidatabase Systems  831\\nFor the REDO phase, the smallest LSN in the Dirty Page Table is 1. Hence the REDO \\nwill start at log record 1 and proceed with the REDO of updates. The LSNs {1, 2, 6, 7} \\ncorresponding to the updates for pages C, B, A, and C, respectively, are not less \\nthan the LSNs of those pages (as shown in the Dirty Page Table). So those data \\npages will be read again and the updates reapplied from the log (assuming the actual \\nLSNs stored on those data pages are less than the corresponding log entry). At this \\npoint, the \\nREDO phase is finished and the UNDO phase starts. From the Transaction \\nTable (Figure 22.5(c)), UNDO is applied only to the active transaction T3. The UNDO \\nphase starts at log entry 6 (the last update for T3) and proceeds backward in the log. \\nThe backward chain of updates for transaction T3 (only log record 6 in this exam-\\nple) is followed and undone.\\n22.6 Recovery in Multidatabase Systems\\nSo far, we have implicitly assumed that a transaction accesses a single database. In \\nsome cases, a single transaction, called a multidatabase transaction, may require \\naccess to multiple databases. These databases may even be stored on different types of \\nDBMSs; for example, some DBMSs may be relational, whereas others are object-\\noriented, hierarchical, or network DBMSs. In such a case, each DBMS involved in the \\nmultidatabase transaction may have its own recovery technique and transaction man-\\nager separate from those of the other DBMSs. This situation is somewhat similar to the \\ncase of a distributed database management system (see Chapter 23), where parts of the \\ndatabase reside at different sites that are connected by a communication network.\\nTo maintain the atomicity of a multidatabase transaction, it is necessary to have a \\ntwo-level recovery mechanism. A global recovery manager , or coordinator , is \\nneeded to maintain information needed for recovery, in addition to the local recov-\\nery managers and the information they maintain (log, tables). The coordinator usu-\\nally follows a protocol called the two-phase commit protocol , whose two phases \\ncan be stated as follows:\\n ■ Phase 1.  When all participating databases signal the coordinator that the \\npart of the multidatabase transaction involving each has concluded, the \\ncoordinator sends a message prepare for commit  to each participant to get \\nready for committing the transaction. Each participating database receiving \\nthat message will force-write all log records and needed information for \\nlocal recovery to disk and then send a ready to commit or OK signal to the \\ncoordinator. If the force-writing to disk fails or the local transaction cannot \\ncommit for some reason, the participating database sends a cannot commit \\nor not OK signal to the coordinator. If the coordinator does not receive a \\nreply from the database within a certain time out interval, it assumes a not \\nOK response.\\n ■ Phase 2. If all participating databases reply OK, and the coordinator’s vote is \\nalso OK, the transaction is successful, and the coordinator sends a commit \\nsignal for the transaction to the participating databases. Because all the local \\neffects of the transaction and information needed for local recovery have'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 845, 'page_label': '846'}, page_content='832 Chapter 22 Database Recovery Techniques\\nbeen recorded in the logs of the participating databases, local recovery from \\nfailure is now possible. Each participating database completes transaction \\ncommit by writing a \\n[commit] entry for the transaction in the log and perma-\\nnently updating the database if needed. Conversely, if one or more of the \\nparticipating databases or the coordinator have a not OK  response, the \\ntransaction has failed, and the coordinator sends a message to roll back or \\nUNDO the local effect of the transaction to each participating database. This \\nis done by undoing the local transaction operations, using the log.\\nThe net effect of the two-phase commit protocol is that either all participating data-\\nbases commit the effect of the transaction or none of them do. In case any of the \\nparticipants—or the coordinator—fails, it is always possible to recover to a state \\nwhere either the transaction is committed or it is rolled back. A failure during or \\nbefore phase 1 usually requires the transaction to be rolled back, whereas a failure \\nduring phase 2 means that a successful transaction can recover and commit.\\n22.7  Database Backup and Recovery  \\nfrom Catastrophic Failures\\nSo far, all the techniques we have discussed apply to noncatastrophic failures. A key \\nassumption has been that the system log is maintained on the disk and is not lost as \\na result of the failure. Similarly, the shadow directory must be stored on disk to \\nallow recovery when shadow paging is used. The recovery techniques we have dis-\\ncussed use the entries in the system log or the shadow directory to recover from \\nfailure by bringing the database back to a consistent state.\\nThe recovery manager of a DBMS must also be equipped to handle more catastrophic \\nfailures such as disk crashes. The main technique used to handle such crashes is a \\ndatabase backup, in which the whole database and the log are periodically copied \\nonto a cheap storage medium such as magnetic tapes or other large capacity offline \\nstorage devices. In case of a catastrophic system failure, the latest backup copy can be \\nreloaded from the tape to the disk, and the system can be restarted.\\nData from critical applications such as banking, insurance, stock market, and other \\ndatabases is periodically backed up in its entirety and moved to physically separate \\nsafe locations. Subterranean storage vaults have been used to protect such data \\nfrom flood, storm, earthquake, or fire damage. Events like the 9/11 terrorist attack \\nin New York (in 2001) and the Katrina hurricane disaster in New Orleans (in 2005) \\nhave created a greater awareness of disaster recovery of critical databases.\\nTo avoid losing all the effects of transactions that have been executed since the last \\nbackup, it is customary to back up the system log at more frequent intervals than full \\ndatabase backup by periodically copying it to magnetic tape. The system log is usu-\\nally substantially smaller than the database itself and hence can be backed up more \\nfrequently. Therefore, users do not lose all transactions they have performed since \\nthe last database backup. All committed transactions recorded in the portion of the \\nsystem log that has been backed up to tape can have their effect on the database'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 846, 'page_label': '847'}, page_content='22.8 Summary  833\\nredone. A new log is started after each database backup. Hence, to recover from disk \\nfailure, the database is first recreated on disk from its latest backup copy on tape. Fol-\\nlowing that, the effects of all the committed transactions whose operations have been \\nrecorded in the backed-up copies of the system log are reconstructed.\\n22.8 Summary\\nIn this chapter, we discussed the techniques for recovery from transaction failures. \\nThe main goal of recovery is to ensure the atomicity property of a transaction. If a \\ntransaction fails before completing its execution, the recovery mechanism has to \\nmake sure that the transaction has no lasting effects on the database. First in Sec-\\ntion\\xa022.1 we gave an informal outline for a recovery process, and then we discussed \\nsystem concepts for recovery. These included a discussion of caching, in-place \\nupdating versus shadowing, before and after images of a data item, \\nUNDO versus \\nREDO recovery operations, steal/no-steal and force/no-force policies, system check-\\npointing, and the write-ahead logging protocol.\\nNext we discussed two different approaches to recovery: deferred update (Sec-\\ntion\\xa0 22.2) and immediate update (Section 22.3). Deferred update techniques \\n postpone any actual updating of the database on disk until a transaction reaches its \\ncommit point. The transaction force-writes the log to disk before recording the \\nupdates in the database. This approach, when used with certain concurrency \\n control methods, is designed never to require transaction rollback, and recovery \\nsimply consists of redoing the operations of transactions committed after the last \\ncheckpoint from the log. The disadvantage is that too much buffer space may be \\nneeded, since updates are kept in the buffers and are not applied to disk until a \\ntrans action commits. Deferred update can lead to a recovery algorithm known as \\nNO-UNDO/REDO. Immediate update techniques may apply changes to the database \\non disk before the transaction reaches a successful conclusion. Any changes applied \\nto the database must first be recorded in the log and force-written to disk so that \\nthese operations can be undone if necessary. We also gave an overview of a recovery \\nalgorithm for immediate update known as \\nUNDO/REDO. Another algorithm, \\nknown as UNDO/NO-REDO, can also be developed for immediate update if all trans-\\naction actions are recorded in the database before commit.\\nWe discussed the shadow paging technique for recovery in Section 22.4, which \\nkeeps track of old database pages by using a shadow directory. This technique, \\nwhich is classified as NO-UNDO/NO-REDO, does not require a log in single-user sys-\\ntems but still needs the log for multiuser systems. We also presented ARIES in Sec-\\ntion 22.5, which is a specific recovery scheme used in many of IBM’s relational \\ndatabase products. Then in Section 22.6 we discussed the two-phase commit proto-\\ncol, which is used for recovery from failures involving multidatabase transactions. \\nFinally, we discussed recovery from catastrophic failures in Section 22.7, which is \\ntypically done by backing up the database and the log to tape. The log can be backed \\nup more frequently than the database, and the backup log can be used to redo oper-\\nations starting from the last database backup.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 847, 'page_label': '848'}, page_content='834 Chapter 22 Database Recovery Techniques\\nReview Questions\\n 22.1. Discuss the different types of transaction failures. What is meant by cata-\\nstrophic failure?\\n 22.2. Discuss the actions taken by the read_item and write_item operations on a \\ndatabase.\\n 22.3. What is the system log used for? What are the typical kinds of entries in a \\nsystem log? What are checkpoints, and why are they important? What are \\ntransaction commit points, and why are they important?\\n 22.4. How are buffering and caching techniques used by the recovery subsystem?\\n 22.5. What are the before image (BFIM) and after image (AFIM) of a data item? \\nWhat is the difference between in-place updating and shadowing, with \\nrespect to their handling of BFIM and AFIM?\\n 22.6. What are UNDO-type and REDO-type log entries?\\n 22.7. Describe the write-ahead logging protocol.\\n 22.8. Identify three typical lists of transactions that are maintained by the recov-\\nery subsystem.\\n 22.9. What is meant by transaction rollback? What is meant by cascading rollback? \\nWhy do practical recovery methods use protocols that do not permit cascad-\\ning rollback? Which recovery techniques do not require any rollback?\\n 22.10. Discuss the UNDO and REDO operations and the recovery techniques that \\nuse each.\\n 22.11. Discuss the deferred update technique of recovery. What are the advantages and \\ndisadvantages of this technique? Why is it called the \\nNO-UNDO/REDO method?\\n 22.12. How can recovery handle transaction operations that do not affect the data-\\nbase, such as the printing of reports by a transaction?\\n 22.13. Discuss the immediate update recovery technique in both single-user and \\nmultiuser environments. What are the advantages and disadvantages of \\nimmediate update?\\n 22.14. What is the difference between the UNDO/REDO and the UNDO/NO-REDO \\nalgorithms for recovery with immediate update? Develop the outline for an \\nUNDO/NO-REDO algorithm.\\n 22.15. Describe the shadow paging recovery technique. Under what circumstances \\ndoes it not require a log?\\n 22.16. Describe the three phases of the ARIES recovery method.\\n 22.17. What are log sequence numbers (LSNs) in ARIES? How are they used? What \\ninformation do the Dirty Page Table and Transaction Table contain? \\nDescribe how fuzzy checkpointing is used in ARIES.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 848, 'page_label': '849'}, page_content='Exercises 835\\n 22.18. What do the terms steal/no-steal and force/no-force mean with regard to buf-\\nfer management for transaction processing?\\n 22.19. Describe the two-phase commit protocol for multidatabase transactions.\\n 22.20. Discuss how disaster recovery from catastrophic failures is handled.\\nExercises\\n 22.21. Suppose that the system crashes before the [read_item, T3, A] entry is written to \\nthe log in Figure 22.1(b). Will that make any difference in the recovery process?\\n 22.22. Suppose that the system crashes before the [write_item, T2, D, 25, 26] entry is \\nwritten to the log in Figure 22.1(b). Will that make any difference in the \\nrecovery process?\\n 22.23. Figure 22.6 shows the log corresponding to a particular schedule at the point \\nof a system crash for four transactions T1, T2, T3, and T4. Suppose that we \\nuse the immediate update protocol with checkpointing. Describe the recov-\\nery process from the system crash. Specify which transactions are rolled \\nback, which operations in the log are redone and which (if any) are undone, \\nand whether any cascading rollback takes place.\\n[checkpoint]\\n[start_transaction, T1]\\n[start_transaction, T2]\\n[start_transaction, T3]\\n[read_item, T1, A]\\n[read_item, T1, D]\\n[read_item, T4, D]\\n[read_item, T2, D]\\n[read_item, T2, B]\\n[write_item, T1, D, 20, 25]\\n[write_item, T2, B, 12, 18]\\n[read_item, T4, A]\\n[write_item, T4, D, 25, 15]\\n[write_item, T3, C, 30, 40]\\n[write_item, T2, D, 15, 25]\\n[write_item, T4, A, 30, 20]\\n[commit, T1]\\n[commit, T4]\\n[start_transaction, T4]\\nSystem crash\\nFigure 22.6\\nA sample schedule and its \\ncorresponding log.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 849, 'page_label': '850'}, page_content='836 Chapter 22 Database Recovery Techniques\\n 22.24. Suppose that we use the deferred update protocol for the example in Fig-\\nure 22.6. Show how the log would be different in the case of deferred update \\nby removing the unnecessary log entries; then describe the recovery process, \\nusing your modified log. Assume that only \\nREDO operations are applied, \\nand specify which operations in the log are redone and which are ignored.\\n 22.25. How does checkpointing in ARIES differ from checkpointing as described \\nin Section 22.1.4?\\n 22.26. How are log sequence numbers used by ARIES to reduce the amount of \\nREDO work needed for recovery? Illustrate with an example using the infor-\\nmation shown in Figure 22.5. You can make your own assumptions as to \\nwhen a page is written to disk.\\n 22.27. What implications would a no-steal/force buffer management policy have \\non checkpointing and recovery?\\nChoose the correct answer for each of the following multiple-choice questions:\\n 22.28. Incremental logging with deferred updates implies that the recovery system \\nmust\\na. store the old value of the updated item in the log\\nb. store the new value of the updated item in the log\\nc. store both the old and new value of the updated item in the log\\nd. store only the Begin Transaction and Commit Transaction records in the log\\n 22.29. The write-ahead logging (WAL) protocol simply means that\\na. writing of a data item should be done ahead of any logging operation\\nb. the log record for an operation should be written before the actual data is \\nwritten\\nc. all log records should be written before a new transaction begins execution\\nd. the log never needs to be written to disk\\n 22.30. In case of transaction failure under a deferred update incremental logging \\nscheme, which of the following will be needed?\\na. an undo operation\\nb. a redo operation\\nc. an undo and redo operation\\nd. none of the above\\n 22.31. For incremental logging with immediate updates, a log record for a transac-\\ntion would contain\\na. a transaction name, a data item name, and the old and new value of the item\\nb. a transaction name, a data item name, and the old value of the item\\nc. a transaction name, a data item name, and the new value of the item\\nd. a transaction name and a data item name'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 850, 'page_label': '851'}, page_content='Exercises 837\\n 22.32. For correct behavior during recovery, undo and redo operations must be\\na. commutative\\nb. associative\\nc. idempotent\\nd. distributive\\n 22.33. When a failure occurs, the log is consulted and each operation is either \\nundone or redone. This is a problem because\\na. searching the entire log is time consuming\\nb. many redos are unnecessary\\nc. both (a) and (b)\\nd. none of the above\\n 22.34. Using a log-based recovery scheme might improve performance as well as \\nprovide a recovery mechanism by\\na. writing the log records to disk when each transaction commits\\nb. writing the appropriate log records to disk during the transaction’s \\nexecution\\nc. waiting to write the log records until multiple transactions commit and \\nwriting them as a batch\\nd. never writing the log records to disk\\n 22.35. There is a possibility of a cascading rollback when\\na. a transaction writes items that have been written only by a committed \\ntransaction\\nb. a transaction writes an item that is previously written by an uncommitted \\ntransaction\\nc. a transaction reads an item that is previously written by an uncommitted \\ntransaction\\nd. both (b) and (c)\\n 22.36. To cope with media (disk) failures, it is necessary\\na. for the DBMS to only execute transactions in a single user environment\\nb. to keep a redundant copy of the database\\nc. to never abort a transaction\\nd. all of the above\\n 22.37. If the shadowing approach is used for flushing a data item back to disk, \\nthen\\na. the item is written to disk only after the transaction commits\\nb. the item is written to a different location on disk\\nc. the item is written to disk before the transaction commits\\nd. the item is written to the same disk location from which it was read'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 851, 'page_label': '852'}, page_content='838 Chapter 22 Database Recovery Techniques\\nSelected Bibliography\\nThe books by Bernstein et al. (1987) and Papadimitriou (1986) are devoted to the \\ntheory and principles of concurrency control and recovery. The book by Gray and \\nReuter (1993) is an encyclopedic work on concurrency control, recovery, and other \\ntransaction-processing issues.\\nVerhofstad (1978) presents a tutorial and survey of recovery techniques in database \\nsystems. Categorizing algorithms based on their \\nUNDO/REDO characteristics is dis-\\ncussed in Haerder and Reuter (1983) and in Bernstein et al. (1983). Gray (1978) \\ndiscusses recovery, along with other system aspects of implementing operating sys-\\ntems for databases. The shadow paging technique is discussed in Lorie (1977), Ver-\\nhofstad (1978), and Reuter (1980). Gray et al. (1981) discuss the recovery mechanism \\nin SYSTEM R. Lockemann and Knutsen (1968), Davies (1973), and Bjork (1973) \\nare early papers that discuss recovery. Chandy et al. (1975) discuss transaction roll-\\nback. Lilien and Bhargava (1985) discuss the concept of integrity block and its use \\nto improve the efficiency of recovery.\\nRecovery using write-ahead logging is analyzed in Jhingran and Khedkar (1992) \\nand is used in the ARIES system (Mohan et al., 1992). More recent work on recov-\\nery includes compensating transactions (Korth et al., 1990) and main memory \\ndatabase recovery (Kumar, 1991). The ARIES recovery algorithms (Mohan et al., \\n1992) have been successful in practice. Franklin et al. (1992) discusses recovery in \\nthe EXODUS system. Two books by Kumar and Hsu (1998) and Kumar and Song \\n(1998) discuss recovery in detail and contain descriptions of recovery methods used \\nin a number of existing relational database products. Examples of page replacement \\nstrategies that are specific for databases are discussed in Chou and DeWitt (1985) \\nand Pazos et al. (2006).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 852, 'page_label': '853'}, page_content='Distributed Databases, NOSQL \\nSystems, and Big Data   \\npart 10'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 853, 'page_label': '854'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 854, 'page_label': '855'}, page_content='841\\n23\\nDistributed Database Concepts\\nI\\nn this chapter, we turn our attention to distributed \\ndatabases (DDBs), distributed database management \\nsystems (DDBMSs), and how the client-server architecture is used as a platform for \\ndatabase application development. Distributed databases bring the advantages of \\ndistributed computing to the database domain. A distributed computing system  \\nconsists of a number of processing sites or nodes that are interconnected by a com-\\nputer network and that cooperate in performing certain assigned tasks. As a general \\ngoal, distributed computing systems partition a big, unmanageable problem into \\nsmaller pieces and solve it efficiently in a coordinated manner. Thus, more comput-\\ning power is harnessed to solve a complex task, and the autonomous processing \\nnodes can be managed independently while they cooperate to provide the needed \\nfunctionalities to solve the problem. DDB technology resulted from a merger of two \\ntechnologies: database technology and distributed systems technology.\\nSeveral distributed database prototype systems were developed in the 1980s and \\n1990s to address the issues of data distribution, data replication, distributed query \\nand transaction processing, distributed database metadata management, and other \\ntopics. More recently, many new technologies have emerged that combine distrib-\\nuted and database technologies. These technologies and systems are being devel-\\noped for dealing with the storage, analysis, and mining of the vast amounts of data \\nthat are being produced and collected, and they are referred to generally as big data \\ntechnologies. The origins of big data technologies come from distributed systems \\nand database systems, as well as data mining and machine learning algorithms that \\ncan process these vast amounts of data to extract needed knowledge.\\nIn this chapter, we discuss the concepts that are central to data distribution and the \\nmanagement of distributed data. Then in the following two chapters, we give an \\noverview of some of the new technologies that have emerged to manage and process \\nbig data. Chapter 24 discusses the new class of database systems known as NOSQL \\nchapter 23'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 855, 'page_label': '856'}, page_content='842 Chapter 23 Distributed Database Concepts\\nsystems, which focus on providing distributed solutions to manage the vast amounts \\nof data that are needed in applications such as social media, healthcare, and security, \\nto name a few. Chapter 25 introduces the concepts and systems being used for pro-\\ncessing and analysis of big data, such as map-reduce and other distributed process-\\ning technologies. We also discuss cloud computing concepts in Chapter 25.\\nSection 23.1 introduces distributed database management and related concepts. \\nIssues of distributed database design, involving fragmenting and sharding of data \\nand distributing it over multiple sites, as well as data replication, are discussed in \\nSection 23.2. Section 23.3 gives an overview of concurrency control and recovery in \\ndistributed databases. Sections 23.4 and  23.5 introduce distributed transaction pro-\\ncessing and distributed query processing techniques, respectively. Sections 23.6 and  \\n23.7 introduce different types of distributed database systems and their architec-\\ntures, including federated and multidatabase systems. The problems of heterogene-\\nity and the needs of autonomy in federated database systems are also highlighted. \\nSection 23.8 discusses catalog management schemes in distributed databases. Sec-\\ntion 23.9 summarizes the chapter.\\nFor a short introduction to the topic of distributed databases, Sections 23.1 through  \\n23.5 may be covered and the other sections may be omitted.\\n23.1 Distributed Database Concepts\\nWe can define a distributed database (DDB)  as a collection of multiple logically \\ninterrelated databases distributed over a computer network, and a distributed \\ndatabase management system (DDBMS) as a software system that manages a dis-\\ntributed database while making the distribution transparent to the user.\\n23.1.1 What Constitutes a DDB\\nFor a database to be called distributed, the following minimum conditions should \\nbe satisfied:\\n ■ Connection of database nodes over a computer network.  There are mul-\\ntiple computers, called sites or nodes. These sites must be connected by an \\nunderlying network to transmit data and commands among sites.\\n ■ Logical interrelation of the connected databases.  It is essential that the \\ninformation in the various database nodes be logically related.\\n ■ Possible absence of homogeneity among connected nodes. It is not neces-\\nsary that all nodes be identical in terms of data, hardware, and software.\\nThe sites may all be located in physical proximity—say, within the same building or a \\ngroup of adjacent buildings—and connected via a local area network, or they may be \\ngeographically distributed over large distances and connected via a long-haul or wide \\narea network. Local area networks typically use wireless hubs or cables, whereas \\nlong-haul networks use telephone lines, cables, wireless communication infrastruc-\\ntures, or satellites. It is common to have a combination of various types of networks.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 856, 'page_label': '857'}, page_content='23.1 Distributed Database Concepts  843\\nNetworks may have different topologies  that define the direct communication \\npaths among sites. The type and topology of the network used may have a signifi-\\ncant impact on the performance and hence on the strategies for distributed query \\nprocessing and distributed database design. For high-level architectural issues, \\nhowever, it does not matter what type of network is used; what matters is that each \\nsite be able to communicate, directly or indirectly, with every other site. For the \\nremainder of this chapter, we assume that some type of network exists among \\nnodes, regardless of any particular topology. We will not address any network- \\nspecific issues, although it is important to understand that for an efficient operation \\nof a distributed database system (DDBS), network design and performance issues \\nare critical and are an integral part of the overall solution. The details of the under-\\nlying network are invisible to the end user.\\n23.1.2 Transparency\\nThe concept of transparency extends the general idea of hiding implementation \\ndetails from end users. A highly transparent system offers a lot of flexibility to the \\nend user/application developer since it requires little or no awareness of underly-\\ning details on their part. In the case of a traditional centralized database, transpar-\\nency simply pertains to logical and physical data independence for application \\ndevelopers. However, in a DDB scenario, the data and software are distributed \\nover multiple nodes connected by a computer network, so additional types of \\ntransparencies are introduced.\\nConsider the company database in Figure 5.5 that we have been discussing through-\\nout the book. The \\nEMPLOYEE, PROJECT, and WORKS_ON tables may be fragmented \\nhorizontally (that is, into sets of rows, as we will discuss in Section 23.2) and stored \\nwith possible replication, as shown in Figure 23.1. The following types of transpar-\\nencies are possible:\\n ■ Data organization transparency (also known as distribution or network \\ntransparency ). This refers to freedom for the user from the operational \\ndetails of the network and the placement of the data in the distributed sys-\\ntem. It may be divided into location transparency and naming transparency. \\nLocation transparency refers to the fact that the command used to perform \\na task is independent of the location of the data and the location of the node \\nwhere the command was issued. Naming transparency implies that once a \\nname is associated with an object, the named objects can be accessed unam-\\nbiguously without additional specification as to where the data is located.\\n ■ Replication transparency.  As we show in Figure 23.1, copies of the same \\ndata objects may be stored at multiple sites for better availability, perfor-\\nmance, and reliability. Replication transparency makes the user unaware of \\nthe existence of these copies.\\n ■ Fragmentation transparency.  Two types of fragmentation are possible. \\nHorizontal fragmentation  distributes a relation (table) into subrelations \\nthat are subsets of the tuples (rows) in the original relation; this is also known'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 857, 'page_label': '858'}, page_content='844 Chapter 23 Distributed Database Concepts\\nas sharding in the newer big data and cloud computing systems. Vertical \\nfragmentation distributes a relation into subrelations where each subrelation \\nis defined by a subset of the columns of the original relation. Fragmentation \\ntransparency makes the user unaware of the existence of fragments.\\n ■ Other transparencies include design transparency  and execution \\n transparency—which refer, respectively, to freedom from knowing how the \\ndistributed database is designed and where a transaction executes.\\n23.1.3 Availability and Reliability\\nReliability and availability are two of the most common potential advantages cited \\nfor distributed databases. Reliability is broadly defined as the probability that a \\nsystem is running (not down) at a certain time point, whereas availability is the \\nprobability that the system is continuously available during a time interval. We can \\ndirectly relate reliability and availability of the database to the faults, errors, and \\nfailures associated with it. A failure can be described as a deviation of a system’s \\nbehavior from that which is specified in order to ensure correct execution of opera-\\ntions. Errors constitute that subset of system states that causes the failure. Fault is \\nthe cause of an error.\\nTo construct a system that is reliable, we can adopt several approaches. One com-\\nmon approach stresses fault tolerance ; it recognizes that faults will occur, and it \\ndesigns mechanisms that can detect and remove faults before they can result in a \\nEMPLOYEES \\nPROJECTS \\nWORKS_ON \\nAll\\nAll\\nAll\\nEMPLOYEES\\nPROJECTS\\nWORKS_ON\\nSan Francisco \\nand Los Angeles\\nSan Francisco\\nSan Francisco \\nemployees\\nEMPLOYEES \\nPROJECTS\\nWORKS_ON\\nLos Angeles\\nLos Angeles and \\nSan Francisco\\nLos Angeles \\nemployees\\nEMPLOYEES\\nPROJECTS\\nWORKS_ON\\nNew York\\nAll\\nNew York \\nemployees\\nEMPLOYEES \\nPROJECTS \\nWORKS_ON\\nAtlanta\\nAtlanta\\nAtlanta \\nemployees\\nChicago\\n(Headquarters)\\nNew York\\nLos Angeles Atlanta\\nSan Francisco\\nCommunications\\nNetwork\\nFigure 23.1 \\nData distribution and replication among distributed databases.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 858, 'page_label': '859'}, page_content='23.1 Distributed Database Concepts  845\\nsystem failure. Another more stringent approach attempts to ensure that the final \\nsystem does not contain any faults. This is done through an exhaustive design pro-\\ncess followed by extensive quality control and testing. A reliable DDBMS tolerates \\nfailures of underlying components, and it processes user requests as long as data-\\nbase consistency is not violated. A DDBMS recovery manager has to deal with fail-\\nures arising from transactions, hardware, and communication networks. Hardware \\nfailures can either be those that result in loss of main memory contents or loss of \\nsecondary storage contents. Network failures occur due to errors associated with \\nmessages and line failures. Message errors can include their loss, corruption, or \\nout-of-order arrival at destination.\\nThe previous definitions are used in computer systems in general, where there is a \\ntechnical distinction between reliability and availability. In most discussions related \\nto DDB, the term availability is used generally as an umbrella term to cover both \\nconcepts.\\n23.1.4 Scalability and Partition Tolerance\\nScalability determines the extent to which the system can expand its capacity while \\ncontinuing to operate without interruption. There are two types of scalability:\\n  1. Horizontal scalability: This refers to expanding the number of nodes in the \\ndistributed system. As nodes are added to the system, it should be possible \\nto distribute some of the data and processing loads from existing nodes to \\nthe new nodes.\\n  2. Vertical scalability: This refers to expanding the capacity of the individual \\nnodes in the system, such as expanding the storage capacity or the process-\\ning power of a node.\\nAs the system expands its number of nodes, it is possible that the network, which \\nconnects the nodes, may have faults that cause the nodes to be partitioned into \\ngroups of nodes. The nodes within each partition are still connected by a subnet-\\nwork, but communication among the partitions is lost. The concept of partition \\ntolerance states that the system should have the capacity to continue operating \\nwhile the network is partitioned.\\n23.1.5 Autonomy\\nAutonomy determines the extent to which individual nodes or DBs in a connected \\nDDB can operate independently. A high degree of autonomy is desirable for \\nincreased flexibility and customized maintenance of an individual node. Autonomy \\ncan be applied to design, communication, and execution. Design autonomy refers \\nto independence of data model usage and transaction management techniques \\namong nodes. Communication autonomy  determines the extent to which each \\nnode can decide on sharing of information with other nodes. Execution autonomy \\nrefers to independence of users to act as they please.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 859, 'page_label': '860'}, page_content='846 Chapter 23 Distributed Database Concepts\\n23.1.6 Advantages of Distributed Databases\\nSome important advantages of DDB are listed below.\\n  1. Improved ease and flexibility of application development . Developing \\nand maintaining applications at geographically distributed sites of an \\norganization is facilitated due to transparency of data distribution and \\ncontrol.\\n  2. Increased availability.  This is achieved by the isolation of faults to their \\nsite of origin without affecting the other database nodes connected to the \\nnetwork. When the data and DDBMS software are distributed over many \\nsites, one site may fail while other sites continue to operate. Only the data \\nand software that exist at the failed site cannot be accessed. Further \\nimprovement is achieved by judiciously replicating data and software at \\nmore than one site. In a centralized system, failure at a single site makes \\nthe whole system unavailable to all users. In a distributed database, some \\nof the data may be unreachable, but users may still be able to access other \\nparts of the database. If the data in the failed site has been replicated at \\nanother site prior to the failure, then the user will not be affected at all. The \\nability of the system to survive network partitioning also contributes to \\nhigh availability.\\n  3. Improved performance.  A distributed DBMS fragments the database \\nby keeping the data closer to where it is needed most. Data localization  \\nreduces the contention for CPU and I/O services and simultaneously \\nreduces access delays involved in wide area networks. When a large \\ndatabase is distributed over multiple sites, smaller databases exist at \\neach site. As a result, local queries and transactions accessing data at a \\nsingle site have better performance because of the smaller local data-\\nbases. In addition, each site has a smaller number of transactions exe-\\ncuting than if all transactions are submitted to a single centralized \\ndatabase. Moreover, interquery and intraquery parallelism can be \\nachieved by executing multiple queries at different sites, or by breaking \\nup a query into a number of subqueries that execute in parallel. This \\ncontributes to improved performance.\\n  4. Easier expansion via scalability . In a distributed environment, expansion \\nof the system in terms of adding more data, increasing database sizes, or \\nadding more nodes is much easier than in centralized (non-distributed) \\nsystems.\\nThe transparencies we discussed in Section 23.1.2 lead to a compromise between \\nease of use and the overhead cost of providing transparency. Total transparency \\nprovides the global user with a view of the entire DDBS as if it is a single centralized \\nsystem. Transparency is provided as a complement to autonomy, which gives the \\nusers tighter control over local databases. Transparency features may be imple-\\nmented as a part of the user language, which may translate the required services \\ninto appropriate operations.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 860, 'page_label': '861'}, page_content='23.2 Data Fragmentation, Replication, and Allocation Techniques for Distributed Database Design  847\\n23.2  Data Fragmentation, Replication,  \\nand Allocation Techniques for Distributed \\nDatabase Design\\nIn this section, we discuss techniques that are used to break up the database into \\nlogical units, called fragments, which may be assigned for storage at the various \\nnodes. We also discuss the use of data replication, which permits certain data to be \\nstored in more than one site to increase availability and reliability; and the process \\nof allocating fragments—or replicas of fragments—for storage at the various nodes. \\nThese techniques are used during the process of distributed database design. The \\ninformation concerning data fragmentation, allocation, and replication is stored in \\na global directory that is accessed by the DDBS applications as needed.\\n23.2.1 Data Fragmentation and Sharding\\nIn a DDB, decisions must be made regarding which site should be used to store \\nwhich portions of the database. For now, we will assume that there is no replication; \\nthat is, each relation—or portion of a relation—is stored at one site only. We dis-\\ncuss replication and its effects later in this section. We also use the terminology of \\nrelational databases, but similar concepts apply to other data models. We assume \\nthat we are starting with a relational database schema and must decide on how to \\ndistribute the relations over the various sites. To illustrate our discussion, we use \\nthe relational database schema shown in Figure 5.5.\\nBefore we decide on how to distribute the data, we must determine the logical units of \\nthe database that are to be distributed. The simplest logical units are the relations \\nthemselves; that is, each whole relation is to be stored at a particular site. In our exam-\\nple, we must decide on a site to store each of the relations \\nEMPLOYEE, DEPARTMENT, \\nPROJECT, WORKS_ON, and DEPENDENT in Figure 5.5. In many cases, however, a \\nrelation can be divided into smaller logical units for distribution. For example, \\nconsider the company database shown in Figure 5.6, and assume there are three \\ncomputer sites—one for each department in the company.\\n1 \\nWe may want to store the database information relating to each department at the \\ncomputer site for that department. A technique called horizontal fragmentation or \\nsharding can be used to partition each relation by department.\\nHorizontal Fragmentation (Sharding). A horizontal fragment or shard of a \\nrelation is a subset of the tuples in that relation. The tuples that belong to the horizontal \\nfragment can be specified by a condition on one or more attributes of the relation, or \\nby some other mechanism. Often, only a single attribute is involved in the condition. \\nFor example, we may define three horizontal fragments on the \\nEMPLOYEE relation in \\nFigure 5.6 with the following conditions: (Dno = 5), (Dno = 4), and (Dno = 1)—each \\n1Of course, in an actual situation, there will be many more tuples in the relation than those shown in \\nFigure 5.6.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 861, 'page_label': '862'}, page_content='848 Chapter 23 Distributed Database Concepts\\nfragment contains the EMPLOYEE tuples working for a particular department. Sim-\\nilarly, we may define three horizontal fragments for the PROJECT relation, with the \\nconditions ( Dnum = 5), ( Dnum = 4), and ( Dnum = 1)—each fragment contains the \\nPROJECT tuples controlled by a particular department. Horizontal fragmentation \\ndivides a relation horizontally by grouping rows to create subsets of tuples, where \\neach subset has a certain logical meaning. These fragments can then be assigned to \\ndifferent sites (nodes) in the distributed system. Derived horizontal  fragmentation \\napplies the partitioning of a primary relation (\\nDEPARTMENT in our example) to \\nother secondary relations ( EMPLOYEE and PROJECT in our example), which are \\nrelated to the primary via a foreign key. Thus, related data between the primary and \\nthe secondary relations gets fragmented in the same way.\\nVertical Fragmentation. Each site may not need all the attributes of a relation, \\nwhich would indicate the need for a different type of fragmentation. Vertical \\n fragmentation divides a relation “vertically” by columns. A vertical fragment of a \\nrelation keeps only certain attributes of the relation. For example, we may want to \\nfragment the \\nEMPLOYEE relation into two vertical fragments. The first fragment \\nincludes personal information— Name, Bdate, Address, and Sex—and the second \\nincludes work-related information— Ssn, Salary, Super_ssn, and Dno. This vertical \\nfragmentation is not quite proper, because if the two fragments are stored sepa-\\nrately, we cannot put the original employee tuples back together since there is no \\ncommon attribute between the two fragments. It is necessary to include the primary \\nkey or some unique key attribute in every vertical fragment so that the full relation \\ncan be reconstructed from the fragments. Hence, we must add the Ssn attribute to \\nthe personal information fragment.\\nNotice that each horizontal fragment on a relation R can be specified in the rela-\\ntional algebra by a σCi(R) (select) operation. A set of horizontal fragments whose \\nconditions C1, C2, … , Cn include all the tuples in R—that is, every tuple in R satis-\\nfies (C1 OR C2 OR … OR Cn)—is called a complete horizontal fragmentation of R. \\nIn many cases a complete horizontal fragmentation is also disjoint; that is, no tuple \\nin R satisfies (Ci AND Cj) for any i ≠ j. Our two earlier examples of horizontal frag-\\nmentation for the EMPLOYEE and PROJECT relations were both complete and dis-\\njoint. To reconstruct the relation R from a complete horizontal fragmentation, we \\nneed to apply the UNION operation to the fragments.\\nA vertical fragment on a relation R can be specified by a πLi(R) operation in the \\nrelational algebra. A set of vertical fragments whose projection lists L1, L2, … , Ln \\ninclude all the attributes in R but share only the primary key attribute of R is called \\na complete vertical fragmentation of R. In this case the projection lists satisfy the \\nfollowing two conditions:\\n ■ L1 ∪ L2 ∪ … ∪ Ln = ATTRS(R)\\n ■ Li ∩ Lj = PK(R) for any i ≠ j, where ATTRS(R) is the set of attributes of R and \\nPK(R) is the primary key of R\\nTo reconstruct the relation R from a complete vertical fragmentation, we apply \\nthe OUTER UNION  operation to the vertical fragments (assuming no horizontal'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 862, 'page_label': '863'}, page_content='23.2 Data Fragmentation, Replication, and Allocation Techniques for Distributed Database Design  849\\nfragmentation is used). Notice that we could also apply a FULL OUTER JOIN opera-\\ntion and get the same result for a complete vertical fragmentation, even when \\nsome horizontal fragmentation may also have been applied. The two vertical frag-\\nments of the \\nEMPLOYEE  relation with projection lists L1 = { Ssn, Name, Bdate, \\nAddress, Sex} and L2 = {Ssn, Salary, Super_ssn, Dno} constitute a complete vertical \\nfragmentation of EMPLOYEE.\\nTwo horizontal fragments that are neither complete nor disjoint are those defined on \\nthe EMPLOYEE relation in Figure 5.5 by the conditions (Salary > 50000) and (Dno = 4); \\nthey may not include all EMPLOYEE tuples, and they may include common tuples. \\nTwo vertical fragments that are not complete are those defined by the attribute lists \\nL\\n1 = {Name, Address} and L2 = {Ssn, Name, Salary}; these lists violate both conditions \\nof a complete vertical fragmentation.\\nMixed (Hybrid) Fragmentation. We can intermix the two types of fragmenta-\\ntion, yielding a mixed fragmentation. For example, we may combine the horizon-\\ntal and vertical fragmentations of the EMPLOYEE relation given earlier into a mixed \\nfragmentation that includes six fragments. In this case, the original relation can be \\nreconstructed by applying UNION and OUTER UNION (or OUTER JOIN) operations \\nin the appropriate order. In general, a fragment of a relation R can be specified by a \\nSELECT-PROJECT combination of operations πL(σC(R)). If C = TRUE (that is, all \\ntuples are selected) and L ≠ ATTRS(R), we get a vertical fragment, and if C ≠ TRUE and \\nL = ATTRS(R), we get a horizontal fragment. Finally, if C ≠ TRUE and L\\xa0≠\\xa0ATTRS(R), \\nwe get a mixed fragment. Notice that a relation can itself be considered a fragment \\nwith C = TRUE and L = ATTRS(R). In the following discussion, the term fragment is \\nused to refer to a relation or to any of the preceding types of fragments.\\nA fragmentation schema of a database is a definition of a set of fragments that includes \\nall attributes and tuples in the database and satisfies the condition that the whole data-\\nbase can be reconstructed from the fragments by applying some sequence of OUTER \\nUNION (or OUTER JOIN) and UNION operations. It is also sometimes useful—although \\nnot necessary—to have all the fragments be disjoint except for the repetition of pri-\\nmary keys among vertical (or mixed) fragments. In the latter case, all replication \\nand distribution of fragments is clearly specified at a subsequent stage, separately \\nfrom fragmentation.\\nAn allocation schema describes the allocation of fragments to nodes (sites) of the \\nDDBS; hence, it is a mapping that specifies for each fragment the site(s) at which it \\nis stored. If a fragment is stored at more than one site, it is said to be replicated. We \\ndiscuss data replication and allocation next.\\n23.2.2 Data Replication and Allocation\\nReplication is useful in improving the availability of data. The most extreme case is \\nreplication of the whole database at every site in the distributed system, thus creat-\\ning a fully replicated distributed database. This can improve availability remark-\\nably because the system can continue to operate as long as at least one site is up. It'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 863, 'page_label': '864'}, page_content='850 Chapter 23 Distributed Database Concepts\\nalso improves performance of retrieval (read performance) for global queries \\nbecause the results of such queries can be obtained locally from any one site; hence, \\na retrieval query can be processed at the local site where it is submitted, if that site \\nincludes a server module. The disadvantage of full replication is that it can slow \\ndown update operations (write performance) drastically, since a single logical \\nupdate must be performed on every copy of the database to keep the copies consis-\\ntent. This is especially true if many copies of the database exist. Full replication \\nmakes the concurrency control and recovery techniques more expensive than they \\nwould be if there was no replication, as we will see in Section 23.3.\\nThe other extreme from full replication involves having no replication —that is, \\neach fragment is stored at exactly one site. In this case, all fragments must be dis-\\njoint, except for the repetition of primary keys among vertical (or mixed) frag-\\nments. This is also called nonredundant allocation.\\nBetween these two extremes, we have a wide spectrum of partial replication  of \\nthe data—that is, some fragments of the database may be replicated whereas oth-\\ners may not. The number of copies of each fragment can range from one up to \\nthe total number of sites in the distributed system. A special case of partial repli-\\ncation is occurring heavily in applications where mobile workers—such as sales \\nforces, financial planners, and claims adjustors—carry partially replicated data-\\nbases with them on laptops and PDAs and synchronize them periodically with \\nthe server database. A description of the replication of fragments is sometimes \\ncalled a replication schema .\\nEach fragment—or each copy of a fragment—must be assigned to a particular site in \\nthe distributed system. This process is called data distribution (or data  allocation). \\nThe choice of sites and the degree of replication depend on the performance and \\navailability goals of the system and on the types and frequencies of transactions \\nsubmitted at each site. For example, if high availability is required, transactions can \\nbe submitted at any site, and most transactions are retrieval only, a fully replicated \\ndatabase is a good choice. However, if certain transactions that access particular \\nparts of the database are mostly submitted at a particular site, the corresponding set \\nof fragments can be allocated at that site only. Data that is accessed at multiple sites \\ncan be replicated at those sites. If many updates are performed, it may be useful to \\nlimit replication. Finding an optimal or even a good solution to distributed data \\nallocation is a complex optimization problem.\\n23.2.3 Example of Fragmentation, Allocation, and Replication\\nWe now consider an example of fragmenting and distributing the company data-\\nbase in Figures 5.5 and  5.6. Suppose that the company has three computer sites—\\none for each current department. Sites 2 and 3 are for departments 5 and 4, \\nrespectively. At each of these sites, we expect frequent access to the \\nEMPLOYEE and \\nPROJECT information for the employees who work in that department  and the \\nprojects controlled by that department.  Further, we assume that these sites mainly \\naccess the Name, Ssn, Salary, and Super_ssn attributes of EMPLOYEE. Site 1 is used'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 864, 'page_label': '865'}, page_content='23.2 Data Fragmentation, Replication, and Allocation Techniques for Distributed Database Design  851\\nby company headquarters and accesses all employee and project information regu-\\nlarly, in addition to keeping track of DEPENDENT information for insurance purposes.\\nAccording to these requirements, the whole database in Figure 5.6 can be stored at \\nsite 1. To determine the fragments to be replicated at sites 2 and 3, first we can \\nhorizontally fragment \\nDEPARTMENT by its key Dnumber. Then we apply derived \\nfragmentation to the EMPLOYEE, PROJECT, and DEPT_LOCATIONS relations based \\non their foreign keys for department number—called Dno, Dnum, and Dnumber, \\nrespectively, in Figure 5.5. We can vertically fragment the resulting EMPLOYEE \\nfragments to include only the attributes { Name, Ssn, Salary , Super_ssn , Dno}. \\n Figure\\xa023.2 shows the mixed fragments EMPD_5 and EMPD_4, which include the \\nEMPLOYEE tuples satisfying the conditions Dno = 5 and Dno = 4, respectively. The \\nhorizontal fragments of PROJECT , DEPARTMENT , and DEPT_LOCATIONS  are \\n similarly fragmented by department number. All these fragments—stored at sites \\n2\\xa0and 3—are replicated because they are also stored at headquarters—site 1.\\nWe must now fragment the \\nWORKS_ON relation and decide which fragments of \\nWORKS_ON to store at sites 2 and 3. We are confronted with the problem that no \\nattribute of WORKS_ON directly indicates the department to which each tuple \\nbelongs. In fact, each tuple in WORKS_ON relates an employee e to a project P. We \\ncould fragment WORKS_ON based on the department D in which e works or based \\non the department D′ that controls P. Fragmentation becomes easy if we have a \\nconstraint stating that D = D′ for all WORKS_ON tuples—that is, if employees can \\nwork only on projects controlled by the department they work for. However, there \\nis no such constraint in our database in Figure 5.6. For example, the \\nWORKS_ON \\ntuple <333445555, 10, 10.0> relates an employee who works for department 5 with \\na project controlled by department 4. In this case, we could fragment \\nWORKS_ON \\nbased on the department in which the employee works (which is expressed by the \\ncondition C) and then fragment further based on the department that controls the \\nprojects that employee is working on, as shown in Figure 23.3.\\nIn Figure 23.3, the union of fragments G\\n1, G2, and G3 gives all WORKS_ON tuples \\nfor employees who work for department 5. Similarly, the union of fragments G4, G5, \\nand G6 gives all WORKS_ON tuples for employees who work for department 4. On \\nthe other hand, the union of fragments G1, G4, and G7 gives all WORKS_ON tuples \\nfor projects controlled by department 5. The condition for each of the fragments G1 \\nthrough G9 is shown in Figure 23.3. The relations that represent M:N relationships, \\nsuch as WORKS_ON, often have several possible logical fragmentations. In our distri-\\nbution in Figure 23.2, we choose to include all fragments that can be joined to either an \\nEMPLOYEE tuple or a PROJECT tuple at sites 2 and 3. Hence, we place the union of \\nfragments G1, G2, G3, G4, and G7 at site 2 and the union of fragments G4, G5, G6, G2, \\nand G8 at site 3. Notice that fragments G2 and G4 are replicated at both sites. This allo-\\ncation strategy permits the join between the local EMPLOYEE or PROJECT fragments at \\nsite 2 or site 3 and the local WORKS_ON fragment to be performed completely locally. \\nThis clearly demonstrates how complex the problem of database fragmentation and \\nallocation is for large databases. The Selected Bibliography at the end of this chapter \\ndiscusses some of the work done in this area.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 865, 'page_label': '866'}, page_content='852 Chapter 23 Distributed Database Concepts\\n(a)\\n(b)\\nFname\\nJohn B Smith 123456789 30000 333445555 5\\nFranklin T Wong 333445555 40000 888665555 5\\nK Narayan 666884444 38000 3334 45555 5\\nA English 453453453 25000 333445555 5\\nRamesh\\nJoyce\\nEMPD_5\\nMinit Lname Ssn Salary Super_ssn Dno\\nData at site 2\\nData at site 3\\nFname\\nAlicia J Zelaya 999887777 25000 98765 4321 4\\nJennifer S Wallace 987654321 43000 888665555 4\\nV Jabbar 987987987 25000 987654321 4Ahmad\\nEMPD_4\\nMinit Lname Ssn Salary Super_ssn Dno\\nDname\\nResearch 5 333445555 1988-05-22\\nDEP_5\\nDnumber Mgr_ssn Mgr_start_date Dnumber\\n5 Bellaire\\n5 Sugarland\\n5 Houston\\nDEP_5_LOCS\\nLocation\\nDname\\nAdministration 4 987654321 1995-01-01\\nDEP_4\\nDnumber Mgr_ssn Mgr_start_date\\nEssn\\n123456789 1\\n123456789 2\\n666884444\\n453453453\\n453453453\\n333445555\\n333445555\\n333445555\\n333445555\\n1\\n2\\n2\\n3\\n10\\n20\\n3\\n32.5\\n7. 5\\n20.0\\n20.0\\n10.0\\n10.0\\n10.0\\n10.0\\n40.0\\nWORKS_ON_5\\nPno Hours Pname\\nProduct X 1\\nProduct Y 2\\nProduct Z 3\\nBellaire\\nSugarland\\nHouston\\nPROJS_5\\nPnumber Plocation\\n5\\n5\\n5\\nDnum\\nEssn\\n333445555 10\\n999887777 30\\n999887777\\n987987987\\n987987987\\n987654321\\n987654321\\n10\\n30\\n30\\n20\\n10\\n10.0\\n30.0\\n35.0\\n5.0\\n20.0\\n15.0\\n10.0\\nWORKS_ON_4\\nPno Hours Pname\\nComputerization 10\\nNew_benefits 30\\nStafford\\nStafford\\nPROJS_4\\nPnumber Plocation\\n4\\n4\\nDnum\\nDnumber\\n4 Stafford\\nDEP_4_LOCS\\nLocation\\nFigure 23.2 \\nAllocation of fragments to \\nsites. (a) Relation fragments \\nat site 2 corresponding to \\ndepartment 5. (b) Relation \\nfragments at site 3 \\n corresponding to  \\ndepartment 4.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 866, 'page_label': '867'}, page_content='23.2 Data Fragmentation, Replication, and Allocation Techniques for Distributed Database Design  853\\nEssn\\n123456789 1 32.5\\n123456789 2 7 .5\\n3 40.0\\n1 20.0\\n2 20.0\\n2 10.0\\n3 10.0\\n666884444\\n453453453\\n453453453\\n333445555\\n333445555\\nG1\\n1C   = C and (Pno in (SELECT \\nPnumber FROM PROJECT\\nWHERE Dnum = 5))\\nEmployees in Department 5\\nPno Hours Essn\\n333445555 10 10.0\\nG2\\nC2 = C and (Pno in (SELECT \\nPnumber FROM PROJECT\\nWHERE Dnum = 4))\\nPno Hours\\nEssn\\n333445555 20 10.0\\nG3\\nC3 = C and (Pno in (SELECT \\nPnumber FROM PROJECT\\nWHERE Dnum = 1))\\nPno Hours\\nEssn\\nG4\\n(b)\\n(c)\\n(a)\\nC4 = C and (Pno in (SELECT \\nPnumber FROM PROJECT\\nWHERE Dnum = 5))\\nEmployees in Department 4\\nPno Hours\\nEssn\\n999887777 30 30.0\\n999887777 10 10.0\\n987987987 10 35.0\\n987987987 30 5.0\\n987654321 30 20.0\\nG5\\nC5 = C and (Pno in (SELECT \\nPnumber FROM PROJECT\\nWHERE Dnum = 4))\\nPno Hours\\nEssn\\n987654321 20 15.0\\nG6\\nC6 = C and (Pno in (SELECT \\nPnumber FROM PROJECT\\nWHERE Dnum = 1))\\nPno Hours\\nEssn\\nG7 \\nC7 = C and (Pno in (SELECT \\nPnumber FROM PROJECT\\nWHERE Dnum = 5))\\nEmployees in Department 1\\nPno Hours\\nEssn\\nG8\\nC8 = C and (Pno in (SELECT \\nPnumber FROM PROJECT\\nWHERE Dnum = 4))\\nPno Hours\\nEssn\\n888665555 20 Null\\nG9\\nC9 = C and (Pno in (SELECT \\nPnumber FROM PROJECT\\nWHERE Dnum = 1))\\nPno Hours\\nFigure 23.3 \\nComplete and disjoint fragments of the WORKS_ON relation. (a) Fragments of WORKS_ON for employees  \\nworking in department 5 (C = [Essn in (SELECT Ssn FROM EMPLOYEE WHERE Dno = 5)]). (b) Fragments of \\nWORKS_ON for employees working in department 4 (C = [Essn in (SELECT Ssn FROM EMPLOYEE WHERE  \\nDno = 4)]). (c) Fragments of WORKS_ON for employees working in department 1 (C = [Essn in (SELECT Ssn \\nFROM EMPLOYEE WHERE Dno = 1)]).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 867, 'page_label': '868'}, page_content='854 Chapter 23 Distributed Database Concepts\\n23.3  Overview of Concurrency Control  \\nand Recovery in Distributed Databases\\nFor concurrency control and recovery purposes, numerous problems arise in a dis-\\ntributed DBMS environment that are not encountered in a centralized DBMS envi-\\nronment. These include the following:\\n ■ Dealing with multiple copies  of the data items.  The concurrency control \\nmethod is responsible for maintaining consistency among these copies. The \\nrecovery method is responsible for making a copy consistent with other cop-\\nies if the site on which the copy is stored fails and recovers later.\\n ■ Failure of individual sites. The DDBMS should continue to operate with its \\nrunning sites, if possible, when one or more individual sites fail. When a site \\nrecovers, its local database must be brought up-to-date with the rest of the \\nsites before it rejoins the system.\\n ■ Failure of communication links. The system must be able to deal with the \\nfailure of one or more of the communication links that connect the sites. An \\nextreme case of this problem is that network partitioning may occur. This \\nbreaks up the sites into two or more partitions, where the sites within each \\npartition can communicate only with one another and not with sites in other \\npartitions.\\n ■ Distributed commit.  Problems can arise with committing a transaction \\nthat is accessing databases stored on multiple sites if some sites fail during \\nthe commit process. The two-phase commit protocol  (see Section 21.6) is \\noften used to deal with this problem.\\n ■ Distributed deadlock.  Deadlock may occur among several sites, so \\ntechniques for dealing with deadlocks must be extended to take this \\ninto account.\\nDistributed concurrency control and recovery techniques must deal with these \\nand other problems. In the following subsections, we review some of the tech-\\nniques that have been suggested to deal with recovery and concurrency control \\nin DDBMSs.\\n23.3.1  Distributed Concurrency Control Based  \\non a Distinguished Copy of a Data Item\\nTo deal with replicated data items in a distributed database, a number of concur-\\nrency control methods have been proposed that extend the concurrency control \\ntechniques that are used in centralized databases. We discuss these techniques in \\nthe context of extending centralized locking. Similar extensions apply to other con-\\ncurrency control techniques. The idea is to designate a particular copy of each data \\nitem as a distinguished copy. The locks for this data item are associated with the \\ndistinguished copy, and all locking and unlocking requests are sent to the site that \\ncontains that copy.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 868, 'page_label': '869'}, page_content='23.3 Overview of Concurrency Control and Recovery in Distributed Databases  855\\nA number of different methods are based on this idea, but they differ in their \\nmethod of choosing the distinguished copies. In the primary site technique , all \\ndistinguished copies are kept at the same site. A modification of this approach is \\nthe primary site with a backup site . Another approach is the primary copy  \\nmethod, where the distinguished copies of the various data items can be stored in \\ndifferent sites. A site that includes a distinguished copy of a data item basically acts \\nas the coordinator site  for concurrency control on that item. We discuss these \\ntechniques next.\\nPrimary Site Technique. In this method, a single primary site is designated to be \\nthe coordinator site for all database items. Hence, all locks are kept at that site, and \\nall requests for locking or unlocking are sent there. This method is thus an exten-\\nsion of the centralized locking approach. For example, if all transactions follow the \\ntwo-phase locking protocol, serializability is guaranteed. The advantage of this \\napproach is that it is a simple extension of the centralized approach and thus is not \\noverly complex. However, it has certain inherent disadvantages. One is that all \\nlocking requests are sent to a single site, possibly overloading that site and causing \\na system bottleneck. A second disadvantage is that failure of the primary site para-\\nlyzes the system, since all locking information is kept at that site. This can limit \\nsystem reliability and availability.\\nAlthough all locks are accessed at the primary site, the items themselves can be accessed \\nat any site at which they reside. For example, once a transaction obtains a \\nRead_lock on \\na data item from the primary site, it can access any copy of that data item. However, \\nonce a transaction obtains a \\nWrite_lock and updates a data item, the DDBMS is respon-\\nsible for updating all copies of the data item before releasing the lock.\\nPrimary Site with Backup Site. This approach addresses the second disadvan-\\ntage of the primary site method by designating a second site to be a backup site. All \\nlocking information is maintained at both the primary and the backup sites. In case \\nof primary site failure, the backup site takes over as the primary site, and a new \\nbackup site is chosen. This simplifies the process of recovery from failure of the \\nprimary site, since the backup site takes over and processing can resume after a new \\nbackup site is chosen and the lock status information is copied to that site. It slows \\ndown the process of acquiring locks, however, because all lock requests and grant-\\ning of locks must be recorded at both the primary and the backup sites  before a \\nresponse is sent to the requesting transaction. The problem of the primary and \\nbackup sites becoming overloaded with requests and slowing down the system \\nremains undiminished.\\nPrimary Copy Technique. This method attempts to distribute the load of lock \\ncoordination among various sites by having the distinguished copies of different \\ndata items stored at different sites.  Failure of one site affects any transactions that \\nare accessing locks on items whose primary copies reside at that site, but other \\ntransactions are not affected. This method can also use backup sites to enhance reli-\\nability and availability.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 869, 'page_label': '870'}, page_content='856 Chapter 23 Distributed Database Concepts\\nChoosing a New Coordinator Site in Case of Failure. Whenever a coordina-\\ntor site fails in any of the preceding techniques, the sites that are still running must \\nchoose a new coordinator. In the case of the primary site approach with no backup \\nsite, all executing transactions must be aborted and restarted in a tedious recovery \\nprocess. Part of the recovery process involves choosing a new primary site and cre-\\nating a lock manager process and a record of all lock information at that site. For \\nmethods that use backup sites, transaction processing is suspended while the \\nbackup site is designated as the new primary site and a new backup site is chosen \\nand is sent copies of all the locking information from the new primary site.\\nIf a backup site X is about to become the new primary site, X can choose the new \\nbackup site from among the system’s running sites. However, if no backup site \\nexisted, or if both the primary and the backup sites are down, a process called \\nelection can be used to choose the new coordinator site. In this process, any site Y \\nthat attempts to communicate with the coordinator site repeatedly and fails to do so \\ncan assume that the coordinator is down and can start the election process by send-\\ning a message to all running sites proposing that Y become the new coordinator. As \\nsoon as Y receives a majority of yes votes, Y can declare that it is the new coordina-\\ntor. The election algorithm itself is complex, but this is the main idea behind the \\nelection method. The algorithm also resolves any attempt by two or more sites to \\nbecome coordinator at the same time. The references in the Selected Bibliography \\nat the end of this chapter discuss the process in detail.\\n23.3.2 Distributed Concurrency Control Based on Voting\\nThe concurrency control methods for replicated items discussed earlier all use the \\nidea of a distinguished copy that maintains the locks for that item. In the voting \\nmethod, there is no distinguished copy; rather, a lock request is sent to all sites that \\nincludes a copy of the data item. Each copy maintains its own lock and can grant or \\ndeny the request for it. If a transaction that requests a lock is granted that lock by a \\nmajority of the copies, it holds the lock and informs all copies  that it has been \\ngranted the lock. If a transaction does not receive a majority of votes granting it a \\nlock within a certain time-out period, it cancels its request and informs all sites of \\nthe cancellation.\\nThe voting method is considered a truly distributed concurrency control method, \\nsince the responsibility for a decision resides with all the sites involved. Simulation \\nstudies have shown that voting has higher message traffic among sites than do the \\ndistinguished copy methods. If the algorithm takes into account possible site fail-\\nures during the voting process, it becomes extremely complex.\\n23.3.3 Distributed Recovery\\nThe recovery process in distributed databases is quite involved. We give only a very \\nbrief idea of some of the issues here. In some cases it is difficult even to determine \\nwhether a site is down without exchanging numerous messages with other sites. For'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 870, 'page_label': '871'}, page_content='23.4 Overview of Transaction Management in Distributed Databases  857\\nexample, suppose that site X sends a message to site Y and expects a response from \\nY but does not receive it. There are several possible explanations:\\n ■ The message was not delivered to Y because of communication failure.\\n ■ Site Y is down and could not respond.\\n ■ Site Y is running and sent a response, but the response was not delivered.\\nWithout additional information or the sending of additional messages, it is difficult \\nto determine what actually happened.\\nAnother problem with distributed recovery is distributed commit. When a transac-\\ntion is updating data at several sites, it cannot commit until it is sure that the effect \\nof the transaction on every site cannot be lost. This means that every site must first \\nhave recorded the local effects of the transactions permanently in the local site log \\non disk. The two-phase commit protocol is often used to ensure the correctness of \\ndistributed commit (see Section 21.6).\\n23.4  Overview of Transaction Management  \\nin Distributed Databases\\nThe global and local transaction management software modules, along with the \\nconcurrency control and recovery manager of a DDBMS, collectively guarantee the \\nACID properties of transactions (see Chapter 20).\\nAn additional component called the global transaction manager is introduced for \\nsupporting distributed transactions. The site where the transaction originated can \\ntemporarily assume the role of global transaction manager and coordinate the exe-\\ncution of database operations with transaction managers across multiple sites. \\nTransaction managers export their functionality as an interface to the application \\nprograms. The operations exported by this interface are similar to those covered in \\nSection 20.2.1, namely \\nBEGIN_TRANSACTION, READ or WRITE, END_TRANSACTION, \\nCOMMIT_TRANSACTION, and ROLLBACK (or ABORT). The manager stores book-\\nkeeping information related to each transaction, such as a unique identifier, origi-\\nnating site, name, and so on. For READ operations, it returns a local copy if valid and \\navailable. For WRITE operations, it ensures that updates are visible across all sites \\ncontaining copies (replicas) of the data item. For ABORT operations, the manager \\nensures that no effects of the transaction are reflected in any site of the distributed \\ndatabase. For \\nCOMMIT operations, it ensures that the effects of a write are persistently \\nrecorded on all databases containing copies of the data item. Atomic termination \\n(COMMIT/ ABORT) of distributed transactions is commonly implemented using the \\ntwo-phase commit protocol (see Section 22.6).\\nThe transaction manager passes to the concurrency controller module the database \\noperations and associated information. The controller is responsible for acquisition \\nand release of associated locks. If the transaction requires access to a locked \\nresource, it is blocked until the lock is acquired. Once the lock is acquired, the oper-\\nation is sent to the runtime processor, which handles the actual execution of the'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 871, 'page_label': '872'}, page_content='858 Chapter 23 Distributed Database Concepts\\ndatabase operation. Once the operation is completed, locks are released and the \\ntransaction manager is updated with the result of the operation.\\n23.4.1 Two-Phase Commit Protocol\\nIn Section 22.6, we described the two-phase commit protocol (2PC), which requires \\na global recovery manager , or coordinator, to maintain information needed for \\nrecovery, in addition to the local recovery managers and the information they \\nmaintain (log, tables). The two-phase commit protocol has certain drawbacks that \\nled to the development of the three-phase commit protocol, which we discuss next.\\n23.4.2 Three-Phase Commit Protocol\\nThe biggest drawback of 2PC is that it is a blocking protocol. Failure of the coordi-\\nnator blocks all participating sites, causing them to wait until the coordinator \\nrecovers. This can cause performance degradation, especially if participants are \\nholding locks to shared resources. Other types of problems may also occur that \\nmake the outcome of the transaction nondeterministic.\\nThese problems are solved by the three-phase commit (3PC) protocol, which essen-\\ntially divides the second commit phase into two subphases called prepare-to-commit \\nand commit. The prepare-to-commit phase is used to communicate the result of \\nthe vote phase to all participants. If all participants vote yes, then the coordinator \\ninstructs them to move into the prepare-to-commit state. The commit subphase is \\nidentical to its two-phase counterpart. Now, if the coordinator crashes during this \\nsubphase, another participant can see the transaction through to completion. It can \\nsimply ask a crashed participant if it received a prepare-to-commit message. If it \\ndid not, then it safely assumes to abort. Thus the state of the protocol can be recov-\\nered irrespective of which participant crashes. Also, by limiting the time required \\nfor a transaction to commit or abort to a maximum time-out period, the protocol \\nensures that a transaction attempting to commit via 3PC releases locks on time-out.\\nThe main idea is to limit the wait time for participants who have prepared to com-\\nmit and are waiting for a global commit or abort from the coordinator. When a \\nparticipant receives a precommit message, it knows that the rest of the participants \\nhave voted to commit. If a precommit message has not been received, then the par-\\nticipant will abort and release all locks.\\n23.4.3 Operating System Support for Transaction Management\\nThe following are the main benefits of operating system (OS)-supported transaction \\nmanagement:\\n ■ Typically, DBMSs use their own semaphores 2 to guarantee mutually exclu-\\nsive access to shared resources. Since these semaphores are implemented in \\n2Semaphores are data structures used for synchronized and exclusive access to shared resources for \\npreventing race conditions in a parallel computing system.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 872, 'page_label': '873'}, page_content='23.5 Query Processing and Optimization in Distributed Databases  859\\nuser space at the level of the DBMS application software, the OS has no \\nknowledge about them. Hence if the OS deactivates a DBMS process hold-\\ning a lock, other DBMS processes wanting this locked resource get blocked. \\nSuch a situation can cause serious performance degradation. OS-level \\nknowledge of semaphores can help eliminate such situations.\\n ■ Specialized hardware support for locking can be exploited to reduce associ-\\nated costs. This can be of great importance, since locking is one of the most \\ncommon DBMS operations.\\n ■ Providing a set of common transaction support operations though the kernel \\nallows application developers to focus on adding new features to their prod-\\nucts as opposed to reimplementing the common functionality for each appli-\\ncation. For example, if different DDBMSs are to coexist on the same machine \\nand they chose the two-phase commit protocol, then it is more beneficial to \\nhave this protocol implemented as part of the kernel so that the DDBMS \\ndevelopers can focus more on adding new features to their products.\\n23.5  Query Processing and Optimization in  \\nDistributed Databases\\nNow we give an overview of how a DDBMS processes and optimizes a query. First \\nwe discuss the steps involved in query processing and then elaborate on the commu-\\nnication costs of processing a distributed query. Then we discuss a special operation, \\ncalled a semijoin, which is used to optimize some types of queries in a DDBMS. A \\ndetailed discussion about optimization algorithms is beyond the scope of this text. \\nWe attempt to illustrate optimization principles using suitable examples.\\n3\\n23.5.1 Distributed Query Processing\\nA distributed database query is processed in stages as follows:\\n  1. Query Mapping. The input query on distributed data is specified formally \\nusing a query language. It is then translated into an algebraic query on global \\nrelations. This translation is done by referring to the global conceptual \\nschema and does not take into account the actual distribution and replica-\\ntion of data. Hence, this translation is largely identical to the one performed \\nin a centralized DBMS. It is first normalized, analyzed for semantic errors, \\nsimplified, and finally restructured into an algebraic query.\\n  2. Localization.  In a distributed database, fragmentation results in relations \\nbeing stored in separate sites, with some fragments possibly being repli-\\ncated. This stage maps the distributed query on the global schema to sepa-\\nrate queries on individual fragments using data distribution and replication \\ninformation.\\n3For a detailed discussion of optimization algorithms, see Ozsu and Valduriez (1999).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 873, 'page_label': '874'}, page_content='860 Chapter 23 Distributed Database Concepts\\n  3. Global Query Optimization.  Optimization consists of selecting a strategy \\nfrom a list of candidates that is closest to optimal. A list of candidate queries \\ncan be obtained by permuting the ordering of operations within a fragment \\nquery generated by the previous stage. Time is the preferred unit for mea-\\nsuring cost. The total cost is a weighted combination of costs such as CPU \\ncost, I/O costs, and communication costs. Since DDBs are connected by a \\nnetwork, often the communication costs over the network are the most sig-\\nnificant. This is especially true when the sites are connected through a wide \\narea network (WAN).\\n  4. Local Query Optimization.  This stage is common to all sites in the DDB. \\nThe techniques are similar to those used in centralized systems.\\nThe first three stages discussed above are performed at a central control site, \\nwhereas the last stage is performed locally.\\n23.5.2 Data Transfer Costs of Distributed Query Processing\\nWe discussed the issues involved in processing and optimizing a query in a central-\\nized DBMS in Chapter 19. In a distributed system, several additional factors further \\ncomplicate query processing. The first is the cost of transferring data over the net-\\nwork. This data includes intermediate files that are transferred to other sites for \\nfurther processing, as well as the final result files that may have to be transferred to \\nthe site where the query result is needed. Although these costs may not be very high \\nif the sites are connected via a high-performance local area network, they become \\nsignificant in other types of networks. Hence, DDBMS query optimization algo-\\nrithms consider the goal of reducing the amount of data transfer as an optimization \\ncriterion in choosing a distributed query execution strategy.\\nWe illustrate this with two simple sample queries. Suppose that the \\nEMPLOYEE and \\nDEPARTMENT relations in Figure 3.5 are distributed at two sites as shown in Fig-\\nure\\xa023.4. We will assume in this example that neither relation is fragmented. Accord-\\ning to Figure 23.4, the size of the \\nEMPLOYEE relation is 100 * 10,000 = 106 bytes, and \\nthe size of the DEPARTMENT relation is 35 * 100 = 3,500 bytes. Consider the query Q: \\nFor each employee, retrieve the employee name and the name of the department for \\nwhich the employee works. This can be stated as follows in the relational algebra:\\nQ: πFname,Lname,Dname(EMPLOYEE  Dno=Dnumber DEPARTMENT)\\nThe result of this query will include 10,000 records, assuming that every employee \\nis related to a department. Suppose that each record in the query result is 40 bytes \\nlong. The query is submitted at a distinct site 3, which is called the result site  \\nbecause the query result is needed there. Neither the EMPLOYEE  nor the \\n DEPARTMENT relations reside at site 3. There are three simple strategies for execut-\\ning this distributed query:\\n  1. Transfer both the EMPLOYEE and the DEPARTMENT relations to the result \\nsite, and perform the join at site 3. In this case, a total of 1,000,000 + 3,500 = \\n1,003,500 bytes must be transferred.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 874, 'page_label': '875'}, page_content='23.5 Query Processing and Optimization in Distributed Databases  861\\n  2. Transfer the EMPLOYEE relation to site 2, execute the join at site 2, and send \\nthe result to site 3. The size of the query result is 40 * 10,000 = 400,000 bytes, \\nso 400,000 + 1,000,000 = 1,400,000 bytes must be transferred.\\n  3. Transfer the DEPARTMENT relation to site 1, execute the join at site 1, and \\nsend the result to site 3. In this case, 400,000 + 3,500 = 403,500 bytes must be \\ntransferred.\\nIf minimizing the amount of data transfer is our optimization criterion, we should \\nchoose strategy 3. Now consider another query Q′: For each department, retrieve the \\ndepartment name and the name of the department manager.  This can be stated as \\nfollows in the relational algebra:\\nQ′: πFname,Lname,Dname(DEPARTMENT  Mgr_ssn=Ssn EMPLOYEE)\\nAgain, suppose that the query is submitted at site 3. The same three strategies for \\nexecuting query Q apply to Q′, except that the result of Q′ includes only 100 records, \\nassuming that each department has a manager:\\n  1. Transfer both the EMPLOYEE and the DEPARTMENT relations to the result \\nsite, and perform the join at site 3. In this case, a total of 1,000,000 + 3,500 = \\n1,003,500 bytes must be transferred.\\n  2. Transfer the EMPLOYEE relation to site 2, execute the join at site 2, and send \\nthe result to site 3. The size of the query result is 40 * 100 = 4,000 bytes, so \\n4,000 + 1,000,000 = 1,004,000 bytes must be transferred.\\n  3. Transfer the DEPARTMENT relation to site 1, execute the join at site 1, and \\nsend the result to site 3. In this case, 4,000 + 3,500 = 7,500 bytes must be \\ntransferred.\\nAgain, we would choose strategy 3—this time by an overwhelming margin over \\nstrategies 1 and 2. The preceding three strategies are the most obvious ones for the \\nFname\\nEMPLOYEE\\nSite 1:\\n10,000 records\\neach record is 100 bytes long \\nSsn field is 9 bytes long \\nDno field is 4 bytes long\\nSite 2:\\nMinit Lname Ssn Salary Super_ssn DnoBdate Address Sex\\nDname\\nDEPARTMENT\\nDnumber Mgr_ssn Mgr_start_date\\nFname field is 15 bytes long\\nLname field is 15 bytes long\\n100 records\\neach record is 35 bytes long \\nDnumber field is 4 bytes long \\nMgr_ssn field is 9 bytes long\\nDname field is 10 bytes long\\nFigure 23.4 \\nExample to illustrate \\nvolume of data  \\ntransferred.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 875, 'page_label': '876'}, page_content='862 Chapter 23 Distributed Database Concepts\\ncase where the result site (site 3) is different from all the sites that contain files \\ninvolved in the query (sites 1 and 2). However, suppose that the result site is site 2; \\nthen we have two simple strategies:\\n  1. Transfer the EMPLOYEE relation to site 2, execute the query, and present the \\nresult to the user at site 2. Here, the same number of bytes—1,000,000—\\nmust be transferred for both \\nQ and Q′.\\n  2. Transfer the DEPARTMENT relation to site 1, execute the query at site 1, and \\nsend the result back to site 2. In this case 400,000 + 3,500 = 403,500 bytes \\nmust be transferred for Q and 4,000 + 3,500 = 7,500 bytes for Q′.\\nA more complex strategy, which sometimes works better than these simple strate-\\ngies, uses an operation called semijoin. We introduce this operation and discuss \\ndistributed execution using semijoins next.\\n23.5.3 Distributed Query Processing Using Semijoin\\nThe idea behind distributed query processing using the semijoin operation  is to \\nreduce the number of tuples in a relation before transferring it to another site. \\nIntuitively, the idea is to send the joining column of one relation R to the site where \\nthe other relation S is located; this column is then joined with S. Following that, \\nthe join attributes, along with the attributes required in the result, are projected \\nout and shipped back to the original site and joined with R. Hence, only the join-\\ning column of R is transferred in one direction, and a subset of S with no extrane-\\nous tuples or attributes is transferred in the other direction. If only a small fraction \\nof the tuples in S participate in the join, this can be an efficient solution to mini-\\nmizing data transfer.\\nTo illustrate this, consider the following strategy for executing \\nQ or Q′:\\n  1. Project the join attributes of DEPARTMENT at site 2, and transfer them to site 1. \\nFor Q, we transfer F = πDnumber(DEPARTMENT), whose size is 4 * 100 = 400 \\nbytes, whereas for Q′, we transfer F′ = πMgr_ssn(DEPARTMENT), whose size is \\n9 * 100 = 900 bytes.\\n  2. Join the transferred file with the EMPLOYEE relation at site 1, and transfer \\nthe required attributes from the resulting file to site 2. For Q, we transfer \\nR = πDno, Fname, Lname (F  Dnumber=Dno EMPLOYEE), whose size is 34 * 10,000 = \\n340,000 bytes, whereas for Q′, we transfer R′ = πMgr_ssn, Fname, Lname  \\n(F′  Mgr_ssn=Ssn EMPLOYEE), whose size is 39 * 100 = 3,900 bytes.\\n  3. Execute the query by joining the transferred file R or R′ with DEPARTMENT, \\nand present the result to the user at site 2.\\nUsing this strategy, we transfer 340,400 bytes for Q and 4,800 bytes for Q′. We lim-\\nited the EMPLOYEE attributes and tuples transmitted to site 2 in step 2 to only those \\nthat will actually be joined  with a DEPARTMENT tuple in step 3. For query Q, this \\nturned out to include all EMPLOYEE tuples, so little improvement was achieved. \\nHowever, for Q′ only 100 out of the 10,000 EMPLOYEE tuples were needed.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 876, 'page_label': '877'}, page_content='23.5 Query Processing and Optimization in Distributed Databases  863\\nThe semijoin operation was devised to formalize this strategy. A semijoin operation \\nR A=B S, where A and B are domain-compatible attributes of R and S, respectively, \\nproduces the same result as the relational algebra expression πR(R A=B S). In a dis-\\ntributed environment where R and S reside at different sites, the semijoin is typically \\nimplemented by first transferring F = πB(S) to the site where R resides and then join-\\ning F with R, thus leading to the strategy discussed here.\\nNotice that the semijoin operation is not commutative; that is,\\nR  S ≠S  R\\n23.5.4 Query and Update Decomposition\\nIn a DDBMS with no distribution transparency, the user phrases a query directly in \\nterms of specific fragments. For example, consider another query Q: Retrieve the \\nnames and hours per week for each employee who works on some project controlled \\nby department 5, which is specified on the distributed database where the relations \\nat sites 2 and 3 are shown in Figure 23.2, and those at site 1 are shown in Fig-\\nure\\xa05.6, as in our earlier example. A user who submits such a query must specify \\nwhether it references the \\nPROJS_5  and WORKS_ON_5  relations at site 2 (Fig-\\nure\\xa023.2) or the PROJECT and WORKS_ON relations at site 1 (Figure 5.6). The user \\nmust also maintain consistency of replicated data items when updating a DDBMS \\nwith no replication transparency.\\nOn the other hand, a DDBMS that supports full distribution, fragmentation,  and \\nreplication transparency  allows the user to specify a query or update request on \\nthe schema in Figure 5.5 just as though the DBMS were centralized. For updates, \\nthe DDBMS is responsible for maintaining consistency among replicated items  \\nby\\xa0using one of the distributed concurrency control algorithms discussed in \\n Section\\xa0 23.3. For queries, a query decomposition  module must break up or \\n decompose a query into subqueries that can be executed at the individual sites. \\nAdditionally, a strategy for combining the results of the subqueries to form the \\nquery result must be generated. Whenever the DDBMS determines that an item \\nreferenced in the query is replicated, it must choose or materialize  a particular \\nreplica during query execution.\\nTo determine which replicas include the data items referenced in a query, the \\nDDBMS refers to the fragmentation, replication, and distribution information \\nstored in the DDBMS catalog. For vertical fragmentation, the attribute list for \\neach fragment is kept in the catalog. For horizontal fragmentation, a condition, \\nsometimes called a guard, is kept for each fragment. This is basically a selection \\ncondition that specifies which tuples exist in the fragment; it is called a guard \\nbecause only tuples that satisfy this condition  are permitted to be stored in the \\nfragment. For mixed fragments, both the attribute list and the guard condition \\nare kept in the catalog.\\nIn our earlier example, the guard conditions for fragments at site 1 (Figure 5.6) are \\nTRUE (all tuples), and the attribute lists are * (all attributes). For the fragments'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 877, 'page_label': '878'}, page_content='864 Chapter 23 Distributed Database Concepts\\nshown in Figure 23.2, we have the guard conditions and attribute lists shown in \\nFigure 23.5. When the DDBMS decomposes an update request, it can determine \\nwhich fragments must be updated by examining their guard conditions. For exam-\\nple, a user request to insert a new \\nEMPLOYEE  tuple <‘Alex’, ‘B’, ‘Coleman’, \\n‘345671239’, ‘22-APR-64’, ‘3306 Sandstone, Houston, TX’, M, 33000, ‘987654321’, \\n4> would be decomposed by the DDBMS into two insert requests: the first inserts \\nthe preceding tuple in the EMPLOYEE fragment at site 1, and the second inserts the \\nprojected tuple <‘Alex’, ‘B’, ‘Coleman’, ‘345671239’, 33000, ‘987654321’, 4> in the \\nEMPD4 fragment at site 3.\\nFor query decomposition, the DDBMS can determine which fragments may contain \\nthe required tuples by comparing the query condition with the guard conditions. For \\nFigure 23.5 \\nGuard conditions and \\nattributes lists for  \\nfragments.  \\n(a) Site 2 fragments.  \\n(b) Site 3 fragments.\\n(a) EMPD5\\n  attribute list: Fname, Minit, Lname, Ssn, Salary, Super_ssn, Dno\\n guard condition: Dno = 5\\n DEP5\\n  attribute list: * (all attributes Dname, Dnumber, Mgr_ssn, Mgr_start_date)\\n guard condition: Dnumber = 5\\n DEP5_LOCS\\n  attribute list: * (all attributes Dnumber, Location)\\n guard condition: Dnumber = 5\\n PROJS5\\n  attribute list: * (all attributes Pname, Pnumber, Plocation, Dnum)\\n guard condition: Dnum = 5\\n WORKS_ON5\\n  attribute list: * (all attributes Essn, Pno,Hours)\\n guard condition: Essn IN (πSsn (EMPD5)) OR Pno IN (πPnumber (PROJS5))\\n(b) EMPD4\\n  attribute list: Fname, Minit, Lname, Ssn, Salary, Super_ssn, Dno\\n guard condition: Dno = 4\\n DEP4\\n  attribute list: * (all attributes Dname, Dnumber, Mgr_ssn, Mgr_start_date)\\n guard condition: Dnumber = 4\\n DEP4_LOCS\\n  attribute list: * (all attributes Dnumber, Location)\\n guard condition: Dnumber = 4\\n PROJS4\\n  attribute list: * (all attributes Pname, Pnumber, Plocation, Dnum)\\n guard condition: Dnum = 4\\n WORKS_ON4\\n  attribute list: * (all attributes Essn, Pno, Hours)\\n guard condition: Essn IN (πSsn (EMPD4))\\n  OR Pno IN (πPnumber (PROJS4))'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 878, 'page_label': '879'}, page_content='23.6 Types of Distributed Database Systems  865\\nexample, consider the query Q: Retrieve the names and hours per week for each \\nemployee who works on some project controlled by department 5 . This can be speci-\\nfied in SQL on the schema in Figure 5.5 as follows:\\nQ: SELECT Fname, Lname, Hours\\n FROM EMPLOYEE, PROJECT, WORKS_ON\\n WHERE Dnum =5 AND Pnumber=Pno AND Essn=Ssn;\\nSuppose that the query is submitted at site 2, which is where the query result will be \\nneeded. The DDBMS can determine from the guard condition on PROJS5 and \\nWORKS_ON5 that all tuples satisfying the conditions (Dnum = 5 AND Pnumber = Pno) \\nreside at site 2. Hence, it may decompose the query into the following relational alge-\\nbra subqueries:\\nT\\n1 ← πEssn(PROJS5 Pnumber=PnoWORKS_ON5)\\nT2 ← πEssn, Fname, Lname(T1 Essn=SsnEMPLOYEE)\\nRESULT ← πFname, Lname, Hours(T2* WORKS_ON5)\\nThis decomposition can be used to execute the query by using a semijoin strategy. \\nThe DDBMS knows from the guard conditions that PROJS5 contains exactly those \\ntuples satisfying (Dnum = 5) and that WORKS_ON5 contains all tuples to be joined \\nwith PROJS5; hence, subquery T1 can be executed at site 2, and the projected column \\nEssn can be sent to site 1. Subquery T2 can then be executed at site 1, and the result \\ncan be sent back to site 2, where the final query result is calculated and displayed to \\nthe user. An alternative strategy would be to send the query Q itself to site 1, which \\nincludes all the database tuples, where it would be executed locally and from which \\nthe result would be sent back to site 2. The query optimizer would estimate the costs \\nof both strategies and would choose the one with the lower cost estimate.\\n23.6 Types of Distributed Database Systems\\nThe term distributed database management system  can describe various systems \\nthat differ from one another in many respects. The main thing that all such systems \\nhave in common is the fact that data and software are distributed over multiple sites \\nconnected by some form of communication network. In this section, we discuss a \\nnumber of types of DDBMSs and the criteria and factors that make some of these \\nsystems different.\\nThe first factor we consider is the degree of homogeneity of the DDBMS software. If \\nall servers (or individual local DBMSs) use identical software and all users (clients) use \\nidentical software, the DDBMS is called homogeneous; otherwise, it is called hetero-\\ngeneous. Another factor related to the degree of homogeneity is the degree of local \\nautonomy. If there is no provision for the local site to function as a standalone DBMS, \\nthen the system has no local autonomy. On the other hand, if direct access by local \\ntransactions to a server is permitted, the system has some degree of local autonomy.\\nFigure 23.6 shows classification of DDBMS alternatives along orthogonal axes of \\ndistribution, autonomy, and heterogeneity. For a centralized database, there is'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 879, 'page_label': '880'}, page_content='866 Chapter 23 Distributed Database Concepts\\ncomplete autonomy but a total lack of distribution and heterogeneity (point A in \\nthe figure). We see that the degree of local autonomy provides further ground for \\nclassification into federated and multidatabase systems. At one extreme of the \\nautonomy spectrum, we have a DDBMS that looks like a centralized DBMS to the \\nuser, with zero autonomy (point B). A single conceptual schema exists, and all \\naccess to the system is obtained through a site that is part of the DDBMS—which \\nmeans that no local autonomy exists. Along the autonomy axis we encounter two \\ntypes of DDBMSs called federated database system  (point C) and multidatabase \\nsystem (point D). In such systems, each server is an independent and autonomous \\ncentralized DBMS that has its own local users, local transactions, and DBA, and \\nhence has a very high degree of local autonomy.  The term federated database \\n system (FDBS) is used when there is some global view or schema of the federation \\nof databases that is shared by the applications (point C). On the other hand, a \\n multidatabase system  has full local autonomy in that it does not have a global \\nschema but interactively constructs one as needed by the application (point D). \\nBoth systems are hybrids between distributed and centralized systems, and the \\ndistinction we made between them is not strictly followed. We will refer to them as \\nFDBSs in a generic sense. Point D in the diagram may also stand for a system with \\nfull local autonomy and full heterogeneity—this could be a peer-to-peer database \\nsystem. In a heterogeneous FDBS, one server may be a relational DBMS, another a \\nnetwork DBMS (such as Computer Associates’ IDMS or HP’S IMAGE/3000), and \\nB\\nDistribution\\nHeterogeneity\\nLegend:\\nA: Traditional centralized database \\n systems\\nB: Pure distributed dat abase systems\\nC:  Federated database systems\\nD: Multidatabase or peer-to-peer \\n database systems\\nC D\\nA\\nAutonomy\\nFigure 23.6 \\nClassification  \\nof distributed \\ndatabases.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 880, 'page_label': '881'}, page_content='23.6 Types of Distributed Database Systems  867\\na third an object DBMS (such as Object Design’s ObjectStore) or hierarchical \\nDBMS (such as IBM’s IMS); in such a case, it is necessary to have a canonical system \\n language and to include language translators to translate subqueries from the \\ncanonical language to the language of each server.\\nWe briefly discuss the issues affecting the design of FDBSs next.\\n23.6.1 Federated Database Management Systems Issues\\nThe type of heterogeneity present in FDBSs may arise from several sources. We \\ndiscuss these sources first and then point out how the different types of autonomies \\ncontribute to a semantic heterogeneity that must be resolved in a heterogeneous \\nFDBS.\\n ■ Differences in data models. Databases in an organization come from a vari-\\nety of data models, including the so-called legacy models (hierarchical and \\nnetwork), the relational data model, the object data model, and even files. \\nThe modeling capabilities of the models vary. Hence, to deal with them uni-\\nformly via a single global schema or to process them in a single language is \\nchallenging. Even if two databases are both from the RDBMS environment, \\nthe same information may be represented as an attribute name, as a relation \\nname, or as a value in different databases. This calls for an intelligent query-\\nprocessing mechanism that can relate information based on metadata.\\n ■ Differences in constraints. Constraint facilities for specification and imple-\\nmentation vary from system to system. There are comparable features that \\nmust be reconciled in the construction of a global schema. For example, the \\nrelationships from ER models are represented as referential integrity con-\\nstraints in the relational model. Triggers may have to be used to implement \\ncertain constraints in the relational model. The global schema must also deal \\nwith potential conflicts among constraints.\\n ■ Differences in query languages.  Even with the same data model, the lan-\\nguages and their versions vary. For example, SQL has multiple versions like \\nSQL-89, SQL-92, SQL-99, and SQL:2008, and each system has its own set of \\ndata types, comparison operators, string manipulation features, and so on.\\nSemantic Heterogeneity. Semantic heterogeneity occurs when there are differ-\\nences in the meaning, interpretation, and intended use of the same or related data. \\nSemantic heterogeneity among component database systems (DBSs) creates the \\nbiggest hurdle in designing global schemas of heterogeneous databases. The design \\nautonomy of component DBSs refers to their freedom of choosing the following \\ndesign parameters; the design parameters in turn affect the eventual complexity of \\nthe FDBS:\\n ■ The universe of discourse from which the data is drawn.  For example, for \\ntwo customer accounts, databases in the federation may be from the United \\nStates and Japan and have entirely different sets of attributes about customer \\naccounts required by the accounting practices. Currency rate fluctuations'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 881, 'page_label': '882'}, page_content='868 Chapter 23 Distributed Database Concepts\\nwould also present a problem. Hence, relations in these two databases that \\nhave identical names—CUSTOMER or ACCOUNT—may have some common \\nand some entirely distinct information.\\n ■ Representation and naming.  The representation and naming of data ele-\\nments and the structure of the data model may be prespecified for each local \\ndatabase.\\n ■ The understanding, meaning, and subjective interpretation of data.  This \\nis a chief contributor to semantic heterogeneity.\\n ■ Transaction and policy constraints. These deal with serializability criteria, \\ncompensating transactions, and other transaction policies.\\n ■ Derivation of summaries.  Aggregation, summarization, and other data-\\nprocessing features and operations supported by the system.\\nThe above problems related to semantic heterogeneity are being faced by all major \\nmultinational and governmental organizations in all application areas. In today’s \\ncommercial environment, most enterprises are resorting to heterogeneous FDBSs, \\nhaving heavily invested in the development of individual database systems using \\ndiverse data models on different platforms over the last 20 to 30 years. Enterprises \\nare using various forms of software—typically called the middleware ; or Web-\\nbased packages called application servers (for example, WebLogic or WebSphere); \\nand even generic systems, called enterprise resource planning (ERP) systems (for \\nexample, SAP, J. D. Edwards ERP)—to manage the transport of queries and trans-\\nactions from the global application to individual databases (with possible additional \\nprocessing for business rules) and the data from the heterogeneous database servers \\nto the global application. Detailed discussion of these types of software systems is \\noutside the scope of this text.\\nJust as providing the ultimate transparency is the goal of any distributed database \\narchitecture, local component databases strive to preserve autonomy. \\n Communication autonomy  of a component DBS refers to its ability to decide \\nwhether to communicate with another component DBS. Execution autonomy  \\nrefers to the ability of a component DBS to execute local operations without inter-\\nference from external operations by other component DBSs and its ability to decide \\nthe order in which to execute them. The association autonomy  of a component \\nDBS implies that it has the ability to decide whether and how much to share its \\nfunctionality (operations it supports) and resources (data it manages) with other \\ncomponent DBSs. The major challenge of designing FDBSs is to let component \\nDBSs interoperate while still providing the above types of autonomies to them.\\n23.7 Distributed Database Architectures\\nIn this section, we first briefly point out the distinction between parallel and distrib-\\nuted database architectures. Although both are prevalent in industry today, there are \\nvarious manifestations of the distributed architectures that are continuously evolv-\\ning among large enterprises. The parallel architecture is more common in high-per-'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 882, 'page_label': '883'}, page_content='23.7 Distributed Database Architectures  869\\nformance computing, where there is a need for multiprocessor architectures to cope \\nwith the volume of data undergoing transaction processing and  warehousing \\n applications. We then introduce a generic architecture of a distributed database. \\nThis is followed by discussions on the architecture of three-tier client/server and \\nfederated database systems.\\n23.7.1 Parallel versus Distributed Architectures\\nThere are two main types of multiprocessor system architectures that are com-\\nmonplace:\\n ■ Shared memory (tightly coupled) architecture.  Multiple processors share \\nsecondary (disk) storage and also share primary memory.\\n ■ Shared disk (loosely coupled) architecture.  Multiple processors share sec-\\nondary (disk) storage but each has their own primary memory.\\nThese architectures enable processors to communicate without the overhead of \\nexchanging messages over a network. 4 Database management systems developed \\nusing the above types of architectures are termed parallel database management \\nsystems rather than DDBMSs, since they utilize parallel processor technology. \\nAnother type of multiprocessor architecture is called shared-nothing architecture. \\nIn this architecture, every processor has its own primary and secondary (disk) \\nmemory, no common memory exists, and the processors communicate over a high-\\nspeed interconnection network (bus or switch). Although the shared-nothing \\narchitecture resembles a distributed database computing environment, major dif-\\nferences exist in the mode of operation. In shared-nothing multiprocessor systems, \\nthere is symmetry and homogeneity of nodes; this is not true of the distributed \\ndatabase environment, where heterogeneity of hardware and operating system at \\neach node is very common. Shared-nothing architecture is also considered as an \\nenvironment for parallel databases. Figure 23.7(a) illustrates a parallel database \\n(shared nothing), whereas Figure 23.7(b) illustrates a centralized database with dis-\\ntributed access and Figure 23.7(c) shows a pure distributed database. We will not \\nexpand on parallel architectures and related data management issues here.\\n23.7.2 General Architecture of Pure Distributed Databases\\nIn this section, we discuss both the logical and component architectural models of a \\nDDB. In Figure 23.8, which describes the generic schema architecture of a DDB, the \\nenterprise is presented with a consistent, unified view showing the logical structure \\nof underlying data across all nodes. This view is represented by the global concep-\\ntual schema (GCS), which provides network transparency (see Section 23.1.2). To \\naccommodate potential heterogeneity in the DDB, each node is shown as having its \\nown local internal schema (LIS) based on physical organization details at that \\n4If both primary and secondary memories are shared, the architecture is also known as shared- every-\\nthing architecture.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 883, 'page_label': '884'}, page_content='870 Chapter 23 Distributed Database Concepts\\n particular site. The logical organization of data at each site is specified by the local \\nconceptual schema (LCS). The GCS, LCS, and their underlying mappings provide \\nthe fragmentation and replication transparency discussed in Section 23.1.2. Fig-\\nure\\xa023.8 shows the component architecture of a DDB. It is an extension of its cen-\\ntralized counterpart (Figure 2.3) in Chapter 2. For the sake of simplicity, common \\n(a)\\n(b)\\nSwitch\\nCPU\\nComputer System 1\\nMemory\\nDB CPU\\nComputer System 2\\nMemory\\nDB\\nCPU\\nMemory\\nDB\\nComputer System n\\nCentral Site\\n(Chicago)\\nSite\\n(New York)\\nSite\\n(Los Angeles)\\nSite\\n(Atlanta)\\nSite\\n(San Francisco)\\nDB1 DB2\\nCommunications\\nNetwork\\n(c)\\nSite 5\\nSite 1\\nSite 2\\nSite 4\\nSite 3\\nCommunications\\nNetwork\\nFigure 23.7 \\nSome different database system architectures. (a) Shared-nothing architecture. (b) A networked architecture with a \\ncentralized database at one of the sites. (c) A truly distributed database architecture.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 884, 'page_label': '885'}, page_content='23.7 Distributed Database Architectures  871\\nelements are not shown here. The global query compiler references the global \\n conceptual schema from the global system catalog to verify and impose defined \\nconstraints. The global query optimizer references both global and local conceptual \\nschemas and generates optimized local queries from global queries. It evaluates all \\ncandidate strategies using a cost function that estimates cost based on response \\ntime (CPU, I/O, and network latencies) and estimated sizes of intermediate results. \\nThe latter is particularly important in queries involving joins. Having computed the \\ncost for each candidate, the optimizer selects the candidate with the minimum cost \\nfor execution. Each local DBMS would have its local query optimizer, transaction \\nmanager, and execution engines as well as the local system catalog, which houses the \\nlocal schemas. The global transaction manager is responsible for coordinating the \\nexecution across multiple sites in conjunction with the local transaction manager at \\nthose sites.\\n23.7.3 Federated Database Schema Architecture\\nTypical five-level schema architecture to support global applications in the FDBS \\nenvironment is shown in Figure 23.9. In this architecture, the local schema is the \\nUser\\nStored \\nData\\nGlobal Conceptual Schema (GCS)\\nExternal\\nView\\nUser\\nExternal\\nView\\nLocal Conceptual Schema (LCS) Local Conceptual Schema (LCS)\\nLocal Internal Schema (LIS) Local Internal Schema (LIS)\\nStored \\nData\\nSite 1 Site nSites 2 to n–1\\nFigure 23.8 \\nSchema architecture of \\ndistributed databases.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 885, 'page_label': '886'}, page_content='872 Chapter 23 Distributed Database Concepts\\nconceptual schema (full database definition) of a component database, and the \\ncomponent schema is derived by translating the local schema into a canonical data \\nmodel or common data model (CDM) for the FDBS. Schema translation from the \\nlocal schema to the component schema is accompanied by generating mappings to \\ntransform commands on a component schema into commands on the correspond-\\ning local schema. The export schema represents the subset of a component schema \\nthat is available to the FDBS. The federated schema is the global schema or view, \\nwhich is the result of integrating all the shareable export schemas. The external \\nschemas define the schema for a user group or an application, as in the three-level \\nschema architecture.\\nAll the problems related to query processing, transaction processing, and directory \\nand metadata management and recovery apply to FDBSs with additional consider-\\nations. It is not within our scope to discuss them in detail here.\\n23.7.4 An Overview of Three-Tier Client/Server Architecture\\nAs we pointed out in the chapter introduction, full-scale DDBMSs have not been \\ndeveloped to support all the types of functionalities that we have discussed so far. \\nInstead, distributed database applications are being developed in the context of the \\nclient/server architectures. We introduced the two-tier client/server architecture in \\nExternal \\nschema\\nFederated \\nschema\\n. . .\\n. . .\\n. . .\\n. . .\\n. . .\\nComponent \\nschema\\nLocal \\nschema\\nComponent \\nDBS\\nExternal \\nschema\\nExternal \\nschema\\nFederated \\nschema\\nExport \\nschema\\nComponent \\nschema\\nLocal \\nschema\\nComponent \\nDBS\\nExport \\nschema\\nExport \\nschema\\nFigure 23.9 \\nThe five-level schema architecture  \\nin a federated database system  \\n(FDBS).\\nSource: Adapted from Sheth and  \\nLarson, “Federated Database Systems \\nfor Managing Distributed,  \\nHeterogeneous, and Autonomous  \\nDatabases.” ACM Computing Surveys \\n(Vol. 22: No. 3, September 1990).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 886, 'page_label': '887'}, page_content='23.7 Distributed Database Architectures  873\\nSection 2.5. It is now more common to use a three-tier architecture rather than a \\ntwo-tier architecture, particularly in Web applications. This architecture is illus-\\ntrated in Figure 23.10.\\nIn the three-tier client/server architecture, the following three layers exist:\\n  1. Presentation layer (client).  This provides the user interface and interacts \\nwith the user. The programs at this layer present Web interfaces or forms to \\nthe client in order to interface with the application. Web browsers are often \\nutilized, and the languages and specifications used include HTML, XHTML, \\nCSS, Flash, MathML, Scalable Vector Graphics (SVG), Java, JavaScript, \\nAdobe Flex, and others. This layer handles user input, output, and naviga-\\ntion by accepting user commands and displaying the needed information, \\nusually in the form of static or dynamic Web pages. The latter are employed \\nwhen the interaction involves database access. When a Web interface is \\nused, this layer typically communicates with the application layer via the \\nHTTP protocol.\\n  2. Application layer (business logic).  This layer programs the application \\nlogic. For example, queries can be formulated based on user input from the \\nclient, or query results can be formatted and sent to the client for presenta-\\ntion. Additional application functionality can be handled at this layer, such \\nas security checks, identity verification, and other functions. The application \\nlayer can interact with one or more databases or data sources as needed by \\nconnecting to the database using ODBC, JDBC, SQL/CLI, or other database \\naccess techniques.\\nClient\\nUser interface or presentation tier\\n(Web browser, HTML, JavaScript, Visual Basic, . . .)\\nHTTP Protocol\\nApplication server\\nApplication (business) logic tier\\n(Application program, JAVA, C/C++, C#, . . .)\\nDatabase server\\nQuery and transaction processing tier\\n(Database access, SQL, PSM, XML, . . .)\\nODBC, JDBC, SQL/CLI, SQLJ\\nFigure 23.10 \\nThe three-tier client/server \\narchitecture.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 887, 'page_label': '888'}, page_content='874 Chapter 23 Distributed Database Concepts\\n  3. Database server.  This layer handles query and update requests from the \\napplication layer, processes the requests, and sends the results. Usually SQL \\nis used to access the database if it is relational or object-relational, and stored \\ndatabase procedures may also be invoked. Query results (and queries) may \\nbe formatted into XML (see Chapter 13) when transmitted between the \\napplication server and the database server.\\nExactly how to divide the DBMS functionality among the client, application server, \\nand database server may vary. The common approach is to include the functional-\\nity of a centralized DBMS at the database server level. A number of relational DBMS \\nproducts have taken this approach, in which an SQL server is provided. The appli-\\ncation server must then formulate the appropriate SQL queries and connect to the \\ndatabase server when needed. The client provides the processing for user interface \\ninteractions. Since SQL is a relational standard, various SQL servers, possibly pro-\\nvided by different vendors, can accept SQL commands through standards such as \\nODBC, JDBC, and SQL/CLI (see Chapter 10).\\nIn this architecture, the application server may also refer to a data dictionary \\nthat includes information on the distribution of data among the various SQL \\nservers, as well as modules for decomposing a global query into a number of \\nlocal queries that can be executed at the various sites. Interaction between an \\napplication server and database server might proceed as follows during the pro-\\ncessing of an SQL query:\\n  1. The application server formulates a user query based on input from the cli-\\nent layer and decomposes it into a number of independent site queries. Each \\nsite query is sent to the appropriate database server site.\\n  2. Each database server processes the local query and sends the results to the \\napplication server site. Increasingly, XML is being touted as the standard for \\ndata exchange (see Chapter 13), so the database server may format the query \\nresult into XML before sending it to the application server.\\n  3. The application server combines the results of the subqueries to produce the \\nresult of the originally required query, formats it into HTML or some other \\nform accepted by the client, and sends it to the client site for display.\\nThe application server is responsible for generating a distributed execution plan for \\na multisite query or transaction and for supervising distributed execution by send-\\ning commands to servers. These commands include local queries and transactions \\nto be executed, as well as commands to transmit data to other clients or servers. \\nAnother function controlled by the application server (or coordinator) is that of \\nensuring consistency of replicated copies of a data item by employing distributed \\n(or global) concurrency control techniques. The application server must also ensure \\nthe atomicity of global transactions by performing global recovery when certain \\nsites fail.\\nIf the DDBMS has the capability to hide the details of data distribution from the \\napplication server, then it enables the application server to execute global queries \\nand transactions as though the database were centralized, without having to specify'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 888, 'page_label': '889'}, page_content='23.8 Distributed Catalog Management  875\\nthe sites at which the data referenced in the query or transaction resides. This \\n property is called distribution transparency. Some DDBMSs do not provide distri-\\nbution transparency, instead requiring that applications are aware of the details of \\ndata distribution.\\n23.8 Distributed Catalog Management\\nEfficient catalog management in distributed databases is critical to ensure satisfac-\\ntory performance related to site autonomy, view management, and data distribu-\\ntion and replication. Catalogs are databases themselves containing metadata about \\nthe distributed database system.\\nThree popular management schemes for distributed catalogs are centralized cata-\\nlogs, fully replicated  catalogs, and partitioned catalogs. The choice of the scheme \\ndepends on the database itself as well as the access patterns of the applications to \\nthe underlying data.\\nCentralized Catalogs. In this scheme, the entire catalog is stored in one single \\nsite. Due to its central nature, it is easy to implement. On the other hand, the \\nadvantages of reliability, availability, autonomy, and distribution of processing \\nload are adversely impacted. For read operations from noncentral sites, the \\nrequested catalog data is locked at the central site and is then sent to the \\nrequesting site. On completion of the read operation, an acknowledgment is \\nsent to the central site, which in turn unlocks this data. All update operations \\nmust be processed through the central site. This can quickly become a perfor-\\nmance bottleneck for write-intensive applications.\\nFully Replicated Catalogs.  In this scheme, identical copies of the complete \\ncatalog are present at each site. This scheme facilitates faster reads by allowing \\nthem to be answered locally. However, all updates must be broadcast to all \\nsites. Updates are treated as transactions, and a centralized two-phase commit \\nscheme is employed to ensure catalog consistency. As with the centralized \\nscheme, write-intensive applications may cause increased network traffic due \\nto the broadcast associated with the writes.\\nPartially Replicated Catalogs.  The centralized and fully replicated schemes \\nrestrict site autonomy since they must ensure a consistent global view of the \\ncatalog. Under the partially replicated scheme, each site maintains complete \\ncatalog information on data stored locally at that site. Each site is also permit-\\nted to cache entries retrieved from remote sites. However, there are no guaran-\\ntees that these cached copies will be the most recent and updated. The system \\ntracks catalog entries for sites where the object was created and for sites that \\ncontain copies of this object. Any changes to copies are propagated immedi-\\nately to the original (birth) site. Retrieving updated copies to replace stale data \\nmay be delayed until an access to this data occurs. In general, fragments of rela-\\ntions across sites should be uniquely accessible. Also, to ensure data distribu-\\ntion transparency, users should be allowed to create synonyms for remote \\nobjects and use these synonyms for subsequent referrals.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 889, 'page_label': '890'}, page_content='876 Chapter 23 Distributed Database Concepts\\n23.9 Summary\\nIn this chapter, we provided an introduction to distributed databases. This is a very \\nbroad topic, and we discussed only some of the basic techniques used with distrib-\\nuted databases. First in Section 23.1 we discussed the reasons for distribution and \\nDDB concepts in Section 23.1.1. Then we defined the concept of distribution trans-\\nparency and the related concepts of fragmentation transparency and replication \\ntransparency in Section 23.1.2. We discussed the concepts of distributed availability \\nand reliability in Section 23.1.3, and gave an overview of scalability and partition \\ntolerance issues in Section 23.1.4. We discussed autonomy of nodes in a distributed \\nsystem in Section 23.1.5 and the potential advantages of distributed databases over \\ncentralized system in Section 23.1.6.\\nIn Section 23.2, we discussed the design issues related to data fragmentation, \\nreplication, and distribution. We distinguished between horizontal fragmenta-\\ntion (sharding) and vertical fragmentation of relations in Section 23.2.1. We \\nthen discussed in Section 23.2.2 the use of data replication to improve system \\nreliability and availability. In Section 23.3, we briefly discussed the concur-\\nrency control and recovery techniques used in DDBMSs, and then reviewed \\nsome of the additional problems that must be dealt with in a distributed envi-\\nronment that do not appear in a centralized environment. Then in Section 23.4 \\nwe discussed transaction management, including different commit protocols \\n(2-phase commit, 3-phase commit) and operating system support for transac-\\ntion management.\\nWe then illustrated some of the techniques used in distributed query processing in \\nSection 23.5, and discussed the cost of communication among sites, which is con-\\nsidered a major factor in distributed query optimization. We compared the differ-\\nent techniques for executing joins, and we then presented the semijoin technique \\nfor joining relations that reside on different sites in Section 23.5.3.\\nFollowing that, in Section 23.6, we categorized DDBMSs by using criteria such as \\nthe degree of homogeneity of software modules and the degree of local autonomy. \\nIn Section 23.7 we distinguished between parallel and distributed system architec-\\ntures and then introduced the generic architecture of distributed databases from \\nboth a component as well as a schematic architectural perspective. In Section 23.7.3 \\nwe discussed in some detail issues of federated database management, and we \\nfocused on the needs of supporting various types of autonomies and dealing with \\nsemantic heterogeneity. We also reviewed the client/server architecture concepts \\nand related them to distributed databases in Section 23.7.4. We reviewed catalog \\nmanagement in distributed databases and summarized their relative advantages \\nand disadvantages in Section 23.8.\\nChapters 24 and 25 will describe recent advances in distributed databases and dis-\\ntributed computing related to big data. Chapter 24 describes the so-called NOSQL \\nsystems, which are highly scalable, distributed database systems that handle large \\nvolumes of data. Chapter 25 discusses cloud computing and distributed computing \\ntechnologies that are needed to process big data.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 890, 'page_label': '891'}, page_content='Review Questions 877\\nReview Questions\\n 23.1. What are the main reasons for and potential advantages of distributed \\n databases?\\n 23.2. What additional functions does a DDBMS have over a centralized DBMS?\\n 23.3. Discuss what is meant by the following terms: degree of homogeneity of a \\nDDBMS, degree of local autonomy of a DDBMS , federated DBMS, distribu-\\ntion transparency , fragmentation transparency , replication transparency , \\nmultidatabase system.\\n 23.4. Discuss the architecture of a DDBMS. Within the context of a centralized \\nDBMS, briefly explain new components introduced by the distribution of \\ndata.\\n 23.5. What are the main software modules of a DDBMS? Discuss the main \\nfunctions of each of these modules in the context of the client/server \\narchitecture.\\n 23.6. Compare the two-tier and three-tier client/server architectures.\\n 23.7. What is a fragment of a relation? What are the main types of fragments? \\nWhy is fragmentation a useful concept in distributed database design?\\n 23.8. Why is data replication useful in DDBMSs? What typical units of data are \\nreplicated?\\n 23.9. What is meant by data allocation in distributed database design? What typi-\\ncal units of data are distributed over sites?\\n 23.10. How is a horizontal partitioning of a relation specified? How can a relation \\nbe put back together from a complete horizontal partitioning?\\n 23.11. How is a vertical partitioning of a relation specified? How can a relation be \\nput back together from a complete vertical partitioning?\\n 23.12. Discuss the naming problem in distributed databases.\\n 23.13. What are the different stages of processing a query in a DDBMS?\\n 23.14. Discuss the different techniques for executing an equijoin of two files located \\nat different sites. What main factors affect the cost of data transfer?\\n 23.15. Discuss the semijoin method for executing an equijoin of two files located at \\ndifferent sites. Under what conditions is an equijoin strategy efficient?\\n 23.16. Discuss the factors that affect query decomposition. How are guard condi-\\ntions and attribute lists of fragments used during the query decomposition \\nprocess?\\n 23.17. How is the decomposition of an update request different from the decompo-\\nsition of a query? How are guard conditions and attribute lists of fragments \\nused during the decomposition of an update request?'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 891, 'page_label': '892'}, page_content=\"878 Chapter 23 Distributed Database Concepts\\n 23.18. List the support offered by operating systems to a DDBMS and also the ben-\\nefits of these supports.\\n 23.19. Discuss the factors that do not appear in centralized systems but that affect \\nconcurrency control and recovery in distributed systems.\\n 23.20. Discuss the two-phase commit protocol used for transaction management \\nin a DDBMS. List its limitations and explain how they are overcome using \\nthe three-phase commit protocol.\\n 23.21. Compare the primary site method with the primary copy method for dis-\\ntributed concurrency control. How does the use of backup sites affect each?\\n 23.22. When are voting and elections used in distributed databases?\\n 23.23.  Discuss catalog management in distributed databases.\\n 23.24. What are the main challenges facing a traditional DDBMS in the context of \\ntoday’s Internet applications? How does cloud computing attempt to address \\nthem?\\n 23.25. Discuss briefly the support offered by Oracle for homogeneous, heteroge-\\nneous, and client/server-based distributed database architectures.\\n 23.26. Discuss briefly online directories, their management, and their role in dis-\\ntributed databases.\\nExercises\\n 23.27. Consider the data distribution of the COMPANY database, where the frag-\\nments at sites 2 and 3 are as shown in Figure 23.3 and the fragments at site 1 \\nare as shown in Figure 3.6. For each of the following queries, show at least \\ntwo strategies of decomposing and executing the query. Under what condi-\\ntions would each of your strategies work well?\\na. For each employee in department 5, retrieve the employee name and the \\nnames of the employee's dependents.\\nb. Print the names of all employees who work in department 5 but who \\nwork on some project not controlled by department 5.\\n 23.28. Consider the following relations:\\nBOOKS(Book#, Primary_author, Topic, Total_stock, $price)\\nBOOKSTORE(Store#, City, State, Zip, Inventory_value)\\nSTOCK(Store#, Book#, Qty)\\n  Total_stock is the total number of books in stock, and Inventory_value is the \\ntotal inventory value for the store in dollars.\\na. Give an example of two simple predicates that would be meaningful for \\nthe \\nBOOKSTORE relation for horizontal partitioning.\"),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 892, 'page_label': '893'}, page_content='Exercises 879\\nb. How would a derived horizontal partitioning of STOCK be defined based \\non the partitioning of BOOKSTORE?\\nc. Show predicates by which BOOKS may be horizontally partitioned by \\ntopic.\\nd. Show how the STOCK may be further partitioned from the partitions in \\n(b) by adding the predicates in (c).\\n 23.29. Consider a distributed database for a bookstore chain called National Books \\nwith three sites called EAST, MIDDLE, and WEST. The relation schemas are \\ngiven in Exercise 23.28. Consider that BOOKS are fragmented by $price \\namounts into:\\nB1: BOOK1: $price up to $20\\nB2: BOOK2: $price from $20.01 to $50\\nB3: BOOK3: $price from $50.01 to $100\\nB4: BOOK4: $price $100.01 and above\\n  Similarly, BOOK_STORES are divided by zip codes into:\\nS1: EAST: Zip up to 35000\\nS2: MIDDLE: Zip 35001 to 70000\\nS3: WEST: Zip 70001 to 99999\\n  Assume that STOCK is a derived fragment based on BOOKSTORE only.\\na. Consider the query:\\nSELECT Book#, Total_stock\\nFROM Books\\nWHERE $price > 15 AND $price < 55;\\n  Assume that fragments of BOOKSTORE are nonreplicated and assigned \\nbased on region. Assume further that BOOKS are allocated as:\\nEAST: B1, B4\\nMIDDLE: B1, B2\\nWEST: B1, B2, B3, B4\\n  Assuming the query was submitted in EAST, what remote subqueries does it \\ngenerate? (Write in SQL.)\\nb. If the price of Book# = 1234 is updated from $45 to $55 at site MIDDLE, \\nwhat updates does that generate? Write in English and then in SQL.\\nc. Give a sample query issued at WEST that will generate a subquery for \\n MIDDLE.\\nd. Write a query involving selection and projection on the above rela-\\ntions and show two possible query trees that denote different ways of \\nexecution.\\n 23.70. Consider that you have been asked to propose a database architecture in a \\nlarge organization (General Motors, for example) to consolidate all data'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 893, 'page_label': '894'}, page_content='880 Chapter 23 Distributed Database Concepts\\nincluding legacy databases (from hierarchical and network models; no spe-\\ncific knowledge of these models is needed) as well as relational databases, \\nwhich are geographically distributed so that global applications can be sup-\\nported. Assume that alternative 1 is to keep all databases as they are, whereas \\nalternative 2 is to first convert them to relational and then support the appli-\\ncations over a distributed integrated database.\\na. Draw two schematic diagrams for the above alternatives showing the \\nlinkages among appropriate schemas. For alternative 1, choose the \\napproach of providing export schemas for each database and construct-\\ning unified schemas for each application.\\nb. List the steps that you would have to go through under each alternative \\nfrom the present situation until global applications are viable.\\nc. Compare these alternatives from the issues of:\\n  i. design time considerations\\nii. runtime considerations\\nSelected Bibliography\\nThe textbooks by Ceri and Pelagatti (1984a) and Ozsu and Valduriez (1999) are \\ndevoted to distributed databases. Peterson and Davie (2008), Tannenbaum (2003), \\nand Stallings (2007) cover data communications and computer networks. Comer \\n(2008) discusses networks and internets. Ozsu et al. (1994) has a collection of papers \\non distributed object management.\\nMost of the research on distributed database design, query processing, and optimi-\\nzation occurred in the 1980s and 1990s; we quickly review the important references \\nhere. Distributed database design has been addressed in terms of horizontal and \\nvertical fragmentation, allocation, and replication. Ceri et al. (1982) defined the \\nconcept of minterm horizontal fragments. Ceri et al. (1983) developed an integer \\nprogramming-based optimization model for horizontal fragmentation and alloca-\\ntion. Navathe et al. (1984) developed algorithms for vertical fragmentation based \\non attribute affinity and showed a variety of contexts for vertical fragment alloca-\\ntion. Wilson and Navathe (1986) present an analytical model for optimal allocation \\nof fragments. Elmasri et al. (1987) discuss fragmentation for the ECR model; Karla-\\npalem et al. (1996) discuss issues for distributed design of object databases. Navathe \\net al. (1996) discuss mixed fragmentation by combining horizontal and vertical \\nfragmentation; Karlapalem et al. (1996) present a model for redesign of distributed \\ndatabases.\\nDistributed query processing, optimization, and decomposition are discussed in \\nHevner and Yao (1979), Kerschberg et al. (1982), Apers et al. (1983), Ceri and Pela-\\ngatti (1984), and Bodorick et al. (1992). Bernstein and Goodman (1981) discuss the \\ntheory behind semijoin processing. Wong (1983) discusses the use of relationships \\nin relation fragmentation. Concurrency control and recovery schemes are discussed \\nin Bernstein and Goodman (1981a). Kumar and Hsu (1998) compile some articles'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 894, 'page_label': '895'}, page_content='Selected Bibliography 881\\nrelated to recovery in distributed databases. Elections in distributed systems are \\ndiscussed in Garcia-Molina (1982). Lamport (1978) discusses problems with gener-\\nating unique timestamps in a distributed system. Rahimi and Haug (2007) discuss a \\nmore flexible way to construct query critical metadata for P2P databases. Ouzzani \\nand Bouguettaya (2004) outline fundamental problems in distributed query pro-\\ncessing over Web-based data sources.\\nA concurrency control technique for replicated data that is based on voting is pre-\\nsented by Thomas (1979). Gifford (1979) proposes the use of weighted voting, and \\nParis (1986) describes a method called voting with witnesses. Jajodia and Mutchler \\n(1990) discuss dynamic voting. A technique called available copy  is proposed by \\nBernstein and Goodman (1984), and one that uses the idea of a group is presented \\nin ElAbbadi and Toueg (1988). Other work that discusses replicated data includes \\nGladney (1989), Agrawal and ElAbbadi (1990), ElAbbadi and Toueg (1989), Kumar \\nand Segev (1993), Mukkamala (1989), and Wolfson and Milo (1991). Bassiouni \\n(1988) discusses optimistic protocols for DDB concurrency control. Garcia-Molina \\n(1983) and Kumar and Stonebraker (1987) discuss techniques that use the seman-\\ntics of the transactions. Distributed concurrency control techniques based on lock-\\ning and distinguished copies are presented by Menasce et al. (1980) and Minoura \\nand Wiederhold (1982). Obermark (1982) presents algorithms for distributed \\ndeadlock detection. In more recent work, Vadivelu et al. (2008) propose using \\nbackup mechanism and multilevel security to develop algorithms for improving \\nconcurrency. Madria et al. (2007) propose a mechanism based on a multiversion \\ntwo-phase locking scheme and timestamping to address concurrency issues specific \\nto mobile database systems. Boukerche and Tuck (2001) propose a technique that \\nallows transactions to be out of order to a limited extent. They attempt to ease the \\nload on the application developer by exploiting the network environment and pro-\\nducing a schedule equivalent to a temporally ordered serial schedule. Han et al. \\n(2004) propose a deadlock-free and serializable extended Petri net model for Web-\\nbased distributed real-time databases.\\nA survey of recovery techniques in distributed systems is given by Kohler (1981). \\nReed (1983) discusses atomic actions on distributed data. Bhargava (1987) presents \\nan edited compilation of various approaches and techniques for concurrency and \\nreliability in distributed systems.\\nFederated database systems were first defined in McLeod and Heimbigner (1985). \\nTechniques for schema integration in federated databases are presented by Elmasri \\net al. (1986), Batini et al. (1987), Hayne and Ram (1990), and Motro (1987). \\nElmagarmid and Helal (1988) and Gamal-Eldin et al. (1988) discuss the update \\nproblem in heterogeneous DDBSs. Heterogeneous distributed database issues are \\ndiscussed in Hsiao and Kamel (1989). Sheth and Larson (1990) present an exhaus-\\ntive survey of federated database management.\\nSince the late 1980s, multidatabase systems and interoperability have become \\nimportant topics. Techniques for dealing with semantic incompatibilities among \\nmultiple databases are examined in DeMichiel (1989), Siegel and Madnick (1991), \\nKrishnamurthy et al. (1991), and Wang and Madnick (1989). Castano et al. (1998)'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 895, 'page_label': '896'}, page_content='882 Chapter 23 Distributed Database Concepts\\npresent an excellent survey of techniques for analysis of schemas. Pitoura et al. \\n(1995) discuss object orientation in multidatabase systems. Xiao et al. (2003) pro-\\npose an XML-based model for a common data model for multidatabase systems \\nand present a new approach for schema mapping based on this model. Lakshmanan \\net al. (2001) propose extending SQL for interoperability and describe the architec-\\nture and algorithms for achieving the same.\\nTransaction processing in multidatabases is discussed in Mehrotra et al. (1992), \\nGeorgakopoulos et al. (1991), Elmagarmid et al. (1990), and Brietbart et al. \\n(1990), among others. Elmagarmid (1992) discusses transaction processing for \\nadvanced applications, including engineering applications that are discussed in \\nHeiler et al. (1992).\\nThe workflow systems, which are becoming popular for managing information in \\ncomplex organizations, use multilevel and nested transactions in conjunction with \\ndistributed databases. Weikum (1991) discusses multilevel transaction manage-\\nment. Alonso et al. (1997) discuss limitations of current workflow systems. Lopes et \\nal. (2009) propose that users define and execute their own workflows using a client-\\nside Web browser. They attempt to leverage Web 2.0 trends to simplify the user’s \\nwork for workflow management. Jung and Yeom (2008) exploit data workflow to \\ndevelop an improved transaction management system that provides simultaneous, \\ntransparent access to the heterogeneous storages that constitute the HVEM \\nDataGrid. Deelman and Chervanak (2008) list the challenges in data-intensive sci-\\nentific workflows. Specifically, they look at automated management of data, effi-\\ncient mapping techniques, and user feedback issues in workflow mapping. They \\nalso argue for data reuse as an efficient means to manage data and present the chal-\\nlenges therein.\\nA number of experimental distributed DBMSs have been implemented. These \\ninclude distributed INGRES by Epstein et al. (1978), DDTS by Devor and Weel-\\ndreyer (1980), SDD-1 by Rothnie et al. (1980), System R * by Lindsay et al. (1984), \\nSIRIUS-DELTA by Ferrier and Stangret (1982), and MULTIBASE by Smith et al. \\n(1981). The OMNIBASE system by Rusinkiewicz et al. (1988) and the Federated \\nInformation Base developed using the Candide data model by Navathe et al. (1994) \\nare examples of federated DDBMSs. Pitoura et al. (1995) present a comparative \\nsurvey of the federated database system prototypes. Most commercial DBMS ven-\\ndors have products using the client/server approach and offer distributed versions \\nof their systems. Some system issues concerning client/server DBMS architectures \\nare discussed in Carey et al. (1991), DeWitt et al. (1990), and Wang and Rowe \\n(1991). Khoshafian et al. (1992) discuss design issues for relational DBMSs in the \\nclient/server environment. Client/server management issues are discussed in many \\nbooks, such as Zantinge and Adriaans (1996). Di Stefano (2005) discusses data dis-\\ntribution issues specific to grid computing. A major part of this discussion may also \\napply to cloud computing.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 896, 'page_label': '897'}, page_content='883\\n24\\nNOSQL Databases  \\nand Big Data Storage Systems\\nW\\ne now turn our attention to the class of sys-\\ntems developed to manage large amounts of \\ndata in organizations such as Google, Amazon, Facebook, and Twitter and in \\napplications such as social media, Web links, user profiles, marketing and sales, \\nposts and tweets, road maps and spatial data, and e-mail. The term NOSQL is \\ngenerally interpreted as Not Only SQL—rather than NO to SQL—and is meant \\nto convey that many applications need systems other than traditional relational \\nSQL systems to augment their data management needs. Most NOSQL systems \\nare distributed databases or distributed storage systems, with a focus on semis-\\ntructured data storage, high performance, availability, data replication, and scal-\\nability as opposed to an emphasis on immediate data consistency, powerful \\nquery languages, and structured data storage.\\nWe start in Section 24.1 with an introduction to NOSQL systems, their character-\\nistics, and how they differ from SQL systems. We also describe four general cate-\\ngories of NOSQL systems—document-based, key-value stores, column-based, \\nand graph-based. Section 24.2 discusses how NOSQL systems approach the issue \\nof consistency among multiple replicas (copies) by using the paradigm known as \\neventual consistency . We discuss the CAP theorem, which can be used to under-\\nstand the emphasis of NOSQL systems on availability. In Sections 24.3 through  \\n24.6, we present an overview of each category of NOSQL systems—starting with \\ndocument-based systems, followed by key-value stores, then column-based, and \\nfinally graph-based. Some systems may not fall neatly into a single category, but \\nrather use techniques that span two or more categories of NOSQL systems. \\nFinally, Section 24.7 is the chapter summary.\\nchapter 24'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 897, 'page_label': '898'}, page_content='884 Chapter 24 NOSQL Databases and Big Data Storage Systems\\n24.1 Introduction to NOSQL Systems\\n24.1.1 Emergence of NOSQL Systems\\nMany companies and organizations are faced with applications that store vast \\namounts of data. Consider a free e-mail application, such as Google Mail or Yahoo \\nMail or other similar service—this application can have millions of users, and each \\nuser can have thousands of e-mail messages. There is a need for a storage system \\nthat can manage all these e-mails; a structured relational SQL system may not be \\nappropriate because (1) SQL systems offer too many services (powerful query lan-\\nguage, concurrency control, etc.), which this application may not need; and (2) a \\nstructured data model such the traditional relational model may be too restrictive. \\nAlthough newer relational systems do have more complex object-relational model-\\ning options (see Chapter 12), they still require schemas, which are not required by \\nmany of the NOSQL systems.\\nAs another example, consider an application such as Facebook, with millions of \\nusers who submit posts, many with images and videos; then these posts must be \\ndisplayed on pages of other users using the social media relationships among the \\nusers. User profiles, user relationships, and posts must all be stored in a huge collec-\\ntion of data stores, and the appropriate posts must be made available to the sets of \\nusers that have signed up to see these posts. Some of the data for this type of appli-\\ncation is not suitable for a traditional relational system and typically needs multiple \\ntypes of databases and data storage systems.\\nSome of the organizations that were faced with these data management and storage \\napplications decided to develop their own systems:\\n ■ Google developed a proprietary NOSQL system known as BigTable, which is \\nused in many of Google’s applications that require vast amounts of data stor-\\nage, such as Gmail, Google Maps, and Web site indexing. Apache Hbase is an \\nopen source NOSQL system based on similar concepts. Google’s innovation \\nled to the category of NOSQL systems known as column-based  or wide \\ncolumn stores; they are also sometimes referred to as column family stores.\\n ■ Amazon developed a NOSQL system called DynamoDB that is available \\nthrough Amazon’s cloud services. This innovation led to the category known \\nas key-value data stores or sometimes key-tuple or key-object data stores.\\n ■ Facebook developed a NOSQL system called Cassandra, which is now open \\nsource and known as Apache Cassandra. This NOSQL system uses concepts \\nfrom both key-value stores and column-based systems.\\n ■ Other software companies started developing their own solutions and making \\nthem available to users who need these capabilities—for example, MongoDB \\nand CouchDB, which are classified as document-based NOSQL systems or \\ndocument stores.\\n ■ Another category of NOSQL systems is the graph-based NOSQL systems, \\nor graph databases; these include Neo4J and GraphBase, among others.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 898, 'page_label': '899'}, page_content='24.1 Introduction to NOSQL Systems  885\\n ■ Some NOSQL systems, such as OrientDB, combine concepts from many of \\nthe categories discussed above.\\n ■ In addition to the newer types of NOSQL systems listed above, it is also pos-\\nsible to classify database systems based on the object model (see Chapter 12) \\nor on the native XML model (see Chapter 13) as NOSQL systems, although \\nthey may not have the high-performance and replication characteristics of \\nthe other types of NOSQL systems.\\nThese are just a few examples of NOSQL systems that have been developed. There \\nare many systems, and listing all of them is beyond the scope of our presentation.\\n24.1.2 Characteristics of NOSQL Systems\\nWe now discuss the characteristics of many NOSQL systems, and how these sys-\\ntems differ from traditional SQL systems. We divide the characteristics into two \\ncategories—those related to distributed databases and distributed systems, and \\nthose related to data models and query languages.\\nNOSQL characteristics related to distributed databases and distributed \\nsystems. NOSQL systems emphasize high availability, so replicating the data is \\ninherent in many of these systems. Scalability is another important characteristic, \\nbecause many of the applications that use NOSQL systems tend to have data that \\nkeeps growing in volume. High performance is another required characteristic, \\nwhereas serializable consistency may not be as important for some of the NOSQL \\napplications. We discuss some of these characteristics next.\\n  1. Scalability: As we discussed in Section 23.1.4, there are two kinds of scal-\\nability in distributed systems: horizontal and vertical. In NOSQL systems, \\nhorizontal scalability  is generally used, where the distributed system is \\nexpanded by adding more nodes for data storage and processing as the vol-\\nume of data grows. Vertical scalability, on the other hand, refers to expand-\\ning the storage and computing power of existing nodes. In NOSQL systems, \\nhorizontal scalability is employed while the system is operational, so tech-\\nniques for distributing the existing data among new nodes without inter-\\nrupting system operation are necessary. We will discuss some of these \\ntechniques in Sections 24.3 through  24.6 when we discuss specific systems.\\n  2. Availability, Replication and Eventual Consistency:  Many applications \\nthat use NOSQL systems require continuous system availability. To accom-\\nplish this, data is replicated over two or more nodes in a transparent man-\\nner, so that if one node fails, the data is still available on other nodes. \\nReplication improves data availability and can also improve read perfor-\\nmance, because read requests can often be serviced from any of the repli-\\ncated data nodes. However, write performance becomes more cumbersome \\nbecause an update must be applied to every copy of the replicated data items; \\nthis can slow down write performance if serializable consistency is required \\n(see Section 23.3). Many NOSQL applications do not require serializable'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 899, 'page_label': '900'}, page_content='886 Chapter 24 NOSQL Databases and Big Data Storage Systems\\nconsistency, so more relaxed forms of consistency known as eventual \\nconsistency  are used. We discuss this in more detail in Section 24.2.\\n  3. Replication Models: Two major replication models are used in NOSQL sys-\\ntems: master-slave and master-master replication. Master-slave replication \\nrequires one copy to be the master copy; all write operations must be applied \\nto the master copy and then propagated to the slave copies, usually using \\neventual consistency (the slave copies will eventually be the same as the mas-\\nter copy). For read, the master-slave paradigm can be configured in various \\nways. One configuration requires all reads to also be at the master copy, so \\nthis would be similar to the primary site or primary copy methods of distrib-\\nuted concurrency control (see Section 23.3.1), with similar advantages and \\ndisadvantages. Another configuration would allow reads at the slave copies \\nbut would not guarantee that the values are the latest writes, since writes to \\nthe slave nodes can be done after they are applied to the master copy. The \\nmaster-master replication allows reads and writes at any of the replicas but \\nmay not guarantee that reads at nodes that store different copies see the \\nsame values. Different users may write the same data item concurrently at \\ndifferent nodes of the system, so the values of the item will be temporarily \\ninconsistent. A reconciliation method to resolve conflicting write operations \\nof the same data item at different nodes must be implemented as part of the \\nmaster-master replication scheme.\\n  4. Sharding of Files: In many NOSQL applications, files (or collections of data \\nobjects) can have many millions of records (or documents or objects), and \\nthese records can be accessed concurrently by thousands of users. So it is not \\npractical to store the whole file in one node. Sharding  (also known as \\n horizontal partitioning  ; see Section 23.2) of the file records is often \\nemployed in NOSQL systems. This serves to distribute the load of accessing \\nthe file records to multiple nodes. The combination of sharding the file \\nrecords and replicating the shards works in tandem to improve load \\n balancing as well as data availability. We will discuss some of the sharding \\ntechniques in Sections 24.3 through  24.6 when we discuss specific systems.\\n  5. High-Performance Data Access: In many NOSQL applications, it is neces-\\nsary to find individual records or objects (data items) from among the mil-\\nlions of data records or objects in a file. To achieve this, most systems use \\none of two techniques: hashing or range partitioning on object keys. The \\nmajority of accesses to an object will be by providing the key value rather \\nthan by using complex query conditions. The object key is similar to the \\nconcept of object id (see Section 12.1). In hashing, a hash function h(K) is \\napplied to the key K, and the location of the object with key K is determined \\nby the value of h(K). In range partitioning, the location is determined via a \\nrange of key values; for example, location i would hold the objects whose key \\nvalues K are in the range Ki\\nmin ≤ K ≤ Ki max. In applications that require \\nrange queries, where multiple objects within a range of key values are \\nretrieved, range partitioned is preferred. Other indexes can also be used to \\nlocate objects based on attribute conditions different from the key K. We'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 900, 'page_label': '901'}, page_content='24.1 Introduction to NOSQL Systems  887\\nwill discuss some of the hashing, partitioning, and indexing techniques in \\nSections 24.3 through  24.6 when we discuss specific systems.\\nNOSQL characteristics related to data models and query languages.  \\nNOSQL systems emphasize performance and flexibility over modeling power and \\ncomplex querying. We discuss some of these characteristics next.\\n  1. Not Requiring a Schema:  The flexibility of not requiring a schema is \\nachieved in many NOSQL systems by allowing semi-structured, self-\\ndescribing data (see Section 13.1). The users can specify a partial schema in \\nsome systems to improve storage efficiency, but it is not required to have a \\nschema in most of the NOSQL systems. As there may not be a schema to \\nspecify constraints, any constraints on the data would have to be pro-\\ngrammed in the application programs that access the data items. There are \\nvarious languages for describing semistructured data, such as JSON (JavaScript \\nObject Notation) and XML (Extensible Markup Language; see Chapter 13). \\nJSON is used in several NOSQL systems, but other methods for describing \\nsemi-structured data can also be used. We will discuss JSON in Section 24.3 \\nwhen we present document-based NOSQL systems.\\n  2. Less Powerful Query Languages:  Many applications that use NOSQL sys-\\ntems may not require a powerful query language such as SQL, because \\nsearch (read) queries in these systems often locate single objects in a single \\nfile based on their object keys. NOSQL systems typically provide a set of \\nfunctions and operations as a programming API (application programming \\ninterface), so reading and writing the data objects is accomplished by calling \\nthe appropriate operations by the programmer. In many cases, the opera-\\ntions are called CRUD operations, for Create, Read, Update, and Delete. In \\nother cases, they are known as SCRUD because of an added Search (or Find) \\noperation. Some NOSQL systems also provide a high-level query language, \\nbut it may not have the full power of SQL; only a subset of SQL querying \\ncapabilities would be provided. In particular, many NOSQL systems do not \\nprovide join operations as part of the query language itself; the joins need to \\nbe implemented in the application programs.\\n  3. Versioning: Some NOSQL systems provide storage of multiple versions of \\nthe data items, with the timestamps of when the data version was created. \\nWe will discuss this aspect in Section 24.5 when we present column-based \\nNOSQL systems.\\nIn the next section, we give an overview of the various categories of NOSQL \\nsystems.\\n24.1.3 Categories of NOSQL Systems\\nNOSQL systems have been characterized into four major categories, with some \\nadditional categories that encompass other types of systems. The most common \\ncategorization lists the following four major categories:'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 901, 'page_label': '902'}, page_content='888 Chapter 24 NOSQL Databases and Big Data Storage Systems\\n  1. Document-based NOSQL systems: These systems store data in the form of \\ndocuments using well-known formats, such as JSON (JavaScript Object \\nNotation). Documents are accessible via their document id, but can also be \\naccessed rapidly using other indexes.\\n  2. NOSQL key-value stores:  These systems have a simple data model based \\non fast access by the key to the value associated with the key; the value can \\nbe a record or an object or a document or even have a more complex data \\nstructure.\\n  3. Column-based or wide column NOSQL systems: These systems partition a \\ntable by column into column families (a form of vertical partitioning; see \\nSection 23.2), where each column family is stored in its own files. They also \\nallow versioning of data values.\\n  4. Graph-based NOSQL systems:  Data is represented as graphs, and related \\nnodes can be found by traversing the edges using path expressions.\\nAdditional categories can be added as follows to include some systems that are not \\neasily categorized into the above four categories, as well as some other types of sys-\\ntems that have been available even before the term NOSQL became widely used.\\n  5. Hybrid NOSQL systems:  These systems have characteristics from two or \\nmore of the above four categories.\\n  6. Object databases: These systems were discussed in Chapter 12.\\n  7. XML databases: We discussed XML in Chapter 13.\\nEven keyword-based search engines store large amounts of data with fast search \\naccess, so the stored data can be considered as large NOSQL big data stores.\\nThe rest of this chapter is organized as follows. In each of Sections 24.3 through  \\n24.6, we will discuss one of the four main categories of NOSQL systems, and elabo-\\nrate further on which characteristics each category focuses on. Before that, in Sec-\\ntion 24.2, we discuss in more detail the concept of eventual consistency, and we \\ndiscuss the associated CAP theorem.\\n24.2 The CAP Theorem\\nWhen we discussed concurrency control in distributed databases in Section 23.3, \\nwe assumed that the distributed database system (DDBS) is required to enforce the \\nACID properties (atomicity, consistency, isolation, durability) of transactions that \\nare running concurrently (see Section 20.3). In a system with data replication, con-\\ncurrency control becomes more complex because there can be multiple copies of \\neach data item. So if an update is applied to one copy of an item, it must be applied \\nto all other copies in a consistent manner. The possibility exists that one copy of an \\nitem X is updated by a transaction T\\n1 whereas another copy is updated by a transac-\\ntion T2, so two inconsistent copies of the same item exist at two different nodes in \\nthe distributed system. If two other transactions T3 and T4 want to read X, each may \\nread a different copy of item X.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 902, 'page_label': '903'}, page_content='24.2 The CAP Theorem  889\\nWe saw in Section 23.3 that there are distributed concurrency control methods that \\ndo not allow this inconsistency among copies of the same data item, thus enforcing \\nserializability and hence the isolation property in the presence of replication. How-\\never, these techniques often come with high overhead, which would defeat the pur-\\npose of creating multiple copies to improve performance and availability in \\ndistributed database systems such as NOSQL. In the field of distributed systems, \\nthere are various levels of consistency among replicated data items, from weak con-\\nsistency to strong consistency. Enforcing serializability is considered the strongest \\nform of consistency, but it has high overhead so it can reduce performance of read \\nand write operations and hence adversely affect system performance.\\nThe CAP theorem, which was originally introduced as the CAP principle, can be \\nused to explain some of the competing requirements in a distributed system with \\nreplication. The three letters in CAP refer to three desirable properties of distributed \\nsystems with replicated data: consistency (among replicated copies), availability (of \\nthe system for read and write operations) and partition tolerance (in the face of the \\nnodes in the system being partitioned by a network fault). Availability means that \\neach read or write request for a data item will either be processed successfully or will \\nreceive a message that the operation cannot be completed. Partition tolerance means \\nthat the system can continue operating if the network connecting the nodes has a \\nfault that results in two or more partitions, where the nodes in each partition can \\nonly communicate among each other. Consistency means that the nodes will have \\nthe same copies of a replicated data item visible for various transactions.\\nIt is important to note here that the use of the word consistency in CAP and its use \\nin ACID do not refer to the same identical concept . In CAP, the term consistency \\nrefers to the consistency of the values in different copies of the same data item in a \\nreplicated distributed system. In ACID, it refers to the fact that a transaction will \\nnot violate the integrity constraints specified on the database schema. However, if \\nwe consider that the consistency of replicated copies is a specified constraint, then \\nthe two uses of the term consistency would be related.\\nThe CAP theorem states that it is not possible to guarantee all three of the desirable \\nproperties—consistency, availability, and partition tolerance—at the same time in a \\ndistributed system with data replication. If this is the case, then the distributed sys-\\ntem designer would have to choose two properties out of the three to guarantee. It \\nis generally assumed that in many traditional (SQL) applications, guaranteeing \\nconsistency through the ACID properties is important. On the other hand, in a \\nNOSQL distributed data store, a weaker consistency level is often acceptable, and \\nguaranteeing the other two properties (availability, partition tolerance) is impor-\\ntant. Hence, weaker consistency levels are often used in NOSQL system instead of \\nguaranteeing serializability. In particular, a form of consistency known as eventual \\nconsistency is often adopted in NOSQL systems. In Sections 24.3 through  24.6, we \\nwill discuss some of the consistency models used in specific NOSQL systems.\\nThe next four sections of this chapter discuss the characteristics of the four main cat-\\negories of NOSQL systems. We discuss document-based NOSQL systems in Sec-\\ntion\\xa024.3, and we use MongoDB as a representative system. In Section 24.4, we discuss'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 903, 'page_label': '904'}, page_content='890 Chapter 24 NOSQL Databases and Big Data Storage Systems\\nNOSQL systems known as key-value stores. In Section 24.5, we give an overview of \\ncolumn-based NOSQL systems, with a discussion of Hbase as a representative sys-\\ntem. Finally, we introduce graph-based NOSQL systems in Section 24.6.\\n24.3  Document-Based NOSQL Systems  \\nand MongoDB\\nDocument-based or document-oriented NOSQL systems typically store data as \\ncollections of similar documents. These types of systems are also sometimes known \\nas document stores. The individual documents somewhat resemble complex objects \\n(see Section 12.3) or XML documents (see Chapter 13), but a major difference \\nbetween document-based systems versus object and object-relational systems and \\nXML is that there is no requirement to specify a schema—rather, the documents are \\nspecified as self-describing data (see Section 13.1). Although the documents in a \\ncollection should be similar, they can have different data elements (attributes), and \\nnew documents can have new data elements that do not exist in any of the current \\ndocuments in the collection. The system basically extracts the data element names \\nfrom the self-describing documents in the collection, and the user can request that \\nthe system create indexes on some of the data elements. Documents can be speci-\\nfied in various formats, such as XML (see Chapter 13). A popular language to spec-\\nify documents in NOSQL systems is JSON (JavaScript Object Notation).\\nThere are many document-based NOSQL systems, including MongoDB and \\nCouchDB, among many others. We will give an overview of MongoDB in this sec-\\ntion. It is important to note that different systems can use different models, lan-\\nguages, and implementation methods, but giving a complete survey of all \\ndocument-based NOSQL systems is beyond the scope of our presentation.\\n24.3.1 MongoDB Data Model\\nMongoDB documents are stored in BSON (Binary JSON) format, which is a varia-\\ntion of JSON with some additional data types and is more efficient for storage than \\nJSON. Individual documents are stored in a collection. We will use a simple exam-\\nple based on our COMPANY database that we used throughout this book. The \\noperation createCollection is used to create each collection. For example, the fol-\\nlowing command can be used to create a collection called project to hold PROJECT \\nobjects from the COMPANY database (see Figures 5.5 and 5.6):\\ndb.createCollection(“project” , { capped : true, size : 1310720, max : 500 } )\\nThe first parameter “project” is the name of the collection, which is followed by an \\noptional document that specifies collection options. In our example, the collection \\nis capped; this means it has upper limits on its storage space ( size) and number of \\ndocuments ( max). The capping parameters help the system choose the storage \\noptions for each collection. There are other collection options, but we will not dis-\\ncuss them here.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 904, 'page_label': '905'}, page_content='24.3 Document-Based NOSQL Systems and MongoDB  891\\nFor our example, we will create another document collection called worker  to \\nhold information about the EMPLOYEEs who work on each project; for \\nexample:\\ndb.createCollection(“worker” , { capped : true, size : 5242880, max : 2000 } ) )\\nEach document in a collection has a unique ObjectId field, called _id, which is \\nautomatically indexed in the collection unless the user explicitly requests no index \\nfor the _id field. The value of ObjectId can be specified by the user , or it can be \\nsystem-generated if the user does not specify an _id field for a particular document. \\nSystem-generated ObjectIds have a specific format, which combines the timestamp \\nwhen the object is created (4 bytes, in an internal MongoDB format), the node id \\n(3 bytes), the process id (2 bytes), and a counter (3 bytes) into a 16-byte Id value. \\nUser-generated  ObjectsIds can have any value specified by the user as long as it \\nuniquely identifies the document and so these Ids are similar to primary keys in \\nrelational systems.\\nA collection does not have a schema. The structure of the data fields in documents \\nis chosen based on how documents will be accessed and used, and the user can \\nchoose a normalized design (similar to normalized relational tuples) or a denor-\\nmalized design (similar to XML documents or complex objects). Interdocument \\nreferences can be specified by storing in one document the ObjectId or ObjectIds of \\nother related documents. Figure 24.1(a) shows a simplified MongoDB document \\nshowing some of the data from Figure 5.6 from the COMPANY database example \\nthat is used throughout the book. In our example, the _id values are user-defined, \\nand the documents whose _id starts with P (for project) will be stored in the “project” \\ncollection, whereas those whose _id starts with W (for worker) will be stored in the \\n“worker” collection.\\nIn Figure 24.1(a), the workers information is embedded in the project document; so \\nthere is no need for the “worker” collection. This is known as the denormalized pat-\\ntern, which is similar to creating a complex object (see Chapter 12) or an XML \\ndocument (see Chapter 13). A list of values that is enclosed in square brackets [ … ] \\nwithin a document represents a field whose value is an array.\\nAnother option is to use the design in Figure 24.1(b), where worker references  are \\nembedded in the project document, but the worker documents themselves are \\nstored in a separate “worker” collection. A third option in Figure 24.1(c) would \\nuse a normalized design, similar to First Normal Form relations (see Sec-\\ntion\\xa014.3.4). The choice of which design option to use depends on how the data \\nwill be accessed.\\nIt is important to note that the simple design in Figure 24.1(c) is not the general nor-\\nmalized design for a many-to-many relationship, such as the one between employees \\nand projects; rather, we would need three collections for “project”, “employee”, and \\n“works_on”, as we discussed in detail in Section 9.1. Many of the design tradeoffs \\nthat were discussed in Chapters 9 and 14 (for first normal form relations and for ER-\\nto-relational mapping options), and Chapters 12 and 13 (for complex objects and \\nXML) are applicable for choosing the appropriate design for document structures'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 905, 'page_label': '906'}, page_content='892 Chapter 24 NOSQL Databases and Big Data Storage Systems\\n(a) project document with an array of embedded workers:\\n {\\n  _id:    “P1”,\\n  Pname:   “ProductX”,\\n  Plocation:  “Bellaire”,\\n  Workers: [ \\n     { Ename: “John Smith”,\\n         Hours: 32.5\\n     },\\n     { Ename: “Joyce English”,\\n         Hours: 20.0\\n     }\\n    ]\\n );\\n(b) project document with an embedded array of worker ids:\\n {\\n  _id:    “P1”,\\n  Pname:   “ProductX”,\\n  Plocation:  “Bellaire”,\\n  WorkerIds:  [ “W1”, “W2” ]\\n }\\n  { _id:   “W1”,\\n  Ename:   “John Smith”,\\n  Hours:   32.5\\n }\\n  { _id:   “W2”,\\n  Ename:   “Joyce English”,\\n  Hours:   20.0\\n }\\n(c)  normalized project and worker documents (not a fully normalized design  \\nfor M:N relationships):\\n {\\n  _id:    “P1”,\\n  Pname:   “ProductX”,\\n  Plocation:  “Bellaire”\\n }\\n { _id:    “W1”,\\n  Ename:   “John Smith”,\\n  ProjectId:  “P1”,\\n  Hours:   32.5\\n }\\nFigure 24.1 \\nExample of simple \\ndocuments in  \\nMongoDB.  \\n(a) Denormalized  \\ndocument design  \\nwith embedded  \\nsubdocuments.  \\n(b) Embedded array of \\ndocument references. \\n(c) Normalized  \\ndocuments.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 906, 'page_label': '907'}, page_content='24.3 Document-Based NOSQL Systems and MongoDB  893\\nand document collections, so we will not repeat the discussions here. In the design \\nin Figure 24.1(c), an EMPLOYEE who works on several projects would be repre-\\nsented by multiple worker documents  with different _id values; each document \\nwould represent the employee as worker for a particular project . This is similar to \\nthe design decisions for XML schema design (see Section 13.6). However, it is again \\nimportant to note that the typical document-based system does not have a schema, \\nso the design rules would have to be followed whenever individual documents are \\ninserted into a collection.\\n24.3.2 MongoDB CRUD Operations\\nMongoDb has several CRUD operations , where CRUD stands for (create, read, \\nupdate, delete). Documents can be created and inserted into their collections using \\nthe insert operation, whose format is:\\ndb.<collection_name>.insert(<document(s)>)\\nThe parameters of the insert operation can include either a single document or an \\narray of documents, as shown in Figure 24.1(d). The delete operation is called \\nremove, and the format is:\\ndb.<collection_name>.remove(<condition>)\\nThe documents to be removed from the collection are specified by a Boolean con-\\ndition on some of the fields in the collection documents. There is also an update \\noperation, which has a condition to select certain documents, and a $set clause to \\nspecify the update. It is also possible to use the update operation to replace an \\nexisting document with another one but keep the same ObjectId.\\nFor read queries, the main command is called find, and the format is:\\ndb.<collection_name>.find(<condition>)\\nGeneral Boolean conditions can be specified as <condition>, and the documents in \\nthe collection that return true are selected for the query result. For a full discussion \\nof the MongoDb CRUD operations, see the MongoDB online documentation in the \\nchapter references.\\n \\n{ _id:    “W2”,\\n  Ename:   “Joyce English”,\\n  ProjectId:  “P1”,\\n  Hours:   20.0\\n }\\n(d) inserting the documents in (c) into their collections “project” and “worker”:\\n db.project.insert( { _id: “P1”, Pname: “ProductX”, Plocation: “Bellaire” } )\\n db.worker.insert( [ { _id: “W1”, Ename: “John Smith”, ProjectId: “P1”, Hours: 32.5 },\\n      { _id: “W2”, Ename: “Joyce English”, ProjectId: “P1”,  \\n Hours: 20.0 } ] )\\nFigure 24.1 \\n(continued)\\nExample of simple  \\ndocuments in\\nMongoDB. (d) Inserting \\nthe documents in \\n Figure 24.1(c) into \\ntheir collections.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 907, 'page_label': '908'}, page_content='894 Chapter 24 NOSQL Databases and Big Data Storage Systems\\n24.3.3 MongoDB Distributed Systems Characteristics\\nMost MongoDB updates are atomic if they refer to a single document, but MongoDB \\nalso provides a pattern for specifying transactions on multiple documents. Since \\nMongoDB is a distributed system, the two-phase commit method is used to ensure \\natomicity and consistency of multidocument transactions. We discussed the atomi-\\ncity and consistency properties of transactions in Section 20.3, and the two-phase \\ncommit protocol in Section 22.6.\\nReplication in MongoDB. The concept of replica set is used in MongoDB to create \\nmultiple copies of the same data set on different nodes in the distributed system, and \\nit uses a variation of the master-slave approach for replication. For example, suppose \\nthat we want to replicate a particular document collection C. A replica set will have \\none primary copy  of the collection C stored in one node N1, and at least one \\n secondary copy (replica) of C stored at another node N2. Additional copies can be \\nstored in nodes N3, N4, etc., as needed, but the cost of storage and update (write) \\nincreases with the number of replicas. The total number of participants in a replica set \\nmust be at least three, so if only one secondary copy is needed, a participant in the \\n replica set known as an arbiter must run on the third node N3. The arbiter does not \\nhold a replica of the collection but participates in elections to choose a new primary if \\nthe node storing the current primary copy fails. If the total number of members in a rep-\\nlica set is n (one primary plus i secondaries, for a total of n = i + 1), then n must be an odd \\nnumber; if it is not, an arbiter is added to ensure the election process works correctly if \\nthe primary fails. We discussed elections in distributed systems in Section 23.3.1.\\nIn MongoDB replication, all write operations must be applied to the primary copy \\nand then propagated to the secondaries. For read operations, the user can choose \\nthe particular read preference  for their application. The default read preference  \\nprocesses all reads at the primary copy, so all read and write operations are per-\\nformed at the primary node. In this case, secondary copies are mainly to make sure \\nthat the system continues operation if the primary fails, and MongoDB can ensure \\nthat every read request gets the latest document value. To increase read perfor-\\nmance, it is possible to set the read preference so that read requests can be processed \\nat any replica (primary or secondary); however, a read at a secondary is not guaran-\\nteed to get the latest version of a document because there can be a delay in propa-\\ngating writes from the primary to the secondaries.\\nSharding in MongoDB. When a collection holds a very large number of docu-\\nments or requires a large storage space, storing all the documents in one node can \\nlead to performance problems, particularly if there are many user operations \\naccessing the documents concurrently using various CRUD operations. Sharding \\nof the documents in the collection—also known as horizontal partitioning —\\ndivides the documents into disjoint partitions known as shards. This allows the \\nsystem to add more nodes as needed by a process known as horizontal scaling of \\nthe distributed system (see Section 23.1.4), and to store the shards of the collection \\non different nodes to achieve load balancing. Each node will process only those \\noperations pertaining to the documents in the shard stored at that node. Also, each'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 908, 'page_label': '909'}, page_content='24.4 NOSQL Key-Value Stores  895\\nshard will contain fewer documents than if the entire collection were stored at one \\nnode, thus further improving performance.\\nThere are two ways to partition a collection into shards in MongoDB— range \\n partitioning and hash partitioning. Both require that the user specify a particular \\ndocument field to be used as the basis for partitioning the documents into shards. \\nThe partitioning field —known as the shard key  in MongoDB—must have two \\ncharacteristics: it must exist in every document in the collection, and it must have an \\nindex. The ObjectId can be used, but any other field possessing these two character-\\nistics can also be used as the basis for sharding. The values of the shard key are \\ndivided into chunks either through range partitioning or hash partitioning, and the \\ndocuments are partitioned based on the chunks of shard key values.\\nRange partitioning creates the chunks by specifying a range of key values; for example, \\nif the shard key values ranged from one to ten million, it is possible to create ten \\nranges—1 to 1,000,000; 1,000,001 to 2,000,000; … ; 9,000,001 to 10,000,000—and \\neach chunk would contain the key values in one range. Hash partitioning applies a \\nhash function h(K) to each shard key K, and the partitioning of keys into chunks is \\nbased on the hash values (we discussed hashing and its advantages and disadvantages \\nin Section 16.8). In general, if range queries are commonly applied to a collection (for \\nexample, retrieving all documents whose shard key value is between 200 and 400), \\nthen range partitioning is preferred because each range query will typically be submit-\\nted to a single node that contains all the required documents in one shard. If most \\nsearches retrieve one document at a time, hash partitioning may be preferable because \\nit randomizes the distribution of shard key values into chunks.\\nWhen sharding is used, MongoDB queries are submitted to a module called the query \\nrouter, which keeps track of which nodes contain which shards based on the particu-\\nlar partitioning method used on the shard keys. The query (CRUD operation) will be \\nrouted to the nodes that contain the shards that hold the documents that the query is \\nrequesting. If the system cannot determine which shards hold the required docu-\\nments, the query will be submitted to all the nodes that hold shards of the collection. \\nSharding and replication are used together; sharding focuses on improving perfor-\\nmance via load balancing and horizontal scalability, whereas replication focuses on \\nensuring system availability when certain nodes fail in the distributed system.\\nThere are many additional details about the distributed system architecture and com-\\nponents of MongoDB, but a full discussion is outside the scope of our presentation. \\nMongoDB also provides many other services in areas such as system administration, \\nindexing, security, and data aggregation, but we will not discuss these features here. \\nFull documentation of MongoDB is available online (see the bibliographic notes).\\n24.4 NOSQL Key-Value Stores\\nKey-value stores focus on high performance, availability, and scalability by storing \\ndata in a distributed storage system. The data model used in key-value stores is rela-\\ntively simple, and in many of these systems, there is no query language but rather a'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 909, 'page_label': '910'}, page_content='896 Chapter 24 NOSQL Databases and Big Data Storage Systems\\nset of operations that can be used by the application programmers. The key is a \\nunique identifier associated with a data item and is used to locate this data item \\nrapidly. The value is the data item itself, and it can have very different formats for \\ndifferent key-value storage systems. In some cases, the value is just a string of bytes \\nor an array of bytes, and the application using the key-value store has to interpret \\nthe structure of the data value. In other cases, some standard formatted data is \\nallowed; for example, structured data rows (tuples) similar to relational data, or \\nsemistructured data using JSON or some other self-describing data format. Differ-\\nent key-value stores can thus store unstructured, semistructured, or structured data \\nitems (see Section 13.1). The main characteristic of key-value stores is the fact that \\nevery value (data item) must be associated with a unique key, and that retrieving the \\nvalue by supplying the key must be very fast.\\nThere are many systems that fall under the key-value store label, so rather than pro-\\nvide a lot of details on one particular system, we will give a brief introductory over-\\nview for some of these systems and their characteristics.\\n24.4.1 DynamoDB Overview\\nThe DynamoDB system is an Amazon product and is available as part of Amazon’s \\nAWS/SDK platforms (Amazon Web Services/Software Development Kit). It can be \\nused as part of Amazon’s cloud computing services, for the data storage component.\\nDynamoDB data model. The basic data model in DynamoDB uses the concepts \\nof tables, items, and attributes. A table in DynamoDB does not have  a schema; it \\nholds a collection of self-describing items . Each item will consist of a number of \\n(attribute, value) pairs, and attribute values can be single-valued or multivalued. So \\nbasically, a table will hold a collection of items, and each item is a self-describing \\nrecord (or object). DynamoDB also allows the user to specify the items in JSON for-\\nmat, and the system will convert them to the internal storage format of DynamoDB.\\nWhen a table is created, it is required to specify a table name and a primary key; \\nthe primary key will be used to rapidly locate the items in the table. Thus, the pri-\\nmary key is the key and the item is the value for the DynamoDB key-value store. \\nThe primary key attribute must exist in every item in the table. The primary key can \\nbe one of the following two types:\\n ■ A single attribute. The DynamoDB system will use this attribute to build a \\nhash index on the items in the table. This is called a hash type primary key . \\nThe items are not ordered in storage on the value of the hash attribute.\\n ■ A pair of attributes.  This is called a hash and range type primary key . The \\nprimary key will be a pair of attributes (A, B): attribute A will be used for hash-\\ning, and because there will be multiple items with the same value of A, the B \\nvalues will be used for ordering the records with the same A value. A table \\nwith this type of key can have additional secondary indexes defined on its \\nattributes. For example, if we want to store multiple versions of some type of \\nitems in a table, we could use ItemID as hash and Date or Timestamp (when \\nthe version was created) as range in a hash and range type primary key.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 910, 'page_label': '911'}, page_content='24.4 NOSQL Key-Value Stores  897\\nDynamoDB Distributed Characteristics. Because DynamoDB is proprietary, in \\nthe next subsection we will discuss the mechanisms used for replication, sharding, \\nand other distributed system concepts in an open source key-value system called \\nVoldemort. Voldemort is based on many of the techniques proposed for DynamoDB.\\n24.4.2 Voldemort Key-Value Distributed Data Store\\nVoldemort is an open source system available through Apache 2.0 open source licens-\\ning rules. It is based on Amazon’s DynamoDB. The focus is on high performance and \\nhorizontal scalability, as well as on providing replication for high availability and \\nsharding for improving latency (response time) of read and write requests. All three \\nof those features—replication, sharding, and horizontal scalability—are realized \\nthrough a technique to distribute the key-value pairs among the nodes of a distrib-\\nuted cluster; this distribution is known as consistent hashing. Voldemort has been \\nused by LinkedIn for data storage. Some of the features of Voldemort are as follows:\\n ■ Simple basic operations.  A collection of (key, value) pairs is kept in a \\nVoldemort store. In our discussion, we will assume the store is called s. The \\nbasic interface for data storage and retrieval is very simple and includes \\nthree operations: get, put, and delete. The operation s.put(k, v) inserts an \\nitem as a key-value pair with key k and value v. The operation s.delete(k) \\ndeletes the item whose key is k from the store, and the operation v = s.get(k) \\nretrieves the value v associated with key k. The application can use these \\nbasic operations to build its own requirements. At the basic storage level, \\nboth keys and values are arrays of bytes (strings).\\n ■ High-level formatted data values.  The values v in the (k, v) items can be \\nspecified in JSON (JavaScript Object Notation), and the system will convert \\nbetween JSON and the internal storage format. Other data object formats can \\nalso be specified if the application provides the conversion (also known as \\nserialization) between the user format and the storage format as a Serializer \\nclass. The Serializer class must be provided by the user and will include oper-\\nations to convert the user format into a string of bytes for storage as a value, \\nand to convert back a string (array of bytes) retrieved via s.get(k) into the user \\nformat. Voldemort has some built-in serializers for formats other than JSON.\\n ■ Consistent hashing for distributing (key, value) pairs.  A variation of the \\ndata distribution algorithm known as consistent hashing is used in Volde-\\nmort for data distribution among the nodes in the distributed cluster of \\nnodes. A hash function h(k) is applied to the key k of each (k, v) pair, and \\nh(k) determines where the item will be stored. The method assumes that \\nh(k) is an integer value, usually in the range 0 to Hmax = 2\\nn−1, where n is \\nchosen based on the desired range for the hash values. This method is best \\nvisualized by considering the range of all possible integer hash values 0 to \\nHmax to be evenly distributed on a circle (or ring). The nodes in the distrib-\\nuted system are then also located on the same ring; usually each node will \\nhave several locations on the ring (see Figure 24.2). The positioning of the \\npoints on the ring that represent the nodes is done in a psuedorandom manner.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 911, 'page_label': '912'}, page_content='898 Chapter 24 NOSQL Databases and Big Data Storage Systems\\nAn item (k, v) will be stored on the node whose position in the ring follows \\nthe position of h(k) on the ring in a clockwise direction. In Figure 24.2(a), we \\nassume there are three nodes in the distributed cluster labeled A, B, and C, \\nwhere node C has a bigger capacity than nodes A and B. In a typical system, \\nthere will be many more nodes. On the circle, two instances each of A and B \\nare placed, and three instances of C (because of its higher capacity), in a \\npseudorandom manner to cover the circle. Figure 24.2(a) indicates which \\n(k, v) items are placed in which nodes based on the h(k) values.\\nC\\nC\\nA\\nB\\nC\\nA\\nB\\nRange 3\\nRange 1\\nRange 2\\nRange 3\\nRange 3\\nRange 2\\nRange 1\\nC\\nC\\nA\\nD\\nB\\nC\\nA\\nD\\nB\\nRange 3\\nRange 1\\nRange 4\\nRange 3\\nRange 4\\nRange 3\\n(reduced)\\nRange 2\\n(reduced)\\nRange 2\\nRange 1\\nFigure 24.2 \\nExample of consistent \\nhashing. (a) Ring \\n having three nodes A, \\nB, and C, with C having \\ngreater capacity. The \\nh(K) values that map to \\nthe circle points in \\nrange 1 have their (k, v) \\nitems stored in node A, \\nrange 2 in node B, \\nrange 3 in node C. \\n(b) Adding a node D to \\nthe ring. Items in \\nrange 4 are moved to \\nthe node D from node \\nB (range 2 is reduced) \\nand node C (range 3 is \\nreduced).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 912, 'page_label': '913'}, page_content='24.4 NOSQL Key-Value Stores  899\\n ■ The h(k) values that fall in the parts of the circle marked as range 1 in Fig-\\nure\\xa024.2(a) will have their (k, v) items stored in node A because that is the node \\nwhose label follows h(k) on the ring in a clockwise direction; those in range 2 \\nare stored in node B; and those in range 3 are stored in node C. This scheme \\nallows horizontal scalability because when a new node is added to the distrib-\\nuted system, it can be added in one or more locations on the ring depending \\non the node capacity. Only a limited percentage of the (k, v) items will be reas-\\nsigned to the new node from the existing nodes based on the consistent hash-\\ning placement algorithm. Also, those items assigned to the new node may not \\nall come from only one of the existing nodes because the new node can have \\nmultiple locations on the ring. For example, if a node D is added and it has two \\nplacements on the ring as shown in Figure 24.2(b), then some of the items \\nfrom nodes B and C would be moved to node D. The items whose keys hash to \\nrange 4 on the circle (see Figure 24.2(b)) would be migrated to node D. This \\nscheme also allows replication by placing the number of specified replicas of \\nan item on successive nodes on the ring in a clockwise direction. The sharding \\nis built into the method, and different items in the store (file) are located on \\ndifferent nodes in the distributed cluster, which means the items are horizon-\\ntally partitioned (sharded) among the nodes in the distributed system. When \\na node fails, its load of data items can be distributed to the other existing nodes \\nwhose labels follow the labels of the failed node in the ring. And nodes with \\nhigher capacity can have more locations on the ring, as illustrated by node C \\nin Figure 24.2(a), and thus store more items than smaller-capacity nodes.\\n ■ Consistency and versioning.  Voldemort uses a method similar to the one \\ndeveloped for DynamoDB for consistency in the presence of replicas. Basi-\\ncally, concurrent write operations are allowed by different processes so there \\ncould exist two or more different values associated with the same key at dif-\\nferent nodes when items are replicated. Consistency is achieved when the \\nitem is read by using a technique known as versioning and read repair. Con-\\ncurrent writes are allowed, but each write is associated with a vector clock  \\nvalue. When a read occurs, it is possible that different versions of the same \\nvalue (associated with the same key) are read from different nodes. If the \\nsystem can reconcile to a single final value, it will pass that value to the read; \\notherwise, more than one version can be passed back to the application, \\nwhich will reconcile the various versions into one version based on the \\napplication semantics and give this reconciled value back to the nodes.\\n24.4.3 Examples of Other Key-Value Stores\\nIn this section, we briefly review three other key-value stores. It is important to note \\nthat there are many systems that can be classified in this category, and we can only \\nmention a few of these systems.\\nOracle key-value store. Oracle has one of the well-known SQL relational data-\\nbase systems, and Oracle also offers a system based on the key-value store concept; \\nthis system is called the Oracle NoSQL Database.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 913, 'page_label': '914'}, page_content='900 Chapter 24 NOSQL Databases and Big Data Storage Systems\\nRedis key-value cache and store.  Redis differs from the other systems dis-\\ncussed here because it caches its data in main memory to further improve perfor-\\nmance. It offers master-slave replication and high availability, and it also offers \\npersistence by backing up the cache to disk.\\nApache Cassandra.  Cassandra is a NOSQL system that is not easily categorized \\ninto one category; it is sometimes listed in the column-based NOSQL category (see \\nSection 24.5) or in the key-value category. If offers features from several NOSQL \\ncategories and is used by Facebook as well as many other customers.\\n24.5  Column-Based or Wide Column  \\nNOSQL Systems\\nAnother category of NOSQL systems is known as column-based or wide column \\nsystems. The Google distributed storage system for big data, known as BigTable, is \\na well-known example of this class of NOSQL systems, and it is used in many \\nGoogle applications that require large amounts of data storage, such as Gmail. Big-\\nTable uses the Google File System  (GFS) for data storage and distribution. An \\nopen source system known as Apache Hbase is somewhat similar to Google Big-\\nTable, but it typically uses HDFS (Hadoop Distributed File System) for data stor-\\nage. HDFS is used in many cloud computing applications, as we shall discuss in \\nChapter 25. Hbase can also use Amazon’s Simple Storage System  (known as S3) \\nfor data storage. Another well-known example of column-based NOSQL systems is \\nCassandra, which we discussed briefly in Section 24.4.3 because it can also be char-\\nacterized as a key-value store. We will focus on Hbase in this section as an example \\nof this category of NOSQL systems.\\nBigTable (and Hbase) is sometimes described as a sparse multidimensional distrib-\\nuted persistent sorted map , where the word map means a collection of (key, value) \\npairs (the key is mapped to the value). One of the main differences that distinguish \\ncolumn-based systems from key-value stores (see Section 24.4) is the nature of the \\nkey. In column-based systems such as Hbase, the key is multidimensional and so \\nhas several components: typically, a combination of table name, row key, column, \\nand timestamp. As we shall see, the column is typically composed of two compo-\\nnents: column family and column qualifier. We discuss these concepts in more \\ndetail next as they are realized in Apache Hbase.\\n24.5.1 Hbase Data Model and Versioning\\nHbase data model. The data model in Hbase organizes data using the concepts \\nof namespaces, tables, column families, column qualifiers, columns, rows, and data \\ncells. A column is identified by a combination of (column family:column qualifier). \\nData is stored in a self-describing form by associating columns with data values, \\nwhere data values are strings. Hbase also stores multiple versions  of a data item, \\nwith a timestamp associated with each version, so versions and timestamps are also'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 914, 'page_label': '915'}, page_content='24.5 Column-Based or Wide Column NOSQL Systems  901\\npart of the Hbase data model (this is similar to the concept of attribute versioning in \\ntemporal databases, which we shall discuss in Section 26.2). As with other NOSQL \\nsystems, unique keys are associated with stored data items for fast access, but the \\nkeys identify cells in the storage system. Because the focus is on high performance \\nwhen storing huge amounts of data, the data model includes some storage-related \\nconcepts. We discuss the Hbase data modeling concepts and define the terminol-\\nogy next. It is important to note that the use of the words table, row, and column is \\nnot identical to their use in relational databases, but the uses are related.\\n ■ Tables and Rows.  Data in Hbase is stored in tables, and each table has a \\ntable name. Data in a table is stored as self-describing rows. Each row has a \\nunique row key, and row keys are strings that must have the property that \\nthey can be lexicographically ordered, so characters that do not have a lexi-\\ncographic order in the character set cannot be used as part of a row key.\\n ■ Column Families, Column Qualifiers, and Columns. A table is associated \\nwith one or more column families. Each column family will have a name, \\nand the column families associated with a table must be specified when the \\ntable is created and cannot be changed later. Figure 24.3(a) shows how a table \\nmay be created; the table name is followed by the names of the column fami-\\nlies associated with the table. When the data is loaded into a table, each col-\\numn family can be associated with many column qualifiers, but the column \\nqualifiers are not specified as part of creating a table. So the column qualifiers \\nmake the model a self-describing data model because the qualifiers can be \\ndynamically specified as new rows are created and inserted into the table. A \\ncolumn is specified by a combination of ColumnFamily:ColumnQualifier. \\nBasically, column families are a way of grouping together related columns \\n(attributes in relational terminology) for storage purposes, except that the \\ncolumn qualifier names are not specified during table creation. Rather, they \\nare specified when the data is created and stored in rows, so the data is self-\\ndescribing since any column qualifier name can be used in a new row of data \\n(see Figure 24.3(b)). However, it is important that the application program-\\nmers know which column qualifiers belong to each column family, even \\nthough they have the flexibility to create new column qualifiers on the fly \\nwhen new data rows are created. The concept of column family is somewhat \\nsimilar to vertical partitioning  (see Section 23.2), because columns (attri-\\nbutes) that are accessed together because they belong to the same column \\nfamily are stored in the same files. Each column family of a table is stored in \\nits own files using the HDFS file system.\\n ■ Versions and Timestamps. Hbase can keep several versions of a data item, \\nalong with the timestamp associated with each version. The timestamp is a \\nlong integer number that represents the system time when the version was \\ncreated, so newer versions have larger timestamp values. Hbase uses mid-\\nnight ‘January 1, 1970 UTC’ as timestamp value zero, and uses a long integer \\nthat measures the number of milliseconds since that time as the system \\ntimestamp value (this is similar to the value returned by the Java utility  \\njava.util.Date.getTime() and is also used in MongoDB). It is also possible for'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 915, 'page_label': '916'}, page_content='902 Chapter 24 NOSQL Databases and Big Data Storage Systems\\nthe user to define the timestamp value explicitly in a Date format rather than \\nusing the system-generated timestamp.\\n ■ Cells. A cell holds a basic data item in Hbase. The key (address) of a cell is \\nspecified by a combination of (table, rowid, columnfamily, columnqualifier, \\ntimestamp). If timestamp is left out, the latest version of the item is retrieved \\nunless a default number of versions is specified, say the latest three versions. \\nThe default number of versions to be retrieved, as well as the default number \\nof versions that the system needs to keep, are parameters that can be speci-\\nfied during table creation.\\n ■ Namespaces. A namespace is a collection of tables. A namespace basically \\nspecifies a collection of one or more tables that are typically used together by \\nuser applications, and it corresponds to a database that contains a collection \\nof tables in relational terminology.\\n(a) creating a table:\\n create ‘EMPLOYEE’, ‘Name’, ‘Address’, ‘Details’\\n(b) inserting some row data in the EMPLOYEE table:\\n put ‘EMPLOYEE’, ‘row1’, ‘Name:Fname’, ‘John’\\n put ‘EMPLOYEE’, ‘row1’, ‘Name:Lname’, ‘Smith’\\n put ‘EMPLOYEE’, ‘row1’, ‘Name:Nickname’, ‘Johnny’\\n put ‘EMPLOYEE’, ‘row1’, ‘Details:Job’, ‘Engineer’\\n put ‘EMPLOYEE’, ‘row1’, ‘Details:Review’, ‘Good’\\n put ‘EMPLOYEE’, ‘row2’, ‘Name:Fname’, ‘Alicia’\\n put ‘EMPLOYEE’, ‘row2’, ‘Name:Lname’, ‘Zelaya’\\n put ‘EMPLOYEE’, ‘row2’, ‘Name:MName’, ‘Jennifer’\\n put ‘EMPLOYEE’, ‘row2’, ‘Details:Job’, ‘DBA’\\n put ‘EMPLOYEE’, ‘row2’, ‘Details:Supervisor’, ‘James Borg’\\n put ‘EMPLOYEE’, ‘row3’, ‘Name:Fname’, ‘James’\\n put ‘EMPLOYEE’, ‘row3’, ‘Name:Minit’, ‘E’\\n put ‘EMPLOYEE’, ‘row3’, ‘Name:Lname’, ‘Borg’\\n put ‘EMPLOYEE’, ‘row3’, ‘Name:Suffix’, ‘Jr.’\\n put ‘EMPLOYEE’, ‘row3’, ‘Details:Job’, ‘CEO’\\n put ‘EMPLOYEE’, ‘row3’, ‘Details:Salary’, ‘1,000,000’\\n(c) Some Hbase basic CRUD operations:\\n Creating a table: create <tablename>, <column family>, <column family>, …\\n Inserting Data: put <tablename>, <rowid>, <column family>:<column qualifier>, <value>\\n Reading Data (all data in a table): scan <tablename>\\n Retrieve Data (one item): get <tablename>,<rowid>\\nFigure 24.3 \\nExamples in Hbase. (a) Creating a table called EMPLOYEE with three column families: Name, Address, and Details. \\n(b) Inserting some in the EMPLOYEE table; different rows can have different self-describing column qualifiers \\n(Fname, Lname, Nickname, Mname, Minit, Suffix, … for column family Name; Job, Review, Supervisor, Salary  \\nfor column family Details). (c) Some CRUD operations of Hbase.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 916, 'page_label': '917'}, page_content='24.6 NOSQL Graph Databases and Neo4j  903\\n24.5.2 Hbase CRUD Operations\\nHbase has low-level CRUD (create, read, update, delete) operations, as in many of \\nthe NOSQL systems. The formats of some of the basic CRUD operations in Hbase \\nare shown in Figure 24.3(c).\\nHbase only provides low-level CRUD operations. It is the responsibility of the \\napplication programs to implement more complex operations, such as joins \\nbetween rows in different tables. The create operation creates a new table and spec-\\nifies one or more column families associated with that table, but it does not specify \\nthe column qualifiers, as we discussed earlier. The put operation is used for insert-\\ning new data or new versions of existing data items. The get operation is for retriev-\\ning the data associated with a single row in a table, and the scan operation retrieves \\nall the rows.\\n24.5.3 Hbase Storage and Distributed System Concepts\\nEach Hbase table is divided into a number of regions, where each region will hold a \\nrange of the row keys in the table; this is why the row keys must be lexicographically \\nordered. Each region will have a number of stores, where each column family is \\nassigned to one store within the region. Regions are assigned to region servers  \\n(storage nodes) for storage. A master server (master node) is responsible for moni-\\ntoring the region servers and for splitting a table into regions and assigning regions \\nto region servers.\\nHbase uses the Apache Zookeeper open source system for services related to man-\\naging the naming, distribution, and synchronization of the Hbase data on the dis-\\ntributed Hbase server nodes, as well as for coordination and replication services. \\nHbase also uses Apache HDFS (Hadoop Distributed File System) for distributed \\nfile services. So Hbase is built on top of both HDFS and Zookeeper. Zookeeper can \\nitself have several replicas on several nodes for availability, and it keeps the data it \\nneeds in main memory to speed access to the master servers and region servers.\\nWe will not cover the many additional details about the distributed system architecture \\nand components of Hbase; a full discussion is outside the scope of our presentation. Full \\ndocumentation of Hbase is available online (see the bibliographic notes).\\n24.6 NOSQL Graph Databases and Neo4j\\nAnother category of NOSQL systems is known as graph databases  or graph-\\noriented NOSQL systems. The data is represented as a graph, which is a collection \\nof vertices (nodes) and edges. Both nodes and edges can be labeled to indicate the \\ntypes of entities and relationships they represent, and it is generally possible to \\nstore data associated with both individual nodes and individual edges. Many sys-\\ntems can be categorized as graph databases. We will focus our discussion on one \\nparticular system, Neo4j, which is used in many applications. Neo4j is an open \\nsource system, and it is implemented in Java. We will discuss the Neo4j data model'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 917, 'page_label': '918'}, page_content='904 Chapter 24 NOSQL Databases and Big Data Storage Systems\\nin Section 24.6.1, and give an introduction to the Neo4j querying capabilities in \\nSection 24.6.2. Section 24.6.3 gives an overview of the distributed systems and \\nsome other characteristics of Neo4j.\\n24.6.1 Neo4j Data Model\\nThe data model in Neo4j organizes data using the concepts of nodes and relation-\\nships. Both nodes and relationships can have properties, which store the data items \\nassociated with nodes and relationships. Nodes can have labels; the nodes that have \\nthe same label are grouped into a collection that identifies a subset of the nodes in \\nthe database graph for querying purposes. A node can have zero, one, or several \\nlabels. Relationships are directed; each relationship has a start node and end node as \\nwell as a relationship type, which serves a similar role to a node label by identifying \\nsimilar relationships that have the same relationship type. Properties can be speci-\\nfied via a map pattern, which is made of one or more “name : value” pairs enclosed \\nin curly brackets; for example \\n{Lname : ‘Smith’, Fname : ‘John’, Minit : ‘B’}.\\nIn conventional graph theory, nodes and relationships are generally called vertices \\nand edges. The Neo4j graph data model somewhat resembles how data is repre-\\nsented in the ER and EER models (see Chapters 3 and  4) , but with some notable \\ndifferences. Comparing the Neo4j graph model with ER/EER concepts, nodes cor-\\nrespond to entities, node labels correspond to entity types and subclasses , relation-\\nships correspond to relationship instances , relationship types correspond to \\nrelationship types, and properties correspond to attributes. One notable difference \\nis that a relationship is directed in Neo4j, but is not in ER/EER. Another is that a \\nnode may have no label in Neo4j, which is not allowed in ER/EER because every \\nentity must belong to an entity type. A third crucial difference is that the graph \\nmodel of Neo4j is used as a basis for an actual high-performance distributed data-\\nbase system whereas the ER/EER model is mainly used for database design.\\nFigure 24.4(a) shows how a few nodes can be created in Neo4j. There are various \\nways in which nodes and relationships can be created; for example, by calling appro-\\npriate Neo4j operations from various Neo4j APIs. We will just show the high-level \\nsyntax for creating nodes and relationships; to do so, we will use the Neo4j CREATE \\ncommand, which is part of the high-level declarative query language Cypher. Neo4j \\nhas many options and variations for creating nodes and relationships using various \\nscripting interfaces, but a full discussion is outside the scope of our presentation.\\n ■ Labels and properties. When a node is created, the node label can be speci-\\nfied. It is also possible to create nodes without any labels. In Figure 24.4(a), the \\nnode labels are EMPLOYEE, DEPARTMENT, PROJECT, and LOCATION, \\nand the created nodes correspond to some of the data from the COMPANY \\ndatabase in Figure 5.6 with a few modifications; for example, we use EmpId \\ninstead of SSN, and we only include a small subset of the data for illustration \\npurposes. Properties are enclosed in curly brackets { … }. It is possible that \\nsome nodes have multiple labels; for example the same node can be labeled as \\nPERSON and EMPLOYEE and MANAGER by listing all the labels separated \\nby the colon symbol as follows: PERSON:EMPLOYEE:MANAGER. Having \\nmultiple labels is similar to an entity belonging to an entity type (PERSON)'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 918, 'page_label': '919'}, page_content='24.6 NOSQL Graph Databases and Neo4j  905\\nplus some subclasses of PERSON (namely EMPLOYEE and MANAGER) in \\nthe EER model (see Chapter 4) but can also be used for other purposes.\\n ■ Relationships and relationship types. Figure 24.4(b) shows a few example \\nrelationships in Neo4j based on the COMPANY database in Figure 5.6. \\nThe → specifies the direction of the relationship, but the relationship can be \\ntraversed in either direction. The relationship types (labels) in Figure 24.4(b) \\nare WorksFor, Manager, LocatedIn, and WorksOn; only relationships with \\nthe relationship type WorksOn have properties (Hours) in Figure 24.4(b).\\n ■ Paths. A path specifies a traversal of part of the graph. It is typically used as \\npart of a query to specify a pattern, where the query will retrieve from the \\ngraph data that matches the pattern. A path is typically specified by a start \\nnode, followed by one or more relationships, leading to one or more end \\nnodes that satisfy the pattern. It is somewhat similar to the concepts of path \\nexpressions that we discussed in Chapters 12 and  13 in the context of query \\nlanguages for object databases (OQL) and XML (XPath and XQuery).\\n ■ Optional Schema.  A schema is optional in Neo4j. Graphs can be created \\nand used without a schema, but in Neo4j version 2.0, a few schema-related \\nfunctions were added. The main features related to schema creation involve \\ncreating indexes and constraints based on the labels and properties. For \\nexample, it is possible to create the equivalent of a key constraint on a prop-\\nerty of a label, so all nodes in the collection of nodes associated with the label \\nmust have unique values for that property.\\n ■ Indexing and node identifiers.  When a node is created, the Neo4j system \\ncreates an internal unique system-defined identifier for each node. To \\nretrieve individual nodes using other properties of the nodes efficiently, the \\nuser can create indexes for the collection of nodes that have a particular \\nlabel. Typically, one or more of the properties of the nodes in that collection \\ncan be indexed. For example, Empid can be used to index nodes with the \\nEMPLOYEE label, Dno to index the nodes with the DEPARTMENT label, \\nand Pno to index the nodes with the PROJECT label.\\n24.6.2 The Cypher Query Language of Neo4j\\nNeo4j has a high-level query language, Cypher. There are declarative commands for \\ncreating nodes and relationships (see Figures 24.4(a) and (b)), as well as for finding \\nnodes and relationships based on specifying patterns. Deletion and modification of \\ndata is also possible in Cypher. We introduced the CREATE command in the previous \\nsection, so we will now give a brief overview of some of the other features of Cypher.\\nA Cypher query is made up of clauses. When a query has several clauses, the result \\nfrom one clause can be the input to the next clause in the query. We will give a fla-\\nvor of the language by discussing some of the clauses using examples. Our presenta-\\ntion is not meant to be a detailed presentation on Cypher, just an introduction to \\nsome of the languages features. Figure 24.4(c) summarizes some of the main clauses \\nthat can be part of a Cyber query. The Cyber language can specify complex queries \\nand updates on a graph database. We will give a few of examples to illustrate simple \\nCyber queries in Figure 24.4(d).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 919, 'page_label': '920'}, page_content='906 Chapter 24 NOSQL Databases and Big Data Storage Systems\\n(a) creating some nodes for the COMPANY data (from Figure 5.6):\\n CREATE (e1: EMPLOYEE, {Empid: ‘1’, Lname: ‘Smith’, Fname: ‘John’, Minit: ‘B’})\\n CREATE (e2: EMPLOYEE, {Empid: ‘2’, Lname: ‘Wong’, Fname: ‘Franklin’})\\n CREATE (e3: EMPLOYEE, {Empid: ‘3’, Lname: ‘Zelaya’, Fname: ‘Alicia’})\\n CREATE (e4: EMPLOYEE, {Empid: ‘4’, Lname: ‘Wallace’, Fname: ‘Jennifer’, Minit: ‘S’})\\n …\\n CREATE (d1: DEPARTMENT, {Dno: ‘5’, Dname: ‘Research’})\\n CREATE (d2: DEPARTMENT, {Dno: ‘4’, Dname: ‘Administration’})\\n …\\n \\nCREATE (p1: PROJECT, {Pno: ‘1’, Pname: ‘ProductX’})\\n CREATE (p2: PROJECT, {Pno: ‘2’, Pname: ‘ProductY’})\\n CREATE (p3: PROJECT, {Pno: ‘10’, Pname: ‘Computerization’})\\n CREATE (p4: PROJECT, {Pno: ‘20’, Pname: ‘Reorganization’})\\n …\\n \\nCREATE (loc1: LOCATION, {Lname: ‘Houston’})\\n CREATE (loc2: LOCATION, {Lname: ‘Stafford’})\\n CREATE (loc3: LOCATION, {Lname: ‘Bellaire’})\\n CREATE (loc4: LOCATION, {Lname: ‘Sugarland’})\\n …\\n(b) creating some relationships for the COMPANY data (from Figure 5.6):\\n CREATE (e1) – [ : WorksFor ] –> (d1)\\n CREATE (e3) – [ : WorksFor ] –> (d2)\\n …\\n \\nCREATE (d1) – [ : Manager ] –> (e2)\\n CREATE (d2) – [ : Manager ] –> (e4)\\n …\\n \\nCREATE (d1) – [ : LocatedIn ] –> (loc1)\\n CREATE (d1) – [ : LocatedIn ] –> (loc3)\\n CREATE (d1) – [ : LocatedIn ] –> (loc4)\\n CREATE (d2) – [ : LocatedIn ] –> (loc2)\\n …\\n \\nCREATE (e1) – [ : WorksOn, {Hours: ‘32.5’} ] –> (p1)\\n CREATE (e1) – [ : WorksOn, {Hours: ‘7.5’} ] –> (p2)\\n CREATE (e2) – [ : WorksOn, {Hours: ‘10.0’} ] –> (p1)\\n CREATE (e2) – [ : WorksOn, {Hours: 10.0} ] –> (p2)\\n CREATE (e2) – [ : WorksOn, {Hours: ‘10.0’} ] –> (p3)\\n CREATE (e2) – [ : WorksOn, {Hours: 10.0} ] –> (p4)\\n …\\nFigure 24.4 \\nExamples in Neo4j using the Cypher language. (a) Creating some nodes. (b) Creating some relationships.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 920, 'page_label': '921'}, page_content='24.6 NOSQL Graph Databases and Neo4j  907\\n(c) Basic simplified syntax of some common Cypher clauses:\\n Finding nodes and relationships that match a pattern: MATCH <pattern>\\n Specifying aggregates and other query variables: WITH <specifications>\\n Specifying conditions on the data to be retrieved: WHERE <condition>\\n Specifying the data to be returned: RETURN <data>\\n Ordering the data to be returned: ORDER BY <data>\\n Limiting the number of returned data items: LIMIT <max number>\\n Creating nodes: CREATE <node, optional labels and properties>\\n Creating relationships: CREATE <relationship, relationship type and optional properties>\\n Deletion: DELETE <nodes or relationships>\\n Specifying property values and labels: SET <property values and labels>\\n Removing property values and labels: REMOVE <property values and labels>\\n(d) Examples of simple Cypher queries:\\n1. MATCH (d : DEPARTMENT {Dno: ‘5’}) – [ : LocatedIn ] → (loc)\\n RETURN d.Dname , loc.Lname\\n2. MATCH (e: EMPLOYEE {Empid: ‘2’}) – [ w: WorksOn ] → (p)\\n RETURN e.Ename , w.Hours, p.Pname\\n3. MATCH (e ) – [ w: WorksOn ] → (p: PROJECT {Pno: 2})\\n RETURN p.Pname, e.Ename , w.Hours\\n4. MATCH (e) – [ w: WorksOn ] → (p)\\n RETURN e.Ename , w.Hours, p.Pname\\n ORDER BY e.Ename\\n5. MATCH (e) – [ w: WorksOn ] → (p)\\n RETURN e.Ename , w.Hours, p.Pname\\n ORDER BY e.Ename\\n LIMIT 10\\n6. MATCH (e) – [ w: WorksOn ] → (p)\\n WITH e, COUNT(p) AS numOfprojs\\n WHERE numOfprojs > 2\\n RETURN e.Ename , numOfprojs\\n ORDER BY numOfprojs\\n7. MATCH (e) – [ w: WorksOn ] → (p)\\n RETURN e , w, p\\n ORDER BY e.Ename\\n LIMIT 10\\n8. MATCH (e: EMPLOYEE {Empid: ‘2’})\\n SET e.Job = ‘Engineer’\\nFigure 24.4 (continued)\\nExamples in Neo4j using the Cypher language. (c) Basic syntax of Cypher queries. (d) Examples of Cypher queries.\\nQuery 1 in Figure 24.4(d) shows how to use the MATCH and RETURN clauses in a \\nquery, and the query retrieves the locations for department number 5. Match speci-\\nfies the pattern and the query variables (d and loc) and RETURN specifies the query \\nresult to be retrieved by refering to the query variables. Query 2 has three variables \\n(e, w, and p), and returns the projects and hours per week that the employee with'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 921, 'page_label': '922'}, page_content='908 Chapter 24 NOSQL Databases and Big Data Storage Systems\\nEmpid = 2 works on. Query 3, on the other hand, returns the employees and hours \\nper week who work on the project with Pno = 2. Query 4 illustrates the ORDER BY \\nclause and returns all employees and the projects they work on, sorted by Ename. It \\nis also possible to limit the number of returned results by using the LIMIT clause as \\nin query 5, which only returns the first 10 answers.\\nQuery 6 illustrates the use of WITH and aggregation, although the WITH clause can \\nbe used to separate clauses in a query even if there is no aggregation. Query 6 also illus-\\ntrates the WHERE clause to specify additional conditions, and the query returns the \\nemployees who work on more than two projects, as well as the number of projects each \\nemployee works on. It is also common to return the nodes and relationships them-\\nselves in the query result, rather than the property values of the nodes as in the previ-\\nous queries. Query 7 is similar to query 5 but returns the nodes and relationships only, \\nand so the query result can be displayed as a graph using Neo4j’s visualization tool. It is \\nalso possible to add or remove labels and properties from nodes. Query 8 shows how to \\nadd more properties to a node by adding a Job property to an employee node.\\nThe above gives a brief flavor for the Cypher query language of Neo4j. The full lan-\\nguage manual is available online (see the bibliographic notes).\\n24.6.3  Neo4j Interfaces and Distributed System Characteristics\\nNeo4j has other interfaces that can be used to create, retrieve, and update nodes and \\nrelationships in a graph database. It also has two main versions: the enterprise edi-\\ntion, which comes with additional capabilities, and the community edition. We dis-\\ncuss some of the additional features of Neo4j in this subsection.\\n ■ Enterprise edition vs. community edition. Both editions support the Neo4j \\ngraph data model and storage system, as well as the Cypher graph query \\nlanguage, and several other interfaces, including a high-performance native \\nAPI, language drivers for several popular programming languages, such as \\nJava, Python, PHP, and the REST (Representational State Transfer) API. In \\naddition, both editions support ACID properties. The enterprise edition \\nsupports additional features for enhancing performance, such as caching \\nand clustering of data and locking.\\n ■ Graph visualization interface. Neo4j has a graph visualization interface, so \\nthat a subset of the nodes and edges in a database graph can be displayed as a \\ngraph. This tool can be used to visualize query results in a graph representation.\\n ■ Master-slave replication.  Neo4j can be configured on a cluster of distrib-\\nuted system nodes (computers), where one node is designated the master \\nnode. The data and indexes are fully replicated on each node in the cluster. \\nVarious ways of synchronizing the data between master and slave nodes can \\nbe configured in the distributed cluster.\\n ■ Caching. A main memory cache can be configured to store the graph data \\nfor improved performance.\\n ■ Logical logs. Logs can be maintained to recover from failures.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 922, 'page_label': '923'}, page_content='Review Questions 909\\nA full discussion of all the features and interfaces of Neo4j is outside the scope of \\nour presentation. Full documentation of Neo4j is available online (see the biblio-\\ngraphic notes).\\n24.7 Summary\\nIn this chapter, we discussed the class of database systems known as NOSQL sys-\\ntems, which focus on efficient storage and retrieval of large amounts of “big data.” \\nApplications that use these types of systems include social media, Web links, user \\nprofiles, marketing and sales, posts and tweets, road maps and spatial data, and \\ne-mail. The term NOSQL is generally interpreted as Not Only SQL—rather than \\nNO to SQL—and is meant to convey that many applications need systems other \\nthan traditional relational SQL systems to augment their data management needs. \\nThese systems are distributed databases or distributed storage systems, with a focus \\non semistructured data storage, high performance, availability, data replication, \\nand scalability rather than an emphasis on immediate data consistency, powerful \\nquery languages, and structured data storage.\\nIn Section 24.1, we started with an introduction to NOSQL systems, their charac-\\nteristics, and how they differ from SQL systems. Four general categories of NOSQL \\nsystems are document-based, key-value stores, column-based, and graph-based. \\nIn Section 24.2, we discussed how NOSQL systems approach the issue of consis-\\ntency among multiple replicas (copies) by using the paradigm known as eventual \\nconsistency. We discussed the CAP theorem, which can be used to understand the \\nemphasis of NOSQL systems on availability. In Sections 24.3 through  24.6, we \\npresented an overview of each of the four main categories of NOSQL systems—\\nstarting with document-based systems in Section 24.3, followed by key-value \\nstores in Section 24.4, then column-based systems in Section 24.5, and finally \\ngraph-based systems in Section 24.6. We also noted that some NOSQL systems \\nmay not fall neatly into a single category but rather use techniques that span two \\nor more categories.\\nReview Questions\\n 24.1. For which types of applications were NOSQL systems developed?\\n 24.2. What are the main categories of NOSQL systems? List a few of the NOSQL \\nsystems in each category.\\n 24.3. What are the main characteristics of NOSQL systems in the areas related to \\ndata models and query languages?\\n 24.4. What are the main characteristics of NOSQL systems in the areas related to \\ndistributed systems and distributed databases?\\n 24.5. What is the CAP theorem? Which of the three properties (consistency, \\navailability, partition tolerance) are most important in NOSQL systems?'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 923, 'page_label': '924'}, page_content='910 Chapter 24 NOSQL Databases and Big Data Storage Systems\\n 24.6. What are the similarities and differences between using consistency in CAP \\nversus using consistency in ACID?\\n 24.7. What are the data modeling concepts used in MongoDB? What are the main \\nCRUD operations of MongoDB?\\n 24.8. Discuss how replication and sharding are done in MongoDB.\\n 24.9. Discuss the data modeling concepts in DynamoDB.\\n 24.10. Describe the consistent hashing schema for data distribution, replication, \\nand sharding. How are consistency and versioning handled in Voldemort?\\n 24.11. What are the data modeling concepts used in column-based NOSQL sys-\\ntems and Hbase?\\n 24.12. What are the main CRUD operations in Hbase?\\n 24.13. Discuss the storage and distributed system methods used in Hbase.\\n 24.14. What are the data modeling concepts used in the graph-oriented NOSQL \\nsystem Neo4j?\\n 24.15. What is the query language for Neo4j?\\n 24.16. Discuss the interfaces and distributed systems characteristics of Neo4j.\\nSelected Bibliography\\nThe original paper that described the Google BigTable distributed storage system \\nis Chang et al. (2006), and the original paper that described the Amazon Dynamo \\nkey-value store system is DeCandia et al. (2007). There are numerous papers that \\ncompare various NOSQL systems with SQl (relational systems); for example, \\nParker et al. (2013). Other papers compare NOSQL systems to other NOSQL sys-\\ntems; for example Cattell (2010), Hecht and Jablonski (2011), and Abramova and \\nBernardino (2013).\\nThe documentation, user manuals, and tutorials for many NOSQL systems can be \\nfound on the Web. Here are a few examples:\\nMongoDB tutorials: docs.mongodb.org/manual/tutorial/\\nMongoDB manual: docs.mongodb.org/manual/\\nVoldemort documentation: docs.project-voldemort.com/voldemort/\\nCassandra Web site: cassandra.apache.org\\nHbase Web site: hbase.apache.org\\nNeo4j documentation: neo4j.com/docs/\\nIn addition, numerous Web sites categorize NOSQL systems into additional sub-\\ncategories based on purpose; nosql-database.org is one example of such a site.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 924, 'page_label': '925'}, page_content='911\\n25\\nBig Data Technologies Based  \\non MapReduce and Hadoop1\\nT\\nhe amount of data worldwide has been growing \\never since the advent of the World Wide Web \\naround 1994. The early search engines—namely, AltaVista (which was acquired by \\nYahoo in 2003 and which later became the Yahoo! search engine) and Lycos (which \\nwas also a search engine and a Web portal—were established soon after the Web \\ncame along. They were later overshadowed by the likes of Google and Bing. Then \\ncame an array of social networks such as Facebook, launched in 2004, and Twitter, \\nfounded in 2006. LinkedIn, a professional network launched in 2003, boasts over \\n250 million users worldwide. Facebook has over 1.3 billion users worldwide today; \\nof these, about 800 million are active on Facebook daily. Twitter had an estimated \\n980 million users in early 2014 and it was reported to have reached the rate of 1 bil-\\nlion tweets per day in October 2012. These statistics are updated continually and \\nare easily available on the Web.\\nOne major implication of the establishment and exponential growth of the Web, \\nwhich brought computing to laypeople worldwide, is that ordinary people started \\ncreating all types of transactions and content that generate new data. These users \\nand consumers of multimedia data require systems to deliver user-specific data \\ninstantaneously from mammoth stores of data at the same time that they create huge \\namounts of data themselves. The result is an explosive growth in the amount of data \\ngenerated and communicated over networks worldwide; in addition, businesses and \\ngovernmental institutions electronically record every transaction of each customer, \\nvendor, and supplier and thus have been accumulating data in so-called data ware-\\nhouses (to be discussed in Chapter 29). Added to this mountain of data is the data \\nchapter 25\\n1We acknowledge the significant contribution of Harish Butani, member of the Hive Program Management \\nCommittee, and Balaji Palanisamy, University of Pittsburgh, to this chapter.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 925, 'page_label': '926'}, page_content='912 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\ngenerated by sensors embedded in devices such as smartphones, energy smart \\nmeters, automobiles, and all kinds of gadgets and machinery that sense, create, and \\ncommunicate data in the internet of things. And, of course, we must consider the \\ndata generated daily from satellite imagery and communication networks.\\nThis phenomenal growth of data generation means that the amount of data in a single \\nrepository can be numbered in petabytes (10**15 bytes, which approximates to 2**50 \\nbytes) or terabytes (e.g., 1,000 terabytes). The term big data has entered our common \\nparlance and refers to such massive amounts of data. The McKinsey report\\n2 defines \\nthe term big data as datasets whose size exceeds the typical reach of a DBMS to capture, \\nstore, manage, and analyze that data. The meaning and implications of this data \\nonslaught are reflected in some of the facts mentioned in the McKinsey report:\\n ■ A $600 disk can store all of the world’s music today.\\n ■ Every month, 30 billion of items of content are stored on Facebook.\\n ■ More data is stored in 15 of the 17 sectors of the U.S. economy than is stored \\nin the Library of Congress, which, as of 2011, stored 235 terabytes of data.\\n ■ There is currently a need for over 140,000 deep-data-analysis positions and \\nover 1.5 million data-savvy managers in the United States. Deep data analy-\\nsis involves more knowledge discovery type analyses.\\nBig data is everywhere, so every sector of the economy stands to benefit by harness-\\ning it appropriately with technologies that will help data users and managers make \\nbetter decisions based on historical evidence. According to the Mckinsey report,\\nIf the U.S. healthcare [system] could use the big data creatively and effectively to \\ndrive efficiency and quality, we estimate that the potential value from data in the \\nsector could be more than $300 billion in value every year.\\nBig data has created countless opportunities to give consumers information in a \\ntimely manner—information that will prove useful in making decisions, discover-\\ning needs and improving performance, customizing products and services, giving \\ndecision makers more effective algorithmic tools, and creating value by innovations \\nin terms of new products, services, and business models. IBM has corroborated this \\nstatement in a recent book,\\n3 which outlines why IBM has embarked on a worldwide \\nmission of enterprise-wide big data analytics. The IBM book describes various types \\nof analytics applications:\\n ■ Descriptive and predictive analytics: Descriptive analytics relates to report-\\ning what has happened, analyzing the data that contributed to it to figure \\nout why it happened, and monitoring new data to find out what is happen-\\ning now. Predictive analytics uses statistical and data mining techniques (see \\nChapter 28) to make predictions about what will happen in the future.\\n2The introduction is largely based on the McKinsey (2012) report on big data from the McKinsey Global \\nInstitute.\\n3See IBM (2014): Analytics Across the Enterprise: How IBM Realizes Business Value from Big Data and \\nAnalytics.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 926, 'page_label': '927'}, page_content='Chapter 25 Big Data Technologies Based on MapReduce and Hadoop  913\\n ■ Prescriptive analytics: Refers to analytics that recommends actions.\\n ■ Social media analytics: Refers to doing a sentiment analysis to assess public \\nopinion on topics or events. It also allows users to discover the behavior pat-\\nterns and tastes of individuals, which can help industry target goods and \\nservices in a customized way.\\n ■ Entity analytics: This is a somewhat new area that groups data about enti-\\nties of interest and learns more about them.\\n ■ Cognitive computing: Refers to an area of developing computing systems \\nthat will interact with people to give them better insight and advice.\\nIn another book, Bill Franks of Teradata4 voices a similar theme; he states that tap-\\nping big data for better analytics is essential for a competitive advantage in any \\nindustry today, and he shows how to develop a “big data advanced analytics ecosys-\\ntem” in any organization to uncover new opportunities in business.\\nAs we can see from all these industry-based publications by experts, big data is \\nentering a new frontier in which big data will be harnessed to provide analytics-\\noriented applications that will lead to increased productivity, higher quality, and \\ngrowth in all businesses. This chapter discusses the technology that has been created \\nover the last decade to harness big data. We focus on those technologies that can be \\nattributed to the MapReduce/Hadoop ecosystem, which covers most of the ground \\nof open source projects for big data applications. We will not be able to get into the \\napplications of the big data technology for analytics. That is a vast area by itself. \\nSome of the basic data mining concepts are mentioned in Chapter 28; however, \\ntoday’s analytics offerings go way beyond the basic concepts we have outlined there.\\nIn Section 25.1, we introduce the essential features of big data. In Section 25.2, we \\nwill give the historical background behind the MapReduce/Hadoop technology \\nand comment on the various releases of Hadoop. Section 25.3 discusses the \\nunderlying file system called Hadoop Distributed File System for Hadoop. We \\ndiscuss its architecture, the I/O operations it supports, and its scalability. Sec-\\ntion\\xa025.4 provides further details on MapReduce (MR), including its runtime \\nenvironment and high-level interfaces called Pig and Hive. We also show the \\npower of MapReduce in terms of the relational join implemented in various ways. \\nSection\\xa025.5 is devoted to the later development called Hadoop v2 or MRv2 or \\nYARN, which separates resource management from job management. Its rationale \\nis explained first, and then its architecture and other frameworks being developed \\non YARN are explained. In Section 25.6 we discuss some general issues related to \\nthe MapReduce/Hadoop technology. First we discuss this technology vis-à-vis \\nthe parallel DBMS technology. Then we discuss it in the context of cloud comput-\\ning, and we mention the data locality issues for improving performance. YARN \\nas a data service platform is discussed next, followed by the challenges for big data \\ntechnology in general. We end this chapter in Section 25.7 by mentioning some \\nongoing projects and summarizing the chapter.\\n4See Franks (2013) : Taming The Big Data Tidal Wave.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 927, 'page_label': '928'}, page_content='914 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\n25.1 What Is Big Data?\\nBig data is becoming a popular and even a fashionable term. People use this term \\nwhenever a large amount of data is involved with some analysis; they think that \\nusing this term will make the analysis look like an advanced application. However, \\nthe term big data legitimately refers to datasets whose size is beyond the ability of \\ntypical database software tools to capture, store, manage, and analyze. In today’s \\nenvironment, the size of datasets that may be considered as big data ranges from \\nterabytes (10 **12 bytes), or petabytes (10 **15 bytes), to exabytes (10 **18 bytes). \\nThe notion of what is Big data will depend on the industry, how data is used, how \\nmuch historical data is involved and many other characteristics. The Gartner \\nGroup, a popular enterprise-level organization that industry looks up to for learn-\\ning about trends, characterized big data in 2011 by the three V’s: volume, velocity, \\nand variety. Other characteristics, such as veracity and value, have been added to \\nthe definition by other researchers. Let us briefly see what these stand for.\\nVolume. The volume of data obviously refers to the size of data managed by the \\nsystem. Data that is somewhat automatically generated tends to be voluminous. \\nExamples include sensor data, such as the data in manufacturing or processing \\nplants generated by sensors; data from scanning equipment, such as smart card and \\ncredit card readers; and data from measurement devices, such as smart meters or \\nenvironmental recording devices.\\nThe industrial internet of things (IIOT or IOT) is expected to bring about a revo-\\nlution that will improve the operational efficiency of enterprises and open up new \\nfrontiers for harnessing intelligent technologies. The IOT will cause billions of \\ndevices to be connected to the Internet because these devices generate data continu-\\nously. For example, in gene sequencing, next generation sequencing (NGS) tech-\\nnology means that the volume of gene sequence data will be increased exponentially.\\nMany additional applications are being developed and are slowly becoming a real-\\nity. These applications include using remote sensing to detect underground sources \\nof energy, environmental monitoring, traffic monitoring and regulation by auto-\\nmatic sensors mounted on vehicles and roads, remote monitoring of patients using \\nspecial scanners and equipment, and tighter control and replenishment of invento-\\nries using radio-frequency identification (RFID) and other technologies. All these \\ndevelopments will have associated with them a large volume of data. Social net-\\nworks such as Twitter and Facebook have hundreds of millions of subscribers \\nworldwide who generate new data with every message they send or post they make. \\nTwitter hit a half billion tweets daily in October 2012.\\n5 The amount of data required \\nto store one second of high-definition video may equal 2,000 pages of text data. \\nThus, the multimedia data being uploaded on YouTube and similar video hosting \\nplatforms is significantly more voluminous than simple numeric or text data. In \\n2010, enterprises stored over 13 exabytes (10 **18 bytes) of data, which amounts to \\nover 50,000 times the amount of data stored by the Library of Congress.\\n6\\n5See Terdiman (2012): http://www.cnet.com/news/report-twitter-hits-half-a-billion-tweets-a-day/\\n6From Jagadish et al. (2014).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 928, 'page_label': '929'}, page_content='25.1 What Is Big Data?  915\\nVelocity. The definition of big data  goes beyond the dimension of volume; it \\nincludes the types and frequency of data that are disruptive to traditional database \\nmanagement tools. The Mckinsey report on big data\\n7 described velocity as the \\nspeed at which data is created, accumulated, ingested, and processed. High velocity \\nis attributed to data when we consider the typical speed of transactions on stock \\nexchanges; this speed reaches billions of transactions per day on certain days. If we \\nmust process these transactions to detect potential fraud or we must process bil-\\nlions of call records on cell phones daily to detect malicious activity, we face the \\nvelocity dimension. Real-time data and streaming data are accumulated by the likes \\nof Twitter and Facebook at a very high velocity. Velocity is helpful in detecting \\ntrends among people that are tweeting a million tweets every three minutes. Pro-\\ncessing of streaming data for analysis also involves the velocity dimension.\\nVariety.  Sources of data in traditional applications were mainly transactions \\ninvolving financial, insurance, travel, healthcare, retail industries, and governmen-\\ntal and judicial processing. The types of sources have expanded dramatically and \\ninclude Internet data (e.g., clickstream and social media), research data (e.g., sur-\\nveys and industry reports), location data (e.g., mobile device data and geospatial \\ndata), images (e.g., surveillance, satellites and medical scanning), e-mails, supply \\nchain data (e.g., EDI—electronic data interchange, vendor catalogs), signal data \\n(e.g., sensors and RFID devices), and videos (YouTube enters hundreds of minutes \\nof video every minute). Big data includes structured, semistructured, and unstruc-\\ntured data (see discussion in Chapter 26) in different proportions based on context.\\nStructured data feature a formally structured data model, such as the relational \\nmodel, in which data are in the form of tables containing rows and columns, and a \\nhierarchical database in IMS, which features record types as segments and fields \\nwithin a record.\\nUnstructured data have no identifiable formal structure. We discussed systems like \\nMongoDB (in Chapter 24), which stores unstructured document-oriented data, \\nand Neo4j, which stores data in the form of a graph. Other forms of unstructured \\ndata include e-mails and blogs, PDF files, audio, video, images, clickstreams, and \\nWeb contents. The advent of the World Wide Web in 1993–1994 led to tremen-\\ndous growth in unstructured data. Some forms of unstructured data may fit into a \\nformat that allows well-defined tags that separate semantic elements; this format \\nmay include the capability to enforce hierarchies within the data. XML is hierarchi-\\ncal in its descriptive mechanism, and various forms of XML have come about in \\nmany domains; for example, biology (bioML—biopolymer markup language), GIS \\n(gML—geography markup language), and brewing (BeerXML—language for \\nexchange of brewing data), to name a few. Unstructured data constitutes the major \\nchallenge in today’s big data systems.\\nVeracity. The veracity dimension of big data is a more recent addition than the \\nadvent of the Internet. Veracity has two built-in features: the credibility of the \\nsource, and the suitability of data for its target audience. It is closely related to trust; \\n7See Mckinsey (2013).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 929, 'page_label': '930'}, page_content='916 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\nlisting veracity as one of the dimensions of big data amounts to saying that data \\ncoming into the so-called big data applications have a variety of trustworthiness, \\nand therefore before we accept the data for analytical or other applications, it must \\ngo through some degree of quality testing and credibility analysis. Many sources of \\ndata generate data that is uncertain, incomplete, and inaccurate, therefore making \\nits veracity questionable.\\nWe now turn our attention to the technologies that are considered the pillars of big \\ndata technologies. It is anticipated that by 2016, more than half of the data in the \\nworld may be processed by Hadoop-related technologies. It is therefore important \\nfor us to trace the MapReduce/Hadoop revolution and understand how this tech-\\nnology is positioned today. The historical development starts with the program-\\nming paradigm called MapReduce programming.\\n25.2 Introduction to MapReduce and Hadoop\\nIn this section, we will introduce the technology for big data analytics and data pro-\\ncessing known as Hadoop, an open source implementation of the MapReduce pro-\\ngramming model. The two core components of Hadoop are the MapReduce \\nprogramming paradigm and HDFS, the Hadoop Distributed File System. We will \\nbriefly explain the background behind Hadoop and then MapReduce. Then we will \\nmake some brief remarks about the Hadoop ecosystem and the Hadoop releases.\\n25.2.1 Historical Background\\nHadoop has originated from the quest for an open source search engine. The first \\nattempt was made by the then Internet archive director Doug Cutting and Univer-\\nsity of Washington graduate student Mike Carafella. Cutting and Carafella devel-\\noped a system called Nutch that could crawl and index hundreds of millions of Web \\npages. It is an open source Apache project.\\n8 After Google released the Google File \\nSystem 9 paper in October 2003 and the MapReduce programming paradigm \\npaper10 in December 2004, Cutting and Carafella realized that a number of things \\nthey were doing could be improved based on the ideas in these two papers. They \\nbuilt an underlying file system and a processing framework that came to be known \\nas Hadoop (which used Java as opposed to the C++ used in MapReduce) and ported \\nNutch on top of it. In 2006, Cutting joined Yahoo, where there was an effort under \\nway to build open source technologies using ideas from the Google File System and \\nthe MapReduce programming paradigm. Yahoo wanted to enhance its search pro-\\ncessing and build an open source infrastructure based on the Google File System \\nand MapReduce. Yahoo spun off the storage engine and the processing parts \\nof Nutch as Hadoop (named after the stuffed elephant toy of Cutting’s son). The \\n8For documentation on Nutch, see http:nutch.apache.org\\n9Ghemawat, Gbioff, and Leung (2003).\\n10Dean and Ghemawat (2004).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 930, 'page_label': '931'}, page_content='25.2 Introduction to MapReduce and Hadoop  917\\ninitial requirements for Hadoop were to run batch processing using cases with a \\nhigh degree of scalability. However, the circa 2006 Hadoop could only run on a \\nhandful of nodes. Later, Yahoo set up a research forum for the company’s data sci-\\nentists; doing so improved the search relevance and ad revenue of the search engine \\nand at the same time helped to mature the Hadoop technology. In 2011, Yahoo \\nspun off Hortonworks as a Hadoop-centered software company. By then, Yahoo’s \\ninfrastructure contained hundreds of petabytes of storage and 42,000 nodes in the \\ncluster. In the years since Hadoop became an open source Apache project, thou-\\nsands of developers worldwide have contributed to it. A joint effort by Google, \\nIBM, and NSF used a 2,000-node Hadoop cluster at a Seattle data center and helped \\nfurther universities’ research on Hadoop. Hadoop has seen tremendous growth \\nsince the 2008 launch of Cloudera as the first commercial Hadoop company and \\nthe subsequent mushrooming of a large number of startups. IDC, a software indus-\\ntry market analysis firm, predicts that the Hadoop market will surpass $800 million \\nin 2016; IDC predicts that the big data market will hit $23 billion in 2016. For more \\ndetails about the history of Hadoop, consult a four-part article by Harris.\\n11\\nAn integral part of Hadoop is the MapReduce programming framework. Before we \\ngo any further, let us try to understand what the MapReduce programming paradigm \\nis all about. We defer a detailed discussion of the HDFS file system to Section 25.3.\\n25.2.2 MapReduce\\nThe MapReduce programming model and runtime environment was first described \\nby Jeffrey Dean and Sanjay Ghemawat (Dean & Ghemawat (2004)) based on their \\nwork at Google. Users write their programs in a functional style of map and reduce \\ntasks, which are automatically parallelized and executed on large clusters of com-\\nmodity hardware. The programming paradigm has existed as far back as the lan-\\nguage LISP, which was designed by John McCarthy in late 1950s. However, the \\nreincarnation of this way of doing parallel programming and the way this paradigm \\nwas implemented at Google gave rise to a new wave of thinking that contributed to \\nthe subsequent developments of technologies such as Hadoop. The runtime system \\nhandles many of the messy engineering aspects of parallelization, fault tolerance, \\ndata distribution, load balancing, and management of task communication. As long \\nas users adhere to the contracts laid out by the MapReduce system, they can just \\nfocus on the logical aspects of this program; this allows programmers without dis-\\ntributed systems experience to perform analysis on very large datasets.\\nThe motivation behind the MapReduce system was the years spent by the authors \\nand others at Google implementing hundreds of special-purpose computations on \\nlarge datasets (e.g., computing inverted indexes from Web content collected via \\nWeb crawling; building Web graphs; and extracting statistics from Web logs, such \\nas frequency distribution of search requests by topic, by region, by type of user, \\netc.). Conceptually, these tasks are not difficult to express; however, given the scale \\n11Derreck Harris : ‘The history of Hadoop: from 4 nodes to the future of data,” at https://gigaom.com/ \\n2013/03/04/the-history-of-hadoop-from-4-nodes-to-the-future-of-data/'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 931, 'page_label': '932'}, page_content='918 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\nof data in billions of Web pages and with the data spread over thousands of \\nmachines, the execution task was nontrivial. Issues of program control and data \\nmanagement, data distribution, parallelization of computation, and handling of \\nfailures became critically important.\\nThe MapReduce programming model and runtime environment was designed to \\ncope with the above complexity. The abstraction is inspired by the map and reduce \\nprimitives present in LISP and many other functional languages. An underlying \\nmodel of data is assumed; this model treats an object of interest in the form of a \\nunique key that has associated content or value. This is the key-value pair. Surpris-\\ningly, many computations can be expressed as applying a map operation to each \\nlogical “record” that produces a set of intermediate key-value pairs and then apply-\\ning a reduce operation to all the values that shared the same key (the purpose of \\nsharing is to combine the derived data). This model allows the infrastructure to \\nparallelize large computations easily and to use re-execution as the primary mecha-\\nnism for fault tolerance. The idea of providing a restricted programming model so \\nthat the runtime can parallelize computations automatically is not new.  MapReduce \\nis the enhancement of those existing ideas. As it is understood today, MapReduce is \\na fault-tolerant implementation and a runtime environment that scales to thousands \\nof processors. The programmer is spared the worry of handling failures. In sub-\\nsequent sections, we will abbreviate MapReduce as MR.\\nThe MapReduce Programming Model In the following description, we use the \\nformalism and description as it was originally described by Dean and Ghemawat \\n(2010).\\n12 The map and reduce functions have the following general form:\\nmap[K1,V1] which is (key, value) : List[K2,V2] and\\nreduce(K2, List[V2]) : List[K3,V3]\\nMap is a generic function that takes a key of type K1 and a value of type V1 and \\nreturns a list of key-value pairs of type K2 and V2. Reduce is a generic function that \\ntakes a key of type K2 and a list of values of type V2 and returns pairs of type \\n(K3,V3). In general, the types K1, K2, K3, etc., are different, with the only require-\\nment that the output types from the Map function must match the input type of the \\nReduce function.\\nThe basic execution workflow of MapReduce is shown in Figure 25.1.\\nAssume that we have a document and we want to make a list of words in it with \\ntheir corresponding frequencies. This ubiquitous word count  example quoted \\ndirectly from Dean and Ghemawat (2004) above goes as follows in pseudocode:\\nMap (String key, String value):\\nfor each word w in value Emitintermediate (w, “1”);\\nHere key is the document name, and value is the text content of the document.\\n12Jeffrey Dean and Sanjay Ghemawat, “MapReduce: Simplified Data Processing on Large Clusters,” in \\nOSDI (2004).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 932, 'page_label': '933'}, page_content='25.2 Introduction to MapReduce and Hadoop  919\\nThen the above lists of (word, 1) pairs are added up to output total counts of all \\nwords found in the document as follows:\\nReduce (String key, Iterator values) : // here the key is a word and values are \\nlists of its counts //\\n Int result =0;\\n For each v in values :\\n  result += Parseint (v);\\n Emit (key, Asstring (result));\\nThe above example in MapReduce programming appears as:\\nmap[LongWritable,Text](key, value) : List[Text, LongWritable] = {\\n String[] words = split(value)\\n for(word : words) {\\n  context.out(Text(word), LongWritable(1))\\n }\\n}\\nreduce[Text, Iterable[LongWritable]](key, values) : List[Text, LongWritable] = {\\n LongWritable c = 0\\n for( v : values) {\\n  c += v\\n }\\n context.out(key,c)\\n }\\nThe data types used in the above example are LongWritable and Text. Each \\nMapReduce job must register a Map and Reduce function. The Map function \\nreceives each key-value pair and on each call can output 0 or more key-value pairs. \\nThe signature of the Map function specifies the data types of its input and output \\nSplit 0 Map\\nSort\\nCopy\\nMerge\\nReduce Output\\nfile 0\\nOutput\\nInput\\nReduce\\nMerge\\nMap\\nMap\\nSplit 1\\nSplit 2\\nOutput\\nfile 1\\nFigure 25.1 \\nOverview of MapReduce \\nexecution. (Adapted \\nfrom T. White, 2012)'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 933, 'page_label': '934'}, page_content='920 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\nkey-value pairs. The Reduce function receives a key and an iterator of values asso-\\nciated with that key. It can output one or more key-value pairs on each invocation. \\nAgain, the signature of the Reduce function indicates the data types of its inputs \\nand outputs. The output type of the Map must match the input type of the Reduce \\nfunction. In the wordcount example, the map function receives each line as a \\nvalue, splits it into words, and emits (via the function context.out) a row for each \\nword with frequency 1. Each invocation of the Reduce function receives for a given \\nword the list of frequencies computed on the Map side. It adds these and emits \\neach word and its frequency as output. The functions interact with a context. The \\ncontext is used to interact with the framework. It is used by clients to send config-\\nuration information to tasks; and tasks can use it to get access to HDFS and read \\ndata directly from HDFS, to output key-value pairs, and to send status (e.g., task \\ncounters) back to the client.\\nThe MapReduce way of implementing some other functions based on Dean and \\nGhemawat (2004) is as follows:\\nDistributed Grep\\nGrep looks for a given pattern in a file. The Map function emits a line if it \\nmatches a supplied pattern. The Reduce function is an identity function that \\ncopies the supplied intermediate data to the output. This is an example of a \\nMap only task; there is no need to incur the cost of a Shuffle. We will provide \\nmore information when we explain the MapReduce runtime.\\nReverse Web-Link Graph\\nThe purpose here is to output (target URL, source URL) pairs for each link to a \\ntarget page found in a page named source. The Reduce function concatenates \\nthe list of all source URLs associated with a given target URL and emits the pair \\n<target, list(source)>.\\nInverted Index\\nThe purpose is to build an inverted index based on all words present in a docu-\\nment repository. The Map function parses each document and emits a sequence \\nof (word, document_id) pairs. The Reduce function takes all pairs for a given \\nword, sorts them by document_id and emits a (word, list (document_id)) pair. \\nThe set of all these pairs forms an inverted index.\\nThese illustrative applications give a sense of the MapReduce programming model’s \\nbroad applicability and the ease of expressing the application’s logic using the Map \\nand Reduce phases.\\nA Job in MapReduce comprises the code for the Map and Reduce (usually pack-\\naged as a jar) phases, a set of artifacts needed to run the tasks (such as files, other \\njars, and archives) and, most importantly, a set of properties specified in a configu-\\nration. There are hundreds of properties that can be specified, but the core ones are \\nas follows:\\n ■ the Map task\\n ■ the Reduce task'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 934, 'page_label': '935'}, page_content='25.3 Hadoop Distributed File System (HDFS)  921\\n ■ the Input that the Job is to run on: typically specified as an HDFS path(s)\\n ■ the Format(Structure) of the Input\\n ■ the Output path\\n ■ the Output Structure\\n ■ the Reduce-side parallelism\\nA Job is submitted to the JobTracker, which then schedules and manages the exe-\\ncution of the Job. It provides a set of interfaces to monitor running Jobs. See the \\nHadoop Wiki\\n13 for further details about the workings of the JobTracker.\\n25.2.3 Hadoop Releases\\nSince the advent of Hadoop as a new distributed framework to run MapReduce \\nprograms, various releases have been produced:\\nThe 1.x releases of Hadoop are a continuation of the original 0.20 code base. \\nSubreleases with this line have added Security, additional HDFS and MapReduce \\nimprovements to support HBase, a better MR programming model, as well as \\nother improvements.\\nThe 2.x releases include the following major features:\\n /box4YARN (Y et Another Resource Navigator) is a general resource manager \\nextracted out of the JobTracker from MR version1.\\n /box4A new MR runtime that runs on top of YARN.\\n /box4Improved HDFS that supports federation and increased availability.\\nAt the time of this writing, Hadoop 2.0 has been around for about a year. The \\nadoption is rapidly picking up; but a significant percentage of Hadoop deployments \\nstill run on Hadoop v1.\\n25.3 Hadoop Distributed File System (HDFS)\\nAs we said earlier, in addition to MapReduce, the other core component of Hadoop \\nis the underlying file system HDFS. In this section, we will first explain the architec-\\nture of HDFS, then describe the file input/output operations supported in HDFS, \\nand finally comment on the scalability of HDFS.\\n25.3.1 HDFS Preliminaries\\nThe Hadoop Distributed File System (HDFS) is the file system component of \\nHadoop and is designed to run on a cluster of commodity hardware. HDFS is pat-\\nterned after the UNIX file system; however, it relaxes a few POSIX (portable oper-\\nating system interface) requirements to enable streaming access to file system data. \\nHDFS provides high-throughput access to large datasets. HDFS stores file system \\n13Hadoop Wiki is at http://hadoop.apache.org/'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 935, 'page_label': '936'}, page_content='922 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\nmetadata and application data separately. Whereas the metadata is stored on a \\ndedicated server, called the NameNode, the application data is stored on other \\nservers, called DataNodes. All servers are fully connected and communicate with \\neach other using TCP-based protocols. To make data durable, the file content is \\nreplicated on multiple DataNodes, as in the Google File System. This not only \\nincreases reliability, but it also multiplies the bandwidth for data transfer and \\nenables colocation of computation with data. It was designed with the following \\nassumptions and goals:\\nHardware failure:  Using commodity hardware, failure of hardware is the \\nnorm rather than an exception. Therefore, with thousands of nodes, automatic \\ndetection and recovery from failures becomes a must.\\nBatch processing:  HDFS has been primarily designed for batch rather than \\ninteractive use. High throughput is emphasized over low latency of data access. \\nFull scans of files are typical.\\nLarge datasets: HDFS was designed to support huge files in the hundreds of \\ngigabytes to terabytes range.\\nSimple coherency model:  HDFS applications need a one writer and many \\nreader access models for files. File content cannot be updated, but only \\nappended. This model alleviates coherency issues among copies of data.\\n25.3.2 Architecture of HDFS\\nHDFS has a master-slave architecture. The master server, called the NameNode, \\nmanages the file system storage area or namespace ; Clients access the namespace \\nthrough the Namenode. The slaves called DataNodes run on a cluster of commod-\\nity machines, usually one per machine. They manage the storage attached to the \\nnode that they run on. The namespace itself comprises Files and Directories. The \\nNamenodes maintain inodes (index nodes) about File and Directories with attri-\\nbutes like ownership, permissions, creation and access times, and disk space quotas. \\nUsing inodes, the mapping of File blocks to DataNodes is determined. DataNodes \\nare responsible for serving read and write requests from clients. DataNodes per-\\nform block creation, deletion, and replication operations as instructed by the \\nNameNode. A cluster can have thousands of DataNodes and tens of thousands of \\nHDFS clients simultaneously connected.\\nTo read a file, a client first connects to the NameNode and obtains the locations of \\nthe data blocks in the file it wants to access; it then connects directly with the \\nDataNodes that house the blocks and reads the data.\\nThe architecture of HDFS has the following highlights:\\n  1. HDFS allows a decoupling of metadata from data operations. Metadata \\noperations are fast whereas data transfers are much slower. If the location \\nof metadata and transfer of data are not decoupled, speed suffers in a dis-\\ntributed environment because data transfer dominates and slows the \\nresponse.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 936, 'page_label': '937'}, page_content='25.3 Hadoop Distributed File System (HDFS)  923\\n  2. Replication is used to provide reliability and high availability. Each block is \\nreplicated (default is three copies) to a number of nodes in the cluster. The \\nhighly contentious files like MapReduce job libraries would have a higher \\nnumber of replicas to reduce network traffic.\\n  3. The network traffic is kept to a minimum. For reads, clients are directed to \\nthe closest DataNode. As far as possible, a local file system read is attempted \\nand involves no network traffic; the next choice is a copy on a node on the \\nsame rack before going to another rack. For writes, to reduce network band-\\nwidth utilization, the first copy is written to the same node as the client. For \\nother copies, travel across racks is minimized.\\nNameNode. The NameNode maintains an image of the file system comprising \\ni-nodes and corresponding block locations. Changes to the file system are main-\\ntained in a Write-ahead commit log (see the discussion of Write-ahead logs in \\nChapter 22) called the Journal. Checkpoints are taken for purposes of recovery; \\nthey represent a persistent record of the image without the dynamic information \\nrelated to the block placement. Block placement information is obtained from \\nthe DataNodes periodically as described below. During Restart, the image is \\nrestored to the last checkpoint and the journal entries are applied to that image. \\nA new checkpoint and empty journal are created so that the NameNode can start \\naccepting new client requests. The startup time of a NameNode is proportional \\nto the Journal file’s size. Merging the checkpoint with the Journal periodically \\nreduces restart time.\\nNote that with the above architecture, it is catastrophic to have any corruption of \\nthe Checkpoint or the Journal. To guard against corruption, both are written to \\nmultiple directories on different volumes.\\nSecondary NameNodes. These are additional NameNodes that can be created \\nto perform either the checkpointing role or a backup role. A Checkpoint node peri-\\nodically combines existing checkpoint and journal files. In backup mode, it acts like \\nanother storage location for the Journal for the primary NameNode. The backup \\nNameNode remains up-to-date with the file system and can take over on failure. In \\nHadoop V1, this takeover must be done manually.\\nDataNodes: Blocks are stored on a DataNode in the node’s native file system. The \\nNameNode directs clients to the DataNodes that contain a copy of the block they \\nwant to read. Each block has its representation in two files in the native file system: \\na file containing the data and a second file containing the metadata, which includes \\nthe checksums for the block data and the block’s generation stamp. DataNodes and \\nNameNodes do not communicate directly but via a so-called heartbeat mechanism, \\nwhich refers to a periodic reporting of the state by the DataNode to the NameNode; \\nthe report is called a Block Report. The report contains the block id, the generation \\nstamp, and the length for each block. The block locations are not part of the \\nnamespace image. They must be obtained from the block reports, and they change \\nas blocks are moved around. The MapReduce Job Tracker, along with the'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 937, 'page_label': '938'}, page_content='924 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\nNameNode, uses the latest block report information for scheduling purposes. In \\nresponse to a heartbeat from the DataNode, the NameNode sends one of the following \\ntypes of commands to the DataNode:\\n ■ Replicate a block to another node.\\n ■ Remove a block replica.\\n ■ Reregister the node or shut down the node.\\n ■ Send an immediate block report.\\n25.3.3 File I/O Operations and Replica Management in HDFS\\nHDFS provides a single-writer, multiple-reader model. Files cannot be updated, but \\nonly appended. A file consists of blocks. Data is written in 64-KB packets in a write \\npipeline, which is set up to minimize network utilization, as we described above. \\nData written to the last block becomes available only after an explicit hflush opera-\\ntion. Simultaneous reading by clients is possible while data is being written. A \\nchecksum is generated and stored for each block and is verified by the client to \\ndetect corruption of data. Upon detection of a corrupt block, the Namenode is noti-\\nfied; it initiates a process to replicate the block and instructs the Datanode to remove \\nthe corrupt block. During the read operation, an attempt is made to fetch a replica \\nfrom as close a node as possible by ordering the nodes in ascending order of dis-\\ntance from the client. A read fails when the Datanode is unavailable, when the \\nchecksum test fails, or when the replica is no longer on the Datanode. HDFS has \\nbeen optimized for batch processing similar to MapReduce.\\nBlock Placement. Nodes of a Hadoop cluster are typically spread across many \\nracks. They are normally organized such that nodes on a rack share a switch, and \\nrack switches are connected to a high-speed switch at the upper level. For example, \\nthe rack level may have a 1-Gb switch, whereas at the top level there may be a 10-Gb \\nswitch. HDFS estimates the network bandwidth between Datanodes based on their \\ndistance. Datanodes on the same physical node have a distance of 0, on the same \\nrack are distance 2 away, and on different racks are distance 4 away. The default \\nHDFS block placement policy balances between minimizing the write cost and \\nmaximizing data reliability and availability as well as aggregate read bandwidth. \\nNetwork bandwidth consumed is estimated based on distance among DataNodes. \\nThus, for DataNodes on the same physical node, the distance is 0, whereas on the \\nsame rack it is 2 and on a different rack it is 4. The ultimate goal of block placement \\nis to minimize the write cost while maximizing data availability and reliability as \\nwell as available bandwidth for reading. Replicas are managed so that there is at \\nleast one on the original node of the client that created it, and others are distributed \\namong other racks. Tasks are preferred to be run on nodes where the data resides; \\nthree replicas gives the scheduler enough leeway to place tasks where the data is.\\nReplica Management. Based on the block reports from the DataNodes, the \\nNameNode tracks the number of replicas and the location of each block. A replica-\\ntion priority queue contains blocks that need to be replicated. A background thread'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 938, 'page_label': '939'}, page_content='25.3 Hadoop Distributed File System (HDFS)  925\\nmonitors this queue and instructs a DataNode to create replicas and distribute \\nthem across racks. NameNode prefers to have as many different racks as possible to \\nhost replicas of a block. Overreplicated blocks cause some replicas to be removed \\nbased on space utilization of the DataNodes.\\n25.3.4 HDFS Scalability\\nSince we are discussing big data technologies in this chapter, it is apropos to discuss \\nsome limits of scalability in HDFS. Hadoop program management committee \\nmember Shvachko commented that the Yahoo HDFS cluster had achieved the fol-\\nlowing levels as opposed to the intended targets (Shvachko, 2010). The numbers in \\nparentheses are the targets he listed. Capacity: 14 petabytes (vs. 10 petabytes); num-\\nber of nodes: 4,000 (vs. 10,000); clients:15,000 (vs. 100,000); and files: 60 million \\n(vs.\\xa0100 million). Thus, Yahoo had come very close to its intended targets in 2010, \\nwith a smaller cluster of 4,000 nodes and fewer clients; but Yahoo had actually \\nexceeded the target with respect to total amount of data handled.\\nSome of the observations made by Shvachko (2010) are worth mentioning. They \\nare based on the HDFS configuration used at Yahoo in 2010. We present the actual \\nand estimated numbers below to give the reader a sense of what is involved in these \\ngigantic data processing environments.\\n ■ The blocksize used was 128K, and an average file contained 1.5 blocks. \\nNameNode used about 200 bytes per block and an additional 200 bytes for \\nan i-node. 100 million files referencing 200 million blocks would require \\nRAM capacity exceeding 60 GB.\\n ■ For 100 million files with size of 200 million blocks and a replication factor \\nof 3, the disk space required is 60 PB. Thus a rule of thumb was proposed \\nthat 1 GB of RAM in NameNode roughly corresponds to 1 PB of data stor-\\nage based on the assumption of 128K blocksize and 1.5 blocks per file.\\n ■ In order to hold 60 PB of data on a 10,000-node cluster, each node needs a \\ncapacity of 6 TB. This can be achieved by having eight 0.75-TB drives.\\n ■ The internal workload for the NameNode is block reports. About 3 reports \\nper second containing block information on 60K blocks per report were \\nreceived by the NameNode.\\n ■ The external load on the NameNode consisted of external connections and \\ntasks from MapReduce jobs. This resulted in tens of thousands of simultane-\\nous connections.\\n ■ The Client Read consisted of performing a block lookup to get block loca-\\ntions from the NameNode, followed by accessing the nearest replica of the \\nblock. A typical client (the Map job from an MR task) would read data from \\n1,000 files with an average reading of half a file each, amounting to 96 MB of \\ndata. This was estimated to take 1.45 seconds. At that rate, 100,000 clients \\nwould send 68,750 block-location requests per second to the NameNode. \\nThis was considered to be well within the capacity of the NameNode, which \\nwas rated at handling 126K requests per second.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 939, 'page_label': '940'}, page_content='926 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\n ■ The write workload: Given a write throughtput of 40 MB/sec, an average cli-\\nent writes 96 MB in 2.4 sec. That creates over 41K “create block” requests \\nfrom 100,000 nodes at the NameNode. This was considered far above the \\nNameNode capacity.\\nThe above analysis assumed that there was only one task per node. In reality, there \\ncould be multiple tasks per node as in the real system at Yahoo, which ran 4  MapReduce \\n(MR)tasks per node. The net result was a bottleneck at the NameNode. Issues such \\nas these have been handled in Hadoop v2, which we discuss in the next section.\\n25.3.5 The Hadoop Ecosystem\\nHadoop is best known for the MapReduce programming model, its runtime infrastruc-\\nture, and the Hadoop Distributed File System (HDFS). However, the Hadoop ecosys-\\ntem has a set of related projects that provide additional functionality on top of these core \\nprojects. Many of them are top-level open source Apache projects and have a very large \\ncontributing user community of their own. We list a few important ones here:\\nPig and Hive:  These provide a higher level interface for working with the \\nHadoop framework.\\n /box4Pig provides a dataflow language. A script written in PigScript translates \\ninto a directed acyclic graph (DAG) of MapReduce jobs.\\n /box4Hive provides an SQL interface on top of MapReduce. Hive’s SQL support \\nincludes most of the SQL-92 features and many of the advanced analytics \\nfeatures from later SQL standards. Hive also defines the SerDe (Serializa-\\ntion/ Deserialization) abstraction, which defines a way of modeling the \\nrecord structure on datasets in HDFS beyond just key-value pairs. We will \\ndiscuss both of these in detail in Section 25.4.4.\\nOozie: This is a service for scheduling and running workflows of Jobs; indi-\\nvidual steps can be MR jobs, Hive queries, Pig scripts, and so on.\\nSqoop: This is a library and a runtime environment for efficiently moving data \\nbetween relational databases and HDFS.\\nHBase: This is a column-oriented key-value store that uses HDFS as its under-\\nlying store. (See Chapter 24 for a more detailed discussion of HBase.) It sup-\\nports both batch processing using MR and key-based lookups. With proper \\ndesign of the key-value scheme, a variety of applications are implemented using \\nHBase. They include time series analysis, data warehousing, generation of \\ncubes and multi-dimensional lookups, and data streaming.\\n25.4 MapReduce: Additional Details\\nWe introduced the MapReduce paradigm in Section 25.2.2. We now elaborate further \\non it in terms of the MapReduce runtime. We discuss how the relational operation of \\njoin can be handled using MapReduce. We examine the high-level interfaces of Pig \\nand Hive. Finally, we discuss the advantages of the combined MapReduce/Hadoop.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 940, 'page_label': '941'}, page_content='25.4 MapReduce: Additional Details  927\\n25.4.1 MapReduce Runtime\\nThe purpose of this section is to give a broad overview of the MapReduce runtime \\nenvironment. For a detailed description, the reader is encouraged to consult White \\n(2012). MapReduce is a master-slave system that usually runs on the same cluster as \\nHDFS. Typically, medium to large Hadoop clusters consist of a two- or three-level \\narchitecture built with rack-mounted servers.\\nJobTracker. The master process is called the JobTracker. It is responsible for man-\\naging the life cycle of Jobs and scheduling Tasks on the cluster. It is responsible for:\\n ■ Job submission, initializing a Job, providing Job status and state to both cli-\\nents and TaskTrackers (the slaves), and Job completion.\\n ■ Scheduling Map and Reduce tasks on the cluster. It does this using a plug-\\ngable Scheduler.\\nTaskTracker. The slave process is called a TaskTracker. There is one running on \\nall Worker nodes  of the cluster. The Map-Reduce tasks run on Worker nodes. \\nTaskTracker daemons running on these nodes register with the JobTracker on \\nstartup. They run tasks that the JobTracker assigns to them. Tasks are run in a sepa-\\nrate process on the node; the life cycle of the process is managed by the TaskTracker. \\nThe TaskTracker creates the task process, monitors its execution, sends periodic \\nstatus heartbeats to the JobTracker, and under failure conditions can kill the pro-\\ncess at the request of the JobTracker. The TaskTracker provides services to the \\nTasks, the most important of which is the Shuffle, which we describe in a sub-\\nsection below.\\nA. Overall flow of a MapReduce Job\\nA MapReduce job goes through the processes of Job Submission, Job Initializa-\\ntion, Task Assignment, Task Execution, and finally Job Completion. The Job \\nTracker and Task Tracker we described above are both involved in these. We \\nbriefly review them below.\\nJob submission A client submits a Job to the JobTracker. The Job package con-\\ntains the executables (as a jar), any other components (files, jars archives) \\nneeded to execute the Job, and the InputSplits for the Job.\\nJob initialization The JobTracker accepts the Job and places it on a Job Queue. \\nBased on the input splits, it creates map tasks for each split. A number of reduce \\ntasks are created based on the Job configuration.\\nTask assignment The JobTracker’s scheduler assigns Task to the TaskTracker \\nfrom one of the running Jobs. In Hadoop v1, TaskTrackers have a fixed number of \\nslots for map tasks and for reduce tasks. The Scheduler takes the location informa-\\ntion of the input files into account when scheduling tasks on cluster nodes.\\nTask execution Once a task has been scheduled on a slot, the TaskTracker \\nmanages the execution of the task: making all Task artifacts available to the'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 941, 'page_label': '942'}, page_content='928 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\nTask process, launching the Task JVM, monitoring the process and coordinat-\\ning with the JobTracker to perform management operations like cleanup on \\nTask exit, and killing Tasks on failure conditions. The TaskTracker also pro-\\nvides the Shuffle Service to Tasks; we describe this when we discuss the Shuffle \\nProcedure below.\\nJob completion Once the last Task in a Job is completed, the JobTracker runs \\nthe Job cleanup task (which is used to clean up intermediate files in both HDFS \\nand the local file systems of TaskTrackers).\\nB. Fault Tolerance in MapReduce\\nThere are three kinds of failures: failure of the Task, failure of the TaskTracker, \\nand failure of the JobTracker.\\nTask failure This can occur if the Task code throws a Runtime exception, or if \\nthe Java Virtual Machine crashes unexpectedly. Another issue is when the Task-\\nTracker does not receive any updates from the Task process for a while (the time \\nperiod is configurable). In all these cases the TaskTracker notifies the JobTracker \\nthat the Task has failed. When the JobTracker is notified of the failure, it will \\nreschedule execution of the task.\\nTaskTracker failure A TaskTracker process may crash or become disconnected \\nfrom the JobTracker. Once the JobTracker marks a TaskTracker as failed, any \\nmap tasks completed by the TaskTracker are put back on the queue to be \\nrescheduled. Similarly, any map task or reduce task in progress on a failed Task-\\nTracker is also rescheduled.\\nJobTracker failure In Hadoop v1, JobTracker failure is not a recoverable failure. \\nThe JobTracker is a Single Point of Failure. The JobTracker has to be manually \\nrestarted. On restart all the running jobs have to be resubmitted. This is one of \\nthe drawbacks of Hadoop v1 that have been addressed by the next generation of \\nHadoop MapReduce called YARN.\\nSemantics in the presence of failure When the user-supplied map and reduce \\noperators are deterministic functions of their input values, the MapReduce sys-\\ntem produces the same output as would have been produced by a nonfaulting \\nsequential execution of the entire program. Each task writes its output to a pri-\\nvate task directory. If the JobTracker receives multiple completions for the same \\nTask, it ignores all but the first one. When a Job is completed, Task outputs are \\nmoved to the Job output directory.\\nC. The Shuffle Procedure\\nA key feature of the MapReduce (MR) programming model is that the reducers \\nget all the rows for a given key together. This is delivered by what is called the \\nMR shuffle. The shuffle is divided into the Map, Copy, and Reduce phases.\\nMap phase: When rows are processed in Map tasks, they are initially held in an \\nin-memory buffer, the size of which is configurable (the default is 100 MB). A'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 942, 'page_label': '943'}, page_content='25.4 MapReduce: Additional Details  929\\nbackground thread partitions the buffered rows based on the number of Reduc-\\ners in the job and the Partitioner. The Partitioner is a pluggable interface that is \\nasked to choose a Reducer for a given Key value and the number of reducers in \\nthe Job. The partitioned rows are sorted on their key values. They can further be \\nsorted on a provided Comparator so that rows with the same key have a stable \\nsort order. This is used for Joins to ensure that for rows with the same key value, \\nrows from the same table are bunched together. Another interface that can be \\nplugged in is the Combiner interface. This is used to reduce the number of rows \\noutput per key from a mapper and is done by applying a reduce operation on \\neach Mapper for all rows with the same key. During the Map phase, several \\niterations of partitioning, sorting, and combining may happen. The end result is \\na single local file per reducer that is sorted on the Key.\\nCopy phase: The Reducers pull their files from all the Mappers as they become \\navailable. These are provided by the JobTracker in Heartbeat responses. Each \\nMapper has a set of listener threads that service Reducer requests for these files.\\nReduce phase:  The Reducer reads all its files from the Mappers. All files are \\nmerged before streaming them to the Reduce function. There may be multiple \\nstages of merging, depending on how the Mapper files become available. The \\nReducer will avoid unnecessary merges; for example, the last N files will be \\nmerged as the rows are being streamed to the Reduce function.\\nD. Job Scheduling\\nThe JobTracker in MR 1.0 is responsible for scheduling work on cluster nodes. \\nClients’ submitted jobs are added to the Job Queue of the JobTracker. The initial \\nversions of Hadoop used a FIFO scheduler that scheduled jobs sequentially as \\nthey were submitted. At any given time, the cluster would run the tasks of a \\nsingle Job. This caused undue delays for short jobs like ad-hoc hive queries if \\nthey had to wait for long-running machine learning–type jobs. The wait times \\nwould exceed runtimes, and the throughput on the cluster would suffer. Addi-\\ntionally, the cluster also would remain underutilized. We briefly describe two \\nother types of schedulers, called the Fair Scheduler and Capacity Scheduler, that \\nalleviate this situation.\\nFair Scheduler: The goal of Fair Scheduler is to provide fast response time to \\nsmall jobs in a Hadoop shared cluster. For this scheduler, jobs are grouped into \\nPools. The capacity of the cluster is evenly shared among the Pools. At any given \\ntime the resources of the cluster are evenly divided among the Pools, thereby \\nutilizing the capacity of the cluster evenly. A typical way to set up Pools is to \\nassign each user a Pool and assign certain Pools a minimum number of slots.\\nCapacity Scheduler:  The Capacity Scheduler is geared to meet the needs of \\nlarge Enterprise customers. It is designed to allow multiple tenants to share \\nresources of a large Hadoop cluster by allocating resources in a timely manner \\nunder a given set of capacity constraints. In large enterprises, individual depart-\\nments are apprehensive of using one centralized Hadoop cluster for concerns'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 943, 'page_label': '944'}, page_content='930 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\nthat they may not be able to meet the service-level agreements (SLAs) of their \\napplications. The Capacity Scheduler is designed to give each tenant guarantees \\nabout cluster capacity using the following provisions:\\n /box4There is support for multiple queues, with hard and soft limits in terms of \\nfraction of resources.\\n /box4Access control lists (ACLs) are used that determine who can submit, view, \\nand modify the Jobs in a queue.\\n /box4Excess capacity is evenly distributed among active Queues.\\n /box4Tenants have usage limits; such limits prevent tenants from monopoliz-\\ning the cluster.\\n25.4.2 Example: Achieving Joins in MapReduce\\nTo understand the power and utility of the MapReduce programming model, it is \\ninstructive to consider the most important operation of relational algebra, called \\nJoin, which we introduced in Chapter 6. We discussed its use via SQL queries \\n(Chapters 7 and 8) and its optimization (Chapters 18 and 19). Let us consider the \\nproblem of joining two relations R(A, B)  with S(B, C)  with the join condition  \\nR.A = S.B . Assume both tables reside on HDFS. Here we list the many strategies \\nthat have been devised to do equi-joins in the MapReduce environment.\\nSort-Merge Join. The broadest strategy for performing a join is to utilize the Shuffle \\nto partition and sort the data and have the reducers merge and generate the output. \\nWe can set up an MR job that reads blocks from both tables in the Map phase. We \\nset up a Partitioner to hash partition rows from R and S on the value of the B  column. \\nThe key output from the Map phase includes a table tag. So the key has the form \\n(tag, (key)). In MR, we can configure a custom Sort for the Job’s shuffle; the custom \\nSort sorts the rows that have the same key. In this case, we Sort rows with the same \\nB value based on the tag. We give the smaller table a tag of 0 and the larger table a tag \\nof 1. So a reducer will see all rows with the same B value in the order: smaller table rows \\nfirst, then larger table rows. The Reducer can buffer smaller table rows; once it starts to \\nreceive large table rows, it can do an in-memory cross-product with the buffered small \\ntable rows to generate the join output. The cost of this strategy is dominated by the \\nshuffle cost, which will write and read each row multiple times.\\nMap-Side Hash Join. For the case when one of R or S is a small table that can be \\nloaded in the memory of each task, we can have the Map phase operate only on the \\nlarge table splits. Each Map task can read the entire small table and create an in-\\nmemory hash map based on B as the hash key. Then it can perform a hash join. This \\nis similar to Hash Joins in databases. The cost of this task is roughly the cost of read-\\ning the large table.\\nPartition Join. Assume that both R and S are stored in such a way that they are \\npartitioned on the join keys. Then all rows in each Split belong to a certain identifi-\\nable range of the domain of the join field, which is B in our example. Assume both \\nR and S are stored as p files. Suppose file (i) contains rows such that (Value B )mod'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 944, 'page_label': '945'}, page_content='25.4 MapReduce: Additional Details  931\\np = i. Then we only need to join the ith file of \\\\(R\\\\) R with the corresponding ith file \\nof S. One way to do this is to perform a variation of the Map-Side join we discussed \\nabove: have the Mapper handling the ith partition of the larger table read the ith \\npartition from the smaller table. This strategy can be expanded to work even when \\nthe two tables do not have the same number of partitions. It is sufficient for one to \\nbe a multiple of the other. For example, if table A is divided into two partitions and \\ntable B is divided into four partitions, then partition 1 from table A needs to join \\nwith partitions 1 and 3 of B, and partition 2 of A needs to join with partitions 2 and 4 \\nof B. The opportunity to perform Bucketed Join (see below) is also common: for \\nexample, assume R and S are outputs of previous sort-merge joins. The output of \\nthe sort-merge join is partitioned in the joining expressions. Further joining this \\ndataset allows us to avoid a shuffle.\\nBucket Joins. This is a combination of Map-Side and Partition Joins. In this case \\nonly one relation, say the right side relation, is Partitioned. We can then run Map-\\npers on the left side relation and perform a Map Join against each Partition from \\nthe right side.\\nN-Way Map-Side Joins. A join on R(A, B, C, D ), S(B, E ), and T(C, F) can be \\nachieved in one MR job provided the rows for a key for all small tables can be buffered \\nin memory. The join is typical in Data Warehouses (see Chapter 29), where R is a fact \\ntable and S and T are dimension tables whose keys are B and C, respectively. Typi-\\ncally, in a Data Warehouse query filters are specified on Dimensional Attributes. \\nHence each Map task has enough memory to hold the hash map of several small \\nDimensional tables. As Fact table rows are being read into the Map task, they can be \\nhash joined with all the dimensional tables that the Map task has read into memory.\\nSimple N-Way Joins. A join on R(A, B), S(B, C), and T(B, D) can be achieved in \\none MR job provided the rows for a key for all small tables can be buffered in mem-\\nory. Suppose R is a large table and S and T are relatively smaller tables. Then it is \\ntypically the case that for any given key value B, the number of rows in S or T will fit \\nin a Task’s memory. Then, by giving the large table the largest tag, it is easy to gen-\\neralize the Sort-Merge join to an N-way join where the joining expressions are the \\nsame. In a Reducer for a key value of B, the reducer will first receive the S rows, then \\nthe T rows, and finally the R rows. Since the assumption is that there aren’t a large \\nnumber of S and T rows, the reducer can cache them. As it receives R rows, it can do \\na cross product with the cached S and T rows and output the result of join.\\nIn addition to the above strategies for performing joins using the MapReduce para-\\ndigm, algorithms have been proposed for other types joins (e.g., the general multi-\\nway natural join with special cases of chain-join or star-join in data warehouses have \\nbeen shown to be handled as a single MR job).\\n14 Similarly, algorithms have been \\nproposed to deal with skew in the join attributes (e.g., in a sales fact table, certain \\ndays may have a disproportionate number of transactions). For joins on attributes \\nwith skew, a modified algorithm would let the Partitioner assign unique values to the \\n14See Afrati and Ullman (2010).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 945, 'page_label': '946'}, page_content='932 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\ndata having a large number of entries and let them be handled by Reduce tasks, \\nwhereas the rest of the values may undergo hash partitioning as usual.\\nThis discussion should provide the reader with a good sense of the many possibili-\\nties of implementing Join strategies on top of MapReduce. There are other factors \\naffecting performance, such as row versus columnar storage and pushing predicates \\ndown to storage handlers. These are beyond our scope of discussion here. Inter-\\nested readers will find ongoing research publications in this area that are similar to \\nAfrati and Ullman (2010).\\nThe purpose of this section is to highlight two major developments that have \\nimpacted the big data community by providing high-level interfaces on top of the \\ncore technology of Hadoop and MapReduce. We will give a brief overview of the \\nlanguage Pig Latin and the system Hive.\\nApache Pig. Pig\\n15 was a system that was designed at Yahoo Research to bridge the \\ngap between declarative-style interfaces such as SQL, which we studied in the con-\\ntext of the relational model, and the more rigid low-level procedural-style program-\\nming style required by MapReduce that we described in Section 25.2.2. Whereas it \\nis possible to express very complex analysis in MR, the user must express programs \\nas a one-input, two-stage (map and reduce) process. Furthermore, MR provides no \\nmethods for describing a complex data flow that applies a sequence of transforma-\\ntions on the input. There is no standard way to do common data transformation \\noperations like Projections, Filtering, Grouping, and Joining. We saw all these \\noperations being expressed declaratively in SQL in Chapters 7 and 8. However, \\nthere is a community of users and programmers that thinks more procedurally. So \\nthe developers of Pig invented the language Pig Latin to fill in the “sweet spot” \\nbetween SQL and MR. We show an example of a simple Group By query expressed \\nin Pig Latin in Olston et al. (2008):\\nThere is a table of urls: (url,category.pagerank).\\nWe wish to find, for categories having a large number of URLs, the average page-\\nrank of the high-pagerank URLs in that category. This requires a grouping of URLs \\nby category. The SQL query that expresses this requirement may look like:\\nSELECT category, AVG(pagerank)\\nFROM urls WHERE pagerank > 0.2\\nGROUP BY category HAVING COUNT(*) > 10**6\\nThe same query in Pig Latin is written as:\\ngood_urls = FILTER urls BY pagerank > 0.2;\\ngroups = GROUP good_urls BY category;\\nbig_groups = FILTER groups BY COUNT(good_urls)> 10**6;\\noutput =  FOREACH big_groups GENERATE \\ncategory, AVG(good_urls.pagerank);\\n15See Olston et al. (2008).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 946, 'page_label': '947'}, page_content='25.4 MapReduce: Additional Details  933\\nAs shown by this example, a Pigscript written using the scripting language Pig Latin \\nis a sequence of data transformation steps. On each step, a basic transformation like \\nFilter, Group By, or Projection is expressed. The script resembles a query plan for \\nthe SQL query similar to the plans we discussed in Chapter 19. The language sup-\\nports operating on nested data structures like JSON (Java Script Object Notation) \\nand XML. It has an extensive and extendible function library, and also an ability to \\nbind schema to data very late or not at all.\\nPig was designed to solve problems such as ad hoc analyses of Web logs and click-\\nstreams. The logs and clickstreams typically require custom processing at row level \\nas well as at an aggregate level. Pig accommodates user-defined functions (UDFs) \\nextensively. It also supports a nested data model with the following four types:\\nAtoms: Simple atomic values such as a number or a string\\nTuples: A sequence of fields, each of which can be of any permissible type\\nBag: A collection of tuples with possible duplicates\\nMap: A collection of data items where each item has a key that allows direct \\naccess to it\\nOlston et al. (2008) demonstrates interesting applications on logs using Pig. An \\nexample is analysis of activity logs for a search engine over any time period (day, \\nweek, month, etc.) to calculate frequency of search terms by a user’s geographic loca-\\ntion. Here the functions needed include mapping IP addresses to geo-locations and \\nusing n-gram extraction. Another application involves co-grouping search queries \\nof one period with those of another period in the past based on search terms.\\nPig was architected so that it could run on different execution environments. In \\nimplementing Pig, Pig Latin was compiled into physical plans that were translated \\ninto a series of MR jobs and run in Hadoop. Pig has been a useful tool for enhanc-\\ning programmers’ productivity in the Hadoop environment.\\n25.4.3 Apache Hive\\nHive was developed at Facebook 16 with a similar intent—to provide a higher level \\ninterface to Hadoop using SQL-like queries and to support the processing of aggre-\\ngate analytical queries that are typical in data warehouses (see Chapter 29). Hive \\nremains a primary interface for accessing data in Hadoop at Facebook; it has been \\nadopted widely in the open source community and is undergoing continuous \\nimprovements. Hive went beyond Pig Latin in that it provided not only a high-level \\nlanguage interface to Hadoop, but a layer that makes Hadoop look like a DBMS \\nwith DDL, metadata repository, JDBC/ODBC access, and an SQL compiler. The \\narchitecture and components of Hive are shown in Figure 25.2.\\nFigure 25.2 shows Apache Thrift as interface in Hive. Apache Thrift defines an \\nInterface Definition Language (IDL) and Communication Protocol used to develop \\n16See Thusoo et al. (2010).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 947, 'page_label': '948'}, page_content='934 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\nremote services. It comes with a runtime and code generation engine that can be \\nused to develop remote services in many languages, including Java, C++, Python, \\nand Ruby. Apache Thrift supports JSON-based and binary protocols; it supports \\nhttp, socket, and file transports.\\nThe Hive query language HiveQL includes a subset of SQL that includes all types of \\njoins, Group By operations, as well as useful functions related to primitive and com-\\nplex data types. We comment below on some of the highlights of the Hive system.\\nInterfacing with HDFS: \\n ■ Tables in Hive are linked to directories in HDFS. Users can define parti-\\ntions within tables. For example, a Web log table can be partitioned by day \\nand within day by the hour. Each partition level introduces a level of direc-\\ntories in HDFS. A table may also be stored as bucketed on a set of columns. \\nThis means that the stored data is physically partitioned by the column(s). \\nFor example, within an hour directory, the data may be bucketed by  Userid; \\nthis means that each hour’s data is stored in a set of files, each file rep-\\nresents a bucket of Users, and the bucket is based on the hashing of the \\nUserid column. Users can specify how many buckets the data should be \\ndivided into.\\n ■ The SerDe (Serialization/Deserialization) plugin architecture lets users \\nspecify how data in native file formats is exposed as rows to Hive SQL oper-\\nators. Hive comes with a rich set of SerDe functions and supported File \\nformats (e.g., CSV, JSON, SequenceFile); columnar formats (e.g., RCFile, \\nORCFile, Parquet); and support for Avro—another data serialization sys-\\ntem. The different StorageHandlers  expand on the SerDe mechanism to \\nallow pluggable behavior for how data is read/written and the ability to \\npush predicates  down to the Storage Handler for early evaluation. For \\nCommand Line\\nInterface (CLI)\\nHIVE\\nJDBC\\nThrift Interface\\nQuery Engine\\nParse Compile\\nODBC\\nMetadata\\nStore\\nOptimize Meta Data\\nService\\nHADOOP CLUSTER\\n(MAP REDUCE + HDFS)\\nExecute\\nFigure 25.2 \\nHive system architecture \\nand components.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 948, 'page_label': '949'}, page_content='25.4 MapReduce: Additional Details  935\\nexample, the JDBC StorageHandler allows a Hive user to define a table that \\nis in fact stored in some relational DBMS and accessed using the JDBC pro-\\ntocol (see Chapter 10) during query execution.\\nSupport of SQL and Optimizations in Hive: Hive incorporated the concepts of \\nLogical and Physical Optimizations similar to those used in optimization of SQL que-\\nries, which we discussed in Chapters 18 and 19. Early on, there was support for logical \\noptimizations such as pruning unneeded columns and pushing selection predicates \\ndown into the query tree. Physical optimizations of converting sort-merge joins to \\nMap-side joins based on user hints and data file sizes have also been incorporated. \\nHive started with support for a subset of SQL-92 that included SELECT, JOIN, \\nGROUP BY, and filters based on conditions in the WHERE clause. Hive users can \\nexpress complex SQL commands in Hive. Early in its development, Hive was able to \\nrun the 22 TPCH benchmark queries (Transaction Processing Performance Council \\nbenchmark for decision support), although with considerable manual rewriting.\\nSignificant strides have been made in language support and in optimizer and run-\\ntime techniques. Here is a sampling of those improvements:\\n ■ Hive SQL has added many analytic features of SQL, such as subquery predicates, \\nCommon Table expressions (this is the WITH clause in SQL that allows users to \\nname common subquery blocks and reference them multiple times in the query; \\nthese expressions can be considered query-level views), aggregates over a certain \\nwindow within the data, Rollups (which refer to higher aggregation levels), and \\nGrouping sets (this capability allows you to express multiple levels of aggrega-\\ntion in one Group By level). Consider, for example, Group By Grouping Sets \\n((year, month), (dayofweek)); this expresses aggregates both at the (Year, \\nMonth) level and also by DayOfWeek. A full set of SQL data types, including \\nvarchars, numeric types, and dates, is now supported. Hive also supports the \\ncommon Change Data Capture ETL flow via Insert and Update statements. In a \\nData Warehouse, the process of delivering slowly changing Dimensions (e.g., \\ncustomers in a Retail Data Warehouse) requires a complex dataflow of identi-\\nfying new and updated records in that Dimension. This is called the Change \\nData Capture (CDC) process. By adding Insert and Update statements in Hive, \\nit is possible to model and execute CDC processes in Hive SQL.\\n ■ Hive now has a greatly expanded set of DDLs for expressing grants and priv-\\nileges in terms of discretionary access control (see Section 30.2).\\n ■ Several standard database optimizations have been incorporated, including \\nPartition pruning, Join reordering, Index rewrite, and Reducing the number \\nof MR jobs. Very large tables, like Fact tables in Data Warehouses, are typi-\\ncally partitioned. Time is probably the most common attribute used for parti-\\ntioning. With HDFS being used as the storage layer, users tend to retain data \\nfor long time periods. But a typical Warehouse will only include the most cur-\\nrent time periods (e.g., the last quarter or current year). The time periods are \\nspecified as filters in the Query. Partition Pruning is the technique of extracting \\nrelevant predicates from the Query filters and translating them to a list of'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 949, 'page_label': '950'}, page_content='936 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\nTable partitions that need to be read. Obviously, this has a huge impact on \\nperformance and cluster utilization: Instead of scanning all partitions retained \\nfor the last N years, only the partitions from the last few weeks/months are \\nscanned. Work in progress includes collecting column- and table-level statis-\\ntics and generating plans based on a cost model that uses these statistics (simi-\\nlar to what we considered for RDBMSs in Chapter 19).\\n ■ Hive now supports Tez as a runtime environment that has significant advan-\\ntages over MR, including that there is no need to write to disk between jobs; \\nand there is no restriction on one-input, two-stage processes. There is also \\nactive work to support Hive on Spark, a new technology that we briefly \\nmention in Section 25.6.\\n25.4.4 Advantages of the Hadoop/MapReduce Technology\\nHadoop version 1 was optimized for batch processing on very large datasets. Vari-\\nous factors contribute to its success:\\n  1. The disk seek rate is a limiting factor when we deal with petabyte-level work-\\nloads. Seek is limited by the disk mechanical structure, whereas the transfer \\nspeed is an electronic feature and increasing steadily. (See Section 16.2 for a \\ndiscussion of disk drives.) The MapReduce model of scanning datasets in \\nparallel alleviates this situation. For instance, scanning a 100-TB dataset \\nsequentially using 1 machine at a rate of 50 Mbps will take about 24 days to \\ncomplete. On the other hand, scanning the same data using 1,000 machines \\nin parallel will just take 35 minutes. Hadoop recommends very large block \\nsizes, 64 MB or higher. So when scanning datasets, the percentage of time \\nspent on disk seeks is negligible. Unlimited disk seek rates combined with \\nprocessing large datasets in chunks and in parallel is what drives the scal-\\nability and speed of the MapReduce model.\\n  2. The MapReduce model allows handling of semistructured data and key-\\nvalue datasets more easily compared to traditional RDBMSs, which require \\na predefined schema. Files such as very large logfiles present a particular \\nproblem in RDBMSs because they need to be parsed in multiple ways before \\nthey can be analyzed.\\n  3. The MapReduce model has linear scalability in that resources can be added \\nto improve job latency and throughput in a linear fashion. The failure model \\nis simple, and individual failed jobs can be rerun without a major impact on \\nthe whole job.\\n25.5 Hadoop v2 alias YAR N\\nIn previous sections, we discussed Hadoop development in detail. Our discussion \\nincluded the core concepts of the MapReduce paradigm for programming and the \\nHDFS underlying storage infrastructure. We also discussed high-level interfaces \\nlike Pig and Hive that are making it possible to do SQL-like, high level data process-\\ning on top of the Hadoop framework. Now we turn our attention to subsequent \\ndevelopments, which are broadly called Hadoop v2 or MRv2 or YARN (Yet Another'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 950, 'page_label': '951'}, page_content='25.5 Hadoop v2 alias YARN  937\\nResource Negotiator). First, we point out the shortcomings of the Hadoop v1 plat-\\nform and the rationale behind YARN.\\n25.5.1 Rationale behind YARN\\nDespite the success of Hadoop v1, user experience with Hadoop v1 in enterprise \\napplications highlighted some shortcomings and suggested that an upgrade of \\nHadoop v1 might be necessary:\\n ■ As cluster sizes and the number of users grew, the JobTracker became a bot-\\ntleneck. It was always known to be the Single Point of Failure.\\n ■ With a static allocation of resources to map and reduce functions, utilization \\nof the cluster of nodes was less than desirable\\n ■ HDFS was regarded as a single storage system for data in the enterprise. \\nUsers wanted to run different types of applications that would not easily fit \\ninto the MR model. Users tended to get around this limitation by running \\nMap-only Jobs, but this only compounded scheduling and utilization issues.\\n ■ On large clusters, it became problematic to keep up with new open source \\nversions of Hadoop, which were released every few months.\\nThe above reasons explain the rationale for developing version 2 of Hadoop. Some \\nof the points mentioned in the previous list warrant a more detailed discussion, \\nwhich we provide next.\\nMultitenancy: Multitenancy refers to accommodating multiple tenants/users con-\\ncurrently so that they can share resources. As the cluster sizes grew and the number \\nof users increased, several communities of users shared the Hadoop cluster. At \\nYahoo, the original solution to this problem was Hadoop on Demand, which was \\nbased on the Torque resource manager and Maui scheduler. Users could set up a \\nseparate cluster for each Job or set of Jobs. This had several advantages:\\n ■ Each cluster could run its own version of Hadoop.\\n ■ JobTracker failures were isolated to a single cluster.\\n ■ Each user/organization could make independent decisions on the size and \\nconfiguration of its cluster depending on expected workloads.\\nBut Yahoo abandoned Hadoop on Demand for the following reasons:\\n ■ Resource allocation was not based on data locality. So most reads and writes \\nfrom HDFS were remote accesses, which negated one of the key benefits of \\nthe MR model of mostly local data accesses.\\n ■ The allocation of a cluster was static. This meant large parts of a cluster were \\nmostly idle:\\n /box4Within an MR job, the reduce slots were not usable during the Map phase \\nand the map slots were not usable during the Reduce phase. When using \\nhigher level languages like Pig and Hive, each script or query spawned \\nmultiple Jobs. Since cluster allocation was static, the maximum nodes \\nneeded in any Job had to be acquired upfront.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 951, 'page_label': '952'}, page_content='938 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\n /box4Even with the use of Fair or Capacity scheduling (see our discussion in \\nSection 25.4.2), dividing the cluster into fixed map and reduce slots meant \\nthe cluster was underutilized.\\n ■ The latency involved in acquiring a cluster was high—a cluster would be \\ngranted only when enough nodes were available. Users started extending the \\nlifetime of clusters and holding the clusters longer than they needed. This \\naffected cluster utilization negatively.\\nJobTracker Scalability. As the cluster sizes increased beyond 4,000 nodes, issues \\nwith memory management and locking made it difficult to enhance JobTracker to \\nhandle the workload. Multiple options were considered, such as holding data about \\nJobs in memory, limiting the number of tasks per Job, limiting the number of Jobs \\nsubmitted per user, and limiting the number of concurrently running jobs. None of \\nthese seemed to fully satisfy all users; JobTracker often ran out of memory.\\nA related issue concerned completed Jobs. Completed jobs were held in JobTracker \\nand took up memory. Many schemes attempted to reduce the number and memory \\nfootprint of completed Jobs. Eventually, a viable solution was to offload this func-\\ntion to a separate Job History daemon.\\nAs the number of TaskTrackers grew, the latencies for heartbeats (signals from \\nTaskTracker to JobTracker) were almost 200 ms. This meant that heartbeat intervals \\nfor TaskTrackers could be 40 seconds or more when there were more than 200 task \\ntrackers in the cluster. Efforts were made to fix this but were eventually abandoned.\\nJobTracker: Single Point of Failure. The recovery model of Hadoop v1 was \\nvery weak. A failure of JobTracker would bring down the entire cluster. In this \\nevent, the state of running Jobs was lost, and all jobs would have to be resubmitted \\nand JobTracker restarted. Efforts to make the information about completed jobs \\npersist did not succeed. A related issue was to deploy new versions of the software. \\nThis required scheduling a cluster downtime, which resulted in backlogs of jobs \\nand a subsequent strain on JobTracker upon restart.\\nMisuse of the MapReduce Programming Model. MR runtime was not a great \\nfit for iterative processing; this was particularly true for machine learning algo-\\nrithms in analytical workloads. Each iteration is treated as an MR job. Graph algo-\\nrithms are better expressed using a bulk synchronous parallel (BSP) model, which \\nuses message passing as opposed to the Map and Reduce primitives. Users got \\naround these impediments by inefficient alternatives such as implementing \\nmachine learning algorithms as long-running Map-only jobs. These types of jobs \\ninitially read data from HDFS and executed the first pass in parallel; but then \\nexchanged data with each other outside the control of the framework. Also, the \\nfault tolerance was lost. The JobTracker was not aware of how these jobs operated; \\nthis lack of awareness led to poor utilization and instability in the cluster.\\nResource Model Issues. In Hadoop v1, a node is divided into a fixed number of \\nMap and Reduce slots. This led to cluster underutilization because idle slots could'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 952, 'page_label': '953'}, page_content='25.5 Hadoop v2 alias YARN  939\\nnot be used. Jobs other than MR could not run easily on the nodes because the node \\ncapacity remained unpredictable.\\nThe aforementioned issues illustrate why Hadoop v1 needed upgrading. \\nAlthough attempts were made to fix in Hadoop v1 many of the issues listed \\nabove, it became clear that a redesign was needed. The goals of the new design \\nwere set as follows:\\n ■ To carry forward the scalibility and locality awareness of Hadoop v1.\\n ■ To have multitenancy and high cluster utilization.\\n ■ To have no single point of failure and to be highly available.\\n ■ To support more than just MapReduce jobs. The cluster resources should \\nnot be modeled as static map and reduce slots.\\n ■ To be backward compatible, so existing jobs should run as they are and pos-\\nsibly without any recompilation.\\nThe outcome of these was YARN or Hadoop v2, which we discuss in the next section.\\n25.5.2 YARN Architecture\\nOverview. Having provided the motivation behind upgrading Hadoop v1, we \\nnow discuss the detailed architecture of the next generation of Hadoop, which is \\npopularly known as MRv2, MapReduce 2.0, Hadoop v2, or YARN. 17 The central \\nidea of YARN is the separation of cluster Resource Management from Jobs man-\\nagement. Additionally, YARN introduces the notion of an ApplicationMaster , \\nwhich is now responsible for managing work (task data flows, task lifecycles, \\ntask failover, etc.). MapReduce is now available as a service/application provided \\nby the MapReduce ApplicationMaster . The implications of these two decisions \\nare far-reaching and are central to the notion of a data service operating system. \\nFigure 25.3 shows a high-level schematic diagram of Hadoop v1 and Hadoop v2 \\nside by side.\\nThe ResourceManager and the per worker node NodeManager together form the \\nplatform on which any Application can be hosted on YARN. The Resource Manager \\nmanages the cluster, doling out Resources based on a pluggable scheduling policy \\n(such as a fairness policy or optimizing cluster utilization policy). It is also respon-\\nsible for the lifecycle of nodes in the cluster in that it will track when nodes go \\ndown, when nodes become unreachable, or when new nodes join. Node failures are \\nreported to the ApplicationMasters that had containers on the failed node. New \\nnodes become available for use by ApplicationMasters.\\nApplicationMasters send ResourceRequests to the ResourceManager which then \\nresponds with cluster Container leases. A Container is a lease by the Resource-\\nManager to the ApplicationManager to use certain amount of resources on a node \\n17See the Apache website: http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/\\nYARN.html for up-to-date documentation on YARN.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 953, 'page_label': '954'}, page_content='940 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\nof the cluster. The ApplicationMaster presents a Container Launch Context to the \\nNodeManager for the node that this lease references. The Launch Context, in \\naddition to containing the lease, also specifies how to run the process for the task \\nand how to get any resources like jars, libs for the process, environment variables, \\nand security tokens. A node has a certain processing power in terms of number of \\ncores, memory, network bandwidth, etc. Currently, YARN only considers mem-\\nory. Based on its processing power, a node can be divided into an interchangeable \\nset of containers. Once an ApplicationMaster receives a container lease, it is free to \\nschedule work on it as it pleases. ApplicationMasters, based on their workload, can \\ncontinuously change their Resource requirements. The ResourceManager bases its \\nscheduling decisions purely on these requests, on the state of the cluster, and on \\nthe cluster’s scheduling policy. It is not aware of the actual tasks being carried out \\non the nodes. The responsibility of managing and analyzing the actual work is left \\nto ApplicationMasters.\\nThe NodeManager is responsible for managing Containers on their nodes. Con-\\ntainers are responsible for reporting on the node health. They also handle the pro-\\ncedure for nodes joining the cluster. Containers provide the Container Launch \\nservice to ApplicationMasters. Other services available include a Local cache, which \\ncould be User level, Application level, or Container level. Containers also can be \\nconfigured to provide other services to Tasks running on them. For example, for \\nMR tasks, the shuffle is now provided as a Node-level service.\\nThe ApplicationMaster is now responsible for running jobs on the cluster. Based on \\ntheir job(s) the clusters negotiate for Resources with the ResourceManager. The \\nApplicationMaster  itself runs on the cluster; at startup time a client submits an \\nApplication to the ResourceManager, which then allocates a container for the \\nApplicationMaster and launches it in that container. In the case of MR, the \\n ApplicationMaster takes over most of the tasks of the JobTracker: it launches Map \\nand Reduce tasks, makes decisions on their placement, manages failover of tasks, \\nmaintains counters similar to Job state counters, and provides a monitoring inter-\\nface for running Jobs. The management and interface for completed jobs has been \\nmoved to a separate Job History Server.\\nHadoop  v1\\nHDFS\\nMap Reduce\\nCluster\\nResource Management\\n+\\nJob Management\\nPig Hive\\nHadoop  v2\\nHDFS\\nMap Reduce\\nApplication Mstr\\nYAR N\\nRESOURCE MANAGEMENT\\nTez\\nApplication Mstr\\nPig Hive\\nFigure 25.3 \\nThe Hadoop v1 vs. \\nHadoop v2 \\n schematic.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 954, 'page_label': '955'}, page_content='25.5 Hadoop v2 alias YARN  941\\nThe following advantages accrue from the separation of Resource Management \\nfrom Application Management in the YARN architecture:\\n ■ A rich diversity of Data Services is available to utilize the cluster. Each of \\nthese can expose its own programming model.\\n ■ Application Masters are free to negotiate resources in patterns that are opti-\\nmized for their work: for example, machine learning Apps may hold Con-\\ntainers for long durations.\\n ■ The Resource and Container model allows nodes to be utilized in a dynamic \\nmanner, which increases the overall utilization of the cluster.\\n ■ The ResourceManager does only one thing—manage resources; hence it is \\nhighly scalable to tens of thousands of nodes.\\n ■ With ApplicationMasters managing Jobs, it is possible to have multiple ver-\\nsions of an Application running on the cluster. There is no need for a global \\ncluster update, which would require that all Jobs be stopped.\\nFailure of an ApplicationMaster affects only Jobs managed by it. The Resource-\\nManager provides some degree of management of ApplicationMasters. Let us \\nbriefly consider each of the components of the YARN environment.\\nResource Manager (RM). The Resource Manager is only concerned with allo-\\ncating resources to Applications, and not with optimizing the processing within \\nApplications. The policy of resource allocation is pluggable. Application Masters \\nare supposed to request resources that would optimize their workload.\\nThe Resource Manager exposes the following interfaces:\\n  1. An API for clients to start ApplicationMasters\\n  2. A protocol for ApplicationMasters to negotiate for cluster resources\\n  3. A protocol for NodeManagers to report on node resources and be managed \\nby the Resource Manager\\nThe scheduler in the ResourceManager matches the Resource Requirements sub-\\nmitted by Applications against the global state of the cluster resources. The alloca-\\ntion is based on the policies of the pluggable Scheduler (such as capacity or fairness). \\nResources are requested by ApplicationMasters as Resource Requests. A Resource \\nRequest specifies:\\n ■ The number of containers needed\\n ■ The physical resources (CPU, memory) needed per container\\n ■ The locality preferences (physical node, rack) of the containers\\n ■ The priority of the request for the Application\\nThe scheduler satisfies these requests based on the state of the cluster as reported by \\nthe NodeManager heartbeats. The locality and priority guides the scheduler toward \\nalternatives: for example, if a requested node is busy, the next best alternative is \\nanother node on the same rack.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 955, 'page_label': '956'}, page_content='942 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\nThe scheduler also has the ability to request resources back from an Application if \\nneeded and can even take back the resources forcibly. Applications, in returning a \\ncontainer, can migrate the work to another container, or checkpoint the state and \\nrestore it on another container. It is important to point out what the Resource man-\\nager is not responsible for: handling the execution of tasks within an application, \\nproviding any status information about applications, providing history of finished \\njobs, and providing any recovery for failed tasks.\\nApplicationMaster (AM). The ApplicationMaster is responsible for coordinating \\nthe execution of an Application on the cluster. An Application can be a set of pro-\\ncesses like an MR Job, or it can be a long-running service like a Hadoop on demand \\n(HOD) cluster serving multiple MR jobs. This is left to the Application Writer.\\nThe ApplicationMaster will periodically notify the ResourceManager of its current \\nResource Requirements through a heartbeat mechanism. Resources are handed to \\nthe ApplicationMaster as Container leases. Resources used by an Application are \\ndynamic: they are based on the progress of the application and the state of the clus-\\nter. Consider an example: the MR ApplicationMaster running an MR job will ask \\nfor a container on each of the m nodes where an InputSplit resides. If it gets a con-\\ntainer on one of the nodes, the ApplicationMaster will either remove the request for \\ncontainers on the rest of the m-1 nodes or at least reduce their priority. On the \\nother hand, if the map task fails, it is AM that tracks this failure and requests con-\\ntainers on other nodes that have a replica of the same InputSplit.\\nNodeManager. A NodeManager runs on every worker node of the cluster. It \\n manages Containers and provides pluggable services for Containers. Based on a \\ndetailed Container Launch Context specification, a NodeManager can launch a pro-\\ncess on its node with the environment and local directories set up. It also monitors to \\nmake sure the resource utilization does not exceed specifications. It also periodically \\nreports on the state of the Containers and the node health. A NodeManager provides \\nlocal services to all Containers running on it. The Log Aggregation service is used to \\nupload each task’s standard output and standard error (stdout and stderr) to HDFS. \\nA NodeManager may be configured to run a set of pluggable auxillary services. For \\nexample, the MR Shuffle is provided as a NodeManager service. A Container run-\\nning a Map task produces the Map output and writes to local disk.The output is \\nmade available to Reducers of the Job via the Shuffle service running on the Node.\\nFault tolerance and availability. The RM remains the single point of failure in \\nYARN. On restart, the RM can recover its state from a persistent store. It kills all \\ncontainers in the cluster and restarts each ApplicationMaster. There is currently a \\npush to provide an active/passive mode for RMs. The failure of an Application-\\nMaster is not a catastrophic event; it only affects one Application. It is responsible \\nfor recovering the state of its Application. For example, the MR ApplicationMaster \\nwill recover its completed task and rerun any running tasks.\\nFailure of a Container because of issues with the Node or because of Application \\ncode is tracked by the framework and reported to the ApplicationMaster. It is the \\nresponsibility of the ApplicationMaster to recover from the failure.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 956, 'page_label': '957'}, page_content='25.5 Hadoop v2 alias YARN  943\\n25.5.3 Other Frameworks on YARN\\nThe YARN architecture described above has made it possible for other application \\nframeworks to be developed as well as other programming models to be supported \\nthat can provide additional services on the shared Hadoop cluster. Here we list \\nsome of the Frameworks that have become available in YARN at the time this text \\nwas written.\\nApache Tez. Tez is an extensible framework being developed at Hortonworks for \\nbuilding high-performance applications in YARN; these applications will handle \\nlarge datasets up to petabytes. Tez allows users to express their workflow as a \\ndirected acyclic graph (DAG) of tasks. Jobs are modeled as DAGs, where Vertices \\nare tasks or operations and Edges represent interoperation dependencies or flows \\nof data. Tez supports the standard dataflow patterns like pipeline, scatter-gather, \\nand broadcast. Users can specify the concurrency in a DAG, as well as the failover \\ncharacteristics, such as whether to store task output in persistent storage or to \\nrecompute it. The DAG can be changed at runtime based on job and cluster state. \\nThe DAG model is a more natural fit (than executing as one or more MapReduce \\njobs) for Pig scripts and SQL physical plans. Both Hive and Pig now provide a mode \\nin which they run on Tez. Both have benefitted in terms of simpler plans and sig-\\nnificant performance improvements. An often cited performance optimization is \\nthe Map-Reduce-Reduce pattern; an SQL query that has a Join followed by a Group-\\nBy normally is translated to two MR jobs: one for the Join and one for the Group-\\nBy. In the first MR stage, the output of the join will be written to HDFS and read \\nback in the Map phase of the second MR for the Group-By Job. In Tez, this extra \\nwrite and read to/from HDFS can be avoided by having the Join Vertex of the DAG \\nstream resulting rows to the Group-By Vertex.\\nApache Giraph. Apache Giraph is the open source implementation of Google’s \\nPregel system,\\n18 which was a large-scale graph processing system used to calculate \\nPage-Rank. (See Section 27.7.3 for a definition of Page-Rank.) Pregel was based on \\nthe bulk synchronous processing (BSP) model of computation.\\n19 Giraph added sev-\\neral features to Pregel, including sharded aggregators (sharding, as defined in \\nChapter 24, refers to a form of partitioning) and edge-oriented input. The Hadoop \\nv1 version of Giraph ran as MR jobs, which was not a very good fit. It did this by \\nrunning long-running Map-only Jobs. On YARN, the Giraph implementation \\nexposes an iterative processing model. Giraph is currently used at Facebook to ana-\\nlyze the social network users’ graph, which has users as nodes and their connections \\nas edges; the current number of users is approximately 1.3 billion.\\nHoya: HBase on YARN. The Hortonworks Hoya (HBase on YARN) project pro-\\nvides for elastic HBase clusters running on YARN with the goal of more flexibility \\nand improved utilization of the cluster. We discussed HBase in Section 24.5 as a \\n18Pregel is described in Malewicz et al. (2010).\\n19BSP is a model for designing parallel algorithms and was originally proposed by Valiant (1990).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 957, 'page_label': '958'}, page_content='944 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\ndistributed, open source, nonrelational database that manages tables with billions of \\nrows and millions of columns. HBase is patterned after BigTable from Google20 but is \\nimplemented using Hadoop and HDFS. Hoya is being developed to address the need \\nfor creating on-demand clusters of HBase, with possibly different versions of HBase \\nrunning on the same cluster. Each of the HBase instances can be individually config-\\nured. The Hoya ApplicationMaster launches the HBase Master locally. The Hoya AM \\nalso asks the YARN RM for a set of containers to launch HBase RegionServers on the \\ncluster. HBase RegionServers are the worker processes of Hbase; each ColumnFamily \\n(which is like a set of Columns in a relational table) is distributed across a set of \\nRegionServers. This can be used to start one or more HBase instances on the cluster, \\non demand. The clusters are elastic and can grow or shrink based on demand.\\nThe above three examples of the applications developed on YARN should give \\nthe\\xa0reader a sense of the possibilities that have been opened up by the decoupling \\nof\\xa0 Resource Management from Application Management in the overall  \\nHadoop/MapReduce architecture by YARN.\\n25.6 General Discussion\\nSo far, we have discussed the big data technology development that has occurred \\nroughly in the 2004–2014 time frame, and we have emphasized Hadoop v1 and \\nYARN (also referred to as Hadoop v2 or MRv2). In this section, we must first state \\nthe following disclaimer: there are a number of ongoing projects under Apache open \\nsource banner as well as in companies devoted to developing products in this area \\n(e.g., Hortonworks, Cloudera, MapR) as well as many private startup companies. \\nSimilarly, the Amplab at University of California and other academic institutions are \\ncontributing heavily to developing technology that we have not been able to cover in \\ndetail. There is also a series of issues associated with the cloud concept, with running \\nMapReduce in the cloud environment, and with data warehousing in the cloud that \\nwe have not discussed. Given this background, we now cover a few general topics \\nthat are worth mentioning in the context of the elaborate descriptions we presented \\nso far in this chapter. We present issues related to the tussle between the traditional \\napproach to high performance applications in parallel RDBMS implementations vis-\\nà-vis Hadoop- and YARN-based technologies. Then we present a few points related \\nto how big data and cloud technologies will be complementary in nature. We outline \\nissues related to the locality of data and the optimization issues inherent in the stor-\\nage clouds and the compute clouds. We also discuss YARN as a data services plat-\\nform and the ongoing movement to harness big data for analytics. Finally, we present \\nsome current challenges facing the entire big data movement.\\n25.6.1 Hadoop/MapReduce vs. Parallel RDBMS\\nA team of data experts, including Abadi, DeWitt, Madden, and Stonebracker, have \\ndone a methodological study comparing a couple of parallel database systems with \\n20BigTable is described in Chang et al. (2006).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 958, 'page_label': '959'}, page_content='25.6 General Discussion  945\\nthe open source version of Hadoop/MR (see, for example, Pavlo et al. (2009)). \\nThese experts measure the performance of these two approaches on the same \\nbenchmark using a 100-node cluster. They admit that the parallel database took \\nlonger to load and tune compared to MR, but the performance of parallel DBMSs \\nwas “strikingly better.” We list the areas the experts compared in the study and \\nattempt to show the progress made in both DBMSs and Hadoop since then.\\nPerformance. In their paper, Pavlo et al. concluded that parallel DBMSs were \\nthree to six times faster than MR. The paper lists many reasons why the DBMSs \\ngave better performance. Among the reasons given are the following: (i) indexing \\nwith B\\n+-trees, which expedites selection and filtering; (ii) novel storage orientation \\n(e.g., column-based storage has certain advantages); (iii) techniques that allow \\noperations on compressed data directly; and (iv) parallel query optimization tech-\\nniques common in parallel DBMSs.\\nSince the time of Pavlo et al.’s comparison, which involved Hadoop version 0.19, \\nhuge strides have been made in the MR runtime, the storage formats, and the plan-\\nning capabilities for job scheduling and for optimizing complex data flows in the \\nHadoop ecosystem. ORC and Parquet file formats are sophisticated Columnar file \\nformats that have the same aggressive compression techniques, the ability to push \\npredicates to the storage layer, and the ability to answer aggregate queries without \\nscanning data. We will briefly talk about the improvements in HDFS and MR; \\nApache Hive has made huge strides in both the runtime and Cost-based optimiza-\\ntions of complex SQLs. In their move to transform Hadoop from batch into real-\\ntime and interactive query mode, Hortonworks (2014) reports orders-of-magnitude \\ngains in performance of queries on a TPC-DS (decision support )–style bench-\\nmark. Cloudera’s Impala product, as reported in Cloudera (2014), uses Parquet \\n(the open source columnar data format) and is claimed to perform comparably to \\ntraditional RDBMSs.\\nUpfront Cost advantage. Hadoop has maintained its cost advantage. With few \\nexceptions, Hadoop continues to be primarily an open source platform. YARN, \\nHive, and Spark are all developed as Apache projects and are available as freely \\ndownloadable packages.\\nHandling Unstructured/Semistructured data. MR reads data by applying the \\nschema definition to it; doing so allows it to handle semistructured datasets like \\nCSVS, JSON, and XML documents. The loading process is relatively inexpensive \\nfor the Hadoop/MR systems. However, the support for unstructured data is defi-\\nnitely on the rise in RDBMSs. PostgreSQL now supports key-value stores and json; \\nmost RDBMSs have a support for XML. On the other hand, one of the reasons for \\nthe performance gains on the Hadoop side has been the use of specialized data for-\\nmats like ORC (Optimized Row Columnar) and Parquet (another open source \\ncolumnar format). The latter may not remain a strongly differentiating feature \\namong RDBMSs and Hadoop-based systems for too long because RDBMSs may \\nalso incorporate special data formats.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 959, 'page_label': '960'}, page_content='946 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\nHigher level language support. SQL was a distinguishing feature that was in \\nfavor for RDBMSs for writing complex analytical queries. However, Hive has \\nincorporated a large number of SQL features in HiveQL, including grouping and \\naggregation as well as nested subqueries and multiple functions that are useful in \\ndata warehouses, as we discussed previously. Hive 0.13 is able to execute about 50 \\nqueries from the TPC-DS benchmark without any manual rewriting. New machine \\nlearning–oriented function libraries are emerging (e.g., the function library at \\nmadlib.net supports traditional RDBMSs like PostgreSql as well as the Pivotal dis-\\ntribution of Hadoop database (PHD)). Pivotal’s HAWQ claims to be the latest and \\nmost powerful parallel SQL engine combining the advantages of SQL and Hadoop. \\nFurthermore, the YARN plugin architecture that we discussed simplifies the pro-\\ncess of extending the fabric with new components and new functions. Pig and \\nHive have extendibility with UDFs (user-defined functions). Several data services \\nare now available on YARN, such as Revolution R and Apache Mahout for machine \\nlearning and Giraph for graph processing. Many traditional DBMSs now run on \\nthe YARN platform; for example, the Vortex analytic platform from Actian\\n21 and \\nBigSQL 3.0 from IBM.22\\nFault tolerance. Fault tolerance remains a decided advantage of MR-based sys-\\ntems. The panel of authors in Pavlo et al. (2009) also acknowledged that “MR does \\na superior job of minimizing the amount of work lost when a hardware failure \\noccurs.” As pointed out by these authors, this capability comes at the cost of mate-\\nrializing intermediate files between Map and Reduce phases. But as Hadoop begins \\nto handle very complex data flows (such as in Apache Tez) and as the need for \\nlatencies decreases, users can trade off performance for fault tolerance. For exam-\\nple, in Apache Spark one can configure an intermediate Resilient Distributed \\nDataset (RDD)\\n23 to be either materialized on disk or in memory, or even to be \\nrecomputed from its input.\\nAs we can see from this discussion, even though MR started with a goal of sup-\\nporting batch-oriented workloads, it could not keep up with traditional parallel \\nRDBMSs in terms of interactive query workloads, as exemplified by Pavlo et al. \\n(2009). However, the two camps have moved much closer to each other in capa-\\nbilities. Market forces, such as the need for venture capital for new startups, require \\nan SQL engine for new applications that largely deal with very large semistruc-\\ntured datasets; and the research community’s interest and involvement have \\nbrought about substantial improvements in Hadoop’s capability to handle tradi-\\ntional analytical workloads. But there is still significant catching up to be done in \\nall the areas pointed out in Pavlo et al. (2009): runtime, planning and optimiza-\\ntion, and analytic feature-sets.\\n21See http://www.actian.com/about-us/blog/sql-hadoop-real-deal/ for a current description.\\n22See Presentation at http://www.slideshare.net/Hadoop_Summit/w-325p230-azubirigrayatv4 for a \\ncurrent description.\\n23See Zaharia et al. (2012).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 960, 'page_label': '961'}, page_content='25.6 General Discussion  947\\n25.6.2 Big Data in Cloud Computing\\nThe cloud computing movement and the big data movement have been proceeding \\nconcurrently for more than a decade. It is not possible to address the details of \\ncloud computing issues in the present context. However, we state some compelling \\nreasons why big data technology is in some sense dependent on cloud technology \\nnot only for its further expansion, but for its continued existence.\\n ■ The cloud model affords a high degree of flexibility in terms of management \\nof resources: “scaling out,” which refers to adding more nodes or resources; \\n“scaling up,” which refers to adding more resources to a node in the system; \\nor even downgrading are easily handled almost instantaneously.\\n ■ The resources are interchangeable; this fact, coupled with the design of dis-\\ntributed software, creates a good ecosystem where failure can be absorbed \\neasily and where virtual computing instances can be left unperturbed. For \\nthe cost of a few hundred dollars, it is possible to perform data mining oper-\\nations that involve complete scans of terabyte databases, and to crawl huge \\nWeb sites that contain millions of pages.\\n ■ It is not uncommon for big data projects to exhibit unpredictable or peak \\ncomputing power and storage needs. These projects are faced with the chal-\\nlenge of providing for this peak demand on an as-needed and not necessar-\\nily continuous basis. At the same time, business stakeholders expect swift, \\ninexpensive, and dependable products and project outcomes. To meet with \\nthese conflicting requirements, cloud services offer an ideal solution.\\n ■ A common situation in which cloud services and big data go hand-in-hand \\nis as follows: Data is transferred to or collected in a cloud data storage sys-\\ntem, like Amazon’s S3, for the purpose of collecting log files or exporting \\ntext-formatted data. Alternatively, database adapters can be utilized to \\naccess data from databases in the cloud. Data processing frameworks like \\nPig, Hive, and MapReduce, which we described above in Section 25.4, are \\nused to analyze raw data (which may have originated in the cloud).\\n ■ Big data projects and startup companies benefit a great deal from using a \\ncloud storage service. They can trade capital expenditure for operational \\nexpenditure; this is an excellent trade because it requires no capital outlay or \\nrisk. Cloud storage provides reliable and scalable storage solutions of a qual-\\nity otherwise unachievable.\\n ■ Cloud services and resources are globally distributed. They ensure high avail-\\nability and durability unattainable by most but the largest organizations.\\nThe Netflix Case for Marrying Cloud and Big Data. 24 Netflix is a large orga-\\nnization characterized by a very profitable business model and an extremely inex-\\npensive and reliable service for consumers. Netflix provides video streaming \\nservices to millions of customers today thanks to a highly efficient information \\n24Based on http://techblog.netflix.com/2013/01/hadoop-platform-as-service-in-cloud.html'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 961, 'page_label': '962'}, page_content='948 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\nsystem and data warehouse. Netflix uses Amazon S3 rather than HDFS as the data \\nprocessing and analysis platform for several reasons. Netflix presently uses Ama-\\nzon’s Elastic MapReduce (EMR) distribution of Hadoop. Netflix cites the main \\nreason for its choice as the following: S3 is designed for 99.999999999% durability \\nand 99.99% availability of objects over a given year, and S3 can sustain concurrent \\nloss of data in two facilities. S3 provides bucket versioning, which allows Netflix to \\nrecover inadvertently deleted data. The elasticity of S3 has allowed Netflix a practi-\\ncally unlimited storage capacity; this capacity has enabled Netflix to grow its storage \\nfrom a few hundred terabytes to petabytes without any difficulty or prior planning. \\nUsing S3 as the data warehouse enables Netflix to run multiple Hadoop clusters that \\nare fault-tolerant and can sustain excess load. Netflix executives claim that they have \\nno concerns about data redistribution or loss during expansion or shrinking of the \\nwarehouse. Although Netflix’s production and query clusters are long-running clus-\\nters in the cloud, they can be essentially treated as completely transient. If a cluster \\ngoes down, Netflix can simply substitute with another identically sized cluster, pos-\\nsibly in a different geographic zone, in a few minutes and not sustain any data loss.\\n25.6.3  Data Locality Issues and Resource Optimization  \\nfor Big Data Applications in a Cloud\\nThe increasing interest in cloud computing combined with the demands of big data \\ntechnology means that data centers must be increasingly cost-effective and con-\\nsumer-driven. Also, many cloud infrastructures are not intrinsically designed to \\nhandle the scale of data required for present-day data analytics. Cloud service pro-\\nviders are faced with daunting challenges in terms of resource management and \\ncapacity planning to provide for big data technology applications.\\nThe network load of many big data applications, including Hadoop/MapReduce, is of \\nspecial concern in a data center because large amounts of data can be generated dur-\\ning job execution. For instance, in a MapReduce job, each reduce task needs to read \\nthe output of all map tasks, and a sudden explosion of network traffic can signifi-\\ncantly deteriorate cloud performance. Also, when data is located in one infrastructure \\n(say, in a storage cloud like Amazon S3) and processed in a compute cloud (such as \\nAmazon EC2), job performance suffers significant delays due to data loading.\\nResearch projects have proposed\\n25 a self-configurable, locality-based data and vir-\\ntual machine management framework based on the storage-compute model. This \\nframework enables MapReduce jobs to access most of their data either locally or \\nfrom close-by nodes, including all input, output, and intermediate data generated \\nduring map and reduce phases of the jobs. Such frameworks categorize jobs using a \\ndata-size sensitive classifier into four classes based on a data size–based footprint. \\nThen they provision virtual MapReduce clusters in a locality-aware manner, which \\nenables efficient pairing and allocation of MapReduce virtual machines (VMs) to \\nreduce the network distance between storage and compute nodes for both map and \\nreduce processing.\\n25See Palanisamy et al. (2011).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 962, 'page_label': '963'}, page_content='25.6 General Discussion  949\\nRecently, caching techniques have been shown to improve the performance of \\nMapReduce jobs for various workloads. 26 The PACMan framework provides sup-\\nport for in-memory caching, and the MixApart system provides support for disk-\\nbased caching when the data is stored in an enterprise storage server within the \\nsame site. Caching techniques allow flexibility in that data is stored in a separate \\nstorage infrastructure that allows prefetching and caching of the most essential \\ndata. Recent work\\n27 has addressed the big data caching problem in the context of \\nprivacy-conscious scenarios, wherein data stored in encrypted form in a public \\ncloud must be processed in a separate, secure enterprise site.\\nIn addition to the data locality problem, one of the most challenging goals for cloud \\nproviders is to optimally provision virtual clusters for jobs while minimizing the \\noverall consumption cost of the cloud data center.\\nAn important focus of cloud resource optimization is to optimize globally across all \\njobs in the cloud as opposed to per-job resource optimizations. A good example of \\na globally optimized cloud- managed system is the recent Google BigQuery sys-\\ntem,\\n28 which allows Google to run SQL-like queries against very large datasets with \\npotentially billions of rows using an Excel-like interface. In the BigQuery service, \\ncustomers only submit the queries to be processed on the large datasets, and the \\ncloud system intelligently manages the resources for the SQL-like queries. Simi-\\nlarly, the Cura resource optimization model\\n29 proposed for MapReduce in a cloud \\nachieves global resource optimization by minimizing the overall resource utiliza-\\ntion in the cloud as opposed to per-job or per-customer resource optimization.\\n25.6.4 YARN as a Data Service Platform\\nThe separation of resource management from application management has taken \\nHadoop to another level as a platform. Hadoop v1 was all about MapReduce. In \\nHadoop v2, MapReduce is one of the many application frameworks that can run on \\nthe cluster. As we discussed in Section 25.5, this has opened the door for many services \\n(with their own programming models) to be provided on YARN. There is no need to \\ntranslate all data processing techniques and algorithms into a set of MapReduce jobs. \\nMapReduce is presently being used only for batch-oriented processing such as the \\nETL (extract, transform, load) process in data warehouses (see Chapter 29). The \\nemerging trend is to see Hadoop as a data lake, where a significant portion of enter-\\nprise data resides and where processing happens. Traditionally, HDFS has been \\nwhere an enterprise’s historical data resides because HDFS can handle the scale of \\nsuch data. Most new sources of data, which in today’s search and social networking \\napplications come from Web and machine logs, clickstream data, message data (as \\nin Twitter) and sensor data, also is being stored largely in HDFS.\\n26See the PACMAN framework by Ananthanarayanan et al. (2012) and the MixApart system by \\n Mihailescu et al. (2013).\\n27See Palanisamy et al. (2014a).\\n28For the Google BigQuery system, see https://developers.google.com/bigquery/\\n29Palanisamy et al. (2014b).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 963, 'page_label': '964'}, page_content='950 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\nThe Hadoop v1 model was the federation model: although HDFS was the storage \\nlayer for the enterprise, processing was a mixture of MapReduce and other engines. \\nOne alternative was to extract data from HDFS store to engines running outside \\nthe cluster in their own silos; such data was moved to graph engines, machine \\nlearning analytical applications, and so forth. The same machines as those used for \\nthe Hadoop cluster were being used for entirely different applications, such as \\nstream processing outside of Hadoop. This scenario was far from ideal since phys-\\nical resources had to be divvied up in a static manner and it was difficult to migrate \\nand upgrade to new versions when multiple frameworks ran on the same machines. \\nWith YARN, the above issues are addressed. Traditional services are taking advan-\\ntage of the YARN ResourceManager and are providing their service on the same \\nHadoop cluster where the data resides.\\nWhereas support for SQL in Hadoop was promised by multiple vendors, the actual \\nsupport has been less than completely desirable. Some vendors required the HDFS \\ndata to be moved out to another database to run SQL; some required wrappers to \\nread the HDFS data before an SQL query ran on it. A new trend among RDBMSs \\nand traditional database systems considers a YARN cluster as a viable platform. \\nOne example is Actian’s analytics platform, which provides SQL in Hadoop\\n30 and \\nwhich is claimed to be a complete and robust implementation of SQL using the \\nActian Vectorwise columnar database (which runs as a YARN application). IBM’s \\nBig SQL 3.0 31 is a project that makes an existing IBM shared-nothing DBMS run \\non a YARN cluster.\\nApache Storm is a distributed scalable streaming engine that allows users to pro-\\ncess real-time data feeds. It is widely used by Twitter. Storm on YARN (http://\\nhortonworks.com/labs/storm/) and SAS on YARN (http://hortonworks.com/\\npartner/sas/) are applications that treat Storm (a distributed stream processing \\napplication) and SAS (statistical analysis software) as applications on the YARN \\nplatform. As we discussed previously, Giraph and HBase Hoya are ongoing efforts \\nthat are rapidly adopting YARN. A wide range of application systems uses the \\nHadoop cluster for storage; examples include services like streaming, machine \\nlearning/statistics, graph processing, OLAP, and key-value stores. These services \\ngo well beyond MapReduce. The goal/promise of YARN is for these services to \\ncoexist on the same cluster and take advantage of the locality of data in HDFS \\nwhile YARN orchestrates their use of cluster resources.\\n25.6.5 Challenges Faced by Big Data Technologies\\nIn a recent article, 32 several database experts voiced their concerns about the \\nimpending challenges faced by big data technologies when such technologies \\n30Current documentation is available at http://www.actian.com/about-us/blog/sql-hadoop-real-deal/\\n31Current information is available at: http://www.slideshare.net/Hadoop_\\nSummit/w-325p230-azubirigrayatv4\\n32See Jagadish et al. (2014).'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 964, 'page_label': '965'}, page_content='25.6 General Discussion  951\\nare used primarily for analytics applications. These concerns include the \\n following:\\n ■ Heterogeneity of information:  Heterogeneity in terms of data types, data \\nformats, data representation, and semantics is unavoidable when it comes to \\nsources of data. One of the phases in the big data life cycle involves integra-\\ntion of this data. The cost of doing a clean job of integration to bring all data \\ninto a single structure is prohibitive for most applications, such as health-\\ncare, energy, transportation, urban planning, and environmental modeling. \\nMost machine learning algorithms expect data to be fed into them in a uni-\\nform structure. The data provenance (which refers to the information about \\nthe origin and ownership of data) is typically not maintained in most analyt-\\nics applications. Proper interpretation of data analysis results requires large \\namounts of metadata.\\n ■ Privacy and confidentiality: Regulations and laws regarding protection of \\nconfidential information are not always available and hence not applied \\nstrictly during big data analysis. Enforcement of HIPAA regulations in the \\nhealthcare environment is one of few instances where privacy and confiden-\\ntiality are strictly enforced. Location-based applications (such as on smart \\nphones and other GPS-equipped devices), logs of user transactions, and \\nclickstreams that capture user behavior all reveal confidential information. \\nUser movement and buying patterns can be tracked to reveal personal iden-\\ntity. Because it is now possible to harness and analyze billions of users’ records \\nvia the technologies described in this chapter, there is widespread concern \\nabout personal information being compromised (e.g., data about individuals \\ncould be leaked from social data networks that are in some way linked to \\nother data networks). Data about customers, cardholders, and employees is \\nheld by organizations and thus is subject to breaches of confidentiality. Jag-\\nadish et al. (2014) voiced a need for stricter control over digital rights man-\\nagement of data similar to the control exercised in the music industry.\\n ■ Need for visualization and better human interfaces: Huge volumes of data \\nare crunched by big data systems, and the results of analyses must be inter-\\npreted and understood by humans. Human preferences must be accounted \\nfor and data must be presented in a properly digestible form. Humans are \\nexperts at detecting patterns and have great intuition about data they are \\nfamiliar with. Machines cannot match humans in this regard. It should be \\npossible to bring together multiple human experts to share and interpret \\nresults of analysis and thereby increase understanding of those results. Mul-\\ntiple modes of visual exploration must be possible to make the best use of \\ndata and to properly interpret results that are out of range and thus are clas-\\nsified as outlier values.\\n ■ Inconsistent and incomplete information: This has been a perennial prob-\\nlem in data collection and management. Future big data systems will allow \\nmultiple sources to be handled by multiple coexisting applications, so prob-\\nlems due to missing data, erroneous data, and uncertain data will be com-\\npounded. The large volume and built-in redundancy of data in fault-tolerant'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 965, 'page_label': '966'}, page_content='952 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\nsystems may compensate to some extent for the missing values, conflicting \\nvalues, hidden relationships, and the like. There is an inherent uncertainty \\nabout data collected from regular users using normal devices when such \\ndata comes in multiple forms (e.g., images, rates of speed, direction of \\ntravel). There is still a lot to be learned about how to use crowdsourcing data \\nto generate effective decision making.\\nThe aforementioned issues are not new to information systems. However, the large \\nvolume and wide variety of information inherent in big data systems compounds \\nthese issues.\\n25.6.6 Moving Forward\\nYARN makes it feasible for enterprises to run and manage many services on one \\ncluster. But building data solutions on Hadoop is still a daunting challenge. A solu-\\ntion may involve assembling ETL (extract, transform, load) processing, machine \\nlearning, graph processing, and/or report creation. Although these different func-\\ntional engines all run on the same cluster, their programming models and metadata \\nare not unified. Analytics application developers must try to integrate all these ser-\\nvices into a coherent solution.\\nOn current hardware, each node contains a significant amount of main memory \\nand flash memory storage. The cluster thus becomes a vast resource of main mem-\\nory and flash storage. Significant innovation has demonstrated the performance \\ngains of in-memory data engines ; for example, SAP HANA is an in-memory, \\ncolumnar scale-out RDBMS that is gaining a wide following.\\n33\\nThe Spark platform from Databricks (https://databricks.com/), which is an off-\\nshoot of the Berkeley Data Analytics Stack from AMPLabs at Berkeley,\\n34addresses \\nboth of the advances mentioned above—namely, the ability to house diverse \\napplica tions in one cluster and the ability to use vast amounts of main memory \\nfor\\xa0faster response. Matei Zaharia developed the Resilient Distributed Datasets \\n(RDD) concept\\n35 as a part of his Ph.D. work at the University of California–Berkeley \\nthat gave rise to the Spark system. The concept is generic enough to be used across \\nall Spark’s engines: Spark core (data flow), Spark-SQL, GraphX, (graph process-\\ning), MLLib (machine learning), and Spark-Streaming (stream processing). For \\nexample, it is possible to write a script in Spark that expresses a data flow that \\nreads data from HDFS, reshapes the data using a Spark-SQL query, passes that \\ninformation to an MLLib function for machine learning–type analysis, and then \\nstores the result back in HDFS.\\n36\\n34See https://amplab.cs.berkeley.edu/software/ for projects at Amplab from the University of California– \\nBerkeley.\\n35The RDD concept was first proposed in Zaharia et al. (2012).\\n36See an example of the use of Spark at https://databricks.com/blog/2014/03/26/spark-sql- \\nmanipulating-structured-data-using-spark-2.html\\n33See http://www.saphana.com/welcome for a variety of documentation on SAP’s HANA system.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 966, 'page_label': '967'}, page_content='25.7 Summary  953\\nRDDs are built on the capabilities of Scala language collections 37 that are able to \\nre-create themselves from their input. RDDs can be configured based on how their \\ndata is distributed and how their data is represented: it can be always re-created \\nfrom input, and it can be cached on disk or in memory. In-memory representa-\\ntions vary from serialized Java objects to highly optimized columnar formats that \\nhave all the advantages of columnar databases (e.g., speed, footprint, operating in \\nserialized form).\\nThe capabilities of a unified programming model and in-memory datasets will \\nlikely be incorporated into the Hadoop ecosystem. Spark is already available as a \\nservice in YARN (http://spark.apache.org/docs/1.0.0/running-on-yarn.html). \\nDetailed discussion of Spark and related technologies in the Berkeley Data Analysis \\nStack is beyond our scope here. Agneeswaran (2014) discusses the potential of \\nSpark and related products; interested readers should consult that source.\\n25.7 Summary\\nIn this chapter, we discussed big data technologies. Reports from IBM, Mckinsey, \\nand Tearadata scientist Bill Franks all predict a vibrant future for this technology, \\nwhich will be at the center of future data analytics and machine learning applications \\nand which is predicted to save businesses billions of dollars in the coming years.\\nWe began our discussion by focusing on developments at Google with the Google \\nfile system and MapReduce (MR), a programming paradigm for distributed pro-\\ncessing that is scalable to huge quantities of data reaching into the petabytes. After \\ngiving a historical development of the technology and mentioning the Hadoop eco-\\nsystem, which spans a large number of currently active Apache projects, we dis-\\ncussed the Hadoop distributed file system (HDFS) by outlining its architecture and \\nits handling of file operations; we also touched on the scalability studies done on \\nHDFS. We then gave details of the MapReduce runtime environment. We provided \\nexamples of how the MapReduce paradigm can be applied to a variety of contexts; \\nwe gave a detailed example of its application to optimizing various relational join \\nalgorithms. We then presented briefly the developments of Pig and Hive, the sys-\\ntems that provide an SQL-like interface with Pig Latin and HiveQL on top of the \\nlow-level MapReduce programming. We also mentioned the advantages of the \\njoint Hadoop/MapReduce technology.\\nHadoop/MapReduce is undergoing further development and is being repositioned \\nas version 2, known as MRv2 or YARN; version 2 separates resource management \\nfrom task/job management. We discussed the rationale behind YARN, its architec-\\nture, and other ongoing frameworks based on YARN, including Apache Tez, a \\nworkflow modeling environment; Apache Giraph, a large-scale graph processing \\nsystem based on Pregel of Google; and Hoya, a Hortonworks rendering of HBase \\nelastic clusters on YARN.\\n37See http://docs.scala-lang.org/overviews/core/architecture-of-scala-collections.html for more information \\non Scala Collections.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 967, 'page_label': '968'}, page_content='954 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\nFinally, we presented a general discussion of some issues related to MapReduce/Hadoop \\ntechnology. We briefly commented on the study done for this architecture vis-à-vis \\nparallel DBMSs. There are circumstances where one is superior over the other, and \\nclaims about the superiority of parallel DBMSs for batch jobs are becoming less rele-\\nvant due to architectural advancements in the form of YARN-related developments. \\nWe discussed the relationship between big data and cloud technologies and the work \\nbeing done to address data locality issues in cloud storage for big data analytics. We \\nstated that YARN is being considered as a generic data services platform, and we \\nlisted the challenges for this technology as outlined in a paper authored by a group of \\ndatabase experts. We concluded with a summary of ongoing projects in the field of \\nbig data.\\nReview Questions\\n 25.1. What is data analytics and what is its role in science and industry?\\n 25.2. How will the big data movement support data analytics?\\n 25.3. What are the important points made in the McKinsey Global Institute report \\nof 2012?\\n 25.4. How do you define big data?\\n 25.5. What are the various types of analytics mentioned in the IBM (2014) book?\\n 25.6. What are the four major characteristics of big data? Provide examples drawn \\nfrom current practice of each characteristic.\\n 25.7. What is meant by veracity of data?\\n 25.8. Give the chronological history of the development of MapReduce/Hadoop \\ntechnology.\\n 25.9. Describe the execution workflow of the MapReduce programming envi-\\nronment.\\n 25.10. Give some examples of MapReduce applications.\\n 25.11. What are the core properties of a job in MapReduce?\\n 25.12. What is the function of JobTracker?\\n 25.13. What are the different releases of Hadoop?\\n 25.14. Describe the architecture of Hadoop in your own words.\\n 25.15. What is the function of the NameNode and secondary NameNode in HDFS?\\n 25.16. What does the Journal in HDFS refer to? What data is kept in it?\\n 25.17. Describe the heartbeat mechanism in HDFS.\\n 25.18. How are copies of data (replicas) managed in HDFS?'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 968, 'page_label': '969'}, page_content='Review Questions 955\\n 25.19. Shvachko (2012) reported on HDFS performance. What did he find? Can \\nyou list some of his results?\\n 25.20. What other projects are included in the open source Hadoop ecosystem?\\n 25.21. Describe the workings of the JobTracker and TaskTracker in MapReduce.\\n 25.22. Describe the overall flow of the job in MapReduce.\\n 25.23. What are the different ways in which MapReduce provides fault tolerance?\\n 25.24. What is the Shuffle procedure in MapReduce?\\n 25.25. Describe how the various job schedulers for MapReduce work.\\n 25.26. What are the different types of joins that can be optimized using \\nMapReduce?\\n 25.27. Describe the MapReduce join procedures for Sort-Merge join, Partition \\nJoin, N-way Map-side join, and Simple N-way join.\\n 25.28. What is Apache Pig, and what is Pig Latin? Give an example of a query in \\nPig Latin.\\n 25.29. What are the main features of Apache Hive? What is its high-level query \\nlanguage?\\n 25.30. What is the SERDE architecture in Hive?\\n 25.31. List some of the optimizations in Hive and its support of SQL.\\n 25.32. Name some advantages of the MapReduce/Hadoop technology.\\n 25.33. Give the rationale in moving from Hadoop v1 to Hadoop v2 (YARN).\\n 25.34. Give an overview of the YARN architecture.\\n 25.35. How does Resource Manager work in YARN?\\n 25.36. What are Apache Tez, Apache Giraph, and Hoya?\\n 25.37. Compare parallel relational DBMSs and the MapReduce/Hadoop systems.\\n 25.38. In what way are big data and cloud technology complementary to one \\nanother?\\n 25.39. What are the data locality issues related to big data applications in cloud \\nstorage?\\n 25.40. What services can YARN offer beyond MapReduce?\\n 25.41. What are some of the challenges faced by big data technologies today?\\n 25.42. Discuss the concept of RDDs (resilient distributed datasets).\\n 25.43. Find out more about ongoing projects such as Spark, Mesos, Shark, and \\nBlinkDB as they relate to the Berkeley Data Analysis Stack.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 969, 'page_label': '970'}, page_content='956 Chapter 25 Big Data Technologies Based on MapReduce and Hadoop\\nSelected Bibliography\\nThe technologies for big data discussed in this chapter have mostly sprung up in the \\nlast ten years or so. The origin of this wave is traced back to the seminal papers from \\nGoogle, including the Google file system (Ghemawat, Gobioff, & Leung, 2003) and \\nthe MapReduce programming paradigm (Dean & Ghemawat, 2004). The Nutch \\nsystem with follow-on work at Yahoo is a precursor of the Hadoop technology and \\ncontinues as an Apache open source project (nutch.apache.org). The BigTable sys-\\ntem from Google (Fay Chang et al., 2006) describes a distributed scalable storage \\nsystem for managing structured data in the petabytes range over thousands of com-\\nmodity servers.\\nIt is not possible to name a specific single publication as “the” Hadoop paper. Many \\nstudies related to MapReduce and Hadoop have been published in the past decade. \\nWe will list only a few landmark developments here. Schvachko (2012) outlines the \\nlimitations of the HDFS file system. Afrati and Ullman (2010) is a good example of \\nusing MapReduce programming in various contexts and applications; they demon-\\nstrate how to optimize relational join operations in MapReduce. Olston et al. (2008) \\ndescribe the Pig system and introduce Pig Latin as a high-level programming lan-\\nguage. Thusoo et al. (2010) describe Hive as a petabyte- scale data warehouse on top \\nof Hadoop. A system for large-scale graph processing called Pregel at Google is \\ndescribed in Malewicz et al. (2010). It uses the bulk synchronous parallel (BSP) \\nmodel of parallel computation originally proposed by Valiant (1990). In Pavlo et al. \\n(2009), a number of database technology experts compared two parallel RDBMSs \\nwith Hadoop/MapReduce and showed how the parallel DBMS can actually per-\\nform better under certain conditions. The results of this study must not be consid-\\nered definitive because of the significant performance improvements achieved in \\nHadoop v2 (YARN). The approach of resilient distributed datasets (RDDs) for in-\\nmemory cluster computing is at the heart of the Berkeley’s Spark system, developed \\nby Zaharia et al. (2013). A recent paper by Jagadish et al. (2014) gives the collective \\nopinion of a number of database experts about the challenges faced by the current \\nbig data technologies.\\nThe definitive resource for Hadoop application developers is the book Hadoop: The \\nDefinitive Guide , by Tom White (2012), which is in its third edition. A book by \\nYARN project founder Arun Murthy with Vavilapalli (2014) describes how YARN \\nincreases scalability and cluster utilization, enables new programming models and \\nservices, and extends applicability beyond batch applications and Java. Agneeswaran \\n(2014) has written about going beyond Hadoop, and he describes the Berkeley Data \\nAnalysis Stack (BDAS) for real-time analytics and machine learning; the Stack \\nincludes Spark, Mesos, and Shark. He also describes Storm, a complex event-pro-\\ncessing engine from Twitter widely used in industry today for real-time computing \\nand analytics.\\nThe Hadoop wiki is at Hadoop.apache.org. There are many open source, big data \\nprojects under Apache, such as Hive, Pig, Oozie, Sqoop, Storm, and HBase. Up-to-\\ndate information about these projects can be found in the documentation at the \\nprojects’ Apache Web sites and wikis. The companies Cloudera, MapR, and Hor-'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 970, 'page_label': '971'}, page_content='Selected Bibliography 957\\ntonworks include on their Web sites documentation about their own distributions \\nof MapReduce/Hadoop-related technologies. The Berkeley Amplab (https://\\namplab.cs.berkeley.edu/) provides documentation about the Berkeley Data Analy-\\nsis Stack (BDAS), including ongoing projects such as GraphX, MLbase, and \\nBlinkDB.\\nThere are some good references that outline the promise of big data technology and \\nlarge scale data management. Bill Franks (2012) talks about how to leverage big \\ndata technologies for advanced analytics and provides insights that will help practi-\\ntioners make better decisions. Schmarzo (2013) discusses how the big data analytics \\ncan empower businesses. Dietrich et al. (2014) describe how IBM has applied the \\npower of big data analytics across the enterprise in applications worldwide. A book \\npublished by McKinsey Global Institute (2012) gives a strategic angle on big data \\ntechnologies by focusing on productivity, competitiveness, and growth.\\nThere has been a parallel development in the cloud technologies that we have not \\nbeen able to discuss in detail in this chapter. We refer the reader to recent books on \\ncloud computing. Erl et al. (2013) discusses models, architectures, and business \\npractices and desccribes how this technology has matured in practice. Kavis (2014) \\npresents the various service models, including software as a service (SaaS), platform \\nas a service (PaaS), and infrastructure as a service (IaaS). Bahga and Madisetti \\n(2013) offer a practical, hands-on introduction to cloud computing. They describe \\nhow to develop cloud applications on various cloud platforms, such as Amazon \\nWeb Service (AWS), Google Cloud, and Microsoft’s Windows Azure.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 971, 'page_label': '972'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 972, 'page_label': '973'}, page_content='Advanced Database Models, \\nSystems, and Applications    \\npart 11'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 973, 'page_label': '974'}, page_content='This page intentionally left blank'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 974, 'page_label': '975'}, page_content='961\\n26\\nEnhanced Data Models: \\nIntroduction to Active,  \\nTemporal, Spatial, Multimedia, \\nand Deductive Databases\\nA\\ns the use of database systems has grown, users \\nhave demanded additional functionality from \\nthese software packages; increased functionality would make it easier to implement \\nmore advanced and complex user applications. Object-oriented databases and \\nobject-relational systems do provide features that allow users to extend their sys-\\ntems by specifying additional abstract data types for each application. However, it is \\nuseful to identify certain common features for some of these advanced applications \\nand to create models that can represent them. Additionally, specialized storage \\nstructures and indexing methods can be implemented to improve the performance \\nof these common features. Then the features can be implemented as abstract data \\ntypes or class libraries and purchased separately from the basic DBMS software \\npackage. The term data blade has been used in Informix and cartridge in Oracle to \\nrefer to such optional submodules that can be included in a DBMS package. Users \\ncan utilize these features directly if they are suitable for their applications, without \\nhaving to reinvent, reimplement, and reprogram such common features.\\nThis chapter introduces database concepts for some of the common features that \\nare needed by advanced applications and are being used widely. We will cover \\nactive rules  that are used in active database applications, temporal concepts  that \\nare used in temporal database applications, and, briefly, some of the issues involv-\\ning spatial databases  and multimedia databases.  We will also discuss deductive \\ndatabases. It is important to note that each of these topics is very broad, and we give \\nchapter 26'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 975, 'page_label': '976'}, page_content='962 Chapter 26 Enhanced Data Models\\nonly a brief introduction to each. In fact, each of these areas can serve as the sole \\ntopic of a complete book.\\nIn Section 26.1, we introduce the topic of active databases, which provide addi-\\ntional functionality for specifying active rules . These rules can be automatically \\ntriggered by events that occur, such as database updates or certain times being \\nreached, and can initiate certain actions that have been specified in the rule declara-\\ntion to occur if certain conditions are met. Many commercial packages include \\nsome of the functionality provided by active databases in the form of triggers . \\nTriggers are now part of the SQL-99 and later standards.\\nIn Section 26.2, we introduce the concepts of temporal databases , which permit \\nthe database system to store a history of changes and allow users to query both cur-\\nrent and past states of the database. Some temporal database models also allow \\nusers to store future expected information, such as planned schedules. It is impor-\\ntant to note that many database applications are temporal, but they are often imple-\\nmented without having much temporal support from the DBMS package—that is, \\nthe temporal concepts are implemented in the application programs that access the \\ndatabase. The ability to create and query temporal data has been added to the SQL \\nstandard in SQL:2011 and is available in the DB2 system, but we do not discuss it \\nhere. The interested reader is referred to the end-of-chapter bibliography.\\nSection 26.3 gives a brief overview of spatial database concepts. We discuss types of \\nspatial data, different kinds of spatial analyses, operations on spatial data, types of \\nspatial queries, spatial data indexing, spatial data mining, and applications of spatial \\ndatabases. Most commercial and open source relational systems provide spatial \\nsupport in their data types and query languages as well as providing indexing and \\nefficient query processing for common spatial operations.\\nSection 26.4 is devoted to multimedia database concepts. Multimedia databases  \\nprovide features that allow users to store and query different types of multimedia \\ninformation, which includes images (such as pictures and drawings), video clips \\n(such as movies, newsreels, and home videos), audio clips (such as songs, phone \\nmessages, and speeches), and documents (such as books and articles). We discuss \\nautomatic analysis of images, object recognition in images, and semantic tagging \\nof images.\\nIn Section 26.5, we discuss deductive databases,\\n1 an area that is at the intersection of \\ndatabases, logic, and artificial intelligence or knowledge bases. A deductive \\n database system includes capabilities to define (deductive) rules, which can deduce \\nor infer additional information from the facts that are stored in a database. Because \\npart of the theoretical foundation for some deductive database systems is mathe-\\nmatical logic, such rules are often referred to as logic databases . Other types of \\nsystems, referred to as expert database systems or knowledge-based systems, also \\nincorporate reasoning and inferencing capabilities; such systems use techniques \\n1Section 26.5 is a summary of Deductive Databases. The full chapter from the third edition, which provides \\na more comprehensive introduction, is available on the book’s Web site.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 976, 'page_label': '977'}, page_content='26.1 Active Database Concepts and Triggers  963\\nthat were developed in the field of artificial intelligence, including semantic net-\\nworks, frames, production systems, or rules for capturing domain-specific knowl-\\nedge. Section 26.6 summarizes the chapter.\\nReaders may choose to peruse the particular topics they are interested in, as the sec-\\ntions in this chapter are practically independent of one another.\\n26.1 Active Database Concepts and Triggers\\nRules that specify actions that are automatically triggered by certain events have \\nbeen considered important enhancements to database systems for quite some time. \\nIn fact, the concept of triggers—a technique for specifying certain types of active \\nrules—has existed in early versions of the SQL specification for relational databases, \\nand triggers are now part of the SQL-99 and later standards. Commercial relational \\nDBMSs—such as Oracle, DB2, and Microsoft SQLServer—have various versions of \\ntriggers available. However, much research into what a general model for active \\ndatabases should look like has been done since the early models of triggers were \\nproposed. In Section 26.1.1, we will present the general concepts that have been \\nproposed for specifying rules for active databases. We will use the syntax of the \\nOracle commercial relational DBMS to illustrate these concepts with specific exam-\\nples, since Oracle triggers are close to the way rules are specified in the SQL stan-\\ndard. Section 26.1.2 will discuss some general design and implementation issues for \\nactive databases. We give examples of how active databases are implemented in the \\nSTARBURST experimental DBMS in Section 26.1.3, since STARBURST provides \\nfor many of the concepts of generalized active databases within its framework. Sec-\\ntion 26.1.4 discusses possible applications of active databases. Finally, Section 26.1.5 \\ndescribes how triggers are declared in the SQL-99 standard.\\n26.1.1  Generalized Model for Active Databases  \\nand Oracle Triggers\\nThe model that has been used to specify active database rules is referred to as \\nthe event-condition-action  (ECA) model. A rule in the ECA model has three \\ncomponents:\\n  1. The event(s)  that triggers the rule: These events are usually database \\nupdate operations that are explicitly applied to the database. However, in \\nthe general model, they could also be temporal events\\n2 or other kinds of \\nexternal events.\\n  2. The condition that determines whether the rule action should be executed: \\nOnce the triggering event has occurred, an optional condition may be evalu-\\nated. If no condition is specified, the action will be executed once the event \\n2An example would be a temporal event specified as a periodic time, such as: Trigger this rule every day \\nat 5:30 a.m.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 977, 'page_label': '978'}, page_content='964 Chapter 26 Enhanced Data Models\\noccurs. If a condition is specified, it is first evaluated, and only if it evaluates \\nto true will the rule action be executed.\\n  3. The action to be taken: The action is usually a sequence of SQL statements, \\nbut it could also be a database transaction or an external program that will \\nbe automatically executed.\\nLet us consider some examples to illustrate these concepts. The examples are \\nbased on a much simplified variation of the \\nCOMPANY  database application \\nfrom Figure 5.5 and are shown in Figure 26.1, with each employee having a \\nname (\\nName ), Social Security number ( Ssn), salary ( Salary ), department to \\nwhich she is currently assigned ( Dno, a foreign key to DEPARTMENT ), and a \\ndirect supervisor ( Supervisor_ssn , a (recursive) foreign key to EMPLOYEE ). For \\nthis example, we assume that NULL  is allowed for Dno, indicating that an \\nemployee may be temporarily unassigned to any department. Each department \\nhas a name (\\nDname), number ( Dno), the total salary of all employees assigned to \\nthe department ( Total_sal ), and a manager ( Manager_ssn , which is a foreign key \\nto EMPLOYEE ).\\nNotice that the Total_sal attribute is really a derived attribute whose value should be \\nthe sum of the salaries of all employees who are assigned to the particular depart-\\nment. Maintaining the correct value of such a derived attribute can be done via an \\nactive rule. First we have to determine the events that may cause a change in the \\nvalue of \\nTotal_sal, which are as follows:\\n  1. Inserting (one or more) new employee tuples\\n  2. Changing the salary of (one or more) existing employees\\n  3. Changing the assignment of existing employees from one department to \\nanother\\n  4. Deleting (one or more) employee tuples\\nIn the case of event 1, we only need to recompute Total_sal if the new employee is \\nimmediately assigned to a department—that is, if the value of the Dno attribute for \\nthe new employee tuple is not NULL (assuming NULL is allowed for Dno). Hence, this \\nwould be the condition to be checked. A similar condition could be checked for \\nevent 2 (and 4) to determine whether the employee whose salary is changed (or \\nwho is being deleted) is currently assigned to a department. For event 3, we will \\nalways execute an action to maintain the value of \\nTotal_sal correctly, so no condition \\nis needed (the action is always executed).\\nName Ssn Salary Dno Supervisor_ssn\\nEMPLOYEE\\nDname Dno Total_sal Manager_ssn\\nDEPARTMENT\\nFigure 26.1 \\nA simplified COMPANY \\ndatabase used for active \\nrule examples.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 978, 'page_label': '979'}, page_content='26.1 Active Database Concepts and Triggers  965\\nThe action for events 1, 2, and 4 is to automatically update the value of Total_sal for \\nthe employee’s department to reflect the newly inserted, updated, or deleted \\nemployee’s salary. In the case of event 3, a twofold action is needed: one to update \\nthe \\nTotal_sal of the employee’s old department and the other to update the Total_sal \\nof the employee’s new department.\\nThe four active rules (or triggers) R1, R2, R3, and R4—corresponding to the above \\nsituation—can be specified in the notation of the Oracle DBMS as shown in Fig-\\nure\\xa026.2(a). Let us consider rule R1 to illustrate the syntax of creating triggers in \\nOracle. The \\nCREATE TRIGGER statement specifies a trigger (or active rule) name—\\nTotal_sal1 for R1. The AFTER clause specifies that the rule will be triggered after the \\nevents that trigger the rule occur. The triggering events—an insert of a new \\nemployee in this example—are specified following the \\nAFTER keyword.3\\nThe ON clause specifies the relation on which the rule is specified— EMPLOYEE for \\nR1. The optional keywords FOR EACH ROW  specify that the rule will be triggered \\nonce for each row that is affected by the triggering event.4\\nThe optional WHEN clause is used to specify any conditions that need to be checked \\nafter the rule is triggered, but before the action is executed. Finally, the action(s) to \\nbe taken is (are) specified as a PL/SQL block, which typically contains one or more \\nSQL statements or calls to execute external procedures.\\nThe four triggers (active rules) R1, R2, R3, and R4 illustrate a number of features of \\nactive rules. First, the basic events that can be specified for triggering the rules are the \\nstandard SQL update commands: INSERT, DELETE, and UPDATE. They are specified by \\nthe keywords INSERT, DELETE, and UPDATE in Oracle notation. In the case of UPDATE, \\none may specify the attributes to be updated—for example, by writing UPDATE OF \\nSalary, Dno. Second, the rule designer needs to have a way to refer to the tuples that have \\nbeen inserted, deleted, or modified by the triggering event. The keywords NEW and OLD \\nare used in Oracle notation; NEW is used to refer to a newly inserted or newly updated \\ntuple, whereas OLD is used to refer to a deleted tuple or to a tuple before it was updated.\\nThus, rule R1 is triggered after an INSERT operation is applied to the EMPLOYEE \\nrelation. In R1, the condition (NEW.Dno IS NOT NULL) is checked, and if it evaluates \\nto true, meaning that the newly inserted employee tuple is related to a department, \\nthen the action is executed. The action updates the DEPARTMENT tuple(s) related to \\nthe newly inserted employee by adding their salary ( NEW.Salary) to the Total_sal \\nattribute of their related department.\\nRule R2 is similar to R1, but it is triggered by an UPDATE operation that updates the \\nSALARY of an employee rather than by an INSERT. Rule R3 is triggered by an update \\nto the Dno attribute of EMPLOYEE, which signifies changing an employee’s assign-\\nment from one department to another. There is no condition to check in R3, so the \\n3As we will see, it is also possible to specify BEFORE instead of AFTER, which indicates that the rule is \\ntriggered before the triggering event is executed.\\n4Again, we will see that an alternative is to trigger the rule only once even if multiple rows (tuples) are \\naffected by the triggering event.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 979, 'page_label': '980'}, page_content='966 Chapter 26 Enhanced Data Models\\n(a) R1: CREATE TRIGGER Total_sal1\\n  AFTER INSERT ON EMPLOYEE\\n  FOR EACH ROW\\n  WHEN ( NEW.Dno IS NOT NULL )\\n   UPDATE DEPARTMENT\\n   SET Total_sal = Total_sal + NEW.Salary\\n   WHERE Dno = NEW.Dno;\\n R2: CREATE TRIGGER Total_sal2\\n  AFTER UPDATE OF Salary ON EMPLOYEE\\n  FOR EACH ROW\\n  WHEN ( NEW.Dno IS NOT NULL )\\n   UPDATE DEPARTMENT\\n   SET Total_sal = Total_sal + NEW.Salary – OLD.Salary\\n   WHERE Dno = NEW.Dno;\\n R3: CREATE TRIGGER Total_sal3\\n  AFTER UPDATE OF Dno ON EMPLOYEE\\n  FOR EACH ROW\\n   BEGIN\\n   UPDATE DEPARTMENT\\n   SET Total_sal = Total_sal + NEW.Salary\\n   WHERE Dno = NEW.Dno;\\n   UPDATE DEPARTMENT\\n   SET Total_sal = Total_sal – OLD.Salary\\n   WHERE Dno = OLD.Dno;\\n   END;\\n R4: CREATE TRIGGER Total_sal4\\n  AFTER DELETE ON EMPLOYEE\\n  FOR EACH ROW\\n  WHEN ( OLD.Dno IS NOT NULL)\\n   UPDATE DEPARTMENT\\n   SET Total_sal = Total_sal – OLD.Salary\\n   WHERE Dno = OLD.Dno;\\n(b) R5: CREATE TRIGGER Inform_supervisor1\\n  BEFORE INSERT OR UPDATE OF Salary, Supervisor_ssn\\n   ON EMPLOYEE\\n  FOR EACH ROW\\n  WHEN ( NEW.Salary > ( SELECT Salary FROM EMPLOYEE\\n            WHERE Ssn = NEW.Supervisor_ssn ) )\\n     inform_supervisor(NEW.Supervisor_ssn, NEW.Ssn );\\nFigure 26.2 \\nSpecifying active rules \\nas triggers in Oracle \\nnotation. (a) Triggers \\nfor automatically \\n maintaining the \\n consistency of Total_sal \\nof DEPARTMENT. \\n(b) Trigger for \\n comparing an \\n employee’s salary with \\nthat of his or her \\nsupervisor.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 980, 'page_label': '981'}, page_content='26.1 Active Database Concepts and Triggers  967\\naction is executed whenever the triggering event occurs. The action updates both \\nthe old department and new department of the reassigned employees by adding \\ntheir salary to \\nTotal_sal of their new department and subtracting their salary from \\nTotal_sal of their old department. Note that this should work even if the value of Dno \\nis NULL, because in this case no department will be selected for the rule action.5\\nIt is important to note the effect of the optional FOR EACH ROW clause, which sig-\\nnifies that the rule is triggered separately for each tuple.  This is known as a row-\\nlevel trigger . If this clause was left out, the trigger would be known as a \\nstatement-level trigger and would be triggered once for each triggering statement. \\nTo see the difference, consider the following update operation, which gives a 10% \\nraise to all employees assigned to department 5. This operation would be an event \\nthat triggers rule \\nR2:\\nUPDATE EMPLOYEE\\nSET Salary  = 1.1 * Salary\\nWHERE Dno  = 5;\\nBecause the above statement could update multiple records, a rule using row-level \\nsemantics, such as R2 in Figure 26.2, would be triggered once for each row, whereas \\na rule using statement-level semantics is triggered only once.  The Oracle system \\nallows the user to choose which of the above options is to be used for each rule. \\nIncluding the optional FOR EACH ROW clause creates a row-level trigger, and leav-\\ning it out creates a statement-level trigger. Note that the keywords NEW and OLD \\ncan only be used with row-level triggers.\\nAs a second example, suppose we want to check whenever an employee’s salary is \\ngreater than the salary of his or her direct supervisor. Several events can trigger this \\nrule: inserting a new employee, changing an employee’s salary, or changing an \\nemployee’s supervisor. Suppose that the action to take would be to call an external \\nprocedure \\ninform_supervisor,6 which will notify the supervisor. The rule could then \\nbe written as in R5 (see Figure 26.2(b)).\\nFigure 26.3 shows the syntax for specifying some of the main options available in \\nOracle triggers. We will describe the syntax for triggers in the SQL-99 standard in \\nSection 26.1.5.\\n26.1.2  Design and Implementation Issues  \\nfor Active Databases\\nThe previous section gave an overview of some of the main concepts for speci-\\nfying active rules. In this section, we discuss some additional issues concerning \\nhow rules are designed and implemented. The first issue concerns activation, \\n5R1, R2, and R4 can also be written without a condition. However, it may be more efficient to execute \\nthem with the condition since the action is not invoked unless it is required.\\n6Assuming that an appropriate external procedure has been declared. This is a feature that is available \\nin SQL-99 and later standards.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 981, 'page_label': '982'}, page_content='968 Chapter 26 Enhanced Data Models\\n<trigger> ::= CREATE TRIGGER <trigger name>\\n ( AFTER I BEFORE ) <triggering events> ON <table name>\\n [ FOR EACH ROW ]\\n [ WHEN <condition> ]\\n <trigger actions> ;\\n<triggering events> ::= <trigger event> { OR <trigger event> }\\n<trigger event> ::=  INSERT I DELETE I UPDATE [ OF <column name> { , <column name> } ]\\n<trigger action> ::= <PL/SQL block>\\nFigure 26.3 \\nA syntax summary for specifying triggers in the Oracle system (main options only).\\ndeactivation, and grouping of rules. In addition to creating rules, an active \\ndatabase system should allow users to activate , deactivate , and drop rules by \\nreferring to their rule names. A deactivated rule  will not be triggered by the \\ntriggering event. This feature allows users to selectively deactivate rules for cer-\\ntain periods of time when they are not needed. The activate command  will \\nmake the rule active again. The drop command  deletes the rule from the sys-\\ntem. Another option is to group rules into named rule sets , so the whole set of \\nrules can be activated, deactivated, or dropped. It is also useful to have a com-\\nmand that can trigger a rule or rule set via an explicit \\nPROCESS RULES  com-\\nmand issued by the user.\\nThe second issue concerns whether the triggered action should be executed before, \\nafter, instead of , or concurrently with  the triggering event. A before trigger  exe-\\ncutes the trigger before executing the event that caused the trigger. It can be used \\nin applications such as checking for constraint violations. An after trigger  exe-\\ncutes the trigger after executing the event, and it can be used in applications such \\nas maintaining derived data and monitoring for specific events and conditions. An \\ninstead of trigger executes the trigger instead of executing the event, and it can be \\nused in applications such as executing corresponding updates on base relations in \\nresponse to an event that is an update of a view.\\nA related issue is whether the action being executed should be considered as a \\nseparate transaction  or whether it should be part of the same transaction that \\ntriggered the rule. We will try to categorize the various options. It is important \\nto note that not all options may be available for a particular active database sys-\\ntem. In fact, most commercial systems are limited to one or two of the options  \\nthat we will now discuss.\\nLet us assume that the triggering event occurs as part of a transaction execution. \\nWe should first consider the various options for how the triggering event is related \\nto the evaluation of the rule’s condition. The rule condition evaluation  is also \\nknown as rule consideration, since the action is to be executed only after consid-\\nering whether the condition evaluates to true or false. There are three main possi-\\nbilities for rule consideration:'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 982, 'page_label': '983'}, page_content='26.1 Active Database Concepts and Triggers  969\\n  1. Immediate consideration.  The condition is evaluated as part of the same \\ntransaction as the triggering event and is evaluated immediately. This case \\ncan be further categorized into three options:\\n /box4Evaluate the condition before executing the triggering event.\\n /box4Evaluate the condition after executing the triggering event.\\n /box4Evaluate the condition instead of executing the triggering event.\\n  2. Deferred consideration. The condition is evaluated at the end of the trans-\\naction that included the triggering event. In this case, there could be many \\ntriggered rules waiting to have their conditions evaluated.\\n  3. Detached consideration. The condition is evaluated as a separate transac-\\ntion, spawned from the triggering transaction.\\nThe next set of options concerns the relationship between evaluating the rule \\ncondition and executing the rule action. Here, again, three options are possible: \\nimmediate , deferred , or detached  execution. Most active systems use the first \\noption. That is, as soon as the condition is evaluated, if it returns true, the action \\nis immediately executed.\\nThe Oracle system (see Section 26.1.1) uses the immediate consideration model, but \\nit allows the user to specify for each rule whether the before or after option is to be \\nused with immediate condition evaluation. It also uses the immediate execution  \\nmodel. The STARBURST system (see Section 26.1.3) uses the deferred consider-\\nation option, meaning that all rules triggered by a transaction wait until the trigger-\\ning transaction reaches its end and issues its \\nCOMMIT WORK command before the \\nrule conditions are evaluated.7\\nAnother issue concerning active database rules is the distinction between row-level \\nrules and statement-level rules. Because SQL update statements (which act as trig-\\ngering events) can specify a set of tuples, one must distinguish between whether the \\nrule should be considered once for the whole statement  or whether it should be \\nconsidered separately for each row  (that is, tuple) affected by the statement. The \\nSQL-99 standard (see Section 26.1.5) and the Oracle system (see Section 26.1.1) \\nallow the user to choose which of the options is to be used for each rule, whereas \\nSTARBURST uses statement-level semantics only. We will give examples of how \\nstatement-level triggers can be specified in Section 26.1.3.\\nOne of the difficulties that may have limited the widespread use of active rules, in \\nspite of their potential to simplify database and software development, is that there \\nare no easy-to-use techniques for designing, writing, and verifying rules. For exam-\\nple, it is difficult to verify that a set of rules is consistent, meaning that two or more \\nrules in the set do not contradict one another. It is also difficult to guarantee \\n termination of a set of rules under all circumstances. To illustrate the termination \\nproblem briefly, consider the rules in Figure 26.4. Here, rule \\nR1 is triggered by an \\nINSERT event on TABLE1 and its action includes an update event on Attribute1 of \\n7ST ARBURST also allows the user to start rule consideration explicitly via a PROCESS RULES command.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 983, 'page_label': '984'}, page_content='970 Chapter 26 Enhanced Data Models\\nTABLE2. However, rule R2’s triggering event is an UPDATE event on Attribute1 of \\nTABLE2, and its action includes an INSERT event on TABLE1. In this example, it is \\neasy to see that these two rules can trigger one another indefinitely, leading to non-\\ntermination. However, if dozens of rules are written, it is very difficult to determine \\nwhether termination is guaranteed or not.\\nIf active rules are to reach their potential, it is necessary to develop tools for the \\ndesign, debugging, and monitoring of active rules that can help users design and \\ndebug their rules.\\n26.1.3  Examples of Statement-Level Active Rules  \\nin STARBURST\\nWe now give some examples to illustrate how rules can be specified in the STARBURST \\nexperimental DBMS. This will allow us to demonstrate how statement-level rules can \\nbe written, since these are the only types of rules allowed in STARBURST.\\nThe three active rules \\nR1S, R2S, and R3S in Figure 26.5 correspond to the first three \\nrules in Figure 26.2, but they use STARBURST notation and statement-level seman-\\ntics. We can explain the rule structure using rule \\nR1S. The CREATE RULE statement \\nspecifies a rule name— Total_sal1 for R1S. The ON clause specifies the relation on \\nwhich the rule is specified—EMPLOYEE for R1S. The WHEN clause is used to specify \\nthe events that trigger the rule. 8 The optional  IF clause is used to specify any \\n conditions that need to be checked. Finally, the THEN clause is used to specify the \\nactions to be taken, which are typically one or more SQL statements.\\nIn STARBURST, the basic events that can be specified for triggering the rules are \\nthe standard SQL update commands: INSERT, DELETE, and UPDATE. These are \\nspecified by the keywords INSERTED, DELETED, and UPDATED in STARBURST \\nnotation. Second, the rule designer needs to have a way to refer to the tuples that \\nhave been modified. The keywords \\nINSERTED , DELETED , NEW-UPDATED , and \\nOLD-UPDATED are used in STARBURST notation to refer to four transition tables \\n(relations) that include the newly inserted tuples, the deleted tuples, the updated \\nR1: CREATE TRIGGER T1\\n AFTER INSERT ON TABLE1\\n FOR EACH ROW\\n  UPDATE TABLE2\\n  SET Attribute1 = … ;\\nR2: CREATE TRIGGER T2\\n AFTER UPDATE OF Attribute1 ON TABLE2\\n FOR EACH ROW\\n  INSERT INTO TABLE1 VALUES ( … );\\nFigure 26.4 \\nAn example to illustrate \\nthe termination problem \\nfor active rules.\\n8Note that the WHEN keyword specifies events in ST ARBURST but is used to specify the rule condition \\nin SQL and Oracle triggers.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 984, 'page_label': '985'}, page_content='26.1 Active Database Concepts and Triggers  971\\nR1S: CREATE RULE Total_sal1 ON EMPLOYEE\\n WHEN INSERTED\\n IF EXISTS ( SELECT * FROM INSERTED WHERE Dno IS NOT NULL)\\n THEN UPDATE  DEPARTMENT AS D\\n  SET  D.Total_sal = D.Total_sal +\\n   ( SELECT SUM (I.Salary) FROM INSERTED AS I WHERE D.Dno = I.Dno )\\n  WHERE D.Dno IN ( SELECT Dno FROM INSERTED );\\nR2S: CREATE RULE Total_sal2 ON EMPLOYEE\\n WHEN UPDATED ( Salary )\\n IF EXISTS ( SELECT * FROM NEW-UPDATED WHERE Dno IS NOT NULL)\\n  OR EXISTS ( SELECT * FROM OLD-UPDATED WHERE Dno IS NOT NULL)\\n THEN UPDATE  DEPARTMENT AS D\\n  SET  D.Total_sal = D.Total_sal +\\n   ( SELECT SUM (N.Salary) FROM NEW-UPDATED AS N\\n    WHERE D.Dno = N.Dno ) –\\n   ( SELECT SUM (O.Salary) FROM OLD-UPDATED AS O\\n    WHERE D.Dno = O.Dno )\\n  WHERE  D.Dno IN ( SELECT Dno FROM NEW-UPDATED ) OR\\n    D.Dno IN ( SELECT Dno FROM OLD-UPDATED);\\nR3S: CREATE RULE Total_sal3 ON EMPLOYEE\\n WHEN UPDATED ( Dno )\\n THEN UPDATE  DEPARTMENT AS D\\n  SET  D.Total_sal = D.Total_sal +\\n   ( SELECT SUM (N.Salary) FROM NEW-UPDATED AS N\\n    WHERE D.Dno = N.Dno )\\n  WHERE  D.Dno IN ( SELECT Dno FROM NEW-UPDATED );\\n  UPDATE  DEPARTMENT AS D\\n  SET  D.Total_sal = Total_sal –\\n   ( SELECT SUM (O.Salary) FROM OLD-UPDATED AS O\\n    WHERE D.Dno = O.Dno )\\n  WHERE  D.Dno IN ( SELECT Dno FROM OLD-UPDATED );\\nFigure 26.5 \\nActive rules using statement-level semantics in STARBURST notation.\\ntuples before they were updated, and the updated tuples after they were updated, \\nrespectively. Obviously, depending on the triggering events, only some of these \\ntransition tables may be available. The rule writer can refer to these tables when \\nwriting the condition and action parts of the rule. Transition tables contain tuples \\nof the same type as those in the relation specified in the \\nON clause of the rule—for \\nR1S, R2S, and R3S, this is the EMPLOYEE relation.\\nIn statement-level semantics, the rule designer can only refer to the transition tables \\nas a whole and the rule is triggered only once, so the rules must be written differ-\\nently than for row-level semantics. Because multiple employee tuples may be'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 985, 'page_label': '986'}, page_content='972 Chapter 26 Enhanced Data Models\\ninserted in a single insert statement, we have to check if at least one  of the newly \\ninserted employee tuples is related to a department. In R1S, the condition\\nEXISTS (SELECT * FROM INSERTED WHERE Dno IS NOT NULL )\\nis checked, and if it evaluates to true, then the action is executed. The action updates in \\na single statement the DEPARTMENT tuple(s) related to the newly inserted employee(s) \\nby adding their salaries to the Total_sal attribute of each related department. Because \\nmore than one newly inserted employee may belong to the same department, we use \\nthe \\nSUM aggregate function to ensure that all their salaries are added.\\nRule R2S is similar to R1S, but is triggered by an UPDATE operation that updates \\nthe salary of one or more employees rather than by an INSERT. Rule R3S is triggered \\nby an update to the Dno attribute of EMPLOYEE, which signifies changing one or \\nmore employees’ assignment from one department to another. There is no condi-\\ntion in \\nR3S, so the action is executed whenever the triggering event occurs. 9 The \\naction updates both the old department(s) and new department(s) of the reassigned \\nemployees by adding their salary to \\nTotal_sal of each new department and subtract-\\ning their salary from Total_sal of each old department.\\nIn our example, it is more complex to write the statement-level rules than the row-\\nlevel rules, as can be illustrated by comparing Figures 26.2 and 26.5. However, this \\nis not a general rule, and other types of active rules may be easier to specify when \\nusing statement-level notation than when using row-level notation.\\nThe execution model for active rules in STARBURST uses deferred consideration. \\nThat is, all the rules that are triggered within a transaction are placed in a set—\\ncalled the conflict set—which is not considered for evaluation of conditions and \\nexecution until the transaction ends (by issuing its \\nCOMMIT WORK  command). \\nSTARBURST also allows the user to explicitly start rule consideration in the middle \\nof a transaction via an explicit \\nPROCESS RULES command. Because multiple rules \\nmust be evaluated, it is necessary to specify an order among the rules. The syntax \\nfor rule declaration in STARBURST allows the specification of ordering among the \\nrules to instruct the system about the order in which a set of rules should be consid-\\nered.\\n10 Additionally, the transition tables— INSERTED, DELETED, NEW-UPDATED, \\nand OLD-UPDATED—contain the net effect of all the operations within the transac-\\ntion that affected each table, since multiple operations may have been applied to \\neach table during the transaction.\\n26.1.4 Potential Applications for Active Databases\\nWe now briefly discuss some of the potential applications of active rules. Obvi-\\nously, one important application is to allow notification of certain conditions that \\n9As in the Oracle examples, rules R1S and R2S can be written without a condition. However, it may be \\nmore efficient to execute them with the condition since the action is not invoked unless it is required.\\n10If no order is specified between a pair of rules, the system default order is based on placing the rule \\ndeclared first ahead of the other rule.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 986, 'page_label': '987'}, page_content='26.1 Active Database Concepts and Triggers  973\\noccur. For example, an active database may be used to monitor, say, the tempera-\\nture of an industrial furnace. The application can periodically insert in the database \\nthe temperature reading records directly from temperature sensors, and active rules \\ncan be written that are triggered whenever a temperature record is inserted, with a \\ncondition that checks if the temperature exceeds the danger level and results in the \\naction to raise an alarm.\\nActive rules can also be used to enforce integrity constraints  by specifying the \\ntypes of events that may cause the constraints to be violated and then evaluating \\nappropriate conditions that check whether the constraints are actually violated by \\nthe event or not. Hence, complex application constraints, often known as business \\nrules, may be enforced that way. For example, in the \\nUNIVERSITY database applica-\\ntion, one rule may monitor the GPA of students whenever a new grade is entered, \\nand it may alert the advisor if the GPA of a student falls below a certain threshold; \\nanother rule may check that course prerequisites are satisfied before allowing a stu-\\ndent to enroll in a course; and so on.\\nOther applications include the automatic maintenance of derived data, such as the \\nexamples of rules \\nR1 through R4 that maintain the derived attribute Total_sal when-\\never individual employee tuples are changed. A similar application is to use active \\nrules to maintain the consistency of materialized views (see Section 5.3) whenever \\nthe base relations are modified. Alternately, an update operation specified on a view \\ncan be a triggering event, which can be converted to updates on the base relations \\nby using an instead of trigger. These applications are also relevant to the new data \\nwarehousing technologies (see Chapter 29). A related application maintains that \\nreplicated tables are consistent by specifying rules that modify the replicas when-\\never the master table is modified.\\n26.1.5 Triggers in SQL-99\\nTriggers in the SQL-99 and later standards are similar to the examples we dis-\\ncussed in Section 26.1.1, with some minor syntactic differences. The basic events \\nthat can be specified for triggering the rules are the standard SQL update com-\\nmands: \\nINSERT, DELETE, and UPDATE. In the case of UPDATE, one may specify the \\nattributes to be updated. Both row-level and statement-level triggers are allowed, \\nindicated in the trigger by the clauses \\nFOR EACH ROW and FOR EACH  STATEMENT, \\nrespectively. One syntactic difference is that the trigger may specify particular \\ntuple variable names for the old and new tuples instead of using the keywords \\nNEW and OLD, as shown in Figure 26.1. Trigger T1 in Figure 26.6 shows how the \\nrow-level trigger R2 from Figure 26.1(a) may be specified in SQL-99. Inside the \\nREFERENCING clause, we named tuple variables (aliases) O and N to refer to the OLD \\ntuple (before modification) and NEW tuple (after modification), respectively. Trigger \\nT2 in Figure 26.6 shows how the statement-level trigger R2S from Figure\\xa026.5 may \\nbe specified in SQL-99. For a statement-level trigger, the  REFERENCING clause is \\nused to refer to the table of all new tuples (newly inserted or newly updated) as N, \\nwhereas the table of all old tuples (deleted tuples or tuples before they were \\nupdated) is referred to as O.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 987, 'page_label': '988'}, page_content='974 Chapter 26 Enhanced Data Models\\n26.2 Temporal Database Concepts\\nTemporal databases, in the broadest sense, encompass all database applications that \\nrequire some aspect of time when organizing their information. Hence, they pro-\\nvide a good example to illustrate the need for developing a set of unifying concepts \\nfor application developers to use. Temporal database applications have been devel-\\noped since the early days of database usage. However, in creating these applications, \\nit is mainly left to the application designers and developers to discover, design, pro-\\ngram, and implement the temporal concepts they need. There are many examples \\nof applications where some aspect of time is needed to maintain the information in \\na database. These include healthcare, where patient histories need to be maintained; \\ninsurance, where claims and accident histories are required as well as information \\nabout the times when insurance policies are in effect; reservation systems in general \\n(hotel, airline, car rental, train, and so on), where information on the dates and \\ntimes when reservations are in effect are required; scientific databases, where data \\ncollected from experiments includes the time when each data is measured; and so \\non. Even the two examples used in this book may be easily expanded into temporal \\napplications. In the \\nCOMPANY database, we may wish to keep SALARY, JOB, and \\nPROJECT histories on each employee. In the UNIVERSITY database, time is already \\nincluded in the SEMESTER and YEAR of each SECTION of a COURSE, the grade his-\\ntory of a STUDENT, and the information on research grants. In fact, it is realistic to \\nconclude that the majority of database applications have some temporal informa-\\ntion. However, users often attempt to simplify or ignore temporal aspects because \\nof the complexity that they add to their applications.\\nT1: CREATE TRIGGER Total_sal1\\n AFTER UPDATE OF Salary ON EMPLOYEE\\n REFERENCING OLD ROW AS O, NEW ROW AS N\\n FOR EACH ROW\\n WHEN ( N.Dno IS NOT NULL )\\n UPDATE DEPARTMENT\\n SET Total_sal = Total_sal + N.salary – O.salary\\n WHERE Dno = N.Dno;\\nT2: CREATE TRIGGER Total_sal2\\n AFTER UPDATE OF Salary ON EMPLOYEE\\n REFERENCING OLD TABLE AS O, NEW TABLE AS N\\n FOR EACH STATEMENT\\n WHEN EXISTS ( SELECT *FROM N WHERE N.Dno IS NOT NULL ) OR\\n  EXISTS ( SELECT * FROM O WHERE O.Dno IS NOT NULL )\\n UPDATE DEPARTMENT AS D\\n SET D.Total_sal = D.Total_sal\\n + ( SELECT SUM (N.Salary) FROM N WHERE D.Dno=N.Dno )\\n – ( SELECT SUM (O.Salary) FROM O WHERE D.Dno=O.Dno )\\n WHERE Dno IN ( ( SELECT Dno FROM N ) UNION ( SELECT Dno FROM O ) );\\nFigure 26.6 \\nTrigger T1 illustrating \\nthe syntax for defining \\ntriggers in SQL-99.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 988, 'page_label': '989'}, page_content='26.2 Temporal Database Concepts  975\\nIn this section, we will introduce some of the concepts that have been developed to deal \\nwith the complexity of temporal database applications. Section 26.2.1 gives an over-\\nview of how time is represented in databases, the different types of temporal informa-\\ntion, and some of the different dimensions of time that may be needed. Section 26.2.2 \\ndiscusses how time can be incorporated into relational databases. Section 26.2.3 gives \\nsome additional options for representing time that are possible in database models that \\nallow complex-structured objects, such as object databases. Section 26.2.4 introduces \\noperations for querying temporal databases and gives a brief overview of the TSQL2 \\nlanguage, which extends SQL with temporal concepts. Section 26.2.5 focuses on time \\nseries data, which is a type of temporal data that is very important in practice.\\n26.2.1  Time Representation, Calendars,  \\nand Time Dimensions\\nFor temporal databases, time is considered to be an ordered sequence of points in \\nsome granularity that is determined by the application. For example, suppose that \\nsome temporal application never requires time units that are less than one second. \\nThen, each time point represents one second using this granularity. In reality, each \\nsecond is a (short) time duration, not a point, since it may be further divided into \\nmilliseconds, microseconds, and so on. Temporal database researchers have used \\nthe term chronon instead of point to describe this minimal granularity for a par-\\nticular application. The main consequence of choosing a minimum granularity—\\nsay, one second—is that events occurring within the same second will be considered \\nto be simultaneous events, even though in reality they may not be.\\nBecause there is no known beginning or ending of time, one needs a reference point \\nfrom which to measure specific time points. Various calendars are used by various \\ncultures (such as Gregorian (Western), Chinese, Islamic, Hindu, Jewish, Coptic, and \\nso on) with different reference points. A calendar organizes time into different time \\nunits for convenience. Most calendars group 60 seconds into a minute, 60 minutes \\ninto an hour, 24 hours into a day (based on the physical time of earth’s rotation \\naround its axis), and 7 days into a week. Further groupings of days into months and \\nmonths into years either follow solar or lunar natural phenomena and are generally \\nirregular. In the Gregorian calendar, which is used in most Western countries, days \\nare grouped into months that are 28, 29, 30, or 31 days, and 12 months are grouped \\ninto a year. Complex formulas are used to map the different time units to one another.\\nIn SQL2, the temporal data types (see Chapter 4) include \\nDATE (specifying Year, \\nMonth, and Day as YYYY-MM-DD), TIME (specifying Hour, Minute, and Second \\nas HH:MM:SS), TIMESTAMP (specifying a Date/Time combination, with options for \\nincluding subsecond divisions if they are needed), INTERVAL  (a relative time \\n duration, such as 10 days or 250 minutes), and PERIOD (an anchored time duration \\nwith a fixed starting point, such as the 10-day period from January 1, 2009, to Jan-\\nuary\\xa010, 2009, inclusive).\\n11\\n11Unfortunately, the terminology has not been used consistently. For example, the term interval is often \\nused to denote an anchored duration. For consistency, we will use the SQL terminology.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 989, 'page_label': '990'}, page_content='976 Chapter 26 Enhanced Data Models\\nEvent Information versus Duration (or State) Information. A temporal data-\\nbase will store information concerning when certain events occur, or when certain \\nfacts are considered to be true. There are several different types of temporal infor-\\nmation. Point events or facts are typically associated in the database with a single \\ntime point in some granularity. For example, a bank deposit event may be associ-\\nated with the timestamp when the deposit was made, or the total monthly sales of a \\nproduct (fact) may be associated with a particular month (say, February 2010). \\nNote that even though such events or facts may have different granularities, each is \\nstill associated with a single time value in the database. This type of information is \\noften represented as time series data, as we will discuss in Section 26.2.5. Duration \\nevents or facts, on the other hand, are associated with a specific time period in the \\ndatabase.\\n12 For example, an employee may have worked in a company from Aug-\\nust\\xa015, 2003 until November 20, 2008.\\nA time period  is represented by its start and end time points  [START-TIME , \\n ENDTIME]. For example, the above period is represented as [2003-08-15, 2008-11-20]. \\nSuch a time period is often interpreted to mean the set of all time points from start-\\ntime to end-time, inclusive, in the specified granularity. Hence, assuming day gran-\\nularity, the period [2003-08-15, 2008-11-20] represents the set of all days from \\nAugust 15, 2003, until November 20, 2008, inclusive.\\n13\\nValid Time and Transaction Time Dimensions. Given a particular event or \\nfact that is associated with a particular time point or time period in the database, the \\nassociation may be interpreted to mean different things. The most natural interpre-\\ntation is that the associated time is the time that the event occurred, or the period \\nduring which the fact was considered to be true in the real world. If this interpreta-\\ntion is used, the associated time is often referred to as the valid time. A temporal \\ndatabase using this interpretation is called a valid time database.\\nHowever, a different interpretation can be used, where the associated time refers to \\nthe time when the information was actually stored in the database; that is, it is the \\nvalue of the system time clock when the information is valid in the system.\\n14 In this \\ncase, the associated time is called the transaction time. A temporal database using \\nthis interpretation is called a transaction time database.\\nOther interpretations can also be intended, but these are considered to be the most \\ncommon ones, and they are referred to as time dimensions. In some applications, \\nonly one of the dimensions is needed and in other cases both time dimensions are \\nrequired, in which case the temporal database is called a bitemporal database. If \\n12This is the same as an anchored duration. It has also been frequently called a time interval, but to avoid \\nconfusion we will use period to be consistent with SQL terminology.\\n13The representation [2003-08-15, 2008-11-20] is called a closed interval representation. One can \\nalso use an open interval, denoted [2003-08-15, 2008-11-21), where the set of points does not include \\nthe end point. Although the latter representation is sometimes more convenient, we shall use closed \\nintervals except where indicated.\\n14The explanation is more involved, as we will see in Section 26.2.3.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 990, 'page_label': '991'}, page_content='26.2 Temporal Database Concepts  977\\nother interpretations are intended for time, the user can define the semantics and \\nprogram the applications appropriately, and this interpretation of time is called a \\nuser-defined time.\\nThe next section shows how these concepts can be incorporated into relational \\ndatabases, and Section 26.2.3 shows an approach to incorporate temporal concepts \\ninto object databases.\\n26.2.2  Incorporating Time in Relational Databases  \\nUsing Tuple Versioning\\nValid Time Relations. Let us now see how the different types of temporal databases \\nmay be represented in the relational model. First, suppose that we would like to include \\nthe history of changes as they occur in the real world. Consider again the database in \\nFigure 26.1, and let us assume that, for this application, the granularity is day. Then, \\nwe\\xa0could convert the two relations \\nEMPLOYEE and DEPARTMENT into valid time \\n relations by adding the attributes Vst (Valid Start Time) and Vet (Valid End Time), \\nwhose data type is DATE in order to provide day granularity. This is shown in Fig-\\nure\\xa026.7(a), where the relations have been renamed EMP_VT and DEPT_VT, respectively.\\nConsider how the EMP_VT relation differs from the nontemporal EMPLOYEE rela-\\ntion (Figure 26.1).15 In EMP_VT, each tuple V represents a version of an employee’s \\n15A nontemporal relation is also called a snapshot relation because it shows only the current snapshot \\nor current state of the database.\\n(a)\\nName\\nEMP_VT\\nSalary DnoSsn Supervisor_ssn Vst Vet\\nName Salary Supervisor_ssnSsn Tst Tet\\n(b)\\n(c)\\nDname\\nDEPT_VT\\nEMP_TT\\nDname Total_sal Manager_ssnDno\\nDno\\nTst Tet\\nDEPT_TT\\nTotal_salDno Manager_ssn Vst Vet\\nName Salary Supervisor_ssnSsn Dno Tst Tet\\nEMP_BT\\nDname Total_sal Manager_ssnDno Tst Tet\\nDEPT_BT\\nVst Vet\\nVst Vet\\nFigure 26.7 \\nDifferent types of temporal \\nrelational databases. (a) Valid \\ntime database schema. \\n(b) Transaction time database \\nschema. (c) Bitemporal \\n database schema.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 991, 'page_label': '992'}, page_content='978 Chapter 26 Enhanced Data Models\\ninformation that is valid (in the real world) only during the time period [V.Vst, \\nV.Vet], whereas in EMPLOYEE each tuple represents only the current state or current \\nversion of each employee. In EMP_VT, the current version of each employee typi-\\ncally has a special value, now, as its valid end time. This special value, now, is a \\ntemporal variable  that implicitly represents the current time as time progresses. \\nThe nontemporal EMPLOYEE relation would only include those tuples from the \\nEMP_VT relation whose Vet is now.\\nFigure 26.8 shows a few tuple versions in the valid-time relations EMP_VT and \\nDEPT_VT. There are two versions of Smith, three versions of Wong, one version of \\nBrown, and one version of Narayan. We can now see how a valid time relation \\nshould behave when information is changed. Whenever one or more attributes of \\nan employee are updated, rather than actually overwriting the old values, as would \\nhappen in a nontemporal relation, the system should create a new version and close \\nthe current version by changing its \\nVet to the end time. Hence, when the user issued \\nthe command to update the salary of Smith effective on June 1, 2003, to $30000, the \\nsecond version of Smith was created (see Figure 26.8). At the time of this update, \\nthe first version of Smith was the current version, with now as its \\nVet, but after the \\nupdate now was changed to May 31, 2003 (one less than June 1, 2003, in day granu-\\nlarity), to indicate that the version has become a closed or history version and that \\nthe new (second) version of Smith is now the current one.\\nIt is important to note that in a valid time relation, the user must generally provide \\nthe valid time of an update. For example, the salary update of Smith may have been \\nName\\nSmith 123456789 25000 5 333445555 2002-06-15 2003-05-31\\nSmith 123456789 30000 5 333445555 2003-06-01 Now\\n333445555 25000 4 999887777 1999-0 8-20 2001-01-31\\n333445555 30000 5 999887777 2001-02-01 2002-03-31\\n333445555 40000 5 888665555 2002-04-01 Now\\n222447777 28000 4 999887777 2001-05-01 2002-08-10\\n666884444 38000 5 3334 45555 2003-08-01 Now\\nWong\\nWong\\nWong\\nBrown\\nNarayan\\n. . .\\n. . .\\nEMP_VT\\nSsn Salary Dno Supervisor_ssn Vst Vet\\nDname\\nResearch\\nResearch\\nDEPT_VT\\n5 8886 65555 2002-03-312001-09-20\\n333445555 2002-04-015 Now\\nDno Manager_ssn Vst Vet\\nFigure 26.8 \\nSome tuple versions in the valid time relations EMP_VT and DEPT_VT.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 992, 'page_label': '993'}, page_content='26.2 Temporal Database Concepts  979\\nentered in the database on May 15, 2003, at 8:52:12 a.m., say, even though the salary \\nchange in the real world is effective on June 1, 2003. This is called a proactive \\nupdate, since it is applied to the database before it becomes effective in the real \\nworld. If the update is applied to the database after it becomes effective in the real \\nworld, it is called a retroactive update. An update that is applied at the same time \\nas it becomes effective is called a simultaneous update.\\nThe action that corresponds to deleting an employee in a nontemporal database \\nwould typically be applied to a valid time database by closing the current version of \\nthe employee being deleted. For example, if Smith leaves the company effective \\nJanuary 19, 2004, then this would be applied by changing \\nVet of the current version \\nof Smith from now to 2004-01-19. In Figure 26.8, there is no current version for \\nBrown, because he presumably left the company on 2002-08-10 and was logically \\ndeleted. However, because the database is temporal, the old information on Brown \\nis still there.\\nThe operation to insert a new employee would correspond to creating the first tuple \\nversion for that employee and making it the current version, with the Vst being the \\neffective (real world) time when the employee starts work. In Figure 26.7, the tuple \\non Narayan illustrates this, since the first version has not been updated yet.\\nNotice that in a valid time relation, the nontemporal key, such as Ssn in EMPLOYEE, \\nis no longer unique in each tuple (version). The new relation key for EMP_VT is a \\ncombination of the nontemporal key and the valid start time attribute Vst,16 so we \\nuse (Ssn, Vst) as primary key. This is because, at any point in time, there should be \\nat most one valid version  of each entity. Hence, the constraint that any two tuple \\nversions representing the same entity should have nonintersecting valid time periods \\nshould hold on valid time relations. Notice that if the nontemporal primary key value \\nmay change over time, it is important to have a unique surrogate key attribute , \\nwhose value never changes for each real-world entity, in order to relate all versions of \\nthe same real-world entity.\\nValid time relations basically keep track of the history of changes as they become \\neffective in the real world. Hence, if all real-world changes are applied, the database \\nkeeps a history of the real-world states that are represented. However, because updates, \\ninsertions, and deletions may be applied retroactively or proactively, there is no \\nrecord of the actual database state at any point in time. If the actual database states are \\nimportant to an application, then one should use transaction time relations.\\nTransaction Time Relations. In a transaction time database, whenever a change \\nis applied to the database, the actual timestamp of the transaction that applied the \\nchange (insert, delete, or update) is recorded. Such a database is most useful when \\nchanges are applied simultaneously in the majority of cases—for example, real-time \\nstock trading or banking transactions. If we convert the nontemporal database in \\nFigure 26.1 into a transaction time database, then the two relations \\nEMPLOYEE and \\nDEPARTMENT are converted into transaction time relations  by adding the attri-\\nbutes Tst (Transaction Start Time) and Tet (Transaction End Time), whose data \\n16A combination of the nontemporal key and the valid end time attribute Vet could also be used.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 993, 'page_label': '994'}, page_content='980 Chapter 26 Enhanced Data Models\\ntype is typically TIMESTAMP. This is shown in Figure 26.7(b), where the relations \\nhave been renamed EMP_TT and DEPT_TT, respectively.\\nIn EMP_TT, each tuple V represents a version of an employee’s information that was \\ncreated at actual time V.Tst and was (logically) removed at actual time V.Tet (because \\nthe information was no longer correct). In EMP_TT, the current version  of each \\nemployee typically has a special value, uc (Until Changed), as its transaction end \\ntime, which indicates that the tuple represents correct information until it is \\nchanged by some other transaction. 17 A transaction time database has also been \\ncalled a rollback database ,18 because a user can logically roll back to the actual \\ndatabase state at any past point in time T by retrieving all tuple versions V whose \\ntransaction time period [V.Tst, V.Tet] includes time point T.\\nBitemporal Relations. Some applications require both valid time and transac-\\ntion time, leading to bitemporal relations. In our example, Figure 26.7(c) shows \\nhow the EMPLOYEE and DEPARTMENT nontemporal relations in Figure 26.1 would \\nappear as bitemporal relations EMP_BT and DEPT_BT, respectively. Figure 26.9 \\nshows a few tuples in these relations. In these tables, tuples whose transaction end \\ntime Tet is uc are the ones representing currently valid information, whereas tuples \\nwhose Tet is an absolute timestamp are tuples that were valid until (just before) that \\ntimestamp. Hence, the tuples with uc in Figure 26.9 correspond to the valid time \\ntuples in Figure 26.7. The transaction start time attribute Tst in each tuple is the \\ntimestamp of the transaction that created that tuple.\\nNow consider how an update operation would be implemented on a bitemporal \\nrelation. In this model of bitemporal databases,19 no attributes are physically changed \\nin any tuple except for the transaction end time attribute Tet with a value of uc.20 To \\nillustrate how tuples are created, consider the EMP_BT relation. The current version \\nV of an employee has uc in its Tet attribute and now in its Vet attribute. If some attri-\\nbute—say, Salary—is updated, then the transaction T that performs the update \\nshould have two parameters: the new value of Salary and the valid time VT when the \\nnew salary becomes effective (in the real world). Assume that VT− is the time point \\nbefore VT in the given valid time granularity and that transaction T has a timestamp \\nTS(T). Then, the following physical changes would be applied to the EMP_BT table:\\n  1. Make a copy V2 of the current version V; set V2.Vet to VT−, V2.Tst to TS(T), \\nV2.Tet to uc, and insert V2 in EMP_BT; V2 is a copy of the previous current \\nversion V after it is closed at valid time VT−.\\n17The uc variable in transaction time relations corresponds to the now variable in valid time relations. \\nHowever, the semantics are slightly different.\\n18Here, the term rollback does not have the same meaning as transaction rollback (see Chapter 23) \\nduring recovery, where the transaction updates are physically undone. Rather, here the updates can be \\nlogically undone, allowing the user to examine the database as it appeared at a previous time point.\\n19There have been many proposed temporal database models. We describe specific models here as \\nexamples to illustrate the concepts.\\n20Some bitemporal models allow the Vet attribute to be changed also, but the interpretations of the \\ntuples are different in those models.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 994, 'page_label': '995'}, page_content='26.2 Temporal Database Concepts  981\\n  2. Make a copy V3 of the current version V; set V3.Vst to VT, V3.Vet to now, V3.\\nSalary to the new salary value, V3.Tst to TS(T), V3.Tet to uc, and insert V3 in \\nEMP_BT; V3 represents the new current version.\\n  3. Set V.Tet to TS(T) since the current version is no longer representing correct \\ninformation.\\nAs an illustration, consider the first three tuples V1, V2, and V3 in EMP_BT in Fig-\\nure\\xa026.9. Before the update of Smith’s salary from 25000 to 30000, only V1 was in \\nEMP_BT and it was the current version and its Tet was uc. Then, a transaction T whose \\ntimestamp TS(T) is ‘2003-06-04,08:56:12’ updates the salary to 30000 with the effec-\\ntive valid time of ‘2003-06-01’. The tuple V2 is created, which is a copy of V1 except \\nthat its Vet is set to ‘2003-05-31’, one day less than the new valid time, and its Tst is the \\ntimestamp of the updating transaction. The tuple V3 is also created, which has the \\nnew salary, its Vst is set to ‘2003-06-01’, and its Tst is also the timestamp of the updat-\\ning transaction. Finally, the Tet of V1 is set to the timestamp of the updating transac-\\ntion, ‘2003-06-04,08:56:12’. Note that this is a retroactive update, since the updating \\ntransaction ran on June 4, 2003, but the salary change is effective on June 1, 2003.\\nSimilarly, when Wong’s salary and department are updated (at the same time) to \\n30000 and 5, the updating transaction’s timestamp is ‘2001-01-07,14:33:02’ and the \\neffective valid time for the update is ‘2001-02-01’. Hence, this is a proactive update \\nbecause the transaction ran on January 7, 2001, but the effective date was Feb-\\nruary\\xa01, 2001. In this case, tuple V\\n4 is logically replaced by V5 and V6.\\nName\\nSmith 123456789 25000 5 333445555 2002-06-15\\nSmith 123456789 25000 5 333445555 2002-06-15\\n123456789 30000 5 333445555 2003-06-01\\n333445555 25000 4 999887777 1999-0 8-20\\n333445555 25000 4 999887777 1999-0 8-20\\n333445555 30000 5 999887777 2001-02-01\\n333445555 30000 5\\n5\\n4\\n4\\n5\\n999887777\\n888667777\\n999887777\\n999887777\\n333445555\\n2001-02-01\\n2002-04-01\\n2001-05-01\\n2001-05-01\\n2003-08-01\\n2002-06-08, 13:05:58\\n2003-06-04, 08:56:12\\n2003-06-04, 08:56:12\\n1999-08-20, 11:18:23\\n2001-01-07 , 14:33:02\\n2001-01-07 , 14:33:02\\n2002-03-28, 09:23:57\\n2002-03-28, 09:23:57\\n2001-04-27 , 16:22:05\\n2002-08-12, 10:11:07\\n2003-07-28, 09:25:37\\n2003-06-04,08:56:12\\nuc\\nuc\\n2001-01-07 ,14:33:02\\nuc\\n2002-03-28,09:23:57\\nuc\\nuc\\n2002-08-12,10:11:07\\nuc\\nuc\\nNow\\n2003-05-31\\nNow\\nNow\\n2001-01-31\\nNow\\n2002-03-31\\nNow\\nNow\\n2002-08-10\\nNow\\nSmith\\nWong\\nWong\\nWong\\nWong\\nWong 333445555\\nBrown 2224 47777\\nBrown 2224 47777\\nNarayan\\n. . .\\n40000\\n28000\\n28000\\n38000666884444\\nEMP_BT\\nSsn Salary Dno Supervisor_ssn Vst Vet Tst Tet\\nDname\\nResearch\\nResearch\\nDEPT_VT\\n5 8886 65555 Now2001-09-20\\n888665555 2001-09-205 1997-03-31\\nDno Manager_ssn Vst Vet\\n2001-09-15,14:52:12\\n2002-03-28,09:23:57\\nTst\\n2001-03-28,09:23:57\\nuc\\nResearch 333445555 2002-04-015 Now 2002-03-28,09:23:57 uc\\nTet\\nFigure 26.9 \\nSome tuple versions in the bitemporal relations EMP_BT and DEPT_BT.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 995, 'page_label': '996'}, page_content='982 Chapter 26 Enhanced Data Models\\nNext, let us illustrate how a delete operation would be implemented on a bitempo-\\nral relation by considering the tuples V9 and V10 in the EMP_BT relation of Fig-\\nure\\xa026.9. Here, employee Brown left the company effective August 10, 2002, and the \\nlogical delete is carried out by a transaction T with \\nTS(T) = 2002-08-12,10:11:07. \\nBefore this, V9 was the current version of Brown, and its Tet was uc. The logical \\ndelete is implemented by setting V9.Tet to 2002-08-12,10:11:07 to invalidate it, and \\ncreating the final version V10 for Brown, with its Vet = 2002-08-10 (see Figure 26.9). \\nFinally, an insert operation  is implemented by creating the first version  as illus-\\ntrated by V11 in the EMP_BT table.\\nImplementation Considerations. There are various options for storing the \\ntuples in a temporal relation. One is to store all the tuples in the same table, as \\nshown in Figures 26.8 and 26.9. Another option is to create two tables: one for the \\ncurrently valid information and the other for the rest of the tuples. For example, in \\nthe bitemporal \\nEMP_BT relation, tuples with uc for their Tet and now for their Vet \\nwould be in one relation, the current table, since they are the ones currently valid \\n(that is, represent the current snapshot), and all other tuples would be in another \\nrelation. This allows the database administrator to have different access paths, such \\nas indexes for each relation, and keeps the size of the current table reasonable. \\nAnother possibility is to create a third table for corrected tuples whose \\nTet is not uc.\\nAnother option that is available is to vertically partition the attributes of the temporal \\nrelation into separate relations so that if a relation has many attributes, a whole new \\ntuple version is created whenever any one of the attributes is updated. If the attributes \\nare updated asynchronously, each new version may differ in only one of the attri-\\nbutes, thus needlessly repeating the other attribute values. If a separate relation is cre-\\nated to contain only the attributes that always change synchronously, with the primary \\nkey replicated in each relation, the database is said to be in temporal normal form. \\nHowever, to combine the information, a variation of join known as temporal \\n intersection join would be needed, which is generally expensive to implement.\\nIt is important to note that bitemporal databases allow a complete record of changes. \\nEven a record of corrections is possible. For example, it is possible that two tuple \\nversions of the same employee may have the same valid time but different attribute \\nvalues as long as their transaction times are disjoint. In this case, the tuple with the \\nlater transaction time is a correction of the other tuple version. Even incorrectly \\nentered valid times may be corrected this way. The incorrect state of the database \\nwill still be available as a previous database state for querying purposes. A database \\nthat keeps such a complete record of changes and corrections is sometimes called \\nan append-only database.\\n26.2.3  Incorporating Time in Object-Oriented Databases  \\nUsing Attribute Versioning\\nThe previous section discussed the tuple versioning approach  to implementing \\ntemporal databases. In this approach, whenever one attribute value is changed, a \\nwhole new tuple version is created, even though all the other attribute values will'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 996, 'page_label': '997'}, page_content='26.2 Temporal Database Concepts  983\\nbe identical to the previous tuple version. An alternative approach can be used \\nin database systems that support complex structured objects , such as object \\ndatabases (see Chapter 11) or object-relational systems. This approach is called \\nattribute versioning .\\nIn attribute versioning, a single complex object is used to store all the temporal \\nchanges of the object. Each attribute that changes over time is called a time-\\nvarying attribute , and it has its values versioned over time by adding temporal \\nperiods to the attribute. The temporal periods may represent valid time, transac-\\ntion time, or bitemporal, depending on the application requirements. Attributes \\nthat do not change over time are called non-time-varying  and are not associated \\nwith the temporal periods. To illustrate this, consider the example in Fig-\\nure\\xa026.10, which is an attribute-versioned valid time representation of \\nEMPLOYEE \\nclass TEMPORAL_SALARY\\n{ attribute Date Valid_start_time;\\n attribute Date Valid_end_time;\\n attribute float Salary;\\n};\\nclass TEMPORAL_DEPT\\n{ attribute Date Valid_start_time;\\n attribute Date Valid_end_time;\\n attribute DEPARTMENT_VT Dept;\\n};\\nclass TEMPORAL_SUPERVISOR\\n{ attribute Date Valid_start_time;\\n attribute Date Valid_end_time;\\n attribute EMPLOYEE_VT Supervisor;\\n};\\nclass TEMPORAL_LIFESPAN\\n{ attribute Date Valid_ start time;\\n attribute Date Valid end time;\\n};\\nclass EMPLOYEE_VT\\n( extent EMPLOYEES )\\n{ attribute list<TEMPORAL_LIFESPAN> lifespan;\\n attribute string  Name;\\n attribute string  Ssn;\\n attribute list<TEMPORAL_SALARY> Sal_history;\\n attribute list<TEMPORAL_DEPT> Dept_history;\\n attribute list <TEMPORAL_SUPERVISOR> Supervisor_history;\\n};\\nFigure 26.10 \\nPossible ODL schema \\nfor a temporal valid \\ntime EMPLOYEE_VT \\nobject class using  \\nattribute versioning.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 997, 'page_label': '998'}, page_content='984 Chapter 26 Enhanced Data Models\\nusing the object definition language (ODL) notation for object databases (see \\nChapter 11). Here, we assumed that name and Social Security number are non-\\ntime-varying attributes, whereas salary, department, and supervisor are time-\\nvarying attributes (they may change over time). Each time-varying attribute is \\nrepresented as a list of tuples \\n<Valid_start_time , Valid_end_time , Value>, ordered by \\nvalid start time.\\nWhenever an attribute is changed in this model, the current attribute version is \\nclosed and a new attribute version  for this attribute only is appended to the list. \\nThis allows attributes to change asynchronously. The current value for each attri-\\nbute has now for its \\nValid_end_time. When using attribute versioning, it is useful to \\ninclude a lifespan temporal attribute associated with the whole object whose value \\nis one or more valid time periods that indicate the valid time of existence for the \\nwhole object. Logical deletion of the object is implemented by closing the lifespan. \\nThe constraint that any time period of an attribute within an object should be a \\nsubset of the object’s lifespan should be enforced.\\nFor bitemporal databases, each attribute version would have a tuple with five \\ncomponents:\\n<\\nValid_start_time, Valid_end_time, Trans_start_time, Trans_end_time, Value>\\nThe object lifespan would also include both valid and transaction time dimensions. \\nTherefore, the full capabilities of bitemporal databases can be available with attri-\\nbute versioning. Mechanisms similar to those discussed earlier for updating tuple \\nversions can be applied to updating attribute versions.\\n26.2.4  Temporal Querying Constructs  \\nand the TSQL2 Language\\nSo far, we have discussed how data models may be extended with temporal con-\\nstructs. Now we give a brief overview of how query operations need to be extended \\nfor temporal querying. We will briefly discuss the TSQL2 language, which extends \\nSQL for querying valid time and transaction time tables, as well as for querying of \\nbitemporal relational tables.\\nIn nontemporal relational databases, the typical selection conditions involve attri-\\nbute conditions, and tuples that satisfy these conditions are selected from the set of \\ncurrent tuples. Following that, the attributes of interest to the query are specified by \\na projection operation  (see Chapter 6). For example, in the query to retrieve the \\nnames of all employees working in department 5 whose salary is greater than 30000, \\nthe selection condition would be as follows:\\n((Salary > 30000) \\nAND (Dno = 5))\\nThe projected attribute would be Name. In a temporal database, the conditions \\nmay involve time in addition to attributes. A pure time condition  involves only \\ntime—for example, to select all employee tuple versions that were valid on a cer-\\ntain time point T  or that were valid during a certain time period  \\n[T1, T2]. In this'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 998, 'page_label': '999'}, page_content='26.2 Temporal Database Concepts  985\\ncase, the specified time period is compared with the valid time period of each tuple \\nversion [T.Vst, T.Vet], and only those tuples that satisfy the condition are selected. \\nIn these operations, a period is considered to be equivalent to the set of time points \\nfrom T\\n1 to T2 inclusive, so the standard set comparison operations can be used. \\nAdditional operations, such as whether one time period ends before another starts, \\nare also needed.21\\nSome of the more common operations used in queries are as follows:\\n[T.Vst, T.Vet] INCLUDES [T1, T2] Equivalent to T1 ≥ T.Vst AND T2 ≤ T.Vet\\n[T.Vst, T.Vet] INCLUDED_IN [T1, T2] Equivalent to T1 ≤ T.Vst AND T2 ≥ T.Vet\\n[T.Vst, T.Vet] OVERLAPS [T1, T2] Equivalent to ( T1 ≤ T.Vet AND T2 ≥ T.Vst)22\\n[T.Vst, T.Vet] BEFORE [T1, T2] Equivalent to T1 ≥ T.Vet\\n[T.Vst, T.Vet] AFTER [T1, T2] Equivalent to T2 ≤ T.Vst\\n[T.Vst, T.Vet] MEETS_BEFORE [T1, T2] Equivalent to T1 = T.Vet + 123\\n[T.Vst, T.Vet] MEETS_AFTER [T1, T2] Equivalent to T2 + 1 = T.Vst\\nAdditionally, operations are needed to manipulate time periods, such as computing \\nthe union or intersection of two time periods. The results of these operations may \\nnot themselves be periods, but rather temporal elements —a collection of one or \\nmore disjoint time periods such that no two time periods in a temporal element are \\ndirectly adjacent. That is, for any two time periods [T1, T2] and [T3, T4] in a tempo-\\nral element, the following three conditions must hold:\\n ■ [T1, T2] intersection [T3, T4] is empty.\\n ■ T3 is not the time point following T2 in the given granularity.\\n ■ T1 is not the time point following T4 in the given granularity.\\nThe latter conditions are necessary to ensure unique representations of temporal \\nelements. If two time periods [T1, T2] and [T3, T4] are adjacent, they are combined \\ninto a single time period [T1, T4]. This is called coalescing of time periods. Coalesc-\\ning also combines intersecting time periods.\\nTo illustrate how pure time conditions can be used, suppose a user wants to select \\nall employee versions that were valid at any point during 2002. The appropriate \\nselection condition applied to the relation in Figure 26.8 would be\\n[T\\n.Vst, T.Vet] OVERLAPS [2002-01-01, 2002-12-31]\\nTypically, most temporal selections are applied to the valid time dimension. For a \\nbitemporal database, one usually applies the conditions to the currently correct \\n21A complete set of operations, known as Allen’s algebra (Allen, 1983), has been defined for comparing \\ntime periods.\\n22This operation returns true if the intersection of the two periods is not empty; it has also been called \\nINTERSECTS_WITH.\\n23Here, 1 refers to one time point in the specified granularity. The MEETS operations basically specify if \\none period starts immediately after another period ends.'),\n",
              " Document(metadata={'producer': 'Acrobat Distiller 15.0 (Windows); modified using iText 2.1.7 by 1T3XT', 'creator': 'HELIOS pdfcat', 'creationdate': '2016-02-04T04:28:03+02:00', 'author': 'Ramez Elmasri, Shamkant B. Navathe', 'moddate': '2025-07-13T15:03:15+07:00', 'title': 'Fundamentals of Database Systems Seventh Edition', 'source': '/content/drive/MyDrive/Colab Notebooks/Llama3/RDB.pdf', 'total_pages': 1176, 'page': 999, 'page_label': '1000'}, page_content='986 Chapter 26 Enhanced Data Models\\ntuples with uc as their transaction end times. However, if the query needs to be \\napplied to a previous database state, an AS_OF T clause is appended to the query, \\nwhich means that the query is applied to the valid time tuples that were correct in \\nthe database at time T.\\nIn addition to pure time conditions, other selections involve attribute and time \\nconditions. For example, suppose we wish to retrieve all \\nEMP_VT tuple versions T \\nfor employees who worked in department 5 at any time during 2002. In this case, \\nthe condition is\\n[T\\n.Vst, T.Vet]OVERLAPS [2002-01-01, 2002-12-31] AND (T.Dno = 5)\\nFinally, we give a brief overview of the TSQL2 query language, which extends SQL \\nwith constructs for temporal databases. The main idea behind TSQL2 is to allow \\nusers to specify whether a relation is nontemporal (that is, a standard SQL relation) \\nor temporal. The \\nCREATE TABLE statement is extended with an optional AS clause \\nto allow users to declare different temporal options. The following options are \\navailable:\\n ■ AS VALID STATE <GRANULARITY > (valid time relation with valid time \\nperiod)\\n ■ AS VALID EVENT <GRANULARITY > (valid time relation with valid time \\npoint)\\n ■ AS TRANSACTION (transaction time relation with transaction time period)\\n ■ AS VALID STATE <GRANULARITY> AND TRANSACTION (bitemporal relation, \\nvalid time period)\\n ■ AS VALID EVENT <GRANULARITY> AND TRANSACTION (bitemporal relation, \\nvalid time point)\\nThe keywords STATE and EVENT are used to specify whether a time period or time \\npoint is associated with the valid time dimension. In TSQL2, rather than have the \\nuser actually see how the temporal tables are implemented (as we discussed in the \\nprevious sections), the TSQL2 language adds query language constructs to specify \\nvarious types of temporal selections, temporal projections, temporal aggregations, \\ntransformation among granularities, and many other concepts. The book by Snod-\\ngrass et al. (1995) describes the language.\\n26.2.5 Time Series Data\\nTime series data is used very often in financial, sales, and economics applications. They \\ninvolve data values that are recorded according to a specific predefined sequence of \\ntime points. Therefore, they are a special type of valid event data, where the event’s \\ntime points are predetermined according to a fixed calendar. Consider the example of \\nclosing daily stock prices of a particular company on the New York Stock Exchange. \\nThe granularity here is day, but the days that the stock market is open are known (non-\\nholiday weekdays). Hence, it has been common to specify a computational procedure \\nthat calculates the particular calendar associated with a time series. Typical queries on'),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "Given the following extracted parts of a long document, create multiple choices questions and answers of the question based on the context below.\n",
        "\n",
        "The question must follow the criteria of six difficulty levels:\n",
        "\n",
        "1. Remember: Questions should start with verbs like \"Define\"\n",
        "2. Understand: Questions should start with verbs like \"Explain\" or \"Describe\"\n",
        "3. Apply: Questions should start with verbs like \"Solve\" or \"Apply\"\n",
        "4. Analyze: Questions should start with verbs like \"Compare\"\n",
        "5. Evaluate: Questions should start with verbs like \"Justify\" or \"Determine\"\n",
        "6. Create: Questions should start with verbs like \"Generate\" or \"Modify\" or \"Develop\"\n",
        "\n",
        "The question has format:\n",
        "Question: Content of Question\n",
        "A) Choice 1\n",
        "B) Choice 2\n",
        "C) Choice 3\n",
        "D) Choice 4\n",
        "Answer: Content of the Choice\n",
        "\n",
        "\n",
        "ALWAYS return a detail \"LEVEL\" and \"PAGE SOURCE\" for each question and answer.\n",
        "\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "\"\"\"\n",
        "prompt=PromptTemplate.from_template(template)\n",
        "print (prompt.format(context=\"Here is some context\", question=\"Here is a question\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJMD7LHZQFak",
        "outputId": "11b9db5f-87e8-45c2-e971-7aaf9732fc1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Given the following extracted parts of a long document, create multiple choices questions and answers of the question based on the context below. \n",
            "\n",
            "The question must follow the criteria of six difficulty levels:\n",
            "\n",
            "1. Remember: Questions should start with verbs like \"Define\" \n",
            "2. Understand: Questions should start with verbs like \"Explain\" or \"Describe\"\n",
            "3. Apply: Questions should start with verbs like \"Solve\" or \"Apply\"\n",
            "4. Analyze: Questions should start with verbs like \"Compare\"\n",
            "5. Evaluate: Questions should start with verbs like \"Justify\" or \"Determine\"\n",
            "6. Create: Questions should start with verbs like \"Generate\" or \"Modify\" or \"Develop\"\n",
            "\n",
            "The question has format:\n",
            "Question: Content of Question\n",
            "A) Choice 1\n",
            "B) Choice 2\n",
            "C) Choice 3\n",
            "D) Choice 4\n",
            "Answer: Content of the Choice\n",
            "\n",
            "\n",
            "ALWAYS return a detail \"LEVEL\" and \"PAGE SOURCE\" for each question and answer.\n",
            "\n",
            "\n",
            "Context: Here is some context\n",
            "\n",
            "Question: Here is a question\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | model | parser"
      ],
      "metadata": {
        "id": "5brOb7kBPQft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.input_schema.schema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmb7Wlb0Tgt7",
        "outputId": "e3655112-b756-4ecc-ff33-2d184b913145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-9-3226659032.py:1: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  chain.input_schema.schema()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'properties': {'context': {'title': 'Context', 'type': 'string'},\n",
              "  'question': {'title': 'Question', 'type': 'string'}},\n",
              " 'required': ['context', 'question'],\n",
              " 'title': 'PromptInput',\n",
              " 'type': 'object'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f8252fc"
      },
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "docs = text_splitter.split_documents(pages)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb2619a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b275c2b-ba8a-41e2-abe9-734b15a050e9"
      },
      "source": [
        "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
        "from langchain_community.embeddings import OllamaEmbeddings\n",
        "\n",
        "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\") # Using a specific embedding model\n",
        "vectorstore = DocArrayInMemorySearch.from_documents(docs, embedding=embeddings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-11-3392791527.py:4: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
            "  embeddings = OllamaEmbeddings(model=\"nomic-embed-text\") # Using a specific embedding model\n",
            "/usr/local/lib/python3.11/dist-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
            "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using without install nomic-embed-text model in terminal**"
      ],
      "metadata": {
        "id": "B_HhjWB64OHS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22e7237e",
        "outputId": "5fb738b6-4f71-439b-ada8-a28c40f0b609"
      },
      "source": [
        "# Uncomment the following line and run the cell to pull the nomic-embed-text model\n",
        "!ollama pull nomic-embed-text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever=vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "7YsolDVkfdFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "chain = (\n",
        "    {\"context\":itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "\n",
        "| prompt\n",
        "| model\n",
        "| parser\n",
        ")"
      ],
      "metadata": {
        "id": "LVGUeRcvfWTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions=[\n",
        "    \"Define the Two-Phase Locking (2PL) protocol in the context of relational databases\",\n",
        "    #\"Create two multiple choice questions and their answers with three concepts: SQL and Query with EXISTS\",\n",
        "    #\"Create two multiple choice questions and their answers with three concepts: SQL and Query with GROUP BY\",\n",
        "    #\"Create two multiple choice questions and their answers with three concepts: SQL and Query with Join\"\n",
        "    ]\n",
        "for question in questions:\n",
        "    print (f\"Questions:{question}\")\n",
        "    print (f\"Respones: {chain.invoke({'question':question})}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNzk4h9UfiY8",
        "outputId": "a5b5f035-3eaa-4b8a-a2c0-b3592ff86c31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Questions:Define the Two-Phase Locking (2PL) protocol in the context of relational databases\n",
            "Respones: Here is a multiple-choice question based on the provided text:\n",
            "\n",
            "**LEVEL:** Remember\n",
            "**PAGE SOURCE:** 821\n",
            "\n",
            "Question: Define the Two-Phase Locking (2PL) protocol in the context of relational databases.\n",
            "\n",
            "A) A locking mechanism that allows transactions to access shared resources without serializability.\n",
            "B) A concurrency control technique that uses locks to guarantee serializability and prevents other transactions from accessing a locked resource until it is released.\n",
            "C) A protocol that requires all transactions to complete their operations before releasing any locks held during the transaction.\n",
            "D) A method of recovering failed database systems by re-executing previously committed transactions.\n",
            "\n",
            "**Answer:** B) A concurrency control technique that uses locks to guarantee serializability and prevents other transactions from accessing a locked resource until it is released.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate result**"
      ],
      "metadata": {
        "id": "FLQyWN-U2q1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# JSON file has a structure like {\"questions\": [\"question1\", \"question2\", ...]}\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Llama3/question.json\", \"r\") as json_file:\n",
        "    data = json.load(json_file)\n",
        "    questions = data[\"questions\"]\n",
        "\n",
        "for question in questions:\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Respone: {chain.invoke({'question': question})}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "EKUtRQWP2aTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the result to Json file**"
      ],
      "metadata": {
        "id": "KAkdSZNA2nsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Load questions from the existing JSON file\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Llama3/question_Bloom.json\", \"r\") as json_file:\n",
        "    data = json.load(json_file)\n",
        "    questions = data[\"questions\"]\n",
        "\n",
        "# Prepare a list to store the results\n",
        "results = []\n",
        "\n",
        "# Process each question\n",
        "for question in questions:\n",
        "    response = chain.invoke({\"question\": question})\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Response: {response}\")\n",
        "    print()\n",
        "\n",
        "#     results.append({\n",
        "#         \"question\": question,\n",
        "#         \"response\": response\n",
        "#     })\n",
        "\n",
        "# # Save the results to a new JSON file\n",
        "# with open(\"/content/drive/MyDrive/Colab Notebooks/Llama3/question_results.json\", \"w\", encoding=\"utf-8\") as output_file:\n",
        "#     json.dump({\"results\": results}, output_file, ensure_ascii=False, indent=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWjpk6Xa2nKP",
        "outputId": "e7862027-5cdb-48bd-fd43-b3ea1c0b264d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Create six multiple choice question and answer of the question with the Access Control concept\n",
            "Response: Here are six multiple-choice questions based on the Access Control concept:\n",
            "\n",
            "**Level 1: Remember**\n",
            "Question: What is content-based access control in the context of database systems?\n",
            "A) A method to restrict user access to specific data objects\n",
            "B) A way to allow users to create their own access control policies\n",
            "C) A technique that takes into account the protection object's content to determine access control\n",
            "D) A security feature that only works for administrative users\n",
            "\n",
            "Answer: C) A technique that takes into account the protection object's content to determine access control (Page 1155, LEVEL: Remember)\n",
            "\n",
            "**Level 2: Understand**\n",
            "Question: What is a requirement for supporting content-based access control in database systems?\n",
            "A) The ability to create user IDs and passwords\n",
            "B) The need to include conditions based on the object content in access control policies\n",
            "C) The requirement for a central authority to manage access control\n",
            "D) The ability to restrict access to specific data objects\n",
            "\n",
            "Answer: B) The need to include conditions based on the object content in access control policies (Page 1155, LEVEL: Understand)\n",
            "\n",
            "**Level 3: Apply**\n",
            "Question: How can you support content-based access control in a database system?\n",
            "A) By creating user IDs and passwords\n",
            "B) By allowing users to create their own access control policies\n",
            "C) By including conditions based on the object content in access control policies\n",
            "D) By restricting access to specific data objects\n",
            "\n",
            "Answer: C) By including conditions based on the object content in access control policies (Page 1155, LEVEL: Apply)\n",
            "\n",
            "**Level 4: Analyze**\n",
            "Question: Compare and contrast mandatory access control (MAC) and role-based access control (RBAC) for multilevel security. How do they differ?\n",
            "A) MAC is more restrictive than RBAC\n",
            "B) Both MAC and RBAC are used for the same purpose, but with different approaches\n",
            "C) RBAC is a subset of MAC\n",
            "D) MAC is only used for administrative users\n",
            "\n",
            "Answer: B) Both MAC and RBAC are used for the same purpose, but with different approaches (Page 1139, LEVEL: Analyze)\n",
            "\n",
            "**Level 5: Evaluate**\n",
            "Question: How do temporal constraints affect role-based access control (RBAC)?\n",
            "A) Temporal constraints make RBAC more restrictive\n",
            "B) Temporal constraints simplify the implementation of RBAC\n",
            "C) Temporal constraints have no impact on RBAC\n",
            "D) Temporal constraints can lead to security breaches in RBAC\n",
            "\n",
            "Answer: A) Temporal constraints make RBAC more restrictive (Page 1156, LEVEL: Evaluate)\n",
            "\n",
            "**Level 6: Create**\n",
            "Question: Design a hypothetical access control system that integrates content-based access control and role-based access control. What features would you include?\n",
            "A) User authentication and authorization\n",
            "B) Role activation and deactivation based on user characteristics\n",
            "C) Conditions based on object content for accessing specific data objects\n",
            "D) All of the above\n",
            "\n",
            "Answer: D) All of the above (Page 1155, LEVEL: Create)\n",
            "\n",
            "Note: The answers are based on the provided context and may not be exact quotes from the text.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQpuhAjU6oDL",
        "outputId": "6ebfff69-5c7f-4167-920e-2cef6d59d48f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docx\n",
            "  Downloading docx-0.2.4.tar.gz (54 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from docx) (5.4.0)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.11/dist-packages (from docx) (11.2.1)\n",
            "Building wheels for collected packages: docx\n",
            "  Building wheel for docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx: filename=docx-0.2.4-py3-none-any.whl size=53893 sha256=164113330076f12e6295651ec630011af13636d90dba2f9ae22f0b587aae5960\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/3e/c3/e81c11effd0be5658a035947c66792dd993bcff317eae0e1ed\n",
            "Successfully built docx\n",
            "Installing collected packages: docx\n",
            "Successfully installed docx-0.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VafxErfx61f0",
        "outputId": "e43cb830-69e4-4031-8b38-9afc650c1223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.14.1)\n",
            "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/253.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/253.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from docx import Document\n",
        "\n",
        "# Load questions from JSON\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Llama3/question.json\", \"r\") as json_file:\n",
        "    data = json.load(json_file)\n",
        "    questions = data[\"questions\"]\n",
        "\n",
        "# Create a new Word document\n",
        "doc = Document()\n",
        "doc.add_heading('Question & Response Results', 0)\n",
        "\n",
        "# Process each question\n",
        "for question in questions:\n",
        "    single_line_question = question.replace(\"\\n\", \" \").strip()\n",
        "    response = chain.invoke({\"question\": single_line_question})\n",
        "\n",
        "    # Add to the Word document\n",
        "    doc.add_paragraph(f\"Question: {single_line_question}\", style='List Bullet')\n",
        "    doc.add_paragraph(f\"Response: {response}\")\n",
        "    doc.add_paragraph(\"\")  # Add an empty line\n",
        "\n",
        "    #print(f\"Question: {single_line_question}\")\n",
        "    #print(f\"Response: {response}\")\n",
        "    #print()\n",
        "\n",
        "# Save the document\n",
        "doc.save(\"/content/drive/MyDrive/Colab Notebooks/Llama3/question_results.docx\")\n"
      ],
      "metadata": {
        "id": "TH9Ac8DT6lAP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}