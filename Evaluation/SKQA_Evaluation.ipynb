{"cells":[{"cell_type":"code","source":["!pip install langchain-openai\n","!pip install langchain\n","!pip install langchain_community\n","!pip install PyPDF2\n","!pip install openai"],"metadata":{"id":"O8Mfh3EfVJo6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753413236431,"user_tz":-480,"elapsed":20639,"user":{"displayName":"Nguyễn Quốc Việt","userId":"08766828920388171241"}},"outputId":"49a26e08-d2b4-49f1-8bbf-6e76adab44f8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.28)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.68 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.70)\n","Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.97.0)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n","Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.4.8)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (1.33)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (6.0.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (4.14.1)\n","Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (25.0)\n","Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (2.11.7)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.86.0->langchain-openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (2025.7.14)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.0.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.11.0)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.23.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.5.0)\n","Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.70)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n","Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.8)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.1)\n","Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (25.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.7.14)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n","Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.27)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.70)\n","Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.26)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.10.1)\n","Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.8)\n","Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.1)\n","Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.8)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.7)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.14.1)\n","Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (25.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (3.11.0)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.7.14)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.9.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n","Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n","Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.97.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q1QpaJEiA2xW","executionInfo":{"status":"ok","timestamp":1753413329846,"user_tz":-480,"elapsed":2415,"user":{"displayName":"Nguyễn Quốc Việt","userId":"08766828920388171241"}},"outputId":"7b77caad-787a-4c92-f759-b2fff28d17a5"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["#Score each doc's relevance to the generated question and answer:\n","#0.00 - Irrelevant: No relation to the generated question/answer\n","#0.33 - Somewhat relevant: Contains related keywords or concepts\n","#0.66 - Relevant: Partially answers or strongly implies the answer\n","#1.00 - Highly relevant: Directly and fully answers the generated question"],"metadata":{"id":"ELOKdnS7zytc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Final Evaluation code without Bleu score**"],"metadata":{"id":"dyMl8Ak7qeOc"}},{"cell_type":"code","source":["\n","from langchain_openai import ChatOpenAI\n","from langchain.chains import LLMChain\n","from langchain.prompts import PromptTemplate\n","from langchain.evaluation import load_evaluator\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.vectorstores import FAISS\n","import numpy as np\n","import PyPDF2\n","import nltk\n","import re\n","import numpy as np\n","import os\n","import openai\n","from PyPDF2 import PdfReader\n","from sklearn.metrics.pairwise import cosine_similarity\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk import pos_tag\n","from openai import OpenAI\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","\n","os.environ['OPENAI_API_KEY'] = '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'\n","\n","\n","llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n","\n","class ResultScore(BaseModel):\n","    score: float = Field(..., description=\"The score of the result, ranging from 0 to 1 where 1 is the best possible score.\")\n","    explanation: str = Field(..., description=\"An extensive explanation of the score.\")\n","\n","faithfulness_prompt = PromptTemplate(\n","    input_variables=[\"context\", \"question\", \"generated_answer\"],\n","    template=\"\"\"\n","\n","    Context: {context}\n","    Question: {question}\n","    Generated Answer: {generated_answer}\n","\n","    Evaluate if the generated answer are faithful to the context.\n","    If the generated answer cannot be derived from the context, the score should be between 0 and 1. Where 1 is the best possible score.\n","    \"\"\"\n",")\n","\n","faithfulness_chain = faithfulness_prompt | llm.with_structured_output(ResultScore)\n","\n","\n","\n","def extract_pdf_text(pdf_path):\n","    \"\"\"Extracts text from a PDF file.\"\"\"\n","    reader = PdfReader(pdf_path)\n","    text = \"\"\n","    for page in reader.pages:\n","        text += page.extract_text()\n","    return text\n","\n","def evaluate_faithfulness(question, answer, pdf_path):\n","    \"\"\"Evaluates if the generated answer are faithful to the context.\n","\n","    Args:\n","        question: The question.\n","        generated answer: The generated answer.\n","        pdf_path: The path to the PDF file containing the context\n","\n","    Returns:\n","        A float between 0 and 1, where 1 is the best possible score.\n","    \"\"\"\n","    # Extract text from the PDF to use as context\n","    context = extract_pdf_text(pdf_path)\n","\n","\n","    # Use 'question' instead of 'generated_question' to match the prompt template\n","    result = faithfulness_chain.invoke({\n","        \"context\": context,\n","        \"question\": question,\n","        \"generated_answer\": answer\n","    })\n","    return result.score\n","\n","# Initialize the OpenAI client\n","client = OpenAI()\n","\n","# Function to obtain embeddings\n","def get_embeddings(text):\n","    response = client.embeddings.create(\n","        input=[text],\n","        model=\"text-embedding-ada-002\"\n","    )\n","    # Access the embedding from the response object\n","    return response.data[0].embedding\n","\n","def evaluate_answer_relevance(contexts, question, generated_answer):\n","    question_embedding = get_embeddings(question)\n","    answer_embedding = get_embeddings(generated_answer)\n","\n","    question_similarities = []\n","    answer_similarities = []\n","\n","    for context in contexts:\n","        context_embedding = get_embeddings(context)\n","        question_sim = cosine_similarity([question_embedding], [context_embedding])[0][0]\n","        answer_sim = cosine_similarity([answer_embedding], [context_embedding])[0][0]\n","        question_similarities.append(question_sim)\n","        answer_similarities.append(answer_sim)\n","\n","    avg_question_similarity = np.mean(question_similarities)\n","    avg_answer_similarity = np.mean(answer_similarities)\n","    ar_score = (avg_question_similarity + avg_answer_similarity) / 2\n","\n","    return ar_score\n","\n","def extract_text_from_pdf(pdf_file_path):\n","    contexts = []\n","    try:\n","        with open(pdf_file_path, 'rb') as file:\n","            reader = PyPDF2.PdfReader(file)\n","            for page in reader.pages:\n","                text = page.extract_text()\n","                if text:\n","                    contexts.append(text.strip())\n","        return contexts\n","    except Exception as e:\n","        print(f\"Error occurred while extracting text from the PDF: {e}\")\n","        return []\n","\n","def extract_sentences_from_pdf(pdf_path):\n","    text = \"\"\n","    try:\n","        with open(pdf_path, 'rb') as file:\n","            reader = PyPDF2.PdfReader(file)\n","            for page in reader.pages:\n","                page_text = page.extract_text()\n","                if page_text:\n","                    text += page_text\n","                else:\n","                    print(f\"Warning: Text extraction failed for a page.\")\n","    except Exception as e:\n","        print(f\"Error reading PDF file: {e}\")\n","        return []\n","\n","    sentences = sent_tokenize(text)\n","    return sentences\n","\n","def extract_keywords_from_text(text):\n","    stop_words = set(stopwords.words('english'))\n","    words = word_tokenize(text)\n","    tagged_words = pos_tag(words)\n","    keywords = [word.lower() for word, pos in tagged_words\n","                if word.isalnum() and word.lower() not in stop_words and pos.startswith('NN')]\n","    return keywords\n","\n","def determine_relevant_sentences(sentences, generated_question, generated_answer):\n","    question_keywords = set(extract_keywords_from_text(generated_question))\n","    answer_keywords = set(extract_keywords_from_text(generated_answer))\n","    combined_keywords = question_keywords.union(answer_keywords)\n","    relevant_sentences = [sentence for sentence in sentences\n","                          if combined_keywords.intersection(set(extract_keywords_from_text(sentence)))]\n","\n","    return relevant_sentences\n","\n","def compute_context_relevance_score(extracted_sentences, total_sentences_in_context):\n","    if total_sentences_in_context == 0:\n","        return 0\n","    return extracted_sentences / total_sentences_in_context\n","\n","# Integrated function for evaluating all three metrics\n","def evaluate_all_metrics(question, generated_answer, pdf_path):\n","    print(\"Extracting PDF content...\")\n","    contexts = extract_text_from_pdf(pdf_path)\n","\n","    if not contexts:\n","        print(\"No contexts could be extracted from the PDF.\")\n","        return None\n","\n","    # Combine all sentences from the PDF to be used in faithfulness evaluation\n","    context = \" \".join(contexts)\n","\n","    # Step 1: Evaluate Faithfulness Score\n","    #print(\"Evaluating Faithfulness Score...\")\n","    faithfulness_score = evaluate_faithfulness(question, generated_answer, pdf_path)\n","    print(f\"Faithfulness Score: {faithfulness_score}\")\n","\n","    # Step 2: Evaluate Answer Relevance Score\n","    #print(\"Evaluating Answer Relevance Score...\")\n","    ar_score = evaluate_answer_relevance(contexts, question, generated_answer)\n","    print(f\"Answer Relevance Score: {ar_score}\")\n","\n","    # Step 3: Evaluate Context Relevance Score\n","    #print(\"Evaluating Context Relevance Score...\")\n","    sentences = extract_sentences_from_pdf(pdf_path)\n","    if sentences:\n","        relevant_sentences = determine_relevant_sentences(sentences, question, generated_answer)\n","        total_sentences_in_context = len(sentences)\n","        extracted_sentences = len(relevant_sentences)\n","        cr_score = compute_context_relevance_score(extracted_sentences, total_sentences_in_context)\n","        #print(f\"Total senctences in context: {total_sentences_in_context}\")\n","        #print(f\"Total extracted sentences: {extracted_sentences}\")\n","        #print(f\"Relevant sentences: {relevant_sentences}\")\n","        print(f\"Context Relevance Score: {cr_score:.2f}\")\n","    else:\n","        cr_score = 0\n","        print(\"No sentences extracted from the PDF for Context Relevance Score.\")\n","\n","    # Return all scores\n","    return {\n","        \"Faithfulness Score\": faithfulness_score,\n","        \"Answer Relevance Score\": ar_score,\n","        \"Context Relevance Score\": cr_score\n","    }\n","\n","# Example Usage\n","pdf_file_path = '/content/delete.pdf'\n","question = \"Create gap filling question with DELETE command in relational database\"\n","generated_answer = \"The DELETE command removes tuples from a relation. It includes a WHERE clause, similar to that used in an SQL query, to select the tuples to be deleted. Tuples are explicitly deleted from only one table at a time. However, the deletion may propagate to tuples in other relations if ________ are specified in the referential integrity constraints of the DDL.\"\n","results = evaluate_all_metrics(question, generated_answer, pdf_file_path)\n","print(\"Evaluation Results:\", results)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fUT2-UYVpoZ9","executionInfo":{"status":"ok","timestamp":1725609311481,"user_tz":-480,"elapsed":2586,"user":{"displayName":"Nguyễn Quốc Việt","userId":"08766828920388171241"}},"outputId":"806cdae0-3515-4331-d2b2-49a197104509"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]},{"output_type":"stream","name":"stdout","text":["Extracting PDF content...\n","Faithfulness Score: 1.0\n","Answer Relevance Score: 0.8745317426349858\n","Context Relevance Score: 1.00\n","Evaluation Results: {'Faithfulness Score': 1.0, 'Answer Relevance Score': 0.8745317426349858, 'Context Relevance Score': 1.0}\n"]}]},{"cell_type":"markdown","source":["**Final Evaluation Code with Blue score**"],"metadata":{"id":"Qhrab3Vx-tBZ"}},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","from langchain.chains import LLMChain\n","from langchain.prompts import PromptTemplate\n","from langchain.evaluation import load_evaluator\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.vectorstores import FAISS\n","import numpy as np\n","import PyPDF2\n","import nltk\n","import re\n","import numpy as np\n","import os\n","import openai\n","from PyPDF2 import PdfReader\n","from sklearn.metrics.pairwise import cosine_similarity\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk import pos_tag\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from openai import OpenAI\n","\n","# Download required NLTK data\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('punkt_tab') # Download punkt_tab resource\n","nltk.download('averaged_perceptron_tagger_eng') # Download the correct resource\n","\n","# Set API key\n","os.environ['OPENAI_API_KEY'] = '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'\n","\n","# Initialize LLM\n","llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n","\n","# Define result schema\n","class ResultScore(BaseModel):\n","    score: float = Field(..., description=\"The score of the result, ranging from 0 to 1 where 1 is the best possible score.\")\n","    explanation: str = Field(..., description=\"An extensive explanation of the score.\")\n","\n","# Prompt template for faithfulness\n","faithfulness_prompt = PromptTemplate(\n","    input_variables=[\"context\", \"question\", \"generated_answer\"],\n","    template=\"\"\"\n","    Context: {context}\n","    Question: {question}\n","    Generated Answer: {generated_answer}\n","\n","    Evaluate if the generated answer is faithful to the context.\n","    If the generated answer cannot be derived from the context, the score should be between 0 and 1. Where 1 is the best possible score.\n","    \"\"\"\n",")\n","\n","faithfulness_chain = faithfulness_prompt | llm.with_structured_output(ResultScore)\n","\n","# PDF text extractor\n","def extract_pdf_text(pdf_path):\n","    reader = PdfReader(pdf_path)\n","    text = \"\"\n","    for page in reader.pages:\n","        text += page.extract_text()\n","    return text\n","\n","def evaluate_faithfulness(question, answer, pdf_path):\n","    context = extract_pdf_text(pdf_path)\n","    result = faithfulness_chain.invoke({\n","        \"context\": context,\n","        \"question\": question,\n","        \"generated_answer\": answer\n","    })\n","    return result.score\n","\n","# Initialize OpenAI client\n","client = OpenAI()\n","\n","# Get embeddings\n","def get_embeddings(text):\n","    response = client.embeddings.create(\n","        input=[text],\n","        model=\"text-embedding-ada-002\"\n","    )\n","    return response.data[0].embedding\n","\n","# Compute cosine similarity-based relevance\n","def evaluate_answer_relevance(contexts, question, generated_answer):\n","    question_embedding = get_embeddings(question)\n","    answer_embedding = get_embeddings(generated_answer)\n","    question_similarities = []\n","    answer_similarities = []\n","    for context in contexts:\n","        context_embedding = get_embeddings(context)\n","        question_sim = cosine_similarity([question_embedding], [context_embedding])[0][0]\n","        answer_sim = cosine_similarity([answer_embedding], [context_embedding])[0][0]\n","        question_similarities.append(question_sim)\n","        answer_similarities.append(answer_sim)\n","    avg_question_similarity = np.mean(question_similarities)\n","    avg_answer_similarity = np.mean(answer_similarities)\n","    return (avg_question_similarity + avg_answer_similarity) / 2\n","\n","# Extract text from PDF as list\n","def extract_text_from_pdf(pdf_file_path):\n","    contexts = []\n","    try:\n","        with open(pdf_file_path, 'rb') as file:\n","            reader = PyPDF2.PdfReader(file)\n","            for page in reader.pages:\n","                text = page.extract_text()\n","                if text:\n","                    contexts.append(text.strip())\n","        return contexts\n","    except Exception as e:\n","        print(f\"Error occurred while extracting text from the PDF: {e}\")\n","        return []\n","\n","# Sentence extraction\n","def extract_sentences_from_pdf(pdf_path):\n","    text = \"\"\n","    try:\n","        with open(pdf_path, 'rb') as file:\n","            reader = PyPDF2.PdfReader(file)\n","            for page in reader.pages:\n","                page_text = page.extract_text()\n","                if page_text:\n","                    text += page_text\n","    except Exception as e:\n","        print(f\"Error reading PDF file: {e}\")\n","        return []\n","    return sent_tokenize(text)\n","\n","# Extract keywords (nouns) from text\n","def extract_keywords_from_text(text):\n","    stop_words = set(stopwords.words('english'))\n","    words = word_tokenize(text)\n","    tagged_words = pos_tag(words)\n","    return [word.lower() for word, pos in tagged_words\n","            if word.isalnum() and word.lower() not in stop_words and pos.startswith('NN')]\n","\n","# Determine relevance by keyword overlap\n","def determine_relevant_sentences(sentences, generated_question, generated_answer):\n","    question_keywords = set(extract_keywords_from_text(generated_question))\n","    answer_keywords = set(extract_keywords_from_text(generated_answer))\n","    combined_keywords = question_keywords.union(answer_keywords)\n","    return [sentence for sentence in sentences\n","            if combined_keywords.intersection(set(extract_keywords_from_text(sentence)))]\n","\n","# Score based on context sentence ratio\n","def compute_context_relevance_score(extracted_sentences, total_sentences_in_context):\n","    if total_sentences_in_context == 0:\n","        return 0\n","    return extracted_sentences / total_sentences_in_context\n","\n","# NEW: BLEU Score Evaluation\n","def evaluate_bleu_score(reference_answer, generated_answer):\n","    reference_tokens = [word_tokenize(reference_answer.lower())]\n","    generated_tokens = word_tokenize(generated_answer.lower())\n","    smoothing = SmoothingFunction().method1\n","    bleu = sentence_bleu(reference_tokens, generated_tokens, smoothing_function=smoothing)\n","    return bleu\n","\n","# Master Evaluation Function\n","def evaluate_all_metrics(question, generated_answer, pdf_path, reference_answer):\n","    print(\"Extracting PDF content...\")\n","    contexts = extract_text_from_pdf(pdf_path)\n","    if not contexts:\n","        print(\"No contexts could be extracted from the PDF.\")\n","        return None\n","    context = \" \".join(contexts)\n","    print(contexts)\n","\n","    #print(\"Evaluating Faithfulness Score...\")\n","    faithfulness_score = evaluate_faithfulness(question, generated_answer, pdf_path)\n","    print(f\"Faithfulness Score: {faithfulness_score:.4f}\")\n","\n","    #print(\"Evaluating Answer Relevance Score...\")\n","    ar_score = evaluate_answer_relevance(contexts, question, generated_answer)\n","    print(f\"Answer Relevance Score: {ar_score:.4f}\")\n","\n","    #print(\"Evaluating Context Relevance Score...\")\n","    sentences = extract_sentences_from_pdf(pdf_path)\n","    if sentences:\n","        relevant_sentences = determine_relevant_sentences(sentences, question, generated_answer)\n","        cr_score = compute_context_relevance_score(len(relevant_sentences), len(sentences))\n","        print(f\"Context Relevance Score: {cr_score:.4f}\")\n","    else:\n","        cr_score = 0\n","        print(\"No sentences extracted from the PDF for Context Relevance Score.\")\n","\n","    #print(\"Evaluating BLEU Score...\")\n","    bleu_score = evaluate_bleu_score(reference_answer, generated_answer)\n","    print(f\"BLEU Score: {bleu_score:.4f}\")\n","\n","    return {\n","        \"Faithfulness Score\": faithfulness_score,\n","        \"Answer Relevance Score\": ar_score,\n","        \"Context Relevance Score\": cr_score,\n","        \"BLEU Score\": bleu_score\n","    }\n","\n","# Example Usage\n","pdf_file_path = '/content/drive/MyDrive/Colab Notebooks/SKQA_Evaluation/delete.pdf'\n","question = \"What is the delete commnand in SQL\"\n","generated_answer = \"The DELETE command removes tuples from a relation using a WHERE clause. If cascading is specified in the referential integrity constraints, the deletion may affect other relations\"\n","reference_answer = \"The DELETE command removes tuples from a relation using a WHERE clause. If cascading is specified in the referential integrity constraints, the deletion may affect other relations.\"\n","\n","results = evaluate_all_metrics(question, generated_answer, pdf_file_path, reference_answer)\n","print(\"Evaluation Results:\", results)"],"metadata":{"id":"Y1AF7L-y-sZs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752551958659,"user_tz":-420,"elapsed":4326,"user":{"displayName":"Nguyễn Quốc Việt","userId":"08766828920388171241"}},"outputId":"8700be30-87bd-40dc-a092-7fd96e13c154"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n","/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1844: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Extracting PDF content...\n","['The DELETE command in SQL is used to remove one or more tuples (rows) from a relation (table). It \\ntypically includes a WHERE clause to specify which tuples should be deleted based on certain conditions. \\nIf the WHERE clause is omitted, all tuples in the tab le will be deleted.']\n","Faithfulness Score: 0.7000\n","Answer Relevance Score: 0.8977\n","Context Relevance Score: 1.0000\n","BLEU Score: 0.9661\n","Evaluation Results: {'Faithfulness Score': 0.7, 'Answer Relevance Score': np.float64(0.8977295598641778), 'Context Relevance Score': 1.0, 'BLEU Score': 0.9661049965255963}\n"]}]},{"cell_type":"markdown","source":["**Evaluation Faithfulness with CSV file**"],"metadata":{"id":"_e_uJDEAOCtK"}},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","from langchain.chains import LLMChain\n","from langchain.prompts import PromptTemplate\n","from langchain.evaluation import load_evaluator\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.vectorstores import FAISS\n","import numpy as np\n","import PyPDF2\n","import nltk\n","import re\n","import numpy as np\n","import os\n","import openai\n","from PyPDF2 import PdfReader\n","from sklearn.metrics.pairwise import cosine_similarity\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk import pos_tag\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from openai import OpenAI\n","\n","# Download required NLTK data\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('punkt_tab') # Download punkt_tab resource\n","nltk.download('averaged_perceptron_tagger_eng') # Download the correct resource\n","\n","# Set API key\n","os.environ['OPENAI_API_KEY'] = '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'\n","\n","# Set up LLM and embedding model\n","llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n","client = OpenAI()\n","\n","# Score model schema\n","class ResultScore(BaseModel):\n","    score: float = Field(..., description=\"The score of the result, ranging from 0 to 1 where 1 is the best possible score.\")\n","    explanation: str = Field(..., description=\"An extensive explanation of the score.\")\n","\n","# Prompt for faithfulness\n","faithfulness_prompt = PromptTemplate(\n","    input_variables=[\"context\", \"question\", \"generated_answer\"],\n","    template=\"\"\"\n","    Context: {context}\n","    Question: {question}\n","    Generated Answer: {generated_answer}\n","\n","    Evaluate if the generated answer is faithful to the context.\n","    Return a score between 0 and 1, where 1 is the best possible.\n","    \"\"\"\n",")\n","faithfulness_chain = faithfulness_prompt | llm.with_structured_output(ResultScore)\n","\n","# Get text embedding\n","def get_embeddings(text):\n","    response = client.embeddings.create(input=[text], model=\"text-embedding-ada-002\")\n","    return response.data[0].embedding\n","\n","# Load context from CSV\n","def load_contexts_from_csv(csv_path, column_name=\"context\"):\n","    try:\n","        df = pd.read_csv(csv_path)\n","        contexts = df[column_name].dropna().tolist()\n","        return contexts\n","    except Exception as e:\n","        print(f\"Failed to load CSV: {e}\")\n","        return []\n","\n","# Faithfulness\n","def evaluate_faithfulness(question, answer, context):\n","    result = faithfulness_chain.invoke({\n","        \"context\": context,\n","        \"question\": question,\n","        \"generated_answer\": answer\n","    })\n","    return result.score\n","\n","# Relevance\n","def evaluate_answer_relevance(contexts, question, generated_answer):\n","    question_embedding = get_embeddings(question)\n","    answer_embedding = get_embeddings(generated_answer)\n","\n","    question_similarities = []\n","    answer_similarities = []\n","\n","    for context in contexts:\n","        context_embedding = get_embeddings(context)\n","        question_sim = cosine_similarity([question_embedding], [context_embedding])[0][0]\n","        answer_sim = cosine_similarity([answer_embedding], [context_embedding])[0][0]\n","        question_similarities.append(question_sim)\n","        answer_similarities.append(answer_sim)\n","\n","    avg_question_similarity = np.mean(question_similarities)\n","    avg_answer_similarity = np.mean(answer_similarities)\n","    return (avg_question_similarity + avg_answer_similarity) / 2\n","\n","# Keyword extraction\n","def extract_keywords(text):\n","    stop_words = set(stopwords.words('english'))\n","    words = word_tokenize(text)\n","    tagged_words = pos_tag(words)\n","    return [word.lower() for word, pos in tagged_words if word.isalnum() and word.lower() not in stop_words and pos.startswith('NN')]\n","\n","# Context relevance\n","def determine_relevant_sentences(contexts, question, answer):\n","    q_keywords = set(extract_keywords(question))\n","    a_keywords = set(extract_keywords(answer))\n","    combined = q_keywords.union(a_keywords)\n","    matched = [s for s in contexts if combined.intersection(set(extract_keywords(s)))]\n","    return matched\n","\n","def compute_context_relevance_score(matched_sentences, total_sentences):\n","    if total_sentences == 0:\n","        return 0\n","    return len(matched_sentences) / total_sentences\n","\n","# Final Evaluation Function\n","def evaluate_all_metrics_csv(csv_path, question, answer, context_column=\"context\"):\n","    contexts = load_contexts_from_csv(csv_path, context_column)\n","    if not contexts:\n","        print(\"No context found.\")\n","        return None\n","\n","    combined_context = \" \".join(contexts)\n","\n","    print(\"Evaluating Faithfulness...\")\n","    faithfulness_score = evaluate_faithfulness(question, answer, combined_context)\n","    print(f\"Faithfulness Score: {faithfulness_score:.2f}\")\n","\n","    print(\"Evaluating Relevance...\")\n","    ar_score = evaluate_answer_relevance(contexts, question, answer)\n","    print(f\"Answer Relevance Score: {ar_score:.2f}\")\n","\n","    print(\"Evaluating Context Relevance...\")\n","    matched = determine_relevant_sentences(contexts, question, answer)\n","    cr_score = compute_context_relevance_score(matched, len(contexts))\n","    print(f\"Context Relevance Score: {cr_score:.2f}\")\n","\n","    return {\n","        \"Faithfulness Score\": faithfulness_score,\n","        \"Answer Relevance Score\": ar_score,\n","        \"Context Relevance Score\": cr_score\n","    }\n","\n","# Example Usage\n","csv_file_path = '/content/drive/MyDrive/Colab Notebooks/SKQA_Evaluation/context.csv'\n","question = \"create a multiple choice question and their answer for discretionary access control (DAC) in the context of relational databases\"\n","generated_answer = \"Define discretionary access control (DAC) in the context of relational databases. Answer: C) DAC is a mechanism that grants and revokes privileges based on user discretion\"\n","\n","results = evaluate_all_metrics_csv(csv_file_path, question, generated_answer)\n","print(\"Evaluation Results:\", results)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VoOEa68bOBTW","executionInfo":{"status":"ok","timestamp":1752564937280,"user_tz":-420,"elapsed":16494,"user":{"displayName":"Nguyễn Quốc Việt","userId":"08766828920388171241"}},"outputId":"eff4934b-1d08-4e2d-abe9-05d1543cd91a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n","\n","For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n","with: `from pydantic import BaseModel`\n","or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n","\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Failed to load CSV: name 'pd' is not defined\n","No context found.\n","Evaluation Results: None\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1844: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["**Evaluation Faithful and save to csv file (worked)**"],"metadata":{"id":"YsbiT2fSAuB_"}},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","from langchain.chains import LLMChain\n","from langchain.prompts import PromptTemplate\n","from langchain.evaluation import load_evaluator\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.vectorstores import FAISS\n","import numpy as np\n","import pandas as pd\n","import PyPDF2\n","import nltk\n","import re\n","import numpy as np\n","import os\n","import openai\n","from PyPDF2 import PdfReader\n","from sklearn.metrics.pairwise import cosine_similarity\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk import pos_tag\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from openai import OpenAI\n","\n","# Download required NLTK data\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('punkt_tab') # Download punkt_tab resource\n","nltk.download('averaged_perceptron_tagger_eng') # Download the correct resource\n","\n","# Set API key\n","os.environ['OPENAI_API_KEY'] = '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'\n","\n","# Initialize models\n","llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n","client = OpenAI()\n","\n","# Pydantic model for structured output\n","class ResultScore(BaseModel):\n","    score: float = Field(..., description=\"Score from 0 to 1\")\n","    explanation: str = Field(..., description=\"Explanation of the score\")\n","\n","# Prompt for evaluating faithfulness\n","faithfulness_prompt = PromptTemplate(\n","    input_variables=[\"context\", \"question\", \"generated_answer\"],\n","    template=\"\"\"\n","    Context: {context}\n","    Question: {question}\n","    Generated Answer: {generated_answer}\n","\n","    Evaluate if the generated answer is faithful to the context.\n","    Return a score from 0 to 1 where 1 is fully faithful.\n","    \"\"\"\n",")\n","faithfulness_chain = faithfulness_prompt | llm.with_structured_output(ResultScore)\n","\n","# Embedding\n","def get_embeddings(text):\n","    response = client.embeddings.create(input=[text], model=\"text-embedding-ada-002\")\n","    return response.data[0].embedding\n","\n","# Extract keywords for context relevance\n","def extract_keywords(text):\n","    stop_words = set(stopwords.words('english'))\n","    words = word_tokenize(text)\n","    tagged_words = pos_tag(words)\n","    return [word.lower() for word, pos in tagged_words if word.isalnum() and word.lower() not in stop_words and pos.startswith('NN')]\n","\n","# Evaluate relevance between answer/question and context\n","def evaluate_answer_relevance(context, question, answer):\n","    question_embedding = get_embeddings(question)\n","    answer_embedding = get_embeddings(answer)\n","    context_embedding = get_embeddings(context)\n","\n","    question_sim = cosine_similarity([question_embedding], [context_embedding])[0][0]\n","    answer_sim = cosine_similarity([answer_embedding], [context_embedding])[0][0]\n","\n","    return (question_sim + answer_sim) / 2\n","\n","# Find context-relevant sentences\n","def determine_relevance_score(context, question, answer):\n","    q_keywords = set(extract_keywords(question))\n","    a_keywords = set(extract_keywords(answer))\n","    combined_keywords = q_keywords.union(a_keywords)\n","\n","    sentences = nltk.sent_tokenize(context)\n","    matched = [s for s in sentences if combined_keywords.intersection(set(extract_keywords(s)))]\n","\n","    if not sentences:\n","        return 0\n","    return len(matched) / len(sentences)\n","\n","# Main evaluation function\n","def evaluate_all_metrics(question, answer, context):\n","    faithfulness = evaluate_faithfulness(question, answer, context)\n","    ar_score = evaluate_answer_relevance(context, question, answer)\n","    cr_score = determine_relevance_score(context, question, answer)\n","\n","    return {\n","        \"Faithfulness Score\": faithfulness,\n","        \"Answer Relevance Score\": ar_score,\n","        \"Context Relevance Score\": cr_score\n","    }\n","\n","def evaluate_faithfulness(question, answer, context):\n","    result = faithfulness_chain.invoke({\n","        \"context\": context,\n","        \"question\": question,\n","        \"generated_answer\": answer\n","    })\n","    return result.score\n","\n","# Read CSV and evaluate each row\n","def evaluate_from_csv(csv_path, output_path=None):\n","    df = pd.read_csv(csv_path,encoding='utf-8-sig')\n","\n","    scores = []\n","    for idx, row in df.iterrows():\n","        question = row['question']\n","        answer = row['generated_answer']\n","        context = row['context']\n","\n","        print(f\"\\nEvaluating Row {idx+1}...\")\n","        result = evaluate_all_metrics(question, answer, context)\n","\n","        scores.append({\n","            \"question\": question,\n","            \"generated_answer\": answer,\n","            \"Faithfulness Score\": result[\"Faithfulness Score\"],\n","            \"Answer Relevance Score\": result[\"Answer Relevance Score\"],\n","            \"Context Relevance Score\": result[\"Context Relevance Score\"]\n","        })\n","\n","    results_df = pd.DataFrame(scores)\n","\n","    if output_path:\n","        results_df.to_csv(output_path, index=False)\n","        print(f\"\\nResults saved to: {output_path}\")\n","\n","    return results_df\n","\n","# Example usage\n","csv_input = '/content/drive/MyDrive/Colab Notebooks/SKQA_Evaluation/urs2.csv'           # CSV must have: question, generated_answer, context\n","csv_output = '/content/drive/MyDrive/Colab Notebooks/SKQA_Evaluation/evaluation_results_ours.csv'  # Optional save path\n","\n","df_results = evaluate_from_csv(csv_input, csv_output)\n","#print(df_results)\n"],"metadata":{"id":"ISP9mmMHP76O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Only Faithfulness**"],"metadata":{"id":"HKPrWnkoupVY"}},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","from langchain.chains import LLMChain\n","from langchain.prompts import PromptTemplate\n","from langchain.evaluation import load_evaluator\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.vectorstores import FAISS\n","import numpy as np\n","import pandas as pd\n","import PyPDF2\n","import nltk\n","import re\n","import numpy as np\n","import os\n","import openai\n","from PyPDF2 import PdfReader\n","from sklearn.metrics.pairwise import cosine_similarity\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk import pos_tag\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from openai import OpenAI\n","import pandas as pd\n","from langchain_openai import ChatOpenAI\n","from langchain.prompts import PromptTemplate\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","\n","os.environ['OPENAI_API_KEY'] = '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'\n","\n","\n","# Initialize LLM\n","llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n","\n","# Pydantic model for structured result\n","class ResultScore(BaseModel):\n","    score: float = Field(..., description=\"Score from 0 to 1\")\n","    explanation: str = Field(..., description=\"Explanation of the score\")\n","\n","# Faithfulness prompt\n","faithfulness_prompt = PromptTemplate(\n","    input_variables=[\"context\", \"question\", \"generated_answer\"],\n","    template=\"\"\"\n","    Context: {context}\n","    Question: {question}\n","    Generated Answer: {generated_answer}\n","\n","    Evaluate if the generated answer is faithful to the context.\n","    Return a score from 0 to 1 where 1 is fully faithful.\n","    \"\"\"\n",")\n","faithfulness_chain = faithfulness_prompt | llm.with_structured_output(ResultScore)\n","\n","# Faithfulness evaluation\n","def evaluate_faithfulness(question, answer, context):\n","    result = faithfulness_chain.invoke({\n","        \"context\": context,\n","        \"question\": question,\n","        \"generated_answer\": answer\n","    })\n","    return result.score\n","\n","# Only evaluate faithfulness from CSV\n","def evaluate_from_csv(csv_path, output_path=None):\n","    df = pd.read_csv(csv_path, encoding='utf-8-sig')\n","    scores = []\n","\n","    for idx, row in df.iterrows():\n","        question = row['question']\n","        answer = row['generated_answer']\n","        context = row['context']\n","\n","        print(f\"\\nEvaluating Row {idx + 1}...\")\n","        faithfulness_score = evaluate_faithfulness(question, answer, context)\n","\n","        scores.append({\n","            \"question\": question,\n","            \"generated_answer\": answer,\n","            \"Faithfulness Score\": faithfulness_score\n","        })\n","\n","    results_df = pd.DataFrame(scores)\n","\n","    if output_path:\n","        results_df.to_csv(output_path, index=False)\n","        print(f\"\\nResults saved to: {output_path}\")\n","\n","    return results_df\n","\n","# Example usage\n","csv_input = '/content/drive/MyDrive/Colab Notebooks/SKQA_Evaluation/Mistral_RAG.csv'\n","csv_output = '/content/drive/MyDrive/Colab Notebooks/SKQA_Evaluation/evaluation_Mistral_RAG.csv'\n","\n","df_results = evaluate_from_csv(csv_input, csv_output)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1_NYtYE8uoQF","executionInfo":{"status":"ok","timestamp":1753410584705,"user_tz":-480,"elapsed":1498853,"user":{"displayName":"Nguyễn Quốc Việt","userId":"08766828920388171241"}},"outputId":"e74efb5c-2f9a-4cda-d2c7-d8244f5c4772"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1844: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evaluating Row 1...\n","\n","Evaluating Row 2...\n","\n","Evaluating Row 3...\n","\n","Evaluating Row 4...\n","\n","Evaluating Row 5...\n","\n","Evaluating Row 6...\n","\n","Evaluating Row 7...\n","\n","Evaluating Row 8...\n","\n","Evaluating Row 9...\n","\n","Evaluating Row 10...\n","\n","Evaluating Row 11...\n","\n","Evaluating Row 12...\n","\n","Evaluating Row 13...\n","\n","Evaluating Row 14...\n","\n","Evaluating Row 15...\n","\n","Evaluating Row 16...\n","\n","Evaluating Row 17...\n","\n","Evaluating Row 18...\n","\n","Evaluating Row 19...\n","\n","Evaluating Row 20...\n","\n","Evaluating Row 21...\n","\n","Evaluating Row 22...\n","\n","Evaluating Row 23...\n","\n","Evaluating Row 24...\n","\n","Evaluating Row 25...\n","\n","Evaluating Row 26...\n","\n","Evaluating Row 27...\n","\n","Evaluating Row 28...\n","\n","Evaluating Row 29...\n","\n","Evaluating Row 30...\n","\n","Evaluating Row 31...\n","\n","Evaluating Row 32...\n","\n","Evaluating Row 33...\n","\n","Evaluating Row 34...\n","\n","Evaluating Row 35...\n","\n","Evaluating Row 36...\n","\n","Evaluating Row 37...\n","\n","Evaluating Row 38...\n","\n","Evaluating Row 39...\n","\n","Evaluating Row 40...\n","\n","Evaluating Row 41...\n","\n","Evaluating Row 42...\n","\n","Evaluating Row 43...\n","\n","Evaluating Row 44...\n","\n","Evaluating Row 45...\n","\n","Evaluating Row 46...\n","\n","Evaluating Row 47...\n","\n","Evaluating Row 48...\n","\n","Evaluating Row 49...\n","\n","Evaluating Row 50...\n","\n","Evaluating Row 51...\n","\n","Evaluating Row 52...\n","\n","Evaluating Row 53...\n","\n","Evaluating Row 54...\n","\n","Evaluating Row 55...\n","\n","Evaluating Row 56...\n","\n","Evaluating Row 57...\n","\n","Evaluating Row 58...\n","\n","Evaluating Row 59...\n","\n","Evaluating Row 60...\n","\n","Evaluating Row 61...\n","\n","Evaluating Row 62...\n","\n","Evaluating Row 63...\n","\n","Evaluating Row 64...\n","\n","Evaluating Row 65...\n","\n","Evaluating Row 66...\n","\n","Evaluating Row 67...\n","\n","Evaluating Row 68...\n","\n","Evaluating Row 69...\n","\n","Evaluating Row 70...\n","\n","Evaluating Row 71...\n","\n","Evaluating Row 72...\n","\n","Evaluating Row 73...\n","\n","Evaluating Row 74...\n","\n","Evaluating Row 75...\n","\n","Evaluating Row 76...\n","\n","Evaluating Row 77...\n","\n","Evaluating Row 78...\n","\n","Evaluating Row 79...\n","\n","Evaluating Row 80...\n","\n","Evaluating Row 81...\n","\n","Evaluating Row 82...\n","\n","Evaluating Row 83...\n","\n","Evaluating Row 84...\n","\n","Evaluating Row 85...\n","\n","Evaluating Row 86...\n","\n","Evaluating Row 87...\n","\n","Evaluating Row 88...\n","\n","Evaluating Row 89...\n","\n","Evaluating Row 90...\n","\n","Evaluating Row 91...\n","\n","Evaluating Row 92...\n","\n","Evaluating Row 93...\n","\n","Evaluating Row 94...\n","\n","Evaluating Row 95...\n","\n","Evaluating Row 96...\n","\n","Evaluating Row 97...\n","\n","Evaluating Row 98...\n","\n","Evaluating Row 99...\n","\n","Evaluating Row 100...\n","\n","Evaluating Row 101...\n","\n","Evaluating Row 102...\n","\n","Evaluating Row 103...\n","\n","Evaluating Row 104...\n","\n","Evaluating Row 105...\n","\n","Evaluating Row 106...\n","\n","Evaluating Row 107...\n","\n","Evaluating Row 108...\n","\n","Evaluating Row 109...\n","\n","Evaluating Row 110...\n","\n","Evaluating Row 111...\n","\n","Evaluating Row 112...\n","\n","Evaluating Row 113...\n","\n","Evaluating Row 114...\n","\n","Evaluating Row 115...\n","\n","Evaluating Row 116...\n","\n","Evaluating Row 117...\n","\n","Evaluating Row 118...\n","\n","Evaluating Row 119...\n","\n","Evaluating Row 120...\n","\n","Evaluating Row 121...\n","\n","Evaluating Row 122...\n","\n","Evaluating Row 123...\n","\n","Evaluating Row 124...\n","\n","Evaluating Row 125...\n","\n","Evaluating Row 126...\n","\n","Evaluating Row 127...\n","\n","Evaluating Row 128...\n","\n","Evaluating Row 129...\n","\n","Evaluating Row 130...\n","\n","Evaluating Row 131...\n","\n","Evaluating Row 132...\n","\n","Evaluating Row 133...\n","\n","Evaluating Row 134...\n","\n","Evaluating Row 135...\n","\n","Evaluating Row 136...\n","\n","Evaluating Row 137...\n","\n","Evaluating Row 138...\n","\n","Evaluating Row 139...\n","\n","Evaluating Row 140...\n","\n","Evaluating Row 141...\n","\n","Evaluating Row 142...\n","\n","Evaluating Row 143...\n","\n","Evaluating Row 144...\n","\n","Evaluating Row 145...\n","\n","Evaluating Row 146...\n","\n","Evaluating Row 147...\n","\n","Evaluating Row 148...\n","\n","Evaluating Row 149...\n","\n","Evaluating Row 150...\n","\n","Evaluating Row 151...\n","\n","Evaluating Row 152...\n","\n","Evaluating Row 153...\n","\n","Evaluating Row 154...\n","\n","Evaluating Row 155...\n","\n","Evaluating Row 156...\n","\n","Evaluating Row 157...\n","\n","Evaluating Row 158...\n","\n","Evaluating Row 159...\n","\n","Evaluating Row 160...\n","\n","Evaluating Row 161...\n","\n","Evaluating Row 162...\n","\n","Evaluating Row 163...\n","\n","Evaluating Row 164...\n","\n","Evaluating Row 165...\n","\n","Evaluating Row 166...\n","\n","Evaluating Row 167...\n","\n","Evaluating Row 168...\n","\n","Evaluating Row 169...\n","\n","Evaluating Row 170...\n","\n","Evaluating Row 171...\n","\n","Evaluating Row 172...\n","\n","Evaluating Row 173...\n","\n","Evaluating Row 174...\n","\n","Evaluating Row 175...\n","\n","Evaluating Row 176...\n","\n","Evaluating Row 177...\n","\n","Evaluating Row 178...\n","\n","Evaluating Row 179...\n","\n","Evaluating Row 180...\n","\n","Evaluating Row 181...\n","\n","Evaluating Row 182...\n","\n","Evaluating Row 183...\n","\n","Evaluating Row 184...\n","\n","Evaluating Row 185...\n","\n","Evaluating Row 186...\n","\n","Evaluating Row 187...\n","\n","Evaluating Row 188...\n","\n","Evaluating Row 189...\n","\n","Evaluating Row 190...\n","\n","Evaluating Row 191...\n","\n","Evaluating Row 192...\n","\n","Evaluating Row 193...\n","\n","Evaluating Row 194...\n","\n","Evaluating Row 195...\n","\n","Evaluating Row 196...\n","\n","Evaluating Row 197...\n","\n","Evaluating Row 198...\n","\n","Evaluating Row 199...\n","\n","Evaluating Row 200...\n","\n","Evaluating Row 201...\n","\n","Evaluating Row 202...\n","\n","Evaluating Row 203...\n","\n","Evaluating Row 204...\n","\n","Evaluating Row 205...\n","\n","Evaluating Row 206...\n","\n","Evaluating Row 207...\n","\n","Evaluating Row 208...\n","\n","Evaluating Row 209...\n","\n","Evaluating Row 210...\n","\n","Evaluating Row 211...\n","\n","Evaluating Row 212...\n","\n","Evaluating Row 213...\n","\n","Evaluating Row 214...\n","\n","Evaluating Row 215...\n","\n","Evaluating Row 216...\n","\n","Evaluating Row 217...\n","\n","Evaluating Row 218...\n","\n","Evaluating Row 219...\n","\n","Evaluating Row 220...\n","\n","Evaluating Row 221...\n","\n","Evaluating Row 222...\n","\n","Evaluating Row 223...\n","\n","Evaluating Row 224...\n","\n","Evaluating Row 225...\n","\n","Evaluating Row 226...\n","\n","Evaluating Row 227...\n","\n","Evaluating Row 228...\n","\n","Evaluating Row 229...\n","\n","Evaluating Row 230...\n","\n","Evaluating Row 231...\n","\n","Evaluating Row 232...\n","\n","Evaluating Row 233...\n","\n","Evaluating Row 234...\n","\n","Evaluating Row 235...\n","\n","Evaluating Row 236...\n","\n","Evaluating Row 237...\n","\n","Evaluating Row 238...\n","\n","Evaluating Row 239...\n","\n","Evaluating Row 240...\n","\n","Evaluating Row 241...\n","\n","Evaluating Row 242...\n","\n","Evaluating Row 243...\n","\n","Evaluating Row 244...\n","\n","Evaluating Row 245...\n","\n","Evaluating Row 246...\n","\n","Evaluating Row 247...\n","\n","Evaluating Row 248...\n","\n","Evaluating Row 249...\n","\n","Evaluating Row 250...\n","\n","Evaluating Row 251...\n","\n","Evaluating Row 252...\n","\n","Evaluating Row 253...\n","\n","Evaluating Row 254...\n","\n","Evaluating Row 255...\n","\n","Evaluating Row 256...\n","\n","Evaluating Row 257...\n","\n","Evaluating Row 258...\n","\n","Evaluating Row 259...\n","\n","Evaluating Row 260...\n","\n","Evaluating Row 261...\n","\n","Evaluating Row 262...\n","\n","Evaluating Row 263...\n","\n","Evaluating Row 264...\n","\n","Evaluating Row 265...\n","\n","Evaluating Row 266...\n","\n","Evaluating Row 267...\n","\n","Evaluating Row 268...\n","\n","Evaluating Row 269...\n","\n","Evaluating Row 270...\n","\n","Evaluating Row 271...\n","\n","Evaluating Row 272...\n","\n","Evaluating Row 273...\n","\n","Evaluating Row 274...\n","\n","Evaluating Row 275...\n","\n","Evaluating Row 276...\n","\n","Evaluating Row 277...\n","\n","Evaluating Row 278...\n","\n","Evaluating Row 279...\n","\n","Evaluating Row 280...\n","\n","Evaluating Row 281...\n","\n","Evaluating Row 282...\n","\n","Evaluating Row 283...\n","\n","Evaluating Row 284...\n","\n","Evaluating Row 285...\n","\n","Evaluating Row 286...\n","\n","Evaluating Row 287...\n","\n","Evaluating Row 288...\n","\n","Evaluating Row 289...\n","\n","Evaluating Row 290...\n","\n","Evaluating Row 291...\n","\n","Evaluating Row 292...\n","\n","Evaluating Row 293...\n","\n","Evaluating Row 294...\n","\n","Evaluating Row 295...\n","\n","Evaluating Row 296...\n","\n","Evaluating Row 297...\n","\n","Evaluating Row 298...\n","\n","Evaluating Row 299...\n","\n","Evaluating Row 300...\n","\n","Evaluating Row 301...\n","\n","Evaluating Row 302...\n","\n","Evaluating Row 303...\n","\n","Evaluating Row 304...\n","\n","Evaluating Row 305...\n","\n","Evaluating Row 306...\n","\n","Evaluating Row 307...\n","\n","Evaluating Row 308...\n","\n","Evaluating Row 309...\n","\n","Evaluating Row 310...\n","\n","Evaluating Row 311...\n","\n","Evaluating Row 312...\n","\n","Evaluating Row 313...\n","\n","Evaluating Row 314...\n","\n","Evaluating Row 315...\n","\n","Evaluating Row 316...\n","\n","Evaluating Row 317...\n","\n","Evaluating Row 318...\n","\n","Evaluating Row 319...\n","\n","Evaluating Row 320...\n","\n","Evaluating Row 321...\n","\n","Evaluating Row 322...\n","\n","Evaluating Row 323...\n","\n","Evaluating Row 324...\n","\n","Evaluating Row 325...\n","\n","Evaluating Row 326...\n","\n","Evaluating Row 327...\n","\n","Evaluating Row 328...\n","\n","Evaluating Row 329...\n","\n","Evaluating Row 330...\n","\n","Evaluating Row 331...\n","\n","Evaluating Row 332...\n","\n","Evaluating Row 333...\n","\n","Evaluating Row 334...\n","\n","Evaluating Row 335...\n","\n","Evaluating Row 336...\n","\n","Evaluating Row 337...\n","\n","Evaluating Row 338...\n","\n","Evaluating Row 339...\n","\n","Evaluating Row 340...\n","\n","Evaluating Row 341...\n","\n","Evaluating Row 342...\n","\n","Evaluating Row 343...\n","\n","Evaluating Row 344...\n","\n","Evaluating Row 345...\n","\n","Evaluating Row 346...\n","\n","Evaluating Row 347...\n","\n","Evaluating Row 348...\n","\n","Evaluating Row 349...\n","\n","Evaluating Row 350...\n","\n","Evaluating Row 351...\n","\n","Evaluating Row 352...\n","\n","Evaluating Row 353...\n","\n","Evaluating Row 354...\n","\n","Evaluating Row 355...\n","\n","Evaluating Row 356...\n","\n","Evaluating Row 357...\n","\n","Evaluating Row 358...\n","\n","Evaluating Row 359...\n","\n","Evaluating Row 360...\n","\n","Evaluating Row 361...\n","\n","Evaluating Row 362...\n","\n","Evaluating Row 363...\n","\n","Evaluating Row 364...\n","\n","Evaluating Row 365...\n","\n","Evaluating Row 366...\n","\n","Evaluating Row 367...\n","\n","Evaluating Row 368...\n","\n","Evaluating Row 369...\n","\n","Evaluating Row 370...\n","\n","Evaluating Row 371...\n","\n","Evaluating Row 372...\n","\n","Evaluating Row 373...\n","\n","Evaluating Row 374...\n","\n","Evaluating Row 375...\n","\n","Evaluating Row 376...\n","\n","Evaluating Row 377...\n","\n","Evaluating Row 378...\n","\n","Evaluating Row 379...\n","\n","Evaluating Row 380...\n","\n","Evaluating Row 381...\n","\n","Evaluating Row 382...\n","\n","Evaluating Row 383...\n","\n","Evaluating Row 384...\n","\n","Evaluating Row 385...\n","\n","Evaluating Row 386...\n","\n","Evaluating Row 387...\n","\n","Evaluating Row 388...\n","\n","Evaluating Row 389...\n","\n","Evaluating Row 390...\n","\n","Evaluating Row 391...\n","\n","Evaluating Row 392...\n","\n","Evaluating Row 393...\n","\n","Evaluating Row 394...\n","\n","Evaluating Row 395...\n","\n","Evaluating Row 396...\n","\n","Evaluating Row 397...\n","\n","Evaluating Row 398...\n","\n","Evaluating Row 399...\n","\n","Evaluating Row 400...\n","\n","Evaluating Row 401...\n","\n","Evaluating Row 402...\n","\n","Evaluating Row 403...\n","\n","Evaluating Row 404...\n","\n","Evaluating Row 405...\n","\n","Evaluating Row 406...\n","\n","Evaluating Row 407...\n","\n","Evaluating Row 408...\n","\n","Evaluating Row 409...\n","\n","Evaluating Row 410...\n","\n","Evaluating Row 411...\n","\n","Evaluating Row 412...\n","\n","Evaluating Row 413...\n","\n","Evaluating Row 414...\n","\n","Evaluating Row 415...\n","\n","Evaluating Row 416...\n","\n","Evaluating Row 417...\n","\n","Evaluating Row 418...\n","\n","Evaluating Row 419...\n","\n","Evaluating Row 420...\n","\n","Evaluating Row 421...\n","\n","Evaluating Row 422...\n","\n","Evaluating Row 423...\n","\n","Evaluating Row 424...\n","\n","Evaluating Row 425...\n","\n","Evaluating Row 426...\n","\n","Evaluating Row 427...\n","\n","Evaluating Row 428...\n","\n","Evaluating Row 429...\n","\n","Evaluating Row 430...\n","\n","Evaluating Row 431...\n","\n","Evaluating Row 432...\n","\n","Evaluating Row 433...\n","\n","Evaluating Row 434...\n","\n","Evaluating Row 435...\n","\n","Evaluating Row 436...\n","\n","Evaluating Row 437...\n","\n","Evaluating Row 438...\n","\n","Evaluating Row 439...\n","\n","Evaluating Row 440...\n","\n","Evaluating Row 441...\n","\n","Evaluating Row 442...\n","\n","Evaluating Row 443...\n","\n","Evaluating Row 444...\n","\n","Evaluating Row 445...\n","\n","Evaluating Row 446...\n","\n","Evaluating Row 447...\n","\n","Evaluating Row 448...\n","\n","Evaluating Row 449...\n","\n","Evaluating Row 450...\n","\n","Evaluating Row 451...\n","\n","Evaluating Row 452...\n","\n","Evaluating Row 453...\n","\n","Evaluating Row 454...\n","\n","Evaluating Row 455...\n","\n","Evaluating Row 456...\n","\n","Evaluating Row 457...\n","\n","Evaluating Row 458...\n","\n","Evaluating Row 459...\n","\n","Evaluating Row 460...\n","\n","Evaluating Row 461...\n","\n","Evaluating Row 462...\n","\n","Evaluating Row 463...\n","\n","Evaluating Row 464...\n","\n","Evaluating Row 465...\n","\n","Evaluating Row 466...\n","\n","Evaluating Row 467...\n","\n","Evaluating Row 468...\n","\n","Evaluating Row 469...\n","\n","Evaluating Row 470...\n","\n","Evaluating Row 471...\n","\n","Evaluating Row 472...\n","\n","Evaluating Row 473...\n","\n","Evaluating Row 474...\n","\n","Evaluating Row 475...\n","\n","Evaluating Row 476...\n","\n","Evaluating Row 477...\n","\n","Evaluating Row 478...\n","\n","Evaluating Row 479...\n","\n","Evaluating Row 480...\n","\n","Evaluating Row 481...\n","\n","Evaluating Row 482...\n","\n","Evaluating Row 483...\n","\n","Evaluating Row 484...\n","\n","Evaluating Row 485...\n","\n","Evaluating Row 486...\n","\n","Evaluating Row 487...\n","\n","Evaluating Row 488...\n","\n","Evaluating Row 489...\n","\n","Evaluating Row 490...\n","\n","Evaluating Row 491...\n","\n","Evaluating Row 492...\n","\n","Evaluating Row 493...\n","\n","Evaluating Row 494...\n","\n","Evaluating Row 495...\n","\n","Evaluating Row 496...\n","\n","Evaluating Row 497...\n","\n","Evaluating Row 498...\n","\n","Evaluating Row 499...\n","\n","Evaluating Row 500...\n","\n","Evaluating Row 501...\n","\n","Evaluating Row 502...\n","\n","Evaluating Row 503...\n","\n","Evaluating Row 504...\n","\n","Evaluating Row 505...\n","\n","Evaluating Row 506...\n","\n","Evaluating Row 507...\n","\n","Evaluating Row 508...\n","\n","Evaluating Row 509...\n","\n","Evaluating Row 510...\n","\n","Evaluating Row 511...\n","\n","Evaluating Row 512...\n","\n","Evaluating Row 513...\n","\n","Evaluating Row 514...\n","\n","Evaluating Row 515...\n","\n","Evaluating Row 516...\n","\n","Evaluating Row 517...\n","\n","Evaluating Row 518...\n","\n","Evaluating Row 519...\n","\n","Evaluating Row 520...\n","\n","Evaluating Row 521...\n","\n","Evaluating Row 522...\n","\n","Evaluating Row 523...\n","\n","Evaluating Row 524...\n","\n","Evaluating Row 525...\n","\n","Evaluating Row 526...\n","\n","Evaluating Row 527...\n","\n","Evaluating Row 528...\n","\n","Evaluating Row 529...\n","\n","Evaluating Row 530...\n","\n","Evaluating Row 531...\n","\n","Evaluating Row 532...\n","\n","Evaluating Row 533...\n","\n","Evaluating Row 534...\n","\n","Evaluating Row 535...\n","\n","Evaluating Row 536...\n","\n","Evaluating Row 537...\n","\n","Evaluating Row 538...\n","\n","Evaluating Row 539...\n","\n","Evaluating Row 540...\n","\n","Evaluating Row 541...\n","\n","Evaluating Row 542...\n","\n","Evaluating Row 543...\n","\n","Evaluating Row 544...\n","\n","Evaluating Row 545...\n","\n","Evaluating Row 546...\n","\n","Evaluating Row 547...\n","\n","Evaluating Row 548...\n","\n","Evaluating Row 549...\n","\n","Evaluating Row 550...\n","\n","Evaluating Row 551...\n","\n","Evaluating Row 552...\n","\n","Evaluating Row 553...\n","\n","Evaluating Row 554...\n","\n","Evaluating Row 555...\n","\n","Evaluating Row 556...\n","\n","Evaluating Row 557...\n","\n","Evaluating Row 558...\n","\n","Evaluating Row 559...\n","\n","Evaluating Row 560...\n","\n","Evaluating Row 561...\n","\n","Evaluating Row 562...\n","\n","Evaluating Row 563...\n","\n","Evaluating Row 564...\n","\n","Evaluating Row 565...\n","\n","Evaluating Row 566...\n","\n","Evaluating Row 567...\n","\n","Evaluating Row 568...\n","\n","Evaluating Row 569...\n","\n","Evaluating Row 570...\n","\n","Evaluating Row 571...\n","\n","Evaluating Row 572...\n","\n","Evaluating Row 573...\n","\n","Evaluating Row 574...\n","\n","Evaluating Row 575...\n","\n","Evaluating Row 576...\n","\n","Evaluating Row 577...\n","\n","Evaluating Row 578...\n","\n","Evaluating Row 579...\n","\n","Evaluating Row 580...\n","\n","Evaluating Row 581...\n","\n","Evaluating Row 582...\n","\n","Evaluating Row 583...\n","\n","Evaluating Row 584...\n","\n","Evaluating Row 585...\n","\n","Evaluating Row 586...\n","\n","Evaluating Row 587...\n","\n","Evaluating Row 588...\n","\n","Results saved to: /content/drive/MyDrive/Colab Notebooks/SKQA_Evaluation/evaluation_Mistral_RAG.csv\n"]}]},{"cell_type":"markdown","source":["**Bleu score Evaluation**"],"metadata":{"id":"KdnmHs1lCnLD"}},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","from langchain.chains import LLMChain\n","from langchain.prompts import PromptTemplate\n","from langchain.evaluation import load_evaluator\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.vectorstores import FAISS\n","import numpy as np\n","import pandas as pd\n","import PyPDF2\n","import nltk\n","import re\n","import numpy as np\n","import os\n","import openai\n","from PyPDF2 import PdfReader\n","from sklearn.metrics.pairwise import cosine_similarity\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk import pos_tag\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from openai import OpenAI\n","\n","# Download required NLTK data\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('punkt_tab') # Download punkt_tab resource\n","nltk.download('averaged_perceptron_tagger_eng') # Download the correct resource\n","os.environ['OPENAI_API_KEY'] = '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'\n","\n","\n","# Download required resources\n","nltk.download('punkt')\n","\n","# Function to compute BLEU score for a single row\n","def compute_bleu_score(generated, reference):\n","    try:\n","        # Tokenize both\n","        candidate = word_tokenize(generated.lower())\n","        reference_tokens = word_tokenize(reference.lower())\n","        references = [reference_tokens]  # BLEU expects a list of references\n","\n","        if not candidate or not reference_tokens:\n","            return 0.0\n","\n","        # Apply smoothing\n","        smoothie = SmoothingFunction().method4\n","        bleu = sentence_bleu(references, candidate, smoothing_function=smoothie)\n","        return bleu\n","    except Exception as e:\n","        print(f\"Error computing BLEU score: {e}\")\n","        return 0.0\n","\n","# Function to process CSV and compute BLEU scores\n","def evaluate_bleu_from_csv(csv_path, output_path=None):\n","    df = pd.read_csv(csv_path)\n","\n","    # Normalize column names\n","    df.columns = [col.strip().lower().replace(\" \", \"_\") for col in df.columns]\n","\n","    if not {'generated_answer', 'references_answer'}.issubset(df.columns):\n","        raise ValueError(\"CSV must contain 'generated_answer' and 'references_answer' columns.\")\n","\n","    results = []\n","    for idx, row in df.iterrows():\n","        gen_ans = row['generated_answer']\n","        ref_ans = row['references_answer']\n","\n","        bleu = compute_bleu_score(gen_ans, ref_ans)\n","        print(f\"Row {idx+1} BLEU Score: {bleu:.4f}\")\n","\n","        results.append({\n","            \"generated_answer\": gen_ans,\n","            \"references_answer\": ref_ans,\n","            \"BLEU Score\": bleu\n","        })\n","\n","    result_df = pd.DataFrame(results)\n","\n","    if output_path:\n","        result_df.to_csv(output_path, index=False)\n","        print(f\"\\nSaved results to: {output_path}\")\n","\n","    return result_df\n","\n","# === Example usage ===\n","csv_input_path = \"/content/drive/MyDrive/Colab Notebooks/SKQA_Evaluation/Evaluate_mistral_rag.csv\"         # Input file\n","csv_output_path = \"/content/drive/MyDrive/Colab Notebooks/SKQA_Evaluation/bleu_scores_mistral_RAG_output.csv\"            # Output file (optional)\n","\n","results_df = evaluate_bleu_from_csv(csv_input_path, csv_output_path)\n","print(\"\\nFinal BLEU Results:\\n\", results_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j80L2FBk_zrb","executionInfo":{"status":"ok","timestamp":1753413368985,"user_tz":-480,"elapsed":709,"user":{"displayName":"Nguyễn Quốc Việt","userId":"08766828920388171241"}},"outputId":"78d4b6cd-0e10-41ba-ee76-a9dee50b5c1a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["Row 1 BLEU Score: 1.0000\n","Row 2 BLEU Score: 1.0000\n","Row 3 BLEU Score: 0.9759\n","Row 4 BLEU Score: 0.9726\n","Row 5 BLEU Score: 0.0625\n","Row 6 BLEU Score: 0.4204\n","Row 7 BLEU Score: 0.9726\n","Row 8 BLEU Score: 0.9266\n","Row 9 BLEU Score: 0.9765\n","Row 10 BLEU Score: 0.9063\n","Row 11 BLEU Score: 0.6260\n","Row 12 BLEU Score: 0.0950\n","Row 13 BLEU Score: 0.5065\n","Row 14 BLEU Score: 0.8726\n","Row 15 BLEU Score: 0.8736\n","Row 16 BLEU Score: 0.5198\n","Row 17 BLEU Score: 0.9506\n","Row 18 BLEU Score: 0.2202\n","Row 19 BLEU Score: 0.6746\n","Row 20 BLEU Score: 0.8800\n","Row 21 BLEU Score: 0.9021\n","Row 22 BLEU Score: 0.9692\n","Row 23 BLEU Score: 0.9109\n","Row 24 BLEU Score: 0.9701\n","Row 25 BLEU Score: 0.9550\n","Row 26 BLEU Score: 0.8763\n","Row 27 BLEU Score: 0.9718\n","Row 28 BLEU Score: 0.1207\n","Row 29 BLEU Score: 0.5156\n","Row 30 BLEU Score: 0.4018\n","Row 31 BLEU Score: 0.9649\n","Row 32 BLEU Score: 0.6945\n","Row 33 BLEU Score: 0.9534\n","Row 34 BLEU Score: 1.0000\n","Row 35 BLEU Score: 0.0219\n","Row 36 BLEU Score: 1.0000\n","Row 37 BLEU Score: 1.0000\n","Row 38 BLEU Score: 0.4834\n","Row 39 BLEU Score: 0.9607\n","Row 40 BLEU Score: 0.9511\n","Row 41 BLEU Score: 1.0000\n","Row 42 BLEU Score: 0.5129\n","Row 43 BLEU Score: 1.0000\n","Row 44 BLEU Score: 0.9452\n","Row 45 BLEU Score: 0.9046\n","Row 46 BLEU Score: 0.6231\n","Row 47 BLEU Score: 0.6086\n","Row 48 BLEU Score: 0.9740\n","Row 49 BLEU Score: 0.7348\n","Row 50 BLEU Score: 0.9682\n","Row 51 BLEU Score: 0.5978\n","Row 52 BLEU Score: 0.0596\n","Row 53 BLEU Score: 0.8440\n","Row 54 BLEU Score: 0.7954\n","Row 55 BLEU Score: 0.7517\n","Row 56 BLEU Score: 1.0000\n","Row 57 BLEU Score: 0.8381\n","Row 58 BLEU Score: 0.6819\n","Row 59 BLEU Score: 0.9120\n","Row 60 BLEU Score: 0.9718\n","Row 61 BLEU Score: 0.9692\n","Row 62 BLEU Score: 0.9452\n","Row 63 BLEU Score: 0.8856\n","Row 64 BLEU Score: 0.7930\n","Row 65 BLEU Score: 0.8575\n","Row 66 BLEU Score: 1.0000\n","Row 67 BLEU Score: 1.0000\n","Row 68 BLEU Score: 1.0000\n","Row 69 BLEU Score: 1.0000\n","Row 70 BLEU Score: 0.6431\n","Row 71 BLEU Score: 0.9820\n","Row 72 BLEU Score: 1.0000\n","Row 73 BLEU Score: 1.0000\n","Row 74 BLEU Score: 0.9009\n","Row 75 BLEU Score: 0.7848\n","Row 76 BLEU Score: 0.9485\n","Row 77 BLEU Score: 1.0000\n","Row 78 BLEU Score: 1.0000\n","Row 79 BLEU Score: 0.9573\n","Row 80 BLEU Score: 1.0000\n","Row 81 BLEU Score: 0.8986\n","Row 82 BLEU Score: 1.0000\n","Row 83 BLEU Score: 0.4834\n","Row 84 BLEU Score: 0.8674\n","Row 85 BLEU Score: 1.0000\n","Row 86 BLEU Score: 0.3620\n","Row 87 BLEU Score: 1.0000\n","Row 88 BLEU Score: 0.8409\n","Row 89 BLEU Score: 0.9485\n","Row 90 BLEU Score: 0.5685\n","Row 91 BLEU Score: 0.9672\n","Row 92 BLEU Score: 0.8493\n","Row 93 BLEU Score: 0.9636\n","Row 94 BLEU Score: 1.0000\n","Row 95 BLEU Score: 0.5203\n","Row 96 BLEU Score: 0.8640\n","Row 97 BLEU Score: 0.9426\n","Row 98 BLEU Score: 0.8751\n","Row 99 BLEU Score: 0.8320\n","Row 100 BLEU Score: 1.0000\n","\n","Saved results to: /content/drive/MyDrive/Colab Notebooks/SKQA_Evaluation/bleu_scores_mistral_RAG_output.csv\n","\n","Final BLEU Results:\n","                                      generated_answer  \\\n","0     A data model is a set of concepts that descr...   \n","1     A database schema is a description of the st...   \n","2     A database state refers to the actual data s...   \n","3    The internal schema is a crucial component of...   \n","4    The conceptual schema is a high-level descrip...   \n","..                                                ...   \n","95   Based on the provided context, a Right Outer ...   \n","96    The keyword DISTINCT is used in SQL to elimi...   \n","97   The keyword \"unique\" in SQL is used to enforc...   \n","98    The SQL (Structured Query Language) is a com...   \n","99    A candidate key in a database is a minimal s...   \n","\n","                                    references_answer  BLEU Score  \n","0   A data model is a set of concepts that describ...    1.000000  \n","1   A database schema is a description of the stru...    1.000000  \n","2   A database state refers to the actual data sto...    0.975886  \n","3   The internal schema is a crucial component of ...    0.972577  \n","4   The internal schema is a crucial component of ...    0.062479  \n","..                                                ...         ...  \n","95  A RIGHT OUTER JOIN is a type of join in SQL th...    0.864009  \n","96  The keyword DISTINCT is used in SQL to elimina...    0.942615  \n","97  The keyword UNIQUE in SQL is used to enforce a...    0.875086  \n","98  SQL, which stands for Structured Query Languag...    0.831995  \n","99  A candidate key in a database is a minimal set...    1.000000  \n","\n","[100 rows x 3 columns]\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}